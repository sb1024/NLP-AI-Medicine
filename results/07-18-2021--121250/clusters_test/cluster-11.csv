text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Innovative Vaccine Approaches ABSTRACT Support is requested for a Keystone Symposia conference entitled Innovative Vaccine Approaches, organized by Drs. Mariagrazia Pizza, Galit Alter and Gordon Dougan. The conference will be held in Vancouver, Canada from June 27- July 1, 2021. Vaccines have the power to prevent and potentially eradicate a wide range of infectious diseases, representing one of the most effective life-saving measures at our disposal against global health threats. The recent coronavirus pandemic has brought the importance and urgency of vaccine development efforts into sharp focus. Moreover, the vaccinology field is evolving very rapidly, thanks to advances in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis of antigens and antigen- antibody complexes and impacts of variation. Over the years, this field has also experienced an elucidation of mechanisms of immunity and protection, and identification of correlates. However, many questions are still unsolved and innovative approaches are needed to address new vaccine challenges like antimicrobial resistance, emerging infectious diseases, cancer and diseases associated with our aging population. This conference will cover the latest advances and novel approaches towards vaccine development, including: (1) novel antigen delivery systems; (2) in vitro and in vivo model systems for vaccine appraisal (3) the use of human challenge models; (4) the role of ‘systems biology’ in the comprehensive analysis of immune correlates, biomarker identification and safety; (5) machine-learning approaches to define correlations between antibody repertoires and protection; and (6) strategies for developing low cost vaccines for economically challenged populations. Together these topics will provide attendees with the new ideas and tools to continue to forge new frontiers in vaccine capabilities. PROJECT NARRATIVE Vaccines have the power to prevent and potentially eradicate a wide range of both infectious and non- infectious diseases. The field is evolving very rapidly due to improvements in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis techniques. This conference will accelerate advances the field, bringing together public and private communities to ensure the end of the COVID-19 pandemic and other epidemics that afflict the population. This event provides a unique opportunity for discussion of the key challenges in making low cost vaccines for economically challenged populations and how to address burning topics such as pandemics, antimicrobial resistance, emerging infectious diseases, cancer and an aging population.",Innovative Vaccine Approaches,10237543,R13AI161938,"['Address', 'Antibody Repertoire', 'Antigen-Antibody Complex', 'Antigens', 'Antimicrobial Resistance', 'Biological Models', 'COVID-19 pandemic', 'Canada', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Coronavirus', 'Disease', 'Educational workshop', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Event', 'Future', 'Genomics', 'Human', 'Immersion', 'Immune', 'Immunity', 'Immunology', 'In Vitro', 'Knowledge', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Microbiology', 'Modeling', 'Outcome', 'Population', 'Privatization', 'Research', 'Research Personnel', 'Role', 'Safety', 'Savings', 'Scientist', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Vaccines', 'Variant', 'aging population', 'biomarker identification', 'clinical practice', 'cost', 'experience', 'frontier', 'global health', 'in vivo Model', 'innovation', 'manufacturability', 'next generation', 'novel', 'novel strategies', 'novel vaccines', 'pandemic disease', 'posters', 'prevent', 'symposium', 'tool', 'vaccine development', 'vaccine discovery', 'vaccinology']",NIAID,KEYSTONE SYMPOSIA,R13,2021,8000
"Maximizing Investigators' Research Award (R35) PROJECT SUMMARY The “Tools for Transmission of Agents and Conditions (TRAC)” program will synergize statistical and mathematical modeling work in three areas of application: 1) Tuberculosis (TB) incidence and transmission; 2) monitoring substance use disorder (SUD) patterns; and 3) SARS CoV-2 transmission modeling. These three conditions are major public health problems, with TB being the leading cause of infectious disease death globally, SUD causing more deaths in the United States than HIV/AIDS in its peak, and SARS CoV-2 causing a pandemic with societal disruption and mortality exceeding anything we have experienced in the last century. We need improved analytical tools that leverage existing data to monitor these diseases, infer transmission hot spots, determine the efficacy of interventions, and understand the burden of these conditions. This program will bring together an expert group of quantitative researchers with skills that are readily applied to these problems. We also leverage our strong collaborations with clinician researchers and public health officials to ensure that the methods we develop are addressing important questions and consistent with our current understanding of these diseases. By creating a program to facilitate communication between these experts, we will enable greater innovation in modeling key aspects of these diseases and create exciting methodological synergies across diseases. Our team is well positioned to incorporate data from emerging technologies, including high throughput sequencing data to determine TB risk signatures and inform transmission links for TB and SARS CoV-2. Our expertise in machine learning, a broad range of statistical methodologies, and mathematical modeling will enable us to leverage the rich information in large databases that are emerging to better understand SUD patterns and identify risk signatures. We will also build infrastructure with our partners to make the analytical tools that we develop more accessible to public health practitioners and other researchers. The impact of this work is to develop a suite of analytical tools that leverage rapidly emerging rich data sets to improve our understanding of disease transmission patterns, monitor changing dynamics of these conditions, and understand intervention strategies that are most effective. This work will inform public health practice for these diseases and create reproducible tools that can be used in an ongoing way. PROJECT NARRATIVE This project will generate analytical tools to address three major public health challenges: 1) Tuberculosis, 2) Substance use disorders, and 3) SARS CoV-2. These tools will improve our understanding of the transmission patterns of these diseases, advance our ability to monitor them, and inform intervention strategies. We will build infrastructure to make these methods available to public health practitioners and other researchers.",Maximizing Investigators' Research Award (R35),10205596,R35GM141821,"['2019-nCoV', 'AIDS/HIV problem', 'Address', 'Area', 'Award', 'Cessation of life', 'Collaborations', 'Communicable Diseases', 'Communication', 'Data', 'Data Set', 'Databases', 'Disease', 'Emerging Technologies', 'Ensure', 'High-Throughput Nucleotide Sequencing', 'Hot Spot', 'Incidence', 'Infrastructure', 'Intervention', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Pattern', 'Positioning Attribute', 'Public Health', 'Public Health Practice', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'SARS-CoV-2 transmission', 'Statistical Models', 'Substance Use Disorder', 'Treatment Efficacy', 'Tuberculosis', 'United States', 'Work', 'analytical tool', 'disease transmission', 'experience', 'improved', 'innovation', 'mathematical model', 'mortality', 'pandemic disease', 'programs', 'skills', 'synergism', 'tool', 'transmission process']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R35,2021,171876
"Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center The “clinical high risk” (CHR) for psychosis syndrome is an antecedent period characterized by attenuated psychotic symptoms that are marked by subtle deviations from normal development in thinking, motivation, affect, behavior, and a decline in functioning. Early intervention in this CHR population is critical to prevent psychosis onset as well as other adverse outcomes. However, the presentation of symptoms and subsequent course is highly variable, and there is a paucity of biomarkers to guide treatment development. Thus, to improve predictive models that are clinically relevant, several issues need to be addressed: 1) focusing on outcomes beyond psychosis; 2) taking into account heterogeneity in samples and outcomes; and 3) integrating data sets with a broad array of variables using innovative algorithms to overcome variability across studies. To address these challenges, the proposed “Psychosis Risk Evaluation Data Integration and Computational Technologies: Data Processing, Analysis, and Coordination Center” (PREDICT-DPACC) brings together a multidisciplinary team of highly experienced researchers with proven capabilities in all aspects of large-scale studies, CHR studies, as well as computational expertise. The ultimate goal is to identify new CHR biomarkers, and CHR subtypes that will enhance future clinical trials. To do so, the PREDICT-DPACC will 1) aggregate extant CHR- related data sets from legacy datasets; 2) provide collaborative management, direction, data processing and coordination for new U01 multisite network(s); and 3) develop and apply advanced algorithms to identify biomarkers that predict outcomes, and to stratify CHR into subtypes based on outcome trajectories, first from the extant data and then refined and applied to the new data. The PREDICT-DPACC team has the broad, comprehensive, and robust infrastructure that is sufficiently flexible to accommodate the inclusion of multiple data types and to optimally address the needs of the CHR U01 network(s). Carefully selected extant data will be rapidly obtained, processed, and uploaded to the NIMH Data Archive (NDA). Proposed analysis methods are powerful and robust, leveraging the expertise and experience of computer scientist developers, and experienced clinical researchers. The U01 network(s) will be coordinated by a team that is experienced in managing large studies, familiar with the needs of such studies, flexible, and is knowledgeable in all aspects of CHR studies, including measures, outcomes, biomarkers, and cohorts. Upon meeting the goals of this U24, and the supported U01 network(s), the expected outcomes of the PREDICT-DPACC will be new predictive biomarkers for CHR outcomes, new definitions of CHR subtypes that are clinically useful, and new curated and comprehensive CHR datasets (extant and new) as well as processing tools and prediction algorithms that are shared with the research community through the NIMH Data Archive. NARRATIVE The “Clinical High Risk” (CHR) for psychosis syndrome in young people represents an opportune window for early intervention to prevent the onset of psychosis and other disorders, and to forestall disability; however, clinical heterogeneity and the paucity of biomarkers have hampered the development of effective intervention. To address these challenges, working with NIMH and key stakeholders, we will harmonize and aggregate existing “legacy” CHR data, and guide and coordinate the collection of new data across a network of sites, to develop biomarker algorithms that can predict individual trajectories for diverse outcomes. This proposal leverages a multidisciplinary team with broad and CHR-specific experience in large-scale multisite and multimodal studies (including clinical trials), along with expertise in data type-specific processing, coordination, analysis, and computational analyses (e.g., machine and deep learning tools from artificial intelligence, and advanced statistical approaches), ethics, community outreach, and data dissemination, all of which will ensure the success of this project.","Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center",10256796,U24MH124629,"['Address', 'Adolescent', 'Affect', 'Algorithms', 'Anxiety Disorders', 'Artificial Intelligence', 'Attenuated', 'Behavior', 'Big Data', 'Biological Markers', 'Child', 'Clinical', 'Clinical Trials', 'Collection', 'Common Data Element', 'Communities', 'Community Outreach', 'Computer Analysis', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease remission', 'Early Intervention', 'Early identification', 'Enrollment', 'Ensure', 'Ethics', 'Evaluation', 'FAIR principles', 'Follow-Up Studies', 'Funding', 'Future', 'Goals', 'Heterogeneity', 'Human Resources', 'Impaired cognition', 'Individual', 'Informatics', 'Infrastructure', 'Instruction', 'Intervention', 'Lead', 'Leadership', 'Longterm Follow-up', 'Machine Learning', 'Measures', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Monitor', 'Moods', 'Motivation', 'National Institute of Mental Health', 'Online Systems', 'Outcome', 'Output', 'Perception', 'Procedures', 'Process', 'Protocols documentation', 'Psychotic Disorders', 'Quality Control', 'Recovery', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sampling', 'Scientist', 'Secure', 'Site', 'Social Functioning', 'Standardization', 'Substance Use Disorder', 'Suggestion', 'Symptoms', 'Technology', 'Thinking', 'Time', 'Training', 'Transact', 'United States', 'Validation', 'Visualization software', 'adverse outcome', 'analytical tool', 'attenuated psychosis syndrome', 'base', 'bioinformatics infrastructure', 'candidate marker', 'clinical heterogeneity', 'clinical risk', 'clinical subtypes', 'clinically relevant', 'cloud based', 'cohort', 'computerized data processing', 'data acquisition', 'data archive', 'data dictionary', 'data dissemination', 'data harmonization', 'data infrastructure', 'data integration', 'data tools', 'deep learning', 'demographics', 'design', 'disability', 'effective intervention', 'experience', 'flexibility', 'functional decline', 'functional disability', 'high risk', 'high risk population', 'improved', 'inclusion criteria', 'innovation', 'meetings', 'member', 'multidisciplinary', 'multimodal data', 'multimodality', 'multiple data types', 'outcome prediction', 'persistent symptom', 'prediction algorithm', 'predictive marker', 'predictive modeling', 'prevent', 'prospective', 'psychotic symptoms', 'quality assurance', 'recruit', 'research study', 'resilience', 'response', 'risk prediction', 'risk stratification', 'success', 'therapy development', 'tool', 'working group']",NIMH,BRIGHAM AND WOMEN'S HOSPITAL,U24,2021,3917810
"ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks We propose an Autonomous Relay Agent for Generation of Ranked Networks (ARAGORN), which will query Knowledge Providers (KPs) and synthesize answers relevant to user-specified questions, building upon algorithms and components developed as part of the ROBOKOP [1,2] application during the feasibility phase of Translator. The ARAGORN services represent the next generation of ROBOKOP component services, iterating and innovating in response to challenges exposed in the Translator feasibility phase. Based on that work, we have identified overarching issues that must be addressed to truly unleash the power of Translator. 1. ARAs must be able to operate in a federated knowledge environment effectively and efficiently. First-generation Translator tools assembled full data sets from which to extract answers, which were subsequently ranked. Second-generation tools must be able to efficiently operate on massive, distributed data, demanding a new approach. ARAGORN will act asynchronously, interleaving KP queries with partial scoring of answers, prioritizing search directions on-the-fly, and delivering early results that are updated over time in response to newly explored paths 2. ARAs must bridge the precision mismatch between data representations and algorithms that require specificity, and users who pose questions and prefer answers at a more abstract level. Biomedical scientists do not pose questions as database queries. Furthermore, even expert users of current biomedical databases such as ROBOKOP KG or RTX require exploration and experimentation to craft queries to express their intent. ARAGORN will employ multiple strategies to remove this barrier to asking questions effectively, from basic maintenance of a question library, to node generalization, query rewriting, and machine learning techniques such as capsule graph networks. ARAGORN will further use elements of specific answers to create gestalt explanations, clustering, and combining answers with similar content, revealing the commonalities and contradictions in answers. 3. ARAs must be able to generalize answer ranking to address a broader range of question formulations and data types, and to account for counterevidence. In the Translator implementation phase, we anticipate having access to many varied KPs and ARAs that provide diverse quantitative metadata regarding the confidence in assertions or strength of associations. There will be a pressing need to synthesize such data into scores for arbitrarily-shaped answer graphs, in order to filter and prioritize answers for further analysis or user digestion. ARAGORN will address this need by providing a novel scoring algorithm capable of (a) scoring arbitrary directed multi-hypergraphs, (b) accounting for heterogeneous quantitative metadata; and (c) leveraging relationship polarity to incorporate counterevidence. ARAGORN will provide access to this functionality, and connect to KPs using community-defined APIs and data models. The ARAGORN team has contributed to these community efforts during the Translator feasibility phase, and if funded will continue to work with the Standards and Reference Implementations (SRI) group, NCATS staff, and other awardees to continue to define and refine methods and models for data sharing and collaboration. The ARAGORN services will be created with collaboration in mind, such that they can be plugged into larger pipelining and architectural efforts. Most of the risks to the ARAGORN strategy are shared by the entire program; as standardization evolves, the ARAGORN team and other members of the Translator consortium will be required to spend effort updating components. ARAGORN will require access to ontology and similarity tools that we anticipate will be provided by KPs or shared infrastructure; if these do not materialize, the ARAGORN team will create the tools that it needs to accomplish its goals. Additionally, we are assuming the existence of fully translator-compliant KPs from which to draw data; if the program collectively decides that compliance is enforced in ARAs instead, we will draw on our work in ROBOKOP to implement the necessary normalization components in ARAGORN. n/a",ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks,10332268,OT2TR003441,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Collaborations', 'Communities', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Digestion', 'Elements', 'Environment', 'Formulation', 'Funding', 'Generations', 'Goals', 'Graph', 'Infrastructure', 'Knowledge', 'Libraries', 'Machine Learning', 'Maintenance', 'Metadata', 'Methods', 'Mind', 'Modeling', 'Ontology', 'Phase', 'Provider', 'Risk', 'Services', 'Specific qualifier value', 'Specificity', 'Standardization', 'Techniques', 'Time', 'Update', 'Work', 'arbitrary spin', 'base', 'biomedical scientist', 'capsule', 'data modeling', 'data sharing', 'database query', 'distributed data', 'innovation', 'member', 'next generation', 'novel', 'novel strategies', 'programs', 'response', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,1052712
"Biomedical Data Translator Development of Autonomous Relay Agent: ARAX This project would continue collaborative work within the Translator consortium by a multi-site team (“Team X-ray”) at Oregon State University (PI Stephen Ramsey) and at two partner institutions, Pennsylvania State University (PI Koslicki) and the Institute for Systems Biology (PI Eric Deutsch; Co-I Jared Roach). Team X-ray was highly productive in Translator's feasibility assessment phase and the team brings critical expertise to Translator (see Resources). Component type: We propose to create, validate, and integrate an autonomous relay agent (ARA) called ARAX . ARAX will be a middleware component in the new Translator architecture that will extend significantly beyond the capabilities of the prototype reasoning tool (RTX) that we created in the feasibility assessment phase. Depending on the input request, ARAX's main output will be ranked subgraphs with clearly explained ranking basis. ARAX will leverage code and algorithms from RTX and will have an explicit application focus area, as described below. Main problems that ARAX is trying to address: Connections within a biomedical knowledge graph have highly variable degrees of (i) confidence (due to ambiguous predicates and/or due to highly variable degrees of reliability of knowledge types) and (ii) potential relevance to the user's query. Such edge-significance variability leads to both incorrect and difficult-to-interpret results which together pose a significant problem for creating broadly useful tools for computer-based biomedical reasoning. We propose to address this problem by explicitly accounting for these two types of edge variability in the reasoning algorithms–spanning a broad range of biomedical query types–that ARAX will provide to Translator. In addition to these broad capabilities, as described in the Project Plan, we will incorporate advanced algorithms in ARAX for responding to queries relating to disease therapy, including (1) drug repositioning for known disease, leveraging knowledge about the disease’s pathogenesis [1] ; and (2) therapeutic recommendations for rare diseases based on symptoms and the putative causal genetic variant. Plan for implementation of the project: In our Project Plan we describe a five-year timeline for creating, validating, and integrating ARAX within Translator, beginning with a three-month sprint leading to a prototype of ARAX by mid-March 2020. Key components of the plan include: (1) leveraging the BioThings Explorer software framework to enable ARAX to dynamically map between compounds, proteins, pathways, variants, phenotypes, and diseases based on knowledge source application programming interfaces in the Translator registry; (2) leveraging COHD and related Translator resources to obtain biomedical semantic distance information; (3) leveraging an application programming interface endpoint for the RTX biomedical knowledge graph, KG2; and (4) implementing probabilistic reasoning algorithms leveraging provenance information and dynamically determined edge relevance scores to improve reasoning. We will systematically use machine-learning to align ranking scores with measures of output quality. Collaboration strengths of our team include (i) developing technical standards for communications between Translator software agents (leveraging PI Deutsch’s extensive past experience); (ii) developing knowledge graph standards (leveraging PI Ramsey’s and PI Koslicki’s expertise); and (iii) deriving use-case vignettes that speak to the transformative potential of Translator (leveraging Co-I Roach’s and PI Ramsey’s expertise). In the development phase, our team would continue to collaborate with other teams and with NIH stakeholders in an adaptive, high-bandwidth, and team-boundary-agnostic fashion, as detailed in the Project Plan. Key challenges to building the proposed system are (1) the need to be able to ""chain"" together analytical steps between tools and (2) the need for cooperative development of standards that enable Translator components to interact; we address them in detail in the Project Plan. n/a",Biomedical Data Translator Development of Autonomous Relay Agent: ARAX,10333468,OT2TR003428,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Area', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disease', 'Institutes', 'Institution', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Oregon', 'Output', 'Pathogenesis', 'Pathway interactions', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Proteins', 'Rare Diseases', 'Recommendation', 'Registries', 'Resources', 'Roentgen Rays', 'Semantics', 'Site', 'Software Framework', 'Source', 'Symptoms', 'System', 'Systems Biology', 'Therapeutic', 'TimeLine', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'application programming interface', 'base', 'experience', 'genetic variant', 'improved', 'knowledge graph', 'middleware', 'prototype', 'tool']",NCATS,OREGON STATE UNIVERSITY,OT2,2021,897051
"Education Pathways for Biomedical Data Science (R25) Project Summary / Abstract This project brings together Drexel University and the Children’s Hospital of Philadelphia (CHOP) to create an adaptive Biomedical Data Science education program to empower researchers to learn and use emerging data science methods. We propose an in-line program to prepare researchers for data-driven work directly in their current field, while also identifying avenues for interdisciplinary collaboration. We will develop novel curricula pathways, leverage existing educational resources, create bridge materials, and provide practicum “lab” activities matching domain-specific projects to participants for hands-on experience. Educational Pathways in Biomedical Data Science will collaborate with the CHOP Office of Academic Training and Outreach Programs to engage a diverse learner audience in novel pedagogical research. Learners will be recruited from active participants in many existing CHOP training initiatives, including a novel data science education program, graduate student training, postdoc mentorship, physician fellowship research, and clinical research staff training. After enrollment, education program managers will cluster participants into collaborative communities of practice where they will receive mentorship and contribute to development of pathways. We acknowledge that we are still learning the most effective interventions for biomedical data science education, both within our specific communities and broadly within medical education (e.g. Federer et al., 2015; Rowhani-Faarid, Allen, and Barnett, 2017). We will develop new evidence of gaps in knowledge, skills, and attitudes among learners. We will develop and implement biomedical data science literacy instruments based on emerging scholarship. We will also gather learner feedback via mixed methods to adapt and evolve our modular resources, ensure robust learner outcomes, and align deliverables with the NIH Strategic Plan for Data Science. Data Science instruction for researchers outside of traditional computer and information sciences is a concrete step toward data-driven scientific literacy for all. We will ensure that participants emerge from this program with computational and algorithmic literacy solidified through hands-on experience. For non-computing researchers, we also will provide the foundational data fluencies necessary for individuals to contribute meaningfully to machine learning research, which will enable data-driven systems, insight-to-decision transformation, decision- making, and data-driven decision management. Finally, for all participants, we will strive to help individuals from a broad spectrum of backgrounds and identities identify new directions in which to develop their careers. Project Narrative “Educational Pathways in Biomedical Data Science” will create evidence-based pathways to guide and augment researcher skill in data-intensive science. Our learning pathways and supporting modules will equip researchers to perform nimble research with massive datasets that span institutional and disciplinary boundaries. We will model cross-disciplinary collaboration by building upon an existing partnership between the College of Computing and Informatics of Drexel University and the Research Institute of the Children’s Hospital of Philadelphia, grounding the project in both computing and biomedical research practice.",Education Pathways for Biomedical Data Science (R25),10199482,R25GM141501,"['Academic Training', 'Attitude', 'Biomedical Research', 'Certification', 'Clinical Research', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Community of Practice', 'Computational algorithm', 'Custom', 'Data', 'Data Science', 'Data Set', 'Decision Making', 'Degree program', 'Development', 'Discipline', 'Ecosystem', 'Education', 'Educational Curriculum', 'Effectiveness', 'Enrollment', 'Ensure', 'Feedback', 'Fellowship', 'Foundations', 'Goals', 'Grouping', 'Home environment', 'Individual', 'Informatics', 'Information Sciences', 'Instruction', 'Knowledge', 'Learning', 'Learning Module', 'Literature', 'Machine Learning', 'Medical Education', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Motivation', 'Outcome', 'Participant', 'Pathway interactions', 'Pediatric Hospitals', 'Peer Review', 'Philadelphia', 'Physicians', 'Plant Roots', 'Postdoctoral Fellow', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Scholarship', 'Science', 'Strategic Planning', 'System', 'Training', 'Training Programs', 'Translating', 'United States National Institutes of Health', 'Universities', 'Work', 'acronyms', 'base', 'biomedical data science', 'biomedical informatics', 'career', 'cohort', 'college', 'computer science', 'education pathway', 'education resources', 'effective intervention', 'evidence base', 'experience', 'formative assessment', 'graduate student', 'insight', 'instrument', 'interdisciplinary collaboration', 'interest', 'literacy', 'novel', 'online course', 'outreach program', 'pedagogy', 'programs', 'science education', 'scientific literacy', 'skills', 'statistics', 'student training', 'success', 'user centered design']",NIGMS,CHILDREN'S HOSP OF PHILADELPHIA,R25,2021,85673
"DOCKET: accelerating knowledge extraction from biomedical data sets Component type: This Knowledge Provider project will continue and significantly extend work done by the Translator Consortium Blue Team, focusing on deriving knowledge from real-world data through complex analytic workflows, integrated to the Translator Knowledge Graph, and served via tools like Big GIM and the Translator Standard API. The problem: We aim to solve the “first mile” problem of translational research: how to integrate the multitude of dynamic small-to-large data sets that have been produced by the research and clinical communities, but that are in different locations, processed in different ways, and in a variety of formats that may not be mutually interoperable. Integrating these data sets requires significant manual work downloading, reformatting, parsing, indexing and analyzing each data set in turn. The technical and ethical challenges of accessing diverse collections of big data, efficiently selecting information relevant to different users’ interests, and extracting the underlying knowledge are problems that remain unsolved. Here, we propose to leverage lessons distilled from our previous and ongoing big data analysis projects to develop a highly automated tool for removing these bottlenecks, enabling researchers to analyze and integrate many valuable data sets with ease and efficiency, and making the data FAIR [1]. Plan: (AIM 1) We will analyze and extract knowledge from rich real-world biomedical data sets (listed in the Resources page) in the domains of wellness, cancer, and large-scale clinical records. (AIM 2) We will formalize methods from Aim 1 to develop DOCKET, a novel tool for onboarding and integrating data from multiple domains. (AIM 3) We will work with other teams to adapt DOCKET to additional knowledge domains. ■ The DOCKET tool will offer 3 modules: (1) DOCKET Overview: Analysis of, and knowledge extraction from, an individual data set. (2) DOCKET Compare: Comparing versions of the same data set to compute confidence values, and comparing different data sets to find commonalities. (3) DOCKET Integrate: Deriving knowledge through integrating different data sets. ■ Researchers will be able to parameterize these functions, resolve inconsistencies, and derive knowledge through the command line, Jupyter notebooks, or other interfaces as specified by Translator Standards. ■ The outcome will be a collection of nodes and edges, richly annotated with context, provenance and confidence levels, ready for incorporation into the Translator Knowledge Graph (TKG). ■ All analyses and derived knowledge will be stored in standardized formats, enabling querying through the Reasoner Std API and ingestion into downstream AI assisted machine learning. ■ Example questions this will allow us to address include: (Wellness) Which clinical analytes, metabolites, proteins, microbiome taxa, etc. are significantly correlated, and which changing analytes predict transition to which disease? [2,3] (Cancer) Which gene mutations in any of X pathways are associated with sensitivity or resistance to any of Y drugs, in cell lines from Z tumor types? (All data sets) Which data set entities are similar to this one? Are there significant clusters? What distinguishes between the clusters? What significant correlations of attributes can be observed? How can this set of entities be expanded by adding similar ones? How do these N versions of this data set differ, and how stable is each knowledge edge as the data set changes over time? Collaboration strengths: Our team has extensive experience with biomedical and domain-agnostic data analytics, integrating multiple relevant data types: omics, clinical measurements and electronic health records (EHRs). We have participated in large collaborative consortia and have subject matter experts willing to advise on proper data interpretation. Our application synergizes with those of other Translator teams (see Letters of Collaboration). Challenges: Data can come in a bewildering diversity of formats. Our solution will be modular, will address the most common formats first, and will leverage established technologies like DataFrames and importers (like pandas.io) where possible. Mapping nodes and edge types onto standard ontologies is crucial for knowledge integration; we will collaborate with the Standards component to maximize success. n/a",DOCKET: accelerating knowledge extraction from biomedical data sets,10330627,OT2TR003443,"['Address', 'Big Data', 'Cell Line', 'Clinical', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Electronic Health Record', 'Ethics', 'FAIR principles', 'Gene Mutation', 'Individual', 'Ingestion', 'Knowledge', 'Knowledge Extraction', 'Letters', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Methods', 'Ontology', 'Outcome', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'Records', 'Research', 'Research Personnel', 'Resistance', 'Resources', 'Specific qualifier value', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Work', 'experience', 'indexing', 'interest', 'interoperability', 'knowledge graph', 'knowledge integration', 'large datasets', 'microbiome', 'novel', 'success', 'tool', 'tumor']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT2,2021,332969
"Tracking the dynamics of how schemas scaffold recall Project Summary Every new experience in our life takes place within the context of familiar environments and situations. However, most research on memory has focused on the artificial memorization of word lists, symbols or pictures; these studies do not meaningfully address how structured prior knowledge about the world (e.g., in the form of a familiar spatial map, or knowledge of how restaurant meals unfold over time) can scaffold new learning. In the proposed studies, I aim to precisely characterize how and where prior knowledge and new information are represented, how they get linked at encoding, and how they interact at recall to allow memories to be retrieved. In the first proposed study of my F99 phase, I test the hypothesis that hippocampal engagement at event boundaries during learning binds new information (i.e. objects) to the scaffold of existing knowledge (i.e. knowledge of a familiar location), and that hippocampal activation during recall mediates the successful retrieval of the bound object from the location in which it was stored. I also test the hypothesis that distinctive representations of spatial locations in the brain will reduce interference between objects stored in those locations. There is a potential downside to using prior knowledge as a scaffold: When there is too much information attached to one part of the scaffold, old and new memories will interfere with each other. How, then, could someone prioritize the retrieval of new memories over older (now-irrelevant) memories that were linked to the scaffold? Recent research on intentional forgetting suggests a solution to this limitation. Specifically, in my second proposed study, I test the hypothesis (supported by neurophysiological evidence, prior neuroimaging results, and computational models) that previously encoded memories can be weakened by moderately activating their neural representation, thereby “cleaning” the scaffold and reducing interference. In the K00 phase, I will extend my research to identify pathologies in how clinical populations use prior knowledge to interpret and remember their experiences, using tools from computational psychiatry; I also plan to design new technological tools to address these issues. Overall, the proposed project makes use of naturalistic and ecologically valid stimuli (in the form of continuous stimuli and immersive virtual reality) paired with advanced machine learning tools applied to brain imaging data, to study the fundamental nature of how new and old information are linked to allow learning. In the long-term, the findings from this project regarding how prior knowledge can be optimally leveraged to support new learning will lead to the development of tools to help memory-impaired individuals make better use of prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly. Project Narrative In my dissertation, I will use newly-developed machine learning techniques to study how the brain uses prior knowledge (about the spatial structure of an environment, or how certain types of events unfold in time) to scaffold new learning. By precisely characterizing how this scaffolding process works, my research will help to identify ways in which prior knowledge can be more optimally leveraged to support learning. This will lead to the development of tools to help memory-impaired individuals make better use of intact prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly.",Tracking the dynamics of how schemas scaffold recall,10156352,F99NS120644,"['Address', 'Behavioral', 'Binding', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Models', 'Cues', 'Data', 'Doctor of Philosophy', 'Environment', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'General Population', 'Goals', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Institution', 'Knowledge', 'Lead', 'Learning', 'Life', 'Link', 'Literature', 'Location', 'Machine Learning', 'Maps', 'Mediating', 'Memory', 'Memory impairment', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Participant', 'Pathology', 'Perception', 'Performance', 'Phase', 'Play', 'Population', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Psyche structure', 'Psychiatry', 'Research', 'Research Project Grants', 'Restaurants', 'Retrieval', 'Scanning', 'Scientist', 'Self-Help Devices', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'Work', 'computerized tools', 'design', 'experience', 'field study', 'forgetting', 'memory encoding', 'memory retrieval', 'neuroimaging', 'neurophysiology', 'phase 1 testing', 'prevent', 'relating to nervous system', 'scaffold', 'skills', 'statistics', 'tool', 'tool development', 'virtual', 'virtual reality', 'virtual reality environment', 'virtual world']",NINDS,PRINCETON UNIVERSITY,F99,2021,47036
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS) Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,10360219,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'experience', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2021,1200946
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS) Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,10115156,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'experience', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2021,4648239
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10173765,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'efficacy evaluation', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2021,256578
"ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care. As part of the feasibility phase of the Translator program, we have developed a disease-agnostic framework and approach for openly exposing clinical data that have been integrated at the patient- and visit-level with environmental exposures data: the Integrated Clinical and Environmental Exposures Service (ICEES). We have validated ICEES and demonstrated the service’s ability to replicate and extend published findings on asthma, while also supporting open team science, accelerated translational discovery, and integration with the broader Translator ecosystem. This proposal aims to move ICEES from prototype to development via creation of an ICEES+ Knowledge Provider (KP). Specifically, we aim to address three major challenges that we have identified through research and development (R&D) of the prototype ICEES in an effort to improve the quality, value, and impact of query answers and assertions. Specific Aim 1. Advance the rigor of insights and assertions that ICEES provides. Our prototype ICEES currently provides the ability to dynamically define cohorts and conduct simple statistical associations to examine bivariate relationships between feature variables. Recently, we have identified an approach to extend the bivariate functionalities to support multivariate analysis of the data. For the proposed work, we will apply multivariate analyses, including traditional statistical methods (e.g., regression models) and machine learning methods (e.g., bayesian neural network models, variational autoencoder models), and systematically quantify the extent of data loss and analytic bounds when algorithms are imposed on the ICEES+ KP open application programming interface (API) versus the Institutional Review Board (IRB)– protected, fully identified, pre-binned, underlying integrated feature tables. The overall goal is to provide users with more rigorous insights and estimates of the robustness, validity, accuracy, and specificity of knowledge and assertions generated via the ICEES+ KP OpenAPI. Specific Aim 2. Address issues related to space–time and causality. Clinical and environmental data are inherently spatiotemporal, with observations or events that are contingent on space and time and may be causally related. For the proposed work, we will evaluate and implement technical approaches (e.g., ICEES+ design modifications), spatiotemporal statistical algorithms (e.g., conditional auto-regression), recurrent neural network models, and causal inference models. As part of this effort, we will derive insights from and contribute real-world evidence to support Causal Activity Models and Adverse Outcome Pathways. We also will explore approaches for incorporating into ICEES+ nationwide public data on school exposures—data that will allow us to begin to address patient mobility. Specific Aim 3. Evaluate the security of the ICEES+ KP to ensure that patient privacy is preserved as new capabilities are enabled. ImPACT is an NSF-funded package of tools and services that provides end-to-end infrastructure and support for privacy-assured research and computation on sensitive data. Over the award period, we will implement and evaluate ImPACT security protocols, focusing initially on application of the ImPACT secure multiparty computation (SMC) algorithm as a method to support secure multi-institutional sharing of data on rare diseases and events—a functionality that is not currently supported by ICEES. In addition, we will evaluate other ImPACT security protocols, working under the guidance of a security advisor and in the context of driving use cases and capabilities developed under Specific Aims1 and 2. Importantly, the project aims will be driven by three use cases and associated high-value queries designed to complement and extend our asthma-focused work on the prototype ICEES: (1) an asthma cohort from the Environmental Polymorphism Registry (EPR) at the National Institute for Environmental Health Sciences (NIEHS); (2) a primary ciliary disease cohort (PCD) from the UNC PCD Registry; and (3) a drug-induced liver injury (DILI) cohort from the National DILI Network. These use cases will invoke new diseases, new data types, new organ systems, new institutions, and new queries, thereby stress-testing the ICEES framework and approach and moving it from prototype to development as the ICEES+ KP. n/a",ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care.,10333478,OT2TR003430,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Award', 'Bayesian neural network', 'Clinical', 'Clinical Data', 'Complement', 'Computational algorithm', 'Data', 'Data Analyses', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Environmental Exposure', 'Etiology', 'Event', 'Funding', 'Genetic Polymorphism', 'Goals', 'Infrastructure', 'Institution', 'Institutional Review Boards', 'Knowledge', 'Methods', 'Modeling', 'Modification', 'Multivariate Analysis', 'National Institute of Environmental Health Sciences', 'Neural Network Simulation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Privacy', 'Protocols documentation', 'Provider', 'Publishing', 'Rare Diseases', 'Registries', 'Research', 'Schools', 'Science', 'Secure', 'Security', 'Services', 'Specificity', 'Statistical Algorithm', 'Statistical Methods', 'Stress Tests', 'Time', 'Translational Research', 'Variant', 'Visit', 'Work', 'adverse outcome', 'application programming interface', 'autoencoder', 'body system', 'clinical care', 'cohort', 'data sharing', 'design', 'improved', 'innovation', 'insight', 'liver injury', 'machine learning method', 'patient mobility', 'patient privacy', 'preservation', 'programs', 'prototype', 'recurrent neural network', 'research and development', 'spatiotemporal', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,982187
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835
"The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration Delirium is a serious cognitive disorder associated with Alzheimer’s disease and related dementias (ADRD) that affects ~2.6 million older adults yearly. It is a frequent complication of acute illness, surgery and, now, of COVID-19 infection in older adults. Recognizing the relative dearth of delirium research, the National Institute for Aging (NIA) supported the establishment of the Network for Investigation of Delirium: Unifying Scientists (NIDUS), a collaborative interdisciplinary group of 28 investigators, from 27 institutions, to advance delirium research and develop network infrastructure. This included the creation of an annual “NIDUS bootcamp” conference, to bring together the growing national- and international delirium research community for networking and education. The bootcamp aims are to advance the science of the field and to provide junior investigators with intensive mentorship, through mock NIH application reviews, clinical and research lectures, breakout sessions, and post-bootcamp networking. Bootcamp alumni are provided guidance on: 1) using the NIDUS Delirium Research Hub, Measurement resources and Bibliography, 2) submitting proposals to the NIDUS Pilot Program (13 one-year $50,000 grants awarded), NIA GEMSSTAR/CLINSTAR, the Alzheimer’s Association, and other foundations, 3) attending Mentoring webinars, 4) participating in Junior Faculty Working Groups, and 5) submitting research abstracts to the American Delirium Society (ADS) Annual Meeting. As PIs, 94 alumni have received 46 grants, of which 18 (40%) were NIH-funded, and published 265 original peer- reviewed articles. NIDUS has jumpstarted the careers of many young investigators, particularly bootcamp alumni, enabling them to launch independent programs in delirium research. The goal of this application is to support continuation of a yearly, themed Delirium Bootcamp Conference (DBC), to ensure that the progress of this active research community is sustained. The first-year theme will be the inter-relationship between delirium and ADRD. The Specific Aims are to: (1) Engage and support junior investigators in delirium research through mentorship and access to the NIDUS resources/network (2) Boost the researchers’ funding success (3) Facilitate publication of delirium research and provide ongoing mentorship, and (4) Facilitate networking among junior, mid-career, and senior researchers during and after DBC. As the pool of delirium investigators expands, there is a critical need for a conference focused on addressing cutting-edge research methods in all areas of delirium research, including the relationship with ADRD, “-Omics” research, machine learning and big data, innovations in randomized trials, animal models and mechanistic research, and clinical practice improvement. The DBC will provide an unparalleled opportunity to advance cutting-edge delirium research through interactive didactic sessions and in-depth guidance on complex and nuanced research methods essential for the highest caliber and most impactful delirium research. Delirium is a serious, yet understudied, cognitive disorder that affects millions of elder Americans, and is closely related to Alzheimer’s disease and related dementias (ADRD). The NIA-supported (2015-2020) Network for Investigation of Delirium Unifying Scientists (NIDUS), a collaborative international network of delirium investigators, developed a successful, annual “NIDUS Bootcamp” conference, laying the foundation for this proposal. The new Delirium Bootcamp (DBC) will convene junior investigators and senior faculty in an annual conference with innovations including: 1) a new thematic focus each year, with the 2021 theme highlighting ADRD; 2) focus on high-impact, state-of-the-art methodologies to advance the field in new directions; 3) finding optimal methods to address the unique challenges of delirium research, and 4) developing collaborative interdisciplinary papers to be initiated at the DBC and completed in ongoing groups; thus, fostering the training, career development and success of the next generation of delirium investigators.",The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration,10237513,R13AG072860,"['Acute', 'Acute Disease', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'American', 'Animal Model', 'Area', 'Attention', 'Award', 'Bibliography', 'Big Data', 'COVID-19', 'Caliber', 'Clinical', 'Clinical Research', 'Cognition', 'Cognition Disorders', 'Collaborations', 'Communities', 'Community Networks', 'Complex', 'Complication', 'Delirium', 'Discipline', 'Education', 'Elderly', 'Ensure', 'Epidemiology', 'Faculty', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Grant', 'Health Expenditures', 'Infrastructure', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurement', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Monoclonal Antibody R24', 'National Institute on Aging', 'Network Infrastructure', 'Operative Surgical Procedures', 'Paper', 'Participant', 'Peer Review', 'Pilot Projects', 'Public Health', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'SARS-CoV-2 infection', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Societies', 'Study Section', 'Training', 'United States National Institutes of Health', 'Writing', 'career', 'career development', 'clinical practice', 'cost', 'innovation', 'interdisciplinary collaboration', 'lectures', 'meetings', 'multidisciplinary', 'neglect', 'next generation', 'patient population', 'peer', 'programs', 'randomized trial', 'response', 'secondary analysis', 'senior faculty', 'skill acquisition', 'success', 'support network', 'symposium', 'systematic review', 'webinar', 'working group']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R13,2021,50000
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10186744,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,377473
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,10086862,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2021,171720
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10216259,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data repository', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2021,886029
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of differenttypes of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",10397321,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2021,1500000
"Carolina Population Center PROJECT SUMMARY/ABSTRACT The Carolina Population Center requests infrastructure support that will advance population dynamics research at CPC by increasing research impact, innovation, and productivity, supporting the development of junior scientists, and reducing the administrative burden on scientists. Infrastructure support will advance science in three primary research areas: Sexuality, Reproduction, Fertility, and Families; Population, Health, and the Environment; and Inequality, Mobility, Disparities, and Well-Being. Much of the research at CPC draws on large publicly available longitudinal data sets that our faculty have designed and collected, including the National Longitudinal Study of Adolescent to Adult Health, the China Health and Nutrition Survey, newer surveys associated with the Transfer Project, and the Study of the Tsunami Aftermath and Recovery, all of which will continue to be important in work related to our primary research areas over the next five years. These projects embody several themes that have guided research at CPC since the Center's inception. These themes, which will continue to shape our work, are the importance of life course processes and longitudinal data, multi-level processes and measurement of context, interventions and natural experiments as means of learning about causal processes, and the relevance of sociodemographic variables such as age, gender, race- ethnicity, and socioeconomic status for disparities in health and well-being. By embedding these themes, our projects provide data that enable us to address barriers that otherwise impede progress in the population sciences generally, and in our primary research areas in particular. We request support for three cores which in combination will provide an institutional infrastructure that will push populations dynamics research forward by empowering CPC faculty to tackle challenging questions using state of the art measurement techniques and methods. The Administrative Core plans activities that maintain a stimulating intellectual community, streamlines administrative processes so that scientists can focus on research, coordinates activities of the Cores so that services are offered efficiently, and communicates information about research and data more broadly. The Development Core supports early stage investigators and other faculty with exciting new ideas through multiple mechanisms: workshops, access to technical expertise in measurement, and seed grants. The Research Services Core enables scientists to address complex and important population research issues by providing access to state-of-the-art research tools and professional support for programming, survey development, and analysis. NARRATIVE This project will provide infrastructure support for a cutting edge program of research on population dynamics at the Carolina Population Center. Research at the Center will analyze state-of-the art data to address fundamental questions regarding fertility, adolescent health, and links between the environment and health. Special attention will be paid to factors creating health disparities.",Carolina Population Center,10136647,P2CHD050924,"['Address', 'Adolescent', 'Adopted', 'Adult', 'Age', 'Applications Grants', 'Area', 'Attention', 'Biological Markers', 'China', 'Cognitive', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Vision Systems', 'Creativeness', 'Data', 'Data Collection', 'Development', 'Diffuse', 'Educational workshop', 'Environment', 'Ethnic Origin', 'Extramural Activities', 'Faculty', 'Family', 'Fertility', 'Fostering', 'Funding', 'Gender', 'Genetic', 'Grant', 'Hand', 'Health', 'Health Surveys', 'Home environment', 'Inequality', 'Infrastructure', 'Intervention', 'Journals', 'Learning', 'Life Cycle Stages', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Mentors', 'Methods', 'Natural experiment', 'Nutrition Surveys', 'Personal Satisfaction', 'Phase', 'Policy Making', 'Population', 'Population Dynamics', 'Population Research', 'Population Sciences', 'Postdoctoral Fellow', 'Process', 'Production', 'Productivity', 'Publishing', 'Race', 'Recovery', 'Reproduction', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Schools', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seeds', 'Services', 'Sexuality', 'Shapes', 'Socioeconomic Status', 'Structure', 'Students', 'Surveys', 'Talents', 'Teacher Professional Development', 'Technical Expertise', 'Techniques', 'Training Programs', 'Tsunami', 'Universities', 'Work', 'adolescent health', 'career', 'collaborative environment', 'cost', 'data access', 'design', 'empowered', 'experience', 'faculty support', 'health disparity', 'innovation', 'interdisciplinary collaboration', 'longitudinal dataset', 'novel strategies', 'population health', 'privacy protection', 'programs', 'research and development', 'response', 'sociodemographic variables', 'success', 'tool']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,P2C,2021,766127
"The Metadata Powerwash - Integrated tools to make biomedical data FAIR Project Summary  The metadata that describe scientific data are fundamental resources to enable (1) the discovery and reuse of the data and (2) the reproducibility of the experiments that generated the data in the first place. Metadata are essential for scientists to understand the associated data and to reuse them, as well as for information technology to index the data, to make the data available, and to provide filters for scientists to search for the corresponding datasets. Currently, the scientific metadata hosted in public repositories suffer from multiple quality issues that limit scientists’ ability to find and reuse the experimental datasets to which they refer. It can take many weeks of a scientist’s time to identify a collection of datasets that fulfill specific criteria when the data are so poorly described—and the majority of the process is necessarily manual.  We propose to develop an end-to-end solution to standardize biomedical metadata with the help of ontologies—data structures that define the terms in an application domain and the relationships among them. There are hundreds of ontologies that provide standard terms for use in biomedicine, and they are essential resources to make biomedical metadata interoperable and reusable. Our approach also will build on the technology created by the Center for Expanded Data Annotation and Retrieval (CEDAR), which offers a library of building blocks and common data elements for defining computer-based metadata templates based on community standards.  Our plan involves three specific aims. First, we will develop a method and tool to standardize the multiple, ad hoc metadata field names that may appear in metadata to represent the same type of information by replacing those field names with the field names used in standard metadata templates or, if no appropriate template match is available, with terms from a relevant ontology. Second, we will develop methods and tools to standardize different types of metadata field values, for example, categorical values such as drugs or diseases, and numerical values such as age, or sample collection date. Third, we will evaluate the speed, precision, and recall of our metadata transformation pipeline—built out of the methods and tools to standardize field names and values—on a large corpus of metadata that we will manually curate based on existing public metadata. We will also carry out experiments to test the effect of the standardized metadata when biomedical scientists perform dataset search in the context of their work. Project Narrative Data that offer precise descriptions of data—metadata—are critical scientific resources that facilitate the discovery, reuse, and reproducibility of the data to which they refer. Our goal is to create methods and tools that improve the quality of scientific metadata hosted in public repositories, and thus enhance the discoverability and re-use of public biomedical datasets. Making data more accessible through scientifically rigorous metadata will accelerate the ability to make transformative data-driven biomedical discoveries using public data archives.",The Metadata Powerwash - Integrated tools to make biomedical data FAIR,10093841,R01LM013498,"['Age', 'Biological Specimen Banks', 'Categories', 'Collection', 'Common Data Element', 'Communities', 'Computers', 'Data', 'Data Science', 'Data Set', 'Disease', 'FAIR principles', 'Funding Agency', 'Goals', 'Gold', 'Information Technology', 'Knowledge', 'Libraries', 'Link', 'Manuals', 'Metadata', 'Methods', 'Names', 'Natural Language Processing', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Problem Solving', 'Process', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Sampling', 'Science', 'Scientist', 'Specific qualifier value', 'Speed', 'Standardization', 'Structure', 'Technology', 'Testing', 'Time', 'Variant', 'Work', 'base', 'biomedical scientist', 'data archive', 'data repository', 'data reuse', 'experimental study', 'improved', 'indexing', 'information organization', 'interoperability', 'metadata standards', 'public repository', 'repository', 'sample collection', 'search engine', 'secondary analysis', 'tool']",NLM,STANFORD UNIVERSITY,R01,2021,334847
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,10178076,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Consolidated Framework for Implementation Research', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'complex data', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'lung injury', 'machine learning method', 'mortality', 'multidisciplinary', 'novel', 'respiratory', 'response', 'theories', 'ventilation']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2021,680901
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",10177978,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Visualization', 'Work', 'addiction', 'archive data', 'archived data', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data integration', 'data modeling', 'data repository', 'data tools', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'image archival system', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2021,744955
"Eastern Nigeria Research Ethics Training (ENRICH) Program Eastern Nigeria Research Ethics Training (ENRICH) Program Project Summary  The Eastern Nigeria Research Ethics Training (ENRICH) Program is a collaborative research ethics training program to be implemented jointly by the University of Nigeria, Nsukka (UNN), NIH/FIC-funded Center for Bioethics and Research (CBR) and University of Maryland School of Medicine (UMSOM). The program will provide forty master’s degrees, two hundred short- and twenty-five medium-term trainings in research ethics training to faculty members, members of ethics committees and individuals who are identified as potential leaders in bioethics by their institutions in eastern Nigeria at the newly established bioethics degree program at UNN. The program builds on a planning project implemented within the current CBR/UMSOM bioethics training grant and is based on assessment of the needs of institutions and ethics committees serving approximately 50 million people in eastern Nigeria. The program will rapidly scale up bioethics expertise and research capacity in eastern Nigeria and ensure that the trainees conduct innovative, culture-specific bioethics research projects and expand our contributions to the global research ethics discourse. Eastern Nigeria Research Ethics Training (ENRICH) Program Project Narrative  The Eastern Nigeria Research Ethics Training (ENRICH) Program is a collaborative research ethics training program to be implemented jointly by the University of Nigeria, Nsukka (UNN), NIH/FIC-funded Center for Bioethics and Research (CBR) and University of Maryland School of Medicine (UMSOM). The program will provide 40 master's degrees, two hundred short- and twenty-five medium-term trainings in research ethics training to faculty members, members of ethics committees and individuals who are identified as potential leaders in bioethics by their institutions in eastern Nigeria.",Eastern Nigeria Research Ethics Training (ENRICH) Program,10228965,R25TW011811,"['Africa', 'Africa South of the Sahara', 'Artificial Intelligence', 'Awareness', 'Behavioral Sciences', 'Bioethics', 'COVID-19 pandemic', 'Collaborations', 'Community Medicine', 'Congo', 'Country', 'Data Science', 'Degree program', 'Development', 'Disease', 'Education', 'Emerging Communicable Diseases', 'Ensure', 'Epidemiology', 'Ethics', 'Ethics Committees', 'Faculty', 'Funding', 'Future', 'Ghana', 'Grant', 'Health', 'Health Technology', 'Individual', 'Institution', 'International', 'Intramural Research Program', 'Kenya', 'Leadership', 'Malawi', 'Maryland', 'Master of Public Health', 'Master of Science', 'Master&apos', 's Degree', 'Mozambique', 'Needs Assessment', 'Nigeria', 'Nigerian', 'Occupations', 'Population', 'Privatization', 'Research', 'Research Ethics', 'Research Ethics Committees', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rwanda', 'Social Sciences', 'South Africa', 'Students', 'Teaching Hospitals', 'Training', 'Training Programs', 'Uganda', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'experience', 'genomic epidemiology', 'innovation', 'medical schools', 'member', 'nutrition', 'pedagogy', 'programs', 'responsible research conduct', 'scale up']",FIC,UNIVERSITY OF MARYLAND BALTIMORE,R25,2021,45101
"University of Buffalo Clinical and Translational Science Institute Contact PD/PI: Murphy, Timothy F The Buffalo Translational Consortium (BTC), which includes the University at Buffalo (UB) health sciences schools, the major healthcare institutions in our region, four key research institutes and five influential community partners, have embarked on a comprehensive strategic plan to build a strong foundation for clinical and translational research in response to our community needs. Buffalo is the second most populous city in New York State and has a rich cultural history. The proportion of underrepresented minorities in Buffalo in 2018 (50%) parallels that projected for the US in 2050, making Buffalo a microcosm of what the US will look like in 30 years. A similar proportion of our population experiences health disparities. The vision for our CTSA hub is to perform innovative research across the translational spectrum to improve the health of our community and the nation. We will develop, test and share novel approaches to engage difficult-to-engage populations and reduce health disparities in our community, which represents a “population of the future”. Guided by our vision, the CTSA has catalyzed a transformation of our environment since our CTSA was first funded in August 2015 with remarkable growth in clinical and translational research. Further, in just the past year, the UB medical school has moved into a spectacular new building and our clinical partner, Kaleida Health, the largest healthcare system in the region, opened the new Oishei Children’s Hospital, both on the Buffalo Niagara Medical Campus and connected to the Clinical and Translational Research Center devoted entirely to clinical and translational research that opened in 2012. This rapid and continuing trajectory of growth in healthcare and research in the region has resulted in a new 21st century Academic Health Center with healthcare, medical education and clinical and translational research on one campus in the heart of Buffalo, creating a foundation to enhance the impact of our CTSA even further. While launching our CTSA, we have prioritized participation in the national consortium through hosting and testing Innovation Labs as a team science tool, working with multiple hubs on initiatives to solve translational research barriers and sharing tools that we have developed with the CTSA consortium, including novel health informatics tools. Our CTSA has five ambitious but achievable aims, including: 1) Accelerate innovative translational research with teams that engage communities, regional stakeholders and the national consortium; 2) Train an excellent, diverse workforce to advance translation of discoveries; 3) Enhance inclusion of special populations across the lifespan and difficult-to-engage populations; 4) Streamline clinical research processes focusing on quality and efficiency with emphasis on multisite studies; 5) Develop, test and share biomedical informatics tools to integrate data from multiple sources to speed translation. Guided by our vision to perform research to improve the health of our community and the nation, we will continue our momentum to expand translational research, train our diverse workforce, streamline processes, engage our community, and actively contribute to the national consortium. Page 243 Project Summary/Abstract Contact PD/PI: Murphy, Timothy F The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health. Page 244 The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health.",University of Buffalo Clinical and Translational Science Institute,10103865,UL1TR001412,"['Achievement', 'Address', 'Adopted', 'African American', 'Buffaloes', 'Center for Translational Science Activities', 'Cities', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Health', 'County', 'Coupled', 'Cultural Backgrounds', 'Data', 'Diverse Workforce', 'Ensure', 'Environment', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Heart', 'Image', 'Imaging technology', 'Individual', 'Influentials', 'Informatics', 'Institutes', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Life Expectancy', 'Longevity', 'Medical', 'Medical Education', 'Medical center', 'Methods', 'Natural Language Processing', 'New York', 'Outcomes Research', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Population', 'Poverty', 'Process', 'Program Development', 'Prospective Studies', 'Public Health', 'Public Health Informatics', 'Recording of previous events', 'Recruitment Activity', 'Refugees', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Sensitivity and Specificity', 'Site', 'Special Population', 'Speed', 'Strategic Planning', 'System', 'Testing', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'Universities', 'Vision', 'Work', 'Workforce Development', 'base', 'biomedical informatics', 'clinical center', 'clinical data repository', 'community partnership', 'data sharing', 'education research', 'experience', 'health care disparity', 'health disparity', 'imaging genetics', 'improved', 'informatics tool', 'innovation', 'interoperability', 'medical schools', 'multidisciplinary', 'multiple data sources', 'novel', 'novel strategies', 'recruit', 'response', 'sharing platform', 'skills', 'social health determinants', 'structured data', 'tool', 'translational impact', 'translational pipeline', 'translational scientist', 'unstructured data']",NCATS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,UL1,2021,3826724
"Meta-analysis in human brain mapping This is the competing renewal of the R01 (MH074457-14) which sustains the BrainMap Project (www.brainmap.org). BrainMap is a neuroimaging research resource facilitating cognitive neuroscience and disease-biomarker discovery via coordinate-based meta-analysis (CBMA). BrainMap provides its end-user community with: curated 3-D coordinate data and experimental metadata from peer-reviewed publications; extensively validated computational tools for CBMA; CBMA-derived tools for data interpretation (e.g., functional property and disease loadings by location) and data analysis (e.g., via CBMA-derived disease models); instructional materials and on-site and on-line venues for learning CBMA methods; and, on-going end-user support. At present, BrainMap.org hosts two coordinate-based databases: task-activation (TA DB) and voxel- based morphometry (VBM DB). A voxel-based physiology database (VBP DB) is in the planning and piloting phase. BrainMap maintains an integrated pipeline of cross-platform (Java) tools for data coding (Scribe), filtered retrieval (Sleuth), activation-likelihood estimation (ALE) CBMA (GingerALE), data visualization (Mango), and data interpretation (CBMA-derived Mango plugins). Multiple network-modeling approaches have been successfully applied to BrainMap data – independent components analysis (ICA), author-topic modeling (ATM), graph-theory modeling (GTM), structural equation modeling (SEM), connectivity-based parcellation (CBP), and meta-analytic connectivity modeling (MACM) – but none are yet optimized and “pipelined” for general use. Utilization of BrainMap resources is substantial: our software, data and meta-data have been used in >1,000 peer-reviewed articles. Of these, > 500 were published in the current funding cycle (2015- 2020). Four aims are proposed, to maintain and extend this high-impact research resource.  Aim 1. Voxel-based Physiology DataBase (VBP DB) with Analysis Exemplars. Aim 2. BrainMap Community Portal for Multivariate Modeling with Applications & Exemplars. Aim 3. Large-scale Parameter Estimations. Aim 4. BrainMap Pipeline Enhancements and Community Support. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data.",Meta-analysis in human brain mapping,10157292,R01MH074457,"['3-Dimensional', 'Address', 'Brain Mapping', 'Categories', 'Code', 'Cognition Disorders', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Disease model', 'Educational workshop', 'Equation', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Java', 'Learning', 'Location', 'Machine Learning', 'Mango - dietary', 'Manuals', 'Mental disorders', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Multivariate Analysis', 'Output', 'Peer Review', 'Phase', 'Physiology', 'Property', 'Publications', 'Publishing', 'Research Domain Criteria', 'Resources', 'Retrieval', 'Site', 'Software Framework', 'Structure', 'Surface', 'Symptoms', 'Taxonomy', 'Texas', 'Training', 'Uncertainty', 'Validation', 'base', 'biomarker discovery', 'case control', 'cognitive neuroscience', 'cohort', 'computerized tools', 'connectome', 'data submission', 'data tools', 'data visualization', 'design', 'experimental study', 'graph theory', 'hemodynamics', 'independent component analysis', 'learning materials', 'lectures', 'morphometry', 'network models', 'neuroimaging', 'simulation', 'webinar']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2021,637306
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"Consortium for Immunotherapeutics against Emerging Viral Threats SUMMARY: OVERALL  This proposal, Consortium for Immunotherapeutics Against Emerging Viral Diseases, addresses a critical gap in the biodefense portfolio by building an academic-industry partnership to advance effective, fully human, antibody-based immunotherapeutics against three major families of emerging/re-emerging viruses: Lassa virus, Ebola and other Filoviruses, and mosquito-transmitted Alphaviruses that threaten millions worldwide. This program follows directly from our significant body of preliminary data (the largest available for these families of viruses), therapeutics in hand, multidisciplinary expertise, and demonstrated collaborative success. Included in the proposed CETR portfolio are: (1) the only available immunotherapeutics against endemic Lassa virus, with reversal of late-stage disease and complete survival in infected non-human primates, (2) novel Ebola and pan- ebolavirus therapeutics that also completely protect non-human primates from disease, and that were built by the paradigm-shifting and comprehensive analysis of a global consortium, and (3) much needed, first-in-class therapeutics against the re-emerging alphaviruses that have tremendous epidemic potential in the United States and around the globe. These multidisciplinary studies, founded upon pioneering structural biology of the antigen targets, include innovations such as agnostic, high-throughput Fc profiling and optimization, coupled with Fv evolution to enhance potency and developability, as well as a sophisticated statistical and computational analysis core to evaluate thresholds and correlates of protection across the major families of pathogens. Together, we aim to understand what findings represent general rules and what data are specific to each virus family. We also aim to provide streamlined systems for antibody choice and optimization that do not yet exist, and to build a broadly applicable platform for mAb discovery and delivery against any novel pathogen as they emerge. The recent resurgence of Lassa, the epidemic nature of Ebola virus and other re-emerging filoviruses, as well as the major population at risk by global movement of mosquito-borne alphaviruses together demonstrate the tremendous global need for immunotherapeutics developed and advanced by this program. NARRATIVE Three major families of emerging viruses (Lassa and other arenaviruses, Ebola and other filoviruses, and mosquito-borne alphaviruses) threaten human health worldwide, but lack approved therapeutics or vaccines. The proposed multidisciplinary consortium, an academic-industry partnership, will advance safe and effective, fully human, monoclonal antibody therapies against these viruses, using candidate therapies that confer complete protection in non-human primates as our starting point. Our collaborative databases, multivariate analyses and innovative antibody optimization strategies will establish platforms for discovery and delivery of much-needed treatments against these and other infectious diseases.",Consortium for Immunotherapeutics against Emerging Viral Threats,10158446,U19AI142790,"['Address', 'Alphavirus', 'Antibodies', 'Antigen Targeting', 'Arenavirus', 'Arthritogenic', 'Biological Assay', 'Communicable Diseases', 'Computer Analysis', 'Computer Models', 'Computing Methodologies', 'Coupled', 'Culicidae', 'Data', 'Databases', 'Developed Countries', 'Developing Countries', 'Disease', 'Ebola', 'Ebola virus', 'Epidemic', 'Evolution', 'Family', 'Filovirus', 'Fostering', 'Goals', 'Hand', 'Health', 'Human', 'Immune', 'Immunotherapeutic agent', 'Lassa virus', 'Machine Learning', 'Mathematics', 'Mediating', 'Monoclonal Antibodies', 'Monoclonal Antibody Therapy', 'Movement', 'Multivariate Analysis', 'Nature', 'Populations at Risk', 'Primate Diseases', 'Reagent', 'Research Project Grants', 'Resources', 'Statistical Data Interpretation', 'System', 'Talents', 'Testing', 'Therapeutic', 'Therapeutic Monoclonal Antibodies', 'Translating', 'Translations', 'United States', 'Vaccines', 'Viral', 'Virus', 'Virus Diseases', 'base', 'biodefense', 'chikungunya', 'clinical development', 'design', 'experience', 'human monoclonal antibodies', 'improved', 'industry partner', 'innovation', 'insight', 'mosquito-borne', 'multidisciplinary', 'nonhuman primate', 'novel', 'pandemic disease', 'pathogen', 'programs', 'research study', 'structural biology', 'success', 'synergism', 'tool']",NIAID,LA JOLLA INSTITUTE FOR IMMUNOLOGY,U19,2021,7065330
"The plasticity of well-being:  A research network to define, measure and promote human flourishing PROJECT SUMMARY/ABSTRACT This U24 application is written in response to RFA-AT-20-003 to establish a high-priority research network on emotional well-being (EWB). While psychological research on well-being has dramatically increased over the past 15 years, virtually all of this work has been descriptive and has not emphasized the “how” of well-being: How might well-being be cultivated? In addition, virtually all of the extant work on the correlates of individual differences in well-being has used responses on retrospective questionnaires as the primary tool to assess well-being. While there have been exciting findings, particularly relating individual differences in well-being to various indices of physical health, many questions remain and methodological limitations plague the validity of this work. This U24 network will assemble a highly multi-disciplinary group of 10 investigators across 3 (or more in the future) institutions to significantly advance our understanding of the “how” of EWB, identify the core plastic constituents of EWB, specify and/or develop robust measures of these constituents at biological, behavioral and experiential levels of analysis and characterize the plasticity of these constituents. The measurement strategy will ultimately focus on the development of technology-based passive measures of EWB that require no explicit user input and are highly scalable. The network will also focus its efforts on the development and evaluation of programs to train EWB and will assess whether such programs might serve as prevention strategies. The network will consist of scientists and scholars from a broad range of fields including psychology, neuroscience, electrical and computer engineering, population health and biology, computer science and the humanities. These scientists and scholars will focus on the following major aims: Aim 1: To arrive at a core consensus of the minimal set of constituents that can be described and measured at biological, behavioral and experiential levels that constitute the plastic elements of EWB and to specify already existing measures and /or develop novel measures of each of these constructs at each level of analysis. Aim 2: Using the active measures described in Aim 1, to develop passive measures using digital technologies of at least two of the core constituents of well-being. Aim 3: To develop pilot projects specifically focusing on prevention strategies for learning well-being in various samples. The network will train new investigators and bring established investigators into this new field, disseminate a framework for understanding the plasticity of well- being, a toolbox of measures for assessing the plasticity of components of well-being, and several pilot datasets that showcase the novel passive and field-friendly biological measures. In these ways, the network will dramatically accelerate progress in the nascent field of EWB. PROJECT NARRATIVE This U24 network on emotional well-being (EWB) will catalyze the emerging field of the plasticity of well-being and will showcase how well-being can be learned and the consequences of such skill development on physical and emotional health and on prevention of disease. A framework for understanding how well-being can be learned along with measures of the core components of well-being that can be learned will be developed and disseminated. The network will also train new investigators in this area and will engage established investigators to contribute to this field.","The plasticity of well-being:  A research network to define, measure and promote human flourishing",10151850,U24AT011289,"['Area', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Biological', 'Cellular Phone', 'Communities', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Distal', 'Drug abuse', 'Elements', 'Emotional', 'Engineering', 'Face', 'Future', 'Gold', 'Grant', 'Health', 'Human', 'Humanities', 'Individual Differences', 'Institution', 'Interruption', 'Literature', 'Measurement', 'Measures', 'Mental Depression', 'Methodology', 'Mind', 'Modernization', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Personal Satisfaction', 'Pilot Projects', 'Plague', 'Population Biology', 'Prevention strategy', 'Program Evaluation', 'Psychology', 'Publications', 'Questionnaires', 'Randomized Controlled Trials', 'Regulation', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specific qualifier value', 'Subgroup', 'Techniques', 'Technology', 'To specify', 'Training', 'Well in self', 'Work', 'base', 'computer science', 'cost', 'digital', 'disorder prevention', 'indexing', 'learning strategy', 'mHealth', 'machine learning algorithm', 'meetings', 'member', 'mindfulness meditation', 'multidisciplinary', 'novel', 'physical conditioning', 'population health', 'prevent', 'programs', 'psychologic', 'response', 'skill acquisition', 'social', 'standard measure', 'technology development', 'tool', 'virtual', 'web site']",NCCIH,UNIVERSITY OF WISCONSIN-MADISON,U24,2021,30000
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,10126885,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'data tools', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'statistical and machine learning', 'tool']",NICHD,DUKE UNIVERSITY,R25,2021,151418
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,10168611,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,315727
"National Alzheimer's Coordinating Center Project summary/abstract NACC (as U01 AG016976, at University of Washington) has been active since 1999. The existing NACC infrastructure is described in the Facilities and Resources Section of this application. The broad goals of the past funding cycles are consistent with those of the current U24 RFA — that is, to serve as: a.) the central hub for organizing and enabling communication within and outside of the ADRC program, including annual meetings and steering committees; b.) a national data resource, collecting data from the Alzheimer's Disease Research Centers (ADRCs) as well as affiliated data and sample repositories; and c.) a facilitator of current and future AD/ADRD research. NACC has considerable experience and success in reaching these goals, and is positioned for continued success in a rapidly advancing field. New data and methods are appearing in areas such as biomarkers, neuropathology, and tests for early detection. Through the strategic adoption of technological advances, we will build on these accomplishments at an accelerated pace. Building on our already significant capabilities, we will: promote and broaden communication within and outside of the ADRC program; expand informatics capabilities of NACC consistent with FAIR principles; conduct and support methodologic and applied research, leveraging deep expertise in biostatistics and data science; and support early-career research scientists by providing peer-reviewed competitive funding for several “junior investigators” each year. We aim to continue to improve our approach in each arena by combining time-tested approaches with the new tools and innovations we are developing to meet the changing scientific, technological, and communication needs of the NIA ADRC program and the field. Narrative NACC (as U01 AG016976, at University of Washington — now seeking renewal as a U24) has been active since 1999, and has established a standardized, longitudinal clinical database of over 42,000 individuals (with neuropathology data on over 6,100), as well as cross-sectional, retrospective data on roughly 66,000 individuals seen at ADRCs between 1984 and 2005. NACC has made these data freely available to researchers worldwide, resulting in hundreds of publications. We will modernize and intensify our informatics approach, making data access and use more efficient; will grow communication and coordination capabilities with the ADRCs and collaborating NIA projects; will develop and apply big-data research tools for the field; and will provide competitive, peer-reviewed research support for several new investigators each year. Together with the field’s leaders, NACC will innovate, develop, and drive solutions to meet the changing needs of the field as well as the NIA ADRC program.",National Alzheimer's Coordinating Center,10204491,U24AG072122,"['Achievement', 'Adoption', 'Age', 'Alzheimer disease prevention', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Applied Research', 'Area', 'Award', 'Big Data', 'Biological Markers', 'Biometry', 'Collaborations', 'Communication', 'Complex', 'Consultations', 'Contracts', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Science', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Dementia', 'Early Diagnosis', 'Enrollment', 'Environment', 'Faculty', 'Funding', 'Future', 'Genetic', 'Genetic Diseases', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Leadership', 'Link', 'Medicine', 'Methodology', 'Methods', 'Mission', 'Modernization', 'Peer Review', 'Positioning Attribute', 'Publications', 'Recording of previous events', 'Research', 'Research Peer Review', 'Research Personnel', 'Research Support', 'Resources', 'Risk Factors', 'Sampling', 'Scientist', 'Secure', 'Services', 'Site', 'Source', 'Specimen', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Washington', 'base', 'career', 'clinical database', 'clinical examination', 'cohort', 'community center', 'data access', 'data resource', 'data sharing', 'data visualization', 'deep learning', 'digital', 'disease heterogeneity', 'e-science', 'experience', 'high standard', 'imaging biomarker', 'improved', 'innovation', 'instrument', 'interest', 'interoperability', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'programs', 'repository', 'social media', 'success', 'tool', 'translational health science', 'trend', 'web site']",NIA,UNIVERSITY OF WASHINGTON,U24,2021,6979612
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),10210417,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative rehabilitation', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2021,983634
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10225620,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'risk stratification', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,707970
"Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder ABSTRACT  This K24 Mid-Career Investigator Career Development Award seeks support for training and mentorship for Christopher Pittenger, MD, Ph.D., a well-established, tenured Associate Professor in Psychiatry at Yale University, Director of the Yale OCD Research Clinic, and Assistant Chair for Translational Research in the Department of Psychiatry. Dr. Pittenger leads a robust patient-oriented research (POR) research program, which is integrated with his basic/translational lab-based research and has produced important new insights into the neurobiological underpinnings and novel treatment avenues for obsessive-compulsive disorder (OCD) and Tourette syndrome (TS). Dr. Pittenger has a long-standing commitment to mentorship; most notably, he is Co-Director of the Neuroscience Research Training Program (NRTP), the research track within the Yale psychiatry residency.  The training plan supported by this grant will allow Dr. Pittenger to increase his skills in quantitative analysis, with a focus on advanced statistical methods and on the design and analysis of fMRI studies. These are areas in which he already has active research with expert collaborators; the aim of the proposed training plan is to enhance his own proficiency to make him a more effective collaborator and mentor in these important domains. Additional training is focused on his own abilities as a mentor and leader, with the goal of increasing his efficacy in the management of his own research groups and in effective and individualized mentorship. These training activities will take place in the context of two NIMH- funded research studies. The first, R01 MH116038, is a recently funded grant on which Dr. Pittenger is co-PI with his close collaborator Alan Anticevic and deploys cutting-edge imaging technology and data analysis approaches to examine brain network connectivity parallels and predictors of therapeutic response to pharmacotherapy in OCD. The second, R01 MH100068, is a grant with collaborator Michelle Hampson that is developing real-time fMRI neurofeedback as a probe and potential treatment for OCD, with promising early results. These two exciting projects provide a fruitful vehicle for the proposed training in statistics and neuroimaging.  Dr. Pittenger will devote substantial time to mentoring under this award. One major focus will be the NRTP; the plan is for him to take over as Director of this program over the next few years, and to take the lead in the next resubmission of our T32 grant in 2022. Support of this increased mentorship effort is a second major motivation for the current application. Dr. Pittenger will also provide mentorship to students, postdocs, and junior faculty in his own research program and throughout the Department of Psychiatry  Together, these integrated plans for training, research, and mentorship will support a well-established mid-career investigator whose robust research program is producing important insights into the neurobiology and treatment of OCD and TS, and whose dedicated mentorship efforts are helping to establish a new generation of translationally grounded patient-oriented researchers in psychiatric neuroscience. NARRATIVE This K24 Mid-Career Investigator Career Development Award in Patient-Oriented Research seeks support for Christopher Pittenger, a tenured Associate Professor of Psychiatry at Yale University and Director of the Yale OCD Research Clinic; training and mentorship activities supported by this award will take place in the context of two NIMH-funded projects, R01 MH100068 and R01 MH116038. The Award will support Dr. Pittenger in a robust training plan aimed at increasing his skills in statistics and in the design and analysis of fMRI experiments, with the goal of making him a more effective collaborator and mentor in these domains. The robust Mentorship Plan supports a range of trainees, from high school students through junior faculty, with a particular focus on the research track with the Yale Psychiatry Residency, of which Dr. Pittenger will become the Director in the coming years.",Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder,10087006,K24MH121571,"['Achievement', 'Adult', 'Area', 'Award', 'Brain', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Data', 'Data Analyses', 'Department chair', 'Disease', 'Dissociation', 'Doctor of Philosophy', 'Double-Blind Method', 'Drug Exposure', 'Faculty', 'Feedback', 'Fluoxetine', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Funding', 'Future', 'Generations', 'Gilles de la Tourette syndrome', 'Goals', 'Grant', 'Health Sciences', 'High School Student', 'Human', 'Image', 'Imaging technology', 'Individual', 'Infrastructure', 'K-Series Research Career Programs', 'Lead', 'Leadership', 'Linux', 'Machine Learning', 'Mentors', 'Mentorship', 'Motivation', 'National Institute of Mental Health', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Obsessive-Compulsive Disorder', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physicians', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preceptorship', 'Prediction of Response to Therapy', 'Protocols documentation', 'Psychiatry', 'Publishing', 'Pythons', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Residencies', 'Rest', 'Scanning', 'Scientist', 'Services', 'Statistical Methods', 'Structure', 'Students', 'Time', 'Training', 'Training Activity', 'Training Programs', 'Training Support', 'Translational Research', 'Universities', 'Work', 'base', 'career', 'career development', 'connectome', 'design', 'disorder control', 'experimental study', 'graph theory', 'innovation', 'insight', 'mid-career faculty', 'neurofeedback', 'neuroimaging', 'next generation', 'novel', 'patient oriented', 'patient oriented research', 'predicting response', 'programs', 'research study', 'simulation', 'skills', 'statistics', 'success', 'symptomatic improvement', 'symptomatology', 'teacher mentor']",NIMH,YALE UNIVERSITY,K24,2021,181029
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt Founded in 1965 as one of the original Intellectual and Developmental Disorders Research Centers (IDDRC), the Vanderbilt Kennedy Center (VKC) IDDRC serves as the central nexus across Vanderbilt for interdisciplinary research, communication, and training in intellectual and developmental disabilities (IDD). The VKC IDDRC serves as a trans-institutional institute that brings together over 200 faculty from 38 departments in 10 schools at Vanderbilt. The VKC’s mission to facilitate discoveries that inform best practices to improve the lives of people with IDD and their families. This mission is met by leveraging our outstanding institutional resources and support, partnering with disability communities, and capitalizing on synergistic interactions across the VKC’s federally-designated centers: the VKC IDDRC, a University Center of Excellence in Developmental Disabilities and a Leadership Education in Neurodevelopmental Disabilities program. The IDDRC as the centerpiece of the VKC is the foundational organizing structure that creates a “Center culture” wherein research and discovery permeates the VKC’s broader training and service activities, thus enhancing the translational research goals of the IDDRC. Demonstrable IDDRC success includes 976 investigator- authored publications and robust NIH funding to Vanderbilt to support IDD-related research ($52.6M in FY20). Harnessing and leveraging this trans-institutional strength to focus on unique challenges in IDD, the overarching goal of the next phase of the IDDRC is to develop precision care for IDD by providing infrastructure and scientific leadership to enable rapid translation of basic discoveries into high- impact IDD interventions and treatments. Three global Aims guide the IDDRC’s work. Aim 1 provides core services to enable and disseminate impactful research on individualizing treatments based upon the causes, mechanisms, and contributing co-morbid sequelae of IDD; Aim 2 focuses on incorporating innovative methods and approaches to enhance multidisciplinary IDD research; and Aim 3 proposes to conduct a signature research project to improve the precision use of antipsychotic medication in people with autism. Across these Aims and five Cores supported by the IDDRC (Administrative, Clinical Translational, Translational Neuroscience, Behavioral Phenotyping, and Data Sciences), three themes permeate our work: (1) recruitment of highly-skilled researchers not currently conducting IDD research (non-traditional researchers); (2) inclusion of IDD participants into research studies that currently do not include IDD (non-traditional subjects); and (3) incorporation of novel scientific approaches and methods (non-traditional approaches). Our IDDRC is ideally posed to enable rapid discovery of precision care approaches by supporting 50 investigators leading 70 research projects (15 from NICHD) and, as highlighted by the Signature Research Project, to promote and implement generative, novel, and impactful research directions, thus meeting the NICHD’s vision of applying newly evolved technologies and approaches to rapidly accelerate the prevention and/or amelioration of IDDs. PUBLIC HEALTH RELEVANCE: As a group, intellectual and developmental disabilities, including Down syndrome and autism spectrum disorder, have dramatic effects on affected people’s and their caregiver’s lives. Unfortunately, there remains a lack of understanding about what causes these disabilities and, critically, how to treat them with targeted therapies. The Vanderbilt Kennedy Center’s Intellectual and Developmental Disabilities Research Center serves as the hub for Vanderbilt’s research efforts focusing on improving the lives of people with intellectual and developmental disabilities by understanding the causes of these disorders and developing and testing therapies tailored to each individual’s precise needs.",Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt,10229591,P50HD103537,"['Academic Medical Centers', 'Affect', 'Antipsychotic Agents', 'Basic Science', 'Behavioral', 'Biomedical Research', 'Caregivers', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Communities', 'Computerized Medical Record', 'Data', 'Data Science', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Disease', 'Disease model', 'Down Syndrome', 'Education', 'Evaluation', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Gap Junctions', 'Genotype', 'Goals', 'Image', 'Individual', 'Infrastructure', 'Institutes', 'Intellectual and Developmental Disabilities Research Centers', 'Intellectual functioning disability', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Longevity', 'Machine Learning', 'Medical Records', 'Methods', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurodevelopmental Disability', 'Obesity', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Pilot Projects', 'Policy Research', 'Prevention', 'Problem behavior', 'Publications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Schools', 'Series', 'Services', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Universities', 'Vision', 'Weight Gain', 'Work', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'clinical translation', 'comorbidity', 'cost effective', 'developmental disease', 'disability', 'drug-induced weight gain', 'experience', 'image processing', 'implementation science', 'improved', 'individualized medicine', 'individuals with autism spectrum disorder', 'innovation', 'large datasets', 'lectures', 'meetings', 'multidisciplinary', 'novel', 'personalized approach', 'personalized care', 'personalized medicine', 'population based', 'pragmatic trial', 'predictive modeling', 'programs', 'public health relevance', 'recruit', 'research study', 'success', 'targeted treatment', 'translational neuroscience', 'trial comparing']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,P50,2021,1364066
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home environment', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10260577,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'risk stratification', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2021,332101
"Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning Project Summary/Abstract A plethora of neuroscience studies shows mounting evidence that neurodegenerative diseases manifest distinct network dysfunction patterns much earlier prior to the onset of clinical symptoms. Since the subject-specific longitudinal network changes are more relevant to the neuropathological process than topological patterns derived from cross-sectional data, recognizing the subtle and dynamic longitudinal network biomarkers from noisy network data is of great demand to enhance the sensitivity and specificity of computer-assisted diagnosis in neurodegenerative diseases. However, current popular statistical inference or machine learning approaches used for neuroimages (in a regular data structure such as grid and lattice) are not fully optimized for the learning task on brain network data which is often encoded in a high dimensional graph (an irregular and non-linear data structure). Such gross adaption is partially responsible for the lack of reliable biomarkers that can be used to predict cognitive decline in routine clinical practice. To address this challenge, we aim to (1) develop a novel GNN (graph neural network) based learning framework to hierarchically discover the multi-scale network biomarkers that can recognize the disease-relevant network alterations over time, and (2) examine the diagnostic power of the new network biomarkers derived from our GNN-based machine learning engine across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia. The success of this project will allow us to integrate the novel GNN-based learning component into our current longitudinal network analysis toolbox and release the AI (artificial intelligence) based network analysis software to the neuroscience and neuroimaging community. Project Narrative The goal of this project is to continue the tool development of longitudinal network analysis for neurodegenerative diseases with the focus on the machine learning component. To do so, we will first develop the GNN (graph neural network) based learning framework to discover the multi-scale network biomarkers from the population of brain network data. After examining the diagnostic value of the network biomarkers discovered by our learning- based method across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia, we will integrate the machine learning component into our current longitudinal network analysis software and release to the neuroscience and neuroimaging community.",Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning,10109509,R03AG070701,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Artificial Intelligence', 'Biological Markers', 'Brain', 'Clinical', 'Cognitive', 'Communities', 'Computer software', 'Computer-Assisted Diagnosis', 'Data', 'Databases', 'Diagnostic', 'Dimensions', 'Disease', 'Early Diagnosis', 'Event', 'Evolution', 'Frontotemporal Dementia', 'Goals', 'Graph', 'Image', 'Impaired cognition', 'Individual', 'Industry', 'Investigation', 'Label', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Nerve Degeneration', 'Network-based', 'Neural Network Simulation', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Neurosciences', 'Outcome', 'Parkinson Disease', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Research', 'Resolution', 'Resources', 'Sample Size', 'Senile Plaques', 'Sensitivity and Specificity', 'Source Code', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Text', 'Time', 'United States National Institutes of Health', 'base', 'clinical practice', 'cohort', 'collaboratory', 'comparison group', 'computerized tools', 'data mining', 'data structure', 'deep learning', 'design', 'high dimensionality', 'machine learning method', 'method development', 'network dysfunction', 'neural network', 'neuroimaging', 'novel', 'outcome forecast', 'software development', 'success', 'tool', 'tool development']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R03,2021,158733
"SCH: INT: Collaborative Research: Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy The research objective of this proposal, Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy Prediction, with Pl Dominique Duncan from the University of Southern California, is to predict the onset of epileptic seizures following traumatic brain injury (TBI), using innovative analytic tools from machine learning and applied mathematics to identify features of epileptiform activity, from a multimodal dataset collected from both an animal model and human patients. The proposed research will accelerate the discovery of salient and robust features of epileptogenesis following TBI from a rich dataset, collected from the Epilepsy Bioinformatics Study for Antiepileptogenic Therapy (EpiBioS4Rx), as it is being acquired by investigating state-of-the-art models, methods, and algorithms from contemporary machine learning theory. This secondary use of data to support automated discovery of reliable knowledge from aggregated records of animal model and human patient data will lead to innovative models to predict post-traumatic epilepsy (PTE). This machine learning based investigation of a rich dataset complements ongoing data acquisition and classical biostatistics-based analyses ongoing in the study and can lead to rigorous outcomes for the development of antiepileptogenic therapies, which can prevent this disease. Identifying salient features in time series and images to help design a predictor of PTE using data from two species and multiple individuals with heterogeneous TBI conditions presents significant theoretical challenges that need to be tackled. In this project, it is proposed to adopt transfer learning and domain adaptation perspectives to accomplish these goals in multimodal biomedical datasets across two populations. Specifically, techniques emerging from d,eep learning literature will be exploited to augment data, share parameters across model components to reduce the number of parameters that need to be optimized, and use state-of-the-art architectures to develop models for feature extraction. These will be compared against established pipelines of hand-crafted feature extraction in rigorous cross-validation analyses. Developed techniques for transfer learning will be able to extract features that generalize across animal and human data. Moreover, these theoretical techniques with associated models and optimization methods will be applicable to other multi-species transfer learning challenges that may arise in the context of health and medicine. Multimodal feature extraction and discriminative model learning for disease onset prediction using novel classifiers also offer insights into biomarker discovery using advanced machine learning techniques through joint multimodal data analysis. A significant percentage of people develop epilepsy after a moderate-severe traumatic brain injury. If we can identify who will develop post-traumatic epilepsy and at what time point after the injury, those patients can be treated with antiepileptogenic therapies and medications to stop or prevent the seizures from occurring. It is likely that biomarkers of epileptogenesis after TBI can only be found by analyzing multimodal data from a large population, which requires advanced mathematical tools and models.",SCH: INT: Collaborative Research: Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy,10093160,R01NS111744,"['Adopted', 'Algorithms', 'Animal Model', 'Antiepileptogenic', 'Architecture', 'Bioinformatics', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Brain imaging', 'California', 'Chemicals', 'Complement', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Graph', 'Hand', 'Health', 'High Frequency Oscillation', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Injury', 'Intuition', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Length', 'Limbic System', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical', 'Medicine', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Onset of illness', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Post-Traumatic Epilepsy', 'Property', 'Proteins', 'Psychological Techniques', 'Psychological Transfer', 'Rattus', 'Records', 'Research', 'Rest', 'Scalp structure', 'Seizures', 'Series', 'Signal Transduction', 'Statistical Models', 'Structure', 'Techniques', 'Thalamic structure', 'Time', 'Tissues', 'Traumatic Brain Injury', 'Universities', 'Update', 'Validation', 'Voting', 'Work', 'analytical tool', 'animal data', 'base', 'biomarker discovery', 'data acquisition', 'data fusion', 'deep learning', 'design', 'feature extraction', 'human data', 'imaging modality', 'improved', 'innovation', 'insight', 'laboratory experiment', 'learning strategy', 'multimodal data', 'multimodality', 'neural network', 'neural network classifier', 'neurophysiology', 'novel', 'post-trauma', 'predictive modeling', 'prevent', 'random forest', 'support vector machine', 'theories', 'tool']",NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,243545
"Swift.ai: research and development of an integrated platform for machine-assisted research synthesis Project Abstract (30 lines of text)  1 Systematic review and evidence mapping, both forms of research synthesis, are formal, sequential processes  2 for identifying, assessing, and integrating the primary scientific literature. These approaches, already  3 cornerstones of evidence-based medicine, have recently gained significant popularity in several other  4 disciplines including environmental, agricultural, and public health research and are increasingly utilized for  5 informed decision making by governmental organizations. It has been estimated that more than 25,000  6 systematic reviews are conducted and published annually and selecting studies for inclusion is one of the most  7 resource intensive steps for any systematic review or evidence map. In Phase I of our research plan, we have  8 developed a web-based, collaborative systematic review web application called SWIFT-Active Screener, an  9 innovative document screening tool that allows users to identify the majority of relevant articles after screening 10 only a fraction of the total number of abstracts. Our goal for the current proposal is to conduct additional 11 research and development required to make SWIFT-Active Screener a commercial success, while also 12 building on and leveraging methods and software we have previously built to address other stages in the 13 systematic review pipeline. Therefore, one of the primary aims of our ongoing research and development is to 14 address this need by expanding the Active Screener application into an integrated platform for research 15 synthesis by uniting it with several of our other related software products. The resulting platform, which we call 16 “swift.ai,” is described in detail in “Aim 1 – Software engineering to create a unified platform for research 17 synthesis.” In “Aim 2 – Improved statistical methods for Active Screener 2.0”, we expand on the methodological 18 research completed during Phase I of this SBIR, to further develop and refine our methods. Specifically, we 19 investigate new ways to integrate state-of-the art methods in deep learning and new ways to better utilize the 20 large amounts of screening data collected from our users in order to improve our models. Finally, in “Aim 3 – 21 Living evidence maps powered by Active Screener 2.0,” we explore new approaches for using machine 22 learning to facilitate evidence mapping. Project narrative Systematic review is a formal process used widely in evidence-based medicine and environmental health research to identify, assess, and integrate the primary scientific literature with the goal of answering a specific, targeted question in pursuit of the current scientific consensus. By conducting research and development to build a unified, web-based, collaborative, systematic review software application that integrates the latest developments in deep-learning, machine learning, natural language processing and artificial intelligence, we will make an important contribution toward ongoing efforts to automate systematic review. These efforts will serve to make systematic reviews both more efficient to produce and less expensive to maintain, a result which will greatly accelerate the process by which scientific consensus is obtained in a variety of medical and health-related disciplines having great public significance.",Swift.ai: research and development of an integrated platform for machine-assisted research synthesis,10259172,R44ES029001,"['Active Learning', 'Address', 'Adoption', 'Agriculture', 'Artificial Intelligence', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Set', 'Decision Making', 'Development', 'Discipline', 'Elements', 'Endocrine disruption', 'Environmental Health', 'Evidence Based Medicine', 'Feedback', 'Focus Groups', 'Goals', 'Government', 'Health', 'Influentials', 'Internet', 'Learning', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Methods', 'Mission', 'Modeling', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Online Systems', 'Phase', 'Policies', 'Positioning Attribute', 'Problem Formulations', 'Procedures', 'Process', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Review Literature', 'Sampling', 'Scientist', 'Screening procedure', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Statistical Methods', 'System', 'Testing', 'Text', 'Toxicology', 'Uncertainty', 'Update', 'active method', 'cost', 'data modeling', 'data sharing', 'deep learning', 'evidence base', 'improved', 'innovation', 'novel strategies', 'public health research', 'research and development', 'response', 'screening', 'simulation', 'success', 'systematic review', 'user-friendly', 'web app']",NIEHS,"SCIOME, LLC",R44,2021,820314
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"xARA: ARA through Explainable AI In response to the NIH FOA OTA-19009 “Biomedical Translator: Development” we propose to build an Autonomous Relay Agent (ARA) that can characterize and rate the quality of information returned from multiple multiscale heterogeneous knowledge providers (KPs). Biomedical researchers develop a trust relationship with a knowledge provider (KP) through frequent and continued use. Over time a familiarity develops that drives their understanding and insight on 1) how to structure and invoke more effective queries, 2) the quality of the results they may expect in response to different query parameters and feature values, and 3) how to assess the relevancy of a specific query’s results. Although this information retrieval paradigm has served the research community moderately well in the past it is not scalable and the number, scope and complexity of KPs is increasing at a dramatic pace (1,613 molecular biology databases reported as of Jan. 2019). Within this ever changing information landscape, a biomedical researcher now has two choices -- either continue using the few KPs they have learned to trust but remain limited in the actionable information they will receive, or invest the time and accept the risk of using a range of new information resources with little or no familiarity and thus uncertain effectiveness. If researchers are to benefit from the vast array of NIH and industry sponsored information assets now available and expanding new information retrieval and quality assessment technologies will be required. We propose to build an Explanatory Autonomous Relay Agent (xARA) that can characterize query results by rating the quality of information returned from multi-scale heterogeneous KPs. The xARA will utilize multiple information retrieval and explainable Artificial Intelligence (xAI) strategies to perform queries across multiple heterogeneous KPs and rank their results by quality and relevancy while also identifying and explaining any inconsistencies among databases for the same query response. To deliver on this promise, we will utilize case-based reasoning and language models trained with biomedical data (i.e., BioBERT and custom annotation embeddings through Reactome and UniProt) permitting a new level of query profiling and assessment. Our strategies will permit 1) information gaps to be filled by testing alternative query patterns that produce different surface syntax yet possess semantically related and actionable concepts, 2) inconsistencies to be identified for a given query feature value, and 3) the identification and elimination or merging of semantically redundant query results via similarity metrics enriched by case-based reasoning strategies employed in the explainable AI (xAI) community to identify machine learning model behavior and performance. The xARA capabilities proposed herein will be based on strategies developed in Dr. Weber’s lab for information retrieval where the desire for greater transparency when reasoning over experimental data is our primary aim. Our multi-institutional team is comprised of senior researchers and software engineers formally trained and experienced in the computer and data sciences, cheminformatics, bioinformatics, molecular biology, and biochemistry. Inherent risks in querying heterogeneous KPs include the presence of inconsistent labeling of the same biomedical concept within unique KP data structures. Manual engineering may be necessary to overcome such hurdles, but will not be a significant challenge for the initial prototype, since only two well documented KPs are being evaluated. Another noteworthy risk is that the quality of word embeddings generated from UniProt and Reactome may not be sufficient, requiring further textual analysis of biomedical text like PubMed, which is feasible within the timeframe of our project plan. n/a",xARA: ARA through Explainable AI,10330631,OT2TR003448,"['Artificial Intelligence', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Communities', 'Custom', 'Data', 'Data Science', 'Databases', 'Development', 'Effectiveness', 'Engineering', 'Familiarity', 'Industry', 'Information Resources', 'Information Retrieval', 'Knowledge', 'Label', 'Language', 'Machine Learning', 'Manuals', 'Modeling', 'Molecular Biology', 'Pattern', 'Performance', 'Provider', 'PubMed', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Software Engineering', 'Structure', 'Surface', 'Technology Assessment', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'base', 'case-based', 'cheminformatics', 'computer science', 'experience', 'insight', 'prototype', 'response', 'syntax']",NCATS,TUFTS MEDICAL CENTER,OT2,2021,736476
"Knowledge-Based Biomedical Data Science Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. Building on decades of work in biomedical ontology development, and exploiting the architectures supporting the Semantic Web, we have demonstrated methods that allow effective querying spanning any combination of data sources in purely biological terms, without the queries having to reflect anything about the structure or distribution of information among any of the sources. These methods are also capable of representing apparently conflicting information in a logically consistent manner, and tracking the provenance of all assertions in the knowledge-base. Perhaps the most important feature of these methods is that they scale to potentially include nearly all knowledge of molecular biology.  We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data. To test this hypothesis, we propose to address the following specific aims:  1. Identify representative and significant analytical needs in knowledge-based data science, and  refine and extend our knowledge-base to address those needs in three distinct domains: clinical  pharmacology, cardiovascular disease and rare genetic disease.  2. Develop novel and implement existing symbolic, statistical, network-based, machine learning  and hybrid approaches to goal-driven inference from very large knowledge-bases. Create a goal-  directed framework for selecting and combining these inference methods to address particular  analytical problems.  3. Overcome barriers to broad external adoption of developed methods by analyzing their  computational complexity, optimizing performance of knowledge-based querying and inference,  developing simplified, biology-focused query languages, lightweight packaging of knowledge  resources and systems, and addressing issues of licensing and data redistribution. Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data.",Knowledge-Based Biomedical Data Science,10197219,R01LM008111,"['Address', 'Adoption', 'Architecture', 'Area', 'Artificial Intelligence', 'Biological', 'Biology', 'Biomedical Research', 'Cardiovascular Diseases', 'Clinical Data', 'Clinical Pharmacology', 'Collaborations', 'Communities', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Duchenne muscular dystrophy', 'Fruit', 'Funding', 'Genomics', 'Goals', 'Heart failure', 'Hybrids', 'Information Distribution', 'Information Resources', 'Knowledge', 'Language', 'Licensing', 'Literature', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Network-based', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Publishing', 'Role', 'Semantics', 'Serum', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'biomedical data science', 'biomedical ontology', 'cohort', 'computer based Semantic Analysis', 'design and construction', 'health data', 'innovation', 'knowledge base', 'large scale data', 'light weight', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'online resource', 'ontology development', 'rare genetic disorder', 'tool', 'transcriptomics']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2021,506502
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,10085652,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Infrastructure', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data cleaning', 'data ecosystem', 'data reuse', 'data sharing', 'data standards', 'digital', 'experience', 'experimental study', 'insight', 'member', 'metadata standards', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2021,489919
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),10145009,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2021,1210147
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10162578,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2021,753275
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,10149399,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,313018
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,10214625,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2021,3125
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227
"Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics PROJECT SUMMARY When an outbreak of an established or emerging infectious disease occurs we ask a standard set of questions that are critical to a lifesaving public health response: Where will future incidence occur? How many cases will there be? And where can we most effectively intervene? The proposed research is motivated by real world instances where answering these questions was critical to making practical public health decisions, and current methods came up short: from deciding if and where to build additional Ebola Treatment Units in the 2014-15 West African Ebola epidemic, to identifying priority districts where oral cholera vaccine should be used in the 2016-17 cholera outbreak in Yemen, to picking locations where sufficient cases might occur to selecting and prioritizing interventions to slow the spread of COVID-19 worldwide. Forecasts informing such decisions are typically generated either using an epidemic model that relies on knowledge of the disease transmission mechanism and epidemic theory or using a statistical model to project the expected number of cases based on the relationship between covariates and observed counts. However, both approaches are subject to limitations, particularly early in an epidemic when few cases are observed. This project is based on the overarching scientific premise that inferences that combine the strengths of mechanistic epidemic models and statistical covariate models will substantially outperform either approach alone in forecasting and making decisions to confront emerging infectious disease threats. Specifically, this project aims to (1) Develop a framework to forecast incidence in ongoing outbreaks that merges mechanistic and machine learning approaches; (2) Validate the framework using retrospective data and apply the framework to inform decision making in emerging epidemics; (3) Integrate this inferential forecasting framework into causal decision theory to optimize critical actions in the public health response to emerging epidemics; and (4) Develop accessible and extensible tools for forecasting and decision analysis in infectious disease epidemics. We will validate these approaches using rigorous simulation studies and by applying the proposed approaches to retrospective data from important recent epidemics (e.g., Ebola, Cholera and COVID-19, as mentioned above). We will prospectively apply our approach to inform the response to emerging disease threats that occur during the project period, including the ongoing COVID-19 pandemic. To ensure that the tools developed are useful, efficient, and user friendly, we will work with international humanitarian organizations responding to epidemics. Successful completion of these aims will provide a flexible and validated framework for forecasting and decision making during ongoing epidemics, while allowing for innovation in mechanistic and statistical approaches. In doing so it will provide tools to optimize responses and reduce morbidity and mortality during public health crises. PROJECT NARRATIVE The purpose of the proposed project is to improve inference, forecasting and decision making in response to emerging infectious diseases by developing a framework to integrate mechanistic and statistical approaches to epidemic modeling and causal inference. Approaches developed will be validated using simulations and retrospective data and applied prospectively to reduce morbidity and mortality in emerging public health crises. Further, they will be incorporated into publically available tools for use in epidemic response.",Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics,10142638,R01GM140564,"['African', 'Algorithms', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Cholera', 'Cholera Vaccine', 'Communicable Diseases', 'Community Health', 'Cost utility', 'Data', 'Data Set', 'Decision Analysis', 'Decision Making', 'Decision Theory', 'Disease', 'Disease Outbreaks', 'Ebola', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Evaluation', 'Fogs', 'Future', 'Geographic Locations', 'Incidence', 'International', 'Intervention', 'Knowledge', 'Liberia', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Online Systems', 'Oral', 'Policies', 'Public Health', 'Research', 'Research Personnel', 'Series', 'Shapes', 'Statistical Algorithm', 'Statistical Methods', 'Statistical Models', 'System', 'Time', 'Translating', 'Update', 'War', 'Work', 'Yemen', 'base', 'case-based', 'curve fitting', 'dashboard', 'disease transmission', 'experience', 'flexibility', 'improved', 'innovation', 'mortality', 'multidimensional data', 'programs', 'prospective', 'response', 'simulation', 'sound', 'surveillance data', 'theories', 'tool', 'transmission process', 'user-friendly']",NIGMS,JOHNS HOPKINS UNIVERSITY,R01,2021,429701
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,10133117,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Comparative Effectiveness Research', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'computer science', 'data sharing', 'design', 'digital', 'diverse data', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'machine learning algorithm', 'machine learning method', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2021,249000
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Nathan Shock Center of Excellence in Basic Biology of Aging OVERALL PROJECT SUMMARY This application is for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington and affiliated institutions. This Center has over the past 25 years provided key resources in support of investigators who study the biology of aging. This application continues a theme that emphasizes outreach and service to the broadest community of investigators in the gerosciences. Of proximal relevance is the characterization of aging-related phenotypes of longevity and healthspan. As our Center services must be easily accessible to outside users, our Longevity and Healthspan Core (Core E) focuses on invertebrate assays, many of them novel. Two other Resources Cores focus on the high dimensional assessments that are closely related to aging phenotypes: Protein Phenotypes of Aging (Core C) and Metabolite Phenotypes of Aging (Core D). Sophisticated computational and bioinformatic tools for data analysis and optimal insight are provided by the Artificial Intelligence and Bioinformatics Core F. Each of these four Resource Cores is led by highly respected experts in that field, including Michael MacCoss and Judit Villen (Core C), Daniel Promislow (Core D), Matt Kaeberlein and Maitreya Dunham (Core E) and Su-In Lee (Core F). Each will push the envelope of appropriate technologies, developing new state-of-the art approaches for assessments that are the most applicable to gerontology and making them accessible to the national aging community. The Research Development Core (Core B) will continue to support pilot and junior faculty studies, with a firm focus on outreach of service to the national geroscience constituency. The Administrative and Program Enrichment Core (Core A) supports administrative management, an external advisory panel, courses, and data sharing and dissemination. Core A’s program of seminars and symposia will continue a focus on sponsorship and organization of national courses, meetings and pre-meetings, as well as workshops in the fields allied to our Resource Core Services. In coordination with other Nathan Shock Centers, we will support a new Geropathology Research initiative. UW NATHAN SHOCK CENTER OVERALL - PROJECT NARRATIVE We apply for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington, which has for 25 years provided key resources supporting investigators who study the biology of aging. The overarching goal of this Center is to have a positive impact on the field by accelerating research discovery and providing research support for investigators nationally and internationally, particularly junior investigators in the process of building their own research programs. We will accomplish this goal through six cores that function synergistically together: four Resource Cores with particular expertise in protein (Core C) and metabolite (Core D) phenotypes of aging, invertebrate longevity and healthspan phenotypes (Core E) and artificial intelligence and bioinformatics (Core F), along with a Research Development Core (Core B) that supports external pilot projects and junior faculty studies, and an Administrative and Program Enrichment Core (Core A) that supports administrative management, an external advisory panel, sponsorship and organization of national meetings and pre-meetings, courses, workshops and seminars, and, in coordination with other Nathan Shock Centers, a Geropathology Research initiative.",Nathan Shock Center of Excellence in Basic Biology of Aging,10260476,P30AG013280,"['Aging', 'Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'Biology of Aging', 'Collaborations', 'Communication', 'Communities', 'Consult', 'Data', 'Data Analyses', 'Development', 'Educational workshop', 'Environment', 'Experimental Designs', 'Faculty', 'Genes', 'Genetic study', 'Gerontology', 'Geroscience', 'Goals', 'Growth', 'Informatics', 'Institution', 'International', 'Invertebrates', 'Leadership', 'Longevity', 'Methodology', 'Methods', 'Microfluidics', 'Molecular Genetics', 'Office of Administrative Management', 'Pathway interactions', 'Phenotype', 'Philosophy', 'Pilot Projects', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteomics', 'Research', 'Research Activity', 'Research Personnel', 'Research Support', 'Resources', 'Robotics', 'Services', 'Shock', 'Statistical Data Interpretation', 'Technology', 'Transcript', 'Universities', 'Variant', 'Washington', 'bioinformatics tool', 'career development', 'cell age', 'computerized tools', 'data dissemination', 'data sharing', 'healthspan', 'high dimensionality', 'insight', 'meetings', 'metabolomics', 'multiple omics', 'novel', 'outreach', 'outreach services', 'programs', 'protein metabolite', 'research and development', 'symposium', 'tool', 'trait']",NIA,UNIVERSITY OF WASHINGTON,P30,2021,962037
"Research Symposium in Communication Sciences and Disorders The Research Symposium in Communication Sciences and Disorders supports a full day of presentations by leading scientists in areas that are having transformational effects in the communication sciences and disorders (CSD) discipline. The Research Symposium is held at the annual Convention of the American Speech-Language-Hearing Association (ASHA) and is open to all of the approximately 15,000 Convention attendees, which includes students, practitioners, and researchers. Following Convention, the Symposium content is widely disseminated through audio recordings of the presentations, which are synced with the slides and transcribed, and by making them freely accessible on the ASHA website. Additionally, each presenter submits an article based on their presentation to the Journal of Speech, Language, and Hearing Research to be published in the annual Research Symposium Forum. An innovation that will be implemented in this current funding cycle is that ASHA will make these articles freely accessible upon publication on the ASHA Journals website and will deposit them in PubMed Central without embargo. The first aim of the Research Symposium grant is to advance scientific discourse and dissemination of scientific discovery and innovation on five topics that are having transformational effects across several subareas in CSD. This will be accomplished, in part, by making the Research Symposium Forum open access and by widely promoting both the recorded and the written content across ASHA’s many communication channels. Over the next 5-year funding cycle, the Symposium will address five topics that cut across the areas of hearing, speech, language, and other aspects of cognition, including (1) Health and Healthcare Equity of People With Communication Disabilities, (2) Bilingualism, (3) Artificial Intelligence in CSD, (4) Genetics in CSD, and (5) Intervention and Implementation Clinical Trials in CSD. The second aim of the Research Symposium grant is to advance the research career development of early- career scientists focused on research in CSD. Between 2021 and 2025, the Research Mentoring- Pair Travel Award and ASHA’s in-kind contribution will provide funding to attend the Symposium and mentoring support to 130 early-career scientists in CSD. The Travel Award recipients will attend the Symposium along with a mentor and engage in mentored research activities before, during, and after each Symposium. These activities are designed to help integrate the protégés into their scientific community and encourage them to pursue a research career and become productive scholars. The scientific base of the CSD discipline will be strengthened by these scientific dissemination, research education, and mentoring activities. The Research Symposium in Communication Sciences and Disorders aims to strengthen the scientific base and increase the research capacity of the discipline, which will lead to improvements in the communication health of millions people with communication or related disorders. The Symposium presentations will advance the scientific dialogue and be broadly disseminated through freely available peer-reviewed publications and transcribed recordings. The associated Travel Award will provide funds to support 130 promising early-career scientists in attending the Research Symposium and engaging in mentored research activities before, during, after the Symposium to increase their recruitment and retention in a research career.",Research Symposium in Communication Sciences and Disorders,10070224,R13DC003383,"['Address', 'American Speech-Language-Hearing Association', 'Area', 'Artificial Intelligence', 'Award', 'Awareness', 'Clinical', 'Clinical Trials', 'Cognition', 'Communication', 'Communication Disability', 'Communities', 'Data', 'Degree program', 'Deposition', 'Dimensions', 'Discipline', 'Disease', 'Doctor&apos', 's Degree', 'Enrollment', 'Ensure', 'Event', 'Funding', 'Generations', 'Genetic', 'Grant', 'Health', 'Health Communication', 'Healthcare', 'Hearing', 'Hour', 'Intervention', 'Journals', 'Knowledge', 'Language', 'Manuscripts', 'Mentors', 'Methodology', 'Monitor', 'Outcome Measure', 'Peer Review', 'Postdoctoral Fellow', 'Preparation', 'PubMed', 'Publications', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seminal', 'Slide', 'Speech', 'Students', 'Surveys', 'Time', 'Travel', 'Work', 'base', 'bilingualism', 'career', 'career development', 'clinical trial implementation', 'design', 'dissemination research', 'doctoral student', 'education research', 'experience', 'innovation', 'knowledge base', 'meetings', 'next generation', 'online community', 'recruit', 'social media', 'stem', 'symposium', 'web site']",NIDCD,AMERICAN SPEECH-LANGUAGE-HEARING ASSN,R13,2021,39900
"CSHL Network Biology Conference PROJECT SUMMARY This proposal seeks support for the conference on Network Biology, to take place March/April 2021 to 2025, at the Cold Spring Harbor Laboratory (CSHL). This meeting, held in biannual rotation on the CSHL campus in New York, brings together senior and junior scientists from both experimental and computational laboratories with common interests in network biology. The meeting will emphasize new discoveries and provide an open forum for the presentation of the latest research and results on molecular networks and their relevance to normal and abnormal cellular physiology. It will be essential for advancing knowledge in all aspects of the network modeling process, from data generation in experimental cell biology to data analysis and computer simulation and from the development and validation of network models describing these data to biological inferences made from the models. The conference will include platform sessions on interaction networks, signaling and network dynamics, regulatory networks, computational tools, artificial intelligence and big data, multi-scale networks, networks and disease, networks in differentiation, microbiome networks, network evolution, synthetic networks, network engineering and networks beyond biology though the exact program for the meeting will be assembled after the abstract submission deadline in February 2021 and adapted to ongoing developments in the field in subsequent years. This conference will include significant components designed to facilitate the active participation of younger scientists such as selection of platform speakers on the basis of the scientific merit of their submitted abstracts as well as poster presentations, round tables, lightning talks and poster prizes. Distinguished speakers will also be invited to give platform talks and interact with more junior scientists. The intimate environment at CSHL fosters social interactions and active participation by all. The majority of participants to the previous CSHL Network Biology meeting expressed that they were “very satisfied”. Speakers' panels have consisted of at least 50% women; the gender balance will be maintained in future meetings. In the 2019 iteration of the meeting, a panel discussion was established to address the challenges of Women in Network Science. We will continue to address big community challenges though panel discussions in this meeting. In 2021, we will discuss Applicability and Translatability of Network Biology with panelists including network biologists whose work is deeply influential throughout the ongoing covid-19 pandemic. PROJECT NARRATIVE Biological systems are functionally and structurally formed by complex networks of interacting molecular components, many of which are encoded in the genome. Elucidating the structure and function of these networks and understanding how their dysregulation causes disease are critical steps toward improving human health. This application seeks support for the conference on Network Biology to be held every two years in March/April 2021-25 at the Cold Spring Harbor Laboratory, to bring together experimental and computational biologists and discuss emerging trends and latest results in the field.",CSHL Network Biology Conference,10137390,R13HG011550,"['Address', 'Animals', 'Artificial Intelligence', 'Attention', 'Awareness', 'Big Data', 'Biochemistry', 'Biological', 'Biological Process', 'Biology', 'COVID-19 pandemic', 'Cell physiology', 'Cellular biology', 'Chalk', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Discipline', 'Disease', 'Engineering', 'Ensure', 'Environment', 'Equilibrium', 'Event', 'Evolution', 'Faculty', 'Fostering', 'Future', 'Gender', 'Gene Proteins', 'Generations', 'Genetic', 'Genome', 'Geography', 'Health', 'Human', 'Industrialization', 'Influentials', 'International', 'Intervention', 'Knowledge', 'Laboratories', 'Length of Stay', 'Lightning', 'Methodology', 'Microbe', 'Modeling', 'Molecular', 'Nationalities', 'New York', 'Normal Cell', 'Organism', 'Participant', 'Plants', 'Postdoctoral Fellow', 'Prize', 'Process', 'Property', 'Published Comment', 'RNA', 'Reagent', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Rotation', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Structure', 'Technology', 'Validation', 'Woman', 'Work', 'base', 'biological systems', 'career', 'computer science', 'computerized tools', 'data exchange', 'data reuse', 'design', 'graduate student', 'host-microbe interactions', 'improved', 'innovation', 'interdisciplinary collaboration', 'interest', 'meetings', 'microbiome', 'multidisciplinary', 'network models', 'posters', 'precision medicine', 'programs', 'senior faculty', 'social', 'symposium', 'trend', 'unpublished works']",NHGRI,COLD SPRING HARBOR LABORATORY,R13,2021,3000
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods. 1 This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings –  2 funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating  3 Biology into In Silico Methodologies: Modern Approaches for incorporating biological  4 reasoning and understanding into computational methods. As a “Contemporary Concepts  5 in Toxicology” meeting, this workshop has the full backing, including being financially  6 underwritten, by the Society of Toxicology.  7 Computational modeling is an important tool for assessing the safety and use of  8 chemicals across many industries, including chemical, pharmaceutical, and consumer products.  9 Moreover, in silico methodologies offer academia and regulatory a fast and cheap method of 10 prioritizing its efforts to maintain compliance and safety in the market and environment. 11 This conference is designed to promote the development of actionable insights and 12 methodologies for increasing the biological relevance of in silico solutions. Specifically, this 13 conference will focus on solving the “black box effect”. There are many ways to validate a 14 model’s accuracy and domain – however if the model cannot explain what is happening 15 biologically, its use is severely diminished. This workshop will bring together regulatory, 16 academia, industry, and service providers to discuss current solutions and efforts, as well as 17 ongoing and future research. One goal of this conference will be to develop a roadmap for the 18 incorporation of AOPs (and similar biological reasonings) for computational tools. 19 This workshop has great appeal for multiple stakeholders within toxicology, namely 20 industry, academia, regulators, as well as service providers. The use of machine-learning to 21 replace laboratory toxicological tests is paramount to the future of the industry (3Rs). The use 22 of in silico models are explicitly referenced by NICEATM’s U.S. Strategic Roadmap, as well as 23 TSCA. Moreover, many industries and regulatory entities are taking significant steps away from 24 animal testing. Most recently, the US EPA stated that it will eliminate animal testing by 2035. 25 This workshop will bring together different stakeholders to discuss the current state of 26 AOPs and in silico methodologies, and to work towards a unified approach for their 27 incorporation. The final outcome of the workshop will be a white-paper that not only reviews the 28 current landscape but discusses concretes steps, as outlined in the breakout session, needed 29 for the regulatory acceptance of machine learning technologies – specifically a roadmap for the 30 inclusion of AOPs into computational tools and explanations. This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings – funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating Biology into In Silico Methodologies: Modern Approaches for incorporating biological reasoning and understanding into computational methods. This workshop will bring together different stakeholders to discuss the current state of AOPs and in silico methodologies, and to work towards a unified approach for their incorporation. The final outcome of the workshop will be a white- paper that not only reviews the current landscape but discusses concretes steps, as outlined in the breakout session, needed for the regulatory acceptance of machine learning technologies – specifically a roadmap for the inclusion of AOPs into computational tools and explanations.",Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods.,10144727,R13ES032662,"['Academia', 'Address', 'Adoption', 'Animal Testing', 'Animals', 'Back', 'Biological', 'Biology', 'Budgets', 'Chemicals', 'Chemistry', 'Communities', 'Computer Models', 'Computing Methodologies', 'Decision Making', 'Development', 'Educational workshop', 'Environment', 'Event', 'Funding', 'Future', 'Goals', 'In Vitro', 'Individual', 'Industry', 'Laboratories', 'Laws', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'National Institute of Environmental Health Sciences', 'Nonprofit Organizations', 'Outcome', 'Paper', 'Pathway interactions', 'Pharmacologic Substance', 'Policies', 'Process', 'Publishing', 'Safety', 'Societies', 'System', 'Technology', 'Testing', 'Toxicology', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'cheminformatics', 'computer framework', 'computerized tools', 'consumer product', 'cost', 'design', 'improved', 'in silico', 'in vivo', 'insight', 'meetings', 'predictive modeling', 'research and development', 'service providers', 'symposium', 'tool', 'web site']",NIEHS,"TOXTRACK, LLC",R13,2021,4000
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),10147746,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'efficacy evaluation', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2021,162000
"Advanced Training at the Interface of Engineering and Oral-Craniofacial Sciences Contact PD/PI: KOO, HYUN Oral diseases and disorders in the craniofacial complex disproportionally and devastatingly afflict susceptible populations, particularly impoverished families and medically or physically compromised persons. Novel engineering approaches, properly leveraged, can yield new paradigms to reveal disease mechanism, new strategies for disease mitigation, and new approaches for affordable/personalized therapies for dental caries, periodontal diseases, and oral cancer. To achieve this vision, academic research bound dentist-scientists must be adept in engineering concepts and engineers must be educated in oral and craniofacial sciences and needs; all must be aware of the complex clinical and regulatory landscapes. To address this urgent need, we propose a multidisciplinary training program in Penn’s School of Dental Medicine (PDM) and School of Engineering & Applied Sciences (SEAS) focused on training dentist-scientists and engineers for academic careers dedicated to research in precision oral health and healthcare innovation. Postdoctoral trainees will adopt cutting-edge approaches at the forefront of engineering and computational sciences to advance the fields of oral biofilm microbiome, host immunity and tissue regeneration, drawing on approaches including artificial intelligence, robotics, nanotechnology, and materials sciences, aware of developmental hurdles and requirements to safely bring new approaches to patients. Trainees will engage in interactive and tailored academic experiences with intensive mentored research via co-mentoring (one advisor from each school), and interaction with a career mentoring committee (CMC) that includes at least one dental clinician. Co-mentors and CMC members will be drawn from the Program Faculty of 26 faculty in PDM and SEAS with significant records of mentorship of multidisciplinary and translational research. Training will include: (1) engineering fundamentals for dental trainees and oral & craniofacial biology principles for engineering trainees, tailored to match their research project and academic needs, (2) clinical research and regulatory affairs, (3) principles of scientific rigor and reproducibility, (4) scientific writing and (5) workshops on professional and career development. Trainees will engage in academic and industry interactions, journal club, give symposia presentations, and participate in AADR/IADR activities. Training will culminate in F/K award applications focused on advancing oral health at the dental-engineering interface. The applicant pool at the University of Pennsylvania is exceptionally strong and diverse, and we anticipate being able to attract outstanding candidates. Furthermore, via partnerships with ADA, AADR/IADR and minority-serving dental schools, we will diversify our candidate pool. We plan to enroll 4 trainees per year. Importantly, this effort will be an element of a newly formed inter-school center between PDM and SEAS with shared funding. The proposed program, unique to Penn, leverages a superb research and training environment within a compact campus where resources for both schools are united through Penn’s new Center for Innovation and Precision Dentistry. Project Summary/Abstract Page 6 Contact PD/PI: KOO, HYUN Advances in engineering approaches offer previously unimagined opportunities to advance the NIDCR 2030 vision of precision oral health for all. To harness this opportunity, a critical mass of cross-trained dentists and engineers engaged in oral and craniofacial research are urgently needed. We will develop this workforce.  Project Narrative Page 7",Advanced Training at the Interface of Engineering and Oral-Craniofacial Sciences,10414192,R90DE031532,"['Address', 'Adopted', 'Applied Research', 'Artificial Intelligence', 'Awareness', 'Biology', 'Clinical', 'Clinical Research', 'Committee Members', 'Complex', 'Computational Science', 'Dental', 'Dental Schools', 'Dental caries', 'Dentistry', 'Dentists', 'Development', 'Disease', 'Educational workshop', 'Elements', 'Engineering', 'Enrollment', 'Environment', 'Faculty', 'Family', 'Funding', 'Healthcare', 'Immunity', 'Industry', 'Interdisciplinary Study', 'Journals', 'K-Series Research Career Programs', 'Medical', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mouth Diseases', 'Nanotechnology', 'National Institute of Dental and Craniofacial Research', 'Oral', 'Oral health', 'Patients', 'Pennsylvania', 'Periodontal Diseases', 'Persons', 'Population', 'Poverty', 'Records', 'Regulatory Affairs', 'Reproducibility', 'Research', 'Research Project Grants', 'Research Training', 'Resources', 'Robotics', 'Schools', 'Science', 'Scientist', 'Training', 'Training Programs', 'Translational Research', 'Universities', 'Vision', 'Writing', 'career', 'career development', 'craniofacial', 'craniofacial complex', 'experience', 'innovation', 'malignant mouth neoplasm', 'materials science', 'microbiome', 'multidisciplinary', 'novel', 'novel strategies', 'oral biofilm', 'personalized medicine', 'programs', 'symposium', 'tissue regeneration']",NIDCR,UNIVERSITY OF PENNSYLVANIA,R90,2021,96721
"UT Southwestern Center for Translational Medicine Contact PD/PI: Toto, Robert D OVERALL: PROJECT SUMMARY/ABSTRACT The Center for Translational Medicine (CTM) at UT Southwestern is a collaboration among 7 academic institutions, 5 health care systems, 6 teaching hospitals and the North Texas community. Our mission is to improve health in local and global communities through innovation and education. Over the past two funding cycles, our CTSA catalyzed innovation and transformed the culture and landscape of our program Hub. We have trained >1,000 members of the translational workforce, co-led the formation of the Accrual to Clinical Trials CTSA network and established new translational technologies, methods, and processes critical to the translational process at every level. We engaged our local communities early on in the design and conduct of clinical research. We also formed new collaborative research services and education and training programs designed to address the top health challenges of our community and the nation. Through these efforts, the CTM has generated considerable momentum toward advancing translational science propelled by a highly collaborative environment that is hard-wired for Team Science and Community Engagement.  Over the next 5 years, we will optimize the organization of our CTSA Hub for more efficient translation of biomedical discoveries into interventions that will ultimately result in the improved health of both our local populations and, in collaboration with the CTSA Network, the broader U.S. population. We will discover, develop, demonstrate, and disseminate new informatics and artificial intelligence solutions to challenging problems in translation at all levels. In collaboration with Hub partners and relevant national CTSA networks, we propose to develop new methods and processes to further the integration of research into practice at the point of care. Building on our success, we are now poised to achieve the five key objectives of the CTSA Program and the Center for Translational Medicine with the following Specific Aims: Aim 1. Produce a well-trained, highly skilled, diverse Translational Workforce. Aim 2. Inculcate Community Engagement and Team Science. Aim 3. Integrate diverse populations across the lifespan into clinical and translational research. Aim 4. Promote innovation and new scientific Methods and Processes. Aim 5. Develop innovative Informatics solutions to overcome translational roadblocks. Aim 6. Increase Workforce Heterogeneity. Impact: With our highly-integrated dynamic research and training environment in place, our Hub will have a powerful and sustained impact on the field of translational science. We will make a major leap forward in the scope, efficiency, and quality of clinical and translational research for the benefit of our Hub and the national consortium. We will collaborate with the Center for Leading Innovation and Collaboration, the Trial Innovation Network, and the Center for Data to Health to bridge the gap between scientific discovery and improved health. Project Summary/Abstract Page 164 Contact PD/PI: Toto, Robert D O. OVERALL:  PROJECT NARRATIVE Improving the health of our nation requires collaboration among teams of biomedical scientists, health care providers, community members, patients, and policymakers. The goal of this proposal is to engage such teams in a national effort to translate new scientific discoveries into clinical practice to improve health. Project Narrative Page 165",UT Southwestern Center for Translational Medicine,10349035,UL1TR003163,"['Address', 'Adoption', 'Artificial Intelligence', 'Basic Science', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communication', 'Communities', 'Data', 'Data Collection', 'Education', 'Ensure', 'Entrepreneurship', 'Environment', 'Faculty', 'Family', 'Fostering', 'Foundations', 'Funding', 'Gap Junctions', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Incentives', 'Individual', 'Industry', 'Informatics', 'Institution', 'Intervention', 'Leadership', 'Longevity', 'Mentors', 'Methods', 'Mission', 'Outcome', 'Patients', 'Phase', 'Population', 'Population Heterogeneity', 'Process', 'Published Comment', 'Qualitative Methods', 'Reproducibility', 'Research', 'Research Training', 'Resources', 'Rural Community', 'Rural Population', 'Science', 'Scientist', 'Services', 'Special Population', 'Teaching Hospitals', 'Technology', 'Testing', 'Texas', 'Training', 'Training Programs', 'Training Support', 'Training and Education', 'Translating', 'Translational Research', 'Translations', 'Underserved Population', 'Urban Community', 'Urban Population', 'academic program', 'biomedical scientist', 'catalyst', 'clinical practice', 'collaborative environment', 'design', 'ethnic diversity', 'improved', 'informatics training', 'innovation', 'member', 'multimodality', 'novel', 'novel strategies', 'personalized medicine', 'point of care', 'population health', 'pre-clinical', 'programs', 'racial diversity', 'recruit', 'research to practice', 'skills', 'success', 'tool', 'translational medicine', 'user-friendly']",NCATS,UT SOUTHWESTERN MEDICAL CENTER,UL1,2021,8029629
"An Agent-Based Modeling Platform for Environmental Biotechnology Hazardous pollutants in the environment continue to threaten public health and environmental  safety. Human exposure to major contaminant classes, such as polyfluorinated compounds  (PFCs), hazardous organic compounds (HOCs), and heavy metals, has been linked to a variety of  diseases and is subject to stringent State and Federal environmental regulations.  Bioremediation is a low-cost and environmentally friendly approach with many successful  use-cases; however, conventional bioremediation technologies can suffer from unreliability, low  degradation rates, and incomplete degradation. As stakeholders to Superfund sites and other sites  with water or soil pollution urgently demand more efficient, less costly and more reliable  remediation technologies, it is critical to look to advancements in computational  modeling to develop next-generation, precision-engineered bioremediation technologies. The proposed project builds on successful outcomes from Phase I in which a new computational  platform was designed and validated to accurately predict the bioremediation kinetics of  a multi-organism microcosm degrading a combination of HOCs in groundwater. The basis of  this platform is an approach called agent-based modeling (ABM), where the functions of  individual components (e.g. microorganisms) within complex ecosystems are used to predict and  optimize system-level properties (e.g. bioremediation kinetics). In this Phase II project, the novel computational platform developed in Phase I is  further improved with a machine learning component that leverages bioinformatics  databases to develop rationally tailored microbiomes for degrading complex pollutant  mixtures. Iterative experimental validation of model outputs is conducted using an innovative  materials science platform that maintains the relative concentration of different species in the  microbiome constant within the multi-zone treatment barrier (in-situ) or multi-zone bioreactor  (ex-situ). The project includes focused development of a prototype for one bioremediation use-case,  which is directly compared to a conventional (non-precision) bioremediation system treating   actual contaminated groundwater. This will be performed in order to assess and quantify  the expected technical and economic benefits of harnessing the project's novel computational  platform in biotechnology development. The broad, long-term impact of the proposed project will be to transform the development and  implementation of bioremediation by integrating advancements in computational modeling, machine  learning, bioinformatics, and materials science. By leveraging novel tools across disciplines, the  project will accelerate the development of more precise, reliable and inexpensive technologies for  environmental remediation. The successful outcome of the proposed project will also provide new  collaborative opportunities for industry and academia to more rapidly address the remediation of  high-priority pollutants in the environment, and ultimately help mitigate the effects of hazardous  pollutants on communities impacted by the presence of environmental contamination. PROJECT NARRATIVE Contaminated soils and waters continue to threaten public health and safety. This project builds on the development of a novel computational platform for predicting the complex, dynamic interactions between microbial ecosystems and hazardous contaminants-of-concern in the environment, and to utilize this information to develop improved engineered remediation biotechnologies.",An Agent-Based Modeling Platform for Environmental Biotechnology,10158243,R44ES026541,"['Academia', 'Address', 'Biodegradation', 'Bioinformatics', 'Bioreactors', 'Bioremediations', 'Biotechnology', 'Chemicals', 'Classification', 'Colorado', 'Communities', 'Complex', 'Computer Models', 'Data', 'Databases', 'Development', 'Discipline', 'Disease', 'Economics', 'Ecosystem', 'Engineering', 'Environment', 'Environmental Monitoring', 'Environmental Pollution', 'Enzymes', 'Exposure to', 'Ginkgo biloba', 'Goals', 'Growth', 'Heavy Metals', 'In Situ', 'Indiana', 'Individual', 'Industry', 'Kinetics', 'Laboratories', 'Learning Module', 'Letters', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Molecular', 'Municipalities', 'Organism', 'Outcome', 'Output', 'Phase', 'Polymers', 'Process', 'Property', 'Public Health', 'Regulation', 'Research', 'Safety', 'Side', 'Site', 'Soil', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Water', 'Water Pollution', 'base', 'computational platform', 'cost', 'design', 'economic evaluation', 'enzyme pathway', 'exposed human population', 'ground water', 'improved', 'innovation', 'laboratory experiment', 'materials science', 'microbial', 'microbiome', 'microorganism', 'next generation', 'novel', 'pollutant', 'prototype', 'remediation', 'research and development', 'soil pollution', 'success', 'superfund site', 'tool']",NIEHS,"MICROVI BIOTECH, INC.",R44,2021,630992
"Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer Project Summary In 2010, Pittsburgh Supercomputing Center (PSC) and D.E. Shaw Research (DESRES) partnered to make the Anton special-purpose molecular dynamics (MD) supercomputer available to the national biomedical research community for the first time. Anton enabled researchers to simulate biomolecular systems two orders of magnitude faster than any conventional supercomputer, allowing researchers access to critical multi- microsecond and longer timescales on which most biologically-significant molecular processes take place. In 2016, with operational support from NIH, DESRES made available a next generation Anton 2 system at PSC at no cost. This multimillion-dollar gift from DESRES, with NIH support, provided a unique opportunity for researchers to tackle even more groundbreaking biological questions by simulating systems as large as 700,000 atoms at a rate of multiple microseconds per day. The goal of this renewal project is to provide the national biomedical research community with continued access to this unique and powerful Anton 2 resource and to maximize the benefit of this resource to the community. Since 2010, PSC has supported 589 research projects conducted by 202 unique PIs on the Anton systems hosted at PSC. So far, these projects have resulted in 292 publications, many of which have had significant impact on their fields of research. These fields cover the entire spectrum of biomolecular processes that form the fundamental underpinnings of biology, including protein folding, ion channel selectivity and gating, membrane dynamics and organization, protein- ligand binding, and many others. Demand for Anton 2 is quite high, with 2-3x higher demand than can be met each year. Given this, our goals are focused not only on providing continued access but also on maximizing the value of this limited resource to the community—recognizing that the creativity of the broad, diverse Anton 2 research community is one of our most powerful resources for innovation. Anton 2 will be integrated as an XSEDE service provider, and the accessibility and impact of Anton 2 will significantly increase by engaging in their extensive broadening participation, outreach, and training programs. Through these outreach efforts, researchers at many more institutions will have the opportunity to use Anton 2, especially researchers from traditionally underrepresented groups in biomedical research. The hundreds of long-timescale MD trajectories researchers generate on Anton 2 constitute a unique and valuable dataset that can be used to gain additional biomedical knowledge and advance the application of machine learning protocols to augment molecular dynamics simulations. This important dataset will be available to researchers and educators worldwide through a web portal and co-located on the PSC's Bridges-2 system for classroom instruction and research, including reanalysis, machine learning, and data mining. Project Narrative The Anton 2 supercomputer made available at Pittsburgh Supercomputing Center through this award will enable researchers to simulate biomolecular systems orders of magnitude faster than any conventional supercomputer. This powerful resource will enable biomedical researchers to better understand the fundamental biomolecular processes of biology, leading to better ways to treat disease and improve quality of life.",Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer,10211715,R01GM116961,"['Academy', 'Area', 'Award', 'Awareness', 'Binding Proteins', 'Biological', 'Biology', 'Biomedical Research', 'Collaborations', 'Communities', 'Community Health Education', 'Creativeness', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Disease', 'Evaluation Reports', 'FAIR principles', 'Funding', 'Gifts', 'Goals', 'Grant', 'Institution', 'Instruction', 'Ion Channel', 'Knowledge', 'Letters', 'Machine Learning', 'Membrane', 'Molecular', 'National Research Council', 'Process', 'Protocols documentation', 'Publications', 'Quality of life', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Running', 'Science', 'Secure', 'Supercomputing', 'System', 'Time', 'Training Programs', 'Underrepresented Populations', 'United States National Academy of Sciences', 'United States National Institutes of Health', 'Work', 'anxious', 'archive data', 'archived data', 'base', 'broadening participation research', 'computing resources', 'cost', 'data management', 'data mining', 'data sharing', 'improved', 'innovation', 'molecular dynamics', 'next generation', 'outreach', 'outreach program', 'price lists', 'protein folding', 'service providers', 'supercomputer', 'uptake', 'web portal']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,408856
"Developing novel technologies that ensure privacy and security in biomedical data science research Data science holds the promise of enabling new pathways to discovery and can improve the understanding, prevention and treatment of complex disorders such as cancer, diabetes, substance abuse, etc., which are significantly on the rise. The promise of data science can be fully realized only when collected data can be collaboratively shared and analyzed. However, the widespread increases in healthcare data breaches due to inappropriate access as well as the increasing number of novel privacy attacks restrict institutions from sharing data. Indeed, in some cases, the results of the analysis can themselves lead to significant privacy harm. The success of the data commons depends on ensuring the maximal access to data, subject to all of the patient privacy requirements including those mandated by legislation, and all of the constraints of the organization collecting the data itself. While there are existing solutions that can solve parts of the problem, there are significant challenges in truly incorporating these into comprehensive working solutions that are usable by the biomedical research community, and new challenges brought on by modern techniques such as deep learning. The long-term goal of this research is to develop technologies that can holistically enable data sharing while respecting privacy and security considerations and to ensure that they are implemented in existing platforms that have widespread acceptance in the research community. Towards this, the objective of this project is to develop complementary solutions for risk inference, distributed learning, and access control that can enable different modalities of data sharing. The problems studied are general in nature and will evolve depending on research successes and new impediments that arise. The proposed program of research is significant since lack of access to biomedical data can lead to fragmentation of care, resulting in higher economic and social costs, and is a significant impediment to biomedical research. The project will result in open-source, freely available software tools that will be integrated into widely used data collection, cohort identification, and distributed analytics platforms. There are several ongoing collaborations that will serve as initial pilot customers to provide use cases, identify the requirements, evaluate results, and in general validate the developed solutions. Project Narrative Statement of Relevance to Public Health Being able to ensure privacy and security while enabling data sharing and analysis is critical to pave the way forward for public health research and improve our understanding of diseases. The proposed work will address the challenges that impede the use of data across all of the different modalities of data sharing. The integration into existing platforms will ensure that the developed models, tools, and solutions directly impact the research community and improve public health interventions.",Developing novel technologies that ensure privacy and security in biomedical data science research,10077318,R35GM134927,"['Address', 'Biomedical Research', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Science', 'Diabetes Mellitus', 'Disease', 'Economics', 'Ensure', 'Goals', 'Healthcare', 'Institution', 'Lead', 'Learning', 'Malignant Neoplasms', 'Modality', 'Modeling', 'Modernization', 'Nature', 'Pathway interactions', 'Prevention', 'Privacy', 'Public Health', 'Research', 'Risk', 'Security', 'Software Tools', 'Statutes and Laws', 'Substance abuse problem', 'Techniques', 'Technology', 'Work', 'biomedical data science', 'care fragmentation', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'new technology', 'novel', 'open source', 'patient privacy', 'programs', 'public health intervention', 'public health research', 'social', 'success', 'tool']",NIGMS,RUTGERS THE STATE UNIV OF NJ NEWARK,R35,2021,383279
"Experimentally guided modeling and simulation for cholera dynamics Project Summary/Abstract Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), remains a global pandemic at present. Quantitative research is urgently needed to clarify the impacts of the current vaccination campaign on the pandemic evolution and economic growth, and to guide future policy development. The overall objective of this proposal is to establish a new computational modeling framework for an investigation of the COVID-19 vaccination campaign in the US, and to incorporate real data to assess the impacts of COVID-19 vaccination on public health and the economy. To achieve this objective, the team will pursue three specific aims: (1) Modeling the transmission and spread of COVID-19 under the impact of vaccination; (2) Modeling the economic impact of COVID-19 vaccination; (3) Conducting a case study for the Chattanooga region in the state of Tennessee. The proposed research is significant because it will incorporate detailed characteristics and potential limitations of the current vaccination campaign (such as the vaccine efficacy, phased allocation schemes, public resistance to vaccination, and vaccine breakthrough due to new variants of SARS- CoV-2) into a sophisticated modeling framework, which will enable us to make more accurate forecasts on the progression and long-term evolution of the pandemic. As such, the project is expected to advance the current understanding of COVID-19 transmission and to quantify the interaction between epidemic spreading, economic growth, and disease prevention and intervention under the impact of COVID-19 vaccination, all of which are important for the control and management of the pandemic. The approach is innovative in the development of a computational framework that integrates novel mechanistic and machine learning models and that connects the epidemic and economic aspects of COVID-19. The innovation of this project is also reflected by the integration of sophisticated computational modeling, rigorous mathematical analysis, intensive numerical simulation, and detailed data validation. The project represents an interdisciplinary collaboration among an applied and computational mathematician with long-term interest in infectious disease modeling (Wang), an epidemiologist with extensive working experiences at CDC and a current member of the regional COVID-19 task force (Heath), a business and management professor with a background in public heath (Mullen), and a statistician with expertise in machine learning and biomedical data analytics (Ma). The success of this project will not only build a solid knowledge base for the complex transmission dynamics of SARS-CoV-2 and the health and economic impacts of COVID-19 vaccination, but also provide important guidelines for the government agencies and public health administrations in pandemic management and policy development. Project Narrative The proposed project is relevant to public health because a deep understanding of the COVID-19 vaccination campaign and its health and economic impacts will help to inform the pandemic management and improve the current practice in disease prevention and intervention. The mathematical and machine learning models developed in this project will improve such understanding and make new knowledge discovery. This research effort aligns with part of NIH's mission to reduce public health burdens of infectious diseases.",Experimentally guided modeling and simulation for cholera dynamics,10376956,R15GM131315,"['2019-nCoV', 'Address', 'Advisory Committees', 'Attention', 'Businesses', 'COVID-19', 'COVID-19 vaccination', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Cholera', 'Clinical Research', 'Collaborations', 'Communicable Diseases', 'Complement', 'Complex', 'Computer Models', 'Computer Simulation', 'Country', 'County', 'Coupled', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Differential Equation', 'Economic Factors', 'Economic Models', 'Economics', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evolution', 'Foundations', 'Future', 'Goals', 'Government Agencies', 'Growth', 'Guidelines', 'Health', 'Investigation', 'Joints', 'Knowledge Discovery', 'Machine Learning', 'Mathematics', 'Mission', 'Modeling', 'Persons', 'Phase', 'Policy Developments', 'Preventive Intervention', 'Public Health', 'Public Health Administration', 'Research', 'Resistance', 'Route', 'SARS-CoV-2 transmission', 'SARS-CoV-2 variant', 'Scheme', 'Schools', 'Science', 'Solid', 'Techniques', 'Tennessee', 'Theoretical Studies', 'Unemployment', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'computer framework', 'disorder prevention', 'dynamic system', 'economic impact', 'economic indicator', 'experience', 'experimental study', 'health economics', 'improved', 'infectious disease model', 'innovation', 'interdisciplinary collaboration', 'interest', 'knowledge base', 'mathematical analysis', 'mathematical learning', 'mathematical model', 'member', 'models and simulation', 'novel', 'pandemic disease', 'professor', 'programs', 'simulation', 'success', 'transmission process', 'vaccine efficacy']",NIGMS,UNIVERSITY OF TENNESSEE CHATTANOOGA,R15,2021,122580
