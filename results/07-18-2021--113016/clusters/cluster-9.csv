text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Ethical Considerations for Language Modeling within Brain-Computer Interfaces Project Summary Machine learning (ML) and Natural Language Processing (NLP) have the potential to transform communication for patients with neurodegenerative disease through personalized and real-time augmentative and alternative communication (AAC) devices. Individuals with severe communication impairments who can no longer control their daily conversations or participate in previous life roles want AAC devices. And they want them to work – to be reliable, effective, and fast. ML and NLP are emerging as promising tools to bridge current technology and next generation devices for individuals with the most severe speech and physical impairments, like the RSVP Keyboard™, a brain-computer interface (BCI) being developed by the parent grant. BCI systems for communication are referred to as AAC-BCIs. NLP efforts to combine large public data sets with private data sets, such as personal email messages, promise to give individuals with communication impairments their own personalized language models, models that are sufficiently robust to get closer to real-time communication. The focus on getting AAC-BCIs to work with machine learning, however, has led to a critical oversight in the field: an inadequate understanding of why individuals want next-generation devices and what trade-offs they are willing to make for faster and more personalized communication. The turn to ML brings this oversight into sharp relief. Individuals should provide input about the data sets used to construct their personal language models, but this raises important ethical questions about what individuals value, how they understand their identity, and what trade-offs they are willing to make relative to their personalized communication data. The goal of this supplement is to fill this gap in understanding so that researchers can implement ML into next generation AAC-BCI systems in a way that is sensitive to the ethical concerns of future users. There are four components to this ethics supplement: (1) to design a toolbox of ethics vignettes tailored to ethical concerns raised by both BCI communication and ML; (2) to administer monthly vignette-based online ethics surveys to individuals with severe communication impairments due to motor neuron disease (e.g., ALS) (n=25) or movement disorders (e.g., Parkinson's disease) (n=25); (3) to conduct semi-structured vignette-based interviews with individuals with pre- clinical or mild communication impairment due to motor neuron disease (n=10) or movement disorder (n=10). Components (2) and (3) will employ an iterative, parallel mixed-method approach. Trends in Likert-style online responses to ethics vignettes in the severe communication impairment cohort will be used to inform and modify the semi-structured interview prompts asked of the pre-clinical or mild impairment cohort. In parallel, themes emerging from direct content analysis of interviews will be used to refine online survey questions. Results of this iterative, mix-methods approach will be used (4) to outline a framework of core ethical domains and preliminary tools (vignettes and discussion prompts) that AAC-BCI researchers can use to assess ethical concerns while developing and iteratively refining communication technology for personalized language models. Project Narrative The populations of US citizens with severe speech and physical impairments secondary to neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies. Bioethical issues about privacy, agency and identity must be included in technology development and implementation as the parent grant implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Ethical Considerations for Language Modeling within Brain-Computer Interfaces,9929337,R01DC009834,"['Address', 'Administrative Supplement', 'Affect', 'Attention', 'Attitude', 'Augmentative and Alternative Communication', 'Award', 'Bioethical Issues', 'Bioethics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Electronic Mail', 'Encapsulated', 'Engineering', 'Ensure', 'Ethical Analysis', 'Ethical Issues', 'Ethics', 'Foundations', 'Future', 'Goals', 'Home environment', 'Impairment', 'Individual', 'Informed Consent', 'Interview', 'Language', 'Letters', 'Life', 'Link', 'Literature', 'Locked-In Syndrome', 'Machine Learning', 'Medical', 'Medical Technology', 'Methods', 'Modeling', 'Monkeys', 'Motor Neuron Disease', 'Movement', 'Movement Disorders', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Oregon', 'Outcome', 'Parents', 'Parkinson Disease', 'Participant', 'Patient advocacy', 'Patients', 'Population', 'Privacy', 'Privatization', 'Public Health', 'Reporting', 'Research Personnel', 'Review Literature', 'Role', 'Secondary to', 'Self-Help Devices', 'Source', 'Speech', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Voice', 'Work', 'advocacy organizations', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'cohort', 'communication device', 'computer science', 'design', 'expectation', 'informant', 'neurophysiology', 'next generation', 'novel', 'parent grant', 'pre-clinical', 'recruit', 'research and development', 'response', 'signal processing', 'skills', 'spelling', 'technology development', 'technology validation', 'tool', 'trend', 'uptake']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,153834,0.038240370463004825
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9619075,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,318386,0.05039807123948038
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. n/a",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,9916239,R01DC018446,"['Acoustics', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Area', 'Artificial Intelligence', 'Basic Science', 'Behavior', 'Behavioral', 'Birds', 'Brain', 'Cell Nucleus', 'Characteristics', 'Clinical Research', 'Clinical assessments', 'Communication', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computer Interface', 'Computer software', 'Computers', 'Course Content', 'Data', 'Data Science', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Educational Materials', 'Educational workshop', 'Effectiveness', 'Electrodes', 'Engineering', 'Evaluation', 'Feedback', 'Finches', 'Future', 'Generations', 'Goals', 'High School Outreach', 'High School Student', 'Human', 'Implant', 'Individual', 'Infrastructure', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Learning Module', 'Limb Prosthesis', 'Limb structure', 'Limes', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neurodegenerative Disorders', 'Neurosciences', 'Outcome Measure', 'Output', 'Patients', 'Performance', 'Play', 'Prevention', 'Principal Investigator', 'Production', 'Prosthesis', 'Quadriplegia', 'Recording of previous events', 'Research', 'Robot', 'Role', 'Running', 'Self-Help Devices', 'Signal Transduction', 'Songbirds', 'Space Models', 'Speech', 'Speech Development', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Translating', 'Translations', 'Upper Extremity', 'Voice', 'Work', 'auditory feedback', 'base', 'bird song', 'brain computer interface', 'brain machine interface', 'data sharing', 'design', 'functional electrical stimulation', 'functional restoration', 'graduate student', 'hackathon', 'high school', 'human subject', 'improved', 'machine learning algorithm', 'meetings', 'mind control', 'model development', 'motor control', 'multidisciplinary', 'neural model', 'neural prosthesis', 'neurodevelopment', 'neurophysiology', 'neurotransmission', 'nonhuman primate', 'novel', 'open source', 'operation', 'programs', 'relating to nervous system', 'repository', 'response', 'signal processing', 'success', 'undergraduate student', 'vocal learning', 'vocalization', 'web site']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,354676,0.04319417924399905
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants ﻿    DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9722203,R01DC014290,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Categories', 'Cochlear Implants', 'Comprehension', 'Development', 'Devices', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Frequencies', 'Hearing', 'Home environment', 'Individual', 'Location', 'Machine Learning', 'Maps', 'Masks', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Problem Solving', 'Quality of life', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Perception', 'Stimulus', 'Surface', 'Testing', 'Time', 'base', 'deaf', 'improved', 'microphone', 'normal hearing', 'public health relevance', 'recruit', 'response', 'simulation', 'sound', 'speech processing', 'speech recognition', 'success']",NIDCD,DUKE UNIVERSITY,R01,2019,326399,0.11768326920382259
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9623341,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,304865,0.1461926350399839
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9600692,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'automated speech recognition', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,568221,0.1339469354487025
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through “part-of-speech” tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (“which”, “what”, “that”). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis – semantics and syntax – that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9669113,R01MH115332,"['Address', 'Affective', 'Age', 'Archives', 'Artificial Intelligence', 'Canis familiaris', 'Categories', 'Classification', 'Clinical', 'Cognition', 'Collaborations', 'Communication', 'Computers', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electroencephalography', 'Felis catus', 'Genetic', 'Grain', 'Graph', 'Human', 'Image', 'Individual', 'International', 'Interview', 'Language', 'Length', 'Linguistics', 'Manuals', 'Measures', 'Mediator of activation protein', 'Metaphor', 'Methods', 'Mind', 'Morbidity - disease rate', 'Morphology', 'NIH Program Announcements', 'National Institute of Mental Health', 'Natural Language Processing', 'Outcome', 'Output', 'Patients', 'Physiological', 'Poverty', 'Production', 'Psychotic Disorders', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Series', 'Site', 'Speech', 'Sum', 'Symptoms', 'Text', 'Thinking', 'United States National Institutes of Health', 'Work', 'Yogurt', 'analytical method', 'base', 'cohort', 'data archive', 'functional disability', 'healthy volunteer', 'high risk', 'indexing', 'natural language', 'neural correlate', 'novel', 'phrases', 'relating to nervous system', 'response', 'secondary analysis', 'syntax', 'vector']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,468909,0.15889817172324472
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,9835650,F32DC018205,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Aphasia', 'Auditory', 'Auditory Perception', 'Auditory area', 'Behavioral', 'Brain', 'Brain region', 'Cognition', 'Communication', 'Data', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Judgment', 'Linguistics', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mind', 'Music', 'Noise', 'Participant', 'Pathway interactions', 'Perception', 'Performance', 'Periodicity', 'Process', 'Psychophysics', 'Records', 'Research', 'Research Personnel', 'Role', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speech Perception', 'Stimulus', 'Structure', 'System', 'Testing', 'Work', 'auditory processing', 'autism spectrum disorder', 'career', 'cognitive neuroscience', 'experimental study', 'insight', 'neuroimaging', 'neuromechanism', 'non-invasive imaging', 'operation', 'programs', 'relating to nervous system', 'sound', 'spectral energy', 'speech processing']",NIDCD,NEW YORK UNIVERSITY,F32,2019,60854,0.1122818330779242
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9771334,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2019,186473,0.07498142798001135
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9719822,K24DC016312,"['3-Dimensional', 'Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'machine learning algorithm', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual', 'virtual vocal tract']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2019,189841,0.126364951711706
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,9720522,K01DC017751,"['Acoustics', 'Address', 'Age', 'Area', 'Auditory', 'Behavior', 'Biomechanics', 'Categories', 'Characteristics', 'Clinical', 'Communication', 'Coupling', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dysphonia', 'Endoscopes', 'Evaluation', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Knowledge', 'Larynx', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mining', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paralysed', 'Patients', 'Physics', 'Physiological', 'Prevention', 'Production', 'Protocols documentation', 'Research', 'Series', 'Severities', 'Source', 'Spastic Dysphonias', 'Speech', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tremor', 'Visual', 'Voice', 'Voice Disorders', 'Voice Disturbances', 'Voice Quality', 'base', 'clinical application', 'clinical development', 'clinical practice', 'clinically relevant', 'cohort', 'flexibility', 'image processing', 'imaging approach', 'improved', 'innovation', 'kinematics', 'sex', 'temporal measurement', 'time use', 'tool', 'treatment strategy', 'vibration', 'vocal cord', 'vocalization']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2019,137795,0.10675608348367202
"Neural Predictors of Language Outcomes in Young Children with Cochlear Implants Impressive advances in cochlear implant (CI) technology in recent years have placed within our grasp the possibility of developing spoken language. However, one remaining question is why CI children as a group still perform below their normal-hearing peers and why performance varies across individuals. In searching for the sources of language development variability in young CI children, our proposed study will also seek to construct clinically useful models that capitalize on pre-surgical neural and behavioral measures for predicting post-surgical language development outcomes at the individual level. At the Lurie Children's Hospital of Chicago, we have collected pre-surgical neural and behavioral measures and post-surgical speech outcome data from about 130 (70 prospectively and 60 retrospectively) subjects over the past five years. We also conducted a preliminary study that demonstrates that individual patients can be classified into better or poorer language improvers six months post-surgery by a machine-learning algorithm that makes predictions based on neuroanatomical measures established pre-surgery. Our proposed study will seek to extend this preliminary research by: (1) continuing data collection and analyzing a larger set of neural measures and outcome data up to two years post-surgery, and (2) testing the generalizability of the predictive models built in Chicago to CI patients of similar characteristics at the Mayo Clinic and the University of Michigan in order to evaluate the models' broader clinical utility. Our studies will be constructed to test two competing hypotheses. The neural preservation hypothesis postulates that brain regions that are unaffected by hearing loss contribute most to language development outcomes, and that they most likely encompass auditory association areas and cognitive brain regions. The neural cycling hypothesis argues that post-surgical language development relies on the recovery of the brain regions that are most affected by hearing loss, most likely in the primary auditory cortical regions. If successful, our predictive models could immediately be deployed to augment current clinical practice, because they concern patient outcome at the individual level. Ultimately, our predictive information will allow clinicians and parents to plan more carefully for post-surgical therapy and to identify personalized management strategies for individual children. Our study directly addresses Priority Area 3 in Hearing and Balance Research of the latest NIDCD Strategic Plan.     Although cochlear implants have allowed better spoken language development in early-deafened children, the language and cognitive abilities of these children continue to lag behind those of their normal-hearing peers. The proposed study will seek to use pre-surgical neural and behavioral measures to predict post-surgical language outcomes in young children who have received a CI in order to assist in better post-surgical planning and the optimization of therapy.    ",Neural Predictors of Language Outcomes in Young Children with Cochlear Implants,9733185,R21DC016069,"['4 year old', 'Address', 'Adult', 'Affect', 'Anatomy', 'Area', 'Auditory', 'Auditory area', 'Basic Science', 'Brain', 'Brain region', 'Characteristics', 'Chicago', 'Child', 'Child Language', 'Classification', 'Clinic', 'Clinical', 'Cochlear Implants', 'Cochlear implant procedure', 'Cognitive', 'Data', 'Data Analyses', 'Data Collection', 'Equilibrium', 'Fiber', 'Funding', 'Goals', 'Hearing', 'Individual', 'Language', 'Language Development', 'Machine Learning', 'Measures', 'Michigan', 'Modeling', 'Multicenter Trials', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Parents', 'Patient-Focused Outcomes', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Population', 'Recording of previous events', 'Recovery', 'Recycling', 'Research', 'Rest', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Speech', 'Strategic Planning', 'Superior temporal gyrus', 'Surgical Management', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Work', 'auditory deprivation', 'auditory pathway', 'base', 'behavior measurement', 'clinical practice', 'clinical research site', 'cognitive ability', 'deaf', 'grasp', 'hearing impairment', 'high risk', 'improved', 'individual patient', 'language outcome', 'machine learning algorithm', 'neural model', 'normal hearing', 'outcome prediction', 'pediatric patients', 'peer', 'personalized management', 'predictive modeling', 'preservation', 'programs', 'prospective', 'relating to nervous system', 'success', 'surgery outcome', 'treatment optimization']",NIDCD,LURIE CHILDREN'S HOSPITAL OF CHICAGO,R21,2019,173098,0.056335825956527405
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9738055,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,303944,-0.00952922417876545
"Structural and functional connectivity markers of developmental speech and language disorders ABSTRACT Developmental speech and language disorders affect an estimated 15% of children and have lifelong impacts on social and emotional development and employment. Two common neurodevelopmental disorders are developmental language disorder (DLD; also called specific language impairment) and developmental stuttering, affecting 7% and 5% of children respectively. Despite their prevalence and immense impact, little is known of the neural causes, correlates, and consequences of these common neurodevelopmental disorders; thus, effective treatment remains elusive. In the proposed project, we will study the neural underpinnings of these disorders using magnetic resonance imaging (MRI) to study structural and functional neural connectivity. Previous studies of connectivity in these populations are limited and show little consensus, likely due in part to small sample sizes. Theoretical accounts of both disorders implicate dysfunctional neural circuits through the basal ganglia. In the current proposal, we will test and compare the structural and functional integrity of neural pathways in large cohorts of people with DLD (N=80) and people who stutter (PWS; N=80) and compare them with similar data obtained in age- and sex-matched control groups of people with typical development (N=160). First, we will assess connectivity in speech/language-specific networks, using diffusion data to assess structural connectivity and resting-state data to assess functional connectivity. Results will indicate abnormalities in connectivity in large cohorts of PWS and people with DLD. In each disorder, we will also determine connectivity contributions to individual differences in behavior. This will reveal how different connectivity patterns are correlated to differences in severity along relevant dimensions (e.g., fluency, language measures), ideally resulting in neural correlates of the disorders. Finally, we will evaluate whole-brain functional connectivity differences between each disorder group and its matched control group using data-driven machine learning approaches. Results will indicate patterns of neural activity that differentiate these disorders from controls. The outcome of this proposal will be the characterization of underlying network differences in these populations, which will ideally lead to the development of targeted behavioral and neuro-modulatory treatments of these multifaceted and pervasive disorders. Research and training will take place at the University of Oxford, an ideal environment in which to pursue this line of research. The applicant will be mentored by world-leading researchers with the knowledge needed to guide him in this work, including expertise in the neural bases of developmental speech and language disorders, cutting-edge methodology in neuroimaging, and machine learning. Achieving these aims will illuminate the neural correlates of these speech and language disorders as well as prepare the applicant for an independent research career in this area. PROJECT NARRATIVE For a surprisingly large number of children, as many as 15%, speech and language development does not go smoothly and results in disorders such as stuttering or language delay. We wish to understand more about the causes of these common disorders and will assess whether the brain networks involved in speech and language development are impaired in people with developmental language disorder and stuttering. Using large existing neuroimaging datasets obtained in these disorders will allow us to address important questions about the causes and consequences of these developmental disorders.",Structural and functional connectivity markers of developmental speech and language disorders,9757857,F32DC017637,"['Address', 'Adolescent', 'Adult', 'Affect', 'Age', 'Area', 'Auditory', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Cerebral cortex', 'Child', 'Classification', 'Clinical', 'Consensus', 'Control Groups', 'Corpus striatum structure', 'Data', 'Data Set', 'Development', 'Developmental Stuttering', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Economics', 'Emotional', 'Employment', 'Environment', 'Event', 'Functional Imaging', 'Future', 'Heterogeneity', 'Image', 'Impairment', 'Individual', 'Individual Differences', 'Inferior frontal gyrus', 'Investigation', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Length', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentors', 'Methodology', 'Motor', 'Network-based', 'Neural Pathways', 'Neurodevelopmental Disorder', 'Neurophysiology - biologic function', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Pattern', 'Population', 'Prevalence', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Rest', 'Sample Size', 'Scanning', 'Semantics', 'Severities', 'Speech', 'Speech Development', 'Speech Disorders', 'Structure', 'Stuttering', 'Superior temporal gyrus', 'Testing', 'Universities', 'Work', 'base', 'career', 'caudate nucleus', 'cohort', 'developmental disease', 'disorder control', 'effective therapy', 'interest', 'language impairment', 'motor control', 'neural circuit', 'neural correlate', 'neural patterning', 'neuroimaging', 'neuroregulation', 'putamen', 'relating to nervous system', 'sex', 'social', 'specific language impairment', 'standardize measure']",NIDCD,UNIVERSITY OF OXFORD,F32,2019,65354,0.07706456746166097
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9829606,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2019,34593,0.11643780738843257
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9660548,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2019,773968,0.11643780738843257
"Decoding the neural time-course of spoken word recognition Project Summary  Word recognition is crucial not only for comprehending spoken language but for mapping spoken words onto text in reading. Individuals with language and reading deficits (e.g., Specific Language Impairment, Dyslexia, Autism, which together affect up to 16% of children) have been shown to have deficits in word recognition, making it crucial to understand this process. A hallmark of word recognition is that listeners activate neural representations of multiple candidate words that are consistent with the early acoustic input, and these candidates compete for recognition as they unfold in real-time.  The overall goal of this proposal is to capitalize on recent developments in multivariate and machine- learning techniques for analyzing signals obtained from the human brain to measure the real-time unfolding of spoken word recognition. Although these techniques have been most widely used with fMRI data, we propose to extend them to EEG data because EEG is easily used with children and clinical populations, and provides access to the time-course of word recognition, thereby revealing underlying cognitive mechanisms of word recognition, such as lexical competition. Our preliminary findings using this EEG-based paradigm have demonstrated that we can decode the recognition of a specific word (among a set of 8-12 alternatives) at each msec time-step after stimulus onset. The method is sensitive to partial activation of competing words that share some phonological features with the target word, thereby revealing the dynamics of lexical competition as the word-recognition system settles on the final target.  Our objectives are to conduct a series of small-scale experiments that achieve three aims. First, we develop and optimize the method with adults (e.g., the experimental procedure and computational implementation). Second, we validate the method with adults by measuring its test/re-test reliability, comparing its estimates of word recognition with traditional behavioral paradigms, and examining how lexical status, and semantic and orthographic expectations shape lexical competition revealed by the EEG measure. This will yield a new, non-invasive, and highly reliable method suitable for assessing spoken word recognition in adults, children, and special populations. Third, we will preliminarily extend the method to children to pave the way for future developmental studies. Taken together, accomplishing these three aims would provide an innovative and powerful tool for assessing a crucial component of language processing in a wide variety of typical and atypical populations. Project Narrative The proposed research will impact public health by establishing a new EEG-based paradigm for understanding how listeners recognize spoken words. Word recognition is crucial not only for comprehending spoken language but for mapping spoken words onto text in reading. Individuals with language and reading deficits (e.g., Specific Language Impairment, Dyslexia, Autism, which together affect up to 16% of children) have been shown to have deficits in word recognition, making it crucial to understand this process. A hallmark of word recognition is that listeners activate neural representations of multiple candidate words that are consistent with the early acoustic input, and these candidates compete for recognition as they unfold in real-time. Our project will develop and optimize a new method in which machine learning tools are used to decode EEG-based neural signals to characterize the time-course of competition. Such a method offers the prospect of a diagnostic tool to identify young children who are at risk for communication disorders.",Decoding the neural time-course of spoken word recognition,9650473,R21DC017596,"['Acoustics', 'Address', 'Adolescence', 'Adult', 'Affect', 'Behavioral', 'Behavioral Paradigm', 'Brain', 'Candy', 'Child', 'Childhood', 'Clinical', 'Cochlear Implants', 'Cognitive', 'Communication impairment', 'Complement', 'Data', 'Development', 'Diagnostic', 'Dyslexia', 'Electrocorticogram', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hearing', 'Human', 'Impairment', 'Implanted Electrodes', 'Individual', 'Instruction', 'Language', 'Language Development Disorders', 'Language Disorders', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Orthography', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Procedures', 'Process', 'Public Health', 'Reading', 'Research', 'Risk', 'Semantics', 'Series', 'Shapes', 'Signal Transduction', 'Standardization', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Visual', 'Visual attention', 'attentional control', 'autism spectrum disorder', 'base', 'behavior measurement', 'behavioral response', 'expectation', 'experimental study', 'indexing', 'innovation', 'insight', 'language processing', 'lexical', 'lexical processing', 'millisecond', 'named group', 'neurotransmission', 'oculomotor', 'phonology', 'reading difficulties', 'relating to nervous system', 'response', 'specific language impairment', 'temporal measurement', 'tool']",NIDCD,"HASKINS LABORATORIES, INC.",R21,2019,277714,0.024727355218278145
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many evidence-based treatments for substance abuse are “talk based” therapies, such as motivational interviewing (MI), but the existing research-based methodology for evaluating counseling quality is to record sessions and use human rating teams to evaluate them. However, using humans as the assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling sessions, provide automatic and intuitive quality scores, and summarize these in actionable feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous NIH-funded research laid a computational foundation for generating MI quality metrics from speech and language features in MI sessions, and led to a prototype of a clinical software support tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical workflows, assessing usability, and initial validation of machine learning of MI fidelity measures in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase II will focus on robust validation of the speech and language technologies underlying the CORE-MI tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability, usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence of increased client retention. The successful execution of this project will break the reliance on human judgment for providing performance-based feedback to MI and will massively expand the capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling interventions, such as motivational interviewing. There are currently no methods for evaluating the quality of such counseling interventions in the real world to support training, supervision, and quality assurance. Building on an existing prototype, Lyssn.io – a technology start-up focused on scalable and cost-efficient human-centered technologies – will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9741887,R44DA046243,"['Adherence', 'Administrator', 'Adoption', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Assessment tool', 'Behavior Therapy', 'Behavioral', 'Benchmarking', 'Client', 'Clinic', 'Clinical', 'Code', 'Communities', 'Computer software', 'Consumption', 'Counseling', 'Dependence', 'Development', 'E-learning', 'Enhancement Technology', 'Environment', 'Evaluation', 'Evidence based treatment', 'Feasibility Studies', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Technology', 'Human', 'Intervention', 'Intuition', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'National Institute of Drug Abuse', 'Needs Assessment', 'Online Systems', 'Opioid', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Professional counselor', 'Protocols documentation', 'Provider', 'Psychology', 'Psychotherapy', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Speech', 'Stream', 'Substance Use Disorder', 'Substance abuse problem', 'Suicide', 'Supervision', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Validation', 'Work', 'addiction', 'automated speech recognition', 'automobile accident', 'base', 'clinical practice', 'cloud based', 'community setting', 'cost', 'cost efficient', 'dashboard', 'design', 'evidence base', 'experience', 'gun homicide', 'implementation research', 'improved', 'innovation', 'motivational enhancement therapy', 'novel', 'opioid abuse', 'opioid treatment program', 'overdose death', 'prediction algorithm', 'protocol development', 'prototype', 'quality assurance', 'research and development', 'signal processing', 'skills', 'sound', 'speech processing', 'substance abuse treatment', 'support tools', 'technological innovation', 'tool', 'tool development', 'treatment services', 'usability', 'user centered design', 'virtual', 'visual feedback']",NIDA,"LYSSN.IO, INC.",R44,2019,553403,0.06328625279528656
"Using Speech Acoustics to Reveal Motor Disruptions in Psychosis Project summary The goal of this project is to investigate the feasibility of using speech acoustics as a clinical biomarker in individuals at clinical high risk (CHR) for developing psychosis. There is evidence that disruptions to cortico-cerebellar circuits in individuals experiencing attenuated psychosis symptoms impact motor control of the face and limbs. This proposal would be the first study to examine whether these motor disruptions in high-risk populations also affect the complex motor control required for speech. In Aim 1 an instrumental approach will be used to investigate the acoustic correlates of psychosis risk. Specifically, speech data will be collected to investigate fine-grained acoustic properties of vowels and consonants in simple repetition tasks as well as during more naturalistic conversational speech. The speech of CHR young adults will be compared to age-matched healthy controls to discover if there are group differences in the speech acoustics that allow us to classify speech samples into healthy and clinical groups. To enable fast, reliable analysis, machine learning-based algorithms will be used to measure the acoustics speech properties of interest. In Aim 2, the speech properties measured in Aim 1 will be compared to other behavioral measures, in order to discover if they correlate with several measures of cerebellar dysfunction (posture control, procedural learning, and motor timing) that are known to occur in CHR individuals. These measures will provide convergent validity for these novel speech measures. Cognitive capabilities which are related and unrelated to speech and motor control will also be assessed, to provide specificity and divergent validity to these measures. In Aim 3, the links between speech features and changes in symptom severity will be assessed at two time points, connecting changes in speech motor control to longitudinal changes in the progression of the symptoms over 12 months. These investigations may reveal speech as a novel and easily-collected biomarker enabling early detection of psychosis risk. Project narrative The goal of this proposal is to determine whether speech patterns can signal vulnerability to psychotic disorders such as schizophrenia. Speech samples will be collected from high-risk and matched healthy control participants in order to: determine if there are abnormalities in the acoustics of vowels and consonants; evaluate if these properties map on to dysfunction of the cerebellum (a brain region impacted in the development of psychosis that also plays a role in speech motor control); and relate these properties to symptom severity and illness progression. This study will lay the groundwork for the use of speech as an inexpensive, non-invasive, and mechanistically-relevant metric that will ultimately support earlier identification and facilitate timely treatment.",Using Speech Acoustics to Reveal Motor Disruptions in Psychosis,9746454,R21MH119677,"['Acoustics', 'Address', 'Affect', 'Age', 'Algorithms', 'Articulators', 'Attenuated', 'Behavior', 'Behavioral', 'Biological Markers', 'Brain region', 'Cerebellar Diseases', 'Cerebellum', 'Clinical', 'Cognitive', 'Complex', 'Computers', 'Control Groups', 'Cueing for speech', 'Data', 'Development', 'Diagnosis', 'Dyskinetic syndrome', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Ensure', 'Equilibrium', 'Etiology', 'Face', 'Fingers', 'Functional disorder', 'Goals', 'Grain', 'Individual', 'Intervention', 'Interview', 'Investigation', 'Larynx', 'Learning', 'Limb structure', 'Linguistics', 'Link', 'Lip structure', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Motor', 'Movement', 'Musculoskeletal Equilibrium', 'National Institute of Mental Health', 'Neurologic', 'Participant', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Posture', 'Process', 'Production', 'Property', 'Psychotic Disorders', 'Research', 'Research Personnel', 'Risk', 'Role', 'Roter', 'Sampling', 'Schizophrenia', 'Scientist', 'Sensory', 'Severities', 'Severity of illness', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Sound', 'Structure', 'Symptoms', 'System', 'Testing', 'Time', 'Tongue', 'Variant', 'Youth', 'base', 'behavior measurement', 'clinical biomarkers', 'clinical predictors', 'experience', 'high risk', 'high risk population', 'improved', 'indexing', 'individualized medicine', 'interest', 'motor control', 'motor deficit', 'motor disorder', 'motor learning', 'novel', 'novel marker', 'potential biomarker', 'relating to nervous system', 'sensory integration', 'tool', 'vocal control', 'young adult']",NIMH,NORTHWESTERN UNIVERSITY,R21,2019,239000,0.14054191523292586
"Circuit Dynamics for encoding and remembering sequence of events We experience the world as a continuous sequence of events, but we remember the events as segmented episodes (e.g., my sister’s wedding). During encoding, we associate a sequence of relevant events and segment deviant events. At retrieval, episodic memory utilizes the encoded associations to replay the flow of events. The encoded associations lead to remembering the sequence of events that occurred within an episode better than the flow of events across segments. The hippocampus and the prefrontal cortices (PFC) are essential parts of the neural circuit for segmenting, linking, and retrieving memories of associated events. This proposal aims to identify neural dynamics in the hippocampus-PFC circuit that support encoding a naturalistic flow of events, i.e., sequences of words. We will determine these neural dynamics using intracranial encephalography (iEEG) acquired from the hippocampus and PFC of epileptic patients, who have electrodes implemented for pre-surgical seizure monitoring. I will model associations of words using Natural Language Processing algorithms, and I will combine the extracted features with advanced data analysis techniques including multivariate pattern analysis to determine neural dynamics engaged during encoding. I will use speech as a model with an identical flow of events in the speech stimuli across participants. This consistency will allow validation of effects across a group of participants. Algorithms for identifying features of speech are well developed and freely available. I will specifically use elements of speech that distinguish context, word dependencies, and reference points of pronouns for modeling concurrent changes in patterns of activity in the local field potential recorded from the hippocampus and PFC. The central hypotheses are that bidirectional communications between the hippocampus and PFC support the encoding of sequences of events and successful subsequent memory. To address a causal relationship between hippocampal function and event segmentation, I will study speech comprehension and speech memory in developmental amnesic patients who suffer from hippocampal damage and have trouble tracking reference points in a speech. To achieve the proposal’s goals, I will pursue training under the mentorship of Dr. Elizabeth Buffalo (University of Washington) that will focus on the advanced analysis of local field potentials. The advanced study of human iEEG data will include comparable electrophysiology signal analyses that have been applied to the recordings from the hippocampus of non-human primates in Buffalo’s memory lab. This skill-set along with ongoing mentoring from Dr. Robert Knight (University of California, Berkeley), who has an established laboratory for human iEEG, and my previous work on human iEEG will provide a vigorous methodological, conceptual, and analytical basis for developing an independent research program. The combination of iEEG, Natural Language Processing modeling, and patients’ behavioral data will provide valuable insights into the neural dynamics of effective speech encoding that predicts subsequent memory, which may inform development into therapeutic interventions. The ability to segment the world into meaningful episodes engages the human hippocampus and prefrontal cortex. Using direct electrophysiological recording from the human brain, advanced analytical techniques, Natural Language Processing models, and the behavior of patients with hippocampal lesions, this proposal will determine the neural dynamics for efficient encoding of sequences of words that predicts successful memory formation. The findings of this proposal may help inform the development of neural prosthetics for assisting patients with memory deficits.",Circuit Dynamics for encoding and remembering sequence of events,9753679,K99MH120048,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavioral', 'Bilateral', 'Brain', 'Brain region', 'Buffaloes', 'California', 'Communication', 'Comprehension', 'Computer Simulation', 'Coupling', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Electrodes', 'Electroencephalography', 'Electrophysiology (science)', 'Elements', 'Epilepsy', 'Episodic memory', 'Event', 'Frequencies', 'Goals', 'Grouping', 'Hippocampus (Brain)', 'Human', 'Impairment', 'Laboratories', 'Lead', 'Lesion', 'Link', 'Memory', 'Memory impairment', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Natural Language Processing', 'Operative Surgical Procedures', 'Participant', 'Patients', 'Pattern', 'Phase', 'Play', 'Prefrontal Cortex', 'Process', 'Research', 'Retrieval', 'Role', 'Seizures', 'Signal Transduction', 'Sister', 'Speech', 'Stimulus', 'Techniques', 'Therapeutic Intervention', 'Training', 'Universities', 'Validation', 'Washington', 'Work', 'deviant', 'encephalography', 'experience', 'indexing', 'insight', 'neural circuit', 'neural prosthesis', 'neurodevelopment', 'neuromechanism', 'nonhuman primate', 'programs', 'relating to nervous system', 'skills']",NIMH,UNIVERSITY OF WASHINGTON,K99,2019,103471,0.049043463469988426
"Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence ABSTRACT  Approximately 15% of toddlers 18-36 months of age experience late language emergence (LLE; Paul, 1992; Singleton, 2018). These late talkers (LTs) have a reduced expressive vocabulary, but average non-linguistic abilities, in the absence of overt sensory or other developmental delays (Collisson, 2016; Paul & Jennings, 1992). Upwards of 16% of LTs prospectively meet criteria for language disorder (Rescorla, 2009), while others retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). LTs are at elevated risk for lifelong language and literacy impairments that negatively impact access to academic and vocational opportunities (Singleton, 2018; Paul, 1993), and even subclinical outcomes have pervasive negative impacts (Rescorla, 2002). This project addresses questions crucial for the early diagnosis of LTs and prerequisite to the applicant’s long-term goal of establishing an independent research program on LLE, aimed ultimately at identifying variation and distribution of behavioral phenotypes to provide a foundation for more targeted interventions for LTs. This project complements prior work on LLE focused on language production by evaluating the time course of word learning and spoken word recognition in LTs and 2 control groups (age- and language-matched typically developing peers), all of whom will complete standardized assessments of cognitive -linguistic abilities. In Expt. 1, participants will train on a simple selection task using 4 novel and 4 familiar words that overlap phonologically (e.g., at onset, BUNNY-BUTTON, or offset, KITTEN-MITTEN). We will use eye tracking to estimate group and individual differences in lexical activation and competition over time. In Expt. 2, we will record EEG (electroencephalography) in a passive listening task. Participants will watch a silent video as newly-learned and familiar words from Expt. 1 are repeated. ERP (event-related potential) analyses will examine individual and group differences in responses to newly-learned vs. familiar words. We will also use machine-learning (support vector machines, SVMs) to decode EEG responses to specific words for each participant, on the logic that fidelity and coherence of responses will determine SVM classification success. Group and individual differences in eye tracking, ERP, and/or EEG-decoding measures will provide new insights into receptive abilities of LTs, and provide a basis for future work aimed at identifying LTs with greatest risk for clinical or subclinical language outcomes. The project will take place at the U. of Connecticut and Haskins Labs. The applicant and sponsors have developed a training plan for the applicant focused on further developing her (1) EEG and statistical skills, (2) knowledge base of the cognitive neuroscience of typical and atypical language development, (3) dissemination skills, and (4) understanding of principles for the responsible conduct of research, with the aim of supporting her goal to be an independent researcher in a Research-1 environment. PROJECT NARRATIVE  Approximately 15% of toddlers meet criteria for being a late talker (LT) (Paul, 1993; Singleton, 2018;) and upwards of 16% of LTs prospectively meet criteria for spoken and/or written language disorder (Rescorla, 2009) while another subset will retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). Late language emergence (LLE) is associated with lifelong clinical and subclinical weaknesses in language and literacy that negatively impact access to academic and vocational opportunities (Paul, 1993; Singleton, 2018), and even subclinical outcomes have a negative impact on vocational and higher educational choices (Rescorla, 2002). The proposed research will address questions prerequisite to the applicant's long-term goal of establishing an independent research program aimed at (1) identifying early markers of chronic impact in order to optimally allocate scarce early intervention resources and (2) identifying variation and distribution of behavioral phenotypes which will provide the foundation for more focused and targeted forms of interventions for LTs with a range of clinical and subclinical language outcomes.",Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence,9836112,F31DC018220,"['3 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Behavioral', 'Child', 'Chronic', 'Classification', 'Clinical', 'Cognitive', 'Complement', 'Complex', 'Connecticut', 'Control Groups', 'Development', 'Developmental Delay Disorders', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Endowment', 'Environment', 'Evaluation', 'Event-Related Potentials', 'Exclusion', 'Eye', 'Foundations', 'Future', 'Goals', 'Grain', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Logic', 'Machine Learning', 'Measures', 'Morphology', 'Neurobiology', 'Outcome', 'Output', 'Participant', 'Phenotype', 'Population', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Risk', 'School-Age Population', 'Sensory', 'Signal Transduction', 'Speech', 'Speed', 'Standardization', 'Testing', 'Time', 'Toddler', 'Training', 'Variant', 'Visual', 'Vocabulary', 'Word Processing', 'Work', 'base', 'clinical risk', 'cognitive neuroscience', 'experience', 'experimental study', 'high risk', 'improved outcome', 'insight', 'knowledge base', 'language impairment', 'language outcome', 'language processing', 'lexical', 'lexical processing', 'literacy', 'multimodality', 'neural correlate', 'novel', 'peer', 'phonology', 'programs', 'prospective', 'reduce symptoms', 'relating to nervous system', 'response', 'responsible research conduct', 'skills', 'social', 'sound', 'success', 'trait', 'word learning']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,F31,2019,40450,0.08049943941723342
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Contact PD/PI: Corcoran, Cheryl M  Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through “part-of-speech” tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (“which”, “what”, “that”). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Project Summary/Abstract Page 7 Contact PD/PI: Corcoran, Cheryl M Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis – semantics and syntax – that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses. Project Narrative Page 8",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9903990,R01MH115332,"['Address', 'Archives', 'Artificial Intelligence', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Electroencephalography', 'Grain', 'Graph', 'Human', 'Image', 'Individual', 'International', 'Language', 'Length', 'Linguistics', 'Manuals', 'Measures', 'Methods', 'Mind', 'Outcome', 'Patients', 'Physiological', 'Poverty', 'Production', 'Psychotic Disorders', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Schizophrenia', 'Scientist', 'Semantics', 'Site', 'Speech', 'Symptoms', 'Text', 'Thinking', 'United States National Institutes of Health', 'Work', 'analytical method', 'base', 'cohort', 'healthy volunteer', 'indexing', 'novel', 'phrases', 'response', 'secondary analysis', 'syntax']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,89238,0.15513526038051356
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9731439,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2019,39939,0.08553563436112609
"Dynamics of Vocal Tract Shaping ﻿    DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9605700,R01DC007124,"['3-Dimensional', 'Acoustics', 'Adult', 'Apraxias', 'Articulation', 'Articulators', 'Beds', 'Cardiac', 'Clinical', 'Cognitive', 'Communication', 'Communities', 'Complex', 'Coupled', 'Data', 'Deglutition Disorders', 'Development', 'Dimensions', 'Educational process of instructing', 'Engineering', 'Epiglottis structure', 'Event', 'German population', 'Gestures', 'Glossectomy', 'Goals', 'Human', 'Image', 'Imaging technology', 'Impairment', 'In Situ', 'Individual', 'International', 'Investigation', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Lateral', 'Linguistics', 'Lip structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Motion', 'Movement', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Oropharyngeal', 'Pattern', 'Pharyngeal structure', 'Play', 'Population', 'Posture', 'Production', 'Property', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Self-Help Devices', 'Series', 'Shapes', 'Sleep Apnea Syndromes', 'Speech', 'Speech Disorders', 'Speed', 'Structure', 'Surgical Flaps', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tongue', 'Traction', 'Training', 'Variant', 'Work', 'automated speech recognition', 'base', 'bioimaging', 'cohesion', 'computerized tools', 'constriction', 'dexterity', 'high dimensionality', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'instrument', 'movie', 'novel', 'outreach', 'phonology', 'post stroke', 'program dissemination', 'public health relevance', 'real-time images', 'reconstruction', 'remediation', 'shape analysis', 'sound', 'spatiotemporal', 'speech synthesis', 'technological innovation', 'theories', 'tongue apex', 'tool', 'web site']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,467515,0.12743950754434213
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'learning strategy', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,0.07721491719431109
"Statistical approaches to linguistic pattern learning PROJECT SUMMARY The long-term aim of the proposed research is to provide an account of how children learn the grammatical structure of their native language from distributional information in linguistic input, and also how these learning mechanisms may differ from those of adult learners. Distributional information is the patterning of elements in a large corpus of sentences. We hypothesize that learners acquire aspects of language structure from the statistics arising from this distributional information, such as which elements co-occur, what positions they regularly occupy in a word or sentence, and with what neighboring elements they frequently occur. Our program of research to date has focused on word segmentation (how learners determine which sound sequences form words) and on word categories (how learners determine which words form grammatical categories such as noun and verb). This work has documented the power and robustness of infants’, children’s, and adults’ ability to use complex distributional information to discover these aspects of language. We now propose to extend our research in new directions, to examine two crucial aspects of learning higher- level linguistic structure. In Part 1 we study the factors that lead learners to generalize a novel inflectional morpheme (like –s for noun plurals) to novel words. In Part 2 we examine how learners acquire phrases and simple hierarchical structure in sentences, and we ask what leads learners to prefer the types of phrase and hierarchical structures that are most common in natural languages.  In our proposed studies we test our hypotheses using miniature artificial language paradigms that afford control over the distributional cues in the input, something that is virtually impossible using only data from natural language learning. In each experiment, participants listen to utterances in a miniature language and then produce their own utterances or make judgments about their acceptability. Crucially, during the learning phase they hear only a sample of the possible utterances that are legal in the artificial language; some are withheld for use in a later post-test, to determine whether learners generalize what they have observed to novel instances (and if so, to which types of novel instances). We have developed highly successful paradigms for engaging young children in miniature language studies, and we have demonstrated important differences between child and adult language learners in these studies. We will also present children and adults with comparable learning paradigms in the visual-motor domain, to assess the time-course of the learning process and the specificity or generality of the results using auditory linguistic materials. Taken together, the results of these studies will document the key variables that enable a distributional learning mechanism to acquire the structure of words (inflectional morphology) and sentences (phrase and hierarchical structure) and will highlight the ways these mechanisms may differ over age and stimulus domain. PROJECT NARRATIVE  The study of age effects in language acquisition can help to determine the timing of optimal language input for bilingual children, deaf children, and children with communicative disabilities. Our findings on statistical learning of words, word categories, morphology, and sentence structure are also highly relevant to understanding language disorders, and our paradigms are widely used for identifying and treating children with difficulties, delays, and disorders of language acquisition. As research in language acquisition has moved from measuring stages of acquisition to understanding the processes by which languages are learned, our proposed studies will make important contributions to understanding where these processes break down and how principles of statistical learning can be used for treatment and rehabilitation.",Statistical approaches to linguistic pattern learning,9607105,R01HD037082,"['Adult', 'Age', 'Auditory', 'Categories', 'Child', 'Clinic', 'Complex', 'Cues', 'Data', 'Diagnostic tests', 'Elements', 'Goals', 'Hearing', 'Infant', 'Information Distribution', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Production', 'Productivity', 'Property', 'Rehabilitation therapy', 'Research', 'Sampling', 'Scheme', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Variant', 'Weight', 'Work', 'age effect', 'base', 'bilingualism', 'deaf', 'disability', 'experimental study', 'innovation', 'interest', 'lexical', 'natural language', 'novel', 'phrases', 'programs', 'sound', 'statistics', 'virtual', 'visual motor', 'word learning']",NICHD,GEORGETOWN UNIVERSITY,R01,2019,580188,0.1190544599038544
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9674437,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,557010,0.11309878176323111
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speaker’s voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patient’s voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patient’s voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,9740858,R01DC016621,"['Acoustics', 'Age', 'Alaryngeal Speech', 'Algorithms', 'Articular Range of Motion', 'Articulation', 'Articulators', 'Characteristics', 'Communication', 'Data', 'Data Collection', 'Development', 'Devices', 'Electrolarynx', 'Electromagnetics', 'Enhancement Technology', 'Esophageal Speech', 'Excision', 'Gender', 'Goals', 'Gold', 'Health', 'Hoarseness', 'Human', 'Impairment', 'Individual', 'Knowledge', 'Laryngeal Prosthesis', 'Laryngectomee', 'Laryngectomy', 'Larynx', 'Life', 'Lip structure', 'Machine Learning', 'Magnetism', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Mechanics', 'Mental Depression', 'Motion', 'Motor', 'Movement', 'Output', 'Participant', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Robotics', 'Science', 'Self-Help Devices', 'Speech', 'Speech Disorders', 'Speech Sound', 'Speech Synthesizers', 'Speech Therapy', 'Speed', 'Technology', 'Testing', 'Time', 'Tongue', 'Tracer', 'Tracheoesophageal Speech', 'United States', 'Voice', 'Voice Disorders', 'Voice Quality', 'Wireless Technology', 'alternative communication', 'auditory feedback', 'base', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'language training', 'machine learning algorithm', 'millisecond', 'new technology', 'novel', 'oral communication', 'preservation', 'prototype', 'social', 'social exclusion', 'sound', 'speech synthesis', 'tool', 'vibration', 'visual feedback', 'vocal cord', 'wearable device']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,618564,0.16583969782942634
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9684602,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,608110,0.08410830212603831
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9753018,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'language outcome', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2019,268205,0.13058911359208208
"Probabilistic learning in developmental language disorder Project Summary/Abstract Currently, we lack an understanding of why grammatical deficits, particularly, are the primary deficit in developmental language disorder in children, and we also lack effective clinical treatment for these deficits. Recent studies have suggested that grammar may be impaired because of its statistical properties, which may be difficult for children with this disorder to learn or attend to. However, we do not yet understand what exactly about statistical input is difficult, and therefore face a gap in determining theoretical mechanisms that can explain the profile of developmental language disorder. In the proposed research, we explore the hypothesis that manipulations in the statistical properties of linguistic input may facilitate grammar learning in children with developmental language disorder. We will test this hypothesis through the following aims: We will compare learning for deterministic versus probabilistic statistical information to determine which type is more easily learned by children with developmental language disorder. We will compare learning for dependencies at different distributions to determine if children with developmental language disorder benefit from certain statistical structures. We will address these aims through two studies: an artificial grammar learning task and a sentence processing task with eye-tracking. These studies are innovative because they use tasks from basic research on language acquisition and processing to isolate aspects of linguistic input that could improve learning in developmental language disorder. Identifying the characteristics of linguistic information that are particularly problematic or relatively helpful for children with developmental language disorder as they learn grammar can help us understand where and how grammatical deficits in this population arise. Findings will be impactful because they may lead to more effective treatment through control of variables that can be simply managed in clinical settings, e.g. how often a word appears in one grammatical structure compared with another. The training provided in this proposal will provide theoretical and technical training in intervention research, working with individuals with developmental language disorder, and using real-time technologies to study language. Project Narrative Language development plays a critical role in a child’s ultimate academic and social success. A lack of effective treatment for the most prominent deficits in children with developmental language disorder represents a critical barrier to these children reaching their full potential as adults. By identifying and distinguishing the properties of language that are particularly effortful as well as those that are relatively easy for these children to learn, we can develop our understanding of learning in this disorder, and potentially make language treatment more effective.",Probabilistic learning in developmental language disorder,9788034,F32DC017373,"['Address', 'Adult', 'Basic Science', 'Characteristics', 'Child', 'Clinical', 'Clinical Treatment', 'Communication', 'Cues', 'Dependence', 'Disease', 'Exposure to', 'Eye', 'Face', 'Impairment', 'Individual', 'Intervention Studies', 'Laboratories', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Outcome', 'Outcome Measure', 'Participant', 'Pattern', 'Play', 'Population', 'Process', 'Property', 'Research', 'Role', 'Science', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'clinically significant', 'design', 'educational atmosphere', 'effective intervention', 'effective therapy', 'farmer', 'improved', 'innovation', 'insight', 'language comprehension', 'language processing', 'peer', 'preservation', 'social', 'specific language impairment', 'statistics', 'success', 'theories']",NIDCD,UNIVERSITY OF ARIZONA,F32,2019,22217,0.07353731428870393
"Objectively Quantifying Speech Outcomes of Children with Cleft Palate Perceptual assessment of hypernasality is considered a critical component when evaluating the speech of children with cleft lip and/or palate (CLP). However, most speech-language pathologists (SLPs) do not receive formal training for perceptual evaluation of speech and, as a result, research shows that the subjective ratings are inherently biased to the perceiver and exhibit considerable variability. In this project, we aim to develop an artificial intelligence (AI) algorithm that automatically evaluates speech along four dimensions deemed to be critically important by the Americleft Speech Outcomes Group (ASOG), namely speech acceptability, articulation, hypernasality, and audible nasal emissions. The AI algorithm in this project is based on an existing database of speech collected as a part of an NIH-funded project to develop reliable speech outcomes by improving the reliability of perceptual ratings by training clinicians (NIDCR DE019-01235, PI: Kathy Chapman). This database contains speech samples from 125 5-7 year olds along with multiple perceptual rating for each speech sample. The clinicians participating in this study were successfully trained using a new protocol from the Americleft Speech Outcomes Group and they exhibit excellent inter-clinician reliability.  In SA1 we will develop an AI algorithm that automatically learns the relationship between a comprehensive set of speech acoustics and the average of the ASOG-trained expert ratings for each of the four perceptual dimensions. This approach is based on technology that the PIs have successfully used to evaluate dysarthric speech. Unique to these algorithms is modeling of perceptual judgments of trained experts using tools from statistical signal processing and AI. The output of the algorithms will map to a clinically- relevant scale, rather than to norm-referenced values that may or may not be meaningful. In SA2, we will evaluate the tool on new data by collecting new speech samples using a mobile app at a partner clinic using the same protocol as in the original study. Every collected sample will be further evaluated by ASOG trained clinicians. We will use this data to evaluate the accuracy of the AI model by comparing the model's predictions with the average of ASOG-trained experts. Preliminary results show promise that the proposed approach will yield a successful tool for accurately characterizing perceptual dimensions in the speech of children with CLP. These results indicate that a number of acoustic features that have been developed previously by the PIs accurately capture differences in hypernasality and articulation between the speech of three children with CLP (with varying severity). Furthermore, we show the success of our approach on a different, but related, task: objective evaluation of dysarthric speech. We show that an algorithm that automatically rates hypernasality performs on par with the judgment of human evaluators. The results of the proposed research will form the basis for a subsequent R01 proposal for the development and evaluation of a clinical tool to objectively quantify and track speech production in children with CLP. Project Narrative Perceptual assessment of the speech of children with cleft lip and/or palate is commonly used as a key clinical indicator upon which follow-on decisions are made about intervention. However, studies show that the inter- clinician reliability can be low. As an alternative, we propose a new objective outcome tool based on signal processing and artificial intelligence that automatically assesses speech acceptability, articulation, hypernasality, and audible nasal emissions directly from speech; the output of the tool is on a scale defined by the Americleft Speech Outcomes Group and can be used by clinicians to objectively measure progress.",Objectively Quantifying Speech Outcomes of Children with Cleft Palate,9765280,R21DE026252,"['7 year old', 'Acoustics', 'Age', 'Algorithms', 'American', 'Articulation', 'Artificial Intelligence', 'Behavior Therapy', 'Child', 'Cleft Palate', 'Cleft lip with or without cleft palate', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Dimensions', 'Ear', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Four-dimensional', 'Frequencies', 'Funding', 'Gold', 'Human', 'Individual', 'International', 'Intervention', 'Judgment', 'Language', 'Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'National Institute of Dental and Craniofacial Research', 'Nose', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Output', 'Pathologist', 'Perception', 'Performance', 'Population', 'Positioning Attribute', 'Production', 'Protocols documentation', 'Proxy', 'Reference Values', 'Reporting', 'Research', 'Sampling', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Utah', 'Validation', 'Validity and Reliability', 'Visit', 'Work', 'base', 'cleft lip and palate', 'clinically relevant', 'craniofacial', 'impression', 'improved outcome', 'learning algorithm', 'mobile application', 'novel', 'predictive modeling', 'signal processing', 'success', 'tool']",NIDCR,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2019,225535,0.1707581021279963
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9603758,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'deaf', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'learning ability', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2019,340010,0.1356575572872618
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9729661,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect', 'treatment optimization']",NIDCD,UNIVERSITY OF ARIZONA,R01,2019,606922,0.0996937014000996
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9613837,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Infrastructure', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2019,268961,0.10901893386261834
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9650545,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Infrastructure', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Text Messaging', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,655251,0.07816844702356515
"NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION ﻿    DESCRIPTION (provided by applicant) Speech perception is one of the most important cognitive operations performed by the human brain and is fundamentally multisensory: when conversing with someone, we use both visual information from their face and auditory information from their voice. Multisensory speech perception is especially important when the auditory component of the speech is noisy, either due to a hearing disorder or normal aging. However, much less is known about the neural computations underlying visual speech perception than about those underlying auditory speech perception. To remedy this gap in existing knowledge, we will use converging evidence from two complementary measures of brain activity, BOLD fMRI and electrocorticography (ECoG). The results of these neural recording studies will be interpreted in the context of a flexible computational model based on the emerging tenet that the brain performs multisensory integration using optimal or Bayesian inference, combining the currently available sensory information with prior experience.  In the first Aim, a Bayesian model will be constructed to explain individual differences in multisensory speech perception along three axes: subjects' ability to understand noisy audiovisual speech; subjects' susceptibility to the McGurk effect, a multisensory illusion; and the time spent fixating the mouth of a talking face.  In the second Aim, we will explore the neural encoding of visual speech using voxel-wise forward encoding models of the BOLD fMRI signal. We will develop encoding models to test 7 different theories of visual speech representation from the linguistic and computer vision literature. In the third Aim, we will use ECoG to examine the neural computations for integrating visual and auditory speech, guided by the Bayesian models developed in Aim 1. First, we will study reduced neural variability for multisensory speech predicted by our model. Second, we will study the representational space of unisensory and multisensory speech. PUBLIC HEALTH RELEVANCE: Understanding speech is one of the most important functions of the human brain. We use information from both the auditory modality (the voice of the person we are talking to) and the visual modality (the facial movements of the person we are talking to) to understand speech. We will use computational models, eye tracking, and brain imaging and recording techniques to study the organization and operation of the brain during audiovisual speech perception.",NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION,9607116,R01NS065395,"['Auditory', 'Auditory Perception', 'Bayesian Analysis', 'Bayesian Modeling', 'Behavioral', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Electrocorticogram', 'Eye', 'Eye Movements', 'Face', 'Functional Magnetic Resonance Imaging', 'Hearing problem', 'Human', 'Illusions', 'Individual', 'Individual Differences', 'Investigation', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Link', 'Literature', 'Measures', 'Mediating', 'Modality', 'Modeling', 'Movement', 'Neurons', 'Noise', 'Oral cavity', 'Perception', 'Persons', 'Population', 'Predisposition', 'Property', 'Publishing', 'Sample Size', 'Sensory', 'Signal Transduction', 'Speech', 'Speech Perception', 'Stimulus', 'Structure of superior temporal sulcus', 'Techniques', 'Testing', 'Time', 'Visual', 'Vocabulary', 'Voice', 'audiovisual speech', 'base', 'behavior measurement', 'experience', 'flexibility', 'hearing impairment', 'multisensory', 'neural model', 'normal aging', 'operation', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'sample fixation', 'speech accuracy', 'theories', 'visual information', 'visual speech']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2019,346719,0.1138101228734051
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9716468,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'learning strategy', 'longitudinal design', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2019,619763,0.06427712866281743
"Speech markers of cognitive impairment in Parkinson's disease ABSTRACT Dr. Kara Smith is a Movement Disorders neurologist at the University of Massachusetts Medical School (UMMS) whose goal is to become an independent investigator focused on early cognitive impairment in Parkinson disease (PD). Her long-term goal is to develop speech markers of cognitive impairment in PD. Cognitive impairment occurs in the majority of PD patients, leading to increased mortality and decreased quality of life. The current diagnostic tools are resource-intensive and have limited sensitivity. Treatments are often offered late in the course of cognitive decline and do not provide optimal benefit. Speech markers could improve detection, monitoring and treatment of cognitive impairment in PD. Speech markers could be monitored frequently and remotely via mobile technology, capturing sensitive, quantitative data about cognitive function in the context of patients’ daily life and in response to therapeutics. Dr. Smith’s role as a clinical movement disorders specialist ideally positions her to lead the application of advanced speech and language research to feasible, patient-oriented tools for real-life clinical practice and clinical trials. Dr. Smith has assembled an expert interdisciplinary mentorship team ideally suited for the goals of this innovative proposal. Dr. Smith and her team have previously shown that a) speech acoustic markers are associated with cognitive function in non-demented PD patients, and b) PD patients with mild cognitive impairment had linguistic deficits including pauses within utterances and grammaticality. Building on these results, Dr. Smith proposes to study speech and language more comprehensively in PD patients with and without mild cognitive impairment and controls to confirm these preliminary results and identify additional biomarkers. The aims of this study will be 1) to develop algorithms using speech acoustic markers to categorize by cognitive status, 2) to identify linguistic markers associated with mild cognitive impairment in PD, and 3) to assess on-line syntactic processing in PD subjects with mild cognitive impairment. The overall goal of the proposal is to identify speech and language markers of early cognitive dysfunction that can be further refined, validated and implemented using mobile technology into a larger scale, longitudinal R01 proposal. Further work will also address the underlying neurobiological mechanisms of these speech markers. Dr. Smith’s rigorous training plan includes a Master’s degree, linguistics and speech motor physiology courses, and experience in signal processing and speech acoustic analysis. Through her training goals, she will advance her knowledge and skills in patient-centered outcomes measures and instrument validation. She will gain experience in research leadership, presentation and dissemination of scientific work, and in grant writing, culminating in an R01 proposal. This K23 award will be critical for Dr. Smith to establish an independent career as a PD clinician-scientist at the unique intersection of speech and language science and cognitive impairment. PUBLIC HEALTH RELEVANCE: Speech markers have the potential to improve diagnosis, monitoring and treatment of cognitive impairment in Parkinson’s disease (PD). Although the majority of PD patients will develop cognitive impairment, the tools available to assess and treat this disabling complication are fraught with limitations. As a detailed and quantitative assessment tool, speech markers may increase sensitivity to early cognitive dysfunction and to changes over time compared with current measures. They may be automated and then implemented through mobile technology to increase patients’ access to cognitive symptom monitoring outside of the clinic setting. Dr. Smith’s proposed career development plan has potential to fill a major gap in PD research by making inexpensive and easy-to-use cognitive assessment tools accessible to patients in rural and international settings, and by fueling clinical trials to discover new therapeutics capable of slowing cognitive decline in PD.",Speech markers of cognitive impairment in Parkinson's disease,9666574,K23DC016656,"['Acoustics', 'Address', 'Algorithms', 'American', 'Area', 'Articulation', 'Assessment tool', 'Award', 'Biological Markers', 'Biomedical Engineering', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Cognitive Therapy', 'Cognitive deficits', 'Complication', 'Comprehension', 'Data', 'Data Analyses', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Foundations', 'Future', 'Goals', 'Grant', 'Health Services Accessibility', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Knowledge', 'Language', 'Language Disorders', 'Lead', 'Leadership', 'Life', 'Linguistics', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Massachusetts', 'Master&apos', 's Degree', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurobiology', 'Neurologist', 'Neuropsychological Tests', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Participant', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiology', 'Population', 'Positioning Attribute', 'Production', 'Proxy', 'Quality of Care', 'Quality of life', 'Research', 'Research Personnel', 'Resources', 'Role', 'Rural', 'Science', 'Scientist', 'Severities', 'Specialist', 'Speech', 'Speech Acoustics', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'Writing', 'career', 'career development', 'clinical movement disorder', 'clinical practice', 'cognitive change', 'cognitive control', 'cognitive function', 'cognitive performance', 'cognitive testing', 'common symptom', 'experience', 'handheld mobile device', 'improved', 'innovation', 'instrument', 'language processing', 'learning strategy', 'lexical retrieval', 'medical schools', 'mild cognitive impairment', 'mobile computing', 'mortality', 'motor deficit', 'neurobiological mechanism', 'non-demented', 'novel', 'novel therapeutics', 'patient oriented', 'public health relevance', 'recruit', 'response', 'screening', 'signal processing', 'skills', 'syntax', 'tool']",NIDCD,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K23,2019,188946,0.07668408995069675
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes Project Summary The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multidimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long- term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries. Project Narrative There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9911475,R01DC006859,"['Acoustics', 'Area', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Computer Simulation', 'Country', 'Custom', 'Data', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Intervention', 'Judgment', 'Language', 'Learning', 'Loudness', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Outcome', 'Outcome Measure', 'Pathologist', 'Patient Monitoring', 'Patients', 'Perception', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Technology', 'Theoretical model', 'Training', 'base', 'clinical practice', 'health disparity', 'improved', 'machine learning algorithm', 'nervous system disorder', 'novel', 'outcome prediction', 'predictive modeling', 'standard of care']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,208745,0.1528254530839814
"Optimization of Personalized Speech Synthesis Our voices are not identical, they are our identities. The human voice is a powerful signal that conveys one’s age, gender, size, ethnicity, and personality, among other attributes. Yet, until now, users of augmentative and alternative communication (AAC) devices, screen reading technologies and other text-to-speech (TTS) applications have relied on a limited set of mass-produced, generic-sounding synthetic voices. This mismatch in vocal identity impacts educational outcomes, infringes on personal safety, and hinders social integration. Conventional methods for building a synthetic voice require a voice actor to record an extensive dataset of studio-quality recordings which are used to train a computational model and generate the output voice. The process is time and labor intensive and thus inaccessible to everyday consumers let alone those with speech impairment. VocaliD Inc’s award-winning technology offers an unprecedented means to build custom crafted synthetic voices that reflect the recipient by combining his/her own residual vocalizations with recordings of a matched speaker from our crowdsourced Human Voicebank. We have discovered that even a single vowel contains enough ""vocal DNA"" to seed the personalization process. VocaliD’s custom voices sound like the recipient in age, personality and vocal identity and have the clarity of everyday talkers. Having made significant progress towards improving the intelligibility and naturalness of our custom voices under Phase II, our voices are within a few percentage points of natural human speech in terms of intelligibility and rated as highly natural sounding by unfamiliar listeners. However, several persistent issues limit the commercial potential of our current methods. First, our new methods are computationally intensive and thus cannot be utilized on current assistive communication devices. Optimization of the methods to reduce latency and thereby improve usability is critical (Aim 1). Another unintended consequence of advances in clarity and naturalness of our voices is the potential for misappropriation. To counteract this, we propose developing a multi-speaker model to create unique new voices and mask the identity of a given speech donor (Aim 2). Last, although the new models are capable of more prosodic variation, current methods rely heavily on exemplars in the training data. Our customers indicate a need and desire for greater control of subtle yet meaningful differences in prosody. (Aim 3) These additional tasks will further bolster the product and likelihood of commercial success for the AAC market and beyond. VocaliD’s breakthrough technology powers the first-ever custom synthetic voices that are made using only brief samples of recipient vocalizations combined with recordings of matched speaker(s) from our crowdsourced voicebank. This Phase II SBIR Administrative Supplement proposal addresses the challenges of creating a scalable and efficient method for achieving high quality, natural sounding, and controllable personalized voices.",Optimization of Personalized Speech Synthesis,9966587,R44DC014607,"['Acoustics', 'Address', 'Administrative Supplement', 'Age', 'Architecture', 'Augmentative and Alternative Communication', 'Award', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Custom', 'DNA', 'Data', 'Data Set', 'Ethnic Origin', 'Gender', 'Generations', 'Gestures', 'Human', 'Impairment', 'Intervention', 'Learning', 'Learning Module', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Outcome', 'Output', 'Pattern', 'Performance', 'Personality', 'Phase', 'Process', 'Quality of life', 'Reading', 'Residual state', 'Safety', 'Sampling', 'Science', 'Seeds', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speech', 'System', 'Technology', 'Text', 'Time', 'To specify', 'Training', 'Variant', 'Voice', 'Voice Quality', 'Wheelchairs', 'Woman', 'base', 'communication device', 'crowdsourcing', 'deep learning', 'digital', 'flexibility', 'improved', 'man', 'novel', 'social integration', 'sound', 'speech synthesis', 'success', 'usability', 'vocalization']",NIDCD,"VOCALID, INC.",R44,2019,601315,0.07504046648582653
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9631443,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Simulation', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'machine learning algorithm', 'nervous system disorder', 'novel', 'optimal treatments', 'outcome prediction', 'phrases', 'predictive modeling', 'recruit', 'signal processing', 'speech in noise', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,308669,0.15344620913912912
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9402599,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,318898,0.05039807123948038
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants ﻿    DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9513918,R01DC014290,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Categories', 'Cochlear Implants', 'Comprehension', 'Development', 'Devices', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Frequencies', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Individual', 'Location', 'Machine Learning', 'Maps', 'Masks', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Problem Solving', 'Quality of life', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Perception', 'Stimulus', 'Surface', 'Testing', 'Time', 'base', 'improved', 'public health relevance', 'recruit', 'response', 'simulation', 'sound', 'speech processing', 'speech recognition', 'success']",NIDCD,DUKE UNIVERSITY,R01,2018,326840,0.11768326920382259
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9390046,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,578454,0.1339469354487025
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through “part-of-speech” tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (“which”, “what”, “that”). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis – semantics and syntax – that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9435649,R01MH115332,"['Address', 'Affective', 'Age', 'Archives', 'Artificial Intelligence', 'Canis familiaris', 'Categories', 'Classification', 'Clinical', 'Cognition', 'Collaborations', 'Communication', 'Computers', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electroencephalography', 'Felis catus', 'Genetic', 'Grain', 'Graph', 'Human', 'Image', 'Individual', 'International', 'Interview', 'Language', 'Length', 'Linguistics', 'Manuals', 'Measures', 'Mediator of activation protein', 'Metaphor', 'Methods', 'Mind', 'Morbidity - disease rate', 'Morphology', 'NIH Program Announcements', 'National Institute of Mental Health', 'Natural Language Processing', 'Outcome', 'Output', 'Patient risk', 'Patients', 'Physiological', 'Poverty', 'Production', 'Psychotic Disorders', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Series', 'Site', 'Speech', 'Sum', 'Symptoms', 'Text', 'Thinking', 'United States National Institutes of Health', 'Work', 'Yogurt', 'analytical method', 'base', 'cohort', 'data archive', 'functional disability', 'healthy volunteer', 'high risk', 'indexing', 'natural language', 'neural correlate', 'novel', 'phrases', 'relating to nervous system', 'response', 'secondary analysis', 'syntax', 'vector']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2018,513989,0.15889817172324472
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9530276,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2018,221909,0.07498142798001135
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9492650,U01NS098969,"['Acoustics', 'Address', 'Adverse effects', 'Basal Ganglia', 'Clinical', 'Code', 'Cues', 'Data', 'Deep Brain Stimulation', 'Dysarthria', 'Electrophysiology (science)', 'Event', 'Goals', 'Language', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Movement', 'Movement Disorders', 'Nature', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Output', 'Parkinson Disease', 'Patients', 'Pattern', 'Performance', 'Phase', 'Production', 'Role', 'STN stimulation', 'Speech', 'Stimulus', 'Stream', 'Structure of subthalamic nucleus', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Universities', 'Voice', 'analytical method', 'base', 'cognitive neuroscience', 'gain of function', 'kinematics', 'learning strategy', 'member', 'microstimulation', 'motor symptom', 'multidisciplinary', 'nervous system disorder', 'neurophysiology', 'novel', 'novel strategies', 'predictive test', 'relating to nervous system', 'response']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2018,875182,0.1215839658242332
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,9390468,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'communication device', 'data mining', 'diagnostic accuracy', 'digital', 'experimental study', 'improved', 'improved functioning', 'innovation', 'jaw movement', 'motor impairment', 'movement analysis', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2018,686265,0.11856188213856729
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9525935,K24DC016312,"['Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual', 'virtual vocal tract']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2018,189841,0.126364951711706
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9645876,U01NS098971,"['Acoustics', 'Acute', 'Address', 'Affect', 'Animal Model', 'Aphasia', 'Apraxias', 'Architecture', 'Archives', 'Area', 'Articulation', 'Articulators', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Biomedical Engineering', 'Brain', 'Brain Mapping', 'Brain region', 'Chronic', 'Clinical', 'Cognitive', 'Communication impairment', 'Communities', 'Complex', 'Computer Simulation', 'Correlation Studies', 'Data', 'Dementia', 'Devices', 'Dimensions', 'Disease', 'Electrocorticogram', 'Electrodes', 'Engineering', 'Ethics', 'Face', 'Foundations', 'Functional disorder', 'Gestures', 'Goals', 'Human', 'Image', 'Imagery', 'Implant', 'Individual', 'Jaw', 'Knowledge', 'Language', 'Larynx', 'Learning', 'Left', 'Light', 'Linguistics', 'Lip structure', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Monitor', 'Motor Cortex', 'Movement', 'Mutism', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Neurosciences', 'Paralysed', 'Pattern', 'Physiology', 'Play', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prefrontal Cortex', 'Procedures', 'Production', 'Property', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Site', 'Social isolation', 'Speech', 'Speech Sound', 'Stroke', 'Stuttering', 'System', 'Technology', 'Time', 'Tongue', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'base', 'cognitive control', 'data sharing', 'density', 'experience', 'implantation', 'innovation', 'insight', 'kinematics', 'motor control', 'multidisciplinary', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'neurosurgery', 'novel', 'relating to nervous system', 'relational database', 'response', 'sound', 'spatiotemporal', 'synergism', 'temporal measurement', 'tool', 'trait']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,189567,0.1218349701174573
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9548753,U01NS098971,"['Acoustics', 'Acute', 'Address', 'Affect', 'Animal Model', 'Aphasia', 'Apraxias', 'Architecture', 'Archives', 'Area', 'Articulation', 'Articulators', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Biomedical Engineering', 'Brain', 'Brain Mapping', 'Brain region', 'Chronic', 'Clinical', 'Cognitive', 'Communication impairment', 'Communities', 'Complex', 'Computer Simulation', 'Correlation Studies', 'Data', 'Dementia', 'Devices', 'Dimensions', 'Disease', 'Electrocorticogram', 'Electrodes', 'Engineering', 'Ethics', 'Face', 'Foundations', 'Functional disorder', 'Gestures', 'Goals', 'Human', 'Image', 'Imagery', 'Implant', 'Individual', 'Jaw', 'Knowledge', 'Language', 'Larynx', 'Learning', 'Left', 'Light', 'Linguistics', 'Lip structure', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Monitor', 'Motor Cortex', 'Movement', 'Mutism', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Neurosciences', 'Paralysed', 'Pattern', 'Physiology', 'Play', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prefrontal Cortex', 'Procedures', 'Production', 'Property', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Site', 'Social isolation', 'Speech', 'Speech Sound', 'Stroke', 'Stuttering', 'System', 'Technology', 'Time', 'Tongue', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'base', 'cognitive control', 'data sharing', 'density', 'experience', 'implantation', 'innovation', 'insight', 'kinematics', 'motor control', 'multidisciplinary', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'neurosurgery', 'novel', 'relating to nervous system', 'relational database', 'response', 'sound', 'spatiotemporal', 'synergism', 'temporal measurement', 'tool', 'trait']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,900000,0.1218349701174573
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9522332,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Eye', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2018,666236,0.11643780738843257
"Technology-supported, measurement-based supervision for Motivational Interviewing Project​ ​Summary/Abstract Millions​ ​of​ ​Americans​ ​receive​ ​evidence-based​ ​counseling​ ​for​ ​substance​ ​use​ ​problems​ ​each​ ​year.​ ​Many evidence-based​ ​treatments​ ​for​ ​substance​ ​abuse​ ​are​ ​“talk​ ​based”​ ​therapies,​ ​such​ ​as​ ​motivational​ ​interviewing (MI),​ ​but​ ​the​ ​existing​ ​research-based​ ​methodology​ ​for​ ​evaluating​ ​counseling​ ​quality​ ​is​ ​to​ ​record​ ​sessions​ ​and use​ ​human​ ​rating​ ​teams​ ​to​ ​evaluate​ ​them.​ ​However,​ ​using​ ​humans​ ​as​ ​the​ ​assessment​ ​tool​ ​via​ ​behavioral coding​ ​is​ ​prohibitive​ ​in​ ​cost​ ​and​ ​time,​ ​can​ ​be​ ​error​ ​prone,​ ​and​ ​is​ ​virtually​ ​never​ ​used​ ​in​ ​the​ ​real​ ​world. Technology​ ​is​ ​needed​ ​that​ ​can​ ​analyze​ ​the​ ​speech​ ​patterns​ ​and​ ​spoken​ ​language​ ​of​ ​counseling​ ​sessions, provide​ ​automatic​ ​and​ ​intuitive​ ​quality​ ​scores,​ ​and​ ​summarize​ ​these​ ​in​ ​actionable​ ​feedback.​ ​Rapid, performance-based​ ​quality​ ​metrics​ ​could​ ​support​ ​training,​ ​ongoing​ ​supervision,​ ​and​ ​quality​ ​assurance​ ​for millions​ ​of​ ​evidence-based​ ​counseling​ ​sessions​ ​for​ ​substance​ ​abuse​ ​each​ ​year.  Lyssn.io​​ ​is​ ​a​ ​start-up​ ​targeting​ ​the​ ​development​ ​of​ ​implementation-focused​ ​technology​ ​to​ ​support evidence-based​ ​counseling.​ ​​ ​Our​ ​goal​ ​is​ ​to​ ​develop​ ​innovative​ ​health​ ​technology​ ​solutions​ ​that​ ​are​ ​objective, scalable,​ ​and​ ​cost​ ​efficient.​ ​​Lyssn.io​​ ​includes​ ​expertise​ ​in​ ​speech​ ​signal​ ​processing,​ ​machine​ ​learning, user-centered​ ​design,​ ​software​ ​engineering,​ ​and​ ​clinical​ ​expertise​ ​in​ ​evidence-based​ ​counseling.​ ​Previous NIH-funded​ ​research​ ​laid​ ​a​ ​computational​ ​foundation​ ​for​ ​generating​ ​MI​ ​quality​ ​metrics​ ​from​ ​speech​ ​and language​ ​features​ ​in​ ​MI​ ​sessions,​ ​and​ ​led​ ​to​ ​a​ ​prototype​ ​of​ ​a​ ​clinical​ ​software​ ​support​ ​tool,​ ​the​ ​Counselor Observer​ ​Ratings​ ​Expert​ ​for​ ​MI​ ​(CORE-MI).  The​ ​current​ ​Fast-Track​ ​SBIR​ ​proposal​ ​includes​ ​Phase​ ​I,​ ​which​ ​will​ ​focus​ ​on​ ​understanding​ ​clinical workflows,​ ​assessing​ ​usability,​ ​and​ ​initial​ ​validation​ ​of​ ​machine​ ​learning​ ​of​ ​MI​ ​fidelity​ ​measures​ ​in​ ​the​ ​opioid treatment​ ​program​ ​at​ ​Evergreen​ ​Treatment​ ​Services​ ​(ETS)​ ​clinic​ ​in​ ​Seattle,​ ​WA.​ ​Phase​ ​II​ ​will​ ​focus​ ​on​ ​robust validation​ ​of​ ​the​ ​speech​ ​and​ ​language​ ​technologies​ ​underlying​ ​the​ ​CORE-MI​ ​tool,​ ​and​ ​development​ ​of​ ​scalable supervision​ ​protocols​ ​that​ ​integrate​ ​CORE-MI​ ​supported​ ​feedback​ ​for​ ​counselors.​ ​Finally,​ ​we​ ​will​ ​conduct​ ​a quasi-experimental​ ​evaluation​ ​of​ ​CORE-MI​ ​supported​ ​supervision​ ​and​ ​training​ ​at​ ​a​ ​second​ ​ETS​ ​clinic​ ​in​ ​the Puget​ ​Sound,​ ​focusing​ ​on​ ​acceptability,​ ​usability,​ ​and​ ​adoption,​ ​the​ ​impact​ ​on​ ​supervision,​ ​improved​ ​MI​ ​fidelity and​ ​preliminary​ ​evidence​ ​of​ ​increased​ ​client​ ​retention.​ ​​ ​The​ ​successful​ ​execution​ ​of​ ​this​ ​project​ ​will​ ​break​ ​the reliance​ ​on​ ​human​ ​judgment​ ​for​ ​providing​ ​performance-based​ ​feedback​ ​to​ ​MI​ ​and​ ​will​ ​massively​ ​expand​ ​the capacity​ ​to​ ​train,​ ​supervise,​ ​and​ ​provide​ ​quality​ ​assurance​ ​in​ ​MI​ ​for​ ​substance​ ​abuse. Project​ ​Narrative Most​ ​evidence-based​ ​treatments​ ​for​ ​substance​ ​abuse​ ​are​ ​in-person​ ​psychotherapy​ ​and​ ​counseling interventions,​ ​such​ ​as​ ​motivational​ ​interviewing.​ ​There​ ​are​ ​currently​ ​no​ ​methods​ ​for​ ​evaluating​ ​the​ ​quality​ ​of such​ ​counseling​ ​interventions​ ​in​ ​the​ ​real​ ​world​ ​to​ ​support​ ​training,​ ​supervision,​ ​and​ ​quality​ ​assurance.​ ​Building on​ ​an​ ​existing​ ​prototype,​ ​​Lyssn.io​​ ​–​ ​a​ ​technology​ ​start-up​ ​focused​ ​on​ ​scalable​ ​and​ ​cost-efficient human-centered​ ​technologies​ ​–​ ​will​ ​enhance​ ​and​ ​evaluate​ ​a​ ​cloud-based,​ ​HIPAA-compliant​ ​clinical​ ​support software​ ​tool​ ​that​ ​uses​ ​automated​ ​speech​ ​recognition​ ​and​ ​machine​ ​learning​ ​in​ ​an​ ​community​ ​based​ ​opioid replacement​ ​clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9556012,R44DA046243,"['Adherence', 'Administrator', 'Adoption', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Assessment tool', 'Behavior Therapy', 'Behavioral', 'Benchmarking', 'Client', 'Clinic', 'Clinical', 'Code', 'Communities', 'Computer software', 'Counseling', 'Dependence', 'Development', 'E-learning', 'Enhancement Technology', 'Environment', 'Evaluation', 'Evidence based treatment', 'Feasibility Studies', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Guns', 'Health Insurance Portability and Accountability Act', 'Health Technology', 'Homicide', 'Human', 'Intervention', 'Intuition', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'National Institute of Drug Abuse', 'Needs Assessment', 'Online Systems', 'Opioid', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Professional counselor', 'Protocols documentation', 'Provider', 'Psychology', 'Psychotherapy', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Speech', 'Stream', 'Substance Use Disorder', 'Substance abuse problem', 'Suicide', 'Supervision', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Validation', 'Work', 'addiction', 'automobile accident', 'base', 'clinical practice', 'cloud based', 'community setting', 'cost', 'cost efficient', 'dashboard', 'design', 'evidence base', 'experience', 'implementation research', 'improved', 'innovation', 'motivational enhancement therapy', 'novel', 'opioid abuse', 'opioid treatment program', 'overdose death', 'prediction algorithm', 'protocol development', 'prototype', 'quality assurance', 'research and development', 'signal processing', 'skills', 'sound', 'speech processing', 'speech recognition', 'substance abuse treatment', 'support tools', 'technological innovation', 'tool', 'tool development', 'treatment services', 'usability', 'user centered design', 'virtual', 'visual feedback']",NIDA,"LYSSN.IO, INC.",R44,2018,146357,0.06208331945821658
"Neural Predictors of Language Outcomes in Young Children with Cochlear Implants Impressive advances in cochlear implant (CI) technology in recent years have placed within our grasp the possibility of developing spoken language. However, one remaining question is why CI children as a group still perform below their normal-hearing peers and why performance varies across individuals. In searching for the sources of language development variability in young CI children, our proposed study will also seek to construct clinically useful models that capitalize on pre-surgical neural and behavioral measures for predicting post-surgical language development outcomes at the individual level. At the Lurie Children's Hospital of Chicago, we have collected pre-surgical neural and behavioral measures and post-surgical speech outcome data from about 130 (70 prospectively and 60 retrospectively) subjects over the past five years. We also conducted a preliminary study that demonstrates that individual patients can be classified into better or poorer language improvers six months post-surgery by a machine-learning algorithm that makes predictions based on neuroanatomical measures established pre-surgery. Our proposed study will seek to extend this preliminary research by: (1) continuing data collection and analyzing a larger set of neural measures and outcome data up to two years post-surgery, and (2) testing the generalizability of the predictive models built in Chicago to CI patients of similar characteristics at the Mayo Clinic and the University of Michigan in order to evaluate the models' broader clinical utility. Our studies will be constructed to test two competing hypotheses. The neural preservation hypothesis postulates that brain regions that are unaffected by hearing loss contribute most to language development outcomes, and that they most likely encompass auditory association areas and cognitive brain regions. The neural cycling hypothesis argues that post-surgical language development relies on the recovery of the brain regions that are most affected by hearing loss, most likely in the primary auditory cortical regions. If successful, our predictive models could immediately be deployed to augment current clinical practice, because they concern patient outcome at the individual level. Ultimately, our predictive information will allow clinicians and parents to plan more carefully for post-surgical therapy and to identify personalized management strategies for individual children. Our study directly addresses Priority Area 3 in Hearing and Balance Research of the latest NIDCD Strategic Plan.     Although cochlear implants have allowed better spoken language development in early-deafened children, the language and cognitive abilities of these children continue to lag behind those of their normal-hearing peers. The proposed study will seek to use pre-surgical neural and behavioral measures to predict post-surgical language outcomes in young children who have received a CI in order to assist in better post-surgical planning and the optimization of therapy.    ",Neural Predictors of Language Outcomes in Young Children with Cochlear Implants,9445282,R21DC016069,"['4 year old', 'Address', 'Adult', 'Affect', 'Algorithms', 'Anatomy', 'Area', 'Auditory', 'Auditory area', 'Basic Science', 'Brain', 'Brain region', 'Characteristics', 'Chicago', 'Child', 'Child Language', 'Classification', 'Clinic', 'Clinical', 'Cochlear Implants', 'Cochlear implant procedure', 'Cognitive', 'Data', 'Data Analyses', 'Data Collection', 'Equilibrium', 'Fiber', 'Funding', 'Goals', 'Hearing', 'Individual', 'Language', 'Language Development', 'Machine Learning', 'Measures', 'Michigan', 'Modeling', 'Multicenter Trials', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Parents', 'Patient-Focused Outcomes', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Population', 'Recording of previous events', 'Recovery', 'Recycling', 'Research', 'Rest', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Speech', 'Strategic Planning', 'Superior temporal gyrus', 'Surgical Management', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Work', 'auditory deprivation', 'auditory pathway', 'base', 'behavior measurement', 'clinical practice', 'clinical research site', 'cognitive ability', 'grasp', 'hearing impairment', 'high risk', 'improved', 'individual patient', 'neural model', 'outcome prediction', 'pediatric patients', 'peer', 'personalized management', 'predictive modeling', 'preservation', 'programs', 'prospective', 'relating to nervous system', 'success', 'surgery outcome', 'treatment optimization']",NIDCD,LURIE CHILDREN'S HOSPITAL OF CHICAGO,R21,2018,245338,0.056335825956527405
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9612777,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2018,39939,0.08553563436112609
"Dynamics of Vocal Tract Shaping ﻿    DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9390471,R01DC007124,"['Acoustics', 'Adult', 'Apraxias', 'Articulation', 'Articulators', 'Beds', 'Cardiac', 'Clinical', 'Cognitive', 'Communication', 'Communities', 'Complex', 'Coupled', 'Data', 'Deglutition Disorders', 'Development', 'Dimensions', 'Educational process of instructing', 'Engineering', 'Epiglottis structure', 'Event', 'German population', 'Gestures', 'Glossectomy', 'Goals', 'Human', 'Image', 'Imaging technology', 'Impairment', 'In Situ', 'Individual', 'International', 'Investigation', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Lateral', 'Linguistics', 'Lip structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Motion', 'Movement', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Oropharyngeal', 'Pattern', 'Pharyngeal structure', 'Play', 'Population', 'Posture', 'Production', 'Property', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Self-Help Devices', 'Series', 'Shapes', 'Sleep Apnea Syndromes', 'Speech', 'Speech Disorders', 'Speed', 'Stroke', 'Structure', 'Surgical Flaps', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tongue', 'Traction', 'Training', 'Variant', 'Work', 'base', 'bioimaging', 'cohesion', 'computerized tools', 'constriction', 'dexterity', 'high dimensionality', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'instrument', 'movie', 'novel', 'outreach', 'phonology', 'program dissemination', 'public health relevance', 'reconstruction', 'remediation', 'shape analysis', 'sound', 'spatiotemporal', 'speech recognition', 'technological innovation', 'theories', 'tongue apex', 'tool', 'web site']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,467515,0.12743950754434213
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9443223,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auricular prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Learning', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'network architecture', 'real world application', 'segregation', 'signal processing', 'sound', 'success']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,292174,0.1461926350399839
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9461502,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,607626,0.11309878176323111
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9470863,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,606853,0.08410830212603831
"Statistical approaches to linguistic pattern learning PROJECT SUMMARY The long-term aim of the proposed research is to provide an account of how children learn the grammatical structure of their native language from distributional information in linguistic input, and also how these learning mechanisms may differ from those of adult learners. Distributional information is the patterning of elements in a large corpus of sentences. We hypothesize that learners acquire aspects of language structure from the statistics arising from this distributional information, such as which elements co-occur, what positions they regularly occupy in a word or sentence, and with what neighboring elements they frequently occur. Our program of research to date has focused on word segmentation (how learners determine which sound sequences form words) and on word categories (how learners determine which words form grammatical categories such as noun and verb). This work has documented the power and robustness of infants’, children’s, and adults’ ability to use complex distributional information to discover these aspects of language. We now propose to extend our research in new directions, to examine two crucial aspects of learning higher- level linguistic structure. In Part 1 we study the factors that lead learners to generalize a novel inflectional morpheme (like –s for noun plurals) to novel words. In Part 2 we examine how learners acquire phrases and simple hierarchical structure in sentences, and we ask what leads learners to prefer the types of phrase and hierarchical structures that are most common in natural languages.  In our proposed studies we test our hypotheses using miniature artificial language paradigms that afford control over the distributional cues in the input, something that is virtually impossible using only data from natural language learning. In each experiment, participants listen to utterances in a miniature language and then produce their own utterances or make judgments about their acceptability. Crucially, during the learning phase they hear only a sample of the possible utterances that are legal in the artificial language; some are withheld for use in a later post-test, to determine whether learners generalize what they have observed to novel instances (and if so, to which types of novel instances). We have developed highly successful paradigms for engaging young children in miniature language studies, and we have demonstrated important differences between child and adult language learners in these studies. We will also present children and adults with comparable learning paradigms in the visual-motor domain, to assess the time-course of the learning process and the specificity or generality of the results using auditory linguistic materials. Taken together, the results of these studies will document the key variables that enable a distributional learning mechanism to acquire the structure of words (inflectional morphology) and sentences (phrase and hierarchical structure) and will highlight the ways these mechanisms may differ over age and stimulus domain. PROJECT NARRATIVE  The study of age effects in language acquisition can help to determine the timing of optimal language input for bilingual children, deaf children, and children with communicative disabilities. Our findings on statistical learning of words, word categories, morphology, and sentence structure are also highly relevant to understanding language disorders, and our paradigms are widely used for identifying and treating children with difficulties, delays, and disorders of language acquisition. As research in language acquisition has moved from measuring stages of acquisition to understanding the processes by which languages are learned, our proposed studies will make important contributions to understanding where these processes break down and how principles of statistical learning can be used for treatment and rehabilitation.",Statistical approaches to linguistic pattern learning,9471944,R01HD037082,"['Adult', 'Age', 'Auditory', 'Categories', 'Child', 'Clinic', 'Complex', 'Cues', 'Data', 'Diagnostic tests', 'Elements', 'Goals', 'Hearing', 'Hearing Impaired Persons', 'Infant', 'Information Distribution', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Production', 'Productivity', 'Property', 'Rehabilitation therapy', 'Research', 'Sampling', 'Scheme', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Variant', 'Weight', 'Work', 'age effect', 'base', 'bilingualism', 'disability', 'experimental study', 'innovation', 'interest', 'lexical', 'natural language', 'novel', 'phrases', 'programs', 'sound', 'statistics', 'virtual', 'visual motor', 'word learning']",NICHD,GEORGETOWN UNIVERSITY,R01,2018,594063,0.1190544599038544
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9533881,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2018,266324,0.13058911359208208
"Verb learning and the early development of sentence comprehension DESCRIPTION (provided by applicant): Children use syntax to understand sentences and to learn verbs; this is syntactic bootstrapping. We proposed a Structure Mapping account of the origins of syntactic bootstrapping. On this account, children begin with an unlearned bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful. In the previous funding period, we tested key predictions of this account, and found strong evidence for structure-mapping. Identifying the set of nouns in sentences yields a partial representation of syntactic structure that allows toddlers to identify verbs, and to interpret novel transitive and intransitive verbs in simple sentences. The proposed research asks how syntactic bootstrapping moves beyond 'counting the nouns', scaling up to the true complexity of verbs and sentences. We focus on two data-sources: distributional learning and discourse structure. First, we propose that distributional learning creates probabilistic syntactic-semantic combinatorial knowledge about verbs. This combinatorial knowledge, also known as verb bias, permits syntactic bootstrapping, and from early in development is used online to help identify the structure and lexical content of sentences, guiding syntactic analysis. Second, we propose that a bias toward discourse continuity increases linguistic support for verb learning by allowing learners to collect evidence for arguments across nearby sentences. Verb bias guides this process, by cuing children to seek referents for missing arguments in the discourse context. To investigate these proposals we combine experiments with toddlers and preschoolers, and a computational model based on systems for automatic semantic role labeling. Experiments with children assess comprehension of familiar and invented verbs in sentences, by measuring children's visual fixations to relevant scenes or objects. Project 1 explores toddlers' encoding of syntactic-semantic combinatorial facts about verbs from listening experience. Project 2 explores toddlers' use of discourse context to guide sentence interpretation, constrained by verb bias. Project 3 asks to what extent verb bias in preschoolers changes with new distributional learning. In Project 4 we develop our computational model to investigate the same processes. Results from experiments with children constrain the features we equip the model to detect; we use the model to test the consequences of our claims for learning from corpora of natural child-directed speech. This combination of experimental and computational studies will advance scientific knowledge about how children learn their native languages, and guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how children learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy. PUBLIC HEALTH RELEVANCE: The proposed research will examine verb learning and the development of sentence comprehension, using a combination of experiments with toddlers and preschoolers, and a computational model of early sentence comprehension. Our findings should have considerable impact, for two main reasons: First, our work will shed light on how learners begin to find meaning in syntax, addressing long-standing and fundamental scientific questions about language development. Second, the findings should help us predict and understand the consequences of individual variations in the early language environment for language development: by studying how young children collect and use linguistic-distributional data about words, we can predict what kinds of data they need to make typical progress, and thus what kinds of early experiences might lead to risks for language difficulties.",Verb learning and the early development of sentence comprehension,9461567,R01HD054448,"['Address', 'Behavior', 'Child', 'Comprehension', 'Computer Simulation', 'Data', 'Data Sources', 'Detection', 'Development', 'Environment', 'Event', 'Feedback', 'Funding', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Link', 'Measures', 'Memory', 'Modeling', 'Natural Language Processing', 'Ocular Fixation', 'Participant', 'Play', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Semantics', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Uncertainty', 'Variant', 'Work', 'base', 'combinatorial', 'computer studies', 'early experience', 'expectation', 'experience', 'experimental study', 'improved', 'individual variation', 'lexical', 'novel', 'pedagogy', 'public health relevance', 'remediation', 'scale up', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2018,307933,0.08118490422238503
"Probabilistic learning in developmental language disorder Project Summary/Abstract Currently, we lack an understanding of why grammatical deficits, particularly, are the primary deficit in developmental language disorder in children, and we also lack effective clinical treatment for these deficits. Recent studies have suggested that grammar may be impaired because of its statistical properties, which may be difficult for children with this disorder to learn or attend to. However, we do not yet understand what exactly about statistical input is difficult, and therefore face a gap in determining theoretical mechanisms that can explain the profile of developmental language disorder. In the proposed research, we explore the hypothesis that manipulations in the statistical properties of linguistic input may facilitate grammar learning in children with developmental language disorder. We will test this hypothesis through the following aims: We will compare learning for deterministic versus probabilistic statistical information to determine which type is more easily learned by children with developmental language disorder. We will compare learning for dependencies at different distributions to determine if children with developmental language disorder benefit from certain statistical structures. We will address these aims through two studies: an artificial grammar learning task and a sentence processing task with eye-tracking. These studies are innovative because they use tasks from basic research on language acquisition and processing to isolate aspects of linguistic input that could improve learning in developmental language disorder. Identifying the characteristics of linguistic information that are particularly problematic or relatively helpful for children with developmental language disorder as they learn grammar can help us understand where and how grammatical deficits in this population arise. Findings will be impactful because they may lead to more effective treatment through control of variables that can be simply managed in clinical settings, e.g. how often a word appears in one grammatical structure compared with another. The training provided in this proposal will provide theoretical and technical training in intervention research, working with individuals with developmental language disorder, and using real-time technologies to study language. Project Narrative Language development plays a critical role in a child’s ultimate academic and social success. A lack of effective treatment for the most prominent deficits in children with developmental language disorder represents a critical barrier to these children reaching their full potential as adults. By identifying and distinguishing the properties of language that are particularly effortful as well as those that are relatively easy for these children to learn, we can develop our understanding of learning in this disorder, and potentially make language treatment more effective.",Probabilistic learning in developmental language disorder,9609288,F32DC017373,"['Address', 'Adult', 'Basic Science', 'Characteristics', 'Child', 'Clinical', 'Clinical Treatment', 'Communication', 'Cues', 'Dependence', 'Disease', 'Exposure to', 'Eye', 'Face', 'Impairment', 'Individual', 'Intervention Studies', 'Laboratories', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Outcome', 'Outcome Measure', 'Participant', 'Pattern', 'Play', 'Population', 'Process', 'Property', 'Research', 'Role', 'Science', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'clinically significant', 'design', 'educational atmosphere', 'effective intervention', 'effective therapy', 'farmer', 'improved', 'innovation', 'insight', 'language comprehension', 'language processing', 'peer', 'social', 'specific language impairment', 'statistics', 'success', 'theories']",NIDCD,UNIVERSITY OF ARIZONA,F32,2018,58282,0.07353731428870393
"Objectively Quantifying Speech Outcomes of Children with Cleft Palate Perceptual assessment of hypernasality is considered a critical component when evaluating the speech of children with cleft lip and/or palate (CLP). However, most speech-language pathologists (SLPs) do not receive formal training for perceptual evaluation of speech and, as a result, research shows that the subjective ratings are inherently biased to the perceiver and exhibit considerable variability. In this project, we aim to develop an artificial intelligence (AI) algorithm that automatically evaluates speech along four dimensions deemed to be critically important by the Americleft Speech Outcomes Group (ASOG), namely speech acceptability, articulation, hypernasality, and audible nasal emissions. The AI algorithm in this project is based on an existing database of speech collected as a part of an NIH-funded project to develop reliable speech outcomes by improving the reliability of perceptual ratings by training clinicians (NIDCR DE019-01235, PI: Kathy Chapman). This database contains speech samples from 125 5-7 year olds along with multiple perceptual rating for each speech sample. The clinicians participating in this study were successfully trained using a new protocol from the Americleft Speech Outcomes Group and they exhibit excellent inter-clinician reliability.  In SA1 we will develop an AI algorithm that automatically learns the relationship between a comprehensive set of speech acoustics and the average of the ASOG-trained expert ratings for each of the four perceptual dimensions. This approach is based on technology that the PIs have successfully used to evaluate dysarthric speech. Unique to these algorithms is modeling of perceptual judgments of trained experts using tools from statistical signal processing and AI. The output of the algorithms will map to a clinically- relevant scale, rather than to norm-referenced values that may or may not be meaningful. In SA2, we will evaluate the tool on new data by collecting new speech samples using a mobile app at a partner clinic using the same protocol as in the original study. Every collected sample will be further evaluated by ASOG trained clinicians. We will use this data to evaluate the accuracy of the AI model by comparing the model's predictions with the average of ASOG-trained experts. Preliminary results show promise that the proposed approach will yield a successful tool for accurately characterizing perceptual dimensions in the speech of children with CLP. These results indicate that a number of acoustic features that have been developed previously by the PIs accurately capture differences in hypernasality and articulation between the speech of three children with CLP (with varying severity). Furthermore, we show the success of our approach on a different, but related, task: objective evaluation of dysarthric speech. We show that an algorithm that automatically rates hypernasality performs on par with the judgment of human evaluators. The results of the proposed research will form the basis for a subsequent R01 proposal for the development and evaluation of a clinical tool to objectively quantify and track speech production in children with CLP. Project Narrative Perceptual assessment of the speech of children with cleft lip and/or palate is commonly used as a key clinical indicator upon which follow-on decisions are made about intervention. However, studies show that the inter- clinician reliability can be low. As an alternative, we propose a new objective outcome tool based on signal processing and artificial intelligence that automatically assesses speech acceptability, articulation, hypernasality, and audible nasal emissions directly from speech; the output of the tool is on a scale defined by the Americleft Speech Outcomes Group and can be used by clinicians to objectively measure progress.",Objectively Quantifying Speech Outcomes of Children with Cleft Palate,9601604,R21DE026252,"['7 year old', 'Acoustics', 'Age', 'Algorithms', 'American', 'Articulation', 'Artificial Intelligence', 'Behavior Therapy', 'Child', 'Cleft Lip', 'Cleft Palate', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Dimensions', 'Ear', 'Ensure', 'Environment', 'Evaluation', 'Exhibits', 'Four-dimensional', 'Frequencies', 'Funding', 'Gold', 'Human', 'Individual', 'International', 'Intervention', 'Judgment', 'Language', 'Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'National Institute of Dental and Craniofacial Research', 'Nose', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Output', 'Palate', 'Pathologist', 'Perception', 'Performance', 'Population', 'Positioning Attribute', 'Production', 'Protocols documentation', 'Proxy', 'Reference Values', 'Reporting', 'Research', 'Sampling', 'Series', 'Severities', 'Signal Transduction', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Utah', 'Validation', 'Validity and Reliability', 'Visit', 'Work', 'base', 'cleft lip and palate', 'clinically relevant', 'craniofacial', 'impression', 'improved outcome', 'mobile application', 'novel', 'predictive modeling', 'signal processing', 'success', 'tool']",NIDCR,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2018,203708,0.1707581021279963
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9379468,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2018,340010,0.1356575572872618
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9506574,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect', 'treatment optimization']",NIDCD,UNIVERSITY OF ARIZONA,R01,2018,606922,0.0996937014000996
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9393259,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2018,268713,0.10901893386261834
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9432500,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,651980,0.07816844702356515
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9432492,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Simulation', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Machine Learning', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'nervous system disorder', 'novel', 'optimal treatments', 'outcome prediction', 'phrases', 'predictive modeling', 'recruit', 'signal processing', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,310124,0.15344620913912912
"NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION ﻿    DESCRIPTION (provided by applicant) Speech perception is one of the most important cognitive operations performed by the human brain and is fundamentally multisensory: when conversing with someone, we use both visual information from their face and auditory information from their voice. Multisensory speech perception is especially important when the auditory component of the speech is noisy, either due to a hearing disorder or normal aging. However, much less is known about the neural computations underlying visual speech perception than about those underlying auditory speech perception. To remedy this gap in existing knowledge, we will use converging evidence from two complementary measures of brain activity, BOLD fMRI and electrocorticography (ECoG). The results of these neural recording studies will be interpreted in the context of a flexible computational model based on the emerging tenet that the brain performs multisensory integration using optimal or Bayesian inference, combining the currently available sensory information with prior experience.  In the first Aim, a Bayesian model will be constructed to explain individual differences in multisensory speech perception along three axes: subjects' ability to understand noisy audiovisual speech; subjects' susceptibility to the McGurk effect, a multisensory illusion; and the time spent fixating the mouth of a talking face.  In the second Aim, we will explore the neural encoding of visual speech using voxel-wise forward encoding models of the BOLD fMRI signal. We will develop encoding models to test 7 different theories of visual speech representation from the linguistic and computer vision literature. In the third Aim, we will use ECoG to examine the neural computations for integrating visual and auditory speech, guided by the Bayesian models developed in Aim 1. First, we will study reduced neural variability for multisensory speech predicted by our model. Second, we will study the representational space of unisensory and multisensory speech. PUBLIC HEALTH RELEVANCE: Understanding speech is one of the most important functions of the human brain. We use information from both the auditory modality (the voice of the person we are talking to) and the visual modality (the facial movements of the person we are talking to) to understand speech. We will use computational models, eye tracking, and brain imaging and recording techniques to study the organization and operation of the brain during audiovisual speech perception.",NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION,9416174,R01NS065395,"['Auditory', 'Auditory Perception', 'Bayesian Analysis', 'Bayesian Modeling', 'Behavioral', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Electrocorticogram', 'Eye', 'Eye Movements', 'Face', 'Functional Magnetic Resonance Imaging', 'Hearing problem', 'Human', 'Illusions', 'Individual', 'Individual Differences', 'Investigation', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Link', 'Literature', 'Measures', 'Mediating', 'Modality', 'Modeling', 'Movement', 'Neurons', 'Noise', 'Oral cavity', 'Perception', 'Persons', 'Population', 'Predisposition', 'Property', 'Publishing', 'Sample Size', 'Sensory', 'Signal Transduction', 'Speech', 'Speech Perception', 'Stimulus', 'Structure of superior temporal sulcus', 'Techniques', 'Testing', 'Time', 'Visual', 'Vocabulary', 'Voice', 'audiovisual speech', 'base', 'behavior measurement', 'experience', 'flexibility', 'hearing impairment', 'multisensory', 'neural model', 'normal aging', 'operation', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'sample fixation', 'speech accuracy', 'theories', 'visual information', 'visual speech']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2018,346719,0.1138101228734051
"Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder. ﻿    DESCRIPTION (provided by applicant): In an effort to intervene before psychosis onset and prevent morbidity, a major recent focus in schizophrenia research has been the identification of young people during a putative prodromal period, so as to develop safe and effective interventions to modify disease course. Over the past decades, studies at Columbia and elsewhere have evaluated clinical high-risk (CHR) individuals across a range of cognitive processes in an effort to identify core deficits of schizophrenia evident before psychosis onset. Subtle thought disorder, manifest in disturbance of language production, is a feature that predates rather than follows, psychosis onset in CHR individuals, and therefore may be an indicator of schizophrenia liability. Subtle thought disorder in schizophrenia and its risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. Here, we propose to instead use a novel automated machine-learning approach to speech analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language. It also evaluates syntax through ""part-of-speech"" tagging. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture subtle thought disorder and discriminate psychosis outcome among CHR individuals. Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we were able to identify a classifier with high accuracy for psychosis onset in a small CHR cohort at Columbia, which included semantic coherence from phrase to phrase, shortened phrase length, and decreased use of determiner pronouns (""which"", ""what"", ""that""). These features were correlated with prodromal symptoms but outperformed them in terms of classification accuracy. They also discriminated schizophrenia from normal speech. While promising, these automated methods of analysis require validation in a second CHR cohort. In this proposal, in collaboration with IBM, we will validate these automated methods using a large archive of speech data from the UCLA CHR cohort. This dataset has several advantages. First, the UCLA CHR cohort has a high prevalence of psychosis transition, important as machine learning is sensitive to group size. Second, it has undergone prior manual linguistic analysis, identifying features of language production that predicted psychosis outcome; hence, automated and manual methods can be directly compared. Third, there are speech data available from healthy controls and recent-onset psychosis patients (for validation). Fourth, several participants have multiple speech assays (such that stability of the classifier can be examined). Beyond validation of methods, we will maximize group size and combine speech data from Columbia and UCLA to characterize a common classifier of psychosis outcome. Automated methods for language analysis may improve prediction of psychosis onset and inform remediation strategies for its prevention. PUBLIC HEALTH RELEVANCE: Subtle thought disorder is an early core feature of schizophrenia evident before psychosis onset: it has traditionally been evaluated using clinical ratings or labor-intensive manual linguistic analyses. This proposal will apply novel computer-based speech analysis methods to existing datasets to identify abnormal semantic and syntactic features of language production that can predict or classify psychosis outcome among youths at clinical high risk for psychosis. Improved characterization of thought disorder can inform targeted preventive interventions for young people at risk for schizophrenia and related psychotic disorders, so as to reduce the morbidity of psychosis.",Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.,9231498,R03MH108933,"['Address', 'Age', 'Archives', 'Artificial Intelligence', 'Biological Assay', 'Cereals', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Deltastab', 'Development', 'Diagnosis', 'Disease', 'Elderly', 'Emotional', 'Friends', 'High Prevalence', 'Human', 'Impairment', 'Individual', 'Language', 'Lead', 'Length', 'Linguistics', 'Machine Learning', 'Manuals', 'Mental disorders', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Occupations', 'Outcome', 'Output', 'Participant', 'Patients', 'Population', 'Poverty', 'Prevention', 'Preventive Intervention', 'Production', 'Psychiatrist', 'Psychiatry', 'Psychotic Disorders', 'Research', 'Risk', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Scientist', 'Semantics', 'Site', 'Source', 'Speech', 'Structure', 'Symptoms', 'Testing', 'Text', 'Thinking', 'Training', 'Validation', 'Youth', 'analytical method', 'base', 'cognitive process', 'cohort', 'demographics', 'disabling symptom', 'effective intervention', 'hazard', 'high risk', 'improved', 'indexing', 'novel', 'phrases', 'prevent', 'public health relevance', 'remediation', 'standard of care', 'syntax', 'targeted treatment', 'tool']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2017,35453,0.11437188115726164
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9199411,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2017,319382,0.05039807123948038
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants ﻿    DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9305035,R01DC014290,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Categories', 'Cochlear Implants', 'Comprehension', 'Development', 'Devices', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Frequencies', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Individual', 'Location', 'Machine Learning', 'Maps', 'Masks', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Problem Solving', 'Quality of life', 'Recruitment Activity', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Perception', 'Stimulus', 'Surface', 'Testing', 'Time', 'base', 'improved', 'public health relevance', 'response', 'simulation', 'sound', 'speech processing', 'speech recognition', 'success']",NIDCD,DUKE UNIVERSITY,R01,2017,293476,0.11768326920382259
"Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome ﻿    DESCRIPTION (provided by applicant): A major limitation of existing assessments of clinically-relevant mental states related to drug use, abuse, and treatment is that self-report measures rely on the capacity and motivation to accurately report one's internal experiences. A potential alternative is presented by emerging computer-based natural language processing methods that can extract fine-grained semantic, structural, and syntactic features from free speech1, potentially providing a unique 'window into the mind.' These methods are widely used in industry2, yet remain largely unknown in clinical research. To begin to assess the potential of these advanced analytic methods in clinical research, we recently partnered with IBM computer science researchers to test computer-based analysis of speech semantic structure. In preliminary work, we were able to demonstrate that such methods could detect acute drug intoxication3 and accurately predicted the development of psychosis in clinical risk states4. Here, we propose to build on these highly promising initial findings, conducting three secondary data analyses to rapidly and cost-effectively advance this novel direction. Projects 1 and 2 will extend our preliminary work on speech markers of mental state changes during acute drug intoxication. In Project 1, we will assess speech semantic, structural, and syntactic features as markers of mental state changes due to MDMA (0, 0.75, 1.5 mg/kg; oral). In Project 2, we will extend these findings to another drug, assessing speech markers of intoxication with LSD (0, 70 μg; intravenous). These projects are possible because we have access to existing transcripts of free speech from within-subject, controlled laboratory studies of the effects of MDMA (N = 77) and LSD (N = 19). Potential future uses for these methods could include rapid characterization of the effects of emerging drugs and, potentially, detection of acute drug intoxication in the absence of biochemical confirmation. Project 3 will assess the use of speech analysis as a prognostic marker in substance abuse treatment. Specifically, we will use speech transcripts (N = 50) from a currently ongoing study to assess whether features extracted from baseline free speech can predict treatment outcome in cocaine users undergoing 12 weeks of CBT relapse prevention. Self-report5,6 and manual coding of speech7-9 suggest that motivation to change may be a predictor of treatment outcome for substance use disorders: we expect that the fine-grained computational methods we will employ will allow the development of more accurate predictive models. The capacity to use automated methods to detect mental states from free speech has wide ranging, potentially transformative implications for addiction medicine and psychiatry more broadly4,10. Results of the proposed secondary analyses projects will efficiently advance understanding of how automated speech analysis, a non-invasive and cost- effective assessment method, could be used in clinical practice and research about drug abuse. More broadly, results may contribute to the empirical basis for the development of automated, objective, speech- based diagnostic and prognostic tests in psychiatry. PUBLIC HEALTH RELEVANCE: Free speech, a unique `window into the mind', represents a rich source of information that can be mined for clinically-relevant information. This application proposes to apply novel computer science speech analysis methods in three secondary data analysis projects to investigate 1) speech markers of mental states during acute drug intoxication; and 2) speech as a prognostic marker in cognitive behavioral treatment for drug abuse. Results will rapidly and cost-effectively advance understanding of how automated speech analysis could be used in clinical practice and research about drug use, abuse, and treatment.",Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome,9232130,R03DA040855,"['Acute', 'Behavior', 'Biochemical', 'Bypass', 'Cereals', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Cocaine', 'Cocaine Abuse', 'Cocaine Users', 'Code', 'Cognitive Therapy', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Double-Blind Method', 'Drug abuse', 'Drug usage', 'Funding', 'Funding Mechanisms', 'Future', 'Human', 'Individual', 'Industry', 'Intoxication', 'Intravenous', 'Laboratory Study', 'Language', 'Lysergic Acid Diethylamide', 'Machine Learning', 'Manuals', 'Measures', 'Medicine', 'Mental disorders', 'Methods', 'Mind', 'Moods', 'Motivation', 'Natural Language Processing', 'Oral', 'Patient Self-Report', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Placebos', 'Prognostic Marker', 'Psychiatry', 'Psychotic Disorders', 'Randomized', 'Reporting', 'Research', 'Research Personnel', 'Research Proposals', 'Sampling', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'Study Subject', 'Substance Use Disorder', 'Technology', 'Testing', 'Transcript', 'Treatment outcome', 'Work', 'addiction', 'analytical method', 'base', 'clinical practice', 'clinical risk', 'clinically relevant', 'cocaine use', 'computer science', 'computerized', 'cost', 'cost effective', 'disorder later incidence prevention', 'ecstasy', 'experience', 'high risk', 'innovation', 'mental state', 'natural language', 'novel', 'outcome prediction', 'predictive modeling', 'prognostic assays', 'programs', 'public health relevance', 'secondary analysis', 'substance abuse treatment', 'syntax']",NIDA,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2017,81000,0.08134512578624477
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9191358,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,602469,0.1339469354487025
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9355730,U01NS098969,"['Acoustics', 'Address', 'Adverse effects', 'Basal Ganglia', 'Clinical', 'Code', 'Cues', 'Data', 'Deep Brain Stimulation', 'Dysarthria', 'Electrophysiology (science)', 'Event', 'Goals', 'Language', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Movement', 'Movement Disorders', 'Nature', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Output', 'Parkinson Disease', 'Patients', 'Pattern', 'Performance', 'Phase', 'Production', 'Role', 'STN stimulation', 'Speech', 'Stimulus', 'Stream', 'Structure of subthalamic nucleus', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Universities', 'Voice', 'analytical method', 'base', 'cognitive neuroscience', 'gain of function', 'kinematics', 'learning strategy', 'member', 'microstimulation', 'motor symptom', 'multidisciplinary', 'nervous system disorder', 'neurophysiology', 'novel', 'novel strategies', 'relating to nervous system', 'response']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2017,900000,0.1215839658242332
"Speech Movement Classification for Assessing and Treating ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",Speech Movement Classification for Assessing and Treating ALS,9341526,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'communication device', 'data mining', 'diagnostic accuracy', 'digital', 'experimental study', 'improved', 'improved functioning', 'innovation', 'jaw movement', 'motor impairment', 'movement analysis', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2017,93248,0.11856188213856729
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,9185964,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'communication device', 'data mining', 'diagnostic accuracy', 'digital', 'experimental study', 'improved', 'improved functioning', 'innovation', 'jaw movement', 'motor impairment', 'movement analysis', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2017,581327,0.11856188213856729
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9370414,K24DC016312,"['Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2017,189841,0.126364951711706
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9356341,U01NS098971,"['Acoustics', 'Acute', 'Address', 'Affect', 'Animal Model', 'Aphasia', 'Apraxias', 'Architecture', 'Archives', 'Area', 'Articulation', 'Articulators', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Biomedical Engineering', 'Brain', 'Brain Mapping', 'Brain region', 'Chronic', 'Clinical', 'Cognitive', 'Communication impairment', 'Communities', 'Complex', 'Computer Simulation', 'Correlation Studies', 'Data', 'Dementia', 'Devices', 'Dimensions', 'Disease', 'Electrocorticogram', 'Electrodes', 'Engineering', 'Ethics', 'Face', 'Foundations', 'Functional disorder', 'Gestures', 'Goals', 'Human', 'Image', 'Imagery', 'Implant', 'Individual', 'Jaw', 'Knowledge', 'Language', 'Larynx', 'Learning', 'Left', 'Light', 'Linguistics', 'Lip structure', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Monitor', 'Motor Cortex', 'Movement', 'Mutism', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Neurosciences', 'Paralysed', 'Pattern', 'Physiology', 'Play', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prefrontal Cortex', 'Procedures', 'Production', 'Property', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Site', 'Social isolation', 'Speech', 'Speech Sound', 'Stroke', 'Stuttering', 'System', 'Technology', 'Time', 'Tongue', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'base', 'cognitive control', 'data sharing', 'density', 'experience', 'implantation', 'innovation', 'insight', 'kinematics', 'motor control', 'multidisciplinary', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'neurosurgery', 'novel', 'relating to nervous system', 'relational database', 'response', 'sound', 'spatiotemporal', 'synergism', 'temporal measurement', 'tool', 'trait']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,900000,0.1218349701174573
"Dynamics of Vocal Tract Shaping ﻿    DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9177754,R01DC007124,"['Acoustics', 'Adult', 'Apraxias', 'Articulation', 'Articulators', 'Beds', 'Cardiac', 'Clinical', 'Communication', 'Communities', 'Complex', 'Coupled', 'Data', 'Deglutition Disorders', 'Development', 'Dimensions', 'Educational process of instructing', 'Engineering', 'Epiglottis structure', 'Event', 'German population', 'Gestures', 'Glossectomy', 'Goals', 'Human', 'Image', 'Imaging technology', 'Impairment', 'In Situ', 'Individual', 'International', 'Investigation', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Lateral', 'Linguistics', 'Lip structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Motion', 'Movement', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Oropharyngeal', 'Pattern', 'Pharyngeal structure', 'Play', 'Population', 'Posture', 'Production', 'Property', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Self-Help Devices', 'Series', 'Shapes', 'Sleep Apnea Syndromes', 'Speech', 'Speech Disorders', 'Speed', 'Stroke', 'Structure', 'Surgical Flaps', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tongue', 'Traction', 'Training', 'Variant', 'Work', 'base', 'bioimaging', 'cognitive control', 'cohesion', 'computerized tools', 'constriction', 'dexterity', 'high dimensionality', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'instrument', 'movie', 'novel', 'outreach', 'phonology', 'program dissemination', 'public health relevance', 'reconstruction', 'remediation', 'shape analysis', 'sound', 'spatiotemporal', 'speech recognition', 'technological innovation', 'theories', 'tongue apex', 'tool', 'web site']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,433810,0.12743950754434213
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9311162,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,608789,0.11309878176323111
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9313700,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'United States National Institutes of Health', 'Variant', 'clinical application', 'clinical practice', 'critical developmental period', 'design', 'evidence base', 'experience', 'experimental study', 'hearing impairment', 'indexing', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2017,267749,0.13058911359208208
"Verb learning and the early development of sentence comprehension DESCRIPTION (provided by applicant): Children use syntax to understand sentences and to learn verbs; this is syntactic bootstrapping. We proposed a Structure Mapping account of the origins of syntactic bootstrapping. On this account, children begin with an unlearned bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful. In the previous funding period, we tested key predictions of this account, and found strong evidence for structure-mapping. Identifying the set of nouns in sentences yields a partial representation of syntactic structure that allows toddlers to identify verbs, and to interpret novel transitive and intransitive verbs in simple sentences. The proposed research asks how syntactic bootstrapping moves beyond 'counting the nouns', scaling up to the true complexity of verbs and sentences. We focus on two data-sources: distributional learning and discourse structure. First, we propose that distributional learning creates probabilistic syntactic-semantic combinatorial knowledge about verbs. This combinatorial knowledge, also known as verb bias, permits syntactic bootstrapping, and from early in development is used online to help identify the structure and lexical content of sentences, guiding syntactic analysis. Second, we propose that a bias toward discourse continuity increases linguistic support for verb learning by allowing learners to collect evidence for arguments across nearby sentences. Verb bias guides this process, by cuing children to seek referents for missing arguments in the discourse context. To investigate these proposals we combine experiments with toddlers and preschoolers, and a computational model based on systems for automatic semantic role labeling. Experiments with children assess comprehension of familiar and invented verbs in sentences, by measuring children's visual fixations to relevant scenes or objects. Project 1 explores toddlers' encoding of syntactic-semantic combinatorial facts about verbs from listening experience. Project 2 explores toddlers' use of discourse context to guide sentence interpretation, constrained by verb bias. Project 3 asks to what extent verb bias in preschoolers changes with new distributional learning. In Project 4 we develop our computational model to investigate the same processes. Results from experiments with children constrain the features we equip the model to detect; we use the model to test the consequences of our claims for learning from corpora of natural child-directed speech. This combination of experimental and computational studies will advance scientific knowledge about how children learn their native languages, and guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how children learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy. PUBLIC HEALTH RELEVANCE: The proposed research will examine verb learning and the development of sentence comprehension, using a combination of experiments with toddlers and preschoolers, and a computational model of early sentence comprehension. Our findings should have considerable impact, for two main reasons: First, our work will shed light on how learners begin to find meaning in syntax, addressing long-standing and fundamental scientific questions about language development. Second, the findings should help us predict and understand the consequences of individual variations in the early language environment for language development: by studying how young children collect and use linguistic-distributional data about words, we can predict what kinds of data they need to make typical progress, and thus what kinds of early experiences might lead to risks for language difficulties.",Verb learning and the early development of sentence comprehension,9244818,R01HD054448,"['Address', 'Behavior', 'Child', 'Comprehension', 'Computer Simulation', 'Data', 'Data Sources', 'Detection', 'Development', 'Environment', 'Event', 'Feedback', 'Funding', 'Individual', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Link', 'Measures', 'Memory', 'Modeling', 'Natural Language Processing', 'Ocular Fixation', 'Participant', 'Play', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Semantics', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Uncertainty', 'Variant', 'Work', 'base', 'combinatorial', 'computer studies', 'early experience', 'expectation', 'experience', 'experimental study', 'improved', 'lexical', 'novel', 'pedagogy', 'public health relevance', 'remediation', 'scale up', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2017,308492,0.08118490422238503
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9307257,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,636163,0.08410830212603831
"Distributional Learning in Children with Language Impairment Project Summary/Abstract Statistical learning experiments have demonstrated that children and infants are sensitive to the types of statistical regularities found in natural language. These experiments often rely on statistical information based on linear dependencies, e.g. that x predicts y either immediately or after some intervening items, whereas learning to creatively use language relies on the ability to form grammatical categories (e.g. verbs, nouns) that share distributions. Distributional learning has not been explored in children or individuals with language impairment. The proposed research can reveal new findings regarding language acquisition and use in these populations. Proposed statistical learning deficits in individuals with language impairment (LI) are thought to have downstream effects causing poorer comprehension, but this relationship has not been experimentally shown. In this project, children with and without LI and their typically developing (TD) peers will complete an online comprehension task that employs natural language and an artificial grammar learning task that employs a made-up language. In the online comprehension task, participants use a computer mouse to choose a preferred interpretation of a sentence that is ambiguous, but that most adults would interpret a certain way due to the distributional properties of the verb, an effect termed verb bias. It has not been shown whether individuals LI are sensitive to verb bias effects, but we predict children with LI will be less sensitive than peers on the basis of previous work showing deficits with verb use and overall poorer linguistic experience in this population. In the artificial grammar learning task, participants will be tested to determine if they have learned the statistical regularities of trained stimuli and formed categories based upon these regularities. We predict TD participants will form more robust categories. It has not been shown whether individuals with LI are worse at utilizing distributional information from novel input, but poor performance on other statistical learning tasks by this population suggests a deficit. We will use measurements from both tasks to verify a relationship between them, for the additional goal of showing that language comprehension and statistical learning are related. This study will provide information about differences between children with LI and their TD peers in the ability to use distributional information from both accumulated and novel input. To this end, we will discover the role of input and experience in using distributional information in linguistic environments. Project Narrative The proposed project will provide information about the extent to which children with and without language impairment utilize distributional information in the input, specifically as regards to language. Problems with language learning are correlated with long-term academic and social difficulties, and a better understanding of how statistical information like words’ distribution is processed and utilized by individuals with language impairment can shed insight into the role of the input in language learning and use. This information could lead to intervention techniques that manipulate distributional information in order to facilitate language development and improve comprehension in children with language impairment.",Distributional Learning in Children with Language Impairment,9352674,F31DC015370,"['Adult', 'Categories', 'Cereals', 'Child', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Cues', 'Dependency', 'Development', 'Eating', 'Environment', 'Eye', 'Failure', 'Future', 'Goals', 'Hearing', 'Individual', 'Infant', 'Information Distribution', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mus', 'Nursery Schools', 'Participant', 'Performance', 'Persons', 'Population', 'Probability', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'base', 'comprehension deficit', 'experience', 'experimental study', 'farmer', 'improved', 'insight', 'language comprehension', 'language impairment', 'natural language', 'novel', 'peer', 'social', 'sound', 'syntax', 'teacher', 'therapy design']",NIDCD,UNIVERSITY OF IOWA,F31,2017,24909,0.11721835462712708
"""Mechanisms of Early Bilingual Language Acquisition"" ﻿    DESCRIPTION (provided by applicant): A majority of children worldwide learn more than one language (Grosjean, 2010), yet theories of language acquisition treat monolingualism as the standard learning model. Bilingualism is highly common, but the mechanisms that drive bilingual learning are not yet well understood. In order to develop rich theories of language acquisition, it is necessary to include a full consideration of the demands of bilingual learning environments and how learners cope with these demands.  The proposed research project seeks to fill this theoretical gap by investigating bilingual statistical learning at the very early stages of languag acquisition. Statistical learning entails discovering structure by tracking patterns that are preset in the input. Statistical learning is a popular framework that has received a great deal of attention for its potential to explain how infants and children acquire many dimensions of linguistic structure. Infants are remarkably skilled at tracking regularities. However, the literatre has not yet addressed how bilingualism affects the ability to extract statistical regularities in linguistic input. The demands are substantially greater for bilinguals than for monolinguals. They must track two separate sets of regularities for every aspect of linguistic structure, from sounds to words to grammar. This research will examine two processes that are fundamental for early language acquisition, the ability to detect words in fluent speech and the ability to associate word forms with meanings. The experiments will address how dual language input affects infants' ability to perform these tasks. In addition, both monolingual and bilingual infants will participate, providing a window on how bilingual experience affects infants' tracking of regularities in dual languages. The project will also explore what cognitive processes support bilingual infants' ability to learn effectively in two immensely complex linguistic systems, focusig on how cognitive control and vocabulary composition relate to statistical learning skills in the laboratory.  In addressing a theoretical gap, the proposed research also has substantial significance for public health. This work will reveal mechanisms that infants use to learn and the conditions that support or hinder bilingual learning. These contributions have potential to affect the design and implementation of early bilingual education programs. In addition, this work will elucidate the mechanisms that typically developing infants use to acquire language, which has applied value for the study of language impairments. Understanding the underlying processes of typical development is crucial for understanding the development of populations who are not acquiring language on a typical course. It is important to know how learning typically proceeds in order to identify potential underlying deficits in learning impairments. PUBLIC HEALTH RELEVANCE: A majority of children worldwide are bilingual, yet there is limited understanding of how bilinguals learn. This work addresses a crucial gap in accounts of language acquisition and will inform programs for bilingual education. In addition, the research will support the search for underlying deficits in children with language impairments by characterizing the mechanisms that drive typical development.","""Mechanisms of Early Bilingual Language Acquisition""",9242682,R03HD084941,"['Address', 'Affect', 'Attention', 'Child', 'Complex', 'Conflict (Psychology)', 'Controlled Vocabulary', 'Cues', 'Development', 'Dimensions', 'Education', 'Environment', 'Future', 'Impairment', 'Infant', 'Information Distribution', 'Knowledge', 'Label', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Learning Skill', 'Linguistics', 'Machine Learning', 'Modeling', 'Nature', 'Pattern', 'Performance', 'Population', 'Process', 'Public Health', 'Research', 'Research Project Grants', 'Shapes', 'Speech', 'Stream', 'Structure', 'System', 'Testing', 'Text', 'Vocabulary', 'Work', 'base', 'bilingualism', 'cognitive control', 'cognitive development', 'cognitive function', 'cognitive process', 'cognitive system', 'design', 'developmental psychology', 'educational atmosphere', 'executive function', 'experience', 'experimental study', 'heuristics', 'infancy', 'language impairment', 'novel', 'phonology', 'programs', 'public health relevance', 'sound', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2017,78500,0.11126463013284166
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication ﻿    DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders. PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,9319226,R03DC013990,"['Address', 'Age', 'Algorithms', 'American Cancer Society', 'Articulation', 'Back', 'Characteristics', 'Clinical', 'Data', 'Devices', 'Diagnosis', 'Electromagnetics', 'Excision', 'Future', 'Gender', 'Goals', 'Health', 'Health Professional', 'Human', 'Impairment', 'Individual', 'Language', 'Laryngeal Prosthesis', 'Laryngectomy', 'Larynx', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Motor', 'Movement', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pathologist', 'Patients', 'Pattern', 'Performance', 'Persons', 'Play', 'Population', 'Research', 'Self-Help Devices', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Sound', 'System', 'Testing', 'Text', 'Time', 'Tongue', 'Tracheoesophageal Speech', 'United States', 'Voice', 'Voice Disorders', 'base', 'cancer therapy', 'clinical practice', 'computer science', 'efficacy testing', 'improved', 'innovative technologies', 'kinematics', 'movement analysis', 'novel', 'oral communication', 'public health relevance', 'sound']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2017,153000,0.15024871385509972
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9297279,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Laws', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'synergism', 'theories', 'treatment effect']",NIDCD,UNIVERSITY OF ARIZONA,R01,2017,606922,0.0996937014000996
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,9178665,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Statistical Study', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'experimental study', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2017,340010,0.1356575572872618
"Extending PhonBank for Clinical Phonology and Speech Analysis The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, and the infrastructure developed in the CHILDES Project, the PhonBank database project now provides universal Internet access to large corpora of transcripts linked to audio for the study of phonological developemnt. PhonBank also provides the Phon program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 25 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",Extending PhonBank for Clinical Phonology and Speech Analysis,9234982,R01HD051698,"['Adult', 'Affect', 'Aphasia', 'Apraxias', 'Area', 'Attention', 'Back', 'Child', 'Clinical', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Equipment and supply inventories', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Individual', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Multilingualism', 'Participant', 'Pattern', 'Population', 'Process', 'Production', 'Productivity', 'Property', 'Protocols documentation', 'Publishing', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Speech', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'analytical tool', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'member', 'phonology', 'programs', 'protocol development', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2017,293203,0.10901893386261834
"Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests Project summary. This Phase I will establish the feasibility of increasing audiological diagnostic information by carrying out word- and phoneme-level analyses of open set responses during speech audiometry and by obtaining subjective hearing measures. Speech audiometry is used in characterizing functional hearing in settings of hearing screening, diagnosis, hearing aid fitting, counseling, aural rehabilitation/training, occupational fitness, and research. A typical procedure used with word and sentence tests in background noise is to ask the client/patient to repeat back what was just said (i.e., give an open set response). Responses are then scored in terms of words or keywords correct/incorrect. This method discards potentially diagnostic information in response errors, because noise can reveal systematic phonetic feature or phoneme confusions, and with background babble, intrusions from the babble. Other response patterns attributable to cognitive or memory declines may manifest in the paucity or verbosity of response words. Specific types of phoneme perception errors are thought to be associated with extent and configuration of hearing loss; and different types of noise maskers (i.e., energetic and informational maskers) present different types of perceptual problems that vary in severity across individuals. In order to utilize response errors, computational methods are needed to establish their relationships to the stimulus. This is because response errors may incorporate incorrect stimulus-to-response phoneme substitutions, as well as insertions or deletions of phonemes or words relative to the stimulus. We have developed sequence alignment methods to mine errors during speech audiometry, which we propose to evaluate using our system (Multi-Measure SPIN Chart: MMSPIN Chart). MMSPIN chart will be further developed and installed in the George Washington University Speech & Hearing Center (Aim 1). Audiologists will use the system during QuickSin sentence and NU-6 word testing with 200 clients (18-85 years of age) who give permission to access their entire clinic records (Aim 2). Their conventional speech audiometry will be augmented by obtaining subjective hearing accuracy judgments and hearing self-efficacy measures. These subjective judgments are designed to expose discrepancies with objective performance and to reveal individual differences in social cognition associated with hearing loss, both of which may account for the large individual differences in performance and intervention outcomes not accounted for by the audiogram. Evaluation of results in Aim 3 will include developing group and individual profile models comprising objective and subjective clinical data. With our clinician partners, we will develop formats for communicating MMSPIN Chart results to clients. In Aim 4, we will present results in a public lecture for audiologists and solicit opinions about how our new results may best impact clinical practice. Our approach can deliver more informative and efficient speech audiometry using existing test materials and can pave the way to more sensitive speech audiometry, including tests that are adaptive to specific levels of speech processing difficulty. Narrative. The typical approach to speech audiometry is to elicit open set responses that are scored in terms of words/keywords correct, discarding information in response errors. This Phase I will establish the feasibility of increasing diagnostic information provided to audiologists by carrying out word- and phoneme-level analyses of open set responses and obtaining subjective hearing measures in conjunction with speech audiometry. The goal is to improve clinical efficiency and effectiveness and to improve patient outcomes.","Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests",9408539,R43DC015749,"['Adult', 'Age', 'Age-Years', 'Attitude to Health', 'Audiometry', 'Authorization documentation', 'Back', 'Classification', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Computers', 'Computing Methodologies', 'Confusion', 'Counseling', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Evaluation', 'Factor Analysis', 'Focus Groups', 'Goals', 'Hearing', 'Hearing Aids', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Judgment', 'Machine Learning', 'Materials Testing', 'Measures', 'Memory Loss', 'Methods', 'Modeling', 'Noise', 'Occupational', 'Outcome', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perception', 'Performance', 'Phase', 'Procedures', 'Pure-Tone Audiometry', 'Questionnaires', 'Records', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Role', 'Self Efficacy', 'Sequence Alignment', 'Severities', 'Speech', 'Speech Audiometry', 'Speech Perception', 'Stimulus', 'Supervision', 'System', 'Technology', 'Test Result', 'Testing', 'Time', 'Training', 'Universities', 'Vision', 'Voice', 'Washington', 'Work', 'clinical practice', 'comparison group', 'data modeling', 'design', 'fitness', 'hearing impairment', 'hearing screening', 'improved', 'lectures', 'permissiveness', 'phonology', 'response', 'satisfaction', 'social cognition', 'speech processing', 'speech recognition', 'touchscreen']",NIDCD,"SEEHEAR, LLC",R43,2017,147919,0.1068262012244148
"Training in lesion-symptom mapping for speech-language research ﻿    DESCRIPTION (provided by applicant): Training in lesion-symptom mapping for speech-language research Abstract: Researchers rely upon the lesion method to evaluate the speech-language status of stroke survivors and draw inferences about underlying brain function. This use of neuropsychology is highly valued in basic speech- language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. In this new landscape, the lesion method represents a form of big-data science that requires large sample sizes and complex image computing to implement lesion-symptom mapping (LSM) across the entire brain, without prior regions of interest. Expertise in these new techniques is becoming critical for high impact speech-language research. The career enhancement plan will provide the candidate with training in cutting-edge LSM. The candidate is an established speech-language investigator with a basic program of multidisciplinary research that includes populations with communication disorders due to stroke. The career enhancement will come at an ideal point, because it will build on the candidate's success in establishing an open-access research registry of stroke survivors (the Western Pennsylvania Patient Registry, WPPR), and current work to develop and validate collaborative videoconferencing for remote neuropsychological assessment. These efforts have created the recruitment pool and datasets that are needed for LSM. The career enhancement will provide the training needed to leverage these resources, thereby augmenting the candidate's program of research and career trajectory. The overarching objectives are to: (1) retool the skills of the candidate to infuse LSM into her program of speech-language research, (2) seed data sharing and data science partnerships to boost the candidate's leadership of WPPR as a national resource, and (3) advance understanding of LSM methods and the neural substrates for speech and language to improve the knowledge base of the candidate and other investigators. The candidate proposes a synergistic set of activities. Didactic activities will give training in machie learning and brain image computing, scholarly travel experiences will afford opportunities to network with speech-language researchers and data scientists whose work is relevant for LSM, and two research studies will provide a hands-on opportunity for the candidate to acquire, apply, and extend LSM methods under the guidance of a superb mentoring team. Study 1 will use univariate and multivariate LSM analysis to investigate the neural substrates of chronic Broca's aphasia and the factors that influence the reproducibility of LSM results. Study 2 will develop and evaluate a workflow for automated lesion segmentation, using a software platform (3D Slicer) that involves two NIH-supported data science centers. Overall, the career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of WPPR as a national resource for speech-language research. PUBLIC HEALTH RELEVANCE: This use of neuropsychology is highly valued in basic speech-language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. This career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of a Pittsburgh- based stroke research registry as a national resource.",Training in lesion-symptom mapping for speech-language research,9274245,K18DC014577,"['Adult', 'Aphasia', 'Big Data', 'Brain', 'Brain imaging', 'Broca Aphasia', 'Chronic', 'Collaborations', 'Communication impairment', 'Community Developments', 'Complex', 'Computer software', 'Data Science', 'Data Set', 'Educational workshop', 'Evaluation', 'Gold', 'Image', 'Interdisciplinary Study', 'Knowledge', 'Language', 'Language Disorders', 'Leadership', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Mentors', 'Methods', 'Modernization', 'Network-based', 'Neuropsychology', 'Participant', 'Pennsylvania', 'Population', 'Recruitment Activity', 'Registries', 'Reproducibility', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sample Size', 'Seeds', 'Speech', 'Stroke', 'Structure-Activity Relationship', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Tissues', 'Training', 'Travel', 'United States', 'United States National Institutes of Health', 'Videoconferencing', 'Work', 'base', 'career', 'data sharing', 'design', 'disability', 'experience', 'improved', 'interest', 'knowledge base', 'language processing', 'method development', 'named group', 'novel', 'patient registry', 'programs', 'public health relevance', 'relating to nervous system', 'research and development', 'research study', 'skills', 'speech processing', 'stroke survivor', 'success', 'theories', 'visiting scholar']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K18,2017,171562,0.11105970847700182
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9233069,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,652111,0.07816844702356515
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9312085,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Simulation', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Machine Learning', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Recruitment Activity', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'nervous system disorder', 'novel', 'outcome prediction', 'phrases', 'predictive modeling', 'signal processing', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,311471,0.15344620913912912
"NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION ﻿    DESCRIPTION (provided by applicant) Speech perception is one of the most important cognitive operations performed by the human brain and is fundamentally multisensory: when conversing with someone, we use both visual information from their face and auditory information from their voice. Multisensory speech perception is especially important when the auditory component of the speech is noisy, either due to a hearing disorder or normal aging. However, much less is known about the neural computations underlying visual speech perception than about those underlying auditory speech perception. To remedy this gap in existing knowledge, we will use converging evidence from two complementary measures of brain activity, BOLD fMRI and electrocorticography (ECoG). The results of these neural recording studies will be interpreted in the context of a flexible computational model based on the emerging tenet that the brain performs multisensory integration using optimal or Bayesian inference, combining the currently available sensory information with prior experience.  In the first Aim, a Bayesian model will be constructed to explain individual differences in multisensory speech perception along three axes: subjects' ability to understand noisy audiovisual speech; subjects' susceptibility to the McGurk effect, a multisensory illusion; and the time spent fixating the mouth of a talking face.  In the second Aim, we will explore the neural encoding of visual speech using voxel-wise forward encoding models of the BOLD fMRI signal. We will develop encoding models to test 7 different theories of visual speech representation from the linguistic and computer vision literature. In the third Aim, we will use ECoG to examine the neural computations for integrating visual and auditory speech, guided by the Bayesian models developed in Aim 1. First, we will study reduced neural variability for multisensory speech predicted by our model. Second, we will study the representational space of unisensory and multisensory speech. PUBLIC HEALTH RELEVANCE: Understanding speech is one of the most important functions of the human brain. We use information from both the auditory modality (the voice of the person we are talking to) and the visual modality (the facial movements of the person we are talking to) to understand speech. We will use computational models, eye tracking, and brain imaging and recording techniques to study the organization and operation of the brain during audiovisual speech perception.",NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION,9197698,R01NS065395,"['Auditory', 'Auditory Perception', 'Bayesian Analysis', 'Bayesian Modeling', 'Behavioral', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Electrocorticogram', 'Employee Strikes', 'Eye', 'Eye Movements', 'Face', 'Functional Magnetic Resonance Imaging', 'Hearing problem', 'Human', 'Illusions', 'Individual', 'Individual Differences', 'Investigation', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Link', 'Literature', 'Measures', 'Mediating', 'Modality', 'Modeling', 'Movement', 'Neurons', 'Noise', 'Oral cavity', 'Perception', 'Persons', 'Population', 'Predisposition', 'Property', 'Publishing', 'Sample Size', 'Sensory', 'Signal Transduction', 'Speech', 'Speech Perception', 'Stimulus', 'Structure of superior temporal sulcus', 'Techniques', 'Testing', 'Time', 'Visual', 'Vocabulary', 'Voice', 'audiovisual speech', 'base', 'behavior measurement', 'experience', 'flexibility', 'hearing impairment', 'multisensory', 'neural model', 'normal aging', 'operation', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'sample fixation', 'speech accuracy', 'theories', 'visual information', 'visual speech']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2017,346719,0.1138101228734051
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustics', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Models', 'Birds', 'Categories', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computational Technique', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrophysiology (science)', 'Elements', 'Environment', 'Failure', 'Foundations', 'Goals', 'Heart', 'Human', 'Individual', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Nuclear', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Population Dynamics', 'Process', 'Property', 'Quality of life', 'Research', 'Role', 'Services', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Structure', 'Sturnus vulgaris', 'Superior temporal gyrus', 'System', 'Systems Development', 'Techniques', 'Testing', 'Time', 'Training', 'Transition Elements', 'Work', 'auditory processing', 'bird song', 'cognitive process', 'experimental study', 'hearing impairment', 'improved', 'language processing', 'microstimulation', 'model development', 'neural circuit', 'neural patterning', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,0.08669499637196956
"Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder. ﻿    DESCRIPTION (provided by applicant): In an effort to intervene before psychosis onset and prevent morbidity, a major recent focus in schizophrenia research has been the identification of young people during a putative prodromal period, so as to develop safe and effective interventions to modify disease course. Over the past decades, studies at Columbia and elsewhere have evaluated clinical high-risk (CHR) individuals across a range of cognitive processes in an effort to identify core deficits of schizophrenia evident before psychosis onset. Subtle thought disorder, manifest in disturbance of language production, is a feature that predates rather than follows, psychosis onset in CHR individuals, and therefore may be an indicator of schizophrenia liability. Subtle thought disorder in schizophrenia and its risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. Here, we propose to instead use a novel automated machine-learning approach to speech analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language. It also evaluates syntax through ""part-of-speech"" tagging. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture subtle thought disorder and discriminate psychosis outcome among CHR individuals. Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we were able to identify a classifier with high accuracy for psychosis onset in a small CHR cohort at Columbia, which included semantic coherence from phrase to phrase, shortened phrase length, and decreased use of determiner pronouns (""which"", ""what"", ""that""). These features were correlated with prodromal symptoms but outperformed them in terms of classification accuracy. They also discriminated schizophrenia from normal speech. While promising, these automated methods of analysis require validation in a second CHR cohort. In this proposal, in collaboration with IBM, we will validate these automated methods using a large archive of speech data from the UCLA CHR cohort. This dataset has several advantages. First, the UCLA CHR cohort has a high prevalence of psychosis transition, important as machine learning is sensitive to group size. Second, it has undergone prior manual linguistic analysis, identifying features of language production that predicted psychosis outcome; hence, automated and manual methods can be directly compared. Third, there are speech data available from healthy controls and recent-onset psychosis patients (for validation). Fourth, several participants have multiple speech assays (such that stability of the classifier can be examined). Beyond validation of methods, we will maximize group size and combine speech data from Columbia and UCLA to characterize a common classifier of psychosis outcome. Automated methods for language analysis may improve prediction of psychosis onset and inform remediation strategies for its prevention.         PUBLIC HEALTH RELEVANCE: Subtle thought disorder is an early core feature of schizophrenia evident before psychosis onset: it has traditionally been evaluated using clinical ratings or labor-intensive manual linguistic analyses. This proposal will apply novel computer-based speech analysis methods to existing datasets to identify abnormal semantic and syntactic features of language production that can predict or classify psychosis outcome among youths at clinical high risk for psychosis. Improved characterization of thought disorder can inform targeted preventive interventions for young people at risk for schizophrenia and related psychotic disorders, so as to reduce the morbidity of psychosis.            ",Automated linguistic analyses of semantics and syntax in speech output in the psychosis prodrome:  A novel paradigm to evaluate subtle thought disorder.,9017082,R03MH108933,"['Address', 'Age', 'Archives', 'Artificial Intelligence', 'Biological Assay', 'Cereals', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Deltastab', 'Development', 'Diagnosis', 'Disease', 'Elderly', 'Emotional', 'Friends', 'High Prevalence', 'Human', 'Impairment', 'Individual', 'Language', 'Lead', 'Length', 'Linguistics', 'Machine Learning', 'Manuals', 'Mental disorders', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Occupations', 'Outcome', 'Output', 'Participant', 'Patients', 'Population', 'Poverty', 'Prevention', 'Preventive Intervention', 'Production', 'Psychiatrist', 'Psychiatry', 'Psychotic Disorders', 'Research', 'Risk', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Scientist', 'Semantics', 'Site', 'Source', 'Speech', 'Structure', 'Symptoms', 'Testing', 'Text', 'Thinking', 'Training', 'Validation', 'Youth', 'base', 'cognitive process', 'cohort', 'demographics', 'disabling symptom', 'effective intervention', 'hazard', 'high risk', 'improved', 'indexing', 'novel', 'phrases', 'prevent', 'public health relevance', 'remediation', 'standard of care', 'syntax', 'targeted treatment', 'tool']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2016,81000,0.11437188115726164
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand.         PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.            ",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9054574,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Educational process of instructing', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Joints', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'research study', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2016,331310,0.05039807123948038
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants ﻿    DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it. PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,9100672,R01DC014290,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Categories', 'Cochlear Implants', 'Comprehension', 'Development', 'Devices', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Frequencies', 'Health', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Individual', 'Location', 'Machine Learning', 'Maps', 'Masks', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Problem Solving', 'Process', 'Quality of life', 'Recruitment Activity', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Perception', 'Stimulus', 'Surface', 'Testing', 'Time', 'base', 'improved', 'response', 'simulation', 'sound', 'speech processing', 'speech recognition', 'success']",NIDCD,DUKE UNIVERSITY,R01,2016,293885,0.11768326920382259
"Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome ﻿    DESCRIPTION (provided by applicant): A major limitation of existing assessments of clinically-relevant mental states related to drug use, abuse, and treatment is that self-report measures rely on the capacity and motivation to accurately report one's internal experiences. A potential alternative is presented by emerging computer-based natural language processing methods that can extract fine-grained semantic, structural, and syntactic features from free speech1, potentially providing a unique 'window into the mind.' These methods are widely used in industry2, yet remain largely unknown in clinical research. To begin to assess the potential of these advanced analytic methods in clinical research, we recently partnered with IBM computer science researchers to test computer-based analysis of speech semantic structure. In preliminary work, we were able to demonstrate that such methods could detect acute drug intoxication3 and accurately predicted the development of psychosis in clinical risk states4. Here, we propose to build on these highly promising initial findings, conducting three secondary data analyses to rapidly and cost-effectively advance this novel direction. Projects 1 and 2 will extend our preliminary work on speech markers of mental state changes during acute drug intoxication. In Project 1, we will assess speech semantic, structural, and syntactic features as markers of mental state changes due to MDMA (0, 0.75, 1.5 mg/kg; oral). In Project 2, we will extend these findings to another drug, assessing speech markers of intoxication with LSD (0, 70 μg; intravenous). These projects are possible because we have access to existing transcripts of free speech from within-subject, controlled laboratory studies of the effects of MDMA (N = 77) and LSD (N = 19). Potential future uses for these methods could include rapid characterization of the effects of emerging drugs and, potentially, detection of acute drug intoxication in the absence of biochemical confirmation. Project 3 will assess the use of speech analysis as a prognostic marker in substance abuse treatment. Specifically, we will use speech transcripts (N = 50) from a currently ongoing study to assess whether features extracted from baseline free speech can predict treatment outcome in cocaine users undergoing 12 weeks of CBT relapse prevention. Self-report5,6 and manual coding of speech7-9 suggest that motivation to change may be a predictor of treatment outcome for substance use disorders: we expect that the fine-grained computational methods we will employ will allow the development of more accurate predictive models. The capacity to use automated methods to detect mental states from free speech has wide ranging, potentially transformative implications for addiction medicine and psychiatry more broadly4,10. Results of the proposed secondary analyses projects will efficiently advance understanding of how automated speech analysis, a non-invasive and cost- effective assessment method, could be used in clinical practice and research about drug abuse. More broadly, results may contribute to the empirical basis for the development of automated, objective, speech- based diagnostic and prognostic tests in psychiatry.         PUBLIC HEALTH RELEVANCE: Free speech, a unique `window into the mind', represents a rich source of information that can be mined for clinically-relevant information. This application proposes to apply novel computer science speech analysis methods in three secondary data analysis projects to investigate 1) speech markers of mental states during acute drug intoxication; and 2) speech as a prognostic marker in cognitive behavioral treatment for drug abuse. Results will rapidly and cost-effectively advance understanding of how automated speech analysis could be used in clinical practice and research about drug use, abuse, and treatment.            ",Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome,9017684,R03DA040855,"['Acute', 'Behavior', 'Biochemical', 'Bypass', 'Cereals', 'Characteristics', 'Clinical', 'Clinical Research', 'Cocaine', 'Cocaine Abuse', 'Cocaine Users', 'Code', 'Cognitive Therapy', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Double-Blind Method', 'Drug abuse', 'Drug usage', 'Funding', 'Funding Mechanisms', 'Future', 'Human', 'Individual', 'Industry', 'Intoxication', 'Intravenous', 'Laboratory Study', 'Language', 'Lysergic Acid Diethylamide', 'Machine Learning', 'Manuals', 'Measures', 'Medicine', 'Mental disorders', 'Methods', 'Mind', 'Mining', 'Moods', 'Motivation', 'Natural Language Processing', 'Oral', 'Outcome', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Placebos', 'Prognostic Marker', 'Psychiatry', 'Psychotic Disorders', 'Randomized', 'Reporting', 'Research', 'Research Personnel', 'Research Proposals', 'Sampling', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'Study Subject', 'Substance Use Disorder', 'Technology', 'Testing', 'Transcript', 'Treatment outcome', 'Work', 'addiction', 'base', 'clinical practice', 'clinical risk', 'clinically relevant', 'cocaine use', 'computer science', 'computerized', 'cost', 'cost effective', 'disorder later incidence prevention', 'ecstasy', 'experience', 'high risk', 'innovation', 'mental state', 'natural language', 'novel', 'outcome prediction', 'predictive modeling', 'prognostic assays', 'programs', 'public health relevance', 'research in practice', 'substance abuse treatment', 'syntax']",NIDA,NEW YORK STATE PSYCHIATRIC INSTITUTE,R03,2016,81000,0.08134512578624477
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment.         PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.                ",Automatic Voice-Based Assessment of Language Abilities,9020029,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Only Child', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Sign Language', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'Writing', 'autism spectrum disorder', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'follow-up', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'research study', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'speech recognition', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,638494,0.1339469354487025
"Subthalamic and corticosubthalamic coding of speech production Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia. Notably, hypophonia and hypokinetic dysarthria (characterized by decreased motor gain) are prevalent in patients with Parkinson's disease (PD). Deep brain stimulation (DBS) of the subthalamic nucleus (STN) produces predictable improvements in other motor symptoms of PD but does not result in consistent improvement in speech and can negatively impact language function. These observations and other accumulating evidence indicate an important role for the basal ganglia in speech. However, a major impediment to developing treatments for speech deficits in movement disorders and reducing speech-related side effects of DBS is the absence of a neurophysiological model for basal ganglia participation in speech production. Testing how general tenets of basal ganglia organization and function apply to the speech motor system presents both unique challenges for clinical neuroscientists and significant opportunities to advance the cognitive neuroscience of speech production. Our overall goals are to determine how motor and linguistic speech information is encoded at multiple levels of granularity within the STN-cortical network, and to determine the relationship between neural activity within the STN-cortical network and the gain of vocal output. Despite the fact that electrophysiological data obtained during DBS surgery offers the unique opportunity to directly assess basal ganglia neuronal activity during speech, this paradigm remains remarkably unexplored. Our central hypothesis is that the STN contributes at multiple levels to the hierarchical control of speech production. Using a completely novel approach, we will rigorously test this hypothesis by simultaneously recording STN units, STN and cortical local field potentials (LFP), and spoken acoustics while PD subjects perform a speech task during DBS surgery. To test for encoding at different levels of granularity, we will explore the extent to which neuronal activity in the STN codes for articulatory and linguistic features associated with different levels of representation within the speech production system (Aim 1). To test for a role in voice modulation, we will explore the extent to which the STN codes for measures of gain, such as volume, pitch and fluency (Aim 2). Additionally, we will directly assess the causal role of STN function in speech production by delivering disruptive stimulation to the STN (Aim 3). A major strength of our project is the complimentary nature of extensive, multi-disciplinary expertise from team members at the University of Pittsburgh, Johns Hopkins University and Carnegie Mellon University. This combined expertise allows us to employ a novel combination of classical analytic methods and more recent machine learning methods for supervised and exploratory analyses to document the neural dynamics of STN and cortical activity during speech production. Speech production and control is disrupted in a number of neurological diseases that involve the basal ganglia, for instance hypophonia and hypokinetic dysarthria are prevalent in patients with Parkinson's disease (PD). We will use a novel experimental approach and combination of analytic techniques to elucidate the contribution of neural activity in the subthalamic nucleus to the hierarchical control of speech production, in subjects with PD undergoing deep brain stimulation surgery.",Subthalamic and corticosubthalamic coding of speech production,9205890,U01NS098969,"['Acoustics', 'Address', 'Adverse effects', 'Basal Ganglia', 'Clinical', 'Code', 'Cues', 'Data', 'Deep Brain Stimulation', 'Dysarthria', 'Electrophysiology (science)', 'Event', 'Goals', 'Language', 'Linguistics', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Movement', 'Movement Disorders', 'Nature', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Output', 'Parkinson Disease', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phonetics', 'Production', 'Role', 'STN stimulation', 'Speech', 'Stimulus', 'Stream', 'Structure of subthalamic nucleus', 'System', 'Techniques', 'Testing', 'Time', 'Universities', 'Voice', 'base', 'cognitive neuroscience', 'gain of function', 'kinematics', 'learning strategy', 'member', 'microstimulation', 'motor symptom', 'nervous system disorder', 'neurophysiology', 'novel', 'novel strategies', 'relating to nervous system', 'response']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2016,900000,0.1215839658242332
"Dynamic behavioral and neural effects of cognitive control on language processing DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications. PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.",Dynamic behavioral and neural effects of cognitive control on language processing,9116243,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2016,60210,0.048799147220020746
"Speech Prosody and Articulatory Dynamics in Spoken Language DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context. One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.",Speech Prosody and Articulatory Dynamics in Spoken Language,9036989,R01DC003172,"['Acoustics', 'Address', 'Affective', 'Articulators', 'Behavior', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Conceptions', 'Data', 'Disease', 'Engineering', 'Environment', 'Evaluation', 'Gestures', 'Grant', 'Human', 'Indium', 'Interruption', 'Investigation', 'Joints', 'Language', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Modeling', 'Movement', 'Nervous System Trauma', 'Oral cavity', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Process', 'Production', 'Property', 'Reading', 'Research', 'Research Personnel', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Source', 'Speech', 'Stream', 'Stroke', 'Structure', 'System', 'Techniques', 'Time', 'Ursidae Family', 'Work', 'autism spectrum disorder', 'base', 'cognitive function', 'cognitive load', 'constriction', 'dynamic system', 'kinematics', 'novel strategies', 'phrases', 'programs', 'research study', 'spatiotemporal', 'speech disorder diagnosis', 'speech recognition', 'syntax']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,477237,0.1745669433703926
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8985675,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Equilibrium', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Life', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Staging', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'communication device', 'data mining', 'diagnostic accuracy', 'digital', 'forging', 'improved', 'innovation', 'jaw movement', 'motor impairment', 'movement analysis', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'research study', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2016,585316,0.11856188213856729
"Functional Architecture of Speech Motor Cortex PROJECT SUMMARY Speaking is one of the most complex actions that we perform, yet nearly all of us learn do it effortlessly. The ability to communicate through speech is often described as the unique and defining trait of human behavior. Despite its importance, the basic neural mechanisms that govern our ability to speak fluently remain unresolved. This proposal addresses two fundamental questions at the crossroads of linguistics, systems neuroscience, and biomedical engineering: 1) How are the kinematic and acoustic targets of articulation represented in human speech motor cortex?, 2) What are the coordinated patterns of cortical activation that gives rise to fluent, continuous speech?, and 3) How does prefrontal cortex govern the cognitive inhibitory control of speech (e.g. stopping)? Our studies should greatly advance understanding of how the speech motor cortex encodes the precise control of articulation during speech production as well as determine whether this control system can be harnessed for novel rehabilitative strategies. Three potential areas of impact are: Neurobiology of Language, where results will shed light on neurophysiologic mechanisms of speech motor control; Human Neurophysiology, where insight gained may suggest novel methods for machine learning-based analyses of distributed population neural activity; and Translational NeuroEngineering, where utilization of novel cortical recording technologies at unparalleled spatiotemporal resolution and duration. We propose to investigate the functional organization of the speech motor cortex during controlled vowel and syllable productions, but also from natural, continuous speech. Our methods utilizing safe, high-density, large-scale intracranial electrode recordings in humans represent a significant advancement over current noninvasive neuroimaging approaches. To accomplish this, we must innovate new, integrative approaches to speech motor control research. We have assembled a team with significant multi- disciplinary strengths in neurosurgery, neurology, ethics, computational modeling, machine learning, neuroscience, engineering, and linguistics. The most debilitating aspect of profound paralysis due to trauma, stroke, or disease is loss of the ability to speak, which leads to profound social isolation. Our research leverages foundational knowledge gained during research piloted under a NIH New Innovator (DP2) award. We wish to broaden the impact of our research in the neurobiology of speech motor control. PROJECT NARRATIVE Discovering the neural mechanisms of speech production has major implications for understanding a large number of communication disorders including mutism, stuttering, apraxia of speech, and aphasia. The proposed research will also have immediate impact on clinical brain mapping procedures for speech.",Functional Architecture of Speech Motor Cortex,9205946,U01NS098971,"['Acoustics', 'Acute', 'Address', 'Affect', 'Animal Model', 'Aphasia', 'Apraxias', 'Architecture', 'Area', 'Articulators', 'Auditory', 'Award', 'Behavior', 'Behavioral', 'Biomedical Engineering', 'Brain', 'Brain Mapping', 'Brain region', 'Chronic', 'Clinical', 'Cognitive', 'Communication impairment', 'Communities', 'Complex', 'Computer Simulation', 'Correlation Studies', 'Data', 'Dementia', 'Devices', 'Dimensions', 'Disease', 'Electrodes', 'Engineering', 'Ethics', 'Face', 'Functional disorder', 'Gestures', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'Implant', 'Individual', 'Jaw', 'Joints', 'Knowledge', 'Language', 'Larynx', 'Learning', 'Left', 'Light', 'Linguistics', 'Lip structure', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Monitor', 'Motor Cortex', 'Movement', 'Mutism', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Neurosciences', 'Paralysed', 'Pattern', 'Physiology', 'Play', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prefrontal Cortex', 'Procedures', 'Production', 'Property', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Site', 'Social isolation', 'Speech', 'Speech Sound', 'Stroke', 'Stuttering', 'System', 'Technology', 'Time', 'Tongue', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'base', 'cognitive control', 'cortex mapping', 'data sharing', 'density', 'experience', 'implantation', 'innovation', 'insight', 'kinematics', 'motor control', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'neurosurgery', 'novel', 'relating to nervous system', 'relational database', 'research study', 'response', 'sound', 'spatiotemporal', 'temporal measurement', 'tool', 'trait']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2016,900000,0.1218349701174573
"Dynamics of Vocal Tract Shaping ﻿    DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate.         PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.            ",Dynamics of Vocal Tract Shaping,9030116,R01DC007124,"['Accounting', 'Acoustics', 'Adult', 'Apraxias', 'Articulators', 'Beds', 'Cardiac', 'Clinical', 'Communication', 'Communities', 'Complex', 'Coupled', 'Data', 'Deglutition Disorders', 'Development', 'Dimensions', 'Educational process of instructing', 'Engineering', 'Epiglottis structure', 'Event', 'German population', 'Gestures', 'Glossectomy', 'Goals', 'Human', 'Image', 'Imaging technology', 'In Situ', 'Individual', 'International', 'Investigation', 'Joints', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Lateral', 'Linguistics', 'Lip structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Motion', 'Movement', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Oropharyngeal', 'Pattern', 'Pharyngeal structure', 'Play', 'Population', 'Posture', 'Production', 'Property', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Self-Help Devices', 'Series', 'Shapes', 'Sleep Apnea Syndromes', 'Speech', 'Speech Disorders', 'Speed', 'Stroke', 'Structure', 'Surgical Flaps', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tongue', 'Traction', 'Training', 'Variant', 'Work', 'base', 'bioimaging', 'computerized tools', 'constriction', 'dexterity', 'image processing', 'improved', 'innovation', 'instrument', 'internal control', 'movie', 'novel', 'outreach', 'phonology', 'program dissemination', 'public health relevance', 'reconstruction', 'remediation', 'sound', 'spatiotemporal', 'speech recognition', 'technological innovation', 'theories', 'tongue apex', 'tool', 'web site']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2016,433810,0.12743950754434213
"The Cortical Dynamics of Motor Activity During Speech Production Speech is critical for human communication, but the cortical control of the fundamental movements of speech production is not clearly understood. Current knowledge primarily stems from functional imaging and lesion studies, which lack the ability to observe rapid changes in activity. Advances in electrocorticography (ECoG) now enable investigation of rapid changes over multiple cortical regions. Early ECoG studies have found ventral motor cortex (M1) activity broadly related to large vocal pitch change and loosely correlated with production of speech sounds, or phonemes. I have demonstrated that even single instances of phonemes can be identified during word production from patterns in activity in M1. However, motor control studies show M1 activity primarily represents movements. Correspondingly, the movements of speech, such as those of the laryngeal musculature involved in vocal pitch, are well understood. Similarly, phonology literature suggests the basic units of speech production are simple articulator movements, or gestures, such as tongue tip closure. Despite strong evidence for movement representation in M1, speech movements have yet to be been investigated with ECoG. The objective of this proposal is to elucidate how the motor cortices control speech movements of articulators and vocal pitch. The research aims of this proposal are to determine the cortical representation of articulatory gestures and vocal pitch during speech and non-speech movements. I will decode high-gamma activity (70-200 Hz) of M1, premotor cortex (PM) and inferior frontal gyrus (IFG) to estimate representation of these movements. Decoding accuracy will quantify the extent to which gestures are represented in each cortical area during speech and non-speech movements. Preliminary results reveal distinct cortical signatures in M1 related to gesture production. Completion of these goals will result in a model of cortical representation of speech movements. This work will enable substantiation of neurophysiological theories, lead to practical applications for patients, and enable investigations of motor activity during higher- order processes of speech. Moreover, we enable comparison of speech to other motor control processes. Results will improve understanding of the cortical representation of the larynx, which remains poorly understood in human physiology research. This study examines cortical activity of motor areas during speech production, with the goal of identifying the cortical representation of articulatory movements and vocal pitch. This research will address fundamental questions about speech motor control during production and phonation, which will enable evaluation of neurophysiological theories and lead to practical applications for patients.",The Cortical Dynamics of Motor Activity During Speech Production,9191603,F32DC015708,"['Acoustics', 'Address', 'Algorithms', 'Area', 'Articulators', 'Communication', 'Controlled Study', 'Craniotomy', 'Electrocorticogram', 'Electrophysiology (science)', 'Evaluation', 'Excision', 'Functional Imaging', 'Gestures', 'Goals', 'Human', 'Inferior frontal gyrus', 'Investigation', 'Knowledge', 'Laryngeal muscle structure', 'Larynx', 'Lead', 'Lesion', 'Lip structure', 'Literature', 'Machine Learning', 'Maps', 'Mechanics', 'Mentors', 'Modeling', 'Motor Activity', 'Motor Cortex', 'Movement', 'Patients', 'Pattern', 'Phonation', 'Physiology', 'Process', 'Production', 'Reading', 'Research', 'Research Personnel', 'Speech', 'Speech Sound', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'analog', 'awake', 'design', 'improved', 'innovation', 'motor control', 'neural prosthesis', 'neurophysiology', 'neurosurgery', 'patient population', 'phonology', 'phrases', 'practical application', 'relating to nervous system', 'restoration', 'speech processing', 'stem', 'theories', 'tongue apex', 'tool', 'tumor']",NIDCD,NORTHWESTERN UNIVERSITY AT CHICAGO,F32,2016,53358,0.09841762068167342
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods. PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.","Infant statistical learning: Resilience, longevity, and specificity",9116242,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Phonetics', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'Variant', 'clinical application', 'clinical practice', 'coping', 'critical developmental period', 'design', 'evidence base', 'experience', 'hearing impairment', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'research study', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2016,263788,0.13058911359208208
"Verb learning and the early development of sentence comprehension DESCRIPTION (provided by applicant): Children use syntax to understand sentences and to learn verbs; this is syntactic bootstrapping. We proposed a Structure Mapping account of the origins of syntactic bootstrapping. On this account, children begin with an unlearned bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful. In the previous funding period, we tested key predictions of this account, and found strong evidence for structure-mapping. Identifying the set of nouns in sentences yields a partial representation of syntactic structure that allows toddlers to identify verbs, and to interpret novel transitive and intransitive verbs in simple sentences. The proposed research asks how syntactic bootstrapping moves beyond 'counting the nouns', scaling up to the true complexity of verbs and sentences. We focus on two data-sources: distributional learning and discourse structure. First, we propose that distributional learning creates probabilistic syntactic-semantic combinatorial knowledge about verbs. This combinatorial knowledge, also known as verb bias, permits syntactic bootstrapping, and from early in development is used online to help identify the structure and lexical content of sentences, guiding syntactic analysis. Second, we propose that a bias toward discourse continuity increases linguistic support for verb learning by allowing learners to collect evidence for arguments across nearby sentences. Verb bias guides this process, by cuing children to seek referents for missing arguments in the discourse context. To investigate these proposals we combine experiments with toddlers and preschoolers, and a computational model based on systems for automatic semantic role labeling. Experiments with children assess comprehension of familiar and invented verbs in sentences, by measuring children's visual fixations to relevant scenes or objects. Project 1 explores toddlers' encoding of syntactic-semantic combinatorial facts about verbs from listening experience. Project 2 explores toddlers' use of discourse context to guide sentence interpretation, constrained by verb bias. Project 3 asks to what extent verb bias in preschoolers changes with new distributional learning. In Project 4 we develop our computational model to investigate the same processes. Results from experiments with children constrain the features we equip the model to detect; we use the model to test the consequences of our claims for learning from corpora of natural child-directed speech. This combination of experimental and computational studies will advance scientific knowledge about how children learn their native languages, and guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how children learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy. PUBLIC HEALTH RELEVANCE: The proposed research will examine verb learning and the development of sentence comprehension, using a combination of experiments with toddlers and preschoolers, and a computational model of early sentence comprehension. Our findings should have considerable impact, for two main reasons: First, our work will shed light on how learners begin to find meaning in syntax, addressing long-standing and fundamental scientific questions about language development. Second, the findings should help us predict and understand the consequences of individual variations in the early language environment for language development: by studying how young children collect and use linguistic-distributional data about words, we can predict what kinds of data they need to make typical progress, and thus what kinds of early experiences might lead to risks for language difficulties.",Verb learning and the early development of sentence comprehension,9040977,R01HD054448,"['Accounting', 'Address', 'Behavior', 'Child', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Data Sources', 'Detection', 'Development', 'Environment', 'Event', 'Feedback', 'Funding', 'Health', 'Individual', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Link', 'Maps', 'Measures', 'Memory', 'Modeling', 'Natural Language Processing', 'Ocular Fixation', 'Participant', 'Play', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Semantics', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Uncertainty', 'Variant', 'Work', 'abstracting', 'base', 'combinatorial', 'computer studies', 'early experience', 'expectation', 'experience', 'improved', 'lexical', 'novel', 'pedagogy', 'remediation', 'research study', 'scale up', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2016,305943,0.08118490422238503
"A Shared Database for the Study of Phonological Development DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",A Shared Database for the Study of Phonological Development,8984169,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Apraxias', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Discourse analysis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2016,270581,0.09669703103371521
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication ﻿    DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders. PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,9114061,R03DC013990,"['Address', 'Age', 'Algorithms', 'American Cancer Society', 'Back', 'Characteristics', 'Clinical', 'Data', 'Devices', 'Diagnosis', 'Electromagnetics', 'Equilibrium', 'Excision', 'Future', 'Gender', 'Goals', 'Health', 'Health Professional', 'Human', 'Individual', 'Joints', 'Language', 'Laryngeal Prosthesis', 'Laryngectomy', 'Larynx', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Motor', 'Movement', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pathologist', 'Patients', 'Pattern', 'Performance', 'Persons', 'Play', 'Population', 'Research', 'Self-Help Devices', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Sound', 'System', 'Testing', 'Text', 'Time', 'Tongue', 'Tracheoesophageal Speech', 'United States', 'Voice', 'Voice Disorders', 'base', 'cancer therapy', 'clinical practice', 'computer science', 'efficacy testing', 'improved', 'innovative technologies', 'kinematics', 'movement analysis', 'novel', 'oral communication', 'sound']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2016,153000,0.15024871385509972
"""Mechanisms of Early Bilingual Language Acquisition"" ﻿    DESCRIPTION (provided by applicant): A majority of children worldwide learn more than one language (Grosjean, 2010), yet theories of language acquisition treat monolingualism as the standard learning model. Bilingualism is highly common, but the mechanisms that drive bilingual learning are not yet well understood. In order to develop rich theories of language acquisition, it is necessary to include a full consideration of the demands of bilingual learning environments and how learners cope with these demands.  The proposed research project seeks to fill this theoretical gap by investigating bilingual statistical learning at the very early stages of languag acquisition. Statistical learning entails discovering structure by tracking patterns that are preset in the input. Statistical learning is a popular framework that has received a great deal of attention for its potential to explain how infants and children acquire many dimensions of linguistic structure. Infants are remarkably skilled at tracking regularities. However, the literatre has not yet addressed how bilingualism affects the ability to extract statistical regularities in linguistic input. The demands are substantially greater for bilinguals than for monolinguals. They must track two separate sets of regularities for every aspect of linguistic structure, from sounds to words to grammar. This research will examine two processes that are fundamental for early language acquisition, the ability to detect words in fluent speech and the ability to associate word forms with meanings. The experiments will address how dual language input affects infants' ability to perform these tasks. In addition, both monolingual and bilingual infants will participate, providing a window on how bilingual experience affects infants' tracking of regularities in dual languages. The project will also explore what cognitive processes support bilingual infants' ability to learn effectively in two immensely complex linguistic systems, focusig on how cognitive control and vocabulary composition relate to statistical learning skills in the laboratory.  In addressing a theoretical gap, the proposed research also has substantial significance for public health. This work will reveal mechanisms that infants use to learn and the conditions that support or hinder bilingual learning. These contributions have potential to affect the design and implementation of early bilingual education programs. In addition, this work will elucidate the mechanisms that typically developing infants use to acquire language, which has applied value for the study of language impairments. Understanding the underlying processes of typical development is crucial for understanding the development of populations who are not acquiring language on a typical course. It is important to know how learning typically proceeds in order to identify potential underlying deficits in learning impairments.         PUBLIC HEALTH RELEVANCE: A majority of children worldwide are bilingual, yet there is limited understanding of how bilinguals learn. This work addresses a crucial gap in accounts of language acquisition and will inform programs for bilingual education. In addition, the research will support the search for underlying deficits in children with language impairments by characterizing the mechanisms that drive typical development.        ","""Mechanisms of Early Bilingual Language Acquisition""",9112198,R03HD084941,"['Accounting', 'Address', 'Affect', 'Attention', 'Child', 'Complex', 'Conflict (Psychology)', 'Controlled Vocabulary', 'Cues', 'Development', 'Dimensions', 'Education', 'Environment', 'Exhibits', 'Future', 'Impairment', 'Infant', 'Knowledge', 'Label', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Learning Skill', 'Linguistics', 'Machine Learning', 'Modeling', 'Nature', 'Pattern', 'Performance', 'Population', 'Process', 'Public Health', 'Research', 'Research Project Grants', 'Shapes', 'Speech', 'Staging', 'Stream', 'Structure', 'System', 'Testing', 'Text', 'Vocabulary', 'Work', 'base', 'bilingualism', 'cognitive control', 'cognitive development', 'cognitive function', 'cognitive process', 'cognitive system', 'coping', 'design', 'developmental psychology', 'educational atmosphere', 'executive function', 'experience', 'heuristics', 'infancy', 'language impairment', 'novel', 'phonology', 'programs', 'public health relevance', 'research study', 'sound', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2016,78438,0.11126463013284166
"Distributional Learning in Children with Language Impairment Project Summary/Abstract Statistical learning experiments have demonstrated that children and infants are sensitive to the types of statistical regularities found in natural language. These experiments often rely on statistical information based on linear dependencies, e.g. that x predicts y either immediately or after some intervening items, whereas learning to creatively use language relies on the ability to form grammatical categories (e.g. verbs, nouns) that share distributions. Distributional learning has not been explored in children or individuals with language impairment. The proposed research can reveal new findings regarding language acquisition and use in these populations. Proposed statistical learning deficits in individuals with language impairment (LI) are thought to have downstream effects causing poorer comprehension, but this relationship has not been experimentally shown. In this project, children with and without LI and their typically developing (TD) peers will complete an online comprehension task that employs natural language and an artificial grammar learning task that employs a made-up language. In the online comprehension task, participants use a computer mouse to choose a preferred interpretation of a sentence that is ambiguous, but that most adults would interpret a certain way due to the distributional properties of the verb, an effect termed verb bias. It has not been shown whether individuals LI are sensitive to verb bias effects, but we predict children with LI will be less sensitive than peers on the basis of previous work showing deficits with verb use and overall poorer linguistic experience in this population. In the artificial grammar learning task, participants will be tested to determine if they have learned the statistical regularities of trained stimuli and formed categories based upon these regularities. We predict TD participants will form more robust categories. It has not been shown whether individuals with LI are worse at utilizing distributional information from novel input, but poor performance on other statistical learning tasks by this population suggests a deficit. We will use measurements from both tasks to verify a relationship between them, for the additional goal of showing that language comprehension and statistical learning are related. This study will provide information about differences between children with LI and their TD peers in the ability to use distributional information from both accumulated and novel input. To this end, we will discover the role of input and experience in using distributional information in linguistic environments. Project Narrative The proposed project will provide information about the extent to which children with and without language impairment utilize distributional information in the input, specifically as regards to language. Problems with language learning are correlated with long-term academic and social difficulties, and a better understanding of how statistical information like words’ distribution is processed and utilized by individuals with language impairment can shed insight into the role of the input in language learning and use. This information could lead to intervention techniques that manipulate distributional information in order to facilitate language development and improve comprehension in children with language impairment.",Distributional Learning in Children with Language Impairment,9255906,F31DC015370,"['Accounting', 'Adult', 'Categories', 'Cereals', 'Child', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Cues', 'Dependency', 'Development', 'Eating', 'Environment', 'Eye', 'Failure', 'Future', 'Goals', 'Hearing', 'Individual', 'Infant', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mus', 'Nursery Schools', 'Participant', 'Performance', 'Persons', 'Population', 'Probability', 'Process', 'Property', 'Qualifying', 'Research', 'Role', 'Semantics', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'abstracting', 'base', 'comprehension deficit', 'experience', 'farmer', 'improved', 'insight', 'language comprehension', 'language impairment', 'natural language', 'novel', 'peer', 'research study', 'social', 'sound', 'syntax', 'teacher', 'therapy design']",NIDCD,UNIVERSITY OF IOWA,F31,2016,31612,0.11721835462712708
"Identification of treatment parameters that maximize language treatment efficacy for children. Poor language skills undermine academic success, which eventually impacts socio-economic outcomes and quality of life. When deficient language skills are first noticed in young children, there is relatively little time available to close the gap before they are faced with the increased language demands of formal education as well as the potential for academic failure. For the 8-13% of preschool children with impaired language skills, language treatments that are faster and more effective are urgently needed. Yet current treatments are notoriously protracted and expensive, and the effects of treatment can be weak. There is a growing call among scholars to step back from the business-as-usual approach to treatment research in favor of a systematic approach that integrates promising theoretical frameworks with experimental manipulations designed to isolate and enhance the effective components of treatment approaches. This grant proposes to leverage insights from the statistical learning perspective on language acquisition, which explains rapid, unguided learning sometimes even in the presence of impaired language. The grant proposes six treatment studies that target two groups of children with poor language skills. “Late Talkers” are children (ages 2-3 years) who are identified by their limited lexicons. Preschool children with specific language impairment (ages 4-5 years) show marked deficits in the use of grammatical morphemes. Parallel sets of studies with these two populations will determine the extent to which treatment variables enhance or detract from treatment efficacy across language domains. The goal of this work will be to identify specific treatment methods, derived from general learning principles, that clinicians can employ to enhance learning outcomes for children with impaired language skills.   Despite forty years of research on language impairments in children, information on effective treatment is sparse. The proposed studies evaluate treatment methods for vocabulary and morphosyntax deficits. The results should yield treatment procedures that can be imported into clinical practice.",Identification of treatment parameters that maximize language treatment efficacy for children.,9172394,R01DC015642,"['3 year old', 'Address', 'Adult', 'Age', 'Back', 'Businesses', 'Child', 'Cleaved cell', 'Dose', 'Early Intervention', 'Economics', 'Education', 'Expenditure', 'Face', 'Failure', 'Family', 'Fathers', 'Goals', 'Grant', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Language Therapy', 'Learning', 'Literature', 'Machine Learning', 'Mental Health', 'Methods', 'Minority', 'Nursery Schools', 'Occupations', 'Outcome', 'Outcome Study', 'Parents', 'Population', 'Preschool Child', 'Procedures', 'Publishing', 'Quality of life', 'Research', 'Rice', 'Schools', 'Series', 'Societies', 'Special Education', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Vocabulary', 'Work', 'clinical practice', 'density', 'design', 'dosage', 'economic outcome', 'effective therapy', 'experience', 'insight', 'language impairment', 'learning outcome', 'literacy', 'peer', 'skills', 'socioeconomics', 'specific language impairment', 'success', 'theories', 'treatment effect']",NIDCD,UNIVERSITY OF ARIZONA,R01,2016,606922,0.0996937014000996
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8976620,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Health', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2016,336609,0.1356575572872618
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9038348,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,652362,0.07816844702356515
"Training in lesion-symptom mapping for speech-language research ﻿    DESCRIPTION (provided by applicant): Training in lesion-symptom mapping for speech-language research Abstract: Researchers rely upon the lesion method to evaluate the speech-language status of stroke survivors and draw inferences about underlying brain function. This use of neuropsychology is highly valued in basic speech- language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. In this new landscape, the lesion method represents a form of big-data science that requires large sample sizes and complex image computing to implement lesion-symptom mapping (LSM) across the entire brain, without prior regions of interest. Expertise in these new techniques is becoming critical for high impact speech-language research. The career enhancement plan will provide the candidate with training in cutting-edge LSM. The candidate is an established speech-language investigator with a basic program of multidisciplinary research that includes populations with communication disorders due to stroke. The career enhancement will come at an ideal point, because it will build on the candidate's success in establishing an open-access research registry of stroke survivors (the Western Pennsylvania Patient Registry, WPPR), and current work to develop and validate collaborative videoconferencing for remote neuropsychological assessment. These efforts have created the recruitment pool and datasets that are needed for LSM. The career enhancement will provide the training needed to leverage these resources, thereby augmenting the candidate's program of research and career trajectory. The overarching objectives are to: (1) retool the skills of the candidate to infuse LSM into her program of speech-language research, (2) seed data sharing and data science partnerships to boost the candidate's leadership of WPPR as a national resource, and (3) advance understanding of LSM methods and the neural substrates for speech and language to improve the knowledge base of the candidate and other investigators. The candidate proposes a synergistic set of activities. Didactic activities will give training in machie learning and brain image computing, scholarly travel experiences will afford opportunities to network with speech-language researchers and data scientists whose work is relevant for LSM, and two research studies will provide a hands-on opportunity for the candidate to acquire, apply, and extend LSM methods under the guidance of a superb mentoring team. Study 1 will use univariate and multivariate LSM analysis to investigate the neural substrates of chronic Broca's aphasia and the factors that influence the reproducibility of LSM results. Study 2 will develop and evaluate a workflow for automated lesion segmentation, using a software platform (3D Slicer) that involves two NIH-supported data science centers. Overall, the career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of WPPR as a national resource for speech-language research. PUBLIC HEALTH RELEVANCE: This use of neuropsychology is highly valued in basic speech-language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. This career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of a Pittsburgh- based stroke research registry as a national resource.",Training in lesion-symptom mapping for speech-language research,9040405,K18DC014577,"['Adult', 'Aphasia', 'Big Data', 'Brain', 'Brain imaging', 'Broca Aphasia', 'Chronic', 'Collaborations', 'Communication impairment', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Educational workshop', 'Evaluation', 'Gold', 'Health', 'Image', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Language', 'Language Disorders', 'Leadership', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Mentors', 'Methods', 'Neuropsychology', 'Participant', 'Pennsylvania', 'Population', 'Registries', 'Reproducibility', 'Research', 'Research Activity', 'Research Methodology', 'Research Personnel', 'Resources', 'Sample Size', 'Seeds', 'Slice', 'Speech', 'Stroke', 'Structure-Activity Relationship', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Tissues', 'Training', 'Travel', 'United States', 'United States National Institutes of Health', 'Videoconferences', 'Videoconferencing', 'Visit', 'Work', 'abstracting', 'base', 'career', 'data sharing', 'design', 'disability', 'experience', 'improved', 'interest', 'knowledge base', 'language processing', 'method development', 'named group', 'neuropsychological', 'novel', 'patient registry', 'programs', 'relating to nervous system', 'research and development', 'research study', 'skills', 'speech processing', 'stroke survivor', 'success', 'theories']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K18,2016,167875,0.11105970847700182
"NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION ﻿    DESCRIPTION (provided by applicant) Speech perception is one of the most important cognitive operations performed by the human brain and is fundamentally multisensory: when conversing with someone, we use both visual information from their face and auditory information from their voice. Multisensory speech perception is especially important when the auditory component of the speech is noisy, either due to a hearing disorder or normal aging. However, much less is known about the neural computations underlying visual speech perception than about those underlying auditory speech perception. To remedy this gap in existing knowledge, we will use converging evidence from two complementary measures of brain activity, BOLD fMRI and electrocorticography (ECoG). The results of these neural recording studies will be interpreted in the context of a flexible computational model based on the emerging tenet that the brain performs multisensory integration using optimal or Bayesian inference, combining the currently available sensory information with prior experience.  In the first Aim, a Bayesian model will be constructed to explain individual differences in multisensory speech perception along three axes: subjects' ability to understand noisy audiovisual speech; subjects' susceptibility to the McGurk effect, a multisensory illusion; and the time spent fixating the mouth of a talking face.  In the second Aim, we will explore the neural encoding of visual speech using voxel-wise forward encoding models of the BOLD fMRI signal. We will develop encoding models to test 7 different theories of visual speech representation from the linguistic and computer vision literature. In the third Aim, we will use ECoG to examine the neural computations for integrating visual and auditory speech, guided by the Bayesian models developed in Aim 1. First, we will study reduced neural variability for multisensory speech predicted by our model. Second, we will study the representational space of unisensory and multisensory speech.         PUBLIC HEALTH RELEVANCE: Understanding speech is one of the most important functions of the human brain. We use information from both the auditory modality (the voice of the person we are talking to) and the visual modality (the facial movements of the person we are talking to) to understand speech. We will use computational models, eye tracking, and brain imaging and recording techniques to study the organization and operation of the brain during audiovisual speech perception.            ",NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION,9055439,R01NS065395,"['Auditory', 'Auditory Perception', 'Bayesian Analysis', 'Bayesian Modeling', 'Behavioral', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Electrocorticogram', 'Employee Strikes', 'Eye', 'Eye Movements', 'Face', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Hearing problem', 'Human', 'Illusions', 'Individual', 'Individual Differences', 'Investigation', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Link', 'Literature', 'Measures', 'Mediating', 'Modality', 'Modeling', 'Movement', 'Neurons', 'Noise', 'Oral cavity', 'Perception', 'Persons', 'Population', 'Predisposition', 'Property', 'Publishing', 'Sample Size', 'Sensory', 'Signal Transduction', 'Speech', 'Speech Perception', 'Stimulus', 'Structure of superior temporal sulcus', 'Techniques', 'Testing', 'Time', 'Visual', 'Vocabulary', 'Voice', 'audiovisual speech', 'base', 'experience', 'flexibility', 'multisensory', 'normal aging', 'operation', 'public health relevance', 'relating to nervous system', 'response', 'sample fixation', 'speech accuracy', 'theories', 'visual information', 'visual speech']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2016,346719,0.1138101228734051
"Investigating neural mechanisms for flexible, robust speech perception with fMRI     DESCRIPTION (provided by applicant): The brain is bombarded by sensory information from the world, and must extract certain pieces of useful information using limited neural resources. This means that the brain must be efficient, throwing away information that is not needed in order to focus on the most important part of the sensory information from the world. However, information that is uninformative in one situation may be highly informative in another, and thus this efficiency must be matched by flexibility. One domain where this is particularly true is speech perception, where a noisy, ambiguous sensory signal is mapped onto underlying linguistic units like phonemes, words, and sentences. This mapping changes substantially depending on who is talking. One way the brain might deal with this is to learn talker-specific representations which optimize the efficiency with which speech sounds are processed, and deploy or ""swap out"" those representations whenever the talker changes, learning new representations for new talkers as necessary. While there is some evidence that listeners do use such a strategy, little is known about the underlying neural mechanisms. This proposal seeks to clarify these mechanisms through two specific aims. First, functional magnetic resonance imaging (fMRI) will image the brains of listeners while they are hearing words from two talkers with different accents, mixed together. By comparing the areas that are active when the talker switches with areas that are active during periods of learning about each accent (as measured by behavioral responses), the circuits by which listeners learn and deploy talker-specific representations will be elucidated. Second, using multi-voxel pattern analysis techniques, the neural representations of identical speech sounds which have different interpretations depending on the talker will be measured to determine how deeply talker-specific knowledge affects the processing of speech sounds. If talker-specific knowledge is being used to optimize the efficiency of perceptual processing at a low level, then within-category differences should result in more similar patterns of activity, while across-category differences should result in more distinct patterns of activity.         PUBLIC HEALTH RELEVANCE: The ability to flexibly adjust the processing and representation of speech sounds depending on who is talking is absolutely fundamental to the effective and fluent comprehension of spoken language, and impairments in this ability would make daily life very difficult. Completion of the proposed research has the potential to lead to new views on neurological disorders which impact language, like Williams Syndrome and Specific Language Impairment, and possibly new classifications of these disorders. Furthermore, by linking robust speech comprehension to more general perceptual adaptation and learning, the proposed work has the potential to shed light on the underlying pathology of disorders such as Autism Spectrum Disorders, which have been hypothesized to involve deficiencies in the integration of top-down expectations and bottom-up sensory information, both in language processing (Stewart & Ota, 2008; Yu, 2010) and general perception (Pellicano & Burr, 2012).                ","Investigating neural mechanisms for flexible, robust speech perception with fMRI",8992857,F31HD082893,"['Accent', 'Acoustics', 'Address', 'Affect', 'Area', 'Auditory', 'Auditory area', 'Behavior', 'Behavioral', 'Brain', 'Brain imaging', 'Breeding', 'Categories', 'Code', 'Cognition', 'Complement', 'Comprehension', 'Computer Simulation', 'Disease', 'Environment', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hearing', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Light', 'Linguistics', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Neurons', 'Pathology', 'Pattern', 'Peach', 'Perception', 'Play', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Perception', 'Speech Sound', 'Staging', 'Stimulus', 'Structure', 'System', 'Techniques', 'Thick', 'Training', 'Uncertainty', 'Voice', 'Williams Syndrome', 'Work', 'autism spectrum disorder', 'base', 'behavioral response', 'cognitive neuroscience', 'disease classification', 'expectation', 'experience', 'flexibility', 'improved', 'insight', 'language impairment', 'language processing', 'nervous system disorder', 'neural circuit', 'neural patterning', 'neuromechanism', 'neurophysiology', 'novel', 'public health relevance', 'relating to nervous system', 'skills', 'sound', 'specific language impairment', 'speech processing', 'statistics', 'transmission process']",NICHD,UNIVERSITY OF ROCHESTER,F31,2016,20746,0.08683848637965795
"A preschool biomarker for literacy DESCRIPTION (provided by applicant): As many as one in ten children have the poor reading and spelling skills that comprise developmental dyslexia. It is widely accepted that there is a neurological basis; however, the nature of that basis is hotly debated. Nevertheless, one consistent view is that poor phonological processing-the ability to access and manipulate the sound units of language-is involved in dyslexia. Indeed, a majority of children with reading deficits exhibit difficulties on an array of phonological processing tasks. A growing body of research has discovered that speech-sound transcription, as measured by electrophysiology, shows striking relationships with phonological processing skills and reading ability in school-age children. As such, we have developed a suite of subcortical and cortical physiological tests that probe some of the core deficits that researchers have postulated as the root elements of poor phonological processing. We will target the subcortical processing of time-varying signals and stimulus regularities, and cortical hemispheric specialization to both fast and slow signals. In a longitudinal cohort of four- to eight-year-olds, we will model the normal neurological speech transcription process, quantify its development, and examine its relationship with the development of literacy-related skills. Our intention is that by leveraging these electrophysiological probes to a pre-reading age group, a biomarker, in preschoolers, may be found that predicts a child's eventual reading skill as he/she progresses through the primary grades. If such a biomarker is found, it would pave the way for earlier and more effectively targeted intervention. As objective neurophysiological measures of literacy become available, a logical step is to apply what has been learned about subcortical and cortical physiology and their relationships with reading to young pre- readers. The outcome of the proposed work will be a deeper understanding of the biological underpinnings of literacy, particularly in pre-literate children, and a means to exploit objective biological responses as biomarkers of future literacy. This outcome will positively impact our understanding of the core deficits leading to poor reading, and has the potential to spur early intervention programs to head off the potential onset of developmental dyslexia.",A preschool biomarker for literacy,9032506,R01HD069414,"['4 year old', '8 year old', 'Acoustics', 'Affect', 'Age', 'Attention', 'Auditory', 'Auditory Brainstem Responses', 'Biological', 'Biological Markers', 'Brain Stem', 'Cerebral Dominance', 'Child', 'Code', 'Cognitive', 'Communication', 'Data', 'Development', 'Developmental reading disorder', 'Disease', 'Dyslexia', 'Early Intervention', 'Early identification', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Employee Strikes', 'Exhibits', 'Failure', 'Financial cost', 'Future', 'Genetic Transcription', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intention', 'Intervention', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Nature', 'Nervous system structure', 'Neurologic', 'Nursery Schools', 'Outcome', 'Pattern', 'Physiological', 'Physiological Processes', 'Physiology', 'Plant Roots', 'Primary Schools', 'Probability', 'Process', 'Publishing', 'Reader', 'Reading', 'Reading Disorder', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Scalp structure', 'School-Age Population', 'Schools', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Sound', 'Staging', 'Stimulus', 'Synapses', 'Technology', 'Testing', 'Time', 'Transcription Process', 'Work', 'abstracting', 'age group', 'auditory pathway', 'base', 'cognitive function', 'cognitive skill', 'cohort', 'contextual factors', 'corticofugal fiber', 'experience', 'falls', 'intervention program', 'literacy', 'literate', 'neurophysiology', 'peer', 'phonology', 'reading ability', 'reading difficulties', 'relating to nervous system', 'remediation', 'response', 'skills', 'social', 'sound', 'spelling', 'stimulus processing']",NICHD,NORTHWESTERN UNIVERSITY,R01,2016,373707,0.041506651099401826
"Neural Systems For Infant Sensitivity to Phonological Rhythmic-Temporal Patterning No abstract available PROJECT NARRATIVE  The goal of this research is to understand how all infants discover the finite set of language units in their native language from the infinite combinations of sensory stimuli around them. Specifically, we explore whether infants are sensitive to the pure timing of the stimuli (the frequency), or whether they also are sensitive to linguistic information within the stimuli (alternation of phonetic-syllabic units). The findings will help us better understand [[on a modality-free level]] how infants begin life with brain mechanisms predisposed for discovering the core [[phonological]] parts of their languages, and how we can support clinicians in identifying infants at risk for phonology-based language and reading disorders.",Neural Systems For Infant Sensitivity to Phonological Rhythmic-Temporal Patterning,9193903,F31HD087085,"['Address', 'Adult', 'Age', 'Attention', 'Auditory', 'Beginning of Life', 'Bilateral', 'Brain', 'Cell Nucleus', 'Child', 'Code', 'Cognitive', 'Complex', 'Data', 'Development', 'Elements', 'Equation', 'Eye', 'Frequencies', 'Goals', 'Growth', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Learning', 'Left', 'Life', 'Light', 'Linguistics', 'Link', 'Machine Learning', 'Modality', 'Nature', 'Near-Infrared Spectroscopy', 'Neurobiology', 'Outcome', 'Pattern', 'Phonetics', 'Play', 'Process', 'Property', 'Reading', 'Reading Disorder', 'Recruitment Activity', 'Research', 'Risk', 'Role', 'Sign Language', 'Signal Transduction', 'Site', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Superior temporal gyrus', 'System', 'Testing', 'Time', 'Tissues', 'Vision', 'Visual', 'Vocabulary', 'adjudicate', 'base', 'cognitive neuroscience', 'experience', 'gaze', 'hemodynamics', 'infancy', 'insight', 'language perception', 'neural circuit', 'novel', 'phonology', 'reading difficulties', 'relating to nervous system', 'response', 'sensory stimulus', 'social', 'sound', 'success', 'syntax']",NICHD,GALLAUDET UNIVERSITY,F31,2016,43576,0.05566878595425213
"Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants ﻿    DESCRIPTION (provided by applicant): Cochlear implants (CIs) provide hearing for over 200,000 recipients worldwide {NIDCD, 2011 #637}. These devices successfully provide high levels of speech understanding in quiet listening conditions; however, more challenging conditions degrade speech comprehension for CI recipients to a much greater degree than for normal hearing listeners {Kokkinakis, 2011 #673;Nelson, 2003 #302}. CI listeners are especially affected by reverberant conditions with even a small level of reverberation degrading comprehension to a greater degree than a large amount of steady-state noise {Hazrati, 2012 #674}. Thus, a method that mitigates the effects of reverberation has the potential to greatly improve the quality of life for CI users. Previous attempts to solve the problem of speech in reverberation for cochlear implants have not been able to be implemented in real time. Our preliminary results suggest that successful mitigation of overlap masking can result in a substantial improvement in speech recognition even if self-masking is not mitigated and we have devised an approach that can be implemented in real time. In the proposed effort, we will first improve the classifier to detect reverberation based on our successful preliminary efforts. Next we will assess the mitigation algorithm, first in normal hearing listeners and then in listeners with cochlear implants. Finally, we will implement the algorithm in real time and again test it.          PUBLIC HEALTH RELEVANCE: While cochlear implants (CIs) provide high levels of speech comprehension in quiet for over 200,000 profoundly deaf individuals worldwide, speech in quiet scenarios are rarely encountered outside of the home. The presence of noise or reverberation in the listening environment decreases speech comprehension for CI users much more rapidly than for normal-hearing listeners, and of these two conditions, reverberation has a greater negative impact. The proposed research aims to provide a robust reverberation mitigation algorithm for CI speech processors thereby improving the ability of CI users to interact in real-world listening environments.            ",Using Machine Learning to Mitigate Reverberation Effects in Cochlear Implants,8963088,R01DC014290,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Categories', 'Cochlear Implants', 'Comprehension', 'Development', 'Devices', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Frequencies', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Individual', 'Location', 'Machine Learning', 'Maps', 'Masks', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Problem Solving', 'Process', 'Quality of life', 'Recruitment Activity', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Perception', 'Stimulus', 'Surface', 'Testing', 'Time', 'base', 'improved', 'public health relevance', 'response', 'simulation', 'sound', 'speech processing', 'speech recognition', 'success']",NIDCD,DUKE UNIVERSITY,R01,2015,289263,0.11768326920382259
"Speech Prosody and Articulatory Dynamics in Spoken Language DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context. One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.",Speech Prosody and Articulatory Dynamics in Spoken Language,8828663,R01DC003172,"['Acoustics', 'Address', 'Affective', 'Articulators', 'Behavior', 'Biological Models', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Conceptions', 'Data', 'Disease', 'Engineering', 'Environment', 'Evaluation', 'Gestures', 'Grant', 'Human', 'Indium', 'Interruption', 'Investigation', 'Joints', 'Language', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Modeling', 'Movement', 'Nervous System Trauma', 'Oral cavity', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Process', 'Production', 'Property', 'Reading', 'Research', 'Research Personnel', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Source', 'Speech', 'Stream', 'Stroke', 'Structure', 'System', 'Techniques', 'Time', 'Ursidae Family', 'Work', 'autism spectrum disorder', 'base', 'cognitive function', 'cognitive load', 'constriction', 'kinematics', 'novel strategies', 'phrases', 'programs', 'research study', 'spatiotemporal', 'speech disorder diagnosis', 'speech recognition', 'syntax']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2015,472112,0.1745669433703926
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8850708,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2015,60542,0.048799147220020746
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer. PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8775639,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Communication Aids for Disabled', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Equilibrium', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Life', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Staging', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'data mining', 'diagnostic accuracy', 'digital', 'forging', 'improved', 'innovation', 'jaw movement', 'motor impairment', 'movement analysis', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'research study', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2015,584132,0.11856188213856729
"Computational characterization of language use in autism spectrum disorder DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features. Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.",Computational characterization of language use in autism spectrum disorder,9085493,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,99966,-0.026151719001363528
"Computational characterization of language use in autism spectrum disorder DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features. Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.",Computational characterization of language use in autism spectrum disorder,8913119,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,692720,-0.026151719001363528
"Neurocognitive determinants of adolescent second language literacy development DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment. The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.",Neurocognitive determinants of adolescent second language literacy development,8852664,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'English Learner', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'bilingualism', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'learning ability', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2015,576358,0.13105742167560738
"Infant statistical learning: Resilience, longevity, and specificity ﻿    DESCRIPTION (provided by applicant): Typically developing infants acquire language at a remarkable rate despite numerous perceptual and cognitive challenges. Infants may begin to learn language by tracking regularities in their environment. Specifically, research suggests that infants possess powerful computational mechanisms that may support the segmentation of words from fluent speech and facilitate word learning. The problem is that there is little research on the extent to which statistical regularities support early language acquisition under the challenging learning conditions often faced by young infants. The objective of the proposed research is to advance integrative and comprehensive theories of infant language acquisition by assessing how statistical learning supports (1) speech segmentation and word learning in background noise, (2) infants' ability to encode lexical representations in long-term memory, and (3) infants' abilities to represent newly segmented words with the appropriate level and type of detail to facilitate subsequent language learning. Three Aims will be addressed across nine experiments designed to test how statistical regularities found in natural language input support resilience, longevity, and representational specificity within a developmental framework. Infants will be familiarized with a short natural Italian language corpus and then tested on their ability o either discriminate words that have strong versus weak internal co-occurrence patterns (8- and 11-month-olds), or associate those words with novel objects (17-month-olds). Experiments are designed to tests how infants cope with simultaneous learning challenges. We will test the predictions that strong syllable co-occurrence patterns will bolster (1) speech segmentation and word learning in noise and (2) long-term memory for newly extracted words, and (3) that infants' word form representations will become more robust and specific. Results from the proposed project will advance our understanding of the learning mechanisms underlying normative language development. Individuals who are, for a variety of sensory, neurological, or developmental reasons, less adept at tracking and representing statistical regularities when faced with real-world learning challenges may be at greater risk for atypical language development. Results from the proposed research will be used to help generate and test hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods.         PUBLIC HEALTH RELEVANCE:     PROJECT NARRATIVE The proposed set of studies explores potential mechanisms underlying positive language outcomes in typically developing infants. Being at risk for atypical language development poses a major health concern. The results of the project will help us generate testable hypotheses about the causal mechanisms for specific language delays in atypical populations, such as for infants with hearing loss or infants who, for various reasons, receive sub-optimal language input during critical developmental periods, and will begin to address NIH's need for evidence-based research to guide clinical practice.            ","Infant statistical learning: Resilience, longevity, and specificity",8984582,R01HD083312,"['Address', 'Affect', 'Chiroptera', 'Cognitive', 'Complex', 'Development', 'Environment', 'Felis catus', 'Future', 'Gender', 'Health', 'Hour', 'Individual', 'Infant', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Longevity', 'Machine Learning', 'Memory', 'Nature', 'Neurologic', 'Noise', 'Outcome', 'Output', 'Pattern', 'Phonetics', 'Play', 'Population', 'Probability', 'Public Health', 'Research', 'Risk', 'Role', 'Sensory', 'Signal Transduction', 'Specificity', 'Speech', 'Stream', 'Testing', 'Variant', 'clinical application', 'clinical practice', 'coping', 'critical developmental period', 'design', 'evidence base', 'experience', 'hearing impairment', 'lexical', 'long term memory', 'natural language', 'novel', 'public health relevance', 'research study', 'resilience', 'sound', 'statistics', 'theories', 'tool', 'word learning']",NICHD,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,2015,241243,0.13058911359208208
"Verb learning and the early development of sentence comprehension DESCRIPTION (provided by applicant): Children use syntax to understand sentences and to learn verbs; this is syntactic bootstrapping. We proposed a Structure Mapping account of the origins of syntactic bootstrapping. On this account, children begin with an unlearned bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful. In the previous funding period, we tested key predictions of this account, and found strong evidence for structure-mapping. Identifying the set of nouns in sentences yields a partial representation of syntactic structure that allows toddlers to identify verbs, and to interpret novel transitive and intransitive verbs in simple sentences. The proposed research asks how syntactic bootstrapping moves beyond 'counting the nouns', scaling up to the true complexity of verbs and sentences. We focus on two data-sources: distributional learning and discourse structure. First, we propose that distributional learning creates probabilistic syntactic-semantic combinatorial knowledge about verbs. This combinatorial knowledge, also known as verb bias, permits syntactic bootstrapping, and from early in development is used online to help identify the structure and lexical content of sentences, guiding syntactic analysis. Second, we propose that a bias toward discourse continuity increases linguistic support for verb learning by allowing learners to collect evidence for arguments across nearby sentences. Verb bias guides this process, by cuing children to seek referents for missing arguments in the discourse context. To investigate these proposals we combine experiments with toddlers and preschoolers, and a computational model based on systems for automatic semantic role labeling. Experiments with children assess comprehension of familiar and invented verbs in sentences, by measuring children's visual fixations to relevant scenes or objects. Project 1 explores toddlers' encoding of syntactic-semantic combinatorial facts about verbs from listening experience. Project 2 explores toddlers' use of discourse context to guide sentence interpretation, constrained by verb bias. Project 3 asks to what extent verb bias in preschoolers changes with new distributional learning. In Project 4 we develop our computational model to investigate the same processes. Results from experiments with children constrain the features we equip the model to detect; we use the model to test the consequences of our claims for learning from corpora of natural child-directed speech. This combination of experimental and computational studies will advance scientific knowledge about how children learn their native languages, and guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how children learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy. PUBLIC HEALTH RELEVANCE: The proposed research will examine verb learning and the development of sentence comprehension, using a combination of experiments with toddlers and preschoolers, and a computational model of early sentence comprehension. Our findings should have considerable impact, for two main reasons: First, our work will shed light on how learners begin to find meaning in syntax, addressing long-standing and fundamental scientific questions about language development. Second, the findings should help us predict and understand the consequences of individual variations in the early language environment for language development: by studying how young children collect and use linguistic-distributional data about words, we can predict what kinds of data they need to make typical progress, and thus what kinds of early experiences might lead to risks for language difficulties.",Verb learning and the early development of sentence comprehension,8837036,R01HD054448,"['Accounting', 'Address', 'Behavior', 'Child', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Data Sources', 'Detection', 'Development', 'Environment', 'Event', 'Feedback', 'Funding', 'Health', 'Individual', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Link', 'Maps', 'Measures', 'Memory', 'Modeling', 'Natural Language Processing', 'Ocular Fixation', 'Participant', 'Play', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Semantics', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Uncertainty', 'Variant', 'Work', 'abstracting', 'base', 'combinatorial', 'computer studies', 'early experience', 'expectation', 'experience', 'improved', 'lexical', 'novel', 'remediation', 'research study', 'scale up', 'syntax', 'theories', 'word learning']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2015,301821,0.08118490422238503
"Statistical learning of multiple patterns in infants, adults, and monkeys DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.","Statistical learning of multiple patterns in infants, adults, and monkeys",8851635,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Health', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Manufactured football', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Soccer', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2015,208800,0.0955637726358405
"Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication ﻿    DESCRIPTION (provided by applicant): The goal of this project is to test the efficacy of a silent speech interface (SSI) as an alternative mode of oral communication for persons who are unable to use their voice (e.g., after laryngectomy, surgical removal of larynx due to the treatment of cancer). We have recently developed a real-time, interactive SSI based on a commercial electromagnetic articulograph. The SSI converts tongue and lip movement to text, and then plays back corresponding synthesized speech sounds with natural sounding voice in real-time. The SSI has potential to restore the patient's voice by identifying the patient's voice characteristics before laryngectomy. Preliminary tests on healthy participants demonstrated the feasibility of the SSI. In this project, we further evaluate the system by studying 15 participants after laryngectomy and 15 age- and gender-matched healthy controls. If successful, the SSI has the potential to transform clinical practice for speech-language pathologists other related health care professionals. The proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broad range of other speech and voice disorders.         PUBLIC HEALTH RELEVANCE: Silent speech interfaces (SSIs) are a novel alternative mode of oral communication for persons who are unable to produce speech sounds (e.g., individuals who undergo a laryngectomy, removal of larynx due to the treatment of laryngeal cancer). SSIs recognize speech sounds from articulatory data and then drive text-to-speech synthesis, which produces speech with natural sounding voice, which is one of the advantages over the current treatment options for these individuals. SSIs hold potential to even restore the patient's own voice by identifying the patient's voice characteristics before laryngectomy. Although participants after laryngectomy will be the test case in this project, the clinical implications of SSIs extend to a larger population of persons with other speech and voice disorders.                ",Real-Time Articulation-to-Speech Mapping for Enhancing Impaired Oral Communication,8957652,R03DC013990,"['Address', 'Age', 'Algorithms', 'American Cancer Society', 'Back', 'Characteristics', 'Clinical', 'Data', 'Devices', 'Diagnosis', 'Electromagnetics', 'Equilibrium', 'Excision', 'Future', 'Gender', 'Goals', 'Health', 'Health Professional', 'Human', 'Individual', 'Joints', 'Language', 'Laryngeal Prosthesis', 'Laryngectomy', 'Larynx', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Motor', 'Movement', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pathologist', 'Patients', 'Pattern', 'Performance', 'Persons', 'Play', 'Population', 'Research', 'Self-Help Devices', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Sound', 'System', 'Testing', 'Text', 'Time', 'Tongue', 'Tracheoesophageal Speech', 'United States', 'Voice', 'Voice Disorders', 'base', 'cancer therapy', 'clinical practice', 'computer science', 'efficacy testing', 'improved', 'innovative technologies', 'kinematics', 'movement analysis', 'novel', 'oral communication', 'public health relevance', 'sound']",NIDCD,UNIVERSITY OF TEXAS DALLAS,R03,2015,153000,0.15024871385509972
"A Shared Database for the Study of Phonological Development DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.",A Shared Database for the Study of Phonological Development,8787131,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2015,268514,0.09669703103371521
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development. PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8797383,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Health', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories', 'word learning']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2015,340010,0.1356575572872618
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002).         PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.                ",Clinic Interactions of a Brain-Computer Interface for Communication,8876473,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'improved', 'innovation', 'intervention program', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,665012,0.07816844702356515
"Investigating neural mechanisms for flexible, robust speech perception with fMRI     DESCRIPTION (provided by applicant): The brain is bombarded by sensory information from the world, and must extract certain pieces of useful information using limited neural resources. This means that the brain must be efficient, throwing away information that is not needed in order to focus on the most important part of the sensory information from the world. However, information that is uninformative in one situation may be highly informative in another, and thus this efficiency must be matched by flexibility. One domain where this is particularly true is speech perception, where a noisy, ambiguous sensory signal is mapped onto underlying linguistic units like phonemes, words, and sentences. This mapping changes substantially depending on who is talking. One way the brain might deal with this is to learn talker-specific representations which optimize the efficiency with which speech sounds are processed, and deploy or ""swap out"" those representations whenever the talker changes, learning new representations for new talkers as necessary. While there is some evidence that listeners do use such a strategy, little is known about the underlying neural mechanisms. This proposal seeks to clarify these mechanisms through two specific aims. First, functional magnetic resonance imaging (fMRI) will image the brains of listeners while they are hearing words from two talkers with different accents, mixed together. By comparing the areas that are active when the talker switches with areas that are active during periods of learning about each accent (as measured by behavioral responses), the circuits by which listeners learn and deploy talker-specific representations will be elucidated. Second, using multi-voxel pattern analysis techniques, the neural representations of identical speech sounds which have different interpretations depending on the talker will be measured to determine how deeply talker-specific knowledge affects the processing of speech sounds. If talker-specific knowledge is being used to optimize the efficiency of perceptual processing at a low level, then within-category differences should result in more similar patterns of activity, while across-category differences should result in more distinct patterns of activity.         PUBLIC HEALTH RELEVANCE: The ability to flexibly adjust the processing and representation of speech sounds depending on who is talking is absolutely fundamental to the effective and fluent comprehension of spoken language, and impairments in this ability would make daily life very difficult. Completion of the proposed research has the potential to lead to new views on neurological disorders which impact language, like Williams Syndrome and Specific Language Impairment, and possibly new classifications of these disorders. Furthermore, by linking robust speech comprehension to more general perceptual adaptation and learning, the proposed work has the potential to shed light on the underlying pathology of disorders such as Autism Spectrum Disorders, which have been hypothesized to involve deficiencies in the integration of top-down expectations and bottom-up sensory information, both in language processing (Stewart & Ota, 2008; Yu, 2010) and general perception (Pellicano & Burr, 2012).                ","Investigating neural mechanisms for flexible, robust speech perception with fMRI",8831930,F31HD082893,"['Accent', 'Acoustics', 'Address', 'Affect', 'Area', 'Auditory', 'Auditory area', 'Behavior', 'Behavioral', 'Brain', 'Brain imaging', 'Breeding', 'Categories', 'Code', 'Cognition', 'Complement', 'Comprehension', 'Computer Simulation', 'Disease', 'Environment', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hearing', 'Impairment', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Light', 'Linguistics', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Neurons', 'Pathology', 'Pattern', 'Peach', 'Perception', 'Play', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Perception', 'Speech Sound', 'Staging', 'Stimulus', 'Structure', 'System', 'Techniques', 'Thick', 'Training', 'Uncertainty', 'Voice', 'Williams Syndrome', 'Work', 'autism spectrum disorder', 'base', 'behavioral response', 'cognitive neuroscience', 'disease classification', 'expectation', 'experience', 'flexibility', 'improved', 'insight', 'language processing', 'nervous system disorder', 'neural circuit', 'neural patterning', 'neuromechanism', 'neurophysiology', 'novel', 'public health relevance', 'relating to nervous system', 'skills', 'sound', 'specific language impairment', 'speech processing', 'statistics', 'transmission process']",NICHD,UNIVERSITY OF ROCHESTER,F31,2015,28238,0.08683848637965795
"Multimodal Speech Translation for Assistive Communication DESCRIPTION (provided by applicant): Dysarthria, a neuromotor speech disorder impacting over 4 million Americans, is often so severe that speech is rendered unintelligible, requiring the use of augmentative and/or alternative communication (AAC) devices. These devices are dated, cumbersome and bulky. Rather than engaging in face-to-face interaction, AAC users spend a disproportionate amount of time navigating through menus of letters/icons to compose a message, which can then be spoken aloud by an integrated text-to-speech synthesis system. Thus AAC interactions are slow, effortful, unnatural, and often hinder rather than support social, educational and vocational opportunities. In fact, many AAC users continue to vocalize with familiar caregivers implying that consistent patterns must underlie dysarthric productions. It is these imprecise yet consistent productions that we propose to capture via multimodal sensors and classify using pattern recognition algorithms for speech translation. While automatic speech recognition is a viable technology for neurologically intact speakers or those with mild impairments, it fails in acoustically harsh speaking contexts and for those with more severe dysarthria. Instead, we focus on multimodal (lingual kinematic and acoustic; LinKA) representations of speech as they provide redundant and complementary channels of input for improved disambiguation. While other approaches have used computer vision, ultrasound imaging and electromyography to simultaneously estimate articulatory and acoustic parameters of speech, they are limited in portability, cost, and application to clinical settings. The current proposal leverages a novel, lightweight, wearable and low-cost array of magnetic sensors near the cheeks that can recognize the magnetic field patterns generated by a small magnetic tracer placed on the tongue to capture lingual kinematics during speech. Coupling tongue movements with the acoustic signal, captured via microphones mounted on the same headset, provides a multidimensional representation of speech that can then be translated into clear understandable speech for a new generation of wearable, speech-driven AAC devices. The proposed work will optimize the efficiency and robustness of lingual-kinematic and acoustic sensing for mobile speech translation (Aim 1), yield a standardized implementation protocol for training and independent use of the LinKA system (Aim 2), and culminate in a 2-week field test of the LinKA translator with 12 potential users with speech impairment (Aim 3). The current proposal is a first and essential step toward a low-cost, wearable, personalized communication enhancement system that can broaden communication opportunities and networks for individuals with speech impairment and thereby increase communication participation, independence and overall quality of life. PUBLIC HEALTH RELEVANCE: Neuromotor speech disorders limit communication opportunities and access to social, educational and employment activities for nearly 4 million Americans. The LinKA (Lingual Kinematic and Acoustic) system is the first low-cost, wireless and wearable technology to simultaneously capture tongue movements and corresponding acoustics of speech. Coupling multimodal speech detection with sophisticated pattern recognition algorithms and an intelligent user interface, we propose to develop the LinKA Translator - an enabling technology that would disambiguate disordered productions and translate them into clear, understandable speech to broaden communication networks for individuals with speech disorder and thereby increase quality of life and independence.",Multimodal Speech Translation for Assistive Communication,8913172,R21EB018764,"['Acoustics', 'Activities of Daily Living', 'Adherence', 'Algorithms', 'American', 'Articular Range of Motion', 'Augmentative and Alternative Communication device', 'Caregivers', 'Cheek structure', 'Clinical', 'Communication', 'Communication Aids for Disabled', 'Communication impairment', 'Computer Interface', 'Computer Vision Systems', 'Coupled', 'Coupling', 'Data', 'Detection', 'Devices', 'Disease', 'Dysarthria', 'Electromyography', 'Employment', 'Ensure', 'Eye', 'Generations', 'Hawks', 'Health', 'Impairment', 'Individual', 'Laboratories', 'Letters', 'Life', 'Magnetism', 'Modification', 'Morphologic artifacts', 'Motor', 'Movement', 'Muscle', 'Outcome Measure', 'Pattern', 'Pattern Recognition', 'Performance', 'Production', 'Protocols documentation', 'Quality of life', 'Recruitment Activity', 'Running', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Social support', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Tongue', 'Tracer', 'Training', 'Translating', 'Translations', 'Ultrasonography', 'Wheelchairs', 'Wireless Technology', 'Work', 'alternative communication', 'coping', 'cost', 'design', 'deviant', 'improved', 'iterative design', 'kinematics', 'magnetic field', 'novel', 'phrases', 'portability', 'research study', 'sensor', 'social', 'speech recognition', 'success', 'usability']",NIBIB,NORTHEASTERN UNIVERSITY,R21,2015,108940,0.152501220694851
"A preschool biomarker for literacy DESCRIPTION (provided by applicant): As many as one in ten children have the poor reading and spelling skills that comprise developmental dyslexia. It is widely accepted that there is a neurological basis; however, the nature of that basis is hotly debated. Nevertheless, one consistent view is that poor phonological processing-the ability to access and manipulate the sound units of language-is involved in dyslexia. Indeed, a majority of children with reading deficits exhibit difficulties on an array of phonological processing tasks. A growing body of research has discovered that speech-sound transcription, as measured by electrophysiology, shows striking relationships with phonological processing skills and reading ability in school-age children. As such, we have developed a suite of subcortical and cortical physiological tests that probe some of the core deficits that researchers have postulated as the root elements of poor phonological processing. We will target the subcortical processing of time-varying signals and stimulus regularities, and cortical hemispheric specialization to both fast and slow signals. In a longitudinal cohort of four- to eight-year-olds, we will model the normal neurological speech transcription process, quantify its development, and examine its relationship with the development of literacy-related skills. Our intention is that by leveraging these electrophysiological probes to a pre-reading age group, a biomarker, in preschoolers, may be found that predicts a child's eventual reading skill as he/she progresses through the primary grades. If such a biomarker is found, it would pave the way for earlier and more effectively targeted intervention. As objective neurophysiological measures of literacy become available, a logical step is to apply what has been learned about subcortical and cortical physiology and their relationships with reading to young pre- readers. The outcome of the proposed work will be a deeper understanding of the biological underpinnings of literacy, particularly in pre-literate children, and a means to exploit objective biological responses as biomarkers of future literacy. This outcome will positively impact our understanding of the core deficits leading to poor reading, and has the potential to spur early intervention programs to head off the potential onset of developmental dyslexia.",A preschool biomarker for literacy,8826794,R01HD069414,"['4 year old', '8 year old', 'Acoustics', 'Affect', 'Age', 'Attention', 'Auditory', 'Auditory Brainstem Responses', 'Biological', 'Biological Markers', 'Brain Stem', 'Cerebral Dominance', 'Child', 'Code', 'Cognitive', 'Communication', 'Data', 'Development', 'Developmental reading disorder', 'Disease', 'Dyslexia', 'Early Intervention', 'Early identification', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Employee Strikes', 'Exhibits', 'Failure', 'Financial cost', 'Future', 'Genetic Transcription', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intention', 'Intervention', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Nature', 'Nervous system structure', 'Neurologic', 'Nursery Schools', 'Outcome', 'Pattern', 'Physiological', 'Physiological Processes', 'Physiology', 'Plant Roots', 'Primary Schools', 'Probability', 'Process', 'Publishing', 'Reader', 'Reading', 'Reading Disorder', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Scalp structure', 'School-Age Population', 'Schools', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Sound', 'Staging', 'Stimulus', 'Synapses', 'Technology', 'Testing', 'Time', 'Transcription Process', 'Work', 'abstracting', 'age group', 'auditory pathway', 'base', 'cognitive function', 'cognitive skill', 'cohort', 'contextual factors', 'corticofugal fiber', 'experience', 'falls', 'intervention program', 'literacy', 'literate', 'neurophysiology', 'peer', 'phonology', 'reading ability', 'reading difficulties', 'relating to nervous system', 'remediation', 'response', 'skills', 'social', 'sound', 'spelling', 'stimulus processing']",NICHD,NORTHWESTERN UNIVERSITY,R01,2015,356936,0.041506651099401826
"Longitudinal Voice Patterns in Bipolar Disorder DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable. PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.",Longitudinal Voice Patterns in Bipolar Disorder,8843048,R34MH100404,"['Accent', 'Acoustics', 'Address', 'Algorithms', 'Anxiety Disorders', 'Behavior', 'Bipolar Depression', 'Bipolar Disorder', 'Bipolar I', 'Bipolar II', 'Car Phone', 'Cellular Phone', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Cognitive', 'Computational algorithm', 'Computer Simulation', 'Computers', 'Computing Methodologies', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Devices', 'Disease', 'Early Diagnosis', 'Emotional', 'Emotions', 'Environmental Monitoring', 'Frequencies', 'Future', 'Goals', 'Hamilton Rating Scale for Depression', 'Health', 'Human', 'Individual', 'Intervention', 'Interview', 'Knowledge', 'Longitudinal Studies', 'Loudness', 'Machine Learning', 'Manic', 'Measurable', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'Motor', 'Movement', 'Neurocognitive', 'Observer Variation', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Pattern Recognition', 'Perception', 'Periodicity', 'Personality', 'Phase', 'Population', 'Prevention', 'Process', 'Property', 'Psychiatric therapeutic procedure', 'Psychopathology', 'Psychotic Disorders', 'Recording of previous events', 'Recruitment Activity', 'Secure', 'Sensory', 'Shapes', 'Solutions', 'Speech', 'Speech Acoustics', 'Stress', 'Structure', 'Technology', 'Telephone', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'base', 'bipolar mania', 'bipolar patients', 'clinically significant', 'digital', 'heuristics', 'innovation', 'insight', 'instrument', 'lexical', 'markov model', 'mental state', 'pressure', 'programs', 'psychologic', 'research study', 'speech processing', 'statistics', 'tool']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2015,155500,0.10332824173768013
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery. PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8793776,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Health', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'behavioral outcome', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2015,386939,0.07923329285156538
"Video-based Speech Enhancement for Vision and Hearing Impairment     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Vision and Hearing Impairment,8659442,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'signal processing', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2014,230945,0.06070689423660619
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.          One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8643200,R01DC003172,"['Acoustics', 'Address', 'Affective', 'Articulators', 'Behavior', 'Biological Models', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Conceptions', 'Data', 'Disease', 'Engineering', 'Environment', 'Evaluation', 'Gestures', 'Grant', 'Human', 'Indium', 'Interruption', 'Investigation', 'Joints', 'Language', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Modeling', 'Movement', 'Nervous System Trauma', 'Oral cavity', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Process', 'Production', 'Property', 'Reading', 'Research', 'Research Personnel', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Speech', 'Stream', 'Stroke', 'Structure', 'System', 'Techniques', 'Time', 'Ursidae Family', 'Work', 'autism spectrum disorder', 'base', 'cognitive function', 'constriction', 'kinematics', 'novel strategies', 'phrases', 'programs', 'research study', 'spatiotemporal', 'speech disorder diagnosis', 'speech recognition', 'syntax']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2014,475459,0.1745669433703926
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8714196,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2014,57782,0.048799147220020746
"SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS     DESCRIPTION (provided by applicant): The purpose of this project is advance the assessment and treatment of speech motor impairments due to ALS using novel computer-based approaches. Recently developed speech movement tracking technology will be used to record movements of tongue, lips, and jaw in 50 persons with ALS and 50 healthy control participants. The speech movement data will be analyzed using custom machine learning algorithms to address three important translational needs in person with ALS: improved early detection of speech motor involvement, improved progress monitoring of speech motor decline, and improved options for maintaining oral communication. The established interdisciplinary team with expertise in data mining, speech- language pathology, clinical neurology, and spatial statistics are well positioned to conduct this research. If successful, the specific aims have the potential to transform clinical practice for speech-language pathologists, neurologists, and other related health care professionals. The propose research will enhance human health by making an impact on individuals with speech motor impairment due to ALS and potentially to a broad range of other speech motor due to stroke, traumatic brain injury, multiple sclerosis, Parkinson's disease, cerebral palsy, traumatic brain injury, and orofacial or laryngeal cancer.         PUBLIC HEALTH RELEVANCE: ALS is one of the most common motor neuron diseases. According to the National Institute of Neurological Disorders and Stroke, approximately 30,000 Americans are living with ALS (NINDS, 2003). Recent evidence suggests ALS incidence is increasing in the general population (Strong & Rosenfeld, 2003), particularly among Gulf War veterans who are nearly twice as likely to develop the disease as veterans not deployed to the Gulf (Haley, 2003). This project is focused on the development and validation of novel machine-learning based tools for improving the assessment and treatment of patients with speech motor impairments due to ALS. If successful, this research may (1) improve early detection and prognostic accuracy, (2) and address the critical need for objective outcome measures for ongoing experimental drug trials, and (3) provide information to develop a novel oral communication device for persons with moderate to severe speech impairment. These developments may ameliorate the socioeconomic burden of speech motor impairments as well as the quality of life for these patients, their families, and the people they closely interact wit.                    ",SPEECH MOVEMENT CLASSIFICATION FOR ASSESSING AND TREATING ALS,8613983,R01DC013547,"['Address', 'Age', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Cerebral Palsy', 'Classification', 'Clinical', 'Communication Aids for Disabled', 'Computers', 'Custom', 'Data', 'Data Set', 'Deglutition', 'Deterioration', 'Development', 'Device Designs', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Dysarthria', 'Early Diagnosis', 'Electromagnetics', 'Equilibrium', 'Family', 'Future', 'Gender', 'General Population', 'Goals', 'Gulf War', 'Health', 'Health Professional', 'Human', 'Impairment', 'Incidence', 'Individual', 'Jaw', 'Language', 'Life', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Monitor', 'Motor', 'Motor Neuron Disease', 'Movement', 'Multiple Sclerosis', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Neurologist', 'Neurology', 'Oral', 'Outcome Measure', 'Parkinson Disease', 'Participant', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Severities', 'Speech', 'Speech Disorders', 'Speech Intelligibility', 'Speech Synthesizers', 'Speech-Language Pathology', 'Staging', 'Stroke', 'System', 'Technology', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Wit', 'Work', 'base', 'clinical decision-making', 'clinical practice', 'data mining', 'diagnostic accuracy', 'digital', 'forging', 'improved', 'innovation', 'jaw movement', 'motor impairment', 'novel', 'novel strategies', 'oral communication', 'orofacial', 'prognostic', 'public health relevance', 'research study', 'socioeconomics', 'statistics', 'tool']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,R01,2014,642629,0.11856188213856729
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8708017,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2014,712942,-0.026151719001363528
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8687699,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'learning ability', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2014,596034,0.13105742167560738
"Verb learning and the early development of sentence comprehension     DESCRIPTION (provided by applicant): Children use syntax to understand sentences and to learn verbs; this is syntactic bootstrapping. We proposed a Structure Mapping account of the origins of syntactic bootstrapping. On this account, children begin with an unlearned bias toward one-to-one mapping between nouns in sentences and participant-roles in events. Given this bias, children find the number of nouns in a sentence inherently meaningful. In the previous funding period, we tested key predictions of this account, and found strong evidence for structure-mapping. Identifying the set of nouns in sentences yields a partial representation of syntactic structure that allows toddlers to identify verbs, and to interpret novel transitive and intransitive verbs in simple sentences. The proposed research asks how syntactic bootstrapping moves beyond 'counting the nouns', scaling up to the true complexity of verbs and sentences. We focus on two data-sources: distributional learning and discourse structure. First, we propose that distributional learning creates probabilistic syntactic-semantic combinatorial knowledge about verbs. This combinatorial knowledge, also known as verb bias, permits syntactic bootstrapping, and from early in development is used online to help identify the structure and lexical content of sentences, guiding syntactic analysis. Second, we propose that a bias toward discourse continuity increases linguistic support for verb learning by allowing learners to collect evidence for arguments across nearby sentences. Verb bias guides this process, by cuing children to seek referents for missing arguments in the discourse context. To investigate these proposals we combine experiments with toddlers and preschoolers, and a computational model based on systems for automatic semantic role labeling. Experiments with children assess comprehension of familiar and invented verbs in sentences, by measuring children's visual fixations to relevant scenes or objects. Project 1 explores toddlers' encoding of syntactic-semantic combinatorial facts about verbs from listening experience. Project 2 explores toddlers' use of discourse context to guide sentence interpretation, constrained by verb bias. Project 3 asks to what extent verb bias in preschoolers changes with new distributional learning. In Project 4 we develop our computational model to investigate the same processes. Results from experiments with children constrain the features we equip the model to detect; we use the model to test the consequences of our claims for learning from corpora of natural child-directed speech. This combination of experimental and computational studies will advance scientific knowledge about how children learn their native languages, and guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how children learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.         PUBLIC HEALTH RELEVANCE: The proposed research will examine verb learning and the development of sentence comprehension, using a combination of experiments with toddlers and preschoolers, and a computational model of early sentence comprehension. Our findings should have considerable impact, for two main reasons: First, our work will shed light on how learners begin to find meaning in syntax, addressing long-standing and fundamental scientific questions about language development. Second, the findings should help us predict and understand the consequences of individual variations in the early language environment for language development: by studying how young children collect and use linguistic-distributional data about words, we can predict what kinds of data they need to make typical progress, and thus what kinds of early experiences might lead to risks for language difficulties.            ",Verb learning and the early development of sentence comprehension,8697336,R01HD054448,"['Accounting', 'Address', 'Behavior', 'Child', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Data Sources', 'Detection', 'Development', 'Environment', 'Event', 'Feedback', 'Funding', 'Individual', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Link', 'Maps', 'Measures', 'Memory', 'Modeling', 'Natural Language Processing', 'Ocular Fixation', 'Participant', 'Play', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Semantics', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Uncertainty', 'Variant', 'Work', 'abstracting', 'base', 'combinatorial', 'computer studies', 'early experience', 'expectation', 'experience', 'improved', 'lexical', 'novel', 'public health relevance', 'remediation', 'research study', 'scale up', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2014,310072,0.08118490422238503
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.       PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8644282,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Manufactured football', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Soccer', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2014,208309,0.0955637726358405
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.        The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8601309,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2014,269616,0.09669703103371521
"Artificial Grammar Learning in Aphasia: An Implicit Learning Approach     DESCRIPTION (provided by applicant): Implicit learning procedures have the potential to greatly enhance language training, and yet have received little attention in the aphasia rehabilitation literature. Preliminary evidence of implicit learning ability in individuals with aphasia suggests that this approach could lead to less effortful language rehabilitation strategies, which may be used in combination with established methods of explicit treatment of grammatical ability. The long-term goal of the proposed work is to further the understanding of learning processes in aphasia, and to use that knowledge to engage patients in language learning strategies that will be most beneficial for language recovery. The specific objective of the proposed project is to test an implicit approach to artificial grammar learning in healthy and agrammatic aphasic individuals using a statistical learning paradigm. The central hypothesis is that implicit learning mechanisms, which are effective in deriving grammatical structure from statistical relationships in language, remain intact in individuals with aphasia, and that grammar learning is enhanced when passive language exposure is combined with active practice. The proposed research will be the first to test learning and short-term retention of an artificial phrae structure grammar under implicit learning conditions in individuals with agrammatic aphasia and healthy age-matched adults. Participants in this study will receive repeated passive exposure to the grammar on two consecutive days, and their acquisition and 24-hour retention of the grammatical rules will be evaluated by grammaticality judgment tests. The proposed research will also use the artificial grammar learning task with healthy young adults to test the relative effects of passive exposure to the grammar compared to active practice with feedback and a combination of both approaches. These contributions are significant because they are the first steps toward evaluation of an approach that utilizes patients' retained learning abilities and hence can improve the quality of life of individuals with aphasia.         PUBLIC HEALTH RELEVANCE: The proposed research aims to further the understanding of language learning strategies that are effective and efficient for healthy adults and for individual with impaired language as a result of brain damage. The successful completion of this project will promote innovative treatments that advance the recovery of communication abilities and hence improve the quality of life of individuals with acquired language disorders.                ",Artificial Grammar Learning in Aphasia: An Implicit Learning Approach,8642022,F31DC013204,"['Acquired Language Disorders', 'Activities of Daily Living', 'Adult', 'Affect', 'Age', 'Agrammatism', 'Aphasia', 'Attention', 'Brain Injuries', 'Child', 'Chronic', 'Communication', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Goals', 'Hour', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Literature', 'Machine Learning', 'Methods', 'Outcome', 'Participant', 'Patients', 'Perceptual learning', 'Procedures', 'Process', 'Property', 'Quality of life', 'Reaction Time', 'Recovery', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Staging', 'Stimulus', 'Stroke', 'Structure', 'Task Performances', 'Testing', 'Training', 'Work', 'aphasia rehabilitation', 'aphasic', 'base', 'design', 'improved', 'innovation', 'language training', 'learning ability', 'novel', 'public health relevance', 'rehabilitation strategy', 'sequence learning', 'young adult']",NIDCD,NORTHWESTERN UNIVERSITY,F31,2014,35352,0.07819718236833535
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.       PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).         ",Statistical Learning in Language Acquisition,8604165,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2014,281519,0.1356575572872618
"Multimodal Speech Translation for Assistive Communication     DESCRIPTION (provided by applicant): Dysarthria, a neuromotor speech disorder impacting over 4 million Americans, is often so severe that speech is rendered unintelligible, requiring the use of augmentative and/or alternative communication (AAC) devices. These devices are dated, cumbersome and bulky. Rather than engaging in face-to-face interaction, AAC users spend a disproportionate amount of time navigating through menus of letters/icons to compose a message, which can then be spoken aloud by an integrated text-to-speech synthesis system. Thus AAC interactions are slow, effortful, unnatural, and often hinder rather than support social, educational and vocational opportunities. In fact, many AAC users continue to vocalize with familiar caregivers implying that consistent patterns must underlie dysarthric productions. It is these imprecise yet consistent productions that we propose to capture via multimodal sensors and classify using pattern recognition algorithms for speech translation. While automatic speech recognition is a viable technology for neurologically intact speakers or those with mild impairments, it fails in acoustically harsh speaking contexts and for those with more severe dysarthria. Instead, we focus on multimodal (lingual kinematic and acoustic; LinKA) representations of speech as they provide redundant and complementary channels of input for improved disambiguation. While other approaches have used computer vision, ultrasound imaging and electromyography to simultaneously estimate articulatory and acoustic parameters of speech, they are limited in portability, cost, and application to clinical settings. The current proposal leverages a novel, lightweight, wearable and low-cost array of magnetic sensors near the cheeks that can recognize the magnetic field patterns generated by a small magnetic tracer placed on the tongue to capture lingual kinematics during speech. Coupling tongue movements with the acoustic signal, captured via microphones mounted on the same headset, provides a multidimensional representation of speech that can then be translated into clear understandable speech for a new generation of wearable, speech-driven AAC devices. The proposed work will optimize the efficiency and robustness of lingual-kinematic and acoustic sensing for mobile speech translation (Aim 1), yield a standardized implementation protocol for training and independent use of the LinKA system (Aim 2), and culminate in a 2-week field test of the LinKA translator with 12 potential users with speech impairment (Aim 3). The current proposal is a first and essential step toward a low-cost, wearable, personalized communication enhancement system that can broaden communication opportunities and networks for individuals with speech impairment and thereby increase communication participation, independence and overall quality of life.         PUBLIC HEALTH RELEVANCE: Neuromotor speech disorders limit communication opportunities and access to social, educational and employment activities for nearly 4 million Americans. The LinKA (Lingual Kinematic and Acoustic) system is the first low-cost, wireless and wearable technology to simultaneously capture tongue movements and corresponding acoustics of speech. Coupling multimodal speech detection with sophisticated pattern recognition algorithms and an intelligent user interface, we propose to develop the LinKA Translator - an enabling technology that would disambiguate disordered productions and translate them into clear, understandable speech to broaden communication networks for individuals with speech disorder and thereby increase quality of life and independence.            ",Multimodal Speech Translation for Assistive Communication,8737379,R21EB018764,"['Acoustics', 'Activities of Daily Living', 'Adherence', 'Algorithms', 'American', 'Articular Range of Motion', 'Augmentative and Alternative Communication device', 'Caregivers', 'Cheek structure', 'Clinical', 'Communication', 'Communication Aids for Disabled', 'Communication impairment', 'Computer Interface', 'Computer Vision Systems', 'Coupled', 'Coupling', 'Data', 'Detection', 'Devices', 'Disease', 'Dysarthria', 'Electromyography', 'Employment', 'Ensure', 'Eye', 'Generations', 'Hawks', 'Impairment', 'Individual', 'Laboratories', 'Letters', 'Life', 'Magnetism', 'Modification', 'Morphologic artifacts', 'Motor', 'Movement', 'Muscle', 'Outcome Measure', 'Pattern', 'Pattern Recognition', 'Performance', 'Production', 'Protocols documentation', 'Quality of life', 'Recruitment Activity', 'Reliance', 'Running', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Simulate', 'Social support', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Tongue', 'Tracer', 'Training', 'Translating', 'Translations', 'Ultrasonography', 'Wheelchairs', 'Wireless Technology', 'Work', 'alternative communication', 'coping', 'cost', 'design', 'deviant', 'improved', 'iterative design', 'kinematics', 'magnetic field', 'novel', 'phrases', 'portability', 'public health relevance', 'research study', 'sensor', 'social', 'speech recognition', 'success', 'usability']",NIBIB,NORTHEASTERN UNIVERSITY,R21,2014,97475,0.152501220694851
"Longitudinal Voice Patterns in Bipolar Disorder     DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable.         PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.                ",Longitudinal Voice Patterns in Bipolar Disorder,8658149,R34MH100404,"['Accent', 'Acoustics', 'Address', 'Algorithms', 'Anxiety Disorders', 'Behavior', 'Bipolar Depression', 'Bipolar Disorder', 'Bipolar I', 'Bipolar II', 'Car Phone', 'Cellular Phone', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Cognitive', 'Computational algorithm', 'Computer Simulation', 'Computers', 'Computing Methodologies', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Devices', 'Disease', 'Early Diagnosis', 'Emotional', 'Emotions', 'Environmental Monitoring', 'Frequencies', 'Future', 'Goals', 'Hamilton Rating Scale for Depression', 'Health', 'Human', 'Individual', 'Intervention', 'Interview', 'Knowledge', 'Longitudinal Studies', 'Loudness', 'Machine Learning', 'Manic', 'Measurable', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'Motor', 'Movement', 'Neurocognitive', 'Observer Variation', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Pattern Recognition', 'Perception', 'Periodicity', 'Personality', 'Phase', 'Population', 'Prevention', 'Process', 'Property', 'Psychiatric therapeutic procedure', 'Psychopathology', 'Psychotic Disorders', 'Recording of previous events', 'Recruitment Activity', 'Secure', 'Sensory', 'Shapes', 'Solutions', 'Speech', 'Speech Acoustics', 'Stress', 'Structure', 'Technology', 'Telephone', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'base', 'bipolar mania', 'clinically significant', 'digital', 'heuristics', 'innovation', 'insight', 'instrument', 'lexical', 'markov model', 'mental state', 'pressure', 'programs', 'psychologic', 'public health relevance', 'research study', 'speech processing', 'statistics', 'tool']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2014,272125,0.10332824173768013
"A preschool biomarker for literacy     DESCRIPTION (provided by applicant): As many as one in ten children have the poor reading and spelling skills that comprise developmental dyslexia. It is widely accepted that there is a neurological basis; however, the nature of that basis is hotly debated. Nevertheless, one consistent view is that poor phonological processing-the ability to access and manipulate the sound units of language-is involved in dyslexia. Indeed, a majority of children with reading deficits exhibit difficulties on an array of phonological processing tasks. A growing body of research has discovered that speech-sound transcription, as measured by electrophysiology, shows striking relationships with phonological processing skills and reading ability in school-age children. As such, we have developed a suite of subcortical and cortical physiological tests that probe some of the core deficits that researchers have postulated as the root elements of poor phonological processing. We will target the subcortical processing of time-varying signals and stimulus regularities, and cortical hemispheric specialization to both fast and slow signals. In a longitudinal cohort of four- to eight-year-olds, we will model the normal neurological speech transcription process, quantify its development, and examine its relationship with the development of literacy-related skills. Our intention is that by leveraging these electrophysiological probes to a pre-reading age group, a biomarker, in preschoolers, may be found that predicts a child's eventual reading skill as he/she progresses through the primary grades. If such a biomarker is found, it would pave the way for earlier and more effectively targeted intervention.          As objective neurophysiological measures of literacy become available, a logical step is to apply what has been learned about subcortical and cortical physiology and their relationships with reading to young pre- readers. The outcome of the proposed work will be a deeper understanding of the biological underpinnings of literacy, particularly in pre-literate children, and a means to exploit objective biological responses as biomarkers of future literacy. This outcome will positively impact our understanding of the core deficits leading to poor reading, and has the potential to spur early intervention programs to head off the potential onset of developmental dyslexia.            ",A preschool biomarker for literacy,8653000,R01HD069414,"['4 year old', '8 year old', 'Acoustics', 'Affect', 'Age', 'Attention', 'Auditory', 'Auditory Brainstem Responses', 'Biological', 'Biological Markers', 'Brain Stem', 'Cerebral Dominance', 'Child', 'Code', 'Cognitive', 'Communication', 'Data', 'Development', 'Developmental reading disorder', 'Disease', 'Dyslexia', 'Early Intervention', 'Early identification', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Employee Strikes', 'Exhibits', 'Failure', 'Financial cost', 'Future', 'Genetic Transcription', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intention', 'Intervention', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Nature', 'Nervous system structure', 'Neurologic', 'Nursery Schools', 'Outcome', 'Pattern', 'Physiological', 'Physiological Processes', 'Physiology', 'Plant Roots', 'Primary Schools', 'Probability', 'Process', 'Publishing', 'Reader', 'Reading', 'Reading Disorder', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Scalp structure', 'School-Age Population', 'Schools', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Sound', 'Staging', 'Stimulus', 'Synapses', 'Technology', 'Testing', 'Time', 'Transcription Process', 'Work', 'abstracting', 'age group', 'auditory pathway', 'base', 'cognitive function', 'cohort', 'contextual factors', 'corticofugal fiber', 'experience', 'falls', 'intervention program', 'literacy', 'literate', 'neurophysiology', 'peer', 'phonology', 'reading ability', 'reading difficulties', 'relating to nervous system', 'remediation', 'response', 'skills', 'social', 'sound', 'spelling', 'stimulus processing']",NICHD,NORTHWESTERN UNIVERSITY,R01,2014,355837,0.041506651099401826
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.        PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8606352,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2014,392213,0.07923329285156538
"Applying Computational Linguistics to Fundamental Components of Schizophrenia DESCRIPTION (provided by applicant): Schizophrenia is a uniquely human disorder with specific effects on the uniquely human capacity of language. Indeed, the gross and subtle language abnormalities of schizophrenia can be seen as fundamental illness components, perhaps even as part of a ""biosignature."" Bringing modern linguistics knowledge and tools to this disorder is a promising approach. We have formed a unique, inter-disciplinary collaboration (Dr. Compton, a schizophrenia researcher; Dr. Covington, a computational linguist; Dr. Lunden, a linguist specializing in phonetics; Dr. Cleary, a statistician; and Dr. Blanchard, an expert in measuring negative symptoms) to study some of the most perplexing and disabling facets of schizophrenia, the language/speech abnormalities linked closely to disorganization and negative symptoms. We will analyze speech abnormalities in patients with schizophrenia and unaffected controls. Rather than examining a single linguistic parameter, we will assess speech in ""syntactic,"" ""semantic,"" ""pragmatic,"" and ""phonetic"" domains of linguistics. We will introduce cutting- edge innovation to this area of study by assessing these indices using psycholinguistics software developed by Dr. Covington's group so that our ratings of speech abnormalities will be highly objective and ultra-reliable.  Our long-term goal is to develop multivariable models, and new methods for clinical and research settings, based on computational linguistic indices with inherent reliability from automation and proven validity. In this exploratory/developmental study, we will collect detailed symptom ratings from 100 schizophrenia patients, as well as audio-recorded speech samples and neurocognition scores from these patients and 100 controls. This study involves early/conceptual stages of new tools and models that could have a major translational impact. We strive to acquire new knowledge and then put it into action. For example, our new methods could translate into advanced clinical applications (e.g., highly reliable, voice-based monitoring of symptom progression or remission). Furthermore, our new models and methods could be a first step toward promising predictive models (e.g., combinations of factors useful in risk prediction among at-risk youth). These objectives are highly aligned with the NIMH Strategic Plan. Our 4 aims are to: (1) examine syntactic, semantic, and pragmatic linguistic parameters using computer analysis of speech, and assess their relation to disorganized symptoms; (2) examine phonetic linguistic parameters using computerized Fourier spectrum analysis of speech, and assess their relation to negative symptoms; (3) determine the combination of psycholinguistic parameters that best predicts patient versus control status; and (4) determine the combination of psycholinguistic parameters that best predicts disorganization scores and negative symptom scores among patients. Given the rich data we will collect, we will also be able to covary the effects of medication and substance use; examine variation in findings based on neutral v. emotionally laden content and spontaneous v. read speech; assess variance in linguistic measures attributable to cognitive domains; and compare results in first-episode and chronic patients. PUBLIC HEALTH RELEVANCE: Schizophrenia is an etiologically complex, heterogeneous mental disorder-ranking among the top 10 causes of disability worldwide-with those affected contending with troubling symptoms, major psychosocial problems, unparalleled societal stigma, health disparities, diverse comorbidities, and an average lifespan reduction of 25 years. We propose a study that would significantly advance knowledge of fundamental but under-studied components of the illness-speech/language abnormalities-by examining a broad array of linguistic indices using cutting-edge artificial intelligence (computational linguistics, or computrs objectively, quickly, and ultra- reliably analyzing speech). This exploratory/developmental work could have major public health significance in terms of potential for future, high-impact clinical assessment tools that can be practicably used in routine practice settings, as well as future predictive models for those at high risk of developing schizophrenia.",Applying Computational Linguistics to Fundamental Components of Schizophrenia,8792658,R21MH097999,"['Acoustics', 'Address', 'Affect', 'Alcohol or Other Drugs use', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Automation', 'Back', 'Behavioral', 'Biological Markers', 'Chronic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collaborations', 'Comorbidity', 'Complement', 'Complex', 'Computational Linguistics', 'Computer Analysis', 'Computer software', 'Computers', 'Data', 'Development', 'Discriminant Analysis', 'Disease', 'Disease remission', 'Exhibits', 'Exploratory/Developmental Grant', 'Future', 'Gender', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Language', 'Linear Regressions', 'Linguistics', 'Link', 'Longevity', 'Measurable', 'Measures', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Movement', 'National Institute of Mental Health', 'Neurobiology', 'Neurocognition', 'Neurocognitive', 'Neurocognitive Deficit', 'Oral cavity', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Phonetics', 'Positioning Attribute', 'Predictive Value', 'Psycholinguistics', 'Public Health', 'Reading', 'Research', 'Research Personnel', 'Risk', 'SCAP2 gene', 'Sampling', 'Schizophrenia', 'Semantics', 'Sensitivity and Specificity', 'Sound Spectrography', 'Spectrum Analysis', 'Speech', 'Staging', 'Strategic Planning', 'Substance Use Disorder', 'Symptoms', 'Techniques', 'Thinking', 'Tongue', 'Translating', 'Universities', 'Variant', 'Voice', 'Washington', 'Work', 'Youth', 'base', 'biosignature', 'clinical application', 'computerized', 'density', 'design', 'disability', 'health disparity', 'high risk', 'indexing', 'innovation', 'lexical', 'neglect', 'predictive modeling', 'psychosocial', 'routine practice', 'social stigma', 'software development', 'syntax', 'tool', 'treatment response']",NIMH,FEINSTEIN INSTITUTE FOR MEDICAL RESEARCH,R21,2014,192679,0.09166412954129137
"Statistical learning, memory systems, and sleep-based memory consolidation No abstract available PUBLIC HEALTH RELEVANCE:  Difficulties with language acquisition are characteristic of a wide range of disorders, such as specific language impairment and autism, and present a major barrier to normal functioning. Statistical learning, the process of extracting complex patterns from the environment, is thought to play a critical role in language acquisition, with deficits in statistical learning potentially contributing to language-related disorders. The current proposal aims to understand how learning mode influences the memory and consolidation processes that underlie statistical learning and may ultimately inform treatments for those with language-related disorders.                ","Statistical learning, memory systems, and sleep-based memory consolidation",8783740,F32HD078223,"['Area', 'Autistic Disorder', 'Awareness', 'Basal Ganglia', 'Behavioral', 'Cerebellum', 'Characteristics', 'Cognitive', 'Conscious', 'Corpus striatum structure', 'Crude Extracts', 'Cues', 'Disease', 'Dissociation', 'Electroencephalography', 'Environment', 'Event', 'Familiarity', 'Fellowship', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Image Analysis', 'Individual', 'Instruction', 'Judgment', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Light', 'Link', 'Machine Learning', 'Measures', 'Medial', 'Memory', 'Napping', 'Neocortex', 'Neurobiology', 'Participant', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Reaction Time', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Role', 'Sensory', 'Sleep', 'Slow-Wave Sleep', 'Speech', 'Stream', 'Structure', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Work', 'base', 'behavior measurement', 'career', 'density', 'implicit memory', 'insight', 'memory retrieval', 'operation', 'public health relevance', 'relating to nervous system', 'response', 'social', 'specific language impairment']",NICHD,NORTHWESTERN UNIVERSITY,F32,2014,51530,0.04498764726839039
"Video-based Speech Enhancement for Persons with Vision and Hearing Loss     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Persons with Vision and Hearing Loss,8443624,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'computerized data processing', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2013,198801,0.05868074323054732
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.          One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8445225,R01DC003172,"['Acoustics', 'Address', 'Affective', 'Articulators', 'Behavior', 'Biological Models', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Conceptions', 'Data', 'Disease', 'Engineering', 'Environment', 'Evaluation', 'Gestures', 'Grant', 'Human', 'Indium', 'Interruption', 'Investigation', 'Joints', 'Language', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Modeling', 'Movement', 'Nervous System Trauma', 'Oral cavity', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Process', 'Production', 'Property', 'Reading', 'Research', 'Research Personnel', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Speech', 'Stream', 'Stroke', 'Structure', 'System', 'Techniques', 'Time', 'Ursidae Family', 'Work', 'autism spectrum disorder', 'base', 'cognitive function', 'constriction', 'kinematics', 'novel strategies', 'phrases', 'programs', 'research study', 'spatiotemporal', 'speech disorder diagnosis', 'speech recognition', 'syntax']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2013,450674,0.1745669433703926
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8529484,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2013,692911,-0.026151719001363528
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8465250,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2013,583762,0.13105742167560738
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.       PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8448772,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2013,203525,0.0955637726358405
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.        The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8409787,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2013,265030,0.09669703103371521
"Artificial Grammar Learning in Aphasia: An Implicit Learning Approach     DESCRIPTION (provided by applicant): Implicit learning procedures have the potential to greatly enhance language training, and yet have received little attention in the aphasia rehabilitation literature. Preliminary evidence of implicit learning ability in individuals with aphasia suggests that this approach could lead to less effortful language rehabilitation strategies, which may be used in combination with established methods of explicit treatment of grammatical ability. The long-term goal of the proposed work is to further the understanding of learning processes in aphasia, and to use that knowledge to engage patients in language learning strategies that will be most beneficial for language recovery. The specific objective of the proposed project is to test an implicit approach to artificial grammar learning in healthy and agrammatic aphasic individuals using a statistical learning paradigm. The central hypothesis is that implicit learning mechanisms, which are effective in deriving grammatical structure from statistical relationships in language, remain intact in individuals with aphasia, and that grammar learning is enhanced when passive language exposure is combined with active practice. The proposed research will be the first to test learning and short-term retention of an artificial phrae structure grammar under implicit learning conditions in individuals with agrammatic aphasia and healthy age-matched adults. Participants in this study will receive repeated passive exposure to the grammar on two consecutive days, and their acquisition and 24-hour retention of the grammatical rules will be evaluated by grammaticality judgment tests. The proposed research will also use the artificial grammar learning task with healthy young adults to test the relative effects of passive exposure to the grammar compared to active practice with feedback and a combination of both approaches. These contributions are significant because they are the first steps toward evaluation of an approach that utilizes patients' retained learning abilities and hence can improve the quality of life of individuals with aphasia.         PUBLIC HEALTH RELEVANCE: The proposed research aims to further the understanding of language learning strategies that are effective and efficient for healthy adults and for individual with impaired language as a result of brain damage. The successful completion of this project will promote innovative treatments that advance the recovery of communication abilities and hence improve the quality of life of individuals with acquired language disorders.                ",Artificial Grammar Learning in Aphasia: An Implicit Learning Approach,8522948,F31DC013204,"['Acquired Language Disorders', 'Activities of Daily Living', 'Adult', 'Affect', 'Age', 'Agrammatism', 'Aphasia', 'Attention', 'Brain Injuries', 'Child', 'Chronic', 'Communication', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Goals', 'Hour', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Literature', 'Machine Learning', 'Methods', 'Outcome', 'Participant', 'Patients', 'Perceptual learning', 'Procedures', 'Process', 'Property', 'Quality of life', 'Reaction Time', 'Recovery', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Staging', 'Stimulus', 'Stroke', 'Structure', 'Task Performances', 'Testing', 'Training', 'Work', 'aphasia rehabilitation', 'aphasic', 'base', 'design', 'improved', 'innovation', 'language training', 'novel', 'public health relevance', 'rehabilitation strategy', 'sequence learning', 'young adult']",NIDCD,NORTHWESTERN UNIVERSITY,F31,2013,34908,0.07819718236833535
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8511737,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2013,289147,0.13645104378236605
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.       PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).         ",Statistical Learning in Language Acquisition,8402391,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2013,274858,0.1356575572872618
"A preschool biomarker for literacy     DESCRIPTION (provided by applicant): As many as one in ten children have the poor reading and spelling skills that comprise developmental dyslexia. It is widely accepted that there is a neurological basis; however, the nature of that basis is hotly debated. Nevertheless, one consistent view is that poor phonological processing-the ability to access and manipulate the sound units of language-is involved in dyslexia. Indeed, a majority of children with reading deficits exhibit difficulties on an array of phonological processing tasks. A growing body of research has discovered that speech-sound transcription, as measured by electrophysiology, shows striking relationships with phonological processing skills and reading ability in school-age children. As such, we have developed a suite of subcortical and cortical physiological tests that probe some of the core deficits that researchers have postulated as the root elements of poor phonological processing. We will target the subcortical processing of time-varying signals and stimulus regularities, and cortical hemispheric specialization to both fast and slow signals. In a longitudinal cohort of four- to eight-year-olds, we will model the normal neurological speech transcription process, quantify its development, and examine its relationship with the development of literacy-related skills. Our intention is that by leveraging these electrophysiological probes to a pre-reading age group, a biomarker, in preschoolers, may be found that predicts a child's eventual reading skill as he/she progresses through the primary grades. If such a biomarker is found, it would pave the way for earlier and more effectively targeted intervention.          As objective neurophysiological measures of literacy become available, a logical step is to apply what has been learned about subcortical and cortical physiology and their relationships with reading to young pre- readers. The outcome of the proposed work will be a deeper understanding of the biological underpinnings of literacy, particularly in pre-literate children, and a means to exploit objective biological responses as biomarkers of future literacy. This outcome will positively impact our understanding of the core deficits leading to poor reading, and has the potential to spur early intervention programs to head off the potential onset of developmental dyslexia.            ",A preschool biomarker for literacy,8433336,R01HD069414,"['4 year old', '8 year old', 'Acoustics', 'Affect', 'Age', 'Attention', 'Auditory', 'Auditory Brainstem Responses', 'Biological', 'Biological Markers', 'Brain Stem', 'Cerebral Dominance', 'Child', 'Code', 'Cognitive', 'Communication', 'Data', 'Development', 'Developmental reading disorder', 'Disease', 'Dyslexia', 'Early Intervention', 'Early identification', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Employee Strikes', 'Exhibits', 'Failure', 'Financial cost', 'Future', 'Genetic Transcription', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intention', 'Intervention', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Nature', 'Nervous system structure', 'Neurologic', 'Nursery Schools', 'Outcome', 'Pattern', 'Physiological', 'Physiological Processes', 'Physiology', 'Plant Roots', 'Primary Schools', 'Probability', 'Process', 'Publishing', 'Reader', 'Reading', 'Reading Disorder', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Scalp structure', 'School-Age Population', 'Schools', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Sound', 'Staging', 'Stimulus', 'Synapses', 'Technology', 'Testing', 'Time', 'Transcription Process', 'Work', 'abstracting', 'age group', 'auditory pathway', 'base', 'cognitive function', 'cohort', 'contextual factors', 'corticofugal fiber', 'experience', 'falls', 'intervention program', 'literacy', 'literate', 'neurophysiology', 'peer', 'phonology', 'relating to nervous system', 'remediation', 'response', 'skills', 'social', 'sound', 'spelling', 'stimulus processing']",NICHD,NORTHWESTERN UNIVERSITY,R01,2013,379124,0.041506651099401826
"Longitudinal Voice Patterns in Bipolar Disorder     DESCRIPTION (provided by applicant): The proposed research study will identify changes in acoustic speech parameters, using innovative cell phone based technology, in order to predict clinically significant mood state transitions in individuals with bipolar disorder. The central hypothesis is that there are quantitative changes in acoustic speech patterns that occur in advance of clinically observed mood changes. These changes is speech patterns can be identified using computational methods over longitudinal monitoring of ecologically gathered voice data that requires minimal input from the individual being observed. These computationally determined changes are imperceptible to human observation but are hypothesized to predict clinically significant mood transitions. To test this hypothesis we will study 50 rapid cycling individuals with bipolar I and II disorder and 10 healthy controls for 6 months by recording their acoustic characteristics of speech (not lexical content) while using a mobile ""smart- phone"". In this manner we are gathering data free of observer bias. We will also gather weekly clinical assessments with standardized instruments (Hamilton Depression Rating Scale and Young Mania Rating Scale) in which we will record their physical voice patterns as well. Bipolar disorder is an ideal disorder for the initial study of speech patterns in the assessment of psychopathology. It is an illness with pathological disruptions of emotion, cognitive and motor capacity. There is a periodicity of the illness pattern that oscillates between manic energized states with charged emotions and pressured rapid speech to depressed emotional phases with retarded movements and inhibited quality and quantity of speech. The successful management of patients with bipolar disorder requires ongoing clinical monitoring of mental states. Currently there are few technologies that address the challenge of monitoring individuals long-term in an ecological manner. Speech pattern recognition technology would allow for unobtrusive monitoring that can be seamlessly integrated into daily routine of mobile phone usage to predict future changes in illness states. The proposed study tests a highly innovative approach by developing a practical solution to assist in the longitudinal management of bipolar patients. Computational algorithms of analyzed speech patterns will use statistic (Gausian Mixture Models and Support Vector Machines) and dynamic (Hidden Markov Models) modeling. This project has the potential of transformative advances in the management of psychiatric disease, as speech patterns, and changes therein, are highly likely to be reflective of current and emerging psychopathology. If successful this technology will provide for the prioritization of patients for medical and psychiatric care based on computational detection of change patterns in voice and speech before they are clinically observable.         PUBLIC HEALTH RELEVANCE: This is a study that detects measurable changes in speech patterns using computer-based analyses and correlates these changes with pathological variation in clinically assessed mood states. Changes in speech patterns are likely to precede and predict clinically significant mood state changes (to mania or depression). The overall goal is to use computational methods for the early detection of mood changes that will provide the opportunity for early clinical intervention.                ",Longitudinal Voice Patterns in Bipolar Disorder,8494970,R34MH100404,"['Accent', 'Acoustics', 'Address', 'Algorithms', 'Anxiety Disorders', 'Behavior', 'Bipolar Disorder', 'Car Phone', 'Cellular Phone', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Cognitive', 'Computational algorithm', 'Computer Simulation', 'Computers', 'Computing Methodologies', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Devices', 'Disease', 'Early Diagnosis', 'Emotional', 'Emotions', 'Environmental Monitoring', 'Frequencies', 'Future', 'Goals', 'Hamilton Rating Scale for Depression', 'Health', 'Human', 'Individual', 'Intervention', 'Interview', 'Knowledge', 'Longitudinal Studies', 'Loudness', 'Machine Learning', 'Manic', 'Measurable', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'Motor', 'Movement', 'Neurocognitive', 'Observer Variation', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Pattern Recognition', 'Perception', 'Periodicity', 'Personality', 'Phase', 'Population', 'Prevention', 'Process', 'Property', 'Psychiatric therapeutic procedure', 'Psychopathology', 'Psychotic Disorders', 'Recording of previous events', 'Recruitment Activity', 'Secure', 'Sensory', 'Shapes', 'Solutions', 'Speech', 'Speech Acoustics', 'Stress', 'Structure', 'Technology', 'Telephone', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'base', 'clinically significant', 'digital', 'heuristics', 'innovation', 'insight', 'instrument', 'lexical', 'markov model', 'mental state', 'pressure', 'programs', 'psychologic', 'public health relevance', 'research study', 'speech processing', 'statistics', 'tool']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R34,2013,272125,0.10332824173768013
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.        PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8411996,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2013,377739,0.07923329285156538
"Longitudinal Analysis of Spoken Language Characteristics in the Nun Study DESCRIPTION (provided by applicant): Verbal communication is one of the most complex and vital human behaviors negatively affected by neurodegenerative disease, and previous research strongly suggests that linguistic characteristics are promising as early clinical indicators. The Nun Study data set offers a rare opportunity to investigate the application of linguistic methods to the assessment of late life cognitive deficits and the development of neurodegenerative disease. We propose to investigate rate of decline in linguistic ability using previously unanalyzed spoken autobiography audio samples repeated over four waves of assessment. Aim 1 will capitalize on work already done to digitize audio recordings of the Nun Study longitudinal spoken autobiography samples. Verbatim transcripts will be produced and will be time-aligned with the audio from each speech sample. Aim 2 will use computational linguistic methods to calculate measures of syntactic complexity and propositional content, and will evaluate the rate of change on these measures over the 41/2 year follow-up period. Mean rates of change will be estimated in those sisters with repeated speech samples available, and will be compared between those sisters with and without dementia to determine if the rate of decline in linguistic ability is associated with diagnostic status. This project leverages the extensive NIH resources already invested in the Nun Study to 1) analyze an under-utilized aspect of this valuable data set, 2) expand upon the study's early findings in the application of linguistic analysis to the study of aging and disease-development, and 3) update the analysis methodology applied to the autobiography samples by making use of automated methods from the field of computational linguistics to combine information about speech content with information from the audio recording. PUBLIC HEALTH RELEVANCE: The Nun Study data set offers a rare opportunity to study speech quality in the development of dementia. This study will investigate rate of decline in linguistic ability using previously unanalyzed spoken autobiography audio samples from the Nun Study. Rate of change will be estimated for those sisters with repeated speech samples available, and will be compared between sisters with and without dementia to determine if the rate of decline in linguistic ability is associated with diagnostic status.",Longitudinal Analysis of Spoken Language Characteristics in the Nun Study,8572958,R03AG045476,"['Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'American', 'Autobiography', 'Automated Annotation', 'Behavior', 'Behavioral', 'Biological Markers', 'Biomedical Research', 'Brain imaging', 'Cerebrospinal Fluid', 'Characteristics', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Collection', 'Communication', 'Complex', 'Data Analyses', 'Data Set', 'Dementia', 'Development', 'Diagnostic', 'Disease', 'Elderly', 'Evaluation', 'Future', 'Health', 'Human', 'Incidence', 'Investigation', 'Language', 'Lesion', 'Life', 'Linguistics', 'Link', 'Longitudinal Studies', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Neuropsychology', 'Positioning Attribute', 'Proteins', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Sister', 'Source', 'Speech', 'Symptoms', 'Testing', 'Time', 'Training', 'Transcript', 'United States National Institutes of Health', 'Update', 'Work', 'analog', 'base', 'brain tissue', 'cognitive change', 'computerized', 'digital', 'follow-up', 'healthy aging', 'longitudinal analysis', 'repository', 'syntax', 'usability']",NIA,UNIVERSITY OF MINNESOTA,R03,2013,76000,0.05634361113077137
"Applying Computational Linguistics to Fundamental Components of Schizophrenia     DESCRIPTION (provided by applicant): Schizophrenia is a uniquely human disorder with specific effects on the uniquely human capacity of language. Indeed, the gross and subtle language abnormalities of schizophrenia can be seen as fundamental illness components, perhaps even as part of a ""biosignature."" Bringing modern linguistics knowledge and tools to this disorder is a promising approach. We have formed a unique, inter-disciplinary collaboration (Dr. Compton, a schizophrenia researcher; Dr. Covington, a computational linguist; Dr. Lunden, a linguist specializing in phonetics; Dr. Cleary, a statistician; and Dr. Blanchard, an expert in measuring negative symptoms) to study some of the most perplexing and disabling facets of schizophrenia, the language/speech abnormalities linked closely to disorganization and negative symptoms. We will analyze speech abnormalities in patients with schizophrenia and unaffected controls. Rather than examining a single linguistic parameter, we will assess speech in ""syntactic,"" ""semantic,"" ""pragmatic,"" and ""phonetic"" domains of linguistics. We will introduce cutting- edge innovation to this area of study by assessing these indices using psycholinguistics software developed by Dr. Covington's group so that our ratings of speech abnormalities will be highly objective and ultra-reliable.  Our long-term goal is to develop multivariable models, and new methods for clinical and research settings, based on computational linguistic indices with inherent reliability from automation and proven validity. In this exploratory/developmental study, we will collect detailed symptom ratings from 100 schizophrenia patients, as well as audio-recorded speech samples and neurocognition scores from these patients and 100 controls. This study involves early/conceptual stages of new tools and models that could have a major translational impact. We strive to acquire new knowledge and then put it into action. For example, our new methods could translate into advanced clinical applications (e.g., highly reliable, voice-based monitoring of symptom progression or remission). Furthermore, our new models and methods could be a first step toward promising predictive models (e.g., combinations of factors useful in risk prediction among at-risk youth). These objectives are highly aligned with the NIMH Strategic Plan. Our 4 aims are to: (1) examine syntactic, semantic, and pragmatic linguistic parameters using computer analysis of speech, and assess their relation to disorganized symptoms; (2) examine phonetic linguistic parameters using computerized Fourier spectrum analysis of speech, and assess their relation to negative symptoms; (3) determine the combination of psycholinguistic parameters that best predicts patient versus control status; and (4) determine the combination of psycholinguistic parameters that best predicts disorganization scores and negative symptom scores among patients. Given the rich data we will collect, we will also be able to covary the effects of medication and substance use; examine variation in findings based on neutral v. emotionally laden content and spontaneous v. read speech; assess variance in linguistic measures attributable to cognitive domains; and compare results in first-episode and chronic patients.         PUBLIC HEALTH RELEVANCE: Schizophrenia is an etiologically complex, heterogeneous mental disorder-ranking among the top 10 causes of disability worldwide-with those affected contending with troubling symptoms, major psychosocial problems, unparalleled societal stigma, health disparities, diverse comorbidities, and an average lifespan reduction of 25 years. We propose a study that would significantly advance knowledge of fundamental but under-studied components of the illness-speech/language abnormalities-by examining a broad array of linguistic indices using cutting-edge artificial intelligence (computational linguistics, or computrs objectively, quickly, and ultra- reliably analyzing speech). This exploratory/developmental work could have major public health significance in terms of potential for future, high-impact clinical assessment tools that can be practicably used in routine practice settings, as well as future predictive models for those at high risk of developing schizophrenia.            ",Applying Computational Linguistics to Fundamental Components of Schizophrenia,8512143,R21MH097999,"['Acoustics', 'Address', 'Affect', 'Alcohol or Other Drugs use', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Automation', 'Back', 'Behavioral', 'Biological Markers', 'Chronic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collaborations', 'Comorbidity', 'Complement', 'Complex', 'Computer Analysis', 'Computer software', 'Computers', 'Data', 'Development', 'Discriminant Analysis', 'Disease', 'Disease remission', 'Exhibits', 'Exploratory/Developmental Grant', 'Future', 'Gender', 'Goals', 'Human', 'Impairment', 'Knowledge', 'Language', 'Linear Regressions', 'Linguistics', 'Link', 'Longevity', 'Measurable', 'Measures', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Movement', 'National Institute of Mental Health', 'Neurobiology', 'Neurocognition', 'Neurocognitive', 'Neurocognitive Deficit', 'Oral cavity', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Phonetics', 'Positioning Attribute', 'Predictive Value', 'Psycholinguistics', 'Public Health', 'Reading', 'Research', 'Research Personnel', 'Risk', 'SCAP2 gene', 'Sampling', 'Schizophrenia', 'Semantics', 'Sensitivity and Specificity', 'Sound Spectrography', 'Spectrum Analysis', 'Speech', 'Staging', 'Strategic Planning', 'Substance Use Disorder', 'Symptoms', 'Techniques', 'Thinking', 'Tongue', 'Translating', 'Universities', 'Variant', 'Voice', 'Washington', 'Work', 'Youth', 'base', 'biosignature', 'clinical application', 'computerized', 'density', 'design', 'disability', 'health disparity', 'high risk', 'indexing', 'innovation', 'lexical', 'neglect', 'predictive modeling', 'psychosocial', 'public health relevance', 'routine practice', 'social stigma', 'software development', 'syntax', 'tool', 'treatment response']",NIMH,GEORGE WASHINGTON UNIVERSITY,R21,2013,249349,0.09166412954129137
"Functional neuroimaging of language processing in primary progressive aphasia  Primary progressive aphasia (PPA) is a clinical syndrome in which degeneration of language regions in the dominant hemisphere is associated with progressive deficits in speech and/or language function. The overall goals of this project are to use functional magnetic resonance imaging (fMRI) to investigate neural changes underlying linguistic deficits in PPA, and to use this information to better discriminate patients with variants of PPA from each other and from normal aging. Recent studies have identified three clinical variants of PPA: progressive non-fluent aphasia (PNFA), semantic dementia (SD) and logopenic progressive aphasia (LPA). Each variant is associated with characteristic linguistic features, distinct patterns of brain atrophy, and different likelihoods of particular underlying pathogenic processes, making correct differential diagnosis highly relevant. We will recruit 48 patients with PPA (16 of each variant) and 24 normal controls over a three year period, and acquire fMRI data along with structural MRI, linguistic and cognitive measures. The fMRI paradigm consists of a syntactic processing task with seven conditions parametrically varying in syntactic complexity. The research will address two specific aims. The first is to identify the relationships between volume loss, changes in functional MRI activation, and linguistic deficits, in the different PPA variants. The second aim is to improve differential diagnosis of PPA variants using machine learning algorithms incorporating both structural and functional imaging measures.  PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8247172,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Aphasias', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Progressive Aphasias', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'relating to nervous system', 'syntax']",NIDCD,UNIVERSITY OF ARIZONA,R03,2012,121968,0.03780179903402148
"Speech Prosody and Articulatory Dynamics in Spoken Language     DESCRIPTION (provided by applicant): One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, local rate modulation, and pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities. The long term objective of the proposed research program is to understand how linguistic structure and communicative context condition the spatiotemporal realization of articulatory movement during speaking. Our linguist-engineer team studies the ""signatures"" of prosody at the level of articulatory patterning. The specific aims of this proposal are to understand and model how speakers differentially modulate the spatiotemporal organization of articulatory gestures as a function of the cognitive source of a break in the speech stream and how the communicative context influences the temporal flow of the speech stream in articulation as speakers interact with one another. We outline a research strategy that investigates the relation between speech initiation/cessation and the control and coordination of articulation. Speech may start, pause, or cease for a variety of reasons in addition to linguistically structured phrase edges. Some breaks in the speech stream may be cognitively ""planned,"" such as interlocutor turn-taking in discourse. Other disruptions in the speech stream might be ""unplanned,"" such as interruptions and word finding challenges. Our approach investigates the articulation of speech in the vocal tract at turn-taking and interruptions in structured dialogue and in the vicinity of pauses that occur for cognitive speech planning reasons. We complement this experimental work with computational modeling of phrasal junctures and pauses, and with machine learning approaches to classifying breaks in speech arising from differing sources. The specific aims will be pursued by using articulatory movement data collected with magnetometer systems for tracking movement inside the mouth and by using our team's computational model of speech production. The experiment work and the concomitant computational modeling of the articulatory findings will provide a profile of the manner in which articulatory patterning is shapd by the larger informational structuring of utterances and by the demands of speech planning in a communicative context.        PUBLIC HEALTH RELEVANCE: One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.              One powerfully communicative aspect of language is prosody, which is the use of pitch, loudness, and temporal properties such as pauses in speech to signal its informational and affective content. Speech production deficits due to neurological damage such as stroke or due to Autism Spectrum Disorder are often characterized by prosodic irregularities and understanding the influence of structural prosody and its deployment in communication on the temporal flow of speech can have critical translational impact in that disfluencies are typically used as a basis for diagnosis of speech disorders. Our research uses instrumental tracking of articulatory movements during speech to provide an understanding of normative production of modulation and pauses in speech flow that could support evidence-driven assessments and treatments of prosodic breakdown in clinical populations, including deploying assistive technologies for the impaired such as automatic speech recognition and machine speech synthesis.            ",Speech Prosody and Articulatory Dynamics in Spoken Language,8282659,R01DC003172,"['Acoustics', 'Address', 'Affective', 'Articulators', 'Behavior', 'Biological Models', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Conceptions', 'Data', 'Disease', 'Engineering', 'Environment', 'Evaluation', 'Gestures', 'Grant', 'Human', 'Indium', 'Interruption', 'Investigation', 'Joints', 'Language', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Modeling', 'Movement', 'Nervous System Trauma', 'Oral cavity', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Process', 'Production', 'Property', 'Reading', 'Research', 'Research Personnel', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Speech', 'Stream', 'Stroke', 'Structure', 'System', 'Techniques', 'Time', 'Ursidae Family', 'Work', 'autism spectrum disorder', 'base', 'cognitive function', 'constriction', 'kinematics', 'novel strategies', 'phrases', 'programs', 'research study', 'spatiotemporal', 'speech disorder diagnosis', 'speech recognition', 'syntax']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2012,549459,0.17079106357170704
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8320877,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,738723,-0.026151719001363528
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.        The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8308379,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2012,636949,0.13105742167560738
"Infant Statistical Learning in Natural Language Acquisition    DESCRIPTION (provided by applicant): Infants are adept at tracking statistical regularities to segment words in continuous speech. Researchers have documented infants' learning abilities using highly simplified artificial languages as speech input. However, natural language is replete with variability. Infants listening to speech encounter different speakers, different word lengths, and numerous other dimensions of complexity. The proposed experiments will use speech that captures key aspects of the natural variation observed in infants' language environments to test whether infants use statistical learning mechanisms in identifying word boundaries. This research will provide a rigorous test of whether statistical learning is in fact linked to early language acquisition. Specific Aim 1 is to examine how infants segment words given variability in utterance types-specifically, the presence of both continuous speech and isolated words. A preliminary study showed that isolated words enhance infants' attention to statistical regularities in fluent, natural speech. Experiment 1 will test the hypothesis that hearing words in isolation helps infants discover other words in continuous speech. Experiment 2 will explore word segmentation given variation in voices, testing whether isolated words enhance statistical learning when speech comes from multiple talkers. Specific Aim 2 is to investigate how variability in language experience influences infants' subsequent detection of statistical regularities in fluent speech. In Experiment 3, infants will first receive brief laboratory exposure to novel isolated words. This pre-familiarization is expected to constrain infants' abilities to establish word boundaries in continuous speech. Experiment 4 will test whether cross-linguistic differences in the proportion of multisyllabic words in infant-directed speech shape infants' word segmentation abilities. Spanish-learning infants, who hear far more multisyllabic words than English-learning infants over the first year, are expected to show greater facility in segmenting trisyllabic words from continuous speech than English-learning infants. The results will assess the degree to which previous learning leads to expectations that facilitate processing future speech, or whether infants' computational abilities operate continuously at each moment in time. The outcomes of these studies will inform future research exploring statistical learning abilities in young children with emergent language impairments.      PUBLIC HEALTH RELEVANCE: The goal of this research is to understand how typically developing infants discover structure in the complex speech they hear from caregivers. Future studies will use these tasks to assess language learning in children exhibiting difficulties with language (e.g., children at risk for specific language impairment, children with emergent autism spectrum disorder, or deaf children with cochlear implants). The eventual goals are to investigate whether the mechanisms responsible for learning are compromised in these clinical populations, and to develop more appropriate tools for early diagnosis and intervention.           PROJECT NARRATIVE The goal of this research is to understand how typically developing infants discover structure in the complex speech they hear from caregivers. Future studies will use these tasks to assess language learning in children exhibiting difficulties with language (e.g., children at risk for specific language impairment, children with emergent autism spectrum disorder, or deaf children with cochlear implants). The eventual goals are to investigate whether the mechanisms responsible for learning are compromised in these clinical populations, and to develop more appropriate tools for early diagnosis and intervention.",Infant Statistical Learning in Natural Language Acquisition,8262167,F32HD069094,"['Address', 'Adult', 'Affect', 'Attention', 'Caregivers', 'Characteristics', 'Child', 'Clinical', 'Cochlear Implants', 'Complex', 'Cues', 'Detection', 'Dimensions', 'Early Diagnosis', 'Early treatment', 'Environment', 'Exhibits', 'Exposure to', 'Female', 'Future', 'Goals', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Impairment', 'Infant', 'Knowledge', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Length', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Outcome Study', 'Pattern', 'Play', 'Population', 'Probability', 'Process', 'Property', 'Research', 'Research Personnel', 'Risk', 'Role', 'Shapes', 'Source', 'Speech', 'Stream', 'Structure', 'Testing', 'Time', 'Variant', 'Vocabulary', 'Voice', 'Yang', 'autism spectrum disorder', 'base', 'expectation', 'experience', 'male', 'natural language', 'novel', 'public health relevance', 'research study', 'simulation', 'specific language impairment', 'tool']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2012,22400,0.14976780168583737
"Measurement of the time course of statistical learning in word segmentation    DESCRIPTION (provided by applicant): Statistical learning refers to a wide variety of phenomena, many of which have been argued to be related to language acquisition. However, there is little agreement on the process that underlies statistical learning. Several different accounts have been proposed, but it has been difficult to differentiate between these accounts as many converge on the same end result of learning. To identify the process responsible for statistical learning, it is necessary to more closely examine behavioral data that can characterize the dynamic characteristics of learning over the course of exposure. The objective of the current project is to develop and apply a novel method for examining statistical learning of linguistic materials. This method will provide more comprehensive and sensitive results than prior methods, which will enable these experiments to distinguish between theories of statistical learning in a way that has not been previously possible. In these experiments, participants will be exposed to a stream of syllables made up for nonsense words. Within this stream, words consistently co-occur, while syllable conjunctions formed across word boundaries are less predictable. Participants will be asked to listen for a particular syllable within the speech stream, and respond with a button press when they hear it. For some of these participants, the syllable will occur in an unpredictable location (for example, go in golabu is relatively unpredictable, because it can occur after the end of any word in the speech stream). For other participants, the syllable will occur in a predictable location (for example, bu in golabu is consistently signaled by the presence of both go and la). The experiments outlined in this proposal are a first step towards a process-based, mechanistic account of statistical learning. The first experiment demonstrates that this novel methodology is feasible, and will assess the extent to which the serial reaction time measure correlates with more standard post-test measures. The second and third experiments seek to test process-level predictions of a theory of statistical learning. Experiment 2 assesses the extent to which working memory is related to performance in the task, especially on different word lengths. Experiment 3 assesses a proposal about how chunking might be supplemented by processes of comparison to make learning of non-adjacent regularities possible. Finally, Experiment 4 asks how multiple cues to segmentation are integrated while learning is occurring in real time. By identifying the dynamic characteristics of learning over the course of exposure to the input, this research will test and refine theories of statistical learning in ways that have not previously been possible.       This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.         ",Measurement of the time course of statistical learning in word segmentation,8326039,R03HD069733,"['Accounting', 'Adult', 'Agreement', 'Architecture', 'Auditory', 'Behavioral', 'Categories', 'Characteristics', 'Child', 'Cues', 'Data', 'Detection', 'Elements', 'Entropy', 'Exposure to', 'Frequencies', 'Grouping', 'Hearing', 'Human', 'Individual Differences', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Length', 'Linguistics', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neurologic', 'Outcome', 'Participant', 'Performance', 'Positioning Attribute', 'Probability', 'Process', 'Reaction Time', 'Recurrence', 'Research', 'Research Proposals', 'Shapes', 'Short-Term Memory', 'Signal Transduction', 'Simulate', 'Speech', 'Statistical sensitivity', 'Stream', 'Structure', 'Testing', 'Time', 'Visual', 'Work', 'Yang', 'auditory stimulus', 'base', 'diene', 'improved', 'insight', 'lexical', 'novel', 'phrases', 'research study', 'statistics', 'theories', 'therapy design']",NICHD,CARNEGIE-MELLON UNIVERSITY,R03,2012,78350,0.07585929164357096
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.      PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.","Statistical learning of multiple patterns in infants, adults, and monkeys",8246395,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'public health relevance', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2012,217762,0.12018310592991296
"A Shared Database for the Study of Phonological Development    DESCRIPTION (provided by applicant): The study of phonological development has important implications for the diagnosis, understanding, and treatment of developmental language disorders. It also has implications for the understanding of language patterns in stuttering, disfluency, aphasia, bilingualism, second language learning, and dementia. Recent computational advances now make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project now provides universal Internet access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not provided effective tools for phonological and phonetic analysis. PhonBank seeks to bridge this gap by providing a new database on phonological development with transcripts linked directly to audio records. It also provides a program that automates creation and analysis of these new corpora. The construction of this database is being be supported by a group of 60 researchers and their students who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data are being structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax.      PUBLIC HEALTH RELEVANCE: The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.           The study of phonological development has important implications for the diagnosis and treatment of developmental disorders such as articulatory impairment, specific language impairment, and stuttering. The tools and methods used in this area can also be used for the study of adult language disorders such as aphasia, apraxia, and dementia, as well as for understanding normal and abnormal patterns of second language learning.         ",A Shared Database for the Study of Phonological Development,8234545,R01HD051698,"['Adult', 'Algorithms', 'Aphasia', 'Area', 'Benchmarking', 'Child', 'Clinical assessments', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Educational workshop', 'Extensible Markup Language', 'Family', 'Frequencies', 'Genetic Transcription', 'Impairment', 'Internet', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Participant', 'Pattern', 'Phonetics', 'Process', 'Records', 'Research Personnel', 'Site', 'Speech Disorders', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'bilingualism', 'computer program', 'developmental disease', 'digital', 'disability', 'improved', 'lexical', 'phonology', 'programs', 'sound', 'specific language impairment', 'syntax', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2012,292839,0.10105504450528205
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8304226,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2012,302966,0.13645104378236605
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8206716,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2012,289629,0.12152633740972749
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.       PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.           Impact/Health Relevance: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8223215,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Health', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'public health relevance', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2012,395174,0.08671530664020367
"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.      PUBLIC HEALTH RELEVANCE: Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.              Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",Computational characterization of language use in autism spectrum disorder,8185086,R01DC012033,"['Affect', 'Affective', 'Age', 'Algorithms', 'Area', 'Autistic Disorder', 'Automation', 'Behavior', 'Characteristics', 'Child', 'Code', 'Computer Analysis', 'Data', 'Development', 'Diagnostic', 'Disease', 'Echolalia', 'Event', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Human', 'Language', 'Manuals', 'Measures', 'Mental disorders', 'Methods', 'National Institute of Mental Health', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurocognitive', 'Orthography', 'Outcome', 'Probability', 'Process', 'Recommendation', 'Research', 'Sampling', 'Semantics', 'Sodium Chloride', 'Specific qualifier value', 'Specificity', 'Speech', 'Staging', 'Stereotyping', 'Structure', 'Technology', 'Testing', 'Text', 'Time', 'Transcript', 'autism spectrum disorder', 'base', 'clinical practice', 'computer science', 'cost', 'data mining', 'improved', 'instrument', 'natural language', 'phrases', 'research clinical testing', 'response', 'specific language impairment', 'speech recognition']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2011,759606,-0.027720254986330642
"Linking Statistical Learning to Vocabulary Development    DESCRIPTION (provided by applicant): The research proposed in this application will investigate the connection between statistical learning and vocabulary development. Statistical learning refers to the process of detecting structure in the environment by tracking patterns present in the input. Recent experiments have revealed that infants possess remarkable statistical learning capabilities. Statistical learning may play a significant role in the precocious development of native language sound structure that occurs during the first year of life. During the second year, vocabulary development accelerates. The proposed experiments are motivated by the hypothesis that statistical learning about sounds lays a foundation for word learning. Thus, infants' ability to track statistical regularities may affect the ability to build a vocabulary. This research will examine the relation between individual differences in infants' vocabulary development and individual differences in statistical learning. The experiments will use measures of listening time and looking time to test infants' detection of novel statistical regularities, and to test their knowledge of native-language statistical regularities. Infants will participate speech, non-speech auditory, and visual statistical learning tasks in order to evaluate the coherence of statistical learning across domains. A label-learning task will also tap infants' ability to use native language statistical regularities to acquire new lexical items. In each experiment, infants' performance on experimental tasks will be integrated with measures of their real-world vocabulary development. This findings of this research promise to inform understanding of the underlying mechanism that contribute to individual differences in language acquisition.      PUBLIC HEALTH RELEVANCE: The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.           Relevance The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.",Linking Statistical Learning to Vocabulary Development,8106300,R03HD062755,"['Address', 'Affect', 'Auditory', 'Child', 'Cognitive', 'Cues', 'Detection', 'Development', 'Disadvantaged', 'Environment', 'Foundations', 'Future', 'Impairment', 'Individual Differences', 'Infant', 'Infant Development', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Pattern', 'Performance', 'Play', 'Process', 'Research', 'Risk', 'Role', 'Services', 'Signal Transduction', 'Specificity', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'Visual', 'Vocabulary', 'base', 'expectation', 'lexical', 'novel', 'prospective', 'public health relevance', 'research study', 'skills', 'sound']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2011,73680,0.11807439024737483
"Speech Therapy Robot (STR) to assist in the administration of evidence based spee    DESCRIPTION (provided by applicant): This SBIR phase I project will develop a Speech Therapy Robot (STR) to assist in the administration of evidence-based speech and language therapy to provide individualized monitoring of multiple clients simultaneously in a school setting. STR will use biologically plausible artificial intelligence models to prototype a system that is affordable, easy to use, portable and extensible to work with any number of students (clients) with disorder. Most children make some mistakes as they learn to say new words, but a speech sound disorder results when mistakes continue past a certain age. Speech sound disorders include problems with articulation (making sounds) and phonological processes (sound patterns), and it is one of the largest disabilities in the United States. Children with speech disorders are evaluated by a speech-language pathologist (SLP) and treated via speech-language intervention within the child's classroom (classroom-based) or outside of the classroom (pull-out). Multiple studies have demonstrated that classroom-based service is beneficial over pull- out service, but currently it is not widely practiced because of the many challenges facing SLPs: 1) it requires collaboration with classroom teachers and administrators who are not trained in speech-language pathology, 2) it can create a larger client-SLP ratio, 3) a small client-nonclient student in-class ratio, 4) unable to provide adequate intervention, 5) there is a large variation in severity of disorder within clients, 6) longer session hours over pull-out service. The American Speech-Language-Hearing Association (ASHA) recommendations caseloads should not exceed 40, but the median caseload is 50 in elementary and secondary schools, with high of 80 clients. This heavy workload for an SLP limits their capacity to provide effective treatment. Thus a robotic system capable of reducing the workload and assisting SLPs to provide improved individual care is highly desired by those in this field. In this Phase I SBIR, we will develop novel biologically plausible models to address these challenges by developing a robot-assisted therapy system capable of real time monitoring and assessment of client and client-provider interaction during the session, to determine client engagement, performance and to give feedback to providers in real time for improved treatment delivery. The biological models attempt to mimic the expert diagnostic capabilities of a SLP and extend it for use by non-SLPs to work with multiple clients at the same time. The solution will not require specialized training to use, allowing teachers to easily use it in their classrooms. In Phase I, we will demonstrate the feasibility and accuracy of STR. STR is not just a minor improvement over existing technologies but a technology and application that do not exist today. In Phase II, we will extend the capabilities towards a fully biologically plausible system to mimic expert human performance levels to develop a robotic system for speech-language therapy, this will be followed by clinical trials to ensure accuracy, efficacy of STR to facilitate evidence-based therapy. Variations of the system can be used towards phonology, morphology/syntax, pragmatics, language, fluency and/or vocabulary.      PUBLIC HEALTH RELEVANCE: Overall the project provides direct relevance to public health by facilitating new insights through the development of a novel biologically plausible artificial intelligence system capable of real time monitoring and assessment of verbal therapy session content in real time to determine patient engagement, performance and give feedback to providers in real time to improve treatment delivery, in a school setting. The novel biologically plausible device will significantly impact the current known methods of in classroom evaluation, monitoring and treatment of speech disorders. The project can help in substantial improvement in patient client interaction, better treatment, lower burden on speech language pathologists, and will significantly impact the current known methods, technologies, treatments, and address critical barriers to progress in the field.           Overall the project provides direct relevance to public health by facilitating new insights through the development of a novel biologically plausible artificial intelligence system capable of real time monitoring and assessment of verbal therapy session content in real time to determine patient engagement, performance and give feedback to providers in real time to improve treatment delivery, in a school setting. The novel biologically plausible device will significantly impact the current known methods of in classroom evaluation, monitoring and treatment of speech disorders. The project can help in substantial improvement in patient client interaction, better treatment, lower burden on speech language pathologists, and will significantly impact the current known methods, technologies, treatments, and address critical barriers to progress in the field.         ",Speech Therapy Robot (STR) to assist in the administration of evidence based spee,8207025,R43LM011325,"['Accent', 'Address', 'Administrator', 'Affect', 'Age', 'Algorithms', 'American Speech-Language-Hearing Association', 'Antirrhinum', 'Area', 'Artificial Intelligence', 'Auditory system', 'Biological Models', 'Caring', 'Cerebellum', 'Child', 'Client', 'Clinical Trials', 'Cognitive', 'Collaborations', 'Communication impairment', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Early identification', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Feedback', 'Florida', 'Future', 'Glosso-Sterandryl', 'Goals', 'Hour', 'Human', 'Impairment', 'Individual', 'Intervention', 'Joints', 'Language', 'Language Pathology', 'Language Therapy', 'Learning', 'Liquid substance', 'Memory', 'Methods', 'Minor', 'Modality', 'Modeling', 'Monitor', 'Morphology', 'Neurons', 'Pathologist', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phonetics', 'Process', 'Provider', 'Public Health', 'Recommendation', 'Robot', 'Robotics', 'Running', 'Schools', 'Secondary Schools', 'Services', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Source', 'Speech', 'Speech Disorders', 'Speech Sound', 'Speech Therapy', 'Speech-Language Pathology', 'Structure', 'Students', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Training', 'United States', 'Universities', 'Variant', 'Vocabulary', 'Voice', 'Work', 'Workload', 'base', 'biological systems', 'cost', 'design', 'disability', 'effective therapy', 'elementary school', 'evidence base', 'improved', 'innovation', 'insight', 'neural model', 'novel', 'phonology', 'prevent', 'professor', 'prototype', 'robot assistance', 'sound', 'speech processing', 'success', 'syntax', 'teacher']",NLM,"AVENTUSOFT, LLC",R43,2011,95949,0.1362649955897552
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,8097952,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Beryllium', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2011,14727,0.13316265358697296
"Neurocognitive determinants of adolescent second language literacy development    DESCRIPTION (provided by applicant): The problem of bilingual education has become especially acute in light of globalization, where an increasing number of countries are faced with multilingual societies. In the United States, the educational challenges associated with integrating non-native populations into society are particularly challenging for the significant cohort of language-minority individuals who come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. The proposed project comprises a comprehensive investigation of the neurocognitive parameters that affect how adolescents acquire and learn to read a new language. The project will employ a longitudinal design in which we will recruit cohorts of adolescents ranging from a basic to medium literacy level in a second language (L2) and track skill development with both behavioral and fMRI measures over 24 months. Cohorts will be recruited in both Israel and the U.S.; thus, each language will serve as both L2 and L1. Specific aims are: 1) To investigate how learning to read in L2 is jointly determined by the linguistic structure of L1 and by individual differences in neurocognitive capacities of the reader; 2) To investigate whether acquiring reading fluency in a second language necessarily depends on acquiring ""native- like"" neurocognitive markers; and 3) To investigate the linguistic and general neurocognitive consequences of learning a new set of statistical regularities in L2. In addition, a cross-sectional fourth aim contrasts Hebrew vs. Spanish as L1 in order to assess both the generality of findings from Hebrew and investigate the impact of qualitative differences in the underlying linguistic structures of an L1 on neurocognitive indices of reading English. This proposed research will directly inform theories of second language learning, and holds promise to inform research on optimal approaches to second language curriculum development. Moreover, the focus on individual differences in L2 learning, at the level of brain and behavior, will yield new insights into challenges to second language literacy acquisition, given the characteristics of an individual's native language and linguistic environment.      PUBLIC HEALTH RELEVANCE: The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.           The proposed research will contribute important foundational knowledge about second language literacy development that will inform educational and health issues in an increasingly multilingual society in which many learners come to the task of acquiring a new language after the acquisition of literacy in L1 has matured. By exploring how differences in language characteristics, in conjunction with neurocognitive individual differences, shape the trajectory of acquiring literacy skills in a new language and how those skills, in turn, impact native language performance, this proposed research aims to provide new understanding of challenges to second language literacy acquisition, given the characteristics of an individual's native language and language environment.         ",Neurocognitive determinants of adolescent second language literacy development,8186590,R01HD067364,"['Acute', 'Address', 'Adolescent', 'Adopted', 'Affect', 'Assimilations', 'Behavioral', 'Characteristics', 'Cognitive', 'Collaborations', 'Country', 'Development', 'Education', 'Educational Curriculum', 'Environment', 'Exposure to', 'Functional Magnetic Resonance Imaging', 'Health', 'Individual', 'Individual Differences', 'Investigation', 'Israel', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Light', 'Linguistics', 'Literature', 'Machine Learning', 'Measures', 'Minority', 'Neurobiology', 'Neurocognitive', 'Orthography', 'Outcome', 'Performance', 'Population', 'Property', 'Psycholinguistics', 'Reader', 'Reading', 'Recruitment Activity', 'Research', 'Role', 'Sampling', 'Semantics', 'Shapes', 'Societies', 'Structure', 'Subgroup', 'System', 'United States', 'Universities', 'Writing', 'base', 'behavior measurement', 'brain behavior', 'cognitive change', 'cohort', 'indexing', 'insight', 'literacy', 'longitudinal design', 'neural circuit', 'neural patterning', 'phonology', 'relating to nervous system', 'skills', 'theories']",NICHD,"HASKINS LABORATORIES, INC.",R01,2011,690049,0.13333304321381056
"Verb learning and the early development of sentence comprehension    DESCRIPTION (provided by applicant): A fundamental task in sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom. Verb knowledge plays a central role in this task. The verb determines what constituents can appear in the sentence, and what participant roles they will convey. In learning a new verb, a child must determine what relationship among participants the verb refers to, without the set of semantic instructions provided by the verb. The syntactic bootstrapping theory proposes that children use precursors of the adult's knowledge of syntax to understand sentences and therefore to learn verbs. This view is supported by evidence that children as young as 2 assign different meanings to verbs presented in different sentence structures. The proposed research asks what syntactic cues are helpful early in acquisition, before many of the complexities of syntax acquisition have been conquered. First, we argue that children treat the number of nouns in the sentence as a cue to its semantic predicate- argument structure. The number of nouns in the sentence is useful because it provides a probabilistic indicator of the verb's number of arguments. Second, early syntactic bootstrapping requires that children represent language experience in an abstract mental vocabulary that permits rapid generalization of syntactic learning to new verbs. Thus, we argue that language-specific grammatical learning, such as detecting the significance of word order in English, should transfer quickly to sentences containing new verbs, permitting progressively finer constraint on sentence interpretation and verb learning. This project explores how syntactic bootstrapping begins, and how it interacts with early progress in syntax acquisition. We take two complementary approaches: (1) Experiments with infants and toddlers will investigate the detection and use of the proposed simple structural cues to sentence interpretation and verb learning. (2) Computational experiments using a system for automatic semantic role labeling will test the main claims of our account using a substantial sample of natural child-directed speech. This combination of experimental and computational studies is intended to advance scientific knowledge about how children learn their native languages, and to guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how infants and toddlers learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.           n/a",Verb learning and the early development of sentence comprehension,8042604,R01HD054448,"['Accounting', 'Adopted', 'Adult', 'American', 'Architecture', 'Child', 'Comprehension', 'Computer Simulation', 'Computers', 'Cues', 'Databases', 'Detection', 'Development', 'Eating', 'Event', 'Face', 'Goals', 'Hand', 'Hearing', 'Heart', 'Infant', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Licensing', 'Linguistics', 'Mind', 'Modeling', 'Natural Language Processing', 'Participant', 'Patient Agents', 'Play', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Psyche structure', 'Psychologist', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Training', 'Vocabulary', 'Work', 'abstracting', 'base', 'computer studies', 'experience', 'feeding', 'lens', 'lexical', 'novel', 'programs', 'remediation', 'research study', 'success', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2011,291831,0.09542299010624786
"Statistical learning of multiple patterns in infants, adults, and monkeys    DESCRIPTION (provided by applicant): The overall goal of the present grant application is to understand how a naive learner collects distributional information from the environment and makes an implicit decision that the corpus of input contains either a single structure or multiple structures. Mature learners are incredibly facile at interpreting information in a context-specific manner, thereby partitioning the input into two or more sub-structures. We will investigate this question of context-specific statistical learning by studying two types of naove learners - human infants and tamarin monkeys - as well as mature adults. The specific objective of the proposed research is to determine whether and how infants learn that there are multiple patterns of information embedded in streams of speech, or that there are multiple words that refer to the same object, and to determine whether context-specific statistical learning has species-specific biases. Two types of experimental designs will be used to study context-specific statistical learning. The first uses a single change in the underlying structure. A variety of contextual cues will be introduced to signal that the underlying structure has undergone a change, and the dependent measure is whether the learner has acquired the first, the second, both the first and the second, or neither structures. The second design uses two alternating structures that are signaled by a variety of stimulus cues to partition the two underlying structures. It is important to note that in both of these designs, if the learner aggregates the structural information across the entire corpus, rather than partitioning the corpus into two subsets, no learning is possible. Thus, these designs test the ability of the learner to extract the contextual cues that partition the input into subsets. The implications of the proposed studies are fundamental to any theory of learning, but particularly to the kind of implicit (passive exposure) statistical learning that is thought to characterize much of early human development in many domains. Infants must learn - by a combination of sensitivity to distributional patterns and innate biases - that patterns of information are context-specific, as in the case of bilingualism. Our proposed experiments will extend our recent studies of human adults by determining (a) whether infants show the same pattern of learning biases (primacy effects) and context-sensitivity (to talker voice), (b) whether tamarin monkeys show these same biases and context effects, and (c) what the limits of context-specific statistical learning are in human adults and infants in both word segmentation and referential tasks.      PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.           Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the infants and adults learn the patterns of words in streams of speech and contrast this with performance in nonhuman primates. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal infants and adults can help to identify loci of language disorders and design methods for remediating disorders.         ","Statistical learning of multiple patterns in infants, adults, and monkeys",8116119,R01HD067250,"['Adult', 'American', 'Applications Grants', 'Benchmarking', 'British', 'Cues', 'Data', 'Development', 'Disease', 'Economics', 'Elements', 'Environment', 'Experimental Designs', 'Exposure to', 'Eye', 'Goals', 'Head', 'Head Movements', 'Hour', 'Human', 'Human Development', 'Infant', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Parents', 'Pattern', 'Performance', 'Phonetics', 'Procedures', 'Recovery', 'Research', 'Rivers', 'Role', 'Saguinus', 'Semantics', 'Signal Transduction', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Sum', 'System', 'Testing', 'Time', 'Variant', 'Voice', 'Work', 'auditory stimulus', 'bilingualism', 'design', 'lexical', 'man', 'nonhuman primate', 'novel', 'phonology', 'preference', 'research study', 'response', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2011,221561,0.12028616471131234
"Measurement of the time course of statistical learning in word segmentation    DESCRIPTION (provided by applicant): Statistical learning refers to a wide variety of phenomena, many of which have been argued to be related to language acquisition. However, there is little agreement on the process that underlies statistical learning. Several different accounts have been proposed, but it has been difficult to differentiate between these accounts as many converge on the same end result of learning. To identify the process responsible for statistical learning, it is necessary to more closely examine behavioral data that can characterize the dynamic characteristics of learning over the course of exposure. The objective of the current project is to develop and apply a novel method for examining statistical learning of linguistic materials. This method will provide more comprehensive and sensitive results than prior methods, which will enable these experiments to distinguish between theories of statistical learning in a way that has not been previously possible. In these experiments, participants will be exposed to a stream of syllables made up for nonsense words. Within this stream, words consistently co-occur, while syllable conjunctions formed across word boundaries are less predictable. Participants will be asked to listen for a particular syllable within the speech stream, and respond with a button press when they hear it. For some of these participants, the syllable will occur in an unpredictable location (for example, go in golabu is relatively unpredictable, because it can occur after the end of any word in the speech stream). For other participants, the syllable will occur in a predictable location (for example, bu in golabu is consistently signaled by the presence of both go and la). The experiments outlined in this proposal are a first step towards a process-based, mechanistic account of statistical learning. The first experiment demonstrates that this novel methodology is feasible, and will assess the extent to which the serial reaction time measure correlates with more standard post-test measures. The second and third experiments seek to test process-level predictions of a theory of statistical learning. Experiment 2 assesses the extent to which working memory is related to performance in the task, especially on different word lengths. Experiment 3 assesses a proposal about how chunking might be supplemented by processes of comparison to make learning of non-adjacent regularities possible. Finally, Experiment 4 asks how multiple cues to segmentation are integrated while learning is occurring in real time. By identifying the dynamic characteristics of learning over the course of exposure to the input, this research will test and refine theories of statistical learning in ways that have not previously been possible.      PUBLIC HEALTH RELEVANCE:This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.          This research proposal will provide insight into the mechanisms underlying language learning. Understanding these mechanisms is critically important for designing interventions that improve language acquisition in both atypically developing children, and adults struggling to acquire a second language.         ",Measurement of the time course of statistical learning in word segmentation,8176333,R03HD069733,"['Accounting', 'Adult', 'Agreement', 'Architecture', 'Auditory', 'Behavioral', 'Categories', 'Characteristics', 'Child', 'Cues', 'Data', 'Detection', 'Elements', 'Entropy', 'Exposure to', 'Frequencies', 'Grouping', 'Hearing', 'Human', 'Individual Differences', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Length', 'Linguistics', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neurologic', 'Outcome', 'Participant', 'Performance', 'Positioning Attribute', 'Probability', 'Process', 'Reaction Time', 'Recurrence', 'Research', 'Research Proposals', 'Shapes', 'Short-Term Memory', 'Signal Transduction', 'Simulate', 'Speech', 'Statistical sensitivity', 'Stream', 'Structure', 'Testing', 'Time', 'Visual', 'Work', 'Yang', 'auditory stimulus', 'base', 'diene', 'improved', 'insight', 'lexical', 'novel', 'phrases', 'research study', 'statistics', 'theories', 'therapy design']",NICHD,CARNEGIE-MELLON UNIVERSITY,R03,2011,78350,0.0989076840663363
"Infant Statistical Learning in Natural Language Acquisition    DESCRIPTION (provided by applicant): Infants are adept at tracking statistical regularities to segment words in continuous speech. Researchers have documented infants' learning abilities using highly simplified artificial languages as speech input. However, natural language is replete with variability. Infants listening to speech encounter different speakers, different word lengths, and numerous other dimensions of complexity. The proposed experiments will use speech that captures key aspects of the natural variation observed in infants' language environments to test whether infants use statistical learning mechanisms in identifying word boundaries. This research will provide a rigorous test of whether statistical learning is in fact linked to early language acquisition. Specific Aim 1 is to examine how infants segment words given variability in utterance types-specifically, the presence of both continuous speech and isolated words. A preliminary study showed that isolated words enhance infants' attention to statistical regularities in fluent, natural speech. Experiment 1 will test the hypothesis that hearing words in isolation helps infants discover other words in continuous speech. Experiment 2 will explore word segmentation given variation in voices, testing whether isolated words enhance statistical learning when speech comes from multiple talkers. Specific Aim 2 is to investigate how variability in language experience influences infants' subsequent detection of statistical regularities in fluent speech. In Experiment 3, infants will first receive brief laboratory exposure to novel isolated words. This pre-familiarization is expected to constrain infants' abilities to establish word boundaries in continuous speech. Experiment 4 will test whether cross-linguistic differences in the proportion of multisyllabic words in infant-directed speech shape infants' word segmentation abilities. Spanish-learning infants, who hear far more multisyllabic words than English-learning infants over the first year, are expected to show greater facility in segmenting trisyllabic words from continuous speech than English-learning infants. The results will assess the degree to which previous learning leads to expectations that facilitate processing future speech, or whether infants' computational abilities operate continuously at each moment in time. The outcomes of these studies will inform future research exploring statistical learning abilities in young children with emergent language impairments.      PUBLIC HEALTH RELEVANCE: The goal of this research is to understand how typically developing infants discover structure in the complex speech they hear from caregivers. Future studies will use these tasks to assess language learning in children exhibiting difficulties with language (e.g., children at risk for specific language impairment, children with emergent autism spectrum disorder, or deaf children with cochlear implants). The eventual goals are to investigate whether the mechanisms responsible for learning are compromised in these clinical populations, and to develop more appropriate tools for early diagnosis and intervention.           The goal of this research is to understand how typically developing infants discover structure in the complex speech they hear from caregivers. Future studies will use these tasks to assess language learning in children exhibiting difficulties with language (e.g., children at risk for specific language impairment, children with emergent autism spectrum disorder, or deaf children with cochlear implants). The eventual goals are to investigate whether the mechanisms responsible for learning are compromised in these clinical populations, and to develop more appropriate tools for early diagnosis and intervention.         ",Infant Statistical Learning in Natural Language Acquisition,8124530,F32HD069094,"['Address', 'Adult', 'Affect', 'Attention', 'Caregivers', 'Characteristics', 'Child', 'Clinical', 'Cochlear Implants', 'Complex', 'Cues', 'Detection', 'Dimensions', 'Early Diagnosis', 'Early treatment', 'Environment', 'Exhibits', 'Exposure to', 'Female', 'Future', 'Goals', 'Hearing', 'Hearing Impaired Persons', 'Home environment', 'Impairment', 'Infant', 'Knowledge', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Length', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Outcome Study', 'Pattern', 'Play', 'Population', 'Probability', 'Process', 'Property', 'Research', 'Research Personnel', 'Research Training', 'Risk', 'Role', 'Shapes', 'Source', 'Speech', 'Stream', 'Structure', 'Testing', 'Time', 'Variant', 'Vocabulary', 'Voice', 'Yang', 'autism spectrum disorder', 'base', 'expectation', 'experience', 'male', 'natural language', 'novel', 'research study', 'simulation', 'specific language impairment', 'tool']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2011,48398,0.14984265821244594
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,8101854,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2011,302966,0.13645104378236605
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,8015278,R37HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R37,2011,289629,0.12152633740972749
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,8044743,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical period', 'design', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'speech processing', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2011,526418,0.22241601537983632
"Functional neuroimaging of language processing in primary progressive aphasia No abstract available  PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8207220,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Aphasias', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Progressive Aphasias', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'relating to nervous system', 'syntax']",NIDCD,UNIVERSITY OF ARIZONA,R03,2011,121967,0.04592666828476215
"Developing an Evidence-Based Treatment Continuum for Spoken and Written Language    DESCRIPTION (provided by applicant): How can recovery from acquired language impairment be maximized? This question is central to the focus of every clinician and clinical researcher working with adults with aphasia, alexia, and agraphia. Nearly six decades of treatment research has yielded evidence supporting the efficacy of a wide range of language rehabilitation approaches. Unfortunately, the research efforts have been directed toward treatment approaches in isolation, and few, if any, researchers have considered the full scope and sequence of treatments necessary to maximize language recovery. In our current research, we tackled this issue with respect to the treatment of acquired agraphia, yielding evidence to support a treatment continuum for single-word writing. In the current proposal, we aim to build on the re-trained skills to maximize lexical retrieval in the spoken language modality, and to extend the treatment sequence to text-level reading and written composition. Our approach is novel in its focus on the interactive contribution of semantic, phonological, and orthographic processes. This perspective stems from evidence that literate adults have strongly established links among these three central language components, and the promotion of interactive processing of residual (and re-trained) skills in each domain can advance performance at multiple levels within the language system (sublexical, lexical, and sentence). We will examine a hierarchically structured treatment continuum where gaining mastery at a given level provides the scaffolding for advancing to the next level. A decision tree is proposed to guide the sequence for each individual in an algorithmic fashion. Using a case series approach, we propose to implement treatment with 50 individuals who reflect a diverse range of severity levels and behavioral and lesion profiles. Individual responses to treatment will be evaluated relative to performance on a comprehensive assessment of language before and after critical phases of treatment, allowing us to test the proposed algorithm. Language behavior and treatment outcomes will also be considered relative to the location and extent of brain damage affecting critical cortical networks. This work will advance the understanding of sequential treatment outcomes, and will serve to establish guidelines regarding treatment candidacy across the continuum. Ultimately, this study has the potential to change the way that clinicians plan treatment: shifting from the administration of isolated treatments to a planned sequence of interventions to maximize language recovery.       PUBLIC HEALTH RELEVANCE: More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.           More than 1 million Americans have persistent acquired language impairment due to brain damage. The rehabilitation of spoken and written language impairments is a high priority for affected individuals, and the quality and efficiency of treatment approaches are critical issues for patients, family members, speech-language pathologists, and third-party payers. The research proposed here has the potential to significantly impact the planning and implementation of behavioral treatment in a manner that maximizes recovery of function.         ",Developing an Evidence-Based Treatment Continuum for Spoken and Written Language,8132735,R01DC007646,"['Acquired Alexia', 'Address', 'Adult', 'Affect', 'Agraphia', 'Alexia', 'Algorithms', 'American', 'Aphasia', 'Behavior Therapy', 'Behavioral', 'Brain', 'Brain Injuries', 'Case Series', 'Characteristics', 'Clinical', 'Communication', 'Cues', 'Decision Making', 'Decision Trees', 'Diagnostic', 'Evaluation', 'Evidence based treatment', 'Failure', 'Family member', 'Future', 'Goals', 'Guidelines', 'Impairment', 'Individual', 'Intervention', 'Knowledge', 'Language', 'Language Disorders', 'Lesion', 'Link', 'Literature', 'Location', 'Modality', 'Oral', 'Orthography', 'Outcome', 'Participant', 'Pathologist', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Protocols documentation', 'Reading', 'Recovery', 'Recovery of Function', 'Recruitment Activity', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Semantics', 'Sequential Treatment', 'Severities', 'Speech', 'Structure', 'System', 'Testing', 'Text', 'Therapeutic', 'Third-Party Payer', 'Training', 'Treatment outcome', 'Work', 'Writing', 'aphasia rehabilitation', 'cohort', 'design', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'literate', 'novel', 'phonology', 'response', 'scaffold', 'skills training', 'stem', 'success', 'treatment planning']",NIDCD,UNIVERSITY OF ARIZONA,R01,2011,397750,0.08691363769908883
"Functional neuroimaging of language processing in primary progressive aphasia    DESCRIPTION (provided by applicant): Primary progressive aphasia (PPA) is a clinical syndrome in which degeneration of language regions in the dominant hemisphere is associated with progressive deficits in speech and/or language function. The overall goals of this project are to use functional magnetic resonance imaging (fMRI) to investigate neural changes underlying linguistic deficits in PPA, and to use this information to better discriminate patients with variants of PPA from each other and from normal aging. Recent studies have identified three clinical variants of PPA: progressive non-fluent aphasia (PNFA), semantic dementia (SD) and logopenic progressive aphasia (LPA). Each variant is associated with characteristic linguistic features, distinct patterns of brain atrophy, and different likelihoods of particular underlying pathogenic processes, making correct differential diagnosis highly relevant. We will recruit 48 patients with PPA (16 of each variant) and 24 normal controls over a three year period, and acquire fMRI data along with structural MRI, linguistic and cognitive measures. The fMRI paradigm consists of a syntactic processing task with seven conditions parametrically varying in syntactic complexity. The research will address two specific aims. The first is to identify the relationships between volume loss, changes in functional MRI activation, and linguistic deficits, in the different PPA variants. The second aim is to improve differential diagnosis of PPA variants using machine learning algorithms incorporating both structural and functional imaging measures.      PUBLIC HEALTH RELEVANCE: PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.              PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,7882100,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Receptive aphasia', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'public health relevance', 'relating to nervous system', 'syntax']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R03,2010,23807,0.04765235607747432
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          n/a",Intonation in spontaneous English & Japanese dialogue,8100589,R01DC007090,"['Accounting', 'Acoustics', 'Address', 'Artificial Intelligence', 'Attention', 'Characteristics', 'Cochlear Implants', 'Cognitive', 'Collection', 'Communication', 'Communication Aids for Disabled', 'Complex', 'Comprehension', 'Cues', 'Development', 'Devices', 'Diagnosis', 'Education', 'Engineering', 'Eye Movements', 'Future', 'Generations', 'Goals', 'Head', 'Hearing', 'Human', 'Instruction', 'Japanese Population', 'Knowledge', 'Language', 'Lead', 'Linguistics', 'Link', 'Measures', 'Memory', 'Methodology', 'Modeling', 'Monitor', 'Names', 'Nature', 'Patients', 'Pattern', 'Performance', 'Phonetics', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Vocabulary', 'Writing', 'aphasic', 'base', 'clinical application', 'cognitive function', 'disability', 'efficacy research', 'improved', 'language processing', 'lexical', 'novel', 'oral communication', 'phonology', 'phrases', 'programs', 'research study', 'speech accuracy', 'syntax', 'theories', 'transmission process']",NIDCD,OHIO STATE UNIVERSITY,R01,2010,211698,0.16899834654316018
"Linking Statistical Learning to Vocabulary Development    DESCRIPTION (provided by applicant): The research proposed in this application will investigate the connection between statistical learning and vocabulary development. Statistical learning refers to the process of detecting structure in the environment by tracking patterns present in the input. Recent experiments have revealed that infants possess remarkable statistical learning capabilities. Statistical learning may play a significant role in the precocious development of native language sound structure that occurs during the first year of life. During the second year, vocabulary development accelerates. The proposed experiments are motivated by the hypothesis that statistical learning about sounds lays a foundation for word learning. Thus, infants' ability to track statistical regularities may affect the ability to build a vocabulary. This research will examine the relation between individual differences in infants' vocabulary development and individual differences in statistical learning. The experiments will use measures of listening time and looking time to test infants' detection of novel statistical regularities, and to test their knowledge of native-language statistical regularities. Infants will participate speech, non-speech auditory, and visual statistical learning tasks in order to evaluate the coherence of statistical learning across domains. A label-learning task will also tap infants' ability to use native language statistical regularities to acquire new lexical items. In each experiment, infants' performance on experimental tasks will be integrated with measures of their real-world vocabulary development. This findings of this research promise to inform understanding of the underlying mechanism that contribute to individual differences in language acquisition.      PUBLIC HEALTH RELEVANCE: The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.           Relevance The proposed research investigates the relation between individual differences in vocabulary development and how they relate to individual differences in statistical learning, a fundamental language acquisition mechanism. The findings from this project will influence understanding of typical language development and have potential to affect understanding of language delays and disorders. By focusing research on a mechanism that is thought to play a significant role in language acquisition, we may help to reveal potential deficits and means to identify infants who are at risk of developing lasting language problems.",Linking Statistical Learning to Vocabulary Development,7990457,R03HD062755,"['Address', 'Affect', 'Auditory', 'Child', 'Cognitive', 'Cues', 'Detection', 'Development', 'Disadvantaged', 'Disease', 'Environment', 'Foundations', 'Future', 'Impairment', 'Individual Differences', 'Infant', 'Infant Development', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Pattern', 'Performance', 'Play', 'Process', 'Research', 'Risk', 'Role', 'Services', 'Signal Transduction', 'Specificity', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'Visual', 'Vocabulary', 'base', 'expectation', 'lexical', 'novel', 'prospective', 'public health relevance', 'research study', 'skills', 'sound']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2010,76500,0.11807439024737483
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,7908812,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Future', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2010,29034,0.13316265358697296
"Verb learning and the early development of sentence comprehension    DESCRIPTION (provided by applicant): A fundamental task in sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom. Verb knowledge plays a central role in this task. The verb determines what constituents can appear in the sentence, and what participant roles they will convey. In learning a new verb, a child must determine what relationship among participants the verb refers to, without the set of semantic instructions provided by the verb. The syntactic bootstrapping theory proposes that children use precursors of the adult's knowledge of syntax to understand sentences and therefore to learn verbs. This view is supported by evidence that children as young as 2 assign different meanings to verbs presented in different sentence structures. The proposed research asks what syntactic cues are helpful early in acquisition, before many of the complexities of syntax acquisition have been conquered. First, we argue that children treat the number of nouns in the sentence as a cue to its semantic predicate- argument structure. The number of nouns in the sentence is useful because it provides a probabilistic indicator of the verb's number of arguments. Second, early syntactic bootstrapping requires that children represent language experience in an abstract mental vocabulary that permits rapid generalization of syntactic learning to new verbs. Thus, we argue that language-specific grammatical learning, such as detecting the significance of word order in English, should transfer quickly to sentences containing new verbs, permitting progressively finer constraint on sentence interpretation and verb learning. This project explores how syntactic bootstrapping begins, and how it interacts with early progress in syntax acquisition. We take two complementary approaches: (1) Experiments with infants and toddlers will investigate the detection and use of the proposed simple structural cues to sentence interpretation and verb learning. (2) Computational experiments using a system for automatic semantic role labeling will test the main claims of our account using a substantial sample of natural child-directed speech. This combination of experimental and computational studies is intended to advance scientific knowledge about how children learn their native languages, and to guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how infants and toddlers learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.           n/a",Verb learning and the early development of sentence comprehension,7758297,R01HD054448,"['Accounting', 'Adopted', 'Adult', 'American', 'Architecture', 'Child', 'Comprehension', 'Computer Simulation', 'Computers', 'Cues', 'Databases', 'Detection', 'Development', 'Eating', 'Event', 'Face', 'Goals', 'Hand', 'Hearing', 'Heart', 'Infant', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Licensing', 'Linguistics', 'Mind', 'Modeling', 'Natural Language Processing', 'Participant', 'Patient Agents', 'Play', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Psyche structure', 'Psychologist', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Training', 'Vocabulary', 'Work', 'abstracting', 'base', 'computer studies', 'experience', 'feeding', 'lens', 'lexical', 'novel', 'programs', 'remediation', 'research study', 'success', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2010,304201,0.09542299010624786
"A Shared Database for the Study of Phonological Development DESCRIPTION:  The study of phonological development has important implications for the diagnosis and treatment of language disorders, models of the biological bases of language production, the teaching of second languages, and the general advancement of linguistic theory. Recents advances in computational power make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project (http://childes.psy.cmu.edu) now provides universal access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not yet built effective tools for phonological and phonetic analysis.  We will close this gap by developing a new Java-based program called Phon that interfaces with the CHILDES transcription format. Phon provides: (1) easy user-controlled utterance boundary marking, (2) an input method for Unicode IPA transcription of child forms, (3) automatic alignment of segments in child forms to waveform regions, (4) automatic insertion of the IPA form for adult target words, (5) automatic alignment of child forms to the adult targets for both segmental and prosodic levels, (6) tools for querying the database, and (7) tools for composing output reports. Phon will be configured to run either locally or over the web as a Java WebStart application. The construction of the new database will be supported by a group of 26 researchers who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data will be structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. Benchmarks will be established to emphasize the direct competitive teasting of competing hypotheses from alternative theoretical and methodological positions. n/a",A Shared Database for the Study of Phonological Development,7813998,R01HD051698,"['Acoustics', 'Adult', 'Algorithms', 'Benchmarking', 'Biological', 'Child', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease model', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Extensible Markup Language', 'Frequencies', 'Generations', 'Genetic Transcription', 'Goals', 'Individual Differences', 'Internet', 'Java', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Output', 'Participant', 'Pattern', 'Phonetics', 'Positioning Attribute', 'Production', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Running', 'Series', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'digital', 'disability', 'lexical', 'member', 'phonology', 'programs', 'sound', 'syntax', 'theories', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2010,223419,0.06242650349155976
"Cognitive Representation in Specific Language Impairment    DESCRIPTION (provided by applicant): The purpose of this project is to investigate the nature of implicit learning in children with Specific Language Impairment (SLI). A key question is whether the language impairments seen in these children are due to impaired cognitive processing mechanisms or are a representational deficit in a specific grammar module. Recently, it has been proposed that: (1) the syntax, morphology, auditory processing, and working memory deficits seen in children with SLI are due instead to a procedural implicit learning deficit, and (2) the relatively spared vocabulary abilities in children with SLI suggests an intact declarative learning system that may function as a compensatory mechanism in their language acquisition. Procedural memory is used in the learning of sequential, cognitive, and perceptual motor skills. Recent work suggests, however, that SLI may instead be a domain general implicit learning impairment that extends beyond procedural learning to include category learning, statistical, and artificial grammar learning, and that this implicit learning impairment may extend beyond the perceptual motor system to include the auditory and visual modalities as well. The purpose of this project is to determine if implicit learning in children with SLI is a domain general or domain specific impairment. A total of 170 children will participate in this 5-year project, including 85 children with SLI, 7-9 years of age and 85 normal language controls (CA) matched on chronological age, nonverbal IQ, and maternal education. A total of 9 implicit learning studies are proposed. Studies 1-3 will examine directly whether implicit learning in children with SLI (N = 45) is impaired for implicit category, statistical, and artificial grammar learning on tasks designed to have auditory, visual, and perceptual motor isomorphs as compared to CA controls (N = 45). Studies 4-6 will examine the nature and time course of implicit category, statistical, and artificial grammar learning in the auditory modality and ask if this knowledge transfers to visual and perceptual motor modalities in children with SLI (N = 40) and CA controls (N = 40). Studies 7-9 ask whether implicit learning predicts not only syntax and morphology knowledge, but also vocabulary knowledge, in both children with SLI (N = 85) and CA controls (N = 85). Theoretically, these studies extend our understanding of linguistic and nonlinguistic deficits in children with SLI by clarifying the extent to which modality specific or general implicit learning deficits may contribute to the language impairments seen in these children. Clinically, these studies will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the implicit learning of abstract representations in children with SLI, and will lead to the development of effective intervention models for school-aged children with SLI who are at risk for severe difficulties in communication, reading, writing, and academic failure. PUBLIC HEALTH RELEVANCE The purpose of this project is to investigate implicit learning in children with Specific Language Impairment (SLI). There is evidence to suggest that children with SLI may have a domain general deficit in implicit learning. Implicit learning is gradual, occurring on an ongoing basis across multiple trials or exemplars, and appears to be the mechanism by which language is learned in typically developing children. The studies proposed in this project address the gap in our understanding of implicit learning abilities in children with SLI by directly examining the extent to which children with SLI may have a modality general implicit learning impairment. The findings from this research will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the language learning in children with language impairments, and will aid the development of effective intervention models for school-aged children with language impairments who are at risk for severe difficulties in communication, reading, writing, and academic failure.          n/a",Cognitive Representation in Specific Language Impairment,8070829,R01DC005650,"['9 year old', 'Address', 'Age', 'Auditory', 'Categories', 'Child', 'Cognitive', 'Collection', 'Communication', 'Complex', 'Conscious', 'Development', 'Education', 'Emotional', 'Exposure to', 'Failure', 'Habits', 'Hearing', 'Impairment', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Memory', 'Memory impairment', 'Modality', 'Modeling', 'Morphology', 'Motor', 'Motor Skills', 'Nature', 'Neurologic', 'Performance', 'Process', 'Reading', 'Research', 'Risk', 'School-Age Population', 'Secondary to', 'Short-Term Memory', 'Stimulus', 'System', 'Time', 'Visual', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'design', 'effective intervention', 'experience', 'implicit memory', 'improved', 'insight', 'lexical', 'motor skill learning', 'novel', 'procedural memory', 'public health relevance', 'specific language impairment', 'success', 'syntax', 'visual process', 'visual processing']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2010,46597,0.06549886463655095
"Sensitivity to spectral cues in infant speech perception    DESCRIPTION (provided by applicant): The proposed research will examine infants' sensitivity to multiple spectral cues in speech perception. Speech is a complex signal, with numerous acoustic cues for every consonant and vowel. Through experience, listeners learn to exploit correlations between multiple cues, making perception more efficient and robust. Adults display this knowledge through their use of cues that are spectrally local (e.g. formant transitions) as well as distributed (e.g. gross spectral shape, or tilt) to distinguish speech sounds. Although prior research has demonstrated infants' ability to distinguish many speech sounds, how they distinguish these sounds is unclear. Infants' sensitivity to individual cues, the relative importance they assign to each cue, and when they learn to exploit correlations between cues all remain poorly understood. We propose four experiments to address these questions. The first aim of this project is to investigate sensitivity to spectral cues. To address this issue, the first two experiments will examine speech perception when the natural covariance between two cues is violated or maintained. The latter two experiments will test sensitivity to changes in individual cues. The second aim is to assess relative cue salience across the lifespan. Results from the first experiment will be compared to existing data from normal-hearing and hearing-impaired elderly adult listeners who completed a similar task (Alexander & Kluender, in press; in preparation) to assess differential effects of listening experience and hearing health on perception of the same speech stimuli. We hypothesize that both 6-to-7-month-old and 11-to-12-month-old-infants will exhibit perceptual sensitivity to both spectral cues in speech perception, with 11-to-12-month-olds displaying the greatest sensitivity. We also hypothesize that younger infants may be relatively more influenced by spectrally global (e.g. tilt) cues than older infants. Our long-term objective is to better understand development of speech perception in infants with normal and compromised hearing. These results will help refine treatment methods for infants with hearing loss, and inform the use of devices such as hearing aids and cochlear implants. Public health statement: The proposed research will reveal the acoustic information infants use to distinguish speech sounds, and whether this information is used differently by adults. Knowing what infants listen for will benefit efforts to facilitate development of speech perception in children with compromised hearing. This research will also investigate when infants learn to exploit statistical regularities between cues in natural speech.             n/a",Sensitivity to spectral cues in infant speech perception,7860410,F31DC009532,"['Acoustics', 'Address', 'Adult', 'Affect', 'Age', 'Body Weight Changes', 'Child', 'Cochlear Implants', 'Complex', 'Conflict (Psychology)', 'Cues', 'Data', 'Development', 'Devices', 'Elderly', 'Environment', 'Exhibits', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Individual', 'Infant', 'Knowledge', 'Learning', 'Light', 'Longevity', 'Machine Learning', 'Methods', 'Modality', 'Perception', 'Population', 'Preparation', 'Public Health', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Resolution', 'Sensorineural Hearing Loss', 'Sensory', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'System', 'Testing', 'Voice', 'Weight', 'base', 'experience', 'hearing impairment', 'infancy', 'research study', 'response', 'sound']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2010,27620,0.13406942416529313
"Cognitive Representation in Specific Language Impairment    DESCRIPTION (provided by applicant): The purpose of this project is to investigate the nature of implicit learning in children with Specific Language Impairment (SLI). A key question is whether the language impairments seen in these children are due to impaired cognitive processing mechanisms or are a representational deficit in a specific grammar module. Recently, it has been proposed that: (1) the syntax, morphology, auditory processing, and working memory deficits seen in children with SLI are due instead to a procedural implicit learning deficit, and (2) the relatively spared vocabulary abilities in children with SLI suggests an intact declarative learning system that may function as a compensatory mechanism in their language acquisition. Procedural memory is used in the learning of sequential, cognitive, and perceptual motor skills. Recent work suggests, however, that SLI may instead be a domain general implicit learning impairment that extends beyond procedural learning to include category learning, statistical, and artificial grammar learning, and that this implicit learning impairment may extend beyond the perceptual motor system to include the auditory and visual modalities as well. The purpose of this project is to determine if implicit learning in children with SLI is a domain general or domain specific impairment. A total of 170 children will participate in this 5-year project, including 85 children with SLI, 7-9 years of age and 85 normal language controls (CA) matched on chronological age, nonverbal IQ, and maternal education. A total of 9 implicit learning studies are proposed. Studies 1-3 will examine directly whether implicit learning in children with SLI (N = 45) is impaired for implicit category, statistical, and artificial grammar learning on tasks designed to have auditory, visual, and perceptual motor isomorphs as compared to CA controls (N = 45). Studies 4-6 will examine the nature and time course of implicit category, statistical, and artificial grammar learning in the auditory modality and ask if this knowledge transfers to visual and perceptual motor modalities in children with SLI (N = 40) and CA controls (N = 40). Studies 7-9 ask whether implicit learning predicts not only syntax and morphology knowledge, but also vocabulary knowledge, in both children with SLI (N = 85) and CA controls (N = 85). Theoretically, these studies extend our understanding of linguistic and nonlinguistic deficits in children with SLI by clarifying the extent to which modality specific or general implicit learning deficits may contribute to the language impairments seen in these children. Clinically, these studies will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the implicit learning of abstract representations in children with SLI, and will lead to the development of effective intervention models for school-aged children with SLI who are at risk for severe difficulties in communication, reading, writing, and academic failure. PUBLIC HEALTH RELEVANCE The purpose of this project is to investigate implicit learning in children with Specific Language Impairment (SLI). There is evidence to suggest that children with SLI may have a domain general deficit in implicit learning. Implicit learning is gradual, occurring on an ongoing basis across multiple trials or exemplars, and appears to be the mechanism by which language is learned in typically developing children. The studies proposed in this project address the gap in our understanding of implicit learning abilities in children with SLI by directly examining the extent to which children with SLI may have a modality general implicit learning impairment. The findings from this research will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the language learning in children with language impairments, and will aid the development of effective intervention models for school-aged children with language impairments who are at risk for severe difficulties in communication, reading, writing, and academic failure.          n/a",Cognitive Representation in Specific Language Impairment,7897798,R01DC005650,"['9 year old', 'Address', 'Age', 'Auditory', 'Categories', 'Child', 'Cognitive', 'Collection', 'Communication', 'Complex', 'Conscious', 'Development', 'Education', 'Emotional', 'Exposure to', 'Failure', 'Habits', 'Hearing', 'Impairment', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Memory', 'Memory impairment', 'Modality', 'Modeling', 'Morphology', 'Motor', 'Motor Skills', 'Nature', 'Neurologic', 'Performance', 'Process', 'Reading', 'Research', 'Risk', 'School-Age Population', 'Secondary to', 'Short-Term Memory', 'Stimulus', 'System', 'Time', 'Visual', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'design', 'effective intervention', 'experience', 'implicit memory', 'improved', 'insight', 'lexical', 'motor skill learning', 'novel', 'procedural memory', 'public health relevance', 'specific language impairment', 'success', 'syntax', 'visual process', 'visual processing']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2010,197110,0.06549886463655095
"Social and Statistical Mechanisms of Prelinguistic Vocal Learning    DESCRIPTION (provided by applicant): How do infants learn to produce the sounds of their language? The vocal abilities of infants change dramatically over the first year of life. Beginning with the earliest, immature vocalizations, infants make rapid progress, typically producing their first words by 12 months of age. Along the way, they begin to produce speech-like syllables and to structure sequences of syllables in accordance with the phonological rules of their language environment. While the vocal achievements of the first year are well-described, not nearly as much is known about the mechanisms of change that drive vocal development. Most work focuses on the maturation of the vocal tract, but studies of vocal development in songbirds found that there are also social sources of developmental change. For example, young male cowbirds (Molothrus ater) rely on the reactions of females to shape their immature sounds into functional song. Based on the avian work, the investigators' preliminary studies have shown that infants can learn new patterns of vocalizing from caregivers' reactions to their babbling. How do infants use social feedback to create new, more developmentally advanced, vocalizations? The goal of the proposed research is to understand the mechanisms by which infants incorporate the phonological patterns of their language into their vocal repertoires. Based on preliminary studies, the investigators hypothesize that the contingent responses of caregivers to babbling facilitate infants' statistical learning of the phonological patterns of their language. To investigate this hypothesis, the variability and temporal contingency of speech to 9-month-old infants will be manipulated to assess their effects on vocal learning. The proposed research has important implications for educating parents in providing optimal learning environments for their infants. An understanding of the role of socially guided learning in speech and language could be used to help parents to be more sensitive to their infants' behavior in ways that would facilitate development. Investigating social influences on phonological development can also contribute to the study of speech-language pathology and of processes underlying both successful and disordered communicative development.      PUBLIC HEALTH RELEVANCE: By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).           Project Relevance By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).",Social and Statistical Mechanisms of Prelinguistic Vocal Learning,7897740,R03HD061524,"['Achievement', 'Age-Months', 'Attention', 'Birds', 'Caregivers', 'Characteristics', 'Child', 'Child Care', 'Communication', 'Communication impairment', 'Crying', 'Development', 'Down Syndrome', 'Environment', 'Feedback', 'Female', 'Fostering', 'Goals', 'Growth', 'Infant', 'Infant Behavior', 'Intervention', 'Knowledge', 'Language', 'Language Delays', 'Language Development Disorders', 'Learning', 'Life', 'Light', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mechanics', 'Motor', 'Movement', 'Nature', 'Outcome', 'Parents', 'Pathology processes', 'Pattern', 'Phonetics', 'Play', 'Preventive', 'Production', 'Provider', 'Reaction', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Snow', 'Social Environment', 'Songbirds', 'Source', 'Speech', 'Speech Perception', 'Speech-Language Pathology', 'Structure', 'Time', 'Work', 'base', 'design', 'high risk', 'insight', 'male', 'phonology', 'programs', 'public health relevance', 'response', 'social', 'sound', 'vocal learning', 'vocalization']",NICHD,CORNELL UNIVERSITY,R03,2010,78705,0.12801714967607922
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7911611,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Categories', 'Child', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2010,312811,0.13645104378236605
"Statistical Learning in Language Acquisition    DESCRIPTION (provided by applicant): First language acquisition is a hallmark of normative human development. A substantial body of research suggests that language learning is facilitated by the ability to track statistical regularities in linguistic input. Research during the current project period clearly demonstrates that infants are powerful statistical learners. However, the relevance of these abilities to the learning problems presented in infants' linguistic environments remains poorly understood. The research proposed in this application will test specific hypotheses concerning infant statistical language learning, focusing on how infants make use of statistical information. Specific Aim One is to determine which surface statistics infants can use given natural language input. Specific Aim Two is to determine how the statistics of sound sequences in real speech influence word learning. Specific Aim Three is to determine whether infants' on-line language processing is affected by statistical information. The results of the research proposed in this competing continuation application will promote positive developmental outcomes by expanding our understanding of the learning mechanisms underlying normative development. Individuals who are less facile at statistical learning may be at risk for developmental language disorders. Subsequent research will use the outcome of these studies to motivate investigations including populations of young children at risk for atypical language development.      PUBLIC HEALTH RELEVANCE: These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).           PROJECT NARRATIVE These studies, which are focused on typical language development, provide an opportunity to test targeted hypotheses concerning the mechanisms underlying positive language acquisition outcomes. The results will inform subsequent studies of children at risk for atypical language development, a major public health concern. We are currently working with a number of relevant populations who are potential targets of future studies based on the experiments proposed in this application, including children with Specific Language Impairment (with Dr. Julia Evans, San Diego State University), deaf toddlers who use cochlear implants (with Dr. Ruth Litovsky, UW-Madison and Dr. Tina Grieco-Calub, Northern Illinois University), toddlers who are late-talkers (with Dr. Susan Ellis-Weismer, UW-Madison), children living in poverty (with Drs. Jan Edwards and Julie Washington, UW-Madison), toddlers with Williams Syndrome (with Drs. Carolyn Mervis and Cara Cashon, U. of Lousiville), and children with Cerebral Palsy (with Dr. Katie Hustad, UW-Madison).",Statistical Learning in Language Acquisition,7782012,R01HD037466,"['Address', 'Affect', 'Cerebral Palsy', 'Child', 'Cochlear Implants', 'Development', 'Discrimination', 'Environment', 'Face', 'Future', 'Glean', 'Hearing Impaired Persons', 'Human Development', 'Illinois', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Learning', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Outcome', 'Outcome Study', 'Pattern', 'Phase', 'Population', 'Poverty', 'Process', 'Property', 'Public Health', 'Research', 'Risk', 'Role', 'Speech', 'Structure', 'Sum', 'Surface', 'Testing', 'Time', 'Toddler', 'Universities', 'Washington', 'Williams Syndrome', 'Work', 'base', 'expectation', 'experience', 'innovation', 'knowledge of results', 'language processing', 'named group', 'natural language', 'programs', 'public health relevance', 'research study', 'sound', 'specific language impairment', 'statistics', 'success', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2010,301697,0.12152633740972749
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,7768396,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Design', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical period', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2010,530965,0.22241601537983632
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,8063408,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Design', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical period', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2010,214173,0.22241601537983632
"Functional neuroimaging of language processing in primary progressive aphasia    DESCRIPTION (provided by applicant): Primary progressive aphasia (PPA) is a clinical syndrome in which degeneration of language regions in the dominant hemisphere is associated with progressive deficits in speech and/or language function. The overall goals of this project are to use functional magnetic resonance imaging (fMRI) to investigate neural changes underlying linguistic deficits in PPA, and to use this information to better discriminate patients with variants of PPA from each other and from normal aging. Recent studies have identified three clinical variants of PPA: progressive non-fluent aphasia (PNFA), semantic dementia (SD) and logopenic progressive aphasia (LPA). Each variant is associated with characteristic linguistic features, distinct patterns of brain atrophy, and different likelihoods of particular underlying pathogenic processes, making correct differential diagnosis highly relevant. We will recruit 48 patients with PPA (16 of each variant) and 24 normal controls over a three year period, and acquire fMRI data along with structural MRI, linguistic and cognitive measures. The fMRI paradigm consists of a syntactic processing task with seven conditions parametrically varying in syntactic complexity. The research will address two specific aims. The first is to identify the relationships between volume loss, changes in functional MRI activation, and linguistic deficits, in the different PPA variants. The second aim is to improve differential diagnosis of PPA variants using machine learning algorithms incorporating both structural and functional imaging measures.      PUBLIC HEALTH RELEVANCE: PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.              PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8203671,R03DC010878,[' '],NIDCD,UNIVERSITY OF ARIZONA,R03,2010,115612,0.04765235607747432
"The Role of Statistical Learning in Acquiring Syntactic Categories    DESCRIPTION (provided by applicant): The proposed experiments will investigate the role of statistical learning in the acquisition of syntactic categories such as ""noun"" and ""verb"". The role of syntactic category knowledge in language acquisition is pervasive; for example, category knowledge both facilitates learning grammatical patterns and facilitates early word learning. While many aspects of language acquisition rely on syntactic category knowledge, the process by which these categories are learned is unclear. The goal of the proposed research is to test the hypothesis that statistical learning plays a role in acquiring syntactic categories. Words from different syntactic categories are distinguishable by statistical cues, such as their distributional properties (i.e., cooccurrence with other words), and their phonological properties (i.e., their sound structure), the first specific aim is to assess infants' sensitivity to these cues in the acquisition of noun and verb categories. If words' statistical properties are used in category learning, infants should be able to use these properties to identify novel category members in the early stages of category acquisition. Moreover, infants' ability to determine the category of novel words should reflect the degree to which they conform to the predominant statistical characteristics of the category, and training on these statistical properties should facilitate their use at younger ages. Infants' ability to categorize novel words will be assessed by testing whether they are mapped to object or action referents. The second specific aim is to test infants' ability to integrate statistical and semantic information in category learning. Acquisition of syntactic categories encompasses learning about both statistical properties and semantic properties, and these cues are correlated in natural language. If infants can integrate these cues, correlations between them should facilitate learning. Infants will be familiarized with an artificial language containing novel categories, and the correlations between statistical and semantic cues will be manipulated. If infants can integrate these cues, they should be better able to detect commonalities in the meanings of words within a category, and to learn the grammatical structures in which these words can occur, when cues are correlated than when they are not. Future studies will test children with Specific Language Impairment and other developmental language disorders (e.g., late talkers), who exhibit impaired word learning abilities and reduced sensitivity to distributional cues identifying syntactic categories. Testing children on these tasks will address the extent to which impaired statistical learning is a contributing factor in these disorders.          n/a",The Role of Statistical Learning in Acquiring Syntactic Categories,7583888,F32HD057698,"['Address', 'Age', 'Categories', 'Characteristics', 'Child', 'Cues', 'Disease', 'Exhibits', 'Future', 'Goals', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Learning', 'Machine Learning', 'Maps', 'Pattern', 'Play', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Staging', 'Structure', 'Testing', 'Training', 'member', 'natural language', 'novel', 'phonology', 'research study', 'sound', 'specific language impairment', 'syntax']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2009,50054,0.07507795673194007
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7932637,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2009,64856,0.08880531172927943
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7531059,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2009,269938,0.08880531172927943
"Constraints on Learning from Inconsistent Input All human learners with normal cognitive capacities who are exposed to language input in childhood  manage to acquire a language that looks very much like their input. However, at present we have little  idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning  mechanisms that underlie and support language learning. This is the focus of the research in this  proposal. Three general questions guide the research.(1) What are the constraints on language learning  mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or  are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if  'so, how? The proposed research examines these questions by investigating the learning of probabilistic  and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique  view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned.  Previous work has shown that learners can acquire probabilistic patterns, however they sometimes  impose consistency on variation. Moreover, children are more likely to change such patterns than are  adults. The present research expands on the earlier results, asking about the nature of the interaction  between learners and input. Series 1 asks about the nature of the input that makes some inconstancy  learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in  languages, asking questions about the specificity of computations learners can perform, the  representations over which such computations can be performed, and the effect of prior domain-specific  knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over  inconsistency at all.In particular, the studies examine whether working memory constraints, rather than  constraints stemming directly from the learning mechanisms themselves, are an important factor  influencing whether learners acquire the variation or instead impose regularity. Both series will be  conducted with adults and children to examine how learning changes over development. Although the  input in the proposed studies is somewhat atypical, the results from these studies will contribute to our  understanding of the learning mechanisms involved in language acquisition more generally, and  ultimately, this increases our understanding of both normal and disordered acquisition. n/a",Constraints on Learning from Inconsistent Input,7560411,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'information processing', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2009,177315,0.07892141615575188
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          n/a",Intonation in spontaneous English & Japanese dialogue,7643857,R01DC007090,"['Accounting', 'Acoustics', 'Address', 'Artificial Intelligence', 'Attention', 'Characteristics', 'Cochlear Implants', 'Cognitive', 'Collection', 'Communication', 'Communication Aids for Disabled', 'Complex', 'Comprehension', 'Cues', 'Development', 'Devices', 'Diagnosis', 'Education', 'Engineering', 'Eye Movements', 'Future', 'Generations', 'Goals', 'Head', 'Hearing', 'Human', 'Instruction', 'Japanese Population', 'Knowledge', 'Language', 'Lead', 'Linguistics', 'Link', 'Measures', 'Memory', 'Methodology', 'Modeling', 'Monitor', 'Names', 'Nature', 'Patients', 'Pattern', 'Performance', 'Phonetics', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Vocabulary', 'Writing', 'aphasic', 'base', 'clinical application', 'cognitive function', 'disability', 'efficacy research', 'improved', 'language processing', 'lexical', 'novel', 'oral communication', 'phonology', 'phrases', 'programs', 'research study', 'speech accuracy', 'syntax', 'theories', 'transmission process']",NIDCD,OHIO STATE UNIVERSITY,R01,2009,213837,0.16899834654316018
"Neuromotor Modeling of Adductor Spasmodic Dysphonia    DESCRIPTION (provided by applicant): Our goal is to create a laryngeal neuromotor model of adductor spasmodic dysphonia (SD), a chronic and often debilitating vocal disorder. We will achieve this goal by identifying specific motoneuron firing patterns that occur during vocal spasm by applying recently-developed multidimensional electromyographic technologies to laryngeal muscles. A neuromotor model of SD will serve to characterize the disorder at the motor nucleus. Neuromotor models, in turn, facilitate parallel research in fields of neuroimaging and drug treatment. Speech requires the coordinated control of multiple muscles by the central nervous system, from diaphragm to lips - with larynx playing a principal role in the phonatory process. Skeletal muscles are controlled by two mechanisms: the recruitment of motoneurons and modulation of motoneuron firing rates. Characterization of laryngeal muscle control at the level of the motoneuron is important toward our understanding of normal speech motor control and of neurologic speech motor disorders. Although studied for many decades, the cause of spasmodic dysphonia has remained elusive. Findings of neuroimaging, genetics, and physiology - including conventional electromyography - have been inconsistent and therefore inconclusive about the neural underpinnings of SD. Irrespective of the heterogeneity of findings using conventional modalities, the central participant in SD is the vocal spasm, and therefore we turn the fine lens offered by the imaging of multiple motoneuron firing activities upon these spasms. We hypothesize that vocal spasms are characterized by episodic increases in new motoneuron firing activity and that these new activities are disordered in firing rate characteristics with the existing pool and among themselves. We will test this hypothesis by obtaining motoneuron firing plots of an intralaryngeal muscle: thyroarytenoid. Motoneuron firing plots contain firing activities of multiple motoneurons simultaneously and in their correct temporal relations. Features of recruitment, correlation, synchronicity, and oscillation during vocal spasm will be compared to periods of non-spasm and to control features of a normal control population. Neuromuscular disorders that disrupt speech affect a sizeable population and often seriously impair the professional, social and family interactions of the affected individual. In applying recent advances in multi-dimensional physiologic and artificial intelligence technologies, this project will formulate models of vocal motor control at the level of the brainstem that improve our understanding of speech production in the normal population and of a voice disorder called spasmodic dysphonia. Knowledge gained from this research aims to assist the development of drug therapy to treat spasmodic dysphonia and other neuromuscular speech disorders.           n/a",Neuromotor Modeling of Adductor Spasmodic Dysphonia,7535517,R21DC008786,"['Affect', 'Artificial Intelligence', 'Biology', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Characteristics', 'Chronic', 'Denervation', 'Development', 'Disease', 'Electromyography', 'Family', 'Genetic', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Knowledge', 'Laryngeal muscle structure', 'Larynx', 'Lip structure', 'Modality', 'Modeling', 'Motor', 'Motor Neurons', 'Muscle', 'Neuraxis', 'Neurologic', 'Neuromuscular Diseases', 'Participant', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physiological', 'Physiology', 'Play', 'Population', 'Population Control', 'Process', 'Production', 'Research', 'Respiratory Diaphragm', 'Role', 'Skeletal Muscle', 'Spasm', 'Spastic Dysphonias', 'Speech', 'Speech Disorders', 'Technology', 'Testing', 'Thyroarytenoid Muscle', 'Voice Disorders', 'improved', 'lens', 'motor control', 'motor disorder', 'neuroimaging', 'neuromuscular', 'relating to nervous system', 'social']",NIDCD,NEW YORK MEDICAL COLLEGE,R21,2009,201958,0.07192453279040778
"Structural and Semantic Cues for the Acquisition of Linguistic Regularties    DESCRIPTION (provided by applicant): The proposed research will examine the ability of infants, children, and adults to learn non-adjacent regularities in langauge. Almost all aspects of language (phonology, morphology, syntax, and semantics) contain structural relations between elements that are reliable and predictable and yet obstructed by other elements. Common examples include the relationship between ""is"" and ""-ing"" from morphology, or the relationship between noun phrases and verb phases in syntax. To date, theories of language learning have not adequately addressed how learners acquire structural knowledge of this type. The difficulty of learning these types of relationsips is one of the biggest criticisms of statistical learning theories of language acquisition, which largely involve learning language by tracking transitional probabilities between adjacent elements in language. The work is also especially important because failure to learn these types of non-adjacent regularities is a hallmark of many language disorders like Specific Language Impariment (SLI). The first aim of this research is to show how language learners might acquire knowledge about non- adjacent dependancies using knowledge of the language's hiearchical structure, and to see if this structure is learnable by an enriched form of statistical learning. We hypothesize that learners will be able to discover probability-dependant ""chunks"" in language, and use these chunks to transform non-adjacent relationships into adjacent relationships. This aim will be addressed by behavioral experiments with infants and adults. The second aim is to see if people find it easier to learn non-adjacent dependancies in language when those dependancies can be tied to language-external semantic cues. For example, a verb (or a verb phrase) and a direct object (or its noun phrase) might be tightly coupled linguisticly, even if they are separated by embedded clauses in particular sentences. It may be that the way learners acquire this linguistic regularity is by keeping track of the semantic or conceptual association between the verb's and direct object's real world referents. We hypothesize that in conditions where there is semantic relatedness between nonadacent elements in language, this will faciliate learning of the linguistic non-adjacent regularity. This aim will be addressed by a behavioral experiment with children and by a computational model designed to explore how the interaciton of semantic and linguistic knowledge facilliates learning. In summary, proposed research will address a critical question about how people learn the structure of language, address a key shortcoming of one current theory of language acquistion, and have important implications for language disorders like SLI.             n/a",Structural and Semantic Cues for the Acquisition of Linguistic Regularties,7678067,F31DC009936,"['Address', 'Adult', 'Behavioral', 'Body of uterus', 'Child', 'Competence', 'Complex', 'Computer Simulation', 'Coupled', 'Cues', 'Dependency', 'Disease', 'Elements', 'Failure', 'Future', 'Goals', 'Human', 'Indium', 'Infant', 'Information Distribution', 'Intention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Machine Learning', 'Morphology', 'Phase', 'Play', 'Probability', 'Process', 'Research', 'Semantics', 'Stream', 'Structure', 'Techniques', 'Testing', 'Walking', 'Work', 'base', 'instrument', 'lexical', 'model design', 'phonology', 'phrases', 'research study', 'sound', 'specific language impairment', 'syntax', 'theories']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2009,28830,0.13316265358697296
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7600444,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'natural language', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2009,22393,0.14920656749044514
"Verb learning and the early development of sentence comprehension    DESCRIPTION (provided by applicant): A fundamental task in sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom. Verb knowledge plays a central role in this task. The verb determines what constituents can appear in the sentence, and what participant roles they will convey. In learning a new verb, a child must determine what relationship among participants the verb refers to, without the set of semantic instructions provided by the verb. The syntactic bootstrapping theory proposes that children use precursors of the adult's knowledge of syntax to understand sentences and therefore to learn verbs. This view is supported by evidence that children as young as 2 assign different meanings to verbs presented in different sentence structures. The proposed research asks what syntactic cues are helpful early in acquisition, before many of the complexities of syntax acquisition have been conquered. First, we argue that children treat the number of nouns in the sentence as a cue to its semantic predicate- argument structure. The number of nouns in the sentence is useful because it provides a probabilistic indicator of the verb's number of arguments. Second, early syntactic bootstrapping requires that children represent language experience in an abstract mental vocabulary that permits rapid generalization of syntactic learning to new verbs. Thus, we argue that language-specific grammatical learning, such as detecting the significance of word order in English, should transfer quickly to sentences containing new verbs, permitting progressively finer constraint on sentence interpretation and verb learning. This project explores how syntactic bootstrapping begins, and how it interacts with early progress in syntax acquisition. We take two complementary approaches: (1) Experiments with infants and toddlers will investigate the detection and use of the proposed simple structural cues to sentence interpretation and verb learning. (2) Computational experiments using a system for automatic semantic role labeling will test the main claims of our account using a substantial sample of natural child-directed speech. This combination of experimental and computational studies is intended to advance scientific knowledge about how children learn their native languages, and to guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how infants and toddlers learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.           n/a",Verb learning and the early development of sentence comprehension,7561736,R01HD054448,"['Accounting', 'Adopted', 'Adult', 'American', 'Architecture', 'Body of uterus', 'Child', 'Comprehension', 'Computer Simulation', 'Computers', 'Cues', 'Databases', 'Detection', 'Development', 'Eating', 'Event', 'Face', 'Goals', 'Hand', 'Hearing', 'Heart', 'Infant', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Licensing', 'Linguistics', 'Mind', 'Modeling', 'Natural Language Processing', 'Participant', 'Patient Agents', 'Play', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Psyche structure', 'Psychologist', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Training', 'Vocabulary', 'Work', 'abstracting', 'base', 'computer studies', 'experience', 'feeding', 'lens', 'lexical', 'novel', 'programs', 'remediation', 'research study', 'success', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2009,235962,0.09542299010624786
"Tools for Automated Assessment of Language    DESCRIPTION (provided by applicant): Language and communication problems critically characterize a number of neurodevelopmental disorders including Developmental Language Disorders (DLD) and Autism Spectrum Disorders (ASD). It is increasingly recognized that assessment should include spontaneous natural language samples. There are measures, such as the Index of Productive Syntax (IPSyn), which are laborious to apply, since they require manual analysis of a corpus of sentences collected from the child. There is therefore a strong need for automated tools to aid clinicians in this task, and to provide more robust analyses for assessment. Many widely-used commercial software packages, such as the Systematic Analysis of Language Transcripts (SALT) do little more than count linguistic features, and still require someone to code those features. Fully automated systems, such as Computerized Profiling (CP) do exist, but reports vary on how well they work. However, recent advances in natural language processing, in particular in the realm of grammar adaptation, mean that we are now able to produce high-quality commercial software that can be used by clinical practitioners in their assessment of child language. This project will build a commercially viable suite of fully automated, software-based tools, requiring no special equipment beyond a standard personal computer, targeted at clinicians who work with children with neurodevelopmental disorders. The system will have been evaluated not only with children with Typical Development (TD), but with data from children with ASD and DLD. The system will include the following components: (1) text normalization tools to help with the clean up and normalization of transcriptions; (2) a state -of-the-art part-of-speech tagger; (3) a state-of-the-art morphological analyzer; (4) a state-of-the-art syntactic parser; (5) a dependency analyzer and semantic-role labeler, (6) a scoring module to take the output of the language analysis, and map this to the IPSyn or other scales. The software will be written in C++ and Java, and will adopt a rigorous industrial coding style, namely the Google style guide, which is in the public domain. As part of an NIH-funded project on Autism, the Center for Spoken Language Understanding, in collaboration with colleagues at Yale University, has collected a corpus of video and audio recorded interactions of children with ASD and DLD, as well as TD children ages 4-8. In this STTR-funded project, we will perform a manual IPSyn assessment on these data and provide the results as a benchmark on how well the system will perform in the field. While the target language for the initial development will be English, the software will be written in a fully language-independent fashion, in that no properties of English will be hard-coded into the system. All that would be required to 'port' the system to a new language would be appropriate training material for the language.      PUBLIC HEALTH RELEVANCE: Language and communication problems critically characterize a number of neurodevelopmental disorders, and it is increasingly recognized that assessment should involve the analysis of spontaneous language samples. This project will develop a package of software programs for the automatic analysis of spontaneous language samples from children with neurodevelopmental disorders. The program will be usable directly by clinicians in their assessment of patients.          n/a",Tools for Automated Assessment of Language,7800817,R41DC010502,"['Adopted', 'Age', 'Arts', 'Autistic Disorder', 'Benchmarking', 'Body of uterus', 'Child', 'Child Development', 'Child Language', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Data', 'Dependency', 'Development', 'Funding', 'Genetic Transcription', 'Java', 'Language', 'Language Development Disorders', 'Linguistics', 'Manuals', 'Maps', 'Measures', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Output', 'Patients', 'Personal Computers', 'Property', 'Public Domains', 'Reporting', 'Role', 'Sampling', 'Semantics', 'Special Equipment', 'Speech', 'System', 'Text', 'Training', 'Transcript', 'Universities', 'Work', 'Writing', 'autism spectrum disorder', 'base', 'computerized', 'indexing', 'natural language', 'programs', 'public health relevance', 'syntax', 'tool']",NIDCD,"BIOSPEECH, INC.",R41,2009,198687,0.04296592577526592
"Cognitive Representation in Specific Language Impairment    DESCRIPTION (provided by applicant): The purpose of this project is to investigate the nature of implicit learning in children with Specific Language Impairment (SLI). A key question is whether the language impairments seen in these children are due to impaired cognitive processing mechanisms or are a representational deficit in a specific grammar module. Recently, it has been proposed that: (1) the syntax, morphology, auditory processing, and working memory deficits seen in children with SLI are due instead to a procedural implicit learning deficit, and (2) the relatively spared vocabulary abilities in children with SLI suggests an intact declarative learning system that may function as a compensatory mechanism in their language acquisition. Procedural memory is used in the learning of sequential, cognitive, and perceptual motor skills. Recent work suggests, however, that SLI may instead be a domain general implicit learning impairment that extends beyond procedural learning to include category learning, statistical, and artificial grammar learning, and that this implicit learning impairment may extend beyond the perceptual motor system to include the auditory and visual modalities as well. The purpose of this project is to determine if implicit learning in children with SLI is a domain general or domain specific impairment. A total of 170 children will participate in this 5-year project, including 85 children with SLI, 7-9 years of age and 85 normal language controls (CA) matched on chronological age, nonverbal IQ, and maternal education. A total of 9 implicit learning studies are proposed. Studies 1-3 will examine directly whether implicit learning in children with SLI (N = 45) is impaired for implicit category, statistical, and artificial grammar learning on tasks designed to have auditory, visual, and perceptual motor isomorphs as compared to CA controls (N = 45). Studies 4-6 will examine the nature and time course of implicit category, statistical, and artificial grammar learning in the auditory modality and ask if this knowledge transfers to visual and perceptual motor modalities in children with SLI (N = 40) and CA controls (N = 40). Studies 7-9 ask whether implicit learning predicts not only syntax and morphology knowledge, but also vocabulary knowledge, in both children with SLI (N = 85) and CA controls (N = 85). Theoretically, these studies extend our understanding of linguistic and nonlinguistic deficits in children with SLI by clarifying the extent to which modality specific or general implicit learning deficits may contribute to the language impairments seen in these children. Clinically, these studies will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the implicit learning of abstract representations in children with SLI, and will lead to the development of effective intervention models for school-aged children with SLI who are at risk for severe difficulties in communication, reading, writing, and academic failure. PUBLIC HEALTH RELEVANCE The purpose of this project is to investigate implicit learning in children with Specific Language Impairment (SLI). There is evidence to suggest that children with SLI may have a domain general deficit in implicit learning. Implicit learning is gradual, occurring on an ongoing basis across multiple trials or exemplars, and appears to be the mechanism by which language is learned in typically developing children. The studies proposed in this project address the gap in our understanding of implicit learning abilities in children with SLI by directly examining the extent to which children with SLI may have a modality general implicit learning impairment. The findings from this research will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the language learning in children with language impairments, and will aid the development of effective intervention models for school-aged children with language impairments who are at risk for severe difficulties in communication, reading, writing, and academic failure.          n/a",Cognitive Representation in Specific Language Impairment,7659525,R01DC005650,"['9 year old', 'Address', 'Age', 'Auditory', 'Categories', 'Child', 'Cognitive', 'Collection', 'Communication', 'Complex', 'Conscious', 'Development', 'Education', 'Emotional', 'Exposure to', 'Failure', 'Habits', 'Hearing', 'Impairment', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Memory', 'Memory impairment', 'Modality', 'Modeling', 'Morphology', 'Motor', 'Motor Skills', 'Nature', 'Neurologic', 'Performance', 'Process', 'Reading', 'Research', 'Risk', 'School-Age Population', 'Secondary to', 'Short-Term Memory', 'Stimulus', 'System', 'Time', 'Visual', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'design', 'effective intervention', 'experience', 'implicit memory', 'improved', 'insight', 'lexical', 'motor skill learning', 'novel', 'procedural memory', 'public health relevance', 'specific language impairment', 'success', 'syntax', 'visual process', 'visual processing']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2009,308285,0.06549886463655095
"Sensitivity to spectral cues in infant speech perception    DESCRIPTION (provided by applicant): The proposed research will examine infants' sensitivity to multiple spectral cues in speech perception. Speech is a complex signal, with numerous acoustic cues for every consonant and vowel. Through experience, listeners learn to exploit correlations between multiple cues, making perception more efficient and robust. Adults display this knowledge through their use of cues that are spectrally local (e.g. formant transitions) as well as distributed (e.g. gross spectral shape, or tilt) to distinguish speech sounds. Although prior research has demonstrated infants' ability to distinguish many speech sounds, how they distinguish these sounds is unclear. Infants' sensitivity to individual cues, the relative importance they assign to each cue, and when they learn to exploit correlations between cues all remain poorly understood. We propose four experiments to address these questions. The first aim of this project is to investigate sensitivity to spectral cues. To address this issue, the first two experiments will examine speech perception when the natural covariance between two cues is violated or maintained. The latter two experiments will test sensitivity to changes in individual cues. The second aim is to assess relative cue salience across the lifespan. Results from the first experiment will be compared to existing data from normal-hearing and hearing-impaired elderly adult listeners who completed a similar task (Alexander & Kluender, in press; in preparation) to assess differential effects of listening experience and hearing health on perception of the same speech stimuli. We hypothesize that both 6-to-7-month-old and 11-to-12-month-old-infants will exhibit perceptual sensitivity to both spectral cues in speech perception, with 11-to-12-month-olds displaying the greatest sensitivity. We also hypothesize that younger infants may be relatively more influenced by spectrally global (e.g. tilt) cues than older infants. Our long-term objective is to better understand development of speech perception in infants with normal and compromised hearing. These results will help refine treatment methods for infants with hearing loss, and inform the use of devices such as hearing aids and cochlear implants. Public health statement: The proposed research will reveal the acoustic information infants use to distinguish speech sounds, and whether this information is used differently by adults. Knowing what infants listen for will benefit efforts to facilitate development of speech perception in children with compromised hearing. This research will also investigate when infants learn to exploit statistical regularities between cues in natural speech.             n/a",Sensitivity to spectral cues in infant speech perception,7655501,F31DC009532,"['Acoustics', 'Address', 'Adult', 'Affect', 'Age', 'Body Weight Changes', 'Child', 'Classification', 'Cochlear Implants', 'Complex', 'Conflict (Psychology)', 'Cues', 'Data', 'Development', 'Devices', 'Elderly', 'Environment', 'Exhibits', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Individual', 'Infant', 'Knowledge', 'Learning', 'Light', 'Longevity', 'Machine Learning', 'Methods', 'Modality', 'Perception', 'Population', 'Preparation', 'Public Health', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Resolution', 'Sensorineural Hearing Loss', 'Sensory', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'System', 'Testing', 'Voice', 'Weight', 'base', 'experience', 'hearing impairment', 'infancy', 'research study', 'response', 'sound']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2009,27416,0.13406942416529313
"A Shared Database for the Study of Phonological Development DESCRIPTION:  The study of phonological development has important implications for the diagnosis and treatment of language disorders, models of the biological bases of language production, the teaching of second languages, and the general advancement of linguistic theory. Recents advances in computational power make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project (http://childes.psy.cmu.edu) now provides universal access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not yet built effective tools for phonological and phonetic analysis.  We will close this gap by developing a new Java-based program called Phon that interfaces with the CHILDES transcription format. Phon provides: (1) easy user-controlled utterance boundary marking, (2) an input method for Unicode IPA transcription of child forms, (3) automatic alignment of segments in child forms to waveform regions, (4) automatic insertion of the IPA form for adult target words, (5) automatic alignment of child forms to the adult targets for both segmental and prosodic levels, (6) tools for querying the database, and (7) tools for composing output reports. Phon will be configured to run either locally or over the web as a Java WebStart application. The construction of the new database will be supported by a group of 26 researchers who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data will be structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. Benchmarks will be established to emphasize the direct competitive teasting of competing hypotheses from alternative theoretical and methodological positions. n/a",A Shared Database for the Study of Phonological Development,7624332,R01HD051698,"['Acoustics', 'Adult', 'Algorithms', 'Benchmarking', 'Biological', 'Body of uterus', 'Child', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease model', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Extensible Markup Language', 'Frequencies', 'Generations', 'Genetic Transcription', 'Goals', 'Individual Differences', 'Internet', 'Java', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Output', 'Participant', 'Pattern', 'Phonetics', 'Positioning Attribute', 'Production', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Running', 'Series', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'digital', 'disability', 'lexical', 'member', 'phonology', 'programs', 'sound', 'syntax', 'theories', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2009,227115,0.06242650349155976
"Social and Statistical Mechanisms of Prelinguistic Vocal Learning    DESCRIPTION (provided by applicant): How do infants learn to produce the sounds of their language? The vocal abilities of infants change dramatically over the first year of life. Beginning with the earliest, immature vocalizations, infants make rapid progress, typically producing their first words by 12 months of age. Along the way, they begin to produce speech-like syllables and to structure sequences of syllables in accordance with the phonological rules of their language environment. While the vocal achievements of the first year are well-described, not nearly as much is known about the mechanisms of change that drive vocal development. Most work focuses on the maturation of the vocal tract, but studies of vocal development in songbirds found that there are also social sources of developmental change. For example, young male cowbirds (Molothrus ater) rely on the reactions of females to shape their immature sounds into functional song. Based on the avian work, the investigators' preliminary studies have shown that infants can learn new patterns of vocalizing from caregivers' reactions to their babbling. How do infants use social feedback to create new, more developmentally advanced, vocalizations? The goal of the proposed research is to understand the mechanisms by which infants incorporate the phonological patterns of their language into their vocal repertoires. Based on preliminary studies, the investigators hypothesize that the contingent responses of caregivers to babbling facilitate infants' statistical learning of the phonological patterns of their language. To investigate this hypothesis, the variability and temporal contingency of speech to 9-month-old infants will be manipulated to assess their effects on vocal learning. The proposed research has important implications for educating parents in providing optimal learning environments for their infants. An understanding of the role of socially guided learning in speech and language could be used to help parents to be more sensitive to their infants' behavior in ways that would facilitate development. Investigating social influences on phonological development can also contribute to the study of speech-language pathology and of processes underlying both successful and disordered communicative development.      PUBLIC HEALTH RELEVANCE: By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).           Project Relevance By illuminating mechanisms by which infants learn to produce the sounds of their language from caregivers' contingent speech, the findings could inform interventions for disordered language development. The results could also be used to help parents and child care providers create social environments that foster and support language growth. Eventually, this research could be used to design preventive programs for infants with a higher risk of language delay (e.g., children with Down Syndrome or SLI).",Social and Statistical Mechanisms of Prelinguistic Vocal Learning,7712197,R03HD061524,"['Achievement', 'Age-Months', 'Attention', 'Birds', 'Caregivers', 'Characteristics', 'Child', 'Child Care', 'Communication', 'Communication impairment', 'Crying', 'Development', 'Down Syndrome', 'Environment', 'Feedback', 'Female', 'Fostering', 'Goals', 'Growth', 'Infant', 'Infant Behavior', 'Intervention', 'Knowledge', 'Language', 'Language Delays', 'Language Development Disorders', 'Learning', 'Life', 'Light', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mechanics', 'Motor', 'Movement', 'Nature', 'Outcome', 'Parents', 'Pathology processes', 'Pattern', 'Phonetics', 'Play', 'Preventive', 'Production', 'Provider', 'Reaction', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Snow', 'Social Environment', 'Songbirds', 'Source', 'Speech', 'Speech Perception', 'Speech-Language Pathology', 'Structure', 'Time', 'Work', 'base', 'design', 'high risk', 'insight', 'male', 'phonology', 'programs', 'public health relevance', 'response', 'social', 'sound', 'vocal learning', 'vocalization']",NICHD,CORNELL UNIVERSITY,R03,2009,79500,0.12801714967607922
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7932503,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Body of uterus', 'Categories', 'Child', 'Classification', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2009,70754,0.13645104378236605
"Statistical approaches to linguistic pattern learning    DESCRIPTION (provided by applicant): The purpose of the proposed research is to provide a comprehensive account of the factors that affect how infants, children, and adults learn the categories of their native language from distributional information in linguistic input. The categories of a language consist of sets of words (e.g., noun, verb) that play a functionally equivalent role in grammatical sentences. Distributional information refers to the patterning of elements in a large corpus of sentences and includes how frequently those elements occur, what position they occupy in a sentence, and the context provided by neighboring elements. Our longstanding program of research on statistical learning in word segmentation (how learners determine which sound sequences form words) has documented the power, rapidity, and robustness of infants, children, and adults sensitivity to complex distributional information. Here we extend that program of research to a crucial aspect of learning higher-level structures of language. In our proposed studies, we use a miniature artificial language paradigm that affords us complete control over all the distributional cues in the input, something that is virtually impossible using real languages. Participants listen to a sample of utterances and make judgments about their acceptability. Crucially, during a learning phase, they do not hear all possible utterances that are ""legal"" in the artificial language; some are withheld for use in a later post-test. The post-test utterances either conform to the distributional patterns present in the learning phase, or they violate those patterns. The key test is whether participants judge novel-but-legal utterances to be acceptable, thereby showing the ability to generalize correctly beyond the input to which they were exposed. Studies of children provide additional support for learning the distributional cues by pairing utterances with videos of simple events. Studies of adults will be used for comparison, and will also present them with learning materials in the visual-motor domain to assess the detailed time-course of learning and the specificity of the results to auditory linguistic materials. Taken together, the results of these studies of infants, children, and adults will document the key structural variables in language learning that enable a distributional mechanism of category formation to operate and will highlight the ways these mechanisms may differ over age and domain. PUBLIC HEALTH RELEVANCE: Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.           Public Health Relevance Statement  Language development is one of the hallmarks of the human species, yet it is difficult to study because of the huge variation in early exposure to different amounts of linguistic input. The use of artificial languages that are acquired in the lab over a few hours provides a window on the mechanisms of language development. We will study language learning in the lab to gain a unique perspective on how the categories (noun, verb, etc) are formed from listening to the patterns of words in a small set of sentences. These studies will not only reveal a basic mechanism of language learning, but also establish benchmarks against which language delay can be compared. Moreover, understanding the mechanisms that lead to successful acquisition in normal children can help to identify loci of language disorders and design methods for remediating disorders.",Statistical approaches to linguistic pattern learning,7728608,R01HD037082,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Auditory', 'Benchmarking', 'Body of uterus', 'Categories', 'Child', 'Classification', 'Complex', 'Cues', 'Developmental Delay Disorders', 'Disease', 'Elements', 'Event', 'Exposure to', 'Eye Movements', 'Feedback', 'Frequencies', 'Goals', 'Hearing', 'Hour', 'Human', 'Human Development', 'Indium', 'Infant', 'Instruction', 'Judgment', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Legal', 'Linguistics', 'Machine Learning', 'Maps', 'Methods', 'Nature', 'Noise', 'Participant', 'Pattern', 'Performance', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Reaction Time', 'Recurrence', 'Relative (related person)', 'Research', 'Resources', 'Role', 'Sampling', 'Series', 'Shapes', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Ursidae Family', 'Variant', 'Visual', 'design', 'lexical', 'natural language', 'novel', 'programs', 'public health relevance', 'remediation', 'research study', 'response', 'scale up', 'sound', 'statistics', 'visual motor']",NICHD,UNIVERSITY OF ROCHESTER,R01,2009,300672,0.13645104378236605
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,7587262,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Design', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical period', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2009,537826,0.22241601537983632
"A Direct Brain to Speech Generator for use in Humans    DESCRIPTION (provided by applicant): LONG TERM OBJECTIVES AND SPECIFIC AIMS: We aim to restore near conversational rate speech in locked-in individuals. In the Phase 1 study, neural recordings from the speech motor area in a 23 year old locked-in subject implanted with the Neurotrophic Electrode System since December 2004 have yielded neural data that have been mapped to phonemic representations and to imagined and actual movements. In the proposed work, we intend to incorporate sophisticated speech recognition algortithms, such as Artificial Neural Networks and Hidden Markov Models, in order to enable rapid pattern recognition for purposes of a real-time Speech Prosthetic development. In addition, Population Vector Analysis as performed for chronic motor studies may realize a method of converting individual neuronal firings into Phonemic or Articulatory Space for driving a Speech Synthesis Model. An additional patient will be implanted with the electrode system to expand and verify the work achieved with the initial subject. The resulting data will add much to understanding the cortical organization of speech production and accelerate the development of a speech prosthetic for locked-in individuals. The website development for data sharing purposes will be expanded and used by the collaborators and other interested parties.       RELEVANCE OF RESEARCH TO PUBLIC HEALTH: The creation of a Speech Prosthetic Device is much needed by locked-in patients suffering from ALS and brain stem stroke. The substantial research being performed in invasive neuroprosthetic studies is focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software. This work is helpful to locked-in patients; however, such patients have indicated that real-time spontaneous speech is a much more desirable final application. The purpose of this research is to develop a speech prosthetic device using the Neurotrophic Electrode Human Cortical Recording system with sophisticated pattern recognition models and software. The majority of neuroprosthetic studies are focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software, however we believe that real-time spontaneous speech would be much more desirable application to locked-in patients.          n/a",A Direct Brain to Speech Generator for use in Humans,7905400,R44DC007050,"['Area', 'Automobile Driving', 'Back', 'Biological Neural Networks', 'Brain', 'Brain Stem', 'Brain Stem Infarctions', 'Chronic', 'Classification', 'Communication', 'Computer software', 'Controlled Study', 'Data', 'Data Analyses', 'Development', 'Electrodes', 'Evaluation', 'FDA approved', 'Feeds', 'Frequencies', 'Human', 'Hybrids', 'Implant', 'Individual', 'Investigation', 'Learning', 'Left', 'Limb structure', 'Link', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Motor', 'Movement', 'Neurons', 'Output', 'Paralysed', 'Pathway interactions', 'Patients', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Phase', 'Phase I Clinical Trials', 'Play', 'Population', 'Population Analysis', 'Process', 'Production', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Recovery', 'Reporting', 'Research', 'Role', 'Signal Transduction', 'Site', 'Sorting - Cell Movement', 'Speech', 'Speech Synthesizers', 'Speed', 'Stream', 'Stroke', 'System', 'Time', 'Training', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'base', 'data acquisition', 'data sharing', 'design', 'detector', 'implantation', 'improved', 'interest', 'male', 'markov model', 'meetings', 'motor control', 'relating to nervous system', 'sound', 'speech recognition', 'tool', 'vector', 'web site']",NIDCD,"NEURAL SIGNALS, INC.",R44,2009,74630,0.11747450650463175
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7478824,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,177729,0.051231787171152884
"When cues converge: multiple regularities in language acquisition    DESCRIPTION (provided by applicant): The goal of this research project is to employ behavioral and computational methods to better understand how infants use multiple regularities when learning language. Many researchers have posited that infants use statistical learning mechanisms to extract these regularities. However, the majority of this work focuses on infants' abilities to exploit a single regularity. In their natural environment, infants receive input that contains many overlapping regularities of varying consistency. Little research has focused on how infants process this type of input. In order to make use of the cues available in natural input, infants must be able to exploit these overlapping probabilistic regularities. The first aim of this grant is to explore how infants use multiple regularities to find words in fluent speech. By 9 months, infants are able to robustly use both lexical stress and sequential statistics to segment words. However, prior research has focused on how infants use these regularities in isolation, or how weighting of the cues changes developmentally. We hypothesize that infants can use these cues for word segmentation when they are probabilistic and overlapping, as they are in natural languages such as English. The second aim is to investigate the effect of multiple regularities on word learning. As a child's vocabulary grows, regularities arise among the labels and referents they know, as well as within the mappings between labels and referents. These regularities may affect the acquisition of new words. However, their potential role in subsequent word learning has not been carefully explored. Using computational models, we can examine these issues by carefully controlling regularities that exist within a vocabulary and by exploring how different types of regularities may affect word learning. These models can lead to a deeper understanding of these processing mechanisms and to novel predictions, which can then be tested in behavioral experiments.    Public Health Interests:  The goal of this research is to better understand how typically developing infants learn language - in particular, how they use the many patterns that exist in natural languages to do so. The ability to make use of multiple regularities likely affects infants' skills at language learning. By better understanding how this process unfolds in typically developing infants, researchers will be able to investigate how children with language delays and disabilities may differ in their ability to integrate multiple cues. In the future, this information will be useful for developing treatment plans.           n/a",When cues converge: multiple regularities in language acquisition,7488931,F31DC008737,"['Adherence', 'Affect', 'Behavioral', 'Body of uterus', 'Child', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Cues', 'Depth', 'Educational process of instructing', 'Environment', 'Face', 'Future', 'Goals', 'Grant', 'Infant', 'Label', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Maps', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Numbers', 'Pattern', 'Probability', 'Process', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Speech', 'Stress', 'System', 'Testing', 'Vocabulary', 'Weight', 'Work', 'design', 'disability', 'experience', 'interest', 'lexical', 'novel', 'research study', 'simulation', 'skills', 'sound', 'statistics', 'tool', 'treatment planning']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2008,31498,0.06884194689258305
"The Role of Statistical Learning in Acquiring Syntactic Categories    DESCRIPTION (provided by applicant): The proposed experiments will investigate the role of statistical learning in the acquisition of syntactic categories such as ""noun"" and ""verb"". The role of syntactic category knowledge in language acquisition is pervasive; for example, category knowledge both facilitates learning grammatical patterns and facilitates early word learning. While many aspects of language acquisition rely on syntactic category knowledge, the process by which these categories are learned is unclear. The goal of the proposed research is to test the hypothesis that statistical learning plays a role in acquiring syntactic categories. Words from different syntactic categories are distinguishable by statistical cues, such as their distributional properties (i.e., cooccurrence with other words), and their phonological properties (i.e., their sound structure), the first specific aim is to assess infants' sensitivity to these cues in the acquisition of noun and verb categories. If words' statistical properties are used in category learning, infants should be able to use these properties to identify novel category members in the early stages of category acquisition. Moreover, infants' ability to determine the category of novel words should reflect the degree to which they conform to the predominant statistical characteristics of the category, and training on these statistical properties should facilitate their use at younger ages. Infants' ability to categorize novel words will be assessed by testing whether they are mapped to object or action referents. The second specific aim is to test infants' ability to integrate statistical and semantic information in category learning. Acquisition of syntactic categories encompasses learning about both statistical properties and semantic properties, and these cues are correlated in natural language. If infants can integrate these cues, correlations between them should facilitate learning. Infants will be familiarized with an artificial language containing novel categories, and the correlations between statistical and semantic cues will be manipulated. If infants can integrate these cues, they should be better able to detect commonalities in the meanings of words within a category, and to learn the grammatical structures in which these words can occur, when cues are correlated than when they are not. Future studies will test children with Specific Language Impairment and other developmental language disorders (e.g., late talkers), who exhibit impaired word learning abilities and reduced sensitivity to distributional cues identifying syntactic categories. Testing children on these tasks will address the extent to which impaired statistical learning is a contributing factor in these disorders.          n/a",The Role of Statistical Learning in Acquiring Syntactic Categories,7408311,F32HD057698,"['Address', 'Age', 'Categories', 'Characteristics', 'Child', 'Cues', 'Disease', 'Exhibits', 'Future', 'Goals', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Language Development Disorders', 'Learning', 'Machine Learning', 'Maps', 'Pattern', 'Play', 'Process', 'Property', 'Research', 'Role', 'Semantics', 'Staging', 'Structure', 'Testing', 'Training', 'member', 'novel', 'phonology', 'research study', 'sound', 'specific language impairment', 'syntax']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2008,46826,0.07507795673194007
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7336359,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2008,270051,0.08880531172927943
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          n/a",Intonation in spontaneous English & Japanese dialogue,7452462,R01DC007090,"['Accounting', 'Acoustics', 'Address', 'Artificial Intelligence', 'Attention', 'Characteristics', 'Clinical Engineering', 'Cochlear Implants', 'Cognitive', 'Collection', 'Communication', 'Communication Aids for Disabled', 'Complex', 'Comprehension', 'Condition', 'Cues', 'Development', 'Devices', 'Diagnosis', 'Education', 'Eye Movements', 'Future', 'Generations', 'Goals', 'Head', 'Hearing', 'Human', 'Instruction', 'Japanese Population', 'Knowledge', 'Language', 'Lead', 'Linguistics', 'Link', 'Measures', 'Memory', 'Methodology', 'Modeling', 'Monitor', 'Names', 'Nature', 'Patients', 'Pattern', 'Performance', 'Phonetics', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Rate', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Vocabulary', 'Writing', 'aphasic', 'base', 'clinical application', 'cognitive function', 'disability', 'efficacy research', 'improved', 'language processing', 'lexical', 'novel', 'oral communication', 'phonology', 'programs', 'research study', 'speech accuracy', 'syntax', 'theories', 'transmission process']",NIDCD,OHIO STATE UNIVERSITY,R01,2008,213837,0.16899834654316018
"Constraints on Learning from Inconsistent Input All human learners with normal cognitive capacities who are exposed to language input in childhood  manage to acquire a language that looks very much like their input. However, at present we have little  idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning  mechanisms that underlie and support language learning. This is the focus of the research in this  proposal. Three general questions guide the research.(1) What are the constraints on language learning  mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or  are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if  'so, how? The proposed research examines these questions by investigating the learning of probabilistic  and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique  view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned.  Previous work has shown that learners can acquire probabilistic patterns, however they sometimes  impose consistency on variation. Moreover, children are more likely to change such patterns than are  adults. The present research expands on the earlier results, asking about the nature of the interaction  between learners and input. Series 1 asks about the nature of the input that makes some inconstancy  learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in  languages, asking questions about the specificity of computations learners can perform, the  representations over which such computations can be performed, and the effect of prior domain-specific  knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over  inconsistency at all.In particular, the studies examine whether working memory constraints, rather than  constraints stemming directly from the learning mechanisms themselves, are an important factor  influencing whether learners acquire the variation or instead impose regularity. Both series will be  conducted with adults and children to examine how learning changes over development. Although the  input in the proposed studies is somewhat atypical, the results from these studies will contribute to our  understanding of the learning mechanisms involved in language acquisition more generally, and  ultimately, this increases our understanding of both normal and disordered acquisition. n/a",Constraints on Learning from Inconsistent Input,7390362,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Computer information processing', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Numbers', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,180295,0.07892141615575188
"An Accessible, Effective Treatment for Sentence Deficit in Agrammatic Aphasia    DESCRIPTION (provided by applicant): The goal of our work is to develop an accessible, effective and cost effective speech and language treatment for aphasia. To achieve this goal, we will develop a commercial prototype of a computer program called Sentactics based on over 15 years of research at Northwestern University that demonstrates the effectiveness of the program to improve speech production and comprehension skills of individuals with aphasia. Preliminary work funded by the NIH resulted in an initial version of the Sentactics program. A clinical trial revealed that individuals with agrammatic aphasia who used Sentactics improved their speech and language production and comprehension skills significantly, with gains equivalent to subjects who were administered the clinical treatment from expert human clinicians. This study also demonstrated that individuals with aphasia find the Sentactics program to be highly engaging and fun to use. Our project aims to demonstrate the feasibility of a commercial prototype of an improved version of Sentactics that incorporates two new features: (a) a spoken language system that uses speech and natural language processing technologies to provide feedback to clients about the accuracy of their speech productions, and (b) a clinician oversight capability that enables individual clinicians to use the internet to monitor multiple simultaneous users of the program and communicate with individual users as needed. In Phase I of the project, we will demonstrate the feasibility of using the spoken language system to provide feedback to clients about the accuracy of their speech productions. In Phase II we will develop a commercial prototype of the program incorporating the spoken language system and clinician oversight functions. We will then field test the program with individuals with aphasia. We will compare changes in the speech production and comprehension abilities of individuals using the Sentactics program to individuals using a commercially available program. PUBLIC HEALTH RELEVANCE: Successful outcomes of this project would result in a commercial prototype of an accessible, affordable, effective and easy to use speech and language therapy program for use by individuals with aphasia in clinics or homes. This project addresses a great national need for inexpensive, intensive, extensive, effective treatments for millions of individuals with aphasia.                        Relevance Successful outcomes of this project would result in a commercial prototype of an accessible, affordable, effective and easy to use speech and language therapy program for use by individuals with aphasia in clinics or homes. This project addresses a great national need for inexpensive, intensive, extensive, effective treatments for millions of individuals with aphasia.  ","An Accessible, Effective Treatment for Sentence Deficit in Agrammatic Aphasia",7611673,R43DC009926,"['Address', 'Aphasia', 'Aphasiology', 'Client', 'Clinic', 'Clinical', 'Clinical Treatment', 'Clinical Trials', 'Communication', 'Comprehension', 'Computers', 'Couples', 'Data', 'Effectiveness', 'Evaluation', 'Feedback', 'Funding', 'Goals', 'Home environment', 'Hospitals', 'Human', 'Individual', 'Internet', 'Language', 'Language Therapy', 'Modeling', 'Monitor', 'Natural Language Processing', 'Numbers', 'Outcome', 'Participant', 'Patients', 'Phase', 'Polishes', 'Production', 'Program Effectiveness', 'Public Health', 'Research', 'Semantics', 'Series', 'Site', 'Speech', 'Speech Recognition Software', 'Stimulus', 'System', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Universities', 'Vocabulary', 'Work', 'aphasic', 'base', 'cohort', 'computer program', 'cost effective', 'design', 'improved', 'iterative design', 'lexical', 'programs', 'prototype', 'research and development', 'response', 'skills', 'speech accuracy', 'speech recognition', 'syntax', 'treatment effect', 'usability', 'user-friendly', 'visual stimulus']",NIDCD,"MENTOR INTERACTIVE, INC.",R43,2008,99956,0.1320908537582725
"Neuromotor Modeling of Adductor Spasmodic Dysphonia    DESCRIPTION (provided by applicant): Our goal is to create a laryngeal neuromotor model of adductor spasmodic dysphonia (SD), a chronic and often debilitating vocal disorder. We will achieve this goal by identifying specific motoneuron firing patterns that occur during vocal spasm by applying recently-developed multidimensional electromyographic technologies to laryngeal muscles. A neuromotor model of SD will serve to characterize the disorder at the motor nucleus. Neuromotor models, in turn, facilitate parallel research in fields of neuroimaging and drug treatment. Speech requires the coordinated control of multiple muscles by the central nervous system, from diaphragm to lips - with larynx playing a principal role in the phonatory process. Skeletal muscles are controlled by two mechanisms: the recruitment of motoneurons and modulation of motoneuron firing rates. Characterization of laryngeal muscle control at the level of the motoneuron is important toward our understanding of normal speech motor control and of neurologic speech motor disorders. Although studied for many decades, the cause of spasmodic dysphonia has remained elusive. Findings of neuroimaging, genetics, and physiology - including conventional electromyography - have been inconsistent and therefore inconclusive about the neural underpinnings of SD. Irrespective of the heterogeneity of findings using conventional modalities, the central participant in SD is the vocal spasm, and therefore we turn the fine lens offered by the imaging of multiple motoneuron firing activities upon these spasms. We hypothesize that vocal spasms are characterized by episodic increases in new motoneuron firing activity and that these new activities are disordered in firing rate characteristics with the existing pool and among themselves. We will test this hypothesis by obtaining motoneuron firing plots of an intralaryngeal muscle: thyroarytenoid. Motoneuron firing plots contain firing activities of multiple motoneurons simultaneously and in their correct temporal relations. Features of recruitment, correlation, synchronicity, and oscillation during vocal spasm will be compared to periods of non-spasm and to control features of a normal control population. Neuromuscular disorders that disrupt speech affect a sizeable population and often seriously impair the professional, social and family interactions of the affected individual. In applying recent advances in multi-dimensional physiologic and artificial intelligence technologies, this project will formulate models of vocal motor control at the level of the brainstem that improve our understanding of speech production in the normal population and of a voice disorder called spasmodic dysphonia. Knowledge gained from this research aims to assist the development of drug therapy to treat spasmodic dysphonia and other neuromuscular speech disorders.           n/a",Neuromotor Modeling of Adductor Spasmodic Dysphonia,7387178,R21DC008786,"['Affect', 'Artificial Intelligence', 'Biology', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Characteristics', 'Chronic', 'Denervation', 'Development', 'Disease', 'Electromyography', 'Family', 'Fire - disasters', 'Genetic', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Knowledge', 'Laryngeal muscle structure', 'Larynx', 'Lip structure', 'Modality', 'Modeling', 'Motor', 'Motor Neurons', 'Muscle', 'Neuraxis', 'Neurologic', 'Neuromuscular Diseases', 'Participant', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physiological', 'Physiology', 'Play', 'Population', 'Population Control', 'Process', 'Production', 'Rate', 'Research', 'Respiratory Diaphragm', 'Role', 'Skeletal Muscle', 'Spasm', 'Spastic Dysphonias', 'Speech', 'Speech Disorders', 'Technology', 'Testing', 'Thyroarytenoid Muscle', 'Voice Disorders', 'improved', 'lens', 'motor control', 'motor disorder', 'neuroimaging', 'relating to nervous system', 'social']",NIDCD,NEW YORK MEDICAL COLLEGE,R21,2008,247971,0.07192453279040778
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7486009,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Numbers', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2008,49646,0.14920656749044514
"Verb learning and the early development of sentence comprehension    DESCRIPTION (provided by applicant): A fundamental task in sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom. Verb knowledge plays a central role in this task. The verb determines what constituents can appear in the sentence, and what participant roles they will convey. In learning a new verb, a child must determine what relationship among participants the verb refers to, without the set of semantic instructions provided by the verb. The syntactic bootstrapping theory proposes that children use precursors of the adult's knowledge of syntax to understand sentences and therefore to learn verbs. This view is supported by evidence that children as young as 2 assign different meanings to verbs presented in different sentence structures. The proposed research asks what syntactic cues are helpful early in acquisition, before many of the complexities of syntax acquisition have been conquered. First, we argue that children treat the number of nouns in the sentence as a cue to its semantic predicate- argument structure. The number of nouns in the sentence is useful because it provides a probabilistic indicator of the verb's number of arguments. Second, early syntactic bootstrapping requires that children represent language experience in an abstract mental vocabulary that permits rapid generalization of syntactic learning to new verbs. Thus, we argue that language-specific grammatical learning, such as detecting the significance of word order in English, should transfer quickly to sentences containing new verbs, permitting progressively finer constraint on sentence interpretation and verb learning. This project explores how syntactic bootstrapping begins, and how it interacts with early progress in syntax acquisition. We take two complementary approaches: (1) Experiments with infants and toddlers will investigate the detection and use of the proposed simple structural cues to sentence interpretation and verb learning. (2) Computational experiments using a system for automatic semantic role labeling will test the main claims of our account using a substantial sample of natural child-directed speech. This combination of experimental and computational studies is intended to advance scientific knowledge about how children learn their native languages, and to guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how infants and toddlers learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.           n/a",Verb learning and the early development of sentence comprehension,7386787,R01HD054448,"['Accounting', 'Adopted', 'Adult', 'American', 'Architecture', 'Body of uterus', 'Child', 'Comprehension', 'Computer Simulation', 'Computers', 'Cues', 'Databases', 'Detection', 'Development', 'Eating', 'Event', 'Face', 'Goals', 'Hand', 'Hearing', 'Heart', 'Infant', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Licensing', 'Linguistics', 'Mind', 'Modeling', 'Natural Language Processing', 'Numbers', 'Participant', 'Patient Agents', 'Play', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Psyche structure', 'Psychologist', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Training', 'Vocabulary', 'Work', 'abstracting', 'base', 'computer studies', 'experience', 'feeding', 'lens', 'lexical', 'novel', 'programs', 'remediation', 'research study', 'success', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2008,239691,0.09542299010624786
"Cognitive Representation in Specific Language Impairment    DESCRIPTION (provided by applicant): The purpose of this project is to investigate the nature of implicit learning in children with Specific Language Impairment (SLI). A key question is whether the language impairments seen in these children are due to impaired cognitive processing mechanisms or are a representational deficit in a specific grammar module. Recently, it has been proposed that: (1) the syntax, morphology, auditory processing, and working memory deficits seen in children with SLI are due instead to a procedural implicit learning deficit, and (2) the relatively spared vocabulary abilities in children with SLI suggests an intact declarative learning system that may function as a compensatory mechanism in their language acquisition. Procedural memory is used in the learning of sequential, cognitive, and perceptual motor skills. Recent work suggests, however, that SLI may instead be a domain general implicit learning impairment that extends beyond procedural learning to include category learning, statistical, and artificial grammar learning, and that this implicit learning impairment may extend beyond the perceptual motor system to include the auditory and visual modalities as well. The purpose of this project is to determine if implicit learning in children with SLI is a domain general or domain specific impairment. A total of 170 children will participate in this 5-year project, including 85 children with SLI, 7-9 years of age and 85 normal language controls (CA) matched on chronological age, nonverbal IQ, and maternal education. A total of 9 implicit learning studies are proposed. Studies 1-3 will examine directly whether implicit learning in children with SLI (N = 45) is impaired for implicit category, statistical, and artificial grammar learning on tasks designed to have auditory, visual, and perceptual motor isomorphs as compared to CA controls (N = 45). Studies 4-6 will examine the nature and time course of implicit category, statistical, and artificial grammar learning in the auditory modality and ask if this knowledge transfers to visual and perceptual motor modalities in children with SLI (N = 40) and CA controls (N = 40). Studies 7-9 ask whether implicit learning predicts not only syntax and morphology knowledge, but also vocabulary knowledge, in both children with SLI (N = 85) and CA controls (N = 85). Theoretically, these studies extend our understanding of linguistic and nonlinguistic deficits in children with SLI by clarifying the extent to which modality specific or general implicit learning deficits may contribute to the language impairments seen in these children. Clinically, these studies will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the implicit learning of abstract representations in children with SLI, and will lead to the development of effective intervention models for school-aged children with SLI who are at risk for severe difficulties in communication, reading, writing, and academic failure. PUBLIC HEALTH RELEVANCE The purpose of this project is to investigate implicit learning in children with Specific Language Impairment (SLI). There is evidence to suggest that children with SLI may have a domain general deficit in implicit learning. Implicit learning is gradual, occurring on an ongoing basis across multiple trials or exemplars, and appears to be the mechanism by which language is learned in typically developing children. The studies proposed in this project address the gap in our understanding of implicit learning abilities in children with SLI by directly examining the extent to which children with SLI may have a modality general implicit learning impairment. The findings from this research will provide valuable insights into the nature and intensity of intervention that may be required to facilitate the language learning in children with language impairments, and will aid the development of effective intervention models for school-aged children with language impairments who are at risk for severe difficulties in communication, reading, writing, and academic failure.          n/a",Cognitive Representation in Specific Language Impairment,7470513,R01DC005650,"['Address', 'Age', 'Age-Years', 'Auditory', 'Categories', 'Child', 'Cognitive', 'Collection', 'Communication', 'Complex', 'Conscious', 'Development', 'Education', 'Emotional', 'Exposure to', 'Failure', 'Habits', 'Hearing', 'Impairment', 'Intervention', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Measures', 'Memory', 'Memory impairment', 'Modality', 'Modeling', 'Morphology', 'Motor', 'Motor Skills', 'Nature', 'Neurologic', 'Performance', 'Process', 'Public Health', 'Purpose', 'Reading', 'Research', 'Risk', 'School-Age Population', 'Secondary to', 'Short-Term Memory', 'Stimulus', 'System', 'Time', 'Visual', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'design', 'experience', 'implicit memory', 'improved', 'insight', 'lexical', 'motor skill learning', 'novel', 'procedural memory', 'specific language impairment', 'success', 'syntax', 'visual process', 'visual processing']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2008,307451,0.06549886463655095
"Linking Language Comprehension to Production Patterns    DESCRIPTION (provided by applicant): This project tests specific hypotheses about dependencies between language comprehension and production, which are typically studied independently. The PI's production-distribution-comprehension (PDC) account holds that utterance planning choices during language production yield distributional patterns in the language, in which certain syntactic structures co-vary with particular word choices, messages, and discourse environments. Comprehenders, through statistical learning during prior comprehension experiences, become highly sensitive to these patterns, and this sensitivity guides comprehension processes. Thus, many aspects of comprehension can ultimately be traced to task demands related to language production. Specific aims of the project include: (1) Link syntactic structure choice in production to mechanisms of sentence planning. (2) Compare the PDC account of comprehension to alternative views of relative clause interpretation. (3) Test the causal relations between production constraints, distributional patterns in the language, and comprehension performance. (4) Relate adult sentence comprehension to statistical learning. (5) Test the current limits of constraint-based models of language comprehension. The PDC approach offers a significant alternative to other views and also may inform language acquisition research by illuminating the role of distributional patterns in child language acquisition. The work also can inform language therapies for brain injured patients in several ways. First, sources of production difficulty are precisely investigated, as are accommodations that unimpaired speakers make in the face of this difficulty. Second, the project investigates the relationship between prior experience with a syntactic construction and comprehension difficulty, which can have implications for the amount and nature of practice that should be provided to patients to improve their comprehension of certain sentence types.         n/a",Linking Language Comprehension to Production Patterns,7426941,R01HD047425,"['Accounting', 'Address', 'Adult', 'Affect', 'Back', 'Brain', 'Brain Injuries', 'Characteristics', 'Child Language', 'Collaborations', 'Comprehension', 'Data', 'Dependence', 'Dependency', 'Depth', 'Disease', 'Environment', 'Face', 'Facility Construction Funding Category', 'Foxes', 'Human Characteristics', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Therapy', 'Learning', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Nature', 'Patients', 'Pattern', 'Performance', 'Play', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Short-Term Memory', 'Source', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Work', 'base', 'experience', 'feeding', 'improved', 'infancy', 'injured', 'insight', 'neuropathology', 'novel', 'preference', 'research study', 'statistics', 'stem', 'syntax', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2008,164747,0.12315615518947916
"Sensitivity to spectral cues in infant speech perception    DESCRIPTION (provided by applicant): The proposed research will examine infants' sensitivity to multiple spectral cues in speech perception. Speech is a complex signal, with numerous acoustic cues for every consonant and vowel. Through experience, listeners learn to exploit correlations between multiple cues, making perception more efficient and robust. Adults display this knowledge through their use of cues that are spectrally local (e.g. formant transitions) as well as distributed (e.g. gross spectral shape, or tilt) to distinguish speech sounds. Although prior research has demonstrated infants' ability to distinguish many speech sounds, how they distinguish these sounds is unclear. Infants' sensitivity to individual cues, the relative importance they assign to each cue, and when they learn to exploit correlations between cues all remain poorly understood. We propose four experiments to address these questions. The first aim of this project is to investigate sensitivity to spectral cues. To address this issue, the first two experiments will examine speech perception when the natural covariance between two cues is violated or maintained. The latter two experiments will test sensitivity to changes in individual cues. The second aim is to assess relative cue salience across the lifespan. Results from the first experiment will be compared to existing data from normal-hearing and hearing-impaired elderly adult listeners who completed a similar task (Alexander & Kluender, in press; in preparation) to assess differential effects of listening experience and hearing health on perception of the same speech stimuli. We hypothesize that both 6-to-7-month-old and 11-to-12-month-old-infants will exhibit perceptual sensitivity to both spectral cues in speech perception, with 11-to-12-month-olds displaying the greatest sensitivity. We also hypothesize that younger infants may be relatively more influenced by spectrally global (e.g. tilt) cues than older infants. Our long-term objective is to better understand development of speech perception in infants with normal and compromised hearing. These results will help refine treatment methods for infants with hearing loss, and inform the use of devices such as hearing aids and cochlear implants. Public health statement: The proposed research will reveal the acoustic information infants use to distinguish speech sounds, and whether this information is used differently by adults. Knowing what infants listen for will benefit efforts to facilitate development of speech perception in children with compromised hearing. This research will also investigate when infants learn to exploit statistical regularities between cues in natural speech.             n/a",Sensitivity to spectral cues in infant speech perception,7546798,F31DC009532,"['Acoustics', 'Address', 'Adult', 'Affect', 'Age', 'Body Weight Changes', 'Child', 'Classification', 'Cochlear Implants', 'Complex', 'Condition', 'Conflict (Psychology)', 'Cues', 'Data', 'Development', 'Devices', 'Elderly', 'Environment', 'Exhibits', 'Frequencies', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Individual', 'Infant', 'Knowledge', 'Learning', 'Light', 'Longevity', 'Machine Learning', 'Methods', 'Modality', 'Perception', 'Population', 'Preparation', 'Public Health', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Resolution', 'Sensorineural Hearing Loss', 'Sensory', 'Shapes', 'Signal Transduction', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'System', 'Testing', 'Voice', 'Weight', 'base', 'experience', 'hearing impairment', 'infancy', 'research study', 'response', 'sound']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2008,27212,0.13406942416529313
"A Shared Database for the Study of Phonological Development DESCRIPTION:  The study of phonological development has important implications for the diagnosis and treatment of language disorders, models of the biological bases of language production, the teaching of second languages, and the general advancement of linguistic theory. Recents advances in computational power make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project (http://childes.psy.cmu.edu) now provides universal access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not yet built effective tools for phonological and phonetic analysis.  We will close this gap by developing a new Java-based program called Phon that interfaces with the CHILDES transcription format. Phon provides: (1) easy user-controlled utterance boundary marking, (2) an input method for Unicode IPA transcription of child forms, (3) automatic alignment of segments in child forms to waveform regions, (4) automatic insertion of the IPA form for adult target words, (5) automatic alignment of child forms to the adult targets for both segmental and prosodic levels, (6) tools for querying the database, and (7) tools for composing output reports. Phon will be configured to run either locally or over the web as a Java WebStart application. The construction of the new database will be supported by a group of 26 researchers who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data will be structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. Benchmarks will be established to emphasize the direct competitive teasting of competing hypotheses from alternative theoretical and methodological positions. n/a",A Shared Database for the Study of Phonological Development,7426485,R01HD051698,"['Acoustics', 'Adult', 'Algorithms', 'Benchmarking', 'Biological', 'Body of uterus', 'Child', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease model', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Extensible Markup Language', 'Facility Construction Funding Category', 'Frequencies', 'Generations', 'Genetic Transcription', 'Goals', 'Individual Differences', 'Internet', 'Java', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Numbers', 'Output', 'Participant', 'Pattern', 'Phonetics', 'Positioning Attribute', 'Production', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Running', 'Series', 'Standards of Weights and Measures', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'digital', 'disability', 'lexical', 'member', 'phonology', 'programs', 'sound', 'syntax', 'theories', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2008,228551,0.06242650349155976
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,7386008,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Appendix', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Other Finding', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Design', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical developmental period', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2008,539966,0.22241601537983632
"A Direct Brain to Speech Generator for use in Humans    DESCRIPTION (provided by applicant): LONG TERM OBJECTIVES AND SPECIFIC AIMS: We aim to restore near conversational rate speech in locked-in individuals. In the Phase 1 study, neural recordings from the speech motor area in a 23 year old locked-in subject implanted with the Neurotrophic Electrode System since December 2004 have yielded neural data that have been mapped to phonemic representations and to imagined and actual movements. In the proposed work, we intend to incorporate sophisticated speech recognition algortithms, such as Artificial Neural Networks and Hidden Markov Models, in order to enable rapid pattern recognition for purposes of a real-time Speech Prosthetic development. In addition, Population Vector Analysis as performed for chronic motor studies may realize a method of converting individual neuronal firings into Phonemic or Articulatory Space for driving a Speech Synthesis Model. An additional patient will be implanted with the electrode system to expand and verify the work achieved with the initial subject. The resulting data will add much to understanding the cortical organization of speech production and accelerate the development of a speech prosthetic for locked-in individuals. The website development for data sharing purposes will be expanded and used by the collaborators and other interested parties.       RELEVANCE OF RESEARCH TO PUBLIC HEALTH: The creation of a Speech Prosthetic Device is much needed by locked-in patients suffering from ALS and brain stem stroke. The substantial research being performed in invasive neuroprosthetic studies is focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software. This work is helpful to locked-in patients; however, such patients have indicated that real-time spontaneous speech is a much more desirable final application. The purpose of this research is to develop a speech prosthetic device using the Neurotrophic Electrode Human Cortical Recording system with sophisticated pattern recognition models and software. The majority of neuroprosthetic studies are focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software, however we believe that real-time spontaneous speech would be much more desirable application to locked-in patients.          n/a",A Direct Brain to Speech Generator for use in Humans,7458646,R44DC007050,"['Amyotrophic Lateral Sclerosis', 'Area', 'Automobile Driving', 'Back', 'Biological Neural Networks', 'Brain', 'Brain Stem', 'Brain Stem Infarctions', 'Chronic', 'Class', 'Classification', 'Communication', 'Computer software', 'Condition', 'Controlled Study', 'Data', 'Data Analyses', 'Development', 'Electrodes', 'Evaluation', 'Feeds', 'Fire - disasters', 'Frequencies', 'Human', 'Hybrids', 'Implant', 'Individual', 'Invasive', 'Investigation', 'Learning', 'Left', 'Limb structure', 'Link', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Motor', 'Movement', 'Neurons', 'Numbers', 'Output', 'Paralysed', 'Pathway interactions', 'Patients', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Phase', 'Phase I Clinical Trials', 'Play', 'Population', 'Population Analysis', 'Process', 'Production', 'Prosthesis', 'Public Health', 'Purpose', 'Rate', 'Recording of previous events', 'Recovery', 'Reporting', 'Research', 'Role', 'Signal Transduction', 'Site', 'Sorting - Cell Movement', 'Speech', 'Speech Synthesizers', 'Speed', 'Stream', 'Stroke', 'System', 'Time', 'Training', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'base', 'data acquisition', 'design', 'detector', 'implantation', 'improved', 'interest', 'male', 'markov model', 'motor control', 'relating to nervous system', 'sound', 'speech recognition', 'tool', 'vector']",NIDCD,"NEURAL SIGNALS, INC.",R44,2008,452155,0.11747450650463175
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7305430,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,229030,0.051231787171152884
"When cues converge: multiple regularities in language acquisition    DESCRIPTION (provided by applicant): The goal of this research project is to employ behavioral and computational methods to better understand how infants use multiple regularities when learning language. Many researchers have posited that infants use statistical learning mechanisms to extract these regularities. However, the majority of this work focuses on infants' abilities to exploit a single regularity. In their natural environment, infants receive input that contains many overlapping regularities of varying consistency. Little research has focused on how infants process this type of input. In order to make use of the cues available in natural input, infants must be able to exploit these overlapping probabilistic regularities. The first aim of this grant is to explore how infants use multiple regularities to find words in fluent speech. By 9 months, infants are able to robustly use both lexical stress and sequential statistics to segment words. However, prior research has focused on how infants use these regularities in isolation, or how weighting of the cues changes developmentally. We hypothesize that infants can use these cues for word segmentation when they are probabilistic and overlapping, as they are in natural languages such as English. The second aim is to investigate the effect of multiple regularities on word learning. As a child's vocabulary grows, regularities arise among the labels and referents they know, as well as within the mappings between labels and referents. These regularities may affect the acquisition of new words. However, their potential role in subsequent word learning has not been carefully explored. Using computational models, we can examine these issues by carefully controlling regularities that exist within a vocabulary and by exploring how different types of regularities may affect word learning. These models can lead to a deeper understanding of these processing mechanisms and to novel predictions, which can then be tested in behavioral experiments.    Public Health Interests:  The goal of this research is to better understand how typically developing infants learn language - in particular, how they use the many patterns that exist in natural languages to do so. The ability to make use of multiple regularities likely affects infants' skills at language learning. By better understanding how this process unfolds in typically developing infants, researchers will be able to investigate how children with language delays and disabilities may differ in their ability to integrate multiple cues. In the future, this information will be useful for developing treatment plans.           n/a",When cues converge: multiple regularities in language acquisition,7286034,F31DC008737,"['Adherence', 'Affect', 'Behavioral', 'Body of uterus', 'Child', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Cues', 'Depth', 'Educational process of instructing', 'Environment', 'Face', 'Future', 'Goals', 'Grant', 'Infant', 'Label', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Maps', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Numbers', 'Pattern', 'Probability', 'Process', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Speech', 'Stress', 'System', 'Testing', 'Vocabulary', 'Weight', 'Work', 'design', 'disability', 'experience', 'interest', 'lexical', 'novel', 'research study', 'simulation', 'skills', 'sound', 'statistics', 'tool', 'treatment planning']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,F31,2007,31498,0.06884194689258305
"Statistical Learning in Language Acquisition DESCRIPTION (provided by applicant): Acquiring a language is among the most daunting feats uniformly accomplished by our species. Explorations of the language learning process present the opportunity to address central issues pertaining to human cognition and its development. The proposed research represents one approach to this topic: the study of the architecture of the learning processes underlying language acquisition, using laboratory learning experiments performed with adult, child, and infant participants. The goal of this research program is to substantially increase our knowledge of the statistical learning mechanisms that detect linguistic units by tracking the patterns of sounds, words, and other units in the input. Recent results suggest that statistical learning processes play an important role in the acquisition of language. However, little is currently known about the types of statistical regularities computed by learners and the constraints on learning that support successful knowledge acquisition. The proposed experiments will ask: (1) How does the structure of the input constrain statistical learning? Studies will consider perceptual, linguistic, and informational constraints on the choice of cues as input to learning. (2) How does prior experience influence statistical learning? Manipulations of prior experience, inside and outside the lab, will be used to assess effects on subsequent learning. (3) Can statistical learning account for basic phenomena in language acquisition? Interactions between statistical learning and other types of processes, such as rule learning and the presence of other cues in the input, will be investigated. All of these issues will be addressed using previously developed laboratory learning paradigms that permit careful manipulation of input and detailed assessment of what participants are able to learn. Studies using linguistic materials will be contrasted with studies using nonlinguistic materials to further explore the locus and domain-specificity of the learning mechanisms under consideration. The answers to these questions will inform an emerging theoretical framework, constrained statistical learning, intended to elucidate the study of language acquisition and other pressing issues in human learning and development. n/a",Statistical Learning in Language Acquisition,7144995,R01HD037466,"['Accounting', 'Acoustics', 'Address', 'Adult', 'Affect', 'Architecture', 'Categories', 'Child', 'Cognition', 'Complex', 'Cues', 'Development', 'Goals', 'Human', 'Indium', 'Infant', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Machine Learning', 'Methodology', 'Nature', 'Operative Surgical Procedures', 'Output', 'Participant', 'Pattern', 'Play', 'Probability', 'Process', 'Research', 'Role', 'Solutions', 'Specificity', 'Speech', 'Structure', 'System', 'analog', 'base', 'design', 'experience', 'programs', 'research study', 'sound', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2007,275672,0.08880531172927943
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          n/a",Intonation in spontaneous English & Japanese dialogue,7253196,R01DC007090,"['Accounting', 'Acoustics', 'Address', 'Artificial Intelligence', 'Attention', 'Characteristics', 'Clinical Engineering', 'Cochlear Implants', 'Cognitive', 'Collection', 'Communication', 'Communication Aids for Disabled', 'Complex', 'Comprehension', 'Condition', 'Cues', 'Development', 'Devices', 'Diagnosis', 'Education', 'Eye Movements', 'Future', 'Generations', 'Goals', 'Head', 'Hearing', 'Human', 'Instruction', 'Japanese Population', 'Knowledge', 'Language', 'Lead', 'Linguistics', 'Link', 'Measures', 'Memory', 'Methodology', 'Modeling', 'Monitor', 'Names', 'Nature', 'Patients', 'Pattern', 'Performance', 'Phonetics', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Rate', 'Reading', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Vocabulary', 'Writing', 'aphasic', 'base', 'clinical application', 'cognitive function', 'disability', 'efficacy research', 'improved', 'language processing', 'lexical', 'novel', 'oral communication', 'phonology', 'programs', 'research study', 'speech accuracy', 'syntax', 'theories', 'transmission process']",NIDCD,OHIO STATE UNIVERSITY,R01,2007,216654,0.16899834654316018
"Constraints on Learning from Inconsistent Input    DESCRIPTION (provided by applicant): All human learners with normal cognitive capacities who are exposed to language input in childhood manage to acquire a language that looks very much like their input. However, at present we have little idea how, exactly, learners accomplish this feat. We have little understanding of the nature of the learning mechanisms that underlie and support language learning. This is the focus of the research in this proposal. Three general questions guide the research. (1) What are the constraints on language learning mechanisms? (2) Are the learning mechanisms involved in language acquisition specific to language or are they of a more general nature? (3) Do these mechanisms change over time as learners age, and if 'so, how? The proposed research examines these questions by investigating the learning of probabilistic and inconsistent patterns in the input using miniature artificial languages. This provides a rather unique view of the constraints on learning mechanisms, examining the limits of what can and cannot be learned. Previous work has shown that learners can acquire probabilistic patterns, however they sometimes impose consistency on variation. Moreover, children are more likely to change such patterns than are adults. The present research expands on the earlier results, asking about the nature of the interaction between learners and input. Series 1 asks about the nature of the input that makes some inconstancy learnable and some not. The studies examine the limits of veridical learning of inconsistent patterns in languages, asking questions about the specificity of computations learners can perform, the representations over which such computations can be performed, and the effect of prior domain-specific knowledge. Series 2 asks about the nature of the learner, asking why learners regularize over inconsistency at all. In particular, the studies examine whether working memory constraints, rather than constraints stemming directly from the learning mechanisms themselves, are an important factor influencing whether learners acquire the variation or instead impose regularity. Both series will be conducted with adults and children to examine how learning changes over development. Although the input in the proposed studies is somewhat atypical, the results from these studies will contribute to our understanding of the learning mechanisms involved in language acquisition more generally, and ultimately, this increases our understanding of both normal and disordered acquisition.         n/a",Constraints on Learning from Inconsistent Input,7212176,R01HD048572,"['Address', 'Adult', 'Affect', 'Age', 'Animals', 'Child', 'Childhood', 'Cognitive', 'Complex', 'Computer information processing', 'Data', 'Development', 'Disease', 'Elements', 'Goals', 'Human', 'Knowledge', 'Language', 'Language Development', 'Lead', 'Learning', 'Machine Learning', 'Modality', 'Nature', 'Numbers', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Research', 'Research Design', 'Research Personnel', 'Series', 'Short-Term Memory', 'Source', 'Specificity', 'Time', 'Variant', 'Work', 'age related', 'design', 'programs', 'research study', 'stem']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,186741,0.07909605257296186
"Verb learning and the early development of sentence comprehension    DESCRIPTION (provided by applicant): A fundamental task in sentence comprehension involves assigning semantic roles to sentence constituents, determining who does what to whom. Verb knowledge plays a central role in this task. The verb determines what constituents can appear in the sentence, and what participant roles they will convey. In learning a new verb, a child must determine what relationship among participants the verb refers to, without the set of semantic instructions provided by the verb. The syntactic bootstrapping theory proposes that children use precursors of the adult's knowledge of syntax to understand sentences and therefore to learn verbs. This view is supported by evidence that children as young as 2 assign different meanings to verbs presented in different sentence structures. The proposed research asks what syntactic cues are helpful early in acquisition, before many of the complexities of syntax acquisition have been conquered. First, we argue that children treat the number of nouns in the sentence as a cue to its semantic predicate- argument structure. The number of nouns in the sentence is useful because it provides a probabilistic indicator of the verb's number of arguments. Second, early syntactic bootstrapping requires that children represent language experience in an abstract mental vocabulary that permits rapid generalization of syntactic learning to new verbs. Thus, we argue that language-specific grammatical learning, such as detecting the significance of word order in English, should transfer quickly to sentences containing new verbs, permitting progressively finer constraint on sentence interpretation and verb learning. This project explores how syntactic bootstrapping begins, and how it interacts with early progress in syntax acquisition. We take two complementary approaches: (1) Experiments with infants and toddlers will investigate the detection and use of the proposed simple structural cues to sentence interpretation and verb learning. (2) Computational experiments using a system for automatic semantic role labeling will test the main claims of our account using a substantial sample of natural child-directed speech. This combination of experimental and computational studies is intended to advance scientific knowledge about how children learn their native languages, and to guide the development of new, robust learning protocols that will be of use in automatic natural language processing. The proposed research will help us to understand how infants and toddlers learn the words and syntax of their native languages; such research will contribute to the detection and remediation of language delays, and to language pedagogy.           n/a",Verb learning and the early development of sentence comprehension,7176737,R01HD054448,"['Accounting', 'Adopted', 'Adult', 'American', 'Architecture', 'Body of uterus', 'Child', 'Comprehension', 'Computer Simulation', 'Computers', 'Cues', 'Databases', 'Detection', 'Development', 'Eating', 'Event', 'Face', 'Goals', 'Hand', 'Hearing', 'Heart', 'Infant', 'Instruction', 'Knowledge', 'Label', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Licensing', 'Linguistics', 'Mind', 'Modeling', 'Natural Language Processing', 'Numbers', 'Participant', 'Patient Agents', 'Play', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Psyche structure', 'Psychologist', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Source', 'Speech', 'Structure', 'System', 'Testing', 'Toddler', 'Training', 'Vocabulary', 'Work', 'abstracting', 'base', 'computer studies', 'experience', 'feeding', 'lens', 'lexical', 'novel', 'programs', 'remediation', 'research study', 'success', 'syntax', 'theories']",NICHD,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2007,241833,0.09542299010624786
"Linking Language Comprehension to Production Patterns    DESCRIPTION (provided by applicant): This project tests specific hypotheses about dependencies between language comprehension and production, which are typically studied independently. The PI's production-distribution-comprehension (PDC) account holds that utterance planning choices during language production yield distributional patterns in the language, in which certain syntactic structures co-vary with particular word choices, messages, and discourse environments. Comprehenders, through statistical learning during prior comprehension experiences, become highly sensitive to these patterns, and this sensitivity guides comprehension processes. Thus, many aspects of comprehension can ultimately be traced to task demands related to language production. Specific aims of the project include: (1) Link syntactic structure choice in production to mechanisms of sentence planning. (2) Compare the PDC account of comprehension to alternative views of relative clause interpretation. (3) Test the causal relations between production constraints, distributional patterns in the language, and comprehension performance. (4) Relate adult sentence comprehension to statistical learning. (5) Test the current limits of constraint-based models of language comprehension. The PDC approach offers a significant alternative to other views and also may inform language acquisition research by illuminating the role of distributional patterns in child language acquisition. The work also can inform language therapies for brain injured patients in several ways. First, sources of production difficulty are precisely investigated, as are accommodations that unimpaired speakers make in the face of this difficulty. Second, the project investigates the relationship between prior experience with a syntactic construction and comprehension difficulty, which can have implications for the amount and nature of practice that should be provided to patients to improve their comprehension of certain sentence types.         n/a",Linking Language Comprehension to Production Patterns,7226029,R01HD047425,"['Accounting', 'Address', 'Adult', 'Affect', 'Back', 'Brain', 'Brain Injuries', 'Characteristics', 'Child Language', 'Collaborations', 'Comprehension', 'Data', 'Dependence', 'Dependency', 'Depth', 'Disease', 'Environment', 'Face', 'Facility Construction Funding Category', 'Foxes', 'Human Characteristics', 'Individual', 'Infant', 'Investigation', 'Knowledge', 'Language', 'Language Development', 'Language Therapy', 'Learning', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Nature', 'Patients', 'Pattern', 'Performance', 'Play', 'Population', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Short-Term Memory', 'Source', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Work', 'base', 'experience', 'feeding', 'improved', 'infancy', 'injured', 'insight', 'neuropathology', 'novel', 'preference', 'research study', 'statistics', 'stem', 'syntax', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R01,2007,168217,0.12315615518947916
"A Shared Database for the Study of Phonological Development DESCRIPTION:  The study of phonological development has important implications for the diagnosis and treatment of language disorders, models of the biological bases of language production, the teaching of second languages, and the general advancement of linguistic theory. Recents advances in computational power make it possible for researchers to link high quality digital recordings to phonological and phonetic transcriptions. Using standards such as Unicode, IPA, and XML, the CHILDES database project (http://childes.psy.cmu.edu) now provides universal access to large corpora of transcripts linked to audio for students of both first and second language acquisition, along with a wide array of tools for lexical, syntactic, and discourse analysis. However, the CHILDES Project has not yet built effective tools for phonological and phonetic analysis.  We will close this gap by developing a new Java-based program called Phon that interfaces with the CHILDES transcription format. Phon provides: (1) easy user-controlled utterance boundary marking, (2) an input method for Unicode IPA transcription of child forms, (3) automatic alignment of segments in child forms to waveform regions, (4) automatic insertion of the IPA form for adult target words, (5) automatic alignment of child forms to the adult targets for both segmental and prosodic levels, (6) tools for querying the database, and (7) tools for composing output reports. Phon will be configured to run either locally or over the web as a Java WebStart application. The construction of the new database will be supported by a group of 26 researchers who have agreed to contribute already collected and transcribed corpora from children learning 17 different languages. Subjects include bilingual children, normally-developing monolinguals, and children with language disorders. The data will be structured to facilitate testing of models regarding babbling universals, variant paths in segmental and prosodic development, markedness effects, prosodic context effects, segmentation patterns, statistical learning, frequency effects, interlanguage transfer, diagnosis of disability, stuttering patterns, disfluency patterns, and the effects of morphology and syntax. Benchmarks will be established to emphasize the direct competitive teasting of competing hypotheses from alternative theoretical and methodological positions. n/a",A Shared Database for the Study of Phonological Development,7265230,R01HD051698,"['Acoustics', 'Adult', 'Algorithms', 'Benchmarking', 'Biological', 'Body of uterus', 'Child', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease model', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Extensible Markup Language', 'Facility Construction Funding Category', 'Frequencies', 'Generations', 'Genetic Transcription', 'Goals', 'Individual Differences', 'Internet', 'Java', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Numbers', 'Output', 'Participant', 'Pattern', 'Phonetics', 'Positioning Attribute', 'Production', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Running', 'Series', 'Standards of Weights and Measures', 'Structure', 'Students', 'Stuttering', 'System', 'Testing', 'Transcript', 'Variant', 'Work', 'base', 'digital', 'disability', 'lexical', 'member', 'phonology', 'programs', 'sound', 'syntax', 'theories', 'tool']",NICHD,CARNEGIE-MELLON UNIVERSITY,R01,2007,234683,0.06242650349155976
"Development of Speech Perception and Brain Plasticity    DESCRIPTION (provided by applicant): Language is a hallmark of human beings. In the last 50 years, debates on language have given way to a new view of the process by which humans acquire language. One catalyst for theoretical change has been empirical studies on infants. In the last decade, researchers have not only charted when infants acquire knowledge about the properties of their native language, but how they do so, and this has caused a revision in linguistic and psychological theories. New research focuses on the phonetic units of speech, the consonants and vowels that form building blocks for words. Key advances from this laboratory are cross- language data showing that infants learn from exposure to language in the earliest periods of development and that this alters speech perception to assist language learning. Moreover, our studies show that early speech predicts later language, and that the clarity of mothers' infant-directed speech is linked to infants' speech perception abilities. Finally, brain measures on infants and adults listening to language suggest that, during early development, the infant brain ""neurally commits"" to the patterns of native language speech and that this both promotes future language learning as well as the decline in nonnative speech perception that occurs at the end of the first year of life. This work on early speech perception is impacting child development, neuroscience, neurobiology, and computational modeling. The early speech measures developed as a part of this project are being used in the study of developmental disabilities including autism, and may provide an early marker of the disability. The data prompted an extension of the Native Language Magnet model to incorporate neural commitment as the mechanism for developmental change. This theoretical position provides the background and framework for the studies in this proposal. Four converging lines of research are proposed to test the theory and further advance our knowledge of infant speech development: (a) speech perception development and its impact on language; (b) the brain correlates of early speech and language development, (c) the role of language input to children, and (d) brain plasticity and the ""critical period"" for language acquisition. The research will produce data that address theories of speech and language development and more general theories of the interface between biology and culture.           n/a",Development of Speech Perception and Brain Plasticity,7212358,R01HD037954,"['Acoustics', 'Address', 'Adult', 'Age-Months', 'Age-Years', 'Appendix', 'Audiotape', 'Autistic Disorder', 'Biology', 'Birth', 'Brain', 'Characteristics', 'Child', 'Child Development', 'Commit', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Developmental Disabilities', 'Event-Related Potentials', 'Evolution', 'Exposure to', 'Funding', 'Future', 'Hour', 'Human', 'Individual', 'Infant', 'Infant Development', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Learning', 'Life', 'Linguistics', 'Link', 'Longevity', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Modeling', 'Mothers', 'Nature', 'Neurobiology', 'Neurosciences', 'Newborn Infant', 'Other Finding', 'Pattern', 'Perception', 'Phase', 'Phonetics', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Psychological Theory', 'Research', 'Research Design', 'Research Personnel', 'Role', 'Social Interaction', 'Speech', 'Speech Development', 'Speech Perception', 'Techniques', 'Television', 'Testing', 'Time', 'Work', 'catalyst', 'critical developmental period', 'disability', 'foreign language', 'infancy', 'language processing', 'relating to nervous system', 'skills', 'theories']",NICHD,UNIVERSITY OF WASHINGTON,R01,2007,573458,0.22241601537983632
"A Direct Brain to Speech Generator for use in Humans    DESCRIPTION (provided by applicant): LONG TERM OBJECTIVES AND SPECIFIC AIMS: We aim to restore near conversational rate speech in locked-in individuals. In the Phase 1 study, neural recordings from the speech motor area in a 23 year old locked-in subject implanted with the Neurotrophic Electrode System since December 2004 have yielded neural data that have been mapped to phonemic representations and to imagined and actual movements. In the proposed work, we intend to incorporate sophisticated speech recognition algortithms, such as Artificial Neural Networks and Hidden Markov Models, in order to enable rapid pattern recognition for purposes of a real-time Speech Prosthetic development. In addition, Population Vector Analysis as performed for chronic motor studies may realize a method of converting individual neuronal firings into Phonemic or Articulatory Space for driving a Speech Synthesis Model. An additional patient will be implanted with the electrode system to expand and verify the work achieved with the initial subject. The resulting data will add much to understanding the cortical organization of speech production and accelerate the development of a speech prosthetic for locked-in individuals. The website development for data sharing purposes will be expanded and used by the collaborators and other interested parties.       RELEVANCE OF RESEARCH TO PUBLIC HEALTH: The creation of a Speech Prosthetic Device is much needed by locked-in patients suffering from ALS and brain stem stroke. The substantial research being performed in invasive neuroprosthetic studies is focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software. This work is helpful to locked-in patients; however, such patients have indicated that real-time spontaneous speech is a much more desirable final application. The purpose of this research is to develop a speech prosthetic device using the Neurotrophic Electrode Human Cortical Recording system with sophisticated pattern recognition models and software. The majority of neuroprosthetic studies are focused on enabling recovery of lost motor functions in paralyzed limbs or providing indirect communication through computer software, however we believe that real-time spontaneous speech would be much more desirable application to locked-in patients.          n/a",A Direct Brain to Speech Generator for use in Humans,7328424,R44DC007050,"['Amyotrophic Lateral Sclerosis', 'Area', 'Automobile Driving', 'Back', 'Biological Neural Networks', 'Brain', 'Brain Stem', 'Brain Stem Infarctions', 'Chronic', 'Class', 'Classification', 'Communication', 'Computer software', 'Condition', 'Controlled Study', 'Data', 'Data Analyses', 'Development', 'Electrodes', 'Evaluation', 'Feeds', 'Fire - disasters', 'Frequencies', 'Human', 'Hybrids', 'Implant', 'Individual', 'Invasive', 'Investigation', 'Learning', 'Left', 'Limb structure', 'Link', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Motor', 'Movement', 'Neurons', 'Numbers', 'Output', 'Paralysed', 'Pathway interactions', 'Patients', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Phase', 'Phase I Clinical Trials', 'Play', 'Population', 'Population Analysis', 'Process', 'Production', 'Prosthesis', 'Public Health', 'Purpose', 'Rate', 'Recording of previous events', 'Recovery', 'Reporting', 'Research', 'Role', 'Signal Transduction', 'Site', 'Sorting - Cell Movement', 'Speech', 'Speech Synthesizers', 'Speed', 'Stream', 'Stroke', 'System', 'Time', 'Training', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'base', 'data acquisition', 'design', 'detector', 'implantation', 'improved', 'interest', 'male', 'markov model', 'motor control', 'relating to nervous system', 'sound', 'speech recognition', 'tool', 'vector']",NIDCD,"NEURAL SIGNALS, INC.",R44,2007,369975,0.11747450650463175
"Analysis and Remediation of Language Production DESCRIPTION (provided by applicant): Aphasia strikes approximately one in 250 Americans. The reduced ability to communicate with language represents, in most cases, a catastrophic loss of self-sufficiency and a source of profound social isolation. No treatment for aphasia reported to date has reliably brought about changes in language production that migrate from highly constrained laboratory tasks such as single picture description to more challenging and socially functional tasks such as the production of entire narratives. The current climate in health care limits access to speech therapy, and thus it is imperative to develop approaches to treatment which allow patients to supplement 1:1 clinical treatment with intensive independent home practice. We have developed two computer programs to address the need for effective aphasia treatments that can be used semi-independently. One is a communication system (CS), which allows aphasic users to record spoken sentences a single word or phrase at a time, to replay these words or phrases, and to build them into sentences and narratives by manipulating visual icons on a computer screen. The other program is a language therapy system (TS) incorporating speech recognition and natural language understanding technology, which allows the computer to 'understand' the patient's spoken sentence and to provide feedback about whether it correctly describes a picture on the screen. This allows independent home practice of spoken language. The goals of this project are: (1) to replicate pilot results showing measurably more structured language production by aphasic patients using the CS, and to link these effects to characteristics of subjects' language processing impairments (Exp. 1); (2) to assess the impact of enhancing the CS with word-finding support for more severely impaired patients (Exp. 2); (3) to replicate the positive outcomes in pilot studies which used the TS and CS to improve aphasic patients' spoken language production, and to use the TS to train subjects on grammatical structures that provide tests of specific hypotheses about the impact of impaired short term memory on aphasic production (Exp. 3); and (4) to use data automatically collected by the CS to investigate the nature of the underlying disruption and to motivate the most effective approaches to remediation (Exp. 4). Information obtained from these studies will provide a basis for the further development of novel, theoretically motivated approaches to aphasia treatment. n/a",Analysis and Remediation of Language Production,7188572,R01DC005629,"['Address', 'American', 'Aphasia', 'Characteristics', 'Climate', 'Clinical Treatment', 'Communication', 'Computer software', 'Computers', 'Condition', 'Data', 'Development', 'Disruption', 'Elements', 'Employee Strikes', 'Evaluation', 'Facility Construction Funding Category', 'Feedback', 'Funding', 'Goals', 'Head', 'Healthcare', 'Home environment', 'Impairment', 'Knowledge', 'Laboratories', 'Language', 'Language Therapy', 'Linguistics', 'Link', 'Measures', 'Monitor', 'Natural Language Processing', 'Nature', 'Numbers', 'Outcome', 'Patients', 'Performance', 'Pilot Projects', 'Play', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reporting', 'Role', 'Semantics', 'Short-Term Memory', 'Social isolation', 'Source', 'Speech', 'Speech Therapy', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Visual', 'analytical method', 'aphasic', 'base', 'computer program', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'novel', 'phonology', 'programs', 'remediation', 'size', 'speech recognition', 'syntax', 'treatment effect']",NIDCD,UNIVERSITY OF MARYLAND BALTIMORE,R01,2007,337888,0.10769319288910713
"Articulatory recovery from speech acoustics    DESCRIPTION (provided by applicant): The project's goal is to build methods and algorithms for the recovery of articulatory movement from acoustic speech signals. In the immediate future this will be accomplished by employing analysis-by-techniques for sonorant sounds of English, but with a view to extend this to obstruents and the speech of other languages. There are four main areas of research that will be conducted to reach these goals. The first area is to study the relationship between small changes in articulation and the resulting acoustics, which is feasible now that a large amount of simultaneously recorded articulatory movement and acoustic data are available. The second area of research is in the kinematics of articulatory movement, particularly that of the tongue. Flesh point data enables a data-driven approach to the modeling of tongue kinematics. A quantitative approach to the kinematics of line segments between flesh points, secant lines, is being pursued because it is a first approximation to a kinematics of tongue shape, which is more closely related to acoustics than the flesh points themselves. Because the method for articulatory recovery is analysis-by-synthesis, it is necessary to have an articulatory synthesizer for an internal speech production model. The third area of research is the construction of an articulatory synthesizer that includes knowledge gained from the second area of research. With progress already made in articulatory synthesis, it is possible to concentrate on the kinematic control of the synthesizer. This also will be done from a data-driven approach with piecewise polynomials fit to secant line kinematic trajectories derived from flesh point data. Finally, the fourth area of research is in the recovery algorithms themselves, which include methods for normalization between different vocal tracts and the articulatory synthesizer's vocal tract. Both veridical (actual space-time articulatory trajectories are reproduced) and non-veridical (categorical segmental properties are reproduced for perceptually accurate identification) articulatory will be tested. Veridical articulatory recovery from speech acoustics is useful for the laboratory and clinic when acoustic and partial articulatory information are available and the scientist or clinician wants to know more about articulation. Non-veridical articulatory recovery is important for models of speech and language learning.         n/a",Articulatory recovery from speech acoustics,7046438,R01DC001247,"['X ray', 'artificial intelligence', 'behavioral /social science research tag', 'computational neuroscience', 'computer program /software', 'human data', 'mathematical model', 'speech', 'speech recognition', 'speech synthesizers']",NIDCD,"CRESS, LLC",R01,2006,198938,0.06107264579666441
"Diagnostic Markers for Childhood Apraxia Speech DESCRIPTION (provided by applicant): Childhood Apraxia of Speech is a highly controversial disorder due to a lack of consensus on the features that define it and the etiologic conditions that explain its origin. The term Suspected Apraxia of Speech (sAOS) has been proposed as an interim term for this putative clinical entity. The point prevalence of sAOS in young children has been estimated at approximately 0.1%. The long-term objective of this proposal is to develop a valid, reliable, and efficient means to classify children as positive for sAOS. In addition to the contributions to theoretical explication of AOS, the software-based diagnostic tools resulting from this work will allow any certified speech-language pathologist to determine if a child's speech includes prosodic features that fall within a 95% confidence interval supporting the diagnosis of sAOS. The aim for this first period of planned programmatic research is to develop automated diagnostic markers for sAOS with clinically adequate sensitivity and specificity (> 90% positive and negative likelihood ratios).  The four specific aims are: (a) to automate and improve the sensitivity and specificity of two existing (manually derived) prosodic markers, (b) to develop four additional automatic, prosody-based diagnostic markers, (c) to derive a single diagnostic index based on a statistical derivative from the six individual markers, and (d) to validate the composite diagnostic marker using classification data obtained from expert clinical researchers.  Procedures are divided into four phases. In Year 1, automated versions of existing markers will be developed that determine speech-event locations using automatic speech recognition (ASR). Based on two pilot studies, this technique is expected to yield results equivalent to published data. The sensitivity of the markers will be improved by methods including normalizing by speaking rate and vowel identity. In Year 2, new automated markers will be created based on ASR and speech-signal processing techniques. These markers will measure variation in interstress timing, linguistic rhythm, speaking rate, and glottal-source characteristics. In the first part of Year 3, results from all six markers will be combined into a single diagnostic index using multi-layer perceptrons. In the latter part of Year 3, per-child errors will be evaluated to determine relationships between specific prosodic factors and the diagnosis of sAOS, providing insight into the features and definition of sAOS. n/a",Diagnostic Markers for Childhood Apraxia Speech,7035268,R21DC006722,"['apraxias', 'artificial intelligence', 'biomarker', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'diagnosis design /evaluation', 'human data', 'speech disorder diagnosis', 'speech disorders', 'speech recognition']",NIDCD,OREGON HEALTH AND SCIENCE UNIVERSITY,R21,2006,159900,0.09012618260112085
"Intonation in spontaneous English & Japanese dialogue    DESCRIPTION (provided by applicant): Spoken dialogue is 1 of the most basic forms of human language, ubiquitous across cultures. It differs in form from written language and read speech, with different vocabulary usage, different syntax, and an expanded use of visually available context. Most importantly, speakers and hearers of dialogue must rely on intonation, or the 'melody in speech.' When we talk, we manipulate the pitch, rate, phrasing, and volume of our speech. Patterns of intonation across a conversation can indicate complex discourse information not available from the words alone, such as what is already known by both speakers, what is newly introduced to 1 or both of them, which information they are finished discussing and what is still to be talked about. Although intonational structuring of discourse information is reported for numerous languages, a theory of the general cognitive mechanism underlying the universal use of intonation has yet to be established. The cross-linguistic research proposed here is crucial for the development of a general theory of intonation use in human language processing. The focus on analyses of unscripted conversational speech provides the most accurate information available about basic human language performance. Studying spontaneous speech has been considered an intractable problem, because it is hard to predict the specific words and sentence structures a speaker will use. We have piloted novel methodology that allows collection of multiple tokens of like utterances from the same speaker in varying intonational conditions. To understand how listeners respond in conversation, we use head-mounted eye-movement monitoring, an immediate, implicit measure of comprehension that allows the listener to speak and move while looking at the objects described by a conversational partner. The comparisons of English and Japanese, 2 languages that differ substantially in their syntax and intonation, test whether intonation is used differently in a language that provides melodic cues more or less reliably, and in different physical forms. Understanding how consistently intonation marks the information status of words and whether intonational cues facilitate listeners' comprehension of messages is important, not only for theories of language processing and development, but also for accurate speech identification and generation systems in artificial intelligence, and for the development of effective diagnoses and therapies for aphasic patients and others with communication loss.          n/a",Intonation in spontaneous English & Japanese dialogue,7144725,R01DC007090,"['clinical research', 'comprehension', 'language', 'speech']",NIDCD,OHIO STATE UNIVERSITY,R01,2006,223125,0.16899834654316018
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,7007660,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2006,29424,0.06558297046271738
"Diagnostic Markers for Childhood Apraxia Speech DESCRIPTION (provided by applicant): Childhood Apraxia of Speech is a highly controversial disorder due to a lack of consensus on the features that define it and the etiologic conditions that explain its origin. The term Suspected Apraxia of Speech (sAOS) has been proposed as an interim term for this putative clinical entity. The point prevalence of sAOS in young children has been estimated at approximately 0.1%. The long-term objective of this proposal is to develop a valid, reliable, and efficient means to classify children as positive for sAOS. In addition to the contributions to theoretical explication of AOS, the software-based diagnostic tools resulting from this work will allow any certified speech-language pathologist to determine if a child's speech includes prosodic features that fall within a 95% confidence interval supporting the diagnosis of sAOS. The aim for this first period of planned programmatic research is to develop automated diagnostic markers for sAOS with clinically adequate sensitivity and specificity (> 90% positive and negative likelihood ratios).  The four specific aims are: (a) to automate and improve the sensitivity and specificity of two existing (manually derived) prosodic markers, (b) to develop four additional automatic, prosody-based diagnostic markers, (c) to derive a single diagnostic index based on a statistical derivative from the six individual markers, and (d) to validate the composite diagnostic marker using classification data obtained from expert clinical researchers.  Procedures are divided into four phases. In Year 1, automated versions of existing markers will be developed that determine speech-event locations using automatic speech recognition (ASR). Based on two pilot studies, this technique is expected to yield results equivalent to published data. The sensitivity of the markers will be improved by methods including normalizing by speaking rate and vowel identity. In Year 2, new automated markers will be created based on ASR and speech-signal processing techniques. These markers will measure variation in interstress timing, linguistic rhythm, speaking rate, and glottal-source characteristics. In the first part of Year 3, results from all six markers will be combined into a single diagnostic index using multi-layer perceptrons. In the latter part of Year 3, per-child errors will be evaluated to determine relationships between specific prosodic factors and the diagnosis of sAOS, providing insight into the features and definition of sAOS. n/a",Diagnostic Markers for Childhood Apraxia Speech,6881272,R21DC006722,"['apraxias', 'artificial intelligence', 'biomarker', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'diagnosis design /evaluation', 'human data', 'speech disorder diagnosis', 'speech disorders', 'speech recognition']",NIDCD,OREGON HEALTH AND SCIENCE UNIVERSITY,R21,2005,164000,0.09012618260112085
"INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA   DESCRIPTION: Dysarthria is a frequent result of several neurological disorders,      including Parkinson disease, stroke, cerebellar pathologies, multiple                sclerosis, and traumatic brain injury. Dysarthrias often lead to decreased           speech intelligibility, but they also affect other dimensions of spoken              language, including voice quality, prosody, and paralinguistic features. These       have not been studied collectively in large numbers of individuals with              dysarthria. This project uses a multiple-task protocol with both perceptual and      acoustic measures to examine intelligibility, voice quality, prosody, and            paralinguistic aspects in children and adults with acquired dysarthria. Several      newly developed analyses will be used to provide quantitative data toward the        construction of profiles of speech impairment and neurologic lesion. Included        will be the first systematic replication of the original work that led to the        contemporary classification of the dysarthrias. The data on dysarthria will be       integrated with data on speech development and normal adult speech in a neural       network model of speech production that is based on internal models of auditory      and articulatory representations of speech.                                                                                                                               n/a",INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA,6833535,R01DC000319,"['Parkinson&apos', 's disease', 'adult human (21+)', 'amyotrophic lateral sclerosis', 'artificial intelligence', 'behavioral /social science research tag', 'cerebellar disorders', 'cerebral palsy', 'child (0-11)', 'clinical research', 'disease /disorder classification', 'dysarthria', 'human subject', 'multiple sclerosis', 'nervous system disorder diagnosis', 'neural information processing', 'perception', 'speech', 'speech disorder diagnosis', 'stroke', 'vocabulary', 'voice']",NIDCD,UNIVERSITY OF WISCONSIN MADISON,R01,2005,437328,0.14361870212694108
"Advanced Medical Speech Recognition DESCRIPTION (provided by applicant):    Electronic medical record systems (EMR) are held back because data entry is slow, expensive, and codified in a format unsuitable for relational database repositories. Medical Reporting Solutions has developed advanced technology, which can overcome these problems through new methods to encode knowledge in medical reports, and a domain specific speech recognition system capable of real-time natural language understanding.      Our research and development uses methods in corpus linguistics and sentential logic to represent the knowledge in free-text medical reports in an efficient, codeable manner. We have created a prototype speech recognizer capable of natural language processing in real-time employing our unique knowledge base. The knowledge base, while under development, is derived from hundreds of thousands of reports in the radiology domain.      Our project plan includes completing our radiology speech recognizer, substantially enlarging our semantic knowledge base to cover 60% of the domain, and extensively testing the system. We plan to test our recognizer by measuring the word error rate (WER), using three different recognition algorithms we believe will substantially enhance performance beyond the best commercial medical speech recognizers. n/a",Advanced Medical Speech Recognition,7199534,R43LM008328,"['behavioral /social science research tag', 'bioimaging /biomedical imaging', 'clinical research', 'human subject', 'language', 'mathematics', 'radiology', 'semantics', 'speech recognition', 'technology /technique development', 'time resolved data']",NLM,"LOGICAL SEMANTICS, INC.",R43,2005,100000,0.08069388481661287
"Advanced Medical Speech Recognition DESCRIPTION (provided by applicant):    Electronic medical record systems (EMR) are held back because data entry is slow, expensive, and codified in a format unsuitable for relational database repositories. Medical Reporting Solutions has developed advanced technology, which can overcome these problems through new methods to encode knowledge in medical reports, and a domain specific speech recognition system capable of real-time natural language understanding.      Our research and development uses methods in corpus linguistics and sentential logic to represent the knowledge in free-text medical reports in an efficient, codeable manner. We have created a prototype speech recognizer capable of natural language processing in real-time employing our unique knowledge base. The knowledge base, while under development, is derived from hundreds of thousands of reports in the radiology domain.      Our project plan includes completing our radiology speech recognizer, substantially enlarging our semantic knowledge base to cover 60% of the domain, and extensively testing the system. We plan to test our recognizer by measuring the word error rate (WER), using three different recognition algorithms we believe will substantially enhance performance beyond the best commercial medical speech recognizers. n/a",Advanced Medical Speech Recognition,6965478,R43LM008328,"['behavioral /social science research tag', 'bioimaging /biomedical imaging', 'clinical research', 'human subject', 'language', 'mathematics', 'radiology', 'semantics', 'speech recognition', 'technology /technique development', 'time resolved data']",NLM,"LOGICAL SEMANTICS, INC.",R43,2005,100000,0.08069388481661287
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6902613,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2005,220725,0.07869884450701026
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6847778,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2005,29424,0.06558297046271738
"Virtual Therapist Speech Treatment for Parkinson Disease    DESCRIPTION (provided by applicant): Our previous studies have generated the first short- and long-term experimental efficacy data for speech treatment for individuals with Idiopathic Parkinson disease (IPD), documenting acoustic, aerodynamic and physiologic changes accompanying treatment. Despite these major steps in establishing the experimental efficacy of speech treatment for individuals with IPD, the ""real world"" treatment of speech remains an unmet need for the vast majority of these individuals. At least 89% of individuals with IPD have disordered speech, but only 3-4% receive speech treatment. This is a serious problem, as individuals with IPD who have received Lee Silverman Voice Treatment (LSVT) therapy benefit in many ways: they not only produce more intelligible and expressive speech, but they often report dramatic improvements in their self esteem and quality of life. We thus propose to conduct research to demonstrate the feasibility 6f a novel solution to make LSVT training more accessible to over one million individuals--the development and testing of a fully automated computer-based speech therapy system, in which voice training is conducted by a virtual speech therapist--and animated computer character that models the key perception and production behaviors of a human therapist. While development of the proposed system may seem futuristic and ambitious at first blush, perceptive animated agents are now a reality, and language training applications using these agents have produced significant gains in speech and language skills of profoundly deaf children. In addition, under a seed grant from the Coleman Foundation, we have developed an initial version of an LSVT therapist that models well the facial expressions, gestures and utterances of a human LSVT therapist. It is thus feasible to develop and assess the potential value of an automated training system that uses a perceptive animated agent to conduct voice training with individuals with IPD. The proposed work builds upon our well established foundation of experimental efficacy data and the successful application of perceptive animated agents in language training tasks to accomplish two specific aims: (1) design and test a fully automated voice training system in which a virtual therapist conducts LSVT sessions with individuals with IPD; and (2) explore the feasibility of using this system as either a substitute or adjunct to LSVT training with human clinicians. In addition to assessment procedures used in previous LSVT efficacy studies, the proposed work will provide new insights into LSVT treatment through sophisticated analyses of audio and video data collected during sessions and pre and post treatment, that employ computer vision and speech signal processing algorithms to analysis of facial movements, gestures and speech data.         n/a",Virtual Therapist Speech Treatment for Parkinson Disease,6885764,R21DC006078,"['Parkinson&apos', 's disease', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'comorbidity', 'computer assisted instruction', 'computer simulation', 'computer system design /evaluation', 'educational resource design /development', 'face expression', 'human middle age (35-64)', 'human old age (65+)', 'human subject', 'human therapy evaluation', 'interactive multimedia', 'language development', 'paralinguistic behavior', 'patient oriented research', 'speech disorders', 'speech therapy', 'training aid', 'verbal behavior', 'verbal learning', 'voice']",NIDCD,UNIVERSITY OF COLORADO AT BOULDER,R21,2005,205957,0.1418361825065324
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6782636,F32HD042927,"['artificial intelligence', 'auditory stimulus', 'behavior test', 'behavioral /social science research tag', 'child (0-11)', 'clinical research', 'comprehension', 'computer simulation', 'cues', 'developmental neurobiology', 'human subject', 'language development', 'neural information processing', 'postdoctoral investigator', 'syntax', 'verbal learning', 'visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2004,47296,0.11061639742176173
"Software Intervention for Advanced Syntax Development This proposal requests SBIR Phase II support to complete and field test language intervention software designed to promote syntactic development in school-age children (5-12 years old).  Language delays are pervasive among school-age children. What's more, two thirds of children identified as having language-specific impairments previously nor have received any form of language intervention during their preschool years. Consequently, there is a clear need to develop language intervention strategies designed specifically to meet the needs of this population; that is, intervention designed to promote development of the more advanced syntactic constructions typically missing from the grammar of these children. In Phase I, a curriculum was developed for introducing the syntax of interrogative operators. Curriculum design was guided by contemporary linguistic research, which suggests ways in which treatment may be improved and more successful outcomes achieved. Software was developed to deliver parts of this curriculum, and was integrated with an artificial intelligence component capable of generating individualized lessons based on emerging competencies. Twenty-six kindergartners used the software successfully during field- testing. In Phase II these efforts will be expanded by developing an integrated series of language intervention modules and verifying that the modules are effective under typical classroom conditions. PROPOSED COMMERCIAL APPLICATIONS: Speech-language pathologists, teachers and parents recognize the importance of intervention when a child's language status is impaired, and such intervention is mandated by Federal Law. As such, we anticipate that our computer-based language intervention system, designed to facilitate language development in school-age children, will be a commercial success and will fulfill an unmet need for individual services. n/a",Software Intervention for Advanced Syntax Development,6764134,R44DC004107,"['artificial intelligence', 'clinical research', 'computer assisted instruction', 'computer program /software', 'computer system design /evaluation', 'educational resource design /development', 'elementary school', 'human subject', 'language development', 'language disorders', 'middle childhood (6-11)', 'psycholinguistics', 'speech disorders', 'syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2004,34450,0.09402993407329258
"Diagnostic Markers for Childhood Apraxia Speech DESCRIPTION (provided by applicant): Childhood Apraxia of Speech is a highly controversial disorder due to a lack of consensus on the features that define it and the etiologic conditions that explain its origin. The term Suspected Apraxia of Speech (sAOS) has been proposed as an interim term for this putative clinical entity. The point prevalence of sAOS in young children has been estimated at approximately 0.1%. The long-term objective of this proposal is to develop a valid, reliable, and efficient means to classify children as positive for sAOS. In addition to the contributions to theoretical explication of AOS, the software-based diagnostic tools resulting from this work will allow any certified speech-language pathologist to determine if a child's speech includes prosodic features that fall within a 95% confidence interval supporting the diagnosis of sAOS. The aim for this first period of planned programmatic research is to develop automated diagnostic markers for sAOS with clinically adequate sensitivity and specificity (> 90% positive and negative likelihood ratios).  The four specific aims are: (a) to automate and improve the sensitivity and specificity of two existing (manually derived) prosodic markers, (b) to develop four additional automatic, prosody-based diagnostic markers, (c) to derive a single diagnostic index based on a statistical derivative from the six individual markers, and (d) to validate the composite diagnostic marker using classification data obtained from expert clinical researchers.  Procedures are divided into four phases. In Year 1, automated versions of existing markers will be developed that determine speech-event locations using automatic speech recognition (ASR). Based on two pilot studies, this technique is expected to yield results equivalent to published data. The sensitivity of the markers will be improved by methods including normalizing by speaking rate and vowel identity. In Year 2, new automated markers will be created based on ASR and speech-signal processing techniques. These markers will measure variation in interstress timing, linguistic rhythm, speaking rate, and glottal-source characteristics. In the first part of Year 3, results from all six markers will be combined into a single diagnostic index using multi-layer perceptrons. In the latter part of Year 3, per-child errors will be evaluated to determine relationships between specific prosodic factors and the diagnosis of sAOS, providing insight into the features and definition of sAOS. n/a",Diagnostic Markers for Childhood Apraxia Speech,6782453,R21DC006722,"['apraxias', 'artificial intelligence', 'biomarker', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'diagnosis design /evaluation', 'human data', 'speech disorder diagnosis', 'speech disorders', 'speech recognition']",NIDCD,OREGON HEALTH AND SCIENCE UNIVERSITY,R21,2004,164000,0.09012618260112085
"INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA   DESCRIPTION: Dysarthria is a frequent result of several neurological disorders,      including Parkinson disease, stroke, cerebellar pathologies, multiple                sclerosis, and traumatic brain injury. Dysarthrias often lead to decreased           speech intelligibility, but they also affect other dimensions of spoken              language, including voice quality, prosody, and paralinguistic features. These       have not been studied collectively in large numbers of individuals with              dysarthria. This project uses a multiple-task protocol with both perceptual and      acoustic measures to examine intelligibility, voice quality, prosody, and            paralinguistic aspects in children and adults with acquired dysarthria. Several      newly developed analyses will be used to provide quantitative data toward the        construction of profiles of speech impairment and neurologic lesion. Included        will be the first systematic replication of the original work that led to the        contemporary classification of the dysarthrias. The data on dysarthria will be       integrated with data on speech development and normal adult speech in a neural       network model of speech production that is based on internal models of auditory      and articulatory representations of speech.                                                                                                                               n/a",INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA,6689543,R01DC000319,"['Parkinson&apos', 's disease', 'adult human (21+)', 'amyotrophic lateral sclerosis', 'artificial intelligence', 'behavioral /social science research tag', 'cerebellar disorders', 'cerebral palsy', 'child (0-11)', 'clinical research', 'disease /disorder classification', 'dysarthria', 'human subject', 'multiple sclerosis', 'nervous system disorder diagnosis', 'neural information processing', 'perception', 'speech', 'speech disorder diagnosis', 'stroke', 'vocabulary', 'voice']",NIDCD,UNIVERSITY OF WISCONSIN MADISON,R01,2004,424599,0.14361870212694108
"Early Language Intervention via the Internet    DESCRIPTION (provided by applicant): This proposal requests SBIR Phase II support to complete and field test an Internet-based language intervention system designed to promote language development in preschool children with language disorders. Language delays are pervasive among school-age children. Early intervention is crucial since the consequences of language delay can be serious and cumulative. Yet research shows that most children with language delays never receive language intervention services during their preschool years. We propose to complete an Internet-based early language intervention system designed specifically for the remediation of language disorders in 3-5 year old children with language function in the range of 24-42 months. The curricular design will be guided by contemporary linguistic research. Online delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks performance and adjusts instructional support. By combining easy access via the Internet with centralized data collection and curricular control, it will become possible to implement and easily manage coordinated school and home language intervention strategies, and to provide services to more children without further taxing limited professional resources. In Phase I we tested the feasibility and technical merit of this objective. A prototype program module was developed and tested with 23 students who were enrolled in an Early Essential Education program, including 19 preschoolers with language delays. Data were collected over the Internet while testing six of these children. In Phase II we plan to fully develop and field-test this Internet-based language intervention system.         n/a",Early Language Intervention via the Internet,6795077,R44DC004487,"['Internet', 'behavioral /social science research tag', 'clinical research', 'computer assisted instruction', 'computer program /software', 'computer system design /evaluation', 'curriculum', 'data collection', 'education evaluation /planning', 'educational resource design /development', 'human subject', 'language development', 'language disorders', 'preschool child (1-5)', 'sociolinguistics', 'speech disorders', 'speech therapy', 'syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2004,606618,0.10497417259984732
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6754401,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2004,220725,0.07869884450701026
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6743829,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2004,29424,0.06558297046271738
"Virtual Therapist Speech Treatment for Parkinson Disease    DESCRIPTION (provided by applicant): Our previous studies have generated the first short- and long-term experimental efficacy data for speech treatment for individuals with Idiopathic Parkinson disease (IPD), documenting acoustic, aerodynamic and physiologic changes accompanying treatment. Despite these major steps in establishing the experimental efficacy of speech treatment for individuals with IPD, the ""real world"" treatment of speech remains an unmet need for the vast majority of these individuals. At least 89% of individuals with IPD have disordered speech, but only 3-4% receive speech treatment. This is a serious problem, as individuals with IPD who have received Lee Silverman Voice Treatment (LSVT) therapy benefit in many ways: they not only produce more intelligible and expressive speech, but they often report dramatic improvements in their self esteem and quality of life. We thus propose to conduct research to demonstrate the feasibility 6f a novel solution to make LSVT training more accessible to over one million individuals--the development and testing of a fully automated computer-based speech therapy system, in which voice training is conducted by a virtual speech therapist--and animated computer character that models the key perception and production behaviors of a human therapist. While development of the proposed system may seem futuristic and ambitious at first blush, perceptive animated agents are now a reality, and language training applications using these agents have produced significant gains in speech and language skills of profoundly deaf children. In addition, under a seed grant from the Coleman Foundation, we have developed an initial version of an LSVT therapist that models well the facial expressions, gestures and utterances of a human LSVT therapist. It is thus feasible to develop and assess the potential value of an automated training system that uses a perceptive animated agent to conduct voice training with individuals with IPD. The proposed work builds upon our well established foundation of experimental efficacy data and the successful application of perceptive animated agents in language training tasks to accomplish two specific aims: (1) design and test a fully automated voice training system in which a virtual therapist conducts LSVT sessions with individuals with IPD; and (2) explore the feasibility of using this system as either a substitute or adjunct to LSVT training with human clinicians. In addition to assessment procedures used in previous LSVT efficacy studies, the proposed work will provide new insights into LSVT treatment through sophisticated analyses of audio and video data collected during sessions and pre and post treatment, that employ computer vision and speech signal processing algorithms to analysis of facial movements, gestures and speech data.         n/a",Virtual Therapist Speech Treatment for Parkinson Disease,6759713,R21DC006078,"['Parkinson&apos', 's disease', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'comorbidity', 'computer assisted instruction', 'computer simulation', 'computer system design /evaluation', 'educational resource design /development', 'face expression', 'human middle age (35-64)', 'human old age (65+)', 'human subject', 'human therapy evaluation', 'interactive multimedia', 'language development', 'paralinguistic behavior', 'patient oriented research', 'speech disorders', 'speech therapy', 'training aid', 'verbal behavior', 'verbal learning', 'voice']",NIDCD,UNIVERSITY OF COLORADO AT BOULDER,R21,2004,148375,0.1418361825065324
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6647078,F32HD042927,"['artificial intelligence', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' clinical research', ' comprehension', ' computer simulation', ' cues', ' developmental neurobiology', ' human subject', ' language development', ' neural information processing', ' postdoctoral investigator', ' syntax', ' verbal learning', ' visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2003,41608,0.11061639742176173
"Software Intervention for Advanced Syntax Development This proposal requests SBIR Phase II support to complete and field test language intervention software designed to promote syntactic development in school-age children (5-12 years old).  Language delays are pervasive among school-age children. What's more, two thirds of children identified as having language-specific impairments previously nor have received any form of language intervention during their preschool years. Consequently, there is a clear need to develop language intervention strategies designed specifically to meet the needs of this population; that is, intervention designed to promote development of the more advanced syntactic constructions typically missing from the grammar of these children. In Phase I, a curriculum was developed for introducing the syntax of interrogative operators. Curriculum design was guided by contemporary linguistic research, which suggests ways in which treatment may be improved and more successful outcomes achieved. Software was developed to deliver parts of this curriculum, and was integrated with an artificial intelligence component capable of generating individualized lessons based on emerging competencies. Twenty-six kindergartners used the software successfully during field- testing. In Phase II these efforts will be expanded by developing an integrated series of language intervention modules and verifying that the modules are effective under typical classroom conditions. PROPOSED COMMERCIAL APPLICATIONS: Speech-language pathologists, teachers and parents recognize the importance of intervention when a child's language status is impaired, and such intervention is mandated by Federal Law. As such, we anticipate that our computer-based language intervention system, designed to facilitate language development in school-age children, will be a commercial success and will fulfill an unmet need for individual services. n/a",Software Intervention for Advanced Syntax Development,6626058,R44DC004107,"['artificial intelligence', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' educational resource design /development', ' elementary school', ' human subject', ' language development', ' language disorders', ' middle childhood (6-11)', ' psycholinguistics', ' speech disorders', ' syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2003,333838,0.09402993407329258
"Production modeling for articulatory recovery The speech production model developed in this work will serve as an internal model in an analysis-by-synthesis algorithm intended to recover articulatory movement from speech acoustics. The speech production model will have three components: 1) an improved version of the Haskins articulatory synthesizer, ASY, 2) an improved task-dynamic model, and 3) an inverse normalizing map, which relates ASY vocal tract shapes to human vocal tract shapes.  In order for ASY and the task-dynamic model to serve as components of a model of a human talker it is necessary that the task-dynamic, with end effectors in ASY, induce the articulatory kinematics observed in the talker as the image of the inverse normalizing map.  ASY and the task-dynamic model are parts of a veridical model of human speech production only in conjunction with an inverse normalizing map.  The approach here will be to make ASY and the task-dynamic model as realistic as possible without compromising their relative simplicity.  This will enable inverse normalizing maps to be mathematically regular functions, which is an important property for articulatory recovery. There have been many empirical studies on vocal tract shape performed since the time ASY was constructed that can be included into ASY.  Improvements in the transfer function calculation can also be made at this time.  With improvements to ASY will necessarily come improvements in the task-dynamic model, particularly tongue control and control during obstruent production.  Various methods for constructing the inverse normalizing map, along with its ability to map articulatory kinematics, will also be tested.  With all three components, the task-dynamic model will be tested using X-ray microbeam data of human speech production.  n/a",Production modeling for articulatory recovery,6634451,R01DC001247,"['X ray', ' artificial intelligence', ' behavioral /social science research tag', ' computational neuroscience', ' computer program /software', ' human data', ' mathematical model', ' speech', ' speech recognition', ' speech synthesizers']",NIDCD,"CRESS, LLC",R01,2003,138502,0.05629840562647656
"Production modeling for articulatory recovery The speech production model developed in this work will serve as an internal model in an analysis-by-synthesis algorithm intended to recover articulatory movement from speech acoustics. The speech production model will have three components: 1) an improved version of the Haskins articulatory synthesizer, ASY, 2) an improved task-dynamic model, and 3) an inverse normalizing map, which relates ASY vocal tract shapes to human vocal tract shapes.  In order for ASY and the task-dynamic model to serve as components of a model of a human talker it is necessary that the task-dynamic, with end effectors in ASY, induce the articulatory kinematics observed in the talker as the image of the inverse normalizing map.  ASY and the task-dynamic model are parts of a veridical model of human speech production only in conjunction with an inverse normalizing map.  The approach here will be to make ASY and the task-dynamic model as realistic as possible without compromising their relative simplicity.  This will enable inverse normalizing maps to be mathematically regular functions, which is an important property for articulatory recovery. There have been many empirical studies on vocal tract shape performed since the time ASY was constructed that can be included into ASY.  Improvements in the transfer function calculation can also be made at this time.  With improvements to ASY will necessarily come improvements in the task-dynamic model, particularly tongue control and control during obstruent production.  Various methods for constructing the inverse normalizing map, along with its ability to map articulatory kinematics, will also be tested.  With all three components, the task-dynamic model will be tested using X-ray microbeam data of human speech production.  n/a",Production modeling for articulatory recovery,6787430,R01DC001247,"['X ray', ' artificial intelligence', ' behavioral /social science research tag', ' computational neuroscience', ' computer program /software', ' human data', ' mathematical model', ' speech', ' speech recognition', ' speech synthesizers']",NIDCD,"CRESS, LLC",R01,2003,49334,0.05629840562647656
"INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA   DESCRIPTION: Dysarthria is a frequent result of several neurological disorders,      including Parkinson disease, stroke, cerebellar pathologies, multiple                sclerosis, and traumatic brain injury. Dysarthrias often lead to decreased           speech intelligibility, but they also affect other dimensions of spoken              language, including voice quality, prosody, and paralinguistic features. These       have not been studied collectively in large numbers of individuals with              dysarthria. This project uses a multiple-task protocol with both perceptual and      acoustic measures to examine intelligibility, voice quality, prosody, and            paralinguistic aspects in children and adults with acquired dysarthria. Several      newly developed analyses will be used to provide quantitative data toward the        construction of profiles of speech impairment and neurologic lesion. Included        will be the first systematic replication of the original work that led to the        contemporary classification of the dysarthrias. The data on dysarthria will be       integrated with data on speech development and normal adult speech in a neural       network model of speech production that is based on internal models of auditory      and articulatory representations of speech.                                                                                                                               n/a",INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA,6626845,R01DC000319,"[""Parkinson's disease"", ' adult human (21+)', ' amyotrophic lateral sclerosis', ' artificial intelligence', ' behavioral /social science research tag', ' cerebellar disorders', ' cerebral palsy', ' child (0-11)', ' clinical research', ' disease /disorder classification', ' dysarthria', ' human subject', ' multiple sclerosis', ' nervous system disorder diagnosis', ' neural information processing', ' perception', ' speech', ' speech disorder diagnosis', ' stroke', ' vocabulary', ' voice']",NIDCD,UNIVERSITY OF WISCONSIN MADISON,R01,2003,412234,0.14361870212694108
"Early Language Intervention via the Internet    DESCRIPTION (provided by applicant): This proposal requests SBIR Phase II support to complete and field test an Internet-based language intervention system designed to promote language development in preschool children with language disorders. Language delays are pervasive among school-age children. Early intervention is crucial since the consequences of language delay can be serious and cumulative. Yet research shows that most children with language delays never receive language intervention services during their preschool years. We propose to complete an Internet-based early language intervention system designed specifically for the remediation of language disorders in 3-5 year old children with language function in the range of 24-42 months. The curricular design will be guided by contemporary linguistic research. Online delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks performance and adjusts instructional support. By combining easy access via the Internet with centralized data collection and curricular control, it will become possible to implement and easily manage coordinated school and home language intervention strategies, and to provide services to more children without further taxing limited professional resources. In Phase I we tested the feasibility and technical merit of this objective. A prototype program module was developed and tested with 23 students who were enrolled in an Early Essential Education program, including 19 preschoolers with language delays. Data were collected over the Internet while testing six of these children. In Phase II we plan to fully develop and field-test this Internet-based language intervention system.         n/a",Early Language Intervention via the Internet,6644533,R44DC004487,"['Internet', ' behavioral /social science research tag', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' curriculum', ' data collection', ' education evaluation /planning', ' educational resource design /development', ' human subject', ' language development', ' language disorders', ' preschool child (1-5)', ' sociolinguistics', ' speech disorders', ' speech therapy', ' syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2003,819451,0.10497417259984732
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6615572,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2003,114544,0.06420679412689355
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6679518,R01MH066228,"['behavioral /social science research tag', ' clinical research', ' computational neuroscience', ' human middle age (35-64)', ' human subject', ' language', ' neural information processing', ' neuropsychology', ' psychopathology', ' schizophrenia', ' short term memory', ' young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2003,220725,0.07869884450701026
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6622537,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2003,28193,0.09418272250687483
"Prosody and function words in early syntax acquisition  DESCRIPTION (provided by candidate):  Broadly, the proposed research will address how infants begin to take a linear string of words in the speech stream and build a hierarchically structured syntactic representation. This question is of importance for accounts of human language development and in the design of software for natural language processing. Both of these endeavors are of interest to those in the area of language deficits, either developmental or traumatic. Specifically, the project will examine the respective roles of function words and prosodic information in the early development of syntax in infants. The investigation will focus on the use of function words in other domains of language acquisition, the interaction between prosody and function words in infants' representation of sentences, and the development of functional syntactic categories. The approach will integrate behavioral and computational methods. Two measures of infant perceptual attention, the Headturn Preference Procedure, and the Intermodal Preferential Looking Paradigm will be used to assess infants' sensitivity to specific cues (prosody and the location of function words) to syntax in various contexts. This behavioral work will be supplemented with connectionist models to compare the relative benefits of different aspects of the speech input in developing syntactic knowledge.   n/a",Prosody and function words in early syntax acquisition,6551481,F32HD042927,"['artificial intelligence', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' clinical research', ' comprehension', ' computer simulation', ' cues', ' developmental neurobiology', ' human subject', ' language development', ' neural information processing', ' postdoctoral investigator', ' syntax', ' verbal learning', ' visual stimulus']",NICHD,BROWN UNIVERSITY,F32,2002,36592,0.11061639742176173
"Software Intervention for Advanced Syntax Development This proposal requests SBIR Phase II support to complete and field test language intervention software designed to promote syntactic development in school-age children (5-12 years old).  Language delays are pervasive among school-age children. What's more, two thirds of children identified as having language-specific impairments previously nor have received any form of language intervention during their preschool years. Consequently, there is a clear need to develop language intervention strategies designed specifically to meet the needs of this population; that is, intervention designed to promote development of the more advanced syntactic constructions typically missing from the grammar of these children. In Phase I, a curriculum was developed for introducing the syntax of interrogative operators. Curriculum design was guided by contemporary linguistic research, which suggests ways in which treatment may be improved and more successful outcomes achieved. Software was developed to deliver parts of this curriculum, and was integrated with an artificial intelligence component capable of generating individualized lessons based on emerging competencies. Twenty-six kindergartners used the software successfully during field- testing. In Phase II these efforts will be expanded by developing an integrated series of language intervention modules and verifying that the modules are effective under typical classroom conditions. PROPOSED COMMERCIAL APPLICATIONS: Speech-language pathologists, teachers and parents recognize the importance of intervention when a child's language status is impaired, and such intervention is mandated by Federal Law. As such, we anticipate that our computer-based language intervention system, designed to facilitate language development in school-age children, will be a commercial success and will fulfill an unmet need for individual services. n/a",Software Intervention for Advanced Syntax Development,6485703,R44DC004107,"['artificial intelligence', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' educational resource design /development', ' elementary school', ' human subject', ' language development', ' language disorders', ' middle childhood (6-11)', ' psycholinguistics', ' speech disorders', ' syntax']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R44,2002,597990,0.09402993407329258
"Production modeling for articulatory recovery The speech production model developed in this work will serve as an internal model in an analysis-by-synthesis algorithm intended to recover articulatory movement from speech acoustics. The speech production model will have three components: 1) an improved version of the Haskins articulatory synthesizer, ASY, 2) an improved task-dynamic model, and 3) an inverse normalizing map, which relates ASY vocal tract shapes to human vocal tract shapes.  In order for ASY and the task-dynamic model to serve as components of a model of a human talker it is necessary that the task-dynamic, with end effectors in ASY, induce the articulatory kinematics observed in the talker as the image of the inverse normalizing map.  ASY and the task-dynamic model are parts of a veridical model of human speech production only in conjunction with an inverse normalizing map.  The approach here will be to make ASY and the task-dynamic model as realistic as possible without compromising their relative simplicity.  This will enable inverse normalizing maps to be mathematically regular functions, which is an important property for articulatory recovery. There have been many empirical studies on vocal tract shape performed since the time ASY was constructed that can be included into ASY.  Improvements in the transfer function calculation can also be made at this time.  With improvements to ASY will necessarily come improvements in the task-dynamic model, particularly tongue control and control during obstruent production.  Various methods for constructing the inverse normalizing map, along with its ability to map articulatory kinematics, will also be tested.  With all three components, the task-dynamic model will be tested using X-ray microbeam data of human speech production.  n/a",Production modeling for articulatory recovery,6516103,R01DC001247,"['X ray', ' artificial intelligence', ' behavioral /social science research tag', ' computational neuroscience', ' computer program /software', ' human data', ' mathematical model', ' speech', ' speech recognition', ' speech synthesizers']",NIDCD,"CRESS, LLC",R01,2002,138502,0.05629840562647656
"INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA   DESCRIPTION: Dysarthria is a frequent result of several neurological disorders,      including Parkinson disease, stroke, cerebellar pathologies, multiple                sclerosis, and traumatic brain injury. Dysarthrias often lead to decreased           speech intelligibility, but they also affect other dimensions of spoken              language, including voice quality, prosody, and paralinguistic features. These       have not been studied collectively in large numbers of individuals with              dysarthria. This project uses a multiple-task protocol with both perceptual and      acoustic measures to examine intelligibility, voice quality, prosody, and            paralinguistic aspects in children and adults with acquired dysarthria. Several      newly developed analyses will be used to provide quantitative data toward the        construction of profiles of speech impairment and neurologic lesion. Included        will be the first systematic replication of the original work that led to the        contemporary classification of the dysarthrias. The data on dysarthria will be       integrated with data on speech development and normal adult speech in a neural       network model of speech production that is based on internal models of auditory      and articulatory representations of speech.                                                                                                                               n/a",INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA,6489511,R01DC000319,"[""Parkinson's disease"", ' adult human (21+)', ' amyotrophic lateral sclerosis', ' artificial intelligence', ' behavioral /social science research tag', ' cerebellar disorders', ' cerebral palsy', ' child (0-11)', ' clinical research', ' disease /disorder classification', ' dysarthria', ' human subject', ' multiple sclerosis', ' nervous system disorder diagnosis', ' neural information processing', ' perception', ' speech', ' speech disorder diagnosis', ' stroke', ' vocabulary', ' voice']",NIDCD,UNIVERSITY OF WISCONSIN MADISON,R01,2002,402685,0.14361870212694108
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6539200,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2002,152849,0.06420679412689355
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6450183,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2002,26141,0.09418272250687483
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6528412,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2002,325555,0.038638334562802516
"Production modeling for articulatory recovery The speech production model developed in this work will serve as an internal model in an analysis-by-synthesis algorithm intended to recover articulatory movement from speech acoustics. The speech production model will have three components: 1) an improved version of the Haskins articulatory synthesizer, ASY, 2) an improved task-dynamic model, and 3) an inverse normalizing map, which relates ASY vocal tract shapes to human vocal tract shapes.  In order for ASY and the task-dynamic model to serve as components of a model of a human talker it is necessary that the task-dynamic, with end effectors in ASY, induce the articulatory kinematics observed in the talker as the image of the inverse normalizing map.  ASY and the task-dynamic model are parts of a veridical model of human speech production only in conjunction with an inverse normalizing map.  The approach here will be to make ASY and the task-dynamic model as realistic as possible without compromising their relative simplicity.  This will enable inverse normalizing maps to be mathematically regular functions, which is an important property for articulatory recovery. There have been many empirical studies on vocal tract shape performed since the time ASY was constructed that can be included into ASY.  Improvements in the transfer function calculation can also be made at this time.  With improvements to ASY will necessarily come improvements in the task-dynamic model, particularly tongue control and control during obstruent production.  Various methods for constructing the inverse normalizing map, along with its ability to map articulatory kinematics, will also be tested.  With all three components, the task-dynamic model will be tested using X-ray microbeam data of human speech production.  n/a",Production modeling for articulatory recovery,6370912,R01DC001247,"['X ray', ' artificial intelligence', ' behavioral /social science research tag', ' computational neuroscience', ' computer program /software', ' human data', ' mathematical model', ' speech', ' speech recognition', ' speech synthesizers']",NIDCD,"CRESS, LLC",R01,2001,137046,0.05629840562647656
"INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA   DESCRIPTION: Dysarthria is a frequent result of several neurological disorders,      including Parkinson disease, stroke, cerebellar pathologies, multiple                sclerosis, and traumatic brain injury. Dysarthrias often lead to decreased           speech intelligibility, but they also affect other dimensions of spoken              language, including voice quality, prosody, and paralinguistic features. These       have not been studied collectively in large numbers of individuals with              dysarthria. This project uses a multiple-task protocol with both perceptual and      acoustic measures to examine intelligibility, voice quality, prosody, and            paralinguistic aspects in children and adults with acquired dysarthria. Several      newly developed analyses will be used to provide quantitative data toward the        construction of profiles of speech impairment and neurologic lesion. Included        will be the first systematic replication of the original work that led to the        contemporary classification of the dysarthrias. The data on dysarthria will be       integrated with data on speech development and normal adult speech in a neural       network model of speech production that is based on internal models of auditory      and articulatory representations of speech.                                                                                                                               n/a",INTELLIGIBILITY ASSESSMENT IN DYSARTHRIA,6286948,R01DC000319,"[""Parkinson's disease"", ' adult human (21+)', ' amyotrophic lateral sclerosis', ' artificial intelligence', ' behavioral /social science research tag', ' cerebellar disorders', ' cerebral palsy', ' child (0-11)', ' clinical research', ' disease /disorder classification', ' dysarthria', ' human subject', ' multiple sclerosis', ' nervous system disorder diagnosis', ' neural information processing', ' perception', ' speech', ' speech disorder diagnosis', ' stroke', ' vocabulary', ' voice']",NIDCD,UNIVERSITY OF WISCONSIN MADISON,R01,2001,407733,0.14361870212694108
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6399830,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2001,145788,0.06420679412689355
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6404288,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2001,673495,0.038638334562802516
"NEURAL NETWORK MODELING OF SPEECH PRODUCTION The long-term objectives of the proposed research are to elucidate the           stages of speaking skill development in infants and the motor control            mechanisms for speech production in adults.  These research areas are            important for early diagnosis and proper treatment of speech disorders.          The proposed research consists primarily of the development, refinement,         and experimental testing of a comprehensive neural network modeling              framework for speech production based on preliminary work described in           Guenther (Appendices A).  Model additions will include an articulatory           mechanism that allows synthesis of speech wave-forms and an acoustic-like        coordinate frame for speech movement planning.  Proposed research also           includes the development of software for producing speaker-specific vocal        tract models based on Magnetic Resonance Imaging (MRI) scans.  These models      will allow synthesis of speech signals that account for the differences in       vocal tract sizes and shapes of different individuals, thus providing a          more accurate means for investigating the acoustic/articulatory                  relationships of individuals acting as subjects in speech production             experiments.  An experimental investigation utilizing these speaker-             specific vocal tract models is also proposed to test an hypothesis               generated by the modeling framework.  Some speakers use two entirely             different articulator configurations, called ""bunched"" and retroflex"", to        produce /r/ in different contexts.  The proposed model predicts that the         same target is specified tot he production mechanism in the two cases, but       that different articulator configurations arise in different contexts due        to two properties of the speech production mechanism: (1) movement planning      in an acoustic-like coordinate frame, and (2) transformation of the planned      acoustic trajectories into articulator movements via a direction-to-             direction mapping.  Speaker-specific vocal tract models corresponding to         two subjects will be incorporated into the proposed modeling framework,          which will then be used to predict which configuration each subject will         use to produce /r/ in each of four contexts.  The hypothesis will be tested      by comparing model performance with the performance of the subjects while        producing /r/ in the same four contests, as measured in an Electro-Magnetic      Midsagittal Articulometer (EMMA) study.  Finally, the proposed modeling          framework will be used to investigate several other issues in speech             production, including two modeling studies of speech motor development in        infants (made possible by the self-organizing nature of the proposed             model), and an investigation of intrinsic timing issues.                             GRANT=R01DE09161                                                             The ability to utilize hemin and hemin containing compounds as an iron           source has been documented for several pathogenic bacteria, including the        periodontopathogen, Porphyromonas gingivalis.  We have previously                determined that P. gingivalis transports the entire hemin moiety into the        cell by an energy-dependent mechanism and that the binding and accumulation      of hemin are induced by growth of cultures in the presence of hemin.             However, the specific P. gingivalis components involved in hemin binding         and transport have not been identified.  Growth of P. gingivalis under           hemin-replete conditions has also been shown to influence the expression of      several virulence factors; however, the role of hemin in the regulation of       specific virulence genes has not been precisely defined.                                                                                                          The primary objectives of the present application are to define the              molecular mechanisms involved in hemin binding and transport in P.               gingivalis and to examine the regulation of hemin responsive genes.  Four        specific aims are proposed:                                                                                                                                       1.  To identify and characterize athe P. gingivalis hemin receptor(s).  P.       gingivalis outer membrane proteins involved in hemin binding will be             identified by hemin affinity chromatography.  The specificity of the             putative receptor(s) will be defined by examining the binding of 14[C]hemin      to P. gingivalis in the presence of hemin and nonahemin iron sources.                                                                                             2.  To clone P. gingivalis genes encoding proteins involved in hemin             binding and transport.  P. gingivalis genes encoding hemin binding proteins      will be cloned by screening E. coli recombinants for the ability to bind         hemin.  P. gingivalis genes encoding proteins involved in hemin transport        will be cloned by screening E. coli hemA mutants for the ability to grow         with hemin.  Corresponding P. gingivalis mutants will be obtained by             insertional inactivation of the cloned genes and characterized both in           vitro and in vivo.                                                                                                                                                3.  To elucidate the regulation of hemin binding and transport genes.  The       regulation of cloned P. gingivalis genes involved in hemin binding and           transport will be examined by analysis of mRNA and transcriptional fusions       under hemin-deplete and -replete conditions.                                                                                                                      4.  To identify P. gingivalis genes that are regulated by the ferric uptake      regulator (Fur).  Our preliminary results indicate that the expression of        hemin/iron-responsive genes in P. gingivalis may be controlled by the            negative ferric uptake regulator protein, Fur.  We will begin to identify        P. gingivalis genes that are regulated by Fur by screening a P. gingivalis       genomic library using the Fur titration asssay.                                                                                                                   The results obtained in these studies will allow us to identify specific         components of the hemin transport system in P. gingivalis and will provide       important information on the regulation of hemin responsive genes.                n/a",NEURAL NETWORK MODELING OF SPEECH PRODUCTION,6150504,R29DC002852,"['artificial intelligence', ' auditory feedback', ' auditory stimulus', ' behavioral /social science research tag', ' clinical research', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' digital imaging', ' human subject', ' language development', ' model design /development', ' psychoacoustics', ' sound', ' speech', ' speech recognition', ' vocal cords', ' vocalization']",NIDCD,BOSTON UNIVERSITY,R29,2000,114255,0.04150974859882227
"EARLY LANGUAGE INTERVENTION VIA THE INTERNET Language delay is pervasive among preschool children. Early intervention is crucial since the consequences of language delay can be serious and cumulative, yet research shows that most preschoolers do not receive language intervention services. We propose to develop an Internet-based early language intervention system designed specifically for the remediation of language disorders in three to five-year-old children with language function in the range of 24 to 42 months. The curricular design will be based on contemporary linguistic research. On-line delivery of the intervention curriculum will be individualized and controlled by an artificial intelligence system that tracks ongoing performance. By combining Internet accessibility with centralized curricular control and data collection, it will become possible to implement and easily manage coordinated school and home language intervention strategies. It will also be possible to provide services to more children without further taxing limited professional resources. Our Phase I goal is to test the feasibility and technical merit of our plans. A prototype internet-based language intervention system will be developed and placed on- line in an Early Essential Education classroom, and students with language delays will be given an opportunity to use the system. PROPOSED COMMERCIAL APPLICATIONS: Speech-language pathologists, teachers, and parents recognize the importance of early intervention when a child's language status is impaired, and Federal law mandates such intervention. We anticipate that a highly accessible Internet-based language intervention system for three to five year olds will fulfill an unmet need for individualized services and will be a commercial success.  n/a",EARLY LANGUAGE INTERVENTION VIA THE INTERNET,6142025,R43DC004487,"['Internet', ' clinical research', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' curriculum', ' early experience', ' educational resource design /development', ' elementary school', ' human subject', ' language development', ' language disorders', ' online computer', ' preschool child (1-5)']",NIDCD,"LAUREATE LEARNING SYSTEMS, INC.",R43,2000,117683,0.11319183376105295
"Decoding inner speech: An AI approach to transcribing thoughts via EEG & EMG ABSTRACT  Losing the capacity to communicate through language has a significant negative impact on a person’s autonomy, social interactions, occupation, mental health, and overall quality of life. Many people lose the capacity to speak and write but keep their thinking intact.  Inner speech is internally and willfully generated, non-articulated verbal thoughts (e.g., reading in silence). Changes in the activation patterns of the brain’s language-related areas co-occur with inner speech and can be detected with electroencephalography (EEG). Furthermore, while inner speech doesn’t lead to any discernible voice sound or articulation, co-occurring low amplitude electrical discharges in the articulatory muscles can be detected with electromyography (EMG). The information about ongoing inner speech reflected in electrophysiological signals (EEG and EMG) can be used to transcribe inner speech into text or voice.  Machine learning algorithms have been used for this purpose, however, the resulting systems have low accuracy and/or are constrained by very small vocabularies (~10 words). Furthermore, these systems need to be trained anew for each user, which significantly increases individual data-collection time. The development of ready-to-use/minimal-training (fine tuning) systems requires large training datasets that algorithms can use to learn high-level features capable of being transferred between individuals. Unfortunately, to date there are no available datasets that are large enough to train these systems.  To tackle these issues, I have assembled a multidisciplinary team of collaborators from Google AI, Yale linguistics, and Yale Psychiatry to develop a state-of-the-art deep neural network to transcribe inner speech to text using EEG and EMG signals. This system will incorporate some of the latest advances in artificial intelligence and data processing developed by Google AI. It will be designed to transcribe phonemes, thus, in principle, will be able to transcribe any word. Furthermore, we will collect the largest (x120 times) multi-subject (n=150) electrophysiological (EEG+EMG) inner speech dataset to date (300 hrs. in total) to train the first ready- to-use/minimal-training inner speech transcriber system.  The technology resulting from this study has the potential to radically improve the quality of life of thousands of patients by providing them with a fast method of communicating their verbal thoughts. Furthermore, by combining this system with one of the many text-to-speech AIs that are currently available, our system could potentially restore the patients’ capacity to produce conversational speech. PROJECT NARRATIVE People that have lost their capacity for verbal communication struggle with isolation, mental illness, and poor quality of life. Artificial intelligence offers an opportunity to translate verbal thoughts into text or synthesized voice and restore verbal communication in impaired people. In this study, we introduce a state-of-the art artificial intelligence system designed to transduce the electrophysiological activity (electroencephalography [EEG] and electromyography [EMG]) accompanying verbal thoughts into text.",Decoding inner speech: An AI approach to transcribing thoughts via EEG & EMG,10058047,R21EB029607,"['ALS2 gene', 'Algorithms', 'American', 'Architecture', 'Area', 'Articulation', 'Artificial Intelligence', 'Attention', 'Brain', 'Clinical', 'Communication', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Development', 'Electroencephalography', 'Electromyography', 'Electrophysiology (science)', 'Expert Systems', 'Fostering', 'Gender', 'Genetic Transcription', 'Hand', 'Impairment', 'Individual', 'Language', 'Lead', 'Learning', 'Letters', 'Linguistics', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Muscle', 'Occupations', 'Output', 'Patients', 'Pattern', 'Performance', 'Persons', 'Psyche structure', 'Psychiatry', 'Quality of life', 'Reading', 'Signal Transduction', 'Social Interaction', 'Speech', 'Stimulus', 'Sum', 'System', 'Technology', 'Text', 'Thinking', 'Time', 'Training', 'Translating', 'Vocabulary', 'Voice', 'Writing', 'algorithm training', 'blind', 'computerized data processing', 'deep learning', 'deep neural network', 'design', 'digital', 'healthy volunteer', 'improved', 'innovation', 'large datasets', 'machine learning algorithm', 'multidisciplinary', 'performance tests', 'sound', 'speech accuracy']",NIBIB,YALE UNIVERSITY,R21,2020,523600,0.11425989783600962
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9831633,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2020,303452,0.1461926350399839
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. n/a",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,9981725,R01DC018446,"['Acoustics', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Area', 'Artificial Intelligence', 'Basic Science', 'Behavior', 'Behavioral', 'Birds', 'Brain', 'Cell Nucleus', 'Characteristics', 'Clinical Research', 'Clinical assessments', 'Communication', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Computer Interface', 'Computer software', 'Computers', 'Course Content', 'Data', 'Data Science', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Educational Materials', 'Educational workshop', 'Electrodes', 'Engineering', 'Evaluation', 'Feedback', 'Finches', 'Future', 'Generations', 'Goals', 'High School Outreach', 'High School Student', 'Human', 'Implant', 'Individual', 'Infrastructure', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Learning Module', 'Limb Prosthesis', 'Limb structure', 'Limes', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neurodegenerative Disorders', 'Neurosciences', 'Outcome Measure', 'Output', 'Patients', 'Performance', 'Play', 'Prevention', 'Principal Investigator', 'Production', 'Prosthesis', 'Quadriplegia', 'Recording of previous events', 'Research', 'Robot', 'Role', 'Running', 'Self-Help Devices', 'Signal Transduction', 'Songbirds', 'Space Models', 'Speech', 'Speech Development', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Translating', 'Translations', 'Upper Extremity', 'Voice', 'Work', 'auditory feedback', 'base', 'bird song', 'brain computer interface', 'brain machine interface', 'data sharing', 'design', 'effectiveness testing', 'functional electrical stimulation', 'functional restoration', 'graduate student', 'hackathon', 'high school', 'human subject', 'improved', 'large datasets', 'machine learning algorithm', 'meetings', 'mind control', 'model development', 'motor control', 'multidisciplinary', 'neural model', 'neural prosthesis', 'neurodevelopment', 'neurophysiology', 'neurotransmission', 'nonhuman primate', 'novel', 'open source', 'operation', 'programs', 'relating to nervous system', 'repository', 'response', 'signal processing', 'success', 'undergraduate student', 'vocal learning', 'vocalization', 'web site']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,344725,0.04319417924399905
"Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App PROJECT SUMMARY Background: Depression during pregnancy and the postpartum period affects up to 15% of US mothers, imposing costs on mother, child, and society. Early detection can significantly reduce the incidence of depression, yet depressive symptoms are often missed during prenatal visits, which tend to focus on maternal and fetal physical health, leaving less time for maternal mental health. Even if mental health is addressed during prenatal care, women may not feel comfortable answering questions that are perceived to be embarrassing or invasive. Failing to detect depression is even more likely during the postpartum period due to infrequent physician visits once the baby has been born. Measurement in the form of daily journals, which can be analyzed using natural language processing, can promote early and more frequent detection of depression during pregnancy and the postpartum period. Study Aims: 1) Model which dynamic features of language used over time best predict changes in depression status in the pregnancy and postpartum periods, creating phenotypes of depression risk; 2) examine how the language patterns that predict depression differ for African-American and Caucasian women; and 3) identify the relationship between the characteristics of what depressed peripartum women say and their treatment-seeking behavior. Innovation: The proposed research is innovative in its use of high frequency natural language measurements, captured in daily journals using a smartphone app, combined with advances in natural language processing models, to assess the onset and trajectory of depression during pregnancy and the postpartum period. This is the first prospective longitudinal study using natural language collection for risk prediction in a clinical population and the first to: 1) characterize the critical topics women discuss during the peripartum period over time using open-ended journals; 2) evaluate multiple facets of language to gain a more comprehensive understanding of the relationship between language and depression; 3) use a longitudinal design approach allowing for optimal modeling of language changes associated with depression onset. Methodology and Expected Results: Monthly depression risk identified from the Edinburgh Postnatal Depression Scale. will be collected through the MyHealthyPregnancy smartphone app, a mobile health application developed through close collaboration between decision scientists, clinicians, statisticians, and local peripartum women. A daily journal embedded in the MyHealthyPregnancy app will collect natural language text from the participants for 10 months (from their first prenatal visit through two months postpartum). Using three distinct natural language processing algorithmic approaches, this study will characterize how the natural language used by peripartum women in their daily journal entries is connected to the onset and experience of peripartum depression, as measured through monthly-administered depression scales. Group- based trajectory modeling will then classify women according to the patterns in their depression scores over time. Potential Impact: This work lays the foundation for developing and evaluating real-time interventions that could be deployed at scale to women who are using language that signals high depression risk. PROJECT NARRATIVE This research will examine how the topics (the people and events mentioned), sentiment (the positive, negative, and neutral affect), and other aspects of language expressed in daily journal entries correspond to diagnostic measures of depression and treatment-seeking in a peripartum clinical population. Psychometric and daily journal entry data will be gathered through an existing smartphone app, MyHealthyPregnancy, which monitors risk and delivers actionable information as part of routine prenatal care provided to the pregnant members of a large regional healthcare system.",Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App,9892136,R21MH119450,"['Address', 'Affect', 'African American', 'Algorithms', 'Appointment', 'Behavior', 'Behavioral Sciences', 'Birth', 'Caring', 'Caucasians', 'Characteristics', 'Child', 'Childbirth', 'Clinical', 'Collaborations', 'Collection', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Developmental Delay Disorders', 'Diagnostic', 'Disclosure', 'Early Diagnosis', 'Early treatment', 'Emotions', 'Environment', 'Event', 'Failure to Thrive', 'Feeling', 'Foundations', 'Frequencies', 'Healthcare Systems', 'Incidence', 'Infant', 'Intervention', 'Journals', 'Language', 'Longitudinal observational study', 'Longitudinal prospective study', 'Measurable', 'Measurement', 'Measures', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Moods', 'Mothers', 'National Institute of Mental Health', 'Natural Language Processing', 'Participant', 'Patients', 'Pattern', 'Perinatal', 'Phenotype', 'Physicians', 'Population', 'Postpartum Depression', 'Postpartum Period', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Prenatal care', 'Psychometrics', 'Race', 'Reporting', 'Research', 'Risk', 'Risk Assessment', 'Scientist', 'Signal Transduction', 'Societies', 'Source', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Visit', 'Voice', 'Well in self', 'Woman', 'Work', 'antepartum depression', 'base', 'cohort', 'cost', 'depression model', 'depressive symptoms', 'experience', 'fetal', 'health assessment', 'improved', 'innovation', 'longitudinal design', 'machine learning algorithm', 'member', 'motherhood', 'natural language', 'patient subsets', 'peripartum depression', 'physical conditioning', 'pregnant', 'racial disparity', 'response', 'routine screening', 'smartphone Application', 'social culture', 'sociodemographics', 'statistical and machine learning', 'time use', 'vector']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,233832,0.042710157850866404
"Real-time deep learning to improve speech intelligibility in noise Project Summary/Abstract  One in eight Americans has hearing loss, and this constitutes a major health and economic burden (Blackwell et al., 2014). The primary complaint of hearing-impaired (HI) listeners is difficulty understanding speech when background noise is present (see Dillon, 2012). While hearing aids (HAs) have improved in recent years, they still provide little benefit in noisy environments. For decades, a means of improving the ability to understand speech in background noise appeared unattainable, despite substantial amounts of research by both universities and HA companies. This changed when deep learning provided the first demonstration of a single-microphone algorithm that improves intelligibly in noise for HI listeners (Healy et al., 2013, 2014, 2015). Although this algorithm provides massive intelligibility improvements (even allowing listeners to improve intelligibility from floor to ceiling levels), it is currently not implemented to operate in real time and is therefore not suitable for implementation into HAs and cochlear implants (CIs). What is needed, therefore, is a highly effective noise-reduction algorithm that is capable of operating in real time. This project aims to address this critical need.  The long-term goal of the currently proposed project is to alleviate HI listeners’ predominant hearing handicap, which is difficulty understanding speech in background noise. The first aim introduces a new algorithm, based on a novel foundational scheme, that is designed to provide substantial benefit for any HI listener in real time. This algorithm will be well suited for implementation into HAs, CIs, and other face-to-face communication applications. The effectiveness of this new algorithm will be quantified using both HI and normal-hearing (NH) listeners. The second aim expands upon this new algorithm by modifying it to accept a small amount of future time-frame information, which could improve its noise-reduction performance but will introduce a brief processing delay. The rationale is that different devices have different allowable latencies. Face-to-face communication devices (HAs, CIs, etc.) have strict low-latency requirements, but other important communication systems (e.g., telephones) have different requirements. It is possible that the addition of future time-frame information within these requirements (up to 150 ms) will result in even better speech intelligibility. But the magnitude of any potential benefit is unknown. This critical information will be established currently. Using both HI and NH listeners, we will measure intelligibility for noisy sentences that have been processed using various amounts of future time information.  This comprehensive fellowship training plan will provide individualized, mentored research training from world-class faculty in a highly supportive and productive environment. The proposed work will endow the applicant with the skills needed to transition to the next stage of his research career, transform our treatment of hearing loss, and substantially impact quality of life for millions of Americans. Project Narrative An estimated 37.5 million Americans have hearing loss, which commonly leads to difficulty understanding speech in background noise. The proposed study will test a new noise-reduction system and improve our treatment of hearing loss.",Real-time deep learning to improve speech intelligibility in noise,10155960,F32DC019314,"['Address', 'Algorithms', 'American', 'Area', 'Auditory', 'Cellular Phone', 'Characteristics', 'Cochlear Implants', 'Communication', 'Complex', 'Data', 'Devices', 'Diagnosis', 'Economic Burden', 'Effectiveness', 'Environment', 'Equilibrium', 'Etiology', 'Faculty', 'Fellowship', 'Floor', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Human', 'Implant', 'Measures', 'Mentors', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Phase', 'Prevention', 'Process', 'Quality of life', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Scheme', 'Seminal', 'Signal Transduction', 'Speech', 'Speech Intelligibility', 'Strategic Planning', 'System', 'Telephone', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Videoconferencing', 'Work', 'artificial neural network', 'base', 'career', 'communication device', 'deep learning', 'deep neural network', 'design', 'experimental study', 'health economics', 'hearing impairment', 'hearing loss treatment', 'improved', 'microphone', 'network architecture', 'neural network', 'normal hearing', 'novel', 'novel strategies', 'operation', 'skills', 'speech in noise', 'wearable device']",NIDCD,OHIO STATE UNIVERSITY,F32,2020,76840,0.06711867176318462
"Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach Thought disorder in psychotic disorders and their risk states has typically been evaluated using clinical rating scales, and occasionally labor-intensive manual methods of linguistic analysis. We propose instead to use a novel automated linguistic corpus-based approach to language analysis informed by artificial intelligence. The method derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to language, and leads to measures of semantic coherence from one phrase to the next. It also evaluates syntactic complexity through “part-of-speech” tagging and analysis of speech graphs. These analyses yield fine-grained indices of speech semantics and syntax that may more accurately capture thought disorder.  Using these automated methods of speech analysis, in collaboration with computer scientists from IBM, we identified a classifier with high accuracy for psychosis onset in a small CHR cohort, which included decreased semantic coherence from phrase to phrase, and decreased syntactic complexity, including shortened phrase length and decreased use of determiner pronouns (“which”, “what”, “that”). These features correlated with prodromal symptoms but outperformed them in classification accuracy. They also discriminated schizophrenia from normal speech. We further cross-validated this automated approach in a second small CHR cohort, identifying a semantics/syntax classifier that classified psychosis outcome in both cohorts, and discriminated speech in recent-onset psychosis patients from normal speech.  These automated linguistic analytic methods hold great promise, but their use thus far has been circumscribed to only a few small studies that aim to discriminate schizophrenia from the norm, and in our own work, predict psychosis. There is a critical gap in our understanding of the linguistic mechanisms that underlie thought disorder. To address this gap, in response to PAR-16-136, we propose to use the RDoC construct of language production, and its linguistic corpus-based analytic paradigm, to study thought disorder dimensionally and transdiagnostically, in a large cohort of 150 putatively healthy volunteers, 150 CHR patients, and 150 recent-onset psychosis patients. We expect that latent semantic analysis will yield measures of semantic coherence that index positive thought disorder (tangentiality, derailment), whereas part-of-speech (POS) tagging/speech graphs will yields measures of syntactic complexity that index negative thought disorder (concreteness, poverty of content).  This large language dataset will be obtained from two PSYSCAN/HARMONY sites, such that these language data will be available for secondary analyses with PSYSCAN/HARMONY imaging and EEG data to study language production at the circuit and physiological levels. This large language and clinical dataset will also be archived at NIH for further linguistic analyses by other investigators. Language offers a privileged view into the mind: it is the basis by which we infer others' thoughts. In collaboration with computer scientists at IBM, we will use advanced computational speech analytic approaches to identify the linguistic basis – semantics and syntax – that underlie language production along a spectrum from normal to gradations of thought disorder. Our large international language dataset on 450 individuals will be archived at NIH as a resource for further linguistic analyses.",Using the RDoC Approach to Understand Thought Disorder: A Linguistic Corpus-Based Approach,9859468,R01MH115332,"['Address', 'Age', 'Archives', 'Artificial Intelligence', 'Canis familiaris', 'Categories', 'Classification', 'Clinical', 'Cognition', 'Collaborations', 'Communication', 'Computers', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electroencephalography', 'Felis catus', 'Genetic', 'Grain', 'Graph', 'Human', 'Image', 'Individual', 'International', 'Interview', 'Language', 'Length', 'Linguistics', 'Manuals', 'Measures', 'Mediator of activation protein', 'Metaphor', 'Methods', 'Mind', 'Mood Disorders', 'Morbidity - disease rate', 'Morphology', 'NIH Program Announcements', 'National Institute of Mental Health', 'Natural Language Processing', 'Outcome', 'Output', 'Patients', 'Physiological', 'Poverty', 'Production', 'Psychotic Disorders', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Scientist', 'Semantics', 'Series', 'Site', 'Speech', 'Sum', 'Symptoms', 'Techniques', 'Text', 'Thinking', 'United States National Institutes of Health', 'Work', 'Yogurt', 'analytical method', 'base', 'cohort', 'data archive', 'functional disability', 'functional outcomes', 'healthy volunteer', 'high risk', 'indexing', 'natural language', 'neural correlate', 'novel', 'phrases', 'relating to nervous system', 'response', 'secondary analysis', 'syntax', 'vector']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,533776,0.15889817172324472
"Circuit Dynamics for encoding and remembering sequence of events We experience the world as a continuous sequence of events, but we remember the events as segmented episodes (e.g., my sister’s wedding). During encoding, we associate a sequence of relevant events and segment deviant events. At retrieval, episodic memory utilizes the encoded associations to replay the flow of events. The encoded associations lead to remembering the sequence of events that occurred within an episode better than the flow of events across segments. The hippocampus and the prefrontal cortices (PFC) are essential parts of the neural circuit for segmenting, linking, and retrieving memories of associated events. This proposal aims to identify neural dynamics in the hippocampus-PFC circuit that support encoding a naturalistic flow of events, i.e., sequences of words. We will determine these neural dynamics using intracranial encephalography (iEEG) acquired from the hippocampus and PFC of epileptic patients, who have electrodes implemented for pre-surgical seizure monitoring. I will model associations of words using Natural Language Processing algorithms, and I will combine the extracted features with advanced data analysis techniques including multivariate pattern analysis to determine neural dynamics engaged during encoding. I will use speech as a model with an identical flow of events in the speech stimuli across participants. This consistency will allow validation of effects across a group of participants. Algorithms for identifying features of speech are well developed and freely available. I will specifically use elements of speech that distinguish context, word dependencies, and reference points of pronouns for modeling concurrent changes in patterns of activity in the local field potential recorded from the hippocampus and PFC. The central hypotheses are that bidirectional communications between the hippocampus and PFC support the encoding of sequences of events and successful subsequent memory. To address a causal relationship between hippocampal function and event segmentation, I will study speech comprehension and speech memory in developmental amnesic patients who suffer from hippocampal damage and have trouble tracking reference points in a speech. To achieve the proposal’s goals, I will pursue training under the mentorship of Dr. Elizabeth Buffalo (University of Washington) that will focus on the advanced analysis of local field potentials. The advanced study of human iEEG data will include comparable electrophysiology signal analyses that have been applied to the recordings from the hippocampus of non-human primates in Buffalo’s memory lab. This skill-set along with ongoing mentoring from Dr. Robert Knight (University of California, Berkeley), who has an established laboratory for human iEEG, and my previous work on human iEEG will provide a vigorous methodological, conceptual, and analytical basis for developing an independent research program. The combination of iEEG, Natural Language Processing modeling, and patients’ behavioral data will provide valuable insights into the neural dynamics of effective speech encoding that predicts subsequent memory, which may inform development into therapeutic interventions. The ability to segment the world into meaningful episodes engages the human hippocampus and prefrontal cortex. Using direct electrophysiological recording from the human brain, advanced analytical techniques, Natural Language Processing models, and the behavior of patients with hippocampal lesions, this proposal will determine the neural dynamics for efficient encoding of sequences of words that predicts successful memory formation. The findings of this proposal may help inform the development of neural prosthetics for assisting patients with memory deficits.",Circuit Dynamics for encoding and remembering sequence of events,9894860,K99MH120048,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavioral', 'Bilateral', 'Brain', 'Brain region', 'Buffaloes', 'California', 'Communication', 'Comprehension', 'Computer Models', 'Coupling', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Electrodes', 'Electroencephalography', 'Electrophysiology (science)', 'Elements', 'Epilepsy', 'Episodic memory', 'Event', 'Frequencies', 'Goals', 'Grouping', 'Hippocampus (Brain)', 'Human', 'Impairment', 'Laboratories', 'Lead', 'Lesion', 'Link', 'Memory', 'Memory impairment', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Natural Language Processing', 'Operative Surgical Procedures', 'Participant', 'Patients', 'Pattern', 'Phase', 'Play', 'Prefrontal Cortex', 'Process', 'Research', 'Retrieval', 'Role', 'Seizures', 'Signal Transduction', 'Sister', 'Speech', 'Stimulus', 'Techniques', 'Therapeutic Intervention', 'Training', 'Universities', 'Validation', 'Washington', 'Work', 'advanced analytics', 'deviant', 'encephalography', 'experience', 'indexing', 'insight', 'neural circuit', 'neural prosthesis', 'neurodevelopment', 'neuromechanism', 'nonhuman primate', 'programs', 'relating to nervous system', 'skills']",NIMH,UNIVERSITY OF WASHINGTON,K99,2020,96235,0.049043463469988426
"Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence ABSTRACT  Approximately 15% of toddlers 18-36 months of age experience late language emergence (LLE; Paul, 1992; Singleton, 2018). These late talkers (LTs) have a reduced expressive vocabulary, but average non-linguistic abilities, in the absence of overt sensory or other developmental delays (Collisson, 2016; Paul & Jennings, 1992). Upwards of 16% of LTs prospectively meet criteria for language disorder (Rescorla, 2009), while others retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). LTs are at elevated risk for lifelong language and literacy impairments that negatively impact access to academic and vocational opportunities (Singleton, 2018; Paul, 1993), and even subclinical outcomes have pervasive negative impacts (Rescorla, 2002). This project addresses questions crucial for the early diagnosis of LTs and prerequisite to the applicant’s long-term goal of establishing an independent research program on LLE, aimed ultimately at identifying variation and distribution of behavioral phenotypes to provide a foundation for more targeted interventions for LTs. This project complements prior work on LLE focused on language production by evaluating the time course of word learning and spoken word recognition in LTs and 2 control groups (age- and language-matched typically developing peers), all of whom will complete standardized assessments of cognitive -linguistic abilities. In Expt. 1, participants will train on a simple selection task using 4 novel and 4 familiar words that overlap phonologically (e.g., at onset, BUNNY-BUTTON, or offset, KITTEN-MITTEN). We will use eye tracking to estimate group and individual differences in lexical activation and competition over time. In Expt. 2, we will record EEG (electroencephalography) in a passive listening task. Participants will watch a silent video as newly-learned and familiar words from Expt. 1 are repeated. ERP (event-related potential) analyses will examine individual and group differences in responses to newly-learned vs. familiar words. We will also use machine-learning (support vector machines, SVMs) to decode EEG responses to specific words for each participant, on the logic that fidelity and coherence of responses will determine SVM classification success. Group and individual differences in eye tracking, ERP, and/or EEG-decoding measures will provide new insights into receptive abilities of LTs, and provide a basis for future work aimed at identifying LTs with greatest risk for clinical or subclinical language outcomes. The project will take place at the U. of Connecticut and Haskins Labs. The applicant and sponsors have developed a training plan for the applicant focused on further developing her (1) EEG and statistical skills, (2) knowledge base of the cognitive neuroscience of typical and atypical language development, (3) dissemination skills, and (4) understanding of principles for the responsible conduct of research, with the aim of supporting her goal to be an independent researcher in a Research-1 environment. PROJECT NARRATIVE  Approximately 15% of toddlers meet criteria for being a late talker (LT) (Paul, 1993; Singleton, 2018;) and upwards of 16% of LTs prospectively meet criteria for spoken and/or written language disorder (Rescorla, 2009) while another subset will retain suboptimal language functioning (Rescorla, 2002; Singleton, 2018). Late language emergence (LLE) is associated with lifelong clinical and subclinical weaknesses in language and literacy that negatively impact access to academic and vocational opportunities (Paul, 1993; Singleton, 2018), and even subclinical outcomes have a negative impact on vocational and higher educational choices (Rescorla, 2002). The proposed research will address questions prerequisite to the applicant's long-term goal of establishing an independent research program aimed at (1) identifying early markers of chronic impact in order to optimally allocate scarce early intervention resources and (2) identifying variation and distribution of behavioral phenotypes which will provide the foundation for more focused and targeted forms of interventions for LTs with a range of clinical and subclinical language outcomes.",Behavioral and Neurobiological Underpinnings of Spoken Word Recognition in Late Language Emergence,9975626,F31DC018220,"['3 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Behavioral', 'Child', 'Chronic', 'Classification', 'Clinical', 'Cognitive', 'Complement', 'Complex', 'Connecticut', 'Control Groups', 'Development', 'Developmental Delay Disorders', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Endowment', 'Environment', 'Evaluation', 'Event-Related Potentials', 'Exclusion', 'Foundations', 'Future', 'Goals', 'Grain', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Knowledge', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Logic', 'Machine Learning', 'Measures', 'Morphology', 'Neurobiology', 'Outcome', 'Output', 'Participant', 'Phenotype', 'Population', 'Process', 'Production', 'Property', 'Research', 'Research Personnel', 'Resources', 'Risk', 'School-Age Population', 'Sensory', 'Signal Transduction', 'Speech', 'Speed', 'Standardization', 'Testing', 'Time', 'Toddler', 'Training', 'Variant', 'Visual', 'Vocabulary', 'Word Processing', 'Work', 'base', 'behavioral phenotyping', 'clinical risk', 'cognitive neuroscience', 'experience', 'experimental study', 'high risk', 'improved outcome', 'insight', 'knowledge base', 'language impairment', 'language outcome', 'language processing', 'lexical', 'lexical processing', 'literacy', 'multimodality', 'neural correlate', 'novel', 'peer', 'phonology', 'programs', 'prospective', 'reduce symptoms', 'relating to nervous system', 'response', 'responsible research conduct', 'skills', 'social', 'sound', 'success', 'support vector machine', 'trait', 'visual tracking', 'word learning']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,F31,2020,15602,0.08049943941723342
"Automatic Voice-Based Assessment of Language Abilities ﻿    DESCRIPTION (provided by applicant): Since untreated language disorder - a disorder with a prevalence of at least 7% - can lead to serious behavioral and educational problems, large-scale early language assessment is urgently needed not only for early identification of language disorder but also for planning interventions and tracking progress. This is all the more so because a recent study found that 71% of children diagnosed with Specific Language Impairment (a type of language disorder) had not been previously identified. However, such large-scale efforts would pose a large burden on professional staff and on other scarce resources. As a result, clinicians, educators, and researchers have argued for the use of computer based assessment. Recently, progress has been made with computer based language assessment, but it has been limited to language comprehension (i.e., receptive vocabulary and grammar). Thus, computer based assessment of language production that is expressive language and particularly discourse skills, is still lacking. One contributing factor is that a key technology needed for this, Automatic Speech Recognition (ASR), is perceived as inadequate for accurate scoring of language tests since even the best ASR systems have word error rates in excess of 20%. However, this perception is based on a limited perspective of how ASR can be used for assessment, in which a general- purpose ASR system provides an (often inaccurate) transcript of the child's speech, which then would be scored automatically according to conventional rules. We take an alternative perspective, and propose an innovative approach that comprises two core concepts. The first is that of creating special-purpose, test-specific ASR systems whose search space is carefully matched to the space of responses a test may elicit. The second is that of integrating these systems with machine-learning based scoring algorithms whereby the latter operate not on the final, ""best"" transcript generated by the ASR system but on the rich layers of intermediate representations that the ASR system computes in the process of recognizing the input speech (""rich representation""). Earlier experiments in our lab with digit and narrative recall tests have demonstrated the feasibility of this approach. In the proposed project we will create computer-based scoring and test administration systems for tests in the expressive modality as well as in the vocabulary, grammar, and discourse domains; we will also create a system for a non-word repetition test. The systems will be applied to a diverse group of 300 children ages 3-9 with typical development and with neurodevelopmental disorders, and will be validated against conventional language measures. The automated language tests developed in the project cover core diagnostic criteria for language disorders but also create a technological foundation for the computerization of a much broader array of tests for voice based language and cognitive assessment. PUBLIC HEALTH RELEVANCE: There is a significant need for language assessment for early detection, diagnosis, screening, and progress tracking of language difficulties. However, assessment involves face-to-face sessions with a professional, which may not always be available and affordable. The project goal is to provide a technology solution, by designing, implementing, and evaluating computer-based systems for automated voice-based language assessment (both test administration and test scoring) for narrative recall, picture naming, sentence repetition, sentence completion, and nonword repetition.",Automatic Voice-Based Assessment of Language Abilities,9825536,R01DC013996,"['Adult', 'Age', 'Algorithms', 'American', 'American Sign Language', 'Assessment tool', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavioral', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Comprehension', 'Computer Systems', 'Computers', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Digit structure', 'Disease', 'Early Diagnosis', 'Early identification', 'Emotional', 'Ensure', 'Face', 'Foundations', 'Friends', 'Funding', 'Goals', 'Hearing', 'High Prevalence', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Disorders', 'Language Tests', 'Lead', 'Learning', 'Machine Learning', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modality', 'Morphology', 'Names', 'National Institute on Deafness and Other Communication Disorders', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Parents', 'Perception', 'Performance', 'Policies', 'Prevalence', 'Privatization', 'Process', 'Production', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Scoring Method', 'Semantics', 'Services', 'Societies', 'Speech', 'Supervision', 'System', 'Technology', 'Testing', 'Transcript', 'Translating', 'Vocabulary', 'Voice', 'autism spectrum disorder', 'automated speech recognition', 'base', 'cognitive testing', 'computerized', 'cost', 'design', 'experimental study', 'follow up assessment', 'innovation', 'innovative technologies', 'language comprehension', 'language disorder diagnosis', 'phonology', 'psychiatric symptom', 'public health relevance', 'response', 'school district', 'screening', 'service intervention', 'skills', 'social communication', 'specific language impairment', 'syntax', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,574747,0.1339469354487025
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9894782,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,517151,0.11309878176323111
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,9895715,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,583798,0.08410830212603831
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,9964782,K24DC016312,"['3-Dimensional', 'Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'effectiveness testing', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'machine learning algorithm', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual', 'virtual vocal tract']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2020,189841,0.126364951711706
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many  evidence-based treatments for substance abuse are “talk based” therapies, such as motivational  interviewing (MI), but the existing research-based methodology for evaluating counseling quality is  to record sessions and use human rating teams to evaluate them. However, using humans as the  assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is  virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling  sessions, provide automatic and intuitive quality scores, and summarize these in actionable  feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and  quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support  evidence-based counseling.  Our goal is to develop innovative health technology solutions that are  objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing,  machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling.  Previous NIH-funded research laid a computational foundation for generating MI quality metrics from  speech and language features in MI sessions, and led to a prototype of a clinical software support  tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical  workflows, assessing usability, and initial validation of machine learning of MI fidelity measures  in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase  II will focus on robust validation of the speech and language technologies underlying the CORE-MI  tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback  for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported  supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability,  usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence  of increased client retention.  The successful execution of this project will break the reliance on  human judgment for providing performance-based feedback to MI and will massively expand the  capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling  interventions, such as motivational interviewing. There are currently no methods for evaluating the  quality of such counseling interventions in the real world to support training, supervision, and  quality assurance. Building on an existing prototype, Lyssn.io – a technology start-up focused on  scalable and cost-efficient human-centered technologies – will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community  based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9930480,R44DA046243,"['Administrator', 'Adoption', 'Alcohol or Other Drugs use', 'American', 'Assessment tool', 'Behavioral', 'Client', 'Clinic', 'Clinical', 'Code', 'Communities', 'Computer software', 'Counseling', 'Development', 'Evaluation', 'Evidence based treatment', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Health Technology', 'Human', 'Intervention', 'Interview', 'Intuition', 'Judgment', 'Language', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Opioid', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Primary Health Care', 'Professional counselor', 'Protocols documentation', 'Provider', 'Psychotherapy', 'Research', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Speech', 'Substance abuse problem', 'Supervision', 'Technology', 'Time', 'Training', 'Training Support', 'Transcript', 'United States National Institutes of Health', 'Validation', 'automated speech recognition', 'base', 'cloud based', 'commercialization', 'cost', 'cost efficient', 'design', 'evidence base', 'improved', 'innovation', 'motivational enhancement therapy', 'opioid treatment program', 'primary care setting', 'prototype', 'quality assurance', 'signal processing', 'sound', 'substance abuse treatment', 'support tools', 'technology validation', 'tool development', 'treatment services', 'usability', 'user centered design', 'virtual']",NIDA,"LYSSN.IO, INC.",R44,2020,134649,0.06328625279528656
"Structural and functional connectivity markers of developmental speech and language disorders ABSTRACT Developmental speech and language disorders affect an estimated 15% of children and have lifelong impacts on social and emotional development and employment. Two common neurodevelopmental disorders are developmental language disorder (DLD; also called specific language impairment) and developmental stuttering, affecting 7% and 5% of children respectively. Despite their prevalence and immense impact, little is known of the neural causes, correlates, and consequences of these common neurodevelopmental disorders; thus, effective treatment remains elusive. In the proposed project, we will study the neural underpinnings of these disorders using magnetic resonance imaging (MRI) to study structural and functional neural connectivity. Previous studies of connectivity in these populations are limited and show little consensus, likely due in part to small sample sizes. Theoretical accounts of both disorders implicate dysfunctional neural circuits through the basal ganglia. In the current proposal, we will test and compare the structural and functional integrity of neural pathways in large cohorts of people with DLD (N=80) and people who stutter (PWS; N=80) and compare them with similar data obtained in age- and sex-matched control groups of people with typical development (N=160). First, we will assess connectivity in speech/language-specific networks, using diffusion data to assess structural connectivity and resting-state data to assess functional connectivity. Results will indicate abnormalities in connectivity in large cohorts of PWS and people with DLD. In each disorder, we will also determine connectivity contributions to individual differences in behavior. This will reveal how different connectivity patterns are correlated to differences in severity along relevant dimensions (e.g., fluency, language measures), ideally resulting in neural correlates of the disorders. Finally, we will evaluate whole-brain functional connectivity differences between each disorder group and its matched control group using data-driven machine learning approaches. Results will indicate patterns of neural activity that differentiate these disorders from controls. The outcome of this proposal will be the characterization of underlying network differences in these populations, which will ideally lead to the development of targeted behavioral and neuro-modulatory treatments of these multifaceted and pervasive disorders. Research and training will take place at the University of Oxford, an ideal environment in which to pursue this line of research. The applicant will be mentored by world-leading researchers with the knowledge needed to guide him in this work, including expertise in the neural bases of developmental speech and language disorders, cutting-edge methodology in neuroimaging, and machine learning. Achieving these aims will illuminate the neural correlates of these speech and language disorders as well as prepare the applicant for an independent research career in this area. PROJECT NARRATIVE For a surprisingly large number of children, as many as 15%, speech and language development does not go smoothly and results in disorders such as stuttering or language delay. We wish to understand more about the causes of these common disorders and will assess whether the brain networks involved in speech and language development are impaired in people with developmental language disorder and stuttering. Using large existing neuroimaging datasets obtained in these disorders will allow us to address important questions about the causes and consequences of these developmental disorders.",Structural and functional connectivity markers of developmental speech and language disorders,9944309,F32DC017637,"['Address', 'Adolescent', 'Adult', 'Affect', 'Age', 'Area', 'Auditory', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Cerebral cortex', 'Child', 'Classification', 'Clinical', 'Comprehension', 'Consensus', 'Control Groups', 'Corpus striatum structure', 'Data', 'Data Set', 'Development', 'Developmental Stuttering', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Emotional', 'Employment', 'Environment', 'Event', 'Functional Imaging', 'Future', 'Heterogeneity', 'Image', 'Impairment', 'Individual', 'Individual Differences', 'Inferior frontal gyrus', 'Investigation', 'Knowledge', 'Language', 'Language Delays', 'Language Development', 'Language Development Disorders', 'Language Disorders', 'Lead', 'Length', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentors', 'Methodology', 'Motor', 'Network-based', 'Neural Pathways', 'Neurodevelopmental Disorder', 'Neurophysiology - biologic function', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Pattern', 'Population', 'Prevalence', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Rest', 'Sample Size', 'Sampling', 'Scanning', 'Semantics', 'Severities', 'Speech', 'Speech Development', 'Speech Disorders', 'Structure', 'Stuttering', 'Superior temporal gyrus', 'Testing', 'Universities', 'Work', 'base', 'career', 'caudate nucleus', 'cohort', 'developmental disease', 'disorder control', 'economic impact', 'effective therapy', 'interest', 'language impairment', 'motor control', 'neural circuit', 'neural correlate', 'neural network', 'neural patterning', 'neuroimaging', 'neuroregulation', 'putamen', 'relating to nervous system', 'sex', 'social', 'specific language impairment', 'standardize measure']",NIDCD,UNIVERSITY OF OXFORD,F32,2020,69426,0.07706456746166097
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,0.07721491719431109
"A holistic approach to identifying functional units of tongue motion during speech PROJECT SUMMARY  Oral cancers have the seventh highest incidence, with roughly 51,540 new cases and 10,030 cancer- related deaths expected to occur in 2018. Although a variety of treatment methods are available, the death rate is higher than that for most cancers with five-year rates of about 50 percent. The most frequently used treatment method, glossectomy surgery, involves the surgical removal of tumors and surrounding tissues, and the addition of grafted tissues, often followed by radiotherapy. Although tongue cancer and its treatment have debilitating effects on speech, the impact of varying degrees of resection and reconstruction on the formation of functional units in speech has remained poorly understood. In order to produce intelligible speech, a variety of local muscle groupings of the tongue—i.e., functional units—emerge and recede rapidly and nimbly in a highly coordinated fashion. Therefore, understanding the formation of functional units that are critical for speech production can provide substantial insights into normal, pathological, and adapted motor control strategies in controls and patients with tongue cancer for novel therapeutic, surgical, and rehabilitative strategies. One of the critical challenges in pre-operative surgical and treatment planning, as well as in post- operative evaluation for tongue cancer is the difficulty in developing objective and quantitative measures and in evaluating their functional outcome predictability. To address this, in this proposal, three integrated approaches will be used in in vivo tongue motion during speech to seamlessly identify the functional units and associated quantitative measures: multimodal MRI methods, multimodal deep learning, and biomechanical simulations. This will provide a convergent approach, thereby allowing us to (1) test hypotheses about the spatiotemporal basis of muscle coordination in a consilient way, and (2) develop objective quantitative measures that are required for understanding the complex biomechanical system as well as for predicting the functional outcomes after various reconstruction methods. The first proof of concept study published by the PI and the team identified the functional units of speech tasks using the sparse non-negative matrix factorization framework, in which the magnitude and angle of displacements from tagged MRI were used as our input quantities. With these advances in place, we will further incorporate muscle fiber anatomy from diffusion MRI and motion tracking from tagged MRI into our framework to yield physiologically and anatomically meaningful functional units. In addition, we will create a completely novel and integrated way of directly relating the functional units to tongue muscle anatomy, learning joint representation via a multimodal deep learning technique, and linking them to biomechanical simulations. Furthermore, 3D and 4D atlases will be utilized to identify objective and quantitative measures based on our functional units analysis. Taken together, the successful implementation of our integrated framework will identify functional units that can be used for research on tongue motion, for surgical planning, and for diagnosis, prognosis, and rehabilitation in a range of speech-related disorders. PROJECT NARRATIVE  Tongue cancer and its treatment affect tongue structure and function, yet little is known about how the changes in tongue structure due to varying degrees of resection and reconstruction affect the formation of functional units of tongue motion during speech. We propose to use novel integrated platform tools to identify functional units seamlessly with unprecedented resolution and precision. Upon success of this proposal, our integrated framework has the potential to aid in an increased understanding of speech motor control strategies in healthy controls and the patient group, thereby benefiting patients through improved diagnosis, treatment, and rehabilitative strategies.",A holistic approach to identifying functional units of tongue motion during speech,9937181,R01DC018511,"['3-Dimensional', 'Acoustics', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Atlases', 'Behavior', 'Biomechanics', 'Cessation of life', 'Clinical', 'Complex', 'Computing Methodologies', 'Data', 'Death Rate', 'Deglutition', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Evaluation', 'Excision', 'Exhibits', 'Fiber', 'Geometry', 'Glossectomy', 'Goals', 'Grouping', 'Impairment', 'Incidence', 'Joints', 'Knowledge', 'Learning', 'Link', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Muscle', 'Muscle Fibers', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Physiological', 'Postoperative Period', 'Predictive Value', 'Procedures', 'Production', 'Proxy', 'Publishing', 'Radiation therapy', 'Rehabilitation therapy', 'Research', 'Resolution', 'Speech', 'Speech Intelligibility', 'Standardization', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Tissue Grafts', 'Tissues', 'Tongue', 'Weight', 'Work', 'base', 'biomechanical model', 'clinical practice', 'deep learning', 'functional outcomes', 'holistic approach', 'improved', 'in vivo', 'insight', 'malignant mouth neoplasm', 'malignant tongue neoplasm', 'motor control', 'multimodality', 'muscular structure', 'novel', 'novel therapeutics', 'outcome forecast', 'outcome prediction', 'reconstruction', 'rehabilitation strategy', 'signal processing', 'spatiotemporal', 'success', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,588403,0.04087422364749721
"Technology-supported, measurement-based supervision for Motivational Interviewing Millions of Americans receive evidence-based counseling for substance use problems each year. Many evidence-based treatments for substance abuse are “talk based” therapies, such as motivational interviewing (MI), but the existing research-based methodology for evaluating counseling quality is to record sessions and use human rating teams to evaluate them. However, using humans as the assessment tool via behavioral coding is prohibitive in cost and time, can be error prone, and is virtually never used in the real world. Technology is needed that can analyze the speech patterns and spoken language of counseling sessions, provide automatic and intuitive quality scores, and summarize these in actionable feedback. Rapid, performance-based quality metrics could support training, ongoing supervision, and quality assurance for millions of evidence-based counseling sessions for substance abuse each year. Lyssn.io is a start-up targeting the development of implementation-focused technology to support evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. Lyssn.io includes expertise in speech signal processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous NIH-funded research laid a computational foundation for generating MI quality metrics from speech and language features in MI sessions, and led to a prototype of a clinical software support tool, the Counselor Observer Ratings Expert for MI (CORE-MI). The current Fast-Track SBIR proposal includes Phase I, which will focus on understanding clinical workflows, assessing usability, and initial validation of machine learning of MI fidelity measures in the opioid treatment program at Evergreen Treatment Services (ETS) clinic in Seattle, WA. Phase II will focus on robust validation of the speech and language technologies underlying the CORE-MI tool, and development of scalable supervision protocols that integrate CORE-MI supported feedback for counselors. Finally, we will conduct a quasi-experimental evaluation of CORE-MI supported supervision and training at a second ETS clinic in the Puget Sound, focusing on acceptability, usability, and adoption, the impact on supervision, improved MI fidelity and preliminary evidence of increased client retention. The successful execution of this project will break the reliance on human judgment for providing performance-based feedback to MI and will massively expand the capacity to train, supervise, and provide quality assurance in MI for substance abuse. Most evidence-based treatments for substance abuse are in-person psychotherapy and counseling interventions, such as motivational interviewing. There are currently no methods for evaluating the quality of such counseling interventions in the real world to support training, supervision, and quality assurance. Building on an existing prototype, Lyssn.io – a technology start-up focused on scalable and cost-efficient human-centered technologies – will enhance and evaluate a cloud-based, HIPAA-compliant clinical support software tool that uses automated speech recognition and machine learning in an community based opioid replacement clinic.","Technology-supported, measurement-based supervision for Motivational Interviewing",9847959,R44DA046243,"['Adherence', 'Administrator', 'Adoption', 'Alcohol or Other Drugs use', 'Algorithms', 'American', 'Assessment tool', 'Behavior Therapy', 'Behavioral', 'Benchmarking', 'Client', 'Clinic', 'Clinical', 'Code', 'Communities', 'Computer software', 'Consumption', 'Counseling', 'Dependence', 'Development', 'E-learning', 'Enhancement Technology', 'Environment', 'Evaluation', 'Evidence based treatment', 'Feasibility Studies', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Technology', 'Human', 'Intervention', 'Intuition', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'National Institute of Drug Abuse', 'Needs Assessment', 'Online Systems', 'Opioid', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Professional counselor', 'Protocols documentation', 'Provider', 'Psychology', 'Psychotherapy', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Speech', 'Stream', 'Substance Use Disorder', 'Substance abuse problem', 'Suicide', 'Supervision', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Validation', 'Work', 'addiction', 'automated speech recognition', 'automobile accident', 'base', 'clinical practice', 'cloud based', 'community setting', 'cost', 'cost efficient', 'dashboard', 'design', 'encryption', 'evidence base', 'experience', 'gun homicide', 'implementation research', 'improved', 'innovation', 'motivational enhancement therapy', 'novel', 'opioid abuse', 'opioid treatment program', 'overdose death', 'prediction algorithm', 'protocol development', 'prototype', 'quality assurance', 'research and development', 'signal processing', 'skills', 'sound', 'speech processing', 'substance abuse treatment', 'support tools', 'technological innovation', 'tool', 'tool development', 'treatment services', 'usability', 'user centered design', 'virtual', 'visual feedback']",NIDA,"LYSSN.IO, INC.",R44,2020,394059,0.06328625279528656
"Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders Abstract: Early and accurate diagnosis of neurocognitive disorders (NCDs) is critical for planning, treatment, and research referral, but demands time and expertise often unavailable to primary care providers. Speech and language are often impaired early in the disease course of several NCDs. Previous research has demonstrated the diagnostic potential of computer speech analysis (CSA), with differences between healthy controls and disorders such as mild cognitive impairment (MCI) and Alzheimer's disease. However, there are several additional steps that must be taken to make CSA a diagnostically viable screening tool. This proposal includes a career development plan providing the applicant with training, mentorship, and experience in the following areas in order to bring CSA techniques into clinical practice: 1) computational linguistics and paralinguistics, 2) longitudinal markers of disease, and 3) design of novel technology for dissemination. As part of this training, academic and professional skills, including ethics in research, will also be expanded. Uniquely qualified mentorship and advisory teams have been selected to ensure the success of the proposed training and research. The proposed study is a prospective, longitudinal, observational, cohort investigation of two distinct research groups. The first group is a highly selected and well-characterized research cohort of healthy control, Alzheimer's disease, and MCI subjects (Group A). In Group A, the performance and reproducibility of a machine learning algorithm will be improved to distinguish Alzheimer's disease and MCI from healthy controls using CSA. Multiple regression and voxel-based morphometry will be used to better understand what may drive group differences in CSA measures in Group A as well. Clinical applications of this algorithm will then be assessed in a clinic-based cohort of patients with different NCDs (Group B) in order reduce spectrum bias likely present in prior studies. As sub-aims in both groups, possible further improvement of the algorithmic outcomes with longitudinal CSA measures will also be examined. The overall objective is to develop intuitive, reliable and reproducible CSA-based clinical measures by correlating them with established neuropsychiatric and imaging markers, determining their efficacy in clinical populations, and determining how they change over time. As a result, this research will validate specific speech traits as useful diagnostic markers of neurocognitive disease and explain why those markers differ between patient groups, both of which are major steps towards the design of novel and easily implemented tools in the screening of NCDs such as Alzheimer's disease. PROJECT NARRATIVE Computational speech analysis (CSA) has shown promise as a cost-effective, rapid screening for patients with neurocognitive disorders (NCDs) by objectively and automatically quantifying speech and language use; however, critical steps must be taken before these measures can become clinically useful. I have training and experience in the neurology of speech and language, but require additional training in computational linguistics and paralinguistics, longitudinal markers of disease including neuroimaging and neuropsychological measures, and design of novel technology for dissemination in order to bring CSA into clinical practice. In this project, we propose to investigate the utility of using CSA measures in two distinct patient groups, including a highly characterized group of research participants that includes healthy controls, Alzheimer's disease patients, and mild cognitive impairment patients (Group A), and a group of consented clinic patients with different NCDs (Group B) and to follow these two groups in prospective, longitudinal studies to correlate spontaneous speech measures with standardized linguistic, neuropsychological, and biological measures.",Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders,9975566,K23AG063900,"['Accent', 'Address', 'Adult', 'Advisory Committees', 'Algorithms', 'Alzheimer disease screening', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Alzheimer&apos', 's disease pathology', 'Alzheimer&apos', 's disease patient', 'Area', 'Biological', 'Brain', 'Caregivers', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Communities', 'Computational Linguistics', 'Computers', 'Consent', 'Cross-Sectional Studies', 'Dementia', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Disease', 'Disease Marker', 'Early Diagnosis', 'Effectiveness', 'Enrollment', 'Ensure', 'Ethics', 'Evaluation', 'Fostering', 'Frontotemporal Dementia', 'Goals', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Intuition', 'Investigation', 'Knowledge', 'Language', 'Language Tests', 'Lead', 'Lewy Body Dementia', 'Linguistics', 'Liquid substance', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Mentorship', 'Neurocognitive', 'Neurology', 'Neuropsychological Tests', 'Neuropsychology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Population', 'Positioning Attribute', 'Preparation', 'Prevalence', 'Primary Health Care', 'Quality of life', 'Reproducibility', 'Research', 'Screening procedure', 'Speech', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'accurate diagnosis', 'aging population', 'base', 'care providers', 'career development', 'clinical application', 'clinical practice', 'cohort', 'cost effective', 'design', 'diagnostic biomarker', 'experience', 'healthy aging', 'imaging biomarker', 'improved', 'machine learning algorithm', 'mild cognitive impairment', 'morphometry', 'neurocognitive disorder', 'neuroimaging', 'neuropsychiatry', 'new technology', 'novel', 'novel diagnostics', 'novel therapeutics', 'patient screening', 'primary outcome', 'prospective', 'recruit', 'screening', 'skills', 'success', 'technology development', 'tool', 'trait']",NIA,UNIVERSITY OF COLORADO DENVER,K23,2020,188384,0.022655058449861255
"Computerized assessment of linguistic indicators of lucidity in Alzheimer's Disease dementia The focus of the proposed project is to enable automated detection and analysis of episodes of unexpected lucidity in individuals with late-stage dementia in which the individual long thought to have succumbed to dementia and lost most of his or her cognitive abilities temporarily regains the ability to communicate in a clear and coherent fashion. Currently, the evidence for the existence of these episodes is mostly anecdotal, stemming from reports by caregivers and healthcare professionals. According to these reports, clear speech and language are the most prominent features of episodes of cognitive lucidity. The very low frequency and unexpected nature of these episodes make it challenging to capture objective evidence in the form of audio or video recordings of these events needed to enable systematic and comprehensive investigations. Thus, it is necessary to develop technological solutions for automated linguistic analysis that can be used for long-term continuous monitoring of individuals in late stages of dementia. In this feasibility project, we will develop technology to address two challenging issues: a) accurate conversion of continuous speech to text, and b) automated analysis of the text to measure the degree of coherence. Without robust solutions for these problems, our ability to detect and fully capture and analyze coherent speech in a long-term monitoring setting will remain limited. We will address these problems by developing and testing a robust automatic speech recognition solution based on deep learning technology that can operate autonomously (without sending data to external servers). We will also adapt existing and develop new measures of semantic coherence that are able to work on imperfect transcripts resulting from automatic speech recognition. In order to develop and validate these tools and approaches, we will use existing datasets of spontaneous conversational speech by persons with mild and moderate dementia as well as healthy controls available as part of the Carolina Conversations Collection and Dementia Bank. This project seeks to develop a validated tool approach to automatically monitoring people with advanced dementia who are thought to have lost their cognitive abilities for potential episodes in which they unexpectedly and temporarily regain their ability to communicate coherently. We propose to develop and evaluate a system to record the speech produced in advanced dementia, convert it to text and measure the degree of coherence of the language produced with the intention to identify atypically lucid episodes.",Computerized assessment of linguistic indicators of lucidity in Alzheimer's Disease dementia,10093304,R21AG069792,"['Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Auditory Hallucination', 'Brain', 'Caregivers', 'Characteristics', 'Cognitive', 'Collection', 'Communication', 'Computational Linguistics', 'Confusion', 'Data', 'Data Set', 'Dementia', 'Detection', 'Etiology', 'Event', 'Feasibility Studies', 'Frequencies', 'Goals', 'Health Professional', 'Health care facility', 'Human', 'Individual', 'Intention', 'Investigation', 'Language', 'Linguistics', 'Manuals', 'Measures', 'Methods', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurons', 'Observational Study', 'Output', 'Patient Monitoring', 'Patients', 'Persons', 'Production', 'Reporting', 'Research', 'Sampling', 'Semantics', 'Speech', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic Intervention', 'Transcript', 'Video Recording', 'Work', 'advanced dementia', 'automated analysis', 'automated speech recognition', 'base', 'clear speech', 'cognitive ability', 'computerized', 'deep learning', 'evidence base', 'experience', 'long term memory', 'prospective', 'relating to nervous system', 'stem', 'tool']",NIA,UNIVERSITY OF MINNESOTA,R21,2020,442641,0.06164215402401643
"NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION ﻿    DESCRIPTION (provided by applicant) Speech perception is one of the most important cognitive operations performed by the human brain and is fundamentally multisensory: when conversing with someone, we use both visual information from their face and auditory information from their voice. Multisensory speech perception is especially important when the auditory component of the speech is noisy, either due to a hearing disorder or normal aging. However, much less is known about the neural computations underlying visual speech perception than about those underlying auditory speech perception. To remedy this gap in existing knowledge, we will use converging evidence from two complementary measures of brain activity, BOLD fMRI and electrocorticography (ECoG). The results of these neural recording studies will be interpreted in the context of a flexible computational model based on the emerging tenet that the brain performs multisensory integration using optimal or Bayesian inference, combining the currently available sensory information with prior experience.  In the first Aim, a Bayesian model will be constructed to explain individual differences in multisensory speech perception along three axes: subjects' ability to understand noisy audiovisual speech; subjects' susceptibility to the McGurk effect, a multisensory illusion; and the time spent fixating the mouth of a talking face.  In the second Aim, we will explore the neural encoding of visual speech using voxel-wise forward encoding models of the BOLD fMRI signal. We will develop encoding models to test 7 different theories of visual speech representation from the linguistic and computer vision literature. In the third Aim, we will use ECoG to examine the neural computations for integrating visual and auditory speech, guided by the Bayesian models developed in Aim 1. First, we will study reduced neural variability for multisensory speech predicted by our model. Second, we will study the representational space of unisensory and multisensory speech. PUBLIC HEALTH RELEVANCE: Understanding speech is one of the most important functions of the human brain. We use information from both the auditory modality (the voice of the person we are talking to) and the visual modality (the facial movements of the person we are talking to) to understand speech. We will use computational models, eye tracking, and brain imaging and recording techniques to study the organization and operation of the brain during audiovisual speech perception.",NEURAL SUBSTRATES OF OPTIMAL MULTISENSORY INTEGRATION,9867756,R01NS065395,"['Auditory', 'Auditory Perception', 'Bayesian Analysis', 'Bayesian Modeling', 'Behavioral', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Models', 'Computer Vision Systems', 'Data', 'Electrocorticogram', 'Eye Movements', 'Face', 'Functional Magnetic Resonance Imaging', 'Hearing problem', 'Human', 'Illusions', 'Individual', 'Individual Differences', 'Investigation', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Link', 'Literature', 'Measures', 'Mediating', 'Modality', 'Modeling', 'Movement', 'Neurons', 'Noise', 'Oral cavity', 'Perception', 'Persons', 'Population', 'Predisposition', 'Property', 'Publishing', 'Sample Size', 'Sensory', 'Signal Transduction', 'Speech', 'Speech Perception', 'Stimulus', 'Structure of superior temporal sulcus', 'Techniques', 'Testing', 'Time', 'Visual', 'Vocabulary', 'Voice', 'audiovisual speech', 'base', 'behavior measurement', 'experience', 'flexibility', 'hearing impairment', 'multisensory', 'neural model', 'normal aging', 'operation', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'sample fixation', 'speech accuracy', 'theories', 'visual information', 'visual speech', 'visual tracking']",NINDS,BAYLOR COLLEGE OF MEDICINE,R01,2020,346719,0.1138101228734051
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,9901502,K01DC017751,"['Acoustics', 'Address', 'Age', 'Area', 'Auditory', 'Behavior', 'Biomechanics', 'Categories', 'Characteristics', 'Clinical', 'Communication', 'Coupling', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dysphonia', 'Endoscopes', 'Evaluation', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Knowledge', 'Larynx', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mining', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paralysed', 'Patients', 'Physics', 'Physiological', 'Prevention', 'Production', 'Protocols documentation', 'Research', 'Series', 'Severities', 'Source', 'Spastic Dysphonias', 'Speech', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tremor', 'Visual', 'Voice', 'Voice Disorders', 'Voice Disturbances', 'Voice Quality', 'base', 'clinical application', 'clinical development', 'clinical practice', 'clinically relevant', 'cohort', 'flexibility', 'image processing', 'imaging approach', 'improved', 'innovation', 'kinematics', 'sex', 'temporal measurement', 'time use', 'tool', 'treatment strategy', 'vibration', 'vocal cord', 'vocalization']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2020,137795,0.10675608348367202
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9997876,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,283332,-0.00952922417876545
"Using Speech Acoustics to Reveal Motor Disruptions in Psychosis Project summary The goal of this project is to investigate the feasibility of using speech acoustics as a clinical biomarker in individuals at clinical high risk (CHR) for developing psychosis. There is evidence that disruptions to cortico-cerebellar circuits in individuals experiencing attenuated psychosis symptoms impact motor control of the face and limbs. This proposal would be the first study to examine whether these motor disruptions in high-risk populations also affect the complex motor control required for speech. In Aim 1 an instrumental approach will be used to investigate the acoustic correlates of psychosis risk. Specifically, speech data will be collected to investigate fine-grained acoustic properties of vowels and consonants in simple repetition tasks as well as during more naturalistic conversational speech. The speech of CHR young adults will be compared to age-matched healthy controls to discover if there are group differences in the speech acoustics that allow us to classify speech samples into healthy and clinical groups. To enable fast, reliable analysis, machine learning-based algorithms will be used to measure the acoustics speech properties of interest. In Aim 2, the speech properties measured in Aim 1 will be compared to other behavioral measures, in order to discover if they correlate with several measures of cerebellar dysfunction (posture control, procedural learning, and motor timing) that are known to occur in CHR individuals. These measures will provide convergent validity for these novel speech measures. Cognitive capabilities which are related and unrelated to speech and motor control will also be assessed, to provide specificity and divergent validity to these measures. In Aim 3, the links between speech features and changes in symptom severity will be assessed at two time points, connecting changes in speech motor control to longitudinal changes in the progression of the symptoms over 12 months. These investigations may reveal speech as a novel and easily-collected biomarker enabling early detection of psychosis risk. Project narrative The goal of this proposal is to determine whether speech patterns can signal vulnerability to psychotic disorders such as schizophrenia. Speech samples will be collected from high-risk and matched healthy control participants in order to: determine if there are abnormalities in the acoustics of vowels and consonants; evaluate if these properties map on to dysfunction of the cerebellum (a brain region impacted in the development of psychosis that also plays a role in speech motor control); and relate these properties to symptom severity and illness progression. This study will lay the groundwork for the use of speech as an inexpensive, non-invasive, and mechanistically-relevant metric that will ultimately support earlier identification and facilitate timely treatment.",Using Speech Acoustics to Reveal Motor Disruptions in Psychosis,9898478,R21MH119677,"['Acoustics', 'Address', 'Affect', 'Age', 'Algorithms', 'Articulators', 'Attenuated', 'Behavioral', 'Biological Markers', 'Brain region', 'Cerebellar Diseases', 'Cerebellum', 'Clinical', 'Cognitive', 'Complex', 'Computers', 'Control Groups', 'Cueing for speech', 'Data', 'Development', 'Diagnosis', 'Dyskinetic syndrome', 'Early Diagnosis', 'Early Intervention', 'Early identification', 'Ensure', 'Equilibrium', 'Etiology', 'Face', 'Fingers', 'Functional disorder', 'Goals', 'Grain', 'Individual', 'Intervention', 'Interview', 'Investigation', 'Larynx', 'Learning', 'Limb structure', 'Linguistics', 'Link', 'Lip structure', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Motor', 'Movement', 'Musculoskeletal Equilibrium', 'National Institute of Mental Health', 'Neurologic', 'Participant', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Posture', 'Process', 'Production', 'Property', 'Psychotic Disorders', 'Research', 'Research Personnel', 'Risk', 'Role', 'Roter', 'Sampling', 'Schizophrenia', 'Scientist', 'Sensory', 'Severities', 'Severity of illness', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Sound', 'Structure', 'Symptoms', 'System', 'Testing', 'Time', 'Tongue', 'Variant', 'Youth', 'automated algorithm', 'base', 'behavior measurement', 'clinical biomarkers', 'clinical predictors', 'experience', 'high risk', 'high risk population', 'improved', 'indexing', 'individualized medicine', 'interest', 'motor behavior', 'motor control', 'motor deficit', 'motor disorder', 'motor learning', 'novel', 'novel marker', 'potential biomarker', 'relating to nervous system', 'sensory integration', 'tool', 'vocal control', 'young adult']",NIMH,NORTHWESTERN UNIVERSITY,R21,2020,185000,0.14054191523292586
"Decoding the neural time-course of spoken word recognition Project Summary  Word recognition is crucial not only for comprehending spoken language but for mapping spoken words onto text in reading. Individuals with language and reading deficits (e.g., Specific Language Impairment, Dyslexia, Autism, which together affect up to 16% of children) have been shown to have deficits in word recognition, making it crucial to understand this process. A hallmark of word recognition is that listeners activate neural representations of multiple candidate words that are consistent with the early acoustic input, and these candidates compete for recognition as they unfold in real-time.  The overall goal of this proposal is to capitalize on recent developments in multivariate and machine- learning techniques for analyzing signals obtained from the human brain to measure the real-time unfolding of spoken word recognition. Although these techniques have been most widely used with fMRI data, we propose to extend them to EEG data because EEG is easily used with children and clinical populations, and provides access to the time-course of word recognition, thereby revealing underlying cognitive mechanisms of word recognition, such as lexical competition. Our preliminary findings using this EEG-based paradigm have demonstrated that we can decode the recognition of a specific word (among a set of 8-12 alternatives) at each msec time-step after stimulus onset. The method is sensitive to partial activation of competing words that share some phonological features with the target word, thereby revealing the dynamics of lexical competition as the word-recognition system settles on the final target.  Our objectives are to conduct a series of small-scale experiments that achieve three aims. First, we develop and optimize the method with adults (e.g., the experimental procedure and computational implementation). Second, we validate the method with adults by measuring its test/re-test reliability, comparing its estimates of word recognition with traditional behavioral paradigms, and examining how lexical status, and semantic and orthographic expectations shape lexical competition revealed by the EEG measure. This will yield a new, non-invasive, and highly reliable method suitable for assessing spoken word recognition in adults, children, and special populations. Third, we will preliminarily extend the method to children to pave the way for future developmental studies. Taken together, accomplishing these three aims would provide an innovative and powerful tool for assessing a crucial component of language processing in a wide variety of typical and atypical populations. Project Narrative The proposed research will impact public health by establishing a new EEG-based paradigm for understanding how listeners recognize spoken words. Word recognition is crucial not only for comprehending spoken language but for mapping spoken words onto text in reading. Individuals with language and reading deficits (e.g., Specific Language Impairment, Dyslexia, Autism, which together affect up to 16% of children) have been shown to have deficits in word recognition, making it crucial to understand this process. A hallmark of word recognition is that listeners activate neural representations of multiple candidate words that are consistent with the early acoustic input, and these candidates compete for recognition as they unfold in real-time. Our project will develop and optimize a new method in which machine learning tools are used to decode EEG-based neural signals to characterize the time-course of competition. Such a method offers the prospect of a diagnostic tool to identify young children who are at risk for communication disorders.",Decoding the neural time-course of spoken word recognition,9831086,R21DC017596,"['Acoustics', 'Address', 'Adolescence', 'Adult', 'Affect', 'Behavioral', 'Behavioral Paradigm', 'Brain', 'Candy', 'Child', 'Childhood', 'Clinical', 'Cochlear Implants', 'Cognitive', 'Communication impairment', 'Complement', 'Data', 'Development', 'Diagnostic', 'Dyslexia', 'Electrocorticogram', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hearing', 'Human', 'Impairment', 'Implanted Electrodes', 'Individual', 'Instruction', 'Language', 'Language Development Disorders', 'Language Disorders', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Orthography', 'Participant', 'Patients', 'Pilot Projects', 'Population', 'Procedures', 'Process', 'Public Health', 'Reading', 'Research', 'Risk', 'Semantics', 'Series', 'Shapes', 'Signal Transduction', 'Standardization', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Visual', 'Visual attention', 'attentional control', 'autism spectrum disorder', 'base', 'behavior measurement', 'behavioral response', 'expectation', 'experimental study', 'indexing', 'innovation', 'insight', 'language processing', 'lexical', 'lexical processing', 'millisecond', 'named group', 'neurotransmission', 'oculomotor', 'phonology', 'reading difficulties', 'relating to nervous system', 'response', 'specific language impairment', 'temporal measurement', 'tool']",NIDCD,"HASKINS LABORATORIES, INC.",R21,2020,152547,0.024727355218278145
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9944489,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2020,39939,0.08553563436112609
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,9875268,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach', 'visual tracking']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2020,585545,0.11643780738843257
"Dynamics of Vocal Tract Shaping ﻿    DESCRIPTION (provided by applicant): The long-term goal of this project is to wed state-of-the-art technology for imaging the vocal tract with a linguistically informed analysis of dynamic vocal tract constriction actions in order to understand the control and production of the compositional units of spoken language. We have pioneered the use of real time MRI for speech imaging to illuminate articulatory dynamics and to understand how these emerge lawfully from the combined effects of vocal tract constriction events distributed over space (subparts of the tract) and over time. This project has developed and refined a novel real time MRI acquisition ability, making possible current reconstruction rates of up to 96 frames per second, quadrupling current imaging speeds. Data show clear real- time movements of the lips, tongue, velum and epiglottis, providing exquisite information about the spatiotemporal properties of speech gestures in both the oral and pharyngeal portions of the vocal tract. The project has also developed novel noise-mitigated image-synchronized strategies to record speech in-situ during imaging, as well as image processing strategies for deriving linguistically meaningful measures from the data, demon- strating the utility of this approach for linguistic studies of speech communication in a variety of languages. Using our direct access to dynamic information on vocal tract shaping, we investigate vocal tract shaping in three-dimensions as the composition of spatiotemporally coordinated vocal tract action units. This project's specific aims go beyond the dynamic shaping of individual vowels and consonants-postures over time-to examine more complex structuring of articulation-namely, the local and global influences governing linguistic control, temporal coherence and multi-unit coordination. The advances in our technical approach enable a series of studies that leverage: (i) unprecedented high-speech imaging with dynamic rtMRI to consider the prosodic modulation of temporally rapid and temporally coherent speech units; (ii) innovative multi-plane 3D imaging capability to inform the computational identification of linguistic control regimes; and (iii) a large- scale rtMRI corpus ad concomitant machine learning advances to move toward a principled account of system-level co-variability in space and time, both within and among individuals. This symbiotic theory-driven and data-driven research strategy will yield significant innovations in understanding spoken communication. It is no exaggeration to say that the advent of real-time MRI for speech has initiated a dramatic scientific change in the nature of speech production research by allowing for models of production driven by rich quantitative articulatory data. The project is having broad impact through the free dissemination of the unique rtMRI data corpora, tools and models-already used worldwide for research and teaching-and societal out- reach through its website and lay media coverage. Understanding articulatory compositional structure and cross-linguistic potentialities also has critical translational significance impacting the assessment and remediation of speech disorders, as our collaborative work on glossectomy and apraxia has begun to demonstrate. PUBLIC HEALTH RELEVANCE: Real-time imaging of the moving vocal tract with MRI has made direct movies of speech production possible, allowing an investigation of the articulatory composition of speech in healthy adults and illuminating the articulatory dissolution and lack of coherence often found in spoken language disorders. This technology platform, coupled with a linguistically driven theoretical framework that understands speech as composed of articulatory units, provides a scientific foothold for evidence-driven assessment and remediation of speech breakdown in clinical populations, including articulatory remediation and training and deploying assistive technologies for the impaired (automatic speech recognition, machine speech synthesis), and has potential broad impact on the clinical needs of those with swallowing disorders, sleep apnea, or facing recovery of speech function after stroke or surgery. Further, because speech presents the only example of rapid, cognitively- controlled, internal movements of the body, the unique challenges of speech production imaging offer the wider biomedical imaging community traction for advances that improve temporal and spatial image resolution-advances with potential import for cardiac and other imaging.",Dynamics of Vocal Tract Shaping,9829092,R01DC007124,"['3-Dimensional', 'Acoustics', 'Adult', 'Air Movements', 'Apraxias', 'Articulation', 'Articulators', 'Beds', 'Cardiac', 'Clinical', 'Cognitive', 'Communication', 'Communities', 'Complex', 'Coupled', 'Data', 'Deglutition Disorders', 'Development', 'Educational process of instructing', 'Engineering', 'Epiglottis structure', 'Event', 'German population', 'Gestures', 'Glossectomy', 'Goals', 'Human', 'Image', 'Imaging technology', 'Impairment', 'In Situ', 'Individual', 'International', 'Investigation', 'Knowledge', 'Language', 'Language Disorders', 'Larynx', 'Lateral', 'Linguistics', 'Lip structure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Motion', 'Movement', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Oropharyngeal', 'Pattern', 'Pharyngeal structure', 'Play', 'Population', 'Posture', 'Production', 'Property', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Self-Help Devices', 'Series', 'Shapes', 'Sleep Apnea Syndromes', 'Speech', 'Speech Disorders', 'Speed', 'Structure', 'Surgical Flaps', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tongue', 'Traction', 'Training', 'Variant', 'Work', 'automated speech recognition', 'base', 'bioimaging', 'cohesion', 'computerized tools', 'constriction', 'data tools', 'dexterity', 'high dimensionality', 'image processing', 'imaging capabilities', 'improved', 'innovation', 'instrument', 'movie', 'novel', 'outreach', 'phonology', 'post stroke', 'program dissemination', 'public health relevance', 'real-time images', 'reconstruction', 'remediation', 'shape analysis', 'sound', 'spatiotemporal', 'speech synthesis', 'technological innovation', 'theories', 'tongue apex', 'tool', 'web site']",NIDCD,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,467515,0.12743950754434213
"Administrative Supplement to The When to Worry about Language Study (W2W-L) PROJECT SUMMARY – Original Submission Primary language impairment (PLI) begins early in life and affects 6-8% of children. Although language intervention is maximally effective the earlier it is delivered, normative variation in language acquisition across toddlerhood (here 24-36 months) impedes accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model to identify PLI as early as possible. Our developmentally- sensitive, translational approach introduces multiple innovations including: (1) characterizing the developmental patterning of toddler emergent language beginning at 24 mos. using state-of-the-art methods, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language into PLI risk assessment; (3) using a novel paradigm to assess the protective effects of both behavioral and neural synchronization within parent-child language transactions; and (4) consideration of irritability, a robust developmental marker of early mental health risk, to enhance identification of those language delayed toddlers at highest risk for persistence. For the proposed When to Worry about Language Study (W2W-L), we capitalize on our funded study of 350 infants (50% irritable and 50% non-irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24-month-olds. Our key predictors will be toddler emergent language patterns (24-36 months), their neural biomarkers and synchrony within the transactional language environment. Our central outcome is primary language impairment (PLI) status at preschool age (54 mos., when PLI can be reliably evaluated), assessed via clinical gold standard expressive and receptive language abilities. SPECIFIC AIMS: AIM 1a. Evaluate accuracy of PLI prediction based on multi-component measures of language including intensive longitudinal assessments of toddler developmental precursors of key language functions at older ages, neural biomarkers. We will assess neural and linguistic processing via quantitative EEG during parent-child interaction and ERPs to speech sounds as well as during eye tracking tasks and 1b. Evaluate feasibility of creating an algorithm for early identification of PLI that can be applied in clinical practice, using cross-validation and machine learning. AIM 2: Test the hypothesis that parent-child dyadic synchrony buffers PLI risk For the first time, we combine behavioral and novel social EEG measures of parent-child synchrony during natural interaction and a custom-designed word learning task to directly test how observed (behavioral) and neural (EEG) dyadic synchrony impact word learning. AIM 3: Test whether consideration of toddler irritability enhances PLI prediction. In sum, PLI confers sustained negative effects on a variety of personal-social and academic outcomes. Pinpointing children at highest risk for PLI is critical for reducing the public health burden of PLI for children, families, and the systems supporting them, and enhancing targeted allocation of resources. PROJECT NARRATIVE Primary language impairment emerges early and is responsive to intervention; however, many toddlers with early language delays recover naturally, and others who appear to be developing typically show signs of impairment by preschool age. We use a novel, theoretically-grounded, multi-level neurodevelopmental approach to characterize emergent language patterns from 24- 36 mos. along with the influence of neural and linguistic processing and transactional processes within the child's broader language environment. We also test whether PLI prediction is enhanced via consideration of irritability, a robust predictor of early mental health risk. Drawing on findings from our predictive models, we will also examine feasibility of developing a clinical algorithm from this scientifically-validated toolkit. Generating reliable methods for accurate identification of young children at highest risk for language impairment lays the foundation for optimizing early intervention and preventing developmentally-cascading effects on academic and adaptive functioning.",Administrative Supplement to The When to Worry about Language Study (W2W-L),10162280,R01DC016273,"['Address', 'Administrative Supplement', 'Adverse effects', 'Affect', 'African American', 'Age', 'Algorithms', 'Behavioral', 'Biological Markers', 'Buffers', 'COVID-19', 'COVID-19 pandemic', 'Caregivers', 'Child', 'Child Language', 'Child Rearing', 'Clinical', 'Communities', 'Custom', 'Data', 'Data Collection', 'Development', 'Early Intervention', 'Early identification', 'Electroencephalography', 'Environment', 'Family', 'Family member', 'Foundations', 'Funding', 'Goals', 'Gold', 'Hispanics', 'Home environment', 'Human Subject Research', 'Illinois', 'Impairment', 'Individual', 'Infant', 'Institutes', 'Interruption', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Linguistics', 'Machine Learning', 'Measures', 'Mediating', 'Mental Health', 'Methods', 'Modeling', 'Nursery Schools', 'Outcome', 'Parent-Child Relations', 'Parents', 'Participant', 'Pattern', 'Pediatric Hospitals', 'Personal Satisfaction', 'Persons', 'Process', 'Protocols documentation', 'Public Health', 'Race', 'Research Activity', 'Resource Allocation', 'Risk', 'Risk Assessment', 'Sampling', 'Siblings', 'Speech Sound', 'Stress', 'Sum', 'Support System', 'Surveys', 'Testing', 'Time', 'Toddler', 'Transact', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visit', 'base', 'clinical practice', 'cohort', 'coronavirus disease', 'design', 'experience', 'high risk', 'innovation', 'language impairment', 'negative affect', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'protective effect', 'recruit', 'relating to nervous system', 'sex', 'social', 'standard measure', 'stress reduction', 'translational approach', 'tv watching', 'visual tracking', 'word learning']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2020,197084,0.10243508524558473
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speaker’s voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patient’s voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patient’s voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,9994877,R01DC016621,"['Acoustics', 'Age', 'Alaryngeal Speech', 'Algorithms', 'Articular Range of Motion', 'Articulation', 'Articulators', 'Characteristics', 'Communication', 'Data', 'Data Collection', 'Development', 'Devices', 'Electrolarynx', 'Electromagnetics', 'Enhancement Technology', 'Esophageal Speech', 'Excision', 'Gender', 'Goals', 'Gold', 'Health', 'Hoarseness', 'Human', 'Impairment', 'Individual', 'Knowledge', 'Laryngeal Prosthesis', 'Laryngectomee', 'Laryngectomy', 'Larynx', 'Life', 'Lip structure', 'Machine Learning', 'Magnetism', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Mechanics', 'Mental Depression', 'Motion', 'Motor', 'Movement', 'Output', 'Participant', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Production', 'Quality of life', 'Research', 'Robotics', 'Science', 'Self-Help Devices', 'Speech', 'Speech Disorders', 'Speech Sound', 'Speech Synthesizers', 'Speech Therapy', 'Speed', 'Technology', 'Testing', 'Time', 'Tongue', 'Tracer', 'Tracheoesophageal Speech', 'United States', 'Voice', 'Voice Disorders', 'Voice Quality', 'Wireless Technology', 'alternative communication', 'auditory feedback', 'base', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'language training', 'machine learning algorithm', 'millisecond', 'new technology', 'novel', 'oral communication', 'preservation', 'prototype', 'social', 'social exclusion', 'sound', 'speech synthesis', 'tool', 'vibration', 'visual feedback', 'vocal cord', 'wearable device']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2020,580870,0.16583969782942634
"Speech markers of cognitive impairment in Parkinson's disease ABSTRACT Dr. Kara Smith is a Movement Disorders neurologist at the University of Massachusetts Medical School (UMMS) whose goal is to become an independent investigator focused on early cognitive impairment in Parkinson disease (PD). Her long-term goal is to develop speech markers of cognitive impairment in PD. Cognitive impairment occurs in the majority of PD patients, leading to increased mortality and decreased quality of life. The current diagnostic tools are resource-intensive and have limited sensitivity. Treatments are often offered late in the course of cognitive decline and do not provide optimal benefit. Speech markers could improve detection, monitoring and treatment of cognitive impairment in PD. Speech markers could be monitored frequently and remotely via mobile technology, capturing sensitive, quantitative data about cognitive function in the context of patients’ daily life and in response to therapeutics. Dr. Smith’s role as a clinical movement disorders specialist ideally positions her to lead the application of advanced speech and language research to feasible, patient-oriented tools for real-life clinical practice and clinical trials. Dr. Smith has assembled an expert interdisciplinary mentorship team ideally suited for the goals of this innovative proposal. Dr. Smith and her team have previously shown that a) speech acoustic markers are associated with cognitive function in non-demented PD patients, and b) PD patients with mild cognitive impairment had linguistic deficits including pauses within utterances and grammaticality. Building on these results, Dr. Smith proposes to study speech and language more comprehensively in PD patients with and without mild cognitive impairment and controls to confirm these preliminary results and identify additional biomarkers. The aims of this study will be 1) to develop algorithms using speech acoustic markers to categorize by cognitive status, 2) to identify linguistic markers associated with mild cognitive impairment in PD, and 3) to assess on-line syntactic processing in PD subjects with mild cognitive impairment. The overall goal of the proposal is to identify speech and language markers of early cognitive dysfunction that can be further refined, validated and implemented using mobile technology into a larger scale, longitudinal R01 proposal. Further work will also address the underlying neurobiological mechanisms of these speech markers. Dr. Smith’s rigorous training plan includes a Master’s degree, linguistics and speech motor physiology courses, and experience in signal processing and speech acoustic analysis. Through her training goals, she will advance her knowledge and skills in patient-centered outcomes measures and instrument validation. She will gain experience in research leadership, presentation and dissemination of scientific work, and in grant writing, culminating in an R01 proposal. This K23 award will be critical for Dr. Smith to establish an independent career as a PD clinician-scientist at the unique intersection of speech and language science and cognitive impairment. PUBLIC HEALTH RELEVANCE: Speech markers have the potential to improve diagnosis, monitoring and treatment of cognitive impairment in Parkinson’s disease (PD). Although the majority of PD patients will develop cognitive impairment, the tools available to assess and treat this disabling complication are fraught with limitations. As a detailed and quantitative assessment tool, speech markers may increase sensitivity to early cognitive dysfunction and to changes over time compared with current measures. They may be automated and then implemented through mobile technology to increase patients’ access to cognitive symptom monitoring outside of the clinic setting. Dr. Smith’s proposed career development plan has potential to fill a major gap in PD research by making inexpensive and easy-to-use cognitive assessment tools accessible to patients in rural and international settings, and by fueling clinical trials to discover new therapeutics capable of slowing cognitive decline in PD.",Speech markers of cognitive impairment in Parkinson's disease,9883772,K23DC016656,"['Acoustics', 'Address', 'Algorithms', 'American', 'Area', 'Articulation', 'Assessment tool', 'Award', 'Biological Markers', 'Biomedical Engineering', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Cognitive Therapy', 'Cognitive deficits', 'Complication', 'Comprehension', 'Data', 'Data Analyses', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Foundations', 'Future', 'Goals', 'Grant', 'Health Services Accessibility', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Knowledge', 'Language', 'Language Disorders', 'Lead', 'Leadership', 'Life', 'Linguistics', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Massachusetts', 'Master&apos', 's Degree', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurobiology', 'Neurologist', 'Neuropsychological Tests', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Participant', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiology', 'Population', 'Positioning Attribute', 'Production', 'Proxy', 'Quality of Care', 'Quality of life', 'Research', 'Research Personnel', 'Resources', 'Role', 'Rural', 'Science', 'Scientist', 'Severities', 'Specialist', 'Speech', 'Speech Acoustics', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'Writing', 'career', 'career development', 'clinical movement disorder', 'clinical practice', 'cognitive change', 'cognitive control', 'cognitive function', 'cognitive impairment in Parkinson&apos', 's', 'cognitive performance', 'cognitive testing', 'common symptom', 'experience', 'handheld mobile device', 'improved', 'innovation', 'instrument', 'language processing', 'large scale data', 'lexical retrieval', 'machine learning method', 'medical schools', 'mild cognitive impairment', 'mobile computing', 'mortality', 'motor deficit', 'neurobiological mechanism', 'non-demented', 'novel', 'novel therapeutics', 'patient oriented', 'public health relevance', 'recruit', 'response', 'screening', 'signal processing', 'skills', 'syntax', 'tool']",NIDCD,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K23,2020,189216,0.07668408995069675
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,9850868,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Models', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'machine learning algorithm', 'nervous system disorder', 'novel', 'optimal treatments', 'outcome prediction', 'phrases', 'predictive modeling', 'recruit', 'signal processing', 'speech in noise', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,307097,0.15344620913912912
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9913498,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'longitudinal design', 'machine learning method', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2020,592142,0.06427712866281743
