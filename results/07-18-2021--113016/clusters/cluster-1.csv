text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9713512,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2019,647706,-0.008929847667400853
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9767751,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Facebook', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2019,204981,0.008280483434358322
"ADNI Psychometrics: Machine Learning to discern Natural History Aim 2 Supplement Project Summary/Abstract This supplement is to a funded R01 called ADNI Psychometrics. This Supplement builds on the Second Specific Aim of the funded parent grant. That Aim focused on characterizing brain structure and functioning for people with different cognitively- defined subgroups of Alzheimer's disease. The Supplement adds one technique for analyzing the longitudinal structural data we are already analyzing. The new technique for structural data is machine learning. We have the opportunity to collaborate with a talented faculty member in Biomedical Informatics who has specific expertise in machine learning approaches to anatomical data (J Gennari). Dr. Genarri will supervise machine learning approaches to complement the various analytical approaches we already have underway for the longitudinal structural imaging data of Aim 2. Longitudinal imaging data are particularly significant, as any differences we find in the evolution of brain structure over time across subgroups supports the notion that the subgroups have distinct natural histories, which in turn goes a long way towards the provocative conclusion that these subgroups of “Alzheimer's disease” represent distinct conditions. Machine learning approaches to these data were not envisioned in the initial proposal, but represent a particularly valuable complementary approach that may identify similarities and differences in trajectories of the evolution of brain structure that would not be apparent using the more traditional analytic pipelines we outlined in the proposal. This then is the perfect fit for an Administrative Supplement – this is an opportunity to enhance the value of the parent study by adding new expertise to investigate in a complementary and valuable fashion a question that was already addressed by the parent grant. This Supplement builds on the same infrastructure and questions asked in Aim 2, but augments our analytical armamentarium with novel machine learning approaches. Project Narrative This Supplement proposal builds on the second aim of R01 AG 029672,  'ADNI Psychometrics (P Crane, PI) , which is to use ADNI's rich neuroimaging data to compare metabolism and brain structure correlates of cognitively defined Alzheimer's disease subgroups. This proposal would add machine learning approaches for the longitudinal structural imaging data to the analytic strategies already being pursued by the investigators. This Supplement Proposal would substantially augment the scientific value of the overall study.",ADNI Psychometrics: Machine Learning to discern Natural History Aim 2 Supplement,9933184,R01AG029672,"['Address', 'Administrative Supplement', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Attention', 'Brain', 'Clinical', 'Cognitive', 'Complement', 'Cross-Sectional Studies', 'Data', 'Development', 'Diagnosis', 'Disease', 'Enrollment', 'Evolution', 'Faculty', 'Funding', 'Guidelines', 'Image', 'Infrastructure', 'International', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Memory', 'Metabolism', 'Modeling', 'Natural History', 'Parents', 'Psychometrics', 'Published Comment', 'Research Personnel', 'Structure', 'Subgroup', 'Talents', 'Techniques', 'Testing', 'Text', 'Therapeutic', 'Time', 'Visuospatial', 'Work', 'biomedical informatics', 'cerebral atrophy', 'clinical Diagnosis', 'clinical heterogeneity', 'disorder subtype', 'executive function', 'graduate student', 'improved', 'longitudinal analysis', 'member', 'neuroimaging', 'novel', 'parent grant', 'response', 'serial imaging', 'supervised learning']",NIA,UNIVERSITY OF WASHINGTON,R01,2019,281279,-0.04170437830861329
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9803774,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2019,631809,-0.0038029410182492244
"Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data Project Summary The immunology database and analysis portal (ImmPort, http://immport.niaid.nih.gov) is the NIAID-funded public resource for data archive and dissemination from clinical trials and mechanistic research projects. Among the current 291 studies archived in ImmPort, 114 are focused on vaccine responses (91 for influenza vaccine responses), which is the largest category when organized by research focus. As the most effective method of preventing infectious diseases, development of the next-generation vaccines is faced with the bottleneck that traditional empirical design becomes ineffective to stimulate human protective immunity against HIV, RSV, CMV, and other recent major public health threats. This project will focus on three important aspects of informatics approaches to secondary analysis of ImmPort data for influenza vaccination research: a) expanding the data analytical capabilities of ImmPort and ImmPortGalaxy through adding innovative computational methods for user-friendly unsupervised identification of cell populations, b) processing and analyzing a subset of the existing human influenza vaccination study data in ImmPort to identify cell-based biomarkers using the new computational methods, and c) returning data analysis results with data analytical provenance to ImmPort for dissemination of derived data, software tools, as well as semantic assertions of the identified biomarkers. Each aspect is one specific research aim in the proposed work. The project outcome will not only demonstrate the utility of the ImmPort data archive but also generate a foundation for the Human Vaccine Project (HVP) to establish pilot programs for influenza vaccine research, which currently include Vanderbilt University Medical Center; University of California San Diego (UCSD); Scripps Research Institute; La Jolla Institute of Allergy and Immunology; and J. Craig Venter Institute (JCVI). Once such computational analytical workflow is established, it can be applied to the secondary analysis of other ImmPort studies as well as to support the user-driven analytics of their own cytometry data. Each of the specific aims contains innovative methods or new applications of the existing methods. The computational method for population identification in Aim 1 is a newly developed constrained data clustering method, which combines advantages of unsupervised and supervised learning. Cutting-edge machine learning approaches including random forest will be used in Aim 2 for the identification of biomarkers across study cohorts, in addition to the traditional statistical hypothesis testing. Standardized knowledge representation to be developed in Aim 3 for cell-based biomarkers is also innovative, as semantic networks with inferring and deriving capabilities can be built based on the machine-readable knowledge assertions. The proposed work, when accomplished, will foster broader collaboration between ImmPort and the existing vaccine research consortia. It will also accelerate the deployment of up-to-date informatics software tools on ImmPortGalaxy. Project Narrative Flow cytometry (FCM) plays important roles in human influenza vaccination studies through interrogating immune cellular functions and quantifying the immune responses in different conditions. This project will extend the current data analytical capabilities of the Immunology Database and Analysis Portal (ImmPort) through adding novel data analytical methods and software tools for user-friendly identification of cell populations from FCM data in ImmPort influenza vaccine response studies. The derived data and the knowledge generated from the secondary analysis of the ImmPort vaccination study data will be deposited back to ImmPort and shared with the Human Vaccines Project (HVP) consortium for dissemination.",Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data,9724345,UH2AI132342,"['Academic Medical Centers', 'Address', 'Archives', 'Back', 'Biological Markers', 'California', 'Categories', 'Cells', 'Characteristics', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Cytomegalovirus', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Deposition', 'Development', 'Disease', 'Failure', 'Flow Cytometry', 'Fostering', 'Foundations', 'Funding', 'Genetic Transcription', 'HIV', 'Human', 'Hypersensitivity', 'Imagery', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunology', 'Incidence', 'Influenza', 'Influenza vaccination', 'Informatics', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Maps', 'Measles', 'Medical', 'Meta-Analysis', 'Metadata', 'Methods', 'Mumps', 'Names', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Play', 'Poliomyelitis', 'Population', 'Population Statistics', 'Prevalence', 'Prevention strategy', 'Process', 'Public Health', 'Readability', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Institute', 'Research Project Grants', 'Respiratory Syncytial Virus Vaccines', 'Respiratory syncytial virus', 'Role', 'Secondary to', 'Semantics', 'Smallpox', 'Software Tools', 'Source', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Universities', 'Vaccination', 'Vaccine Design', 'Vaccine Research', 'Vaccines', 'Work', 'analytical method', 'base', 'biomarker discovery', 'biomarker identification', 'catalyst', 'cohort', 'comparative', 'computer infrastructure', 'computerized tools', 'data archive', 'data mining', 'data portal', 'data resource', 'design', 'experience', 'experimental study', 'immune function', 'improved', 'influenza virus vaccine', 'information organization', 'innovation', 'neoplastic', 'news', 'novel', 'novel strategies', 'novel vaccines', 'prevent', 'programs', 'public-private partnership', 'random forest', 'response', 'response biomarker', 'secondary analysis', 'statistics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'user-friendly', 'vaccine development', 'vaccine response', 'vaccine trial', 'vaccine-induced immunity']",NIAID,"J. CRAIG VENTER INSTITUTE, INC.",UH2,2019,292500,-0.026862248759288627
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,9927093,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Comorbidity', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2019,253545,0.0009238951450201448
"Pattern Analysis of fMRI via machine learning/sparse models: application to brain development Abstract Resting state fMRI (rsfMRI) provides reproducible, task-independent biomarkers of coherent functional activity linking different brain regions. The main goal of the proposed project is to leverage advances in signal processing and machine learning methods to derive clinically useful biomarkers based on patterns of functional connectivity, and to test these biomarkers in a large study of brain development. Central to our methodology are 1) computing a subject-specific functional parcellation of the brain, which defines nodes for characterizing individualized functional brain networks; 2) extracting sparse connectivity patterns for robustly representing brain networks; 3) capturing heterogeneity in brain networks across individuals in a given population; and 4) deriving individualized predictive indices of psychosis risk from brain connectivity in a large study of brain development. This novel suite of functional connectivity analysis tools will be developed and validated based on data from the Human Connectome Project and the Philadelphia Neurodevelopmental Cohort (PNC). Finally, these techniques will be applied to PNC data in order to delineate heterogeneity in network development in youth with psychosis-spectrum symptoms. Our hypothesis is that patterns of functional connectivity in adolescents with psychosis-spectrum symptoms will be different from those in typically developing adolescents, and this difference will display a high degree of heterogeneity that is linked to underlying heterogeneity in pathologic neurodevelopmental trajectories. Moreover, we expect that machine learning techniques will allow us to predict on an individual basis which adolescents with psychosis-spectrum symptoms will remain stable, which will revert to normal, and which will progress to psychosis, based on their baseline functional connectivity signatures. Our methods are generally applicable to rsfMRI studies for detecting and quantifying spatio-temporal functional connectivity patterns in diverse fields, including diagnosing brain abnormalities in neuropsychiatric diseases, and finding associations of functional connectivity with different cognitive functions. All methods will be made publicly available and form an important new resource for the broader neuroscience community. Project narrative This proposal develops a suite of advanced functional imaging pattern analysis methods, aiming to delineate heterogeneity in brain network development in youth with psychosis-spectrum symptoms, ultimately leading to early biomarkers of neuropsychiatric disorders. Methodologically, the proposed work leverages upon the strengths of sparse and non-negative decompositions of imaging data, which offer several advantages over conventional mass-univariate and linear multivariate methods. One of the largest and most comprehensive cohorts of 1,600 individuals ages 8 through 21 provides unique imaging and clinical data to support the application of these methods to brain development.",Pattern Analysis of fMRI via machine learning/sparse models: application to brain development,9695211,R01EB022573,"['Address', 'Adolescent', 'Age', 'Algorithms', 'Anatomy', 'Biological', 'Biological Markers', 'Brain', 'Brain region', 'Classification', 'Clinical Data', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neurosciences', 'Outcome', 'Pathologic', 'Pathway Analysis', 'Pattern', 'Pattern Recognition', 'Philadelphia', 'Population', 'Psychotic Disorders', 'Reproducibility', 'Resources', 'Rest', 'Risk', 'Sampling', 'Shapes', 'Structure', 'Subgroup', 'Symptoms', 'Techniques', 'Testing', 'Work', 'Youth', 'base', 'brain abnormalities', 'clinical biomarkers', 'cognitive function', 'cohort', 'connectome', 'early detection biomarkers', 'follow-up', 'human data', 'improved', 'indexing', 'interest', 'learning strategy', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'personalized predictions', 'signal processing', 'spatiotemporal', 'tool', 'trend']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,522460,-0.03283250925758898
"User-driven Retrospectively Supervised Classification Updating (RESCU) systemfor robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Our milestones for Phase I are as follows:  Milestone 1.1: Extreme Learning Machine with Adaptively Sparse Representation (EASRC) algorithm  successfully implemented and verified  Milestone 1.2: Implementation of Nessa adaptive learning algorithm and smartwatch interface  Milestone 1.3: User Needs and Design Inputs locked as a result of Focus Group testing  Milestone 1.4: Hold a pre-submission meeting with FDA for feedback on device classification and  planned product performance testing  Milestone 1.5: Hold a Scientific Steering Group (SSG) meeting  Milestone 1.6: Convene a Study Monitoring Committee (SMC) and hold an initial meeting to review  clinical plans.  Milestone 1.7: Develop Clinical Study Protocol  Milestone 1.8: Register the study on www.clinicaltrials.gov. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) systemfor robust upper limb prosthesis control,9779227,U44NS108894,"['Activities of Daily Living', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Feedback', 'Focus Groups', 'Freedom', 'Group Meetings', 'Hand', 'Individual', 'Intuition', 'Joints', 'Machine Learning', 'Methods', 'Monitor', 'Ownership', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Protocols documentation', 'Research', 'Signal Transduction', 'Supervision', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Work', 'adaptive learning', 'base', 'clinical translation', 'design', 'empowerment', 'improved', 'learning algorithm', 'meetings', 'myoelectric control', 'novel', 'operation', 'performance tests', 'prosthesis control', 'signal processing', 'smart watch']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2019,79250,0.006170275530097126
"Human and Machine Learning for Customized Control of Assistive Robots PROJECT SUMMARY This application will result in a technological platform that re-empowers persons with severe paralysis, by allowing them to independently control a wide spectrum of robotic actions. Severe paralysis is devastating, and chronic—and reliance on caregivers is persistent. Assistive machines such as wheelchairs and robotic arms offer a groundbreaking path to independence: where control over their environment and interactions is returned to the person.  However, to operate complex machines like robotic arms and hands typically poses a difﬁcult learning challenge and requires complex control signals—and the commercial control interfaces accessible to persons with severe paralysis (e.g. sip-and-puff, switch-based head arrays) are not adequate. As a result, assistive robotic arms remain largely inaccessible to those with severe paralysis—arguably the population who would beneﬁt from them most.  The purpose of the proposed study is to provide people with tetraplegia with the means to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. Control interfaces that generate a unique map from a user's body motions to control signals for a machine offer a customized interaction, however these interfaces have only been used to issue low-dimensional (2-D) control signals whereas more complex machines require higher-dimensional (e.g. 6-D) signals. We propose an approach that leverages robotics autonomy and machine learning in order to aid the end-user in learning how to issue effective higher-dimensional control signals through body motions. Speciﬁcally, initially the human issues a lower- dimensional control signal and robotics autonomy is used to bridge the gap by taking over whatever is not covered by the human's control signal. Help from the robotics autonomy is then progressively scaled back, automatically, to cover fewer and fewer control dimensions as the user becomes more skilled.  The ﬁrst piece to our approach deals with how to extract control signals from the human, using the body-machine interface. The development and optimization of decoding procedures for controlling a robotic arm using residual body motions will be addressed under Speciﬁc Aim 1. The second piece to our approach deals with how to interpret control signals from a human within a paradigm that shares control between the human and robotics autonomy. To identify which shared-control formulations most effectively utilize the human's control signals will be the topic of Speciﬁc Aim 2. The ﬁnal piece to our approach deals with how to adapt the shared-control paradigm so that more control is transferred to the human over time. This adaptation is necessary for the human's learning process, since the goal in the end is for the human to be able to fully control the robotic arm him/herself, and will be assessed under Speciﬁc Aim 3.  At the completion of this project, tetraplegic end-users will be able to operate a robotic arm using their residual body motions, through an interface that both promotes the use of residual body motions (and thus also recovery of motor skill) and adapts with the human as their abilities change over time. By leveraging adaptive robotics autonomy, our application moreover provides a safe mechanism to facilitate learning how to operate the robotic platform. Frequently the more severe a person's motor impairment, the less able they are to operate the very assistive machines, like powered wheelchairs and robotic arms, which might enhance their quality of life. The purpose of the proposed study is to provide people with tetraplegia with the means, through non-invasive technologies, to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. We propose and study an approach that leverages robot machine learning and autonomy in order to facilitate human motor learning of how to operate a robotic arm using a customized interface, in order to make powered assisted manipulation more accessible to people with severe paralysis. 1",Human and Machine Learning for Customized Control of Assistive Robots,9773039,R01EB024058,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Affect', 'Algorithms', 'Back', 'Caregivers', 'Cerebral Palsy', 'Chronic', 'Complex', 'Computers', 'Custom', 'Data', 'Development', 'Devices', 'Dimensions', 'Eating', 'Effectiveness', 'Environment', 'Exercise', 'Formulation', 'Fostering', 'Freedom', 'Future', 'Goals', 'Hand', 'Head', 'Health Benefit', 'Human', 'Learning', 'Left', 'Limb structure', 'Machine Learning', 'Maintenance', 'Maps', 'Mental Depression', 'Mental Health', 'Motion', 'Motivation', 'Motor', 'Motor Skills', 'Movement', 'Multiple Sclerosis', 'Neurologic', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Population', 'Posture', 'Powered wheelchair', 'Procedures', 'Process', 'Quadriplegia', 'Quality of life', 'Rehabilitation therapy', 'Residual state', 'Robot', 'Robotics', 'Self-Help Devices', 'Shoulder', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Spinal cord injured survivor', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Wheelchairs', 'Work', 'arm', 'assistive robot', 'base', 'body-machine interface', 'brain machine interface', 'empowerment', 'feeding', 'high dimensionality', 'improved', 'machine learning algorithm', 'motor impairment', 'motor learning', 'motor recovery', 'n-dimensional', 'novel strategies', 'physical conditioning', 'psychologic', 'robot control', 'sensor', 'two-dimensional']",NIBIB,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R01,2019,329494,-0.015620403525063442
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,10013405,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'learning algorithm', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'smart watch', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2019,735600,0.005651265757652092
"Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations Q-Chem is a state-of-the-art commercial computational quantum chemistry program that has aided about 60,000 users in their modeling of molecular processes in a wide range of disciplines, including biology, chemistry, and materials science. In this proposal, we seek to significantly reduce the computational time (now around 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions. Specifically, we propose to use a multiple time step (MTS) simulation method, where a low-level (and less accurate) quantum chemistry method is used to propagate the system (i.e. move all atoms) at each time step (usually 0.5 or 1 fs), and then a high-level (i.e. more accurate and expensive) quantum chemistry method is used to correct the force on the atoms at longer time intervals. In this way, the simulation can be performed at the high-level energy surface in a fraction of time, compared with simulations performed only using the high-level quantum chemical method. In the Phase I proposal, our goal is to allow the high-level force update only once every 40—50 fs by identifying appropriate lower-level theories (Aim 1) and incorporating machine-learning techniques (Aim 2). This will accelerate accurate free energy simulations by 20—25 fold, reducing the overall computer time to around 25,000 CPU hours. Thus, our new MTS simulation method will make it feasible to routinely perform computational studies on enzymatic reaction mechanism. The addition of these new tools will also further strengthen Q-Chem's position as a global leader in the molecular modeling software market, making our program the most efficient and reliable computational quantum chemistry package for simulating large, complex chemical/biological systems. In this project, we seek to significantly reduce the computational time (ca. 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions to ca. 25,000 CPU Hours. Building upon sophisticated quantum mechanics, this can lead to reliable and quick predictions of enzyme activities.",Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations,9778517,R43GM133270,"['Acceleration', 'Accounting', 'Adopted', 'Back', 'Biochemical', 'Biochemical Reaction', 'Biology', 'Biomedical Research', 'Chemicals', 'Chemistry', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computers', 'Development', 'Discipline', 'Enzymes', 'Foundations', 'Free Energy', 'Goals', 'Hour', 'Hybrids', 'Lead', 'Machine Learning', 'Maps', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Pathway interactions', 'Performance', 'Phase', 'Positioning Attribute', 'Potential Energy', 'Process', 'Protein Conformation', 'Proteins', 'Quantum Mechanics', 'Reaction', 'Recipe', 'Research', 'Research Personnel', 'Sampling', 'Scheme', 'Solvents', 'Surface', 'System', 'Techniques', 'Time', 'Update', 'biological systems', 'computer studies', 'cost', 'density', 'enzyme activity', 'enzyme model', 'improved', 'innovation', 'learning strategy', 'materials science', 'molecular mechanics', 'molecular modeling', 'programs', 'quantum', 'quantum chemistry', 'quantum computing', 'simulation', 'theories', 'time interval', 'tool']",NIGMS,"Q-CHEM, INC.",R43,2019,132011,-0.004930131895433164
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9706046,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2019,347834,-0.005156844708701949
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures. In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s and Parkinson’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 35,000 researchers that use FreeSurfer through our existing open source mechanism. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner. These new capabilities well enable other studies to significantly increase their ability to detect disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately.",Deep Learning Algorithms for FreeSurfer,9971629,R56AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Architecture', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Parkinson Disease', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'autoencoder', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'morphometry', 'nervous system disorder', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R56,2019,609504,-0.024974021678293823
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user's location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user's location by recognizing standard informational signs present in the environment, tracking the user's trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9934891,R01EY029033,"['Adoption', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Environment', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Medical center', 'Process', 'Research', 'Schools', 'System', 'Tactile', 'Time', 'Travel', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'interest', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,105337,0.027600979729868157
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9797689,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,748584,-0.011846697330784205
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9663319,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416374,0.027600979729868157
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,-0.009609193190788314
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9666293,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'learning strategy', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2019,146837,-0.01638146300395064
"Quantifying causality for neuroscience Abstract: Causality is central to neuroscience. For example, we might ask about the causal effect of a neuron on another neuron, or its influence on perception, action, or cognition. Moreover, any medical approaches aim at producing a causal effect – effecting improvements for patients. Randomized controlled trials (RCTs) are the gold standard to establish causality, but they are not always practical. For example, while we can electrically or optogenetically activate entire areas, large-scale targeted stimulation of individual neurons is hard. Other ways of establishing causality are problematic: if we observe a correlation it is hard to know its cause. The problem is confounding: there are variables that we do not record that affect the variables we do. This also renders model comparisons problematic – a causally wrong model with few parameters may well fit the observed data better than a causally correct one with many parameters. We thus need data analysis tools that allow authoritatively asking causal questions without the need for random perturbation experiments.  Just like neuroscience now, the field of econometrics once focused on correlations. But since the 1980s, empirical economics has undergone a so-called credibility revolution, requiring the development of rigorous methods to establish causality. Several successful methods have emerged to become the workhorses of empirical economics. The idea underlying these methods is that if one can observe variables that approximate random perturbations, then one can still discover causal relations. This is what economists call a quasi-experiment. We here propose to carry over such quasi-experimental techniques to neuroscience. For example in neuroscience, if there is a random variable that affects only one neuron, then any activity in other neurons correlated with that variable must be causally affected by the neuron. Another famous quasi- experimental method is regression discontinuity design (RDD). This approach effectively uses the noise introduced at the threshold to identify causal relations. Importantly, such techniques have, thanks to decades of research in econometrics, very well understood statistical properties. These approaches promise to considerably enrich the approaches towards causality we have in neuroscience. We have a strong interdisciplinary team, spanning economics, experimental, and computational neuroscience, collaborating on adapting these quasi-experimental techniques to problems in neuroscience through a combination of machine learning and domain-specific engineering. This promises to be a major advance relative to current techniques that generally approach causality in neuroscience through model comparison. Project Narrative: The goal of this project is to develop a set of computational techniques that allow neuroscientists to quantify how neurons causally influence one another. To do so, it utilizes approaches popular in econometrics called quasiexperiments. Such approaches to quantify causality is important as medical perturbations of brains, e.g. treatments of epilepsy or depression are aimed at effecting or causing a change in the brain.",Quantifying causality for neuroscience,9775861,R01EB028162,"['Affect', 'Algorithms', 'Area', 'Brain', 'Code', 'Cognition', 'Communities', 'Computational Technique', 'Confounding Factors (Epidemiology)', 'Data', 'Data Analyses', 'Development', 'Economics', 'Engineering', 'Epilepsy', 'Etiology', 'Glean', 'Goals', 'Gold', 'Individual', 'Injections', 'Intervention', 'Learning', 'Machine Learning', 'Medical', 'Mental Depression', 'Methods', 'Modeling', 'Modernization', 'Neurons', 'Neurosciences', 'Noise', 'Organism', 'Output', 'Patients', 'Perception', 'Performance', 'Physiological', 'Property', 'Quasi-experiment', 'Randomized Controlled Trials', 'Refractory', 'Research', 'Synapses', 'Techniques', 'base', 'computational neuroscience', 'design', 'econometrics', 'experimental study', 'improved', 'optogenetics', 'phrases', 'relating to nervous system', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,803000,-0.004769029858068198
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9763514,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2019,305372,0.012062994319409309
"Brain Science Compute Cluster Computational requirements of contemporary brain science research typically exceed financial and resource management limits of individual investigator laboratories. Many brain science research projects require analysis of large data sets with advanced statistical methods and anatomical reconstruction techniques. These methods require high speed computational and graphics engines operating in a multiple processor environments equipped with large capacity, high speed storage devices. An ongoing limitation in the Brown brain science effort at understanding neural processing is the lack of a contemporary and readily accessible high-speed computational resource.  We plan to replace an existing, but 5 year old and now outmoded, central computational resource that has outdated graphic processing units (GPU) and central processing units (CPU) and and limited storage that will serve the computational needs of a core group of brain science investigators at Brown without compromising individual access to stand-alone workstations. The requested computation equipment comprises 13 GPU nodes (total of 52 cores), 12 CPU nodes (288 cores) and 1.2 petabytes of disk storage, which will serve the needs of the assembled brain science researchers. The equipment will become integrated into Brown's high performance Compute Cluster, which has system software that automatically balances GPU and CPU usage, thereby ensuring maximum access to the computational resource for all users. Intensive 3D graphics are off- loaded either to GPUs or to client workstations, thereby further reducing the central computational load. Commercial or open-source software with an open operating environment will be used for analysis using standard and novel statistical and machine learning approaches to assess significance of large data sets.  This proposal details the architecture and benefits of a contemporary computational resource for the major and minor users, and more generally the Brown brain science community. The resource was designed to fill immediate and near-term computational and storage needs of a core group of Brown brain scientists. The system can be readily expansion as needs, either computational, storage, or new users, arise. Expansion of the existing core investigators group can occur easily since the computational power or storage capacity of the system can be readily enhanced at relatively low cost.  The flexible nature of the system will serve a variety of research needs of the Brown brain science community. The computational resource is expected to bring together researchers at Brown working on the common problem of neural processing. Relevance Gaining insights into the neural and brain mechanisms that underlie normal brain function and malfunction in disease requires analysis of large and complex data sets related to behavior and brain physiology, chemistry and structure. This proposals requests support to develop a computing infrastructure devoted to researchers in Brown's Carney Institute for Brain Science who investigate brain structure and function.",Brain Science Compute Cluster,9708078,S10OD025181,"['3-Dimensional', '5 year old', 'Anatomy', 'Architecture', 'Brain', 'Client', 'Communities', 'Computer software', 'Data Set', 'Devices', 'Ensure', 'Environment', 'Equilibrium', 'Equipment', 'High Performance Computing', 'Individual', 'Laboratories', 'Machine Learning', 'Methods', 'Minor', 'Nature', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Speed', 'Statistical Methods', 'System', 'Techniques', 'cluster computing', 'computing resources', 'cost', 'design', 'flexibility', 'novel', 'open source', 'petabyte', 'reconstruction', 'relating to nervous system', 'software systems']",OD,BROWN UNIVERSITY,S10,2019,300000,0.005625678842528396
"Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery PROJECT SUMMARY / ABSTRACT Closed or open fracture reduction and internal fixation is the standard surgical approach in treating pelvic fractures, with current clinical practice using fluoroscopic guidance, guidewire insertion, and cannulated screw placement. The challenge in reckoning complex 3D morphology in 2D fluoroscopy presents a major source of uncertainty, trial-and- error, and poor outcomes, with 20-30% rate of suboptimal screw placement and long fluoroscopic runtime (mean fluoro time > 123 s) exposing operating personnel to high levels of radiation exposure. Despite these challenges, mainstream surgical approach has remained largely unchanged for 35 years, and surgical navigation systems (though increasingly common in neurosurgery) present cost and workflow barriers that limit their broad applicability in trauma surgery. We propose a computer vision-based navigation approach that is compatible with routine trauma surgery workflow, offers real-time guidance with accuracy comparable to stereotactic navigation, gives ten-fold reduction in radiation exposure, and works with tools already common in the trauma surgery arsenal. The proposed system uses a miniature stereoscopic camera mounted onboard the surgical drill in combination with 3D-2D registration of fluoroscopic views for direct, real-time registration of the instrument trajectory relative to patient anatomy. Real-time overlay of instrument trajectory in fluoroscopic views and/or CT permits accurate identification of guidewire entry point, orientation, and conformance within bone corridors and will reduce reliance on “fluoro hunting” and trial-and-error guidewire placement. The following aims develop and evaluate the system for application in pelvic trauma surgery, including quantitative assessment of accuracy, workflow, and radiation dose in pre-clinical studies. Aim 1. System for computer vision-based guidance in trauma surgery. The hardware and software components required for vision-based tracking onboard a standard surgical drill will be developed, providing real-time trajectory overlay in fluoroscopy and/or preoperative CT. A fast calibration method will be developed for automatic drill axis calibration. Automatic feature-based registration of the video and fluoroscopic frames enables real-time overlay of instrument trajectory in fluoroscopic views (Fluoro Navigation), and 3D-2D registration between CT and fluoroscopy will enable real-time overlay of the instrument trajectory in CT (CT Navigation). Aim 2: Evaluation in preclinical studies. The vision-based navigation system will be implemented in pre-clinical (cadaver) experiments to evaluate accuracy and workflow. These studies will evaluate the geometric accuracy and workflow factors relating to the number of repeated insertion attempts, procedure time, and radiation dose, evaluating vision-based Fluoro Navigation and CT Navigation in comparison to conventional freehand fluoroscopy guidance. Successful completion of the aims will establish a system suitable for computer vision-based navigation to be translated to clinical studies in future work. Such a system offers a potentially major advance in routine trauma surgery, bringing capabilities comparable to state-of-the-art stereotactic navigation without the cost, complexity, and additional workflow of conventional navigation. PROJECT NARRATIVE Even experienced trauma surgeons are challenged in resolving the complex 3D morphology of the pelvis in 2D x-ray fluoroscopy, presenting a major source of uncertainty, a high rate of malpositioned screws, and high levels of radiation exposure to the patient and operating staff. To facilitate high-precision pelvic trauma surgery and reduce intraoperative radiation dose, we propose a computer vision-based navigation approach providing real-time overlay of surgical instrument trajectories in fluoroscopic views and CT, facilitating accurate identification of guidewire entry point, orientation, and conformance within safe bone corridors. The approach offers a major advance compared to conventional navigation by not requiring intraoperative 3D imaging, avoiding time-consuming calibration, and eliminating externally-positioned hardware in the operating room, and the proposed research translates the system from basic development and quantitative testing to preclinical studies evaluating geometric accuracy, workflow, and radiation dose.",Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery,9806153,R21EB028330,"['3-Dimensional', '3D Print', 'Affect', 'Anatomy', 'Biopsy', 'Cadaver', 'Calibration', 'Clinical Research', 'Closed Fractures', 'Communities', 'Comorbidity', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Ensure', 'Evaluation', 'Exposure to', 'Fluoroscopy', 'Fracture', 'Future', 'Healthcare', 'High Prevalence', 'Hour', 'Human Resources', 'Image', 'Incidence', 'Mainstreaming', 'Methods', 'Morphology', 'Navigation System', 'Needles', 'Open Fractures', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Outcome', 'Patients', 'Pelvis', 'Persons', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation exposure', 'Research', 'Roentgen Rays', 'Source', 'Structure', 'Surgeon', 'Surgical Instruments', 'System', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Translating', 'Translations', 'Trauma', 'Uncertainty', 'Visceral', 'Vision', 'Work', 'base', 'bone', 'clinical practice', 'cortical bone', 'cost', 'disability', 'experience', 'experimental study', 'improved', 'instrument', 'instrumentation', 'mortality', 'neurosurgery', 'neurovascular', 'pelvis fracture', 'pre-clinical', 'preclinical study', 'sample fixation', 'socioeconomics', 'stereoscopic', 'tool', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,238182,-0.020321118442170667
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9988039,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,49496,-0.03363132253251686
"Intelligent connectomic analysis tool for dense neuronal circuits Intelligent Connectomic Analysis Tool for Dense Neuronal Circuits Project Summary: The lack of basic understanding of neuronal functions and disease processes is a big factor of failures in creating drugs for neurological diseases. High-resolution maps of the complex connectivity of neuronal circuits correlating with functional and/or molecular markers offer invaluable insights into the functional organization of the neuronal structures, which is a key to understanding the brain in health and disease. There is a strong interest in elucidating and quantifying the connectomics of brain networks with subcellular resolution using electron microscopy (EM) and correlate with functional fluorescence microscopy data. The ultimate goal is to elucidate human brain functions and the mechanisms of human brain disorders. This is critically important to enable new diagnostics and therapies for brain disorders.  The reconstruction and analyses of neuronal networks is challenging in part due to the joint requirement of large volume and high resolution and a large gap in connectomic analysis solutions. There is a strong need for next generation, well supported, integrated, easy to use and highly automated analysis tools to detect and classify neurons, trace arbor branches, identify synapses, spines and synaptic vesicles that increase the throughput of otherwise prohibitively time-consuming analyses in connectomic experiments. There is also a strong need for tools to perform downstream data-driven analysis such as functional inference from structure and phenotypic discovery.  Powered by machine learning and DRVision innovations and collaborating with Dr. Rachel Wong and 9 additional labs, this project proposes to create an intelligent connectomic analysis (ICA) tool optimized for dense neuronal circuits. The tool will be commercially supported and integrated with DRVision’s flagship product Aivia to (1) provide accurate and automated neuron tracing in 3D EM and 3D fluorescence data up to multi-terabytes, (2) identify pre- and post-synaptic dendrite segments, (3) correlate light and electron microscopy data, quantify and classify neurons and sub-cellular components, (4) extract and analyze neuron circuits, (5) provide tools for phenotype discoveries, (6) seamlessly integrate the pipeline of ground truth (GT) annotation, editing, and machine learning workflow, and (7) access the required computing infrastructure, database connection, and exchange of data with other tools. Project Narrative The lack of basic understanding of neuronal functions and disease processes is a big factor of failures in creating drugs for neurological diseases. There is a strong interest in elucidating and quantifying the connectomics of brain networks with subcellular resolution using electron microscopy (EM) and correlate with functional fluorescence microscopy data. This is critically important to enable new diagnostics and therapies for brain disorders.  Powered by machine learning and DRVision innovations and collaborating with Dr. Rachel Wong and 9 additional labs, this project proposes to create an intelligent connectomic analysis (ICA) tool optimized for dense neuronal circuits. The tool will be integrated with DRVision’s flagship product Aivia for commercialization.",Intelligent connectomic analysis tool for dense neuronal circuits,9847626,R44MH121167,"['3-Dimensional', 'Active Learning', 'Biological Models', 'Brain', 'Brain Diseases', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Set', 'Databases', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Evaluation', 'Failure', 'Feedback', 'Fluorescence', 'Fluorescence Microscopy', 'Generations', 'Goals', 'Government', 'Health', 'Human', 'Image', 'Infrastructure', 'Intelligence', 'Intelligence Tests', 'Joints', 'Machine Learning', 'Maps', 'Modeling', 'Mus', 'Nervous system structure', 'Neurons', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Process', 'Resolution', 'Retina', 'Structure', 'Synapses', 'Synaptic Vesicles', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Update', 'Validation', 'Vertebral column', 'Zebrafish', 'annotation  system', 'automated analysis', 'brain disorder therapy', 'cell type', 'commercialization', 'data exchange', 'experimental study', 'fluorescence imaging', 'innovation', 'insight', 'interest', 'light microscopy', 'microscopic imaging', 'molecular marker', 'nervous system disorder', 'neuronal circuitry', 'next generation', 'novel diagnostics', 'novel therapeutics', 'prototype', 'reconstruction', 'terabyte', 'tool', 'usability']",NIMH,"DRVISION TECHNOLOGIES, LLC",R44,2019,250873,-0.015125364616283018
"C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative ABSTRACT The BRAIN Initiative is designed to leverage sophisticated neuromodulation, electrophysiological recording, and macroscale neuroimaging techniques in human and non-human animal models in order to develop a multilevel understanding of human brain function. However, the necessary tools for organizing, processing and analyzing neuroimaging data generated through these efforts are not widely available as coherent and easy-to- use software packages. Gaps are particularly apparent for nonhuman data (i.e., monkey, rodent), as most of the existing processing and analytic software packages are specifically designed for human imaging. Methods have been proposed for addressing the challenges inherent to the processing of nonhuman data (e.g., brain extraction, tissue segmentation, spatial normalization, brain parcellation, temporal denoising); to date, these have not been readily integrated into an easy-to-use, robust, and reproducible analysis package. Similarly, many of the sophisticated machine learning and modeling methods developed for neuroimaging analyses are inaccessible to most researchers because they have not been integrated into easy-to-use pipeline software. As a result, translational and comparative neuroimaging researchers patch together neuroinformatics pipelines that use various combinations of disparate software packages and in-house code. We propose to extend the Configurable Pipeline for the Analysis of Connectomes (C-PAC) open-source software to provide robust and reproducible pipelines for functional and structural MRI data. We will integrate the various disparate image processing and analysis methods used to handle the challenges of nonhuman imaging data, into a single, open source, configurable, easy-to-use end-to-end analysis pipeline package that is accessible locally or via the cloud. The end product will not only improve the quality, transparency and reproducibility of nonhuman translational and comparative imaging, but also enable new avenues of scientific inquiry through our inclusion of methods that are yet to be applied to nonhuman imaging data (e.g., gradient- based cortical parcellation methods, hyperalignment). Specific aims of the proposed work include to: 1) Integrate neuroimaging processing and analysis methods optimized for BRAIN Initiative data, 2) Implement strategies for carrying out comparative studies of human and non-human populations, and 3) Extend C-PAC to include cutting-edge analytical strategies for identifying mechanisms of brain function. All development will occur “in the open” using GitHub and other collaborative tools to maximally involve participation in the C-PAC project. Annual hackathons will be held to collaborate with investigators from BRAIN Initiative awards and other neuroinformatics development projects to integrate their tools with C-PAC. Hands-on training will be held to train investigators on optimal use of the newly developed tools. NARRATIVE New neuroimaging analysis software is needed to process and analyze the various human and non-human neuroimaging data collected through the BRAIN Initiative. We will address this need by extending the already mature C-PAC human brain imaging data analysis pipeline to include support for animal data, with a particular focus on providing methods for conducting comparative studies between species. The proposed work will also include a toolbox for helping to align electrophysiological data that is commonly collected in non-human studies, with the brain imaging data.","C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative",9766371,R24MH114806,"['Address', 'Adoption', 'Anatomy', 'Animal Model', 'Architecture', 'Award', 'Behavior', 'Brain', 'Brain imaging', 'Capital', 'Code', 'Communities', 'Comparative Study', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Documentation', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Funding', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Outcome', 'Output', 'Pattern', 'Persons', 'Phenotype', 'Population', 'Process', 'Pythons', 'Readability', 'Reproducibility', 'Research Personnel', 'Rodent', 'Scientific Inquiry', 'Software Design', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validity of Results', 'Work', 'analysis pipeline', 'animal data', 'base', 'brain research', 'cloud based', 'comparative', 'computing resources', 'connectome', 'cost', 'data sharing', 'data structure', 'denoising', 'design', 'flexibility', 'graphical user interface', 'hackathon', 'human imaging', 'image processing', 'improved', 'innovative neurotechnologies', 'investigator training', 'learning strategy', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuroregulation', 'open source', 'software as a service', 'supervised learning', 'tool', 'unsupervised learning']",NIMH,"CHILD MIND INSTITUTE, INC.",R24,2019,545648,0.015067162291622202
"C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative ABSTRACT The BRAIN Initiative is designed to leverage sophisticated neuromodulation, electrophysiological recording, and macroscale neuroimaging techniques in human and non-human animal models in order to develop a multilevel understanding of human brain function. However, the necessary tools for organizing, processing and analyzing neuroimaging data generated through these efforts are not widely available as coherent and easy-to- use software packages. Gaps are particularly apparent for nonhuman data (i.e., monkey, rodent), as most of the existing processing and analytic software packages are specifically designed for human imaging. Methods have been proposed for addressing the challenges inherent to the processing of nonhuman data (e.g., brain extraction, tissue segmentation, spatial normalization, brain parcellation, temporal denoising); to date, these have not been readily integrated into an easy-to-use, robust, and reproducible analysis package. Similarly, many of the sophisticated machine learning and modeling methods developed for neuroimaging analyses are inaccessible to most researchers because they have not been integrated into easy-to-use pipeline software. As a result, translational and comparative neuroimaging researchers patch together neuroinformatics pipelines that use various combinations of disparate software packages and in-house code. We propose to extend the Configurable Pipeline for the Analysis of Connectomes (C-PAC) open-source software to provide robust and reproducible pipelines for functional and structural MRI data. We will integrate the various disparate image processing and analysis methods used to handle the challenges of nonhuman imaging data, into a single, open source, configurable, easy-to-use end-to-end analysis pipeline package that is accessible locally or via the cloud. The end product will not only improve the quality, transparency and reproducibility of nonhuman translational and comparative imaging, but also enable new avenues of scientific inquiry through our inclusion of methods that are yet to be applied to nonhuman imaging data (e.g., gradient- based cortical parcellation methods, hyperalignment). Specific aims of the proposed work include to: 1) Integrate neuroimaging processing and analysis methods optimized for BRAIN Initiative data, 2) Implement strategies for carrying out comparative studies of human and non-human populations, and 3) Extend C-PAC to include cutting-edge analytical strategies for identifying mechanisms of brain function. All development will occur “in the open” using GitHub and other collaborative tools to maximally involve participation in the C-PAC project. Annual hackathons will be held to collaborate with investigators from BRAIN Initiative awards and other neuroinformatics development projects to integrate their tools with C-PAC. Hands-on training will be held to train investigators on optimal use of the newly developed tools. NARRATIVE New neuroimaging analysis software is needed to process and analyze the various human and non-human neuroimaging data collected through the BRAIN Initiative. We will address this need by extending the already mature C-PAC human brain imaging data analysis pipeline to include support for animal data, with a particular focus on providing methods for conducting comparative studies between species. The proposed work will also include a toolbox for helping to align electrophysiological data that is commonly collected in non-human studies, with the brain imaging data.","C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative",9894275,R24MH114806,"['Address', 'Adoption', 'Anatomy', 'Animal Model', 'Architecture', 'Award', 'Behavior', 'Brain', 'Brain imaging', 'Capital', 'Code', 'Communities', 'Comparative Study', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Documentation', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Funding', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Outcome', 'Output', 'Pattern', 'Persons', 'Phenotype', 'Population', 'Process', 'Pythons', 'Readability', 'Reproducibility', 'Research Personnel', 'Rodent', 'Scientific Inquiry', 'Software Design', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validity of Results', 'Work', 'analysis pipeline', 'animal data', 'base', 'brain research', 'cloud based', 'comparative', 'computing resources', 'connectome', 'cost', 'data sharing', 'data structure', 'denoising', 'design', 'flexibility', 'graphical user interface', 'hackathon', 'human imaging', 'image processing', 'improved', 'innovative neurotechnologies', 'investigator training', 'learning strategy', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuroregulation', 'open source', 'software as a service', 'supervised learning', 'tool', 'unsupervised learning']",NIMH,"CHILD MIND INSTITUTE, INC.",R24,2019,23100,0.015067162291622202
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9668174,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'neural network', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2019,78000,0.002572252640708679
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,9712424,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Detection', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Lymphatic vessel', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'disability', 'geometric structure', 'in vivo', 'lymphatic circulation', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,540520,-0.07298530595871174
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,9911854,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2019,15000,-0.004313735509508479
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9786702,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2019,431816,0.01437705698681818
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9650637,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'classification algorithm', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2019,199118,0.013975257102518068
"Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale Project Summary This project aims to leverage the best of both computational and human expertise in neuronal reconstruction towards the goal of accelerating global neuroscience discovery from internationally-sourced imaging data. We propose to create a cloud-based unified platform for converging 3-dimensional images of neurons onto a single analysis platform to (1) train and grow a new expert community of global reconstructors to work across the data from these groups, to (2) generate a community-sourced neuronal reconstruction database of open imaging data that can be incorporated into a 3-dimensional map of neuronal interconnectivity - onto which (3) novel annotations and more complex functional and molecular data can be overlaid. Our approach will evolve with the growing needs of the neuroscience community over time. To do this, in Aim One (Neuronal Reconstruction at Scale), we will test if the newly developed crowd-sourced game-based platform Mozak can develop a collective of new human experts at scale, capable of accelerating the rate of current reconstruction by at least an order of magnitude, at the same time as increasing the robustness, quality and unbiasedness of the final reconstructions. In Aim Two (Robust Multi-Purpose Annotation), we will enhance basic neuronal reconstruction by adding specific semantic annotation— including soma volume and morphological quantification, volumetric analysis, and ongoing features (e.g. dendritic spines, axonal varicosities) requested from the neuroscience community. Experienced and high-ranking members will be given the opportunity to advance through increasingly complex neurons into full arbor brain-wide neuronal projections and multiple clustered groups of neurons in localized circuits. Finally, in Aim 3 (Creation of a Research-Adaptive Data Repository), we aim to develop a database of neuronal images reconstructed using the Mozak interface that will directly serve the general and specific needs of different research groups. Our goal is to make this database dynamically adaptive — as new research questions will invariably bring new needs for additional annotations and cross-referencing with other data modalities. This highquality unbiased processing repository will also be perfectly suited for training sets for automated algorithms, and the generation of a 3-dimensional maps such as Allen Institute for Brain Science (AIBS) common coordinate framework. We expect that the computational reconstruction methods will further improve with the new large corpus of “gold standard” reconstructions. Collectively, the completion of these three aims will create an analysis suite as well as an online community of experts capable of performing in depth analysis of large-scale datasets that will significantly accelerate neuroscience research, enhance machine learning for reconstruction analysis, and create a common platform of baseline neuronal morphology data against which aberrantly functioning neurons can be analyzed. Project Narrative  This project will create a new central nexus point for neuronal reconstruction and semantic annotation (Mozak) that can be used by all research labs via an accessible online portal. We will develop a new cadre of neuronal reconstruction experts that will— in conjunction with automated tools that are enhanced by their work — drastically increase the volume, quality and robustness of neuron reconstructions and annotations. Mozak reconstructions will be shared with existing repositories and will be continually updated and re-annotated based on emerging needs of research - ensuring perpetual relevance, and allowing us to generate a platform to establish the range of “baseline” 3-dimensional readouts of neuronal morphology against which diseased or malfunctioning neurons can be analyzed and understood. 1",Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale,9775212,R01MH116247,"['3-Dimensional', 'Adopted', 'Algorithms', 'Area', 'Axon', 'Brain', 'Characteristics', 'Classification', 'Communities', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Dendritic Spines', 'Disease', 'Ensure', 'Future', 'Gap Junctions', 'Generations', 'Goals', 'Gold', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Molecular', 'Morphology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Output', 'Process', 'Research', 'Science', 'Semantics', 'Slice', 'Source', 'Standardization', 'Structure', 'Techniques', 'Testing', 'Three-dimensional analysis', 'Time', 'Training', 'Update', 'Variant', 'Varicosity', 'Work', 'base', 'citizen science', 'cloud based', 'crowdsourcing', 'data warehouse', 'experience', 'improved', 'member', 'neuronal cell body', 'novel', 'online community', 'petabyte', 'programs', 'reconstruction', 'repository', 'tool', 'two-dimensional']",NIMH,UNIVERSITY OF WASHINGTON,R01,2019,628430,-0.005063557271196805
"Development of brain-computer interface methods to influence brain dynamics in stuttering Project summary Brain dynamics that drive variability within and between patients are an important, but poorly understood, element of many cognitive disorders. The long-term goal of this research project is to develop technology that will identify brain activity patterns associated with successful performance on a given task, and use this pattern as a target for brain-computer interface (BCI) training. The overarching hypothesis is that using BCI training to more often have a brain state that is spontaneously correlated to good performance will, in turn, improve overall performance. This approach could be developed into a powerful tool for rehabilitation and therapy for many neurological and psychiatric disorders. Here we will investigate persistent developmental stuttering (PDS) as a model to study brain dynamics associated with successful vs. unsuccessful performance. PDS is a speech disorder where fluent speech is punctuated to various degrees by stuttering. Individuals with PDS are otherwise neurologically in the normal range, which avoids complicating factors in most patient populations. Stuttering is intermittent; thus on some occasions the brain is in a state conducive to fluent speech and at other times it is not. We propose to use EEG activity shortly before speaking to predict whether somebody with PDS will stutter or speak fluently. Preliminary data are given to show proof of concept with traditional EEG analysis methods. This approach will be expanded by first using advanced methods such as common spatial pattern analysis and machine learning over multiple subject sessions to identify EEG signals that distinguish fluent vs. dysfluent trials (Aim 1). PDS subjects will then be trained to produce and maintain their EEG pattern that is most strongly associated with fluent speech by using BCI methods. We hypothesize that individuals will learn to modulate EEG features to be more consistent with fluent trials, which in turn will significantly reduce stuttering rate. After successful completion of this project we envision a new BCI-based intervention that can be used to encourage neural states conducive to fluent speech in those who stutter. The BCI intervention would complement traditional speech therapy using behavioral methods. The “two-step approach” of first identifying brain states associated with a patient’s best performance followed by BCI training to enter that state more often can be applied to rehabilitation in many other neurological and psychiatric disorders, such as Alzheimer’s disease, traumatic brain injury, and mood disorders, to name a few. Project narrative The goal of this project is to develop brain-computer interface technology to optimize brain function on an individual basis. This could have therapeutic applications to many neurological and psychiatric disorders, including stroke, Alzheimer’s disease, and traumatic brain injury.",Development of brain-computer interface methods to influence brain dynamics in stuttering,9659309,R21DC016353,"['Alzheimer&apos', 's Disease', 'Behavioral', 'Brain', 'Brain region', 'Cognition Disorders', 'Complement', 'Control Groups', 'Cues', 'Data', 'Development', 'Developmental Stuttering', 'Electroencephalography', 'Elements', 'Failure', 'Feedback', 'Frequencies', 'Goals', 'Individual', 'Intervention', 'Learning', 'Machine Learning', 'Memory', 'Mental disorders', 'Metaphor', 'Methods', 'Modeling', 'Mood Disorders', 'Names', 'Neurologic', 'Normal Range', 'Patients', 'Pattern', 'Performance', 'Physiology', 'Rehabilitation therapy', 'Research Project Grants', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Speech', 'Speech Disorders', 'Speech Therapy', 'Stroke', 'Stuttering', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Traumatic Brain Injury', 'Work', 'base', 'brain computer interface', 'improved', 'indexing', 'motor control', 'nervous system disorder', 'patient population', 'relating to nervous system', 'response', 'tool', 'visual feedback']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R21,2019,170514,-0.03675512067646026
"Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain Great discoveries in neuroscience hold promise for reducing the burden of many of the most disabling conditions that threaten human health on a global scale, including mental illnesses and addictions. Increasingly, exceptionally innovative science inspires hope that these devastating brain-based disorders may be prevented, treated, and even cured but, as the BRAIN 2025 Scientific Vision notes, a suite of novel ethical challenges confronts those engaged in innovative neuroscience. These concerns include the deepest questions about what defines humanity and personhood, what forms of novel inquiry may exceed ethically acceptable limits in society, and how to perform ethically sound studies with volunteers who may be vulnerable to exploitation in the research situation. Such issues are particularly salient in mental illness and addiction research because these conditions affect cognition, emotion, motivation, behavior, and self-governance of potential participants. Importantly, some of these ethical issues are amenable to empirical study, which can yield valuable insights and evidence-informed practices that strengthen and enable ethically sound human brain investigation. The overarching goal of this proposal is thus to accelerate neuroscience toward lessening the burden of mental illness and addiction through hypothesis-driven empirical ethics inquiry in three parts. First, we determine the distinct ethical issues and problems encountered in innovative neuroscience related to mental illness and addiction through semi-structured interviews with neuroscientists, neuroethicists, and institutional review board members. Informed by our past work and grounded in a rigorous conceptual model, we examine factors both negative and positive that influence research decisionmaking by people with mental illness and addiction in the context of innovative neuroscience research, and compare their decisionmaking with that of individuals with diabetes and healthy controls. Finally, we develop a new, low-burden screening tool to tailor and enhance the safeguard of informed consent in brain research, providing investigators with a practical, actionable, and protocol-adaptable method for strengthening positive-valence factors and ameliorate negative-valence factors affecting participant decisionmaking. Maximizing our established record of expertise in empirical ethics investigations and neuroethics, this sequence of projects leverages access to the exceptional neuroscience research conducted at Stanford University, including work by BRAIN initiative investigators; provides extensive, systematically collected data on influences on decisionmaking about innovative neuroscience research participation by individuals with mental or physical illness and healthy controls; and develops a new evidence-informed tool for use as a best practice in safeguarding human volunteers in cutting-edge neuroscience. Innovative neuroscience holds extraordinary promise for improving understanding of brain disorders that threaten human health, but as the BRAIN 2025 Scientific Vision notes, new ethical questions are emerging as scientists begin to solve the mysteries of the brain. A rigorous, hypothesis-driven approach to ethical dimensions of neuroscience inquiry is needed to provide investigators, IRBs, policymakers, and the public with evidence to better enable ethical participation in brain research. We develop new knowledge and a novel tool for use as a best practice in safeguarding volunteers in innovative neuroscience research, to ensure ethical participation, enhance trust in science, and accelerate discovery.",Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain,9741540,R01MH114856,"['Achievement', 'Affect', 'Artificial Intelligence', 'Base of the Brain', 'Behavior', 'Behavioral', 'Big Data', 'Brain', 'Brain Diseases', 'Cell model', 'Clinical Research', 'Cognition', 'Collection', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Ecology', 'Effectiveness', 'Emotions', 'Ensure', 'Ethical Issues', 'Ethics', 'Failure', 'Fostering', 'Fright', 'Genes', 'Goals', 'Gold', 'Health', 'Human', 'Human Genome Project', 'Human Volunteers', 'In Vitro', 'Individual', 'Informed Consent', 'Institutional Review Boards', 'Interview', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Motivation', 'Negative Valence', 'Neurosciences', 'Neurosciences Research', 'Participant', 'Personhood', 'Positive Valence', 'Process', 'Protocols documentation', 'Psyche structure', 'Public Health', 'Request for Applications', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Scientist', 'Screening procedure', 'Series', 'Societies', 'Structure', 'Surveys', 'Testing', 'Theoretical model', 'Translations', 'Trust', 'Universities', 'Vision', 'Work', 'addiction', 'base', 'brain machine interface', 'brain research', 'clinical care', 'decision research', 'design', 'evidence base', 'health disparity', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative neurotechnologies', 'insight', 'member', 'neuroethics', 'neuropsychiatry', 'neuroregulation', 'new technology', 'novel', 'optogenetics', 'patient engagement', 'prevent', 'programs', 'sound', 'standard measure', 'tool', 'vaccine development', 'volunteer']",NIMH,STANFORD UNIVERSITY,R01,2019,459850,0.008688715667479703
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9694688,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'connectome data', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genetic architecture', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,450954,-0.009243170508472029
"Boston University CCCR OVERALL ABSTRACT The Boston University CCCR will serve as a central resource for clinical research focused mostly on the most common musculoskeletal disorders, osteoarthritis and gout and will also provide research resources for investigator based research in scleroderma, spondyloarthritis, musculoskeletal pain and osteoporosis. Center grant funding has supported 30-35 papers annually in peer reviewed journals, most in the leading arthritis journals and some in leading general medical journals. This center has trained many of the leading clinical researchers in rheumatology throughout the US and internationally, and many of these former trainees have active collaborations with the center. We will include a broad research community and a core group of faculty in this CCCR. The research community's ready access to core faculty and to the sophisticated research methods and assistance they provide will enhance the clinical and translational research of the community and will increase collaborative opportunities for the core faculty and the community. The CCCR updates BU's historical focus on epidemiologic methods to include new approaches to causal inference and adds new methods in machine learning and mobile health. The Research and Evaluation Support Core Unit (RESCU) is the focal point of this CCCR. A key feature is the weekly research (RESCU meetings in which ongoing and proposed research projects are critically evaluated. This feature ensures frequent interactions between clinician researchers, epidemiologists and biostatisticians who are the core members of the CCCR. The RESCU core unit has provided critical support for other Center grants related to rheumatic and arthritic disorders at Boston University, three current R01/U01's; five current NIH K awards (one K24, 3 K23's, one K01), an R03, an NIH trial planning grant (U34), and multiple ACR RRF awards. The overall goal of this center is to carry out and disseminate high-level clinical research informed both by state of the art clinical research methods and by clinical and biological scientific discoveries. Ultimately, we aim either to prevent the diseases we are studying or to improve the lives of those living with the diseases. NARRATIVE The Boston University Core Center for Clinical Research will provide broad clinical research methods expertise to a large multidisciplinary group of investigators whose research focuses on osteoarthritis and gout with a secondary emphasis on scleroderma, spondyloarthritis, osteoporosis and musculoskeletal pain. The group, which includes persons with backgrounds in rheumatology, physical therapy, epidemiology, biostatistics and  . behavioral science, meets weekly to critically review research projects and serves a broad research community with which it actively engages. It has been successful in publishing influential papers on the diseases of focus and in training many of the clinical research faculty in the US and internationally",Boston University CCCR,9851583,P30AR072571,"['Allied Health Profession', 'Area', 'Arthritis', 'Award', 'Behavioral Sciences', 'Biological', 'Biometry', 'Boston', 'Clinical', 'Clinical Research', 'Cohort Studies', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consultations', 'Databases', 'Degenerative polyarthritis', 'Disease', 'Ensure', 'Environment', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Europe', 'Evaluation', 'Excision', 'Faculty', 'Funding', 'Goals', 'Gout', 'Grant', 'Health', 'Influentials', 'Infusion procedures', 'Institutes', 'Institution', 'International', 'Journals', 'K-Series Research Career Programs', 'Machine Learning', 'Medical', 'Medical Research', 'Medical center', 'Methods', 'Musculoskeletal Diseases', 'Musculoskeletal Pain', 'New England', 'Osteoporosis', 'Outcome', 'Pain', 'Paper', 'Peer Review', 'Persons', 'Physical therapy', 'Privatization', 'Productivity', 'Public Health Schools', 'Publications', 'Publishing', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rheumatism', 'Rheumatology', 'Risk Factors', 'Schools', 'Scleroderma', 'Spondylarthritis', 'Talents', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'cohort', 'design', 'epidemiology study', 'faculty community', 'faculty research', 'improved', 'innovation', 'interdisciplinary collaboration', 'learning strategy', 'mHealth', 'medical schools', 'meetings', 'member', 'multidisciplinary', 'novel', 'novel strategies', 'patient oriented', 'prevent', 'programs', 'protocol development', 'statistical service', 'success']",NIAMS,BOSTON UNIVERSITY MEDICAL CAMPUS,P30,2019,741688,-0.03976403182792195
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",9882865,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2019,340827,-0.015009788696709067
"BRAIN INITIATIVE RESOURCE: DEVELOPMENT OF A HUMAN NEUROELECTROMAGNETIC DATA ARCHIVE AND TOOLS RESOURCE (NEMAR) To take advantage of recent and ongoing advances in intensive and large-scale computational methods, and to preserve the scientific data created by publicly funded research projects, data archives must be created as well as standards for specifying, identifying, and annotating deposited data. The value of and interest in such archives among researchers can be greatly increased by adding to them an active computational capability and framework of analysis and search tools that support further analysis as well as larger scale meta-analysis and large scale data mining. The OpenNeuro.org archive, begun as a repository for functional magnetic resonance imaging (fMRI) data, is such an archive. We propose to build a gateway to OpenNeuro for human electrophysiology data (EEG and MEG, as well as intracranial data recorded from clinical patients to plan brain surgeries or other therapies) – herein we refer to these modalities as neuroelectromagnetic (NEM) data. The Neuroelectromagnetic Data Archive and Tools Resource (NEMAR) at the San Diego Supercomputer Center will act as a gateway to OpenNeuro for NEM data research. Such data uploaded to NEMAR at SDSC will be deposited in the OpenNeuro archive. Still- private NEM data in OpenNeuro will, on user request, be copied to the NEMAR gateway for further user processing using the XSEDE high-performance resources at SDSC in conjunction with The Neuroscience Gateway (nsgportal.org), a freely available and easy to use portal to use of high-performance computing resources for neuroscience research. Publicly available OpenNeuro NEM data will be able to be analyzed by running verified analysis applications on the OpenNeuro system. In this project we will build an application to evaluate the quality of uploaded NEM data, and another to visualize the data, for EEG and MEG at both the scalp and brain source levels, including time-domain and frequency-domain dynamics time locked to sets of experimental events learned from the BIDS- and HED-formatted data annotations. The NEMAR gateway will take a major step toward applying machine learning methods to a large store of carefully collected and stored human electrophysiologic brain data to spur new developments in basic and clinical brain research. The NEMAR gateway to the OpenNeuro.org human neuroimaging data archive will build tools to add human electrical and magnetic brain activity records to the archive, to evaluate its quality for users and visualize its features. The resulting facility will allow applications of new machine learning methods to research on human brain dynamics that can be expected to lead to breakthroughs in understanding how the human brain supports our awareness and behavior in both health and disease.",BRAIN INITIATIVE RESOURCE: DEVELOPMENT OF A HUMAN NEUROELECTROMAGNETIC DATA ARCHIVE AND TOOLS RESOURCE (NEMAR),9795341,R24MH120037,"['Archives', 'Awareness', 'BRAIN initiative', 'Base of the Brain', 'Behavior', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Clinical', 'Cloud Computing', 'Communities', 'Computing Methodologies', 'Custom', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Data Storage and Retrieval', 'Deposition', 'Descriptor', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Educational workshop', 'Electrophysiology (science)', 'Engineering', 'Environment', 'Evaluation', 'Event', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Grant', 'Health', 'High Performance Computing', 'Human', 'Infrastructure', 'Internet', 'Laboratories', 'Lead', 'Libraries', 'Machine Learning', 'Magnetic Resonance', 'Magnetism', 'Magnetoencephalography', 'Meta-Analysis', 'Methods', 'Mining', 'Modality', 'Neurosciences', 'Neurosciences Research', 'Patients', 'Performance', 'Privatization', 'Process', 'Quality Control', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Running', 'Scalp structure', 'Science', 'Source', 'Specific qualifier value', 'Spottings', 'Staging', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Visualization software', 'base', 'brain research', 'brain surgery', 'built environment', 'computational platform', 'computerized data processing', 'computing resources', 'cyber infrastructure', 'data archive', 'data format', 'data mining', 'data structure', 'data submission', 'hackathon', 'interest', 'learning strategy', 'neuroimaging', 'preservation', 'repository', 'response', 'sensor', 'supercomputer', 'support tools', 'tool', 'tool development', 'web interface', 'web services', 'web site']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R24,2019,926107,0.016432361108965444
"Acquisition of a next-generation computing cluster We request funds to purchase our next-generation computing cluster to support computationally intensive NIH-funded research at Washington University in St. Louis. This system will become the foundation of the Center for High Performance Computing (CHPC) to support our active, diverse user community. It has been designed to meet our current and future computing needs. It adds additional capabilities to support emerging fields such as “Deep Learning”. The CHPC currently supports over 775 users from 300 different groups across 33 departments. 58 papers have cited the CHPC. The Center has a proven funding model and is economically sustainable. The Center has partnered with other University organizations to offer training workshops, not only on the use of the cluster, but also on introductory programming for users with no prior programming experience. If this proposal is funded, we will be able to continue to support this ever-growing diverse community of researchers. The proposed system would replace critical components including the management node, the login nodes, the storage, and upgrade the Infiniband networking. We would add substantial upgrades to our computing power with state-of-the-art processors, increased memory capacity for growing jobs, General Purpose Graphical Processing units (GPGPUs), and new capabilities for “Deep Learning”. Nearly all fields of NIH-funded research are faced with increasingly large data sets that require additional computing power to analyze. We propose building a next-generation computing cluster to support this research. Our Center has a proven track record in supporting a large, diverse group of users in all aspects of their computationally demanding research.",Acquisition of a next-generation computing cluster,9707936,S10OD025200,"['Communities', 'Educational workshop', 'Foundations', 'Funding', 'Future', 'High Performance Computing', 'Memory', 'Modeling', 'Occupations', 'Paper', 'Research', 'Research Personnel', 'System', 'Training', 'United States National Institutes of Health', 'Universities', 'Washington', 'cluster computing', 'deep learning', 'design', 'experience', 'next generation']",OD,WASHINGTON UNIVERSITY,S10,2019,597200,-0.0003846532058368303
"Dynamics of long range network interactions  in focal epilepsy PROJECT SUMMARY Epilepsy is the world’s most prominent serious brain disorder, affecting nearly 50 million people worldwide. For about 30% of these patients, seizures remain poorly controlled despite optimal medical management, with attendant effects on health and quality of life. In order to enable advances in the therapeutic management of epilepsy, a thorough understanding of how cellular processes that drive seizures are linked to large-scale network effects is needed. While seizures impact large brain areas and often multiple lobes, the driving processes span regions on the scale of millimeters. These have been well characterized in animal models, but the relevance to human seizures, i.e. how seizures are driven by brain signals from small-scale processes remains unclear. Instead, the view that naturally-occurring seizures may be attributable instead to large-scale neural mass effects (i.e., the epileptic network) is a subject of ongoing debate. Previously, we defined a key role for surround inhibition in shaping EEG recordings of seizures at the onset site and on small spatial scales. We now propose that surround inhibition has a dual role. On a millimeter scale, its abrupt failure permits the advance of a seizure. At long distances from the seizure focus, strong local inhibition serves to mask the excitatory effects of seizures and may help to hasten seizure termination, while weakened inhibition may permit emergence of ictal activity at a distant, noncontiguous seizure site. Multiple seizure foci may go unrecognized with standard EEG interpretation methods, and are likely a critical factor in epilepsy surgery failures. We hypothesize that once established, multiple ictal generators behave as delay-coupled oscillators, demonstrating activity that is synchronized or even temporally reversed. This results in complex and at times counterintuitive network behavior that can be challenging to reverse engineer from EEG recordings. Typically, however, even intracranial EEG recordings provide only a limited view of neural activity. In this project, an interdisciplinary research group with combined expertise in epilepsy, clinical neurophysiology, computational modeling, and mathematics will conduct a comprehensive study of the neuronal contributors to epileptic networks utilizing a unique combined dataset of simultaneous microelectrode and macroelectrode recordings of human seizures. Using a machine learning approach, we will apply this information to develop a multivariate EEG biomarker based on the inferred source of EEG discharges, high frequency oscillations, and very low frequency (DC) shifts and assess its predictive value for post-resection surgical outcome. We anticipate that the project will lead to a theoretical framework for rational development of innovative strategies for developing interventions to control seizures. PROJECT NARRATIVE This project aims to identify the cellular mechanisms of epileptic networks, a critical barrier to developing treatments based on epileptic network analysis and manipulation. An interdisciplinary team of researchers will address this problem by analyzing and modeling multiscale voltage data from epilepsy patients, and utilizing the results to develop a new multivariate biomarker for seizure-generating brain areas.",Dynamics of long range network interactions  in focal epilepsy,9792276,R01NS084142,"['Address', 'Affect', 'Animal Model', 'Area', 'Automobile Driving', 'Award', 'Behavior', 'Biological Markers', 'Biophysics', 'Brain', 'Brain Diseases', 'Cell physiology', 'Clinical', 'Collection', 'Complement', 'Complex', 'Computer Simulation', 'Coupled', 'Data', 'Data Set', 'Decision Making', 'Development', 'Distant', 'Electroencephalography', 'Electrophysiology (science)', 'Engineering', 'Epilepsy', 'Event', 'Excision', 'Failure', 'Focal Seizure', 'Foundations', 'Frequencies', 'Generations', 'Goals', 'Health', 'High Frequency Oscillation', 'Human', 'Impact Seizures', 'In Vitro', 'Incidence', 'Interdisciplinary Study', 'Intervention', 'Link', 'Lobe', 'Location', 'Machine Learning', 'Masks', 'Mathematics', 'Medical', 'Methods', 'Microelectrodes', 'Monitor', 'Neurons', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Pathologic', 'Pathway Analysis', 'Patients', 'Predictive Value', 'Procedures', 'Process', 'Quality of life', 'Research Personnel', 'Role', 'Sampling', 'Seizures', 'Shapes', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Study models', 'Techniques', 'Terminology', 'Testing', 'Therapeutic', 'Time', 'Travel', 'Universities', 'Weight', 'base', 'improved', 'innovation', 'millimeter', 'minimally invasive', 'multi-scale modeling', 'neurophysiology', 'parallel computer', 'relating to nervous system', 'surgery outcome', 'voltage']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,613085,-0.013778479939248502
"Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets Project Summary During the past three decades non-invasive functional brain imaging has developed immensely in terms of measurement technologies, analysis methods, and innovative paradigms to capture information about brain function both in healthy and diseased individuals. Although functional MRI (fMRI) has become very useful, it only provides indirect information about neuronal activity through the neurovascular coupling with a limited temporal resolution. Magnetoencephalography (MEG) and electroencephalography (EEG) remain the only available noninvasive techniques capable of directly measuring the electrophysiological activity with a millisecond resolution. During the past eight years we have developed, with NIH support, the MNE-Python software, which covers multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. To further extend our software to meet the needs of a growing user base and reflect recent developments in the MEG/EEG field we will pursue three specific Aims. In Aim 1 we will: (i) Create an all-embracing suite of noise cancellation tools incorporating and extending methods present in different MEG systems; (ii) Implement device independent methods for head-movement determination and compensation on the basis of head movement data recorded during a MEG session; (iii) Develop methods for automatic tagging of artifacts using machine learning approaches. In Aim 2 our focus is to extend the software to make modern distributed computing resources easily usable in processing and to allow for remote visualization without the need to move large amounts of data across the network. Finally, in Aim 3, we will continue to develop MNE-Python using best programming practices ensuring multiplatform compatibility, extensive web-based documentation, training and forums, and hands-on training workshops. As a result of these developments the MNE-Python will be able to effectively process large number of subjects and huge amounts data ensuing and from multi-site studies harmoniously across different MEG/EEG systems. Narrative MEG and EEG can be used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. However, widespread use of these methods especially in large populations has been problematic because of the lack of well-established analysis approaches, which map the sensor data into the brain space for detailed temporal, spatial, and connectivity analysis. This research will provide well-documented and tested novel analysis software to promote both basic neuroscience and clinical research applications using MEG and EEG.",Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets,9750274,R01NS104585,"['Adult', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Brain imaging', 'Brain region', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Collaborations', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Databases', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Documentation', 'Ecosystem', 'Educational workshop', 'Electroencephalography', 'Electrophysiology (science)', 'Ensure', 'Epilepsy', 'Experimental Designs', 'Financial compensation', 'Functional Magnetic Resonance Imaging', 'Guidelines', 'Head', 'Head Movements', 'Hour', 'Human', 'Imagery', 'Individual', 'Laboratories', 'Language Development', 'Link', 'Machine Learning', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modernization', 'Morphologic artifacts', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Population', 'Process', 'Pythons', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Schizophrenia', 'Science', 'Scientist', 'Site', 'Statistical Data Interpretation', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visualization software', 'Writing', 'analysis pipeline', 'autism spectrum disorder', 'base', 'cloud based', 'cluster computing', 'computing resources', 'data acquisition', 'falls', 'human data', 'innovation', 'millisecond', 'multithreading', 'neurovascular coupling', 'novel', 'open source', 'pedagogy', 'sensor', 'sensor technology', 'software development', 'source localization', 'symposium', 'temporal measurement', 'tool', 'verification and validation']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,543993,0.017859509531928452
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,9882822,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2019,390806,0.01904933802897463
"Brain-wide quantitative mapping of microglia activation SUMMARY Recent technological developments such as tissue clearing and light sheet imaging have allowed for the three- dimensional visualization of the entire brain at cellular resolution. Translucence Biosystems has advanced this technology further by developing a) a proprietary Mesoscale Imaging System that allows visualization of an entire mouse brain much faster than prior techniques, b) machine learning-based algorithms that identify individual cells across the entire intact mouse brain and c) routines that rapidly determine cell densities in >1,200 brain regions defined by the annotated Allen Brain Atlas.  In the present proposal we will show the power of our technique by visualizing microglia density across the entire mouse brain as a biological marker for neuroinflammation. Microglia are the resident immune cells in the brain. While they play important roles in healthy brain function, they also mediate neuroinflammatory processes that have a significant impact in multiple neurodegenerative diseases such as Alzheimer's, Parkinson's, and multiple sclerosis as well as play possible roles in several neurodevelopmental and neurological disorders (e.g., schizophrenia, autism spectrum disorder, chemo brain). A tool for three-dimensional imaging of neuroinflammation patterns across the whole brain will help advance our understanding of neuroinflammatory processes in neurological diseases and aid in the evaluation of therapeutic approaches.  To visualize microglia, we will evaluate multiple strategies, including the CX3CR1-GFP mouse line, which expresses GFP in microglia, Iba1 immunolabeling and other antibody markers of activated microglia. The utility of our approach for monitoring neuroinflammation will be demonstrated in CX3CR1-GFP mice by treating them with the inflammatory agent lipopolysaccharide (LPS). Mice will be injected with three different LPS doses, and then microglia will be visualized and automatically counted across >1,200 brain regions. We will confirm the neuroinflammatory response to LPS by measuring protein markers of inflammation.  The applicability of our technique to neurodegenerative disease will be demonstrated by studying a mouse line used as a model of Alzheimer's disease that presents pronounced patterns of neuroinflammation. These experiments are designed to prove that our approach can provide reliable and detailed information describing neuroinflammation and that our results are better in terms of speed, resolution, and richness of information than any other technique available.  Once the goals for Phase I are met, we will be positioned to develop our microglia activation assay into a new gold standard for precise and complete histological detection of neuroinflammation. During phase II, we plan to 1) develop machine learning tools to establish morphological criteria that differentiate resting from activated microglia, 2) characterize microglial signatures in various mouse models of diseases with known or suspected neuroinflammation components, and 3) validate the microglial targeting of anti-inflammatory therapeutic candidates. NARRATIVE Microglia, the resident immune cells of the brain, protect against injury and infection. Microglia also play a critical role in dysfunctional neuroinflammatory processes that contribute to the development of brain diseases. We have developed novel methods to make mouse brains transparent so we can visualize and precisely count microglia throughout the intact mouse brain. In this proposal, we will test the feasibility of measuring brain-wide microglia activation using two disease models with a strong neuroinflammatory component, including a common transgenic mouse model that recapitulates the amyloid plaque accumulation that is a central feature of Alzheimer’s Disease.",Brain-wide quantitative mapping of microglia activation,9908302,R43MH122070,"['AIDS dementia', 'Affect', 'Aftercare', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Amyloid', 'Amyloid beta-Protein', 'Amyloid deposition', 'Anti-inflammatory', 'Antibodies', 'Atlases', 'Biological Assay', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain region', 'Cell Density', 'Cells', 'Deposition', 'Detection', 'Development', 'Dimensions', 'Disease model', 'Dose', 'Encephalitis', 'Evaluation', 'Exhibits', 'Genes', 'Genetic Transcription', 'Goals', 'Gold', 'Histologic', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging Techniques', 'Immune', 'Individual', 'Infection', 'Inflammation', 'Inflammatory', 'Injury', 'Label', 'Light', 'Lipopolysaccharides', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Microglia', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Multiple Sclerosis', 'Mus', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Parkinson Disease', 'Pathologic', 'Pathology', 'Pattern', 'Phase', 'Phenotype', 'Physical shape', 'Play', 'Positioning Attribute', 'Process', 'Proliferating', 'Property', 'Protocols documentation', 'Publishing', 'Resolution', 'Rest', 'Role', 'Schizophrenia', 'Senile Plaques', 'Site', 'Speed', 'Stains', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Transgenic Mice', 'Traumatic Brain Injury', 'abeta deposition', 'autism spectrum disorder', 'base', 'brain cell', 'chemobrain', 'cytokine', 'density', 'design', 'experimental study', 'imaging Segmentation', 'imaging system', 'improved', 'in vitro Assay', 'in vivo', 'inflammatory marker', 'interest', 'mouse model', 'nervous system disorder', 'neuroinflammation', 'novel', 'protein biomarkers', 'response', 'selective expression', 'therapeutic candidate', 'therapeutic evaluation', 'tool']",NIMH,"TRANSLUCENCE BIOSYSTEMS, INC.",R43,2019,449956,-0.010968661405736877
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,434944,-0.013180015535181843
"SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions  The project will investigate prosthetic support for people with visual impairment (PVI) that integrates computer vision-based prosthetics with video-mediated human-in-the-loop prosthetics. Computer vision- based (CV) prosthetics construe the fundamental technical challenge for visual prosthetics as one of parsing and identifying objects across scales, distances, and orientations. Visual prosthetic applications have been central drivers in the development of computer vision technology through the past 50 years. Video-mediated remote sighted assistance (RSA) prosthetics are more recent, enabled by different technologies, and construe the orienting technical challenge for visual prosthetics as one of effective helping interactions. RSA services are commercially available now, and have evoked much excitement in the PVI community. The two approaches, CV and RSA, will be successively integrated through a series of increasingly refined Wizard of Oz simulations, and investigate possible synergies between the two approaches. We will employ a human-centered design approach, identifying a set of key assistive interaction scenarios that represent authentic needs and concerns of PVIs, by leveraging our 6-year relationship working directly with our local chapter of the National Federation of the Blind. RELEVANCE (See Instructions): 23.7 million American adults have vision loss; 1.3 million people in US are legally blind. This project addresses a transformational opportunity to enhance human performance and experience, to diversify workplace participation, and to enhance economic and social well-being. n/a",SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions ,9928587,R01LM013330,"['Address', 'Adult', 'American', 'Articulation', 'Back', 'Blindness', 'Communities', 'Computer Vision Systems', 'Computers', 'Data Set', 'Development', 'Economics', 'Emotional', 'Female', 'Goals', 'Human', 'Information Sciences', 'Instruction', 'Mediating', 'Modeling', 'Ocular Prosthesis', 'Performance', 'Prosthesis', 'Route', 'Self-Help Devices', 'Series', 'Services', 'Social Well-Being', 'Technology', 'Time', 'Underrepresented Students', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'design', 'experience', 'graduate student', 'human-in-the-loop', 'learning materials', 'legally blind', 'outreach', 'prototype', 'simulation', 'synergism', 'undergraduate student']",NLM,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2019,225147,0.010332293012671544
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9696381,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Mobile Health Application', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'recruit', 'responsible research conduct', 'scale up', 'sensor', 'sensor technology', 'skills', 'smart home', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2019,150529,0.00638527787440669
"Continued Development of Infant Brain Analysis Tools Continued Development of Infant Brain Analysis Tools Abstract: The increasing availability of infant brain MR images, such as those that will be collected through the Baby Connectome Project (BCP, on which Dr. Shen is a Co-PI, focusing on data acquisition), affords unprecedented opportunities for precise charting of dynamic early brain developmental trajectories in understanding normative and aberrant growth. However, to fully benefit from these datasets, a major barrier that needs to be overcome is the critical lacking of computational tools for accurate processing and analysis of infant MRI data, which typically exhibit poor tissue contrast, large within tissue intensity variation, and regionally-heterogeneous and dynamic changes. To fill this critical gap, in 2012 we pioneered in creating an infant-centric MRI processing software package, called infant Brain Extraction and Analysis Tool (iBEAT), and a set of infant-specific atlases, called UNC 0-1-2 Infant Atlases, and further made them freely and publicly available via NITRC. Over the last 4 years, iBEAT and UNC 0-1-2 Infant Atlases have been downloaded 2900+ and 5600+ times, respectively, and contributed to 160+ independent research papers. As indicated by 30+ support letters, iBEAT is now driving the research for MRI studies of early brain development in many labs throughout the world. Results produced by iBEAT are also highlighted in the National Institute of Mental Health (NIMH)'s 2015-2020 Strategic Plan. This project is dedicated to the continuous development, hardening, and dissemination of iBEAT, by developing innovative software modules with comprehensive user support. To achieve this goal, we propose four aims. In Aim 1, we will create an innovative learning-based multi-source information integration framework for joint skull stripping and tissue segmentation for accurate structural measurements. Our method employs random forest to adaptively learn the optimal image appearance features from multimodality images and also informative context features from tissue probability maps. In Aim 2, we will construct longitudinal infant brain atlases at multiple time points (i.e., 1, 3, 6, 9, and 12 months of age) for both T1-/T2-weighted and diffusion-weighted MR images. We propose a longitudinally-consistent sparse representation technique to construct representative atlases with significantly improved structural details by explicitly dealing with possible misalignments between images even after registration. In Aim 3, we will develop a novel learning-based approach for cortical topology correction and integrate it, along with our infant-centric analysis tools and atlases for cortical surfaces, into iBEAT for precise mapping of dynamic and complex cortical changes in infants. Unlike existing tools that perform poorly for infant brains, we will incorporate infant-dedicated tools for topology correction, surface reconstruction, registration, parcellation, and measurements. We will further integrate longitudinal infant cortical surface atlases equipped with parcellations based on growth trajectories. In Aim 4, we will significantly enhance iBEAT in terms of its software functionalities as well as user support via systematic outreach and training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC. Project Narrative This project is dedicated to the continuous development, hardening, and dissemination of iBEAT by developing innovative software modules with comprehensive user support. In particular, we propose four aims: 1) Learning-Based Brain Segmentation; 2) Infant Brain Atlases in the First Year of Life; 3) Cortical Surface-Based Analysis; and 4) Enhancing User Experience and Training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC.",Continued Development of Infant Brain Analysis Tools,9755508,R01MH117943,"['2 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Appearance', 'Atlases', 'Automobile Driving', 'Base of the Brain', 'Brain', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Documentation', 'Education and Outreach', 'Environment', 'Exhibits', 'Goals', 'Growth', 'Human', 'Image', 'Infant', 'Infant Development', 'Joints', 'Label', 'Learning', 'Letters', 'Life', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Methods', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurodevelopmental Disorder', 'Online Systems', 'Paper', 'Play', 'Probability', 'Process', 'Publications', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Series', 'Shapes', 'Software Tools', 'Source', 'Speed', 'Strategic Planning', 'Structure', 'Surface', 'T2 weighted imaging', 'Techniques', 'Time', 'Tissues', 'Training', 'Variant', 'adaptive learning', 'base', 'computerized tools', 'connectome', 'cranium', 'critical period', 'data acquisition', 'diffusion weighted', 'experience', 'file format', 'gray matter', 'imaging modality', 'imaging study', 'improved', 'innovation', 'interoperability', 'novel', 'postnatal', 'random forest', 'reconstruction', 'tool', 'white matter']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,465334,-0.013653895468994039
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9783829,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Eye', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'brain dysfunction', 'career', 'clinical database', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistics', 'symposium', 'tool', 'usability']",NIEHS,VANDERBILT UNIVERSITY,K22,2019,202477,-0.00726623171065115
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,9862231,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Comorbidity', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2019,450365,-0.007998373683279537
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning There is an enormous need for qualified people to pursue careers in STEM (Noonan, 2017). However, the lack of a strong foundation in mathematics means students are less likely to pursue STEM majors and careers (Chen, 2013; Griffith, 2010; Huang, Taddese, & Walter, E, 2000; Kokkelenberg & Sinha, 2010; Lowell et. al., 2009). Students from low-income families, women, and underrepresented minorities are also less likely to major in STEM (Bettinger, 2010; Griffith, 2010; Hill, Corbett & Rose, 2010; Kokkelenberg & Sinha, 2010). Improving math learning in the elementary grades is important to ensure children have the essential foundational skills and strong self-efficacy beliefs to be able to succeed with later mathematics and pursue careers in STEM. With this Fast-Track grant, Class Store ( CS ) , we propose to transform the way in which students learn Number and Operations in Base Ten. CS will be an engaging, commercially available, classroom-based economy game for tablets and Chromebooks that focuses on multi-digit operations. CS will encourage conceptual understanding and build math self-efficacy for students in grades K-5 within the context of a digital, classroom-based marketplace. Within the game, students will create stores, craft objects to sell, engage in selling/purchasing transactions, and work together to increase the value of the economy. In addition, the game will utilize artificial intelligence (AI) to detect strategies students use and help teachers facilitate rich mathematical discussions thereby enhancing students’ reasoning skills. Outcomes. The proposal will encourage three main outcomes, namely: 1) algorithms for detecting math strategies students use, 2) a discussion support dashboard, and 3) algorithms for predicting at-risk status. A key research aim is to determine whether the software can predict math strategies students use and detect which students are at-risk academically as compared to standardized assessment data, which will help teachers intervene appropriately. The discussion support dashboard will help to promote rich mathematical discussion, thereby improving students’ mathematical justification and conceptual understanding. The engaging game will bolster students’ motivation and self-efficacy in mathematics. Improving students’ academic outcomes and self-efficacy in base ten during elementary school will promote later success in high school mathematics. Since the number of advanced math classes students take is correlated with likelihood to complete a STEM degree, (Chen, 2013) a distal outcome of this proposal is increasing students pursuing careers in STEM. There is an enormous need for students majoring in the fields of Science, Technology, Engineering and Mathematics (STEM), yet lacking a strong foundation in mathematics makes students, especially women, minorities and those from low-income backgrounds, less likely to pursue careers in STEM. Class Store will bolster students’ mathematics abilities, including mathematical reasoning and self-efficacy, in the foundational area of Number and Operations in Base 10 in the short and long term. This will, in turn, lead to several positive distal outcomes, such as increased STEM majors and careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9852112,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'STEM field', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2019,413898,0.00712518162373308
"EEGLAB: Software for Analysis of Human Brain Dynamics Electroencephalography (EEG), the first function brain activity imaging modality, has several natural advantages over metabolic brain imaging modalities. EEG is noninvasive, low cost, and lightweight enough to be highly mobile. Two major shifts in scientific perspective on the nature and use of human electrophysiological data are now ongoing. The first is a shift to using EEG data as a source-resolved, relatively high-resolution cortical source imaging modality. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) of the University of California, San Diego (UCSD), began as a set of EEG data analysis running on Matlab (The Mathworks, Inc.) released by Makeig on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now nearly twenty years later, the EEGLAB reference paper [4] has over 6,750 citations (now increasing by over 4 per day), the opt-in EEGLAB discussion email list links 6,000 researchers, the EEGLAB news list over 15,000 researchers, and an independent 2011 survey of 687 research respondents reported EEGLAB to be the software environment most widely used for electrophysiological data analysis in cognitive neuroscience. Our statistics show that after over the past four years, EEGLAB adoption is still growing steadily. Here, we will develop a framework for thorough comparison of preprocessing methods, and will apply machine learning methods on the large body of data collected by our laboratory to build optimized, automated data processing pipelines. We will greatly augment the power of the EEGLAB environment by providing a cross-study meta-analysis capability and will revise the software architecture to use a file and metadata organization compatible with the Brain Imaging Data Structure (BIDS) framework first developed for fMRI/MRI data archiving. These tools will integrate the HED annotating system allowing for meta-analysis across large corpus of studies. We will implement beamforming within EEGLAB. We will develop a hierarchical Bayesian framework for clustering effective sources on multiple measures across subjects and studies, and will develop tools to perform statistical testing on information flow measures at these scales. Although EEG and MEG recording have co- existed for four decades, little available software can combine both data types, recorded concurrently (`MEEG' data), to enhance source separation. We recently showed that ICA decomposition also allows joint MEEG effective source decomposition and will integrate MEG and joint MEEG data decomposition and imaging into the EEGLAB tool set. We will build tools to use MRI- and fMRI-derived anatomical atlases to inform the interpretation of EEG and MEG brain source dynamics. These radical improvements will further the use of non-invasive human electrophysiology for 3-D functional cortical brain imaging in the U.S. and worldwide, thereby accelerating progress in noninvasive basic and clinical human brain research using highly time- and space-resolved measures of brain electromagnetic dynamics. The EEGLAB signal processing environment is now used in many electrophysiological research and teaching laboratories worldwide. To accelerate progress in basic and clinical cognitive neuroscience, we will continue maintenance and development of the EEGLAB environment, introducing new tools for source separation and localization, source clustering, automatic artifact management, and across-studies meta-analysis, and will extend its scope to process magnetoencephalographic (MEG) and joint EEG/MEG data and to highlight parallels between EEG/MEG source dynamics and results of existing research using fMRI and other brain imaging.",EEGLAB: Software for Analysis of Human Brain Dynamics,9737997,R01NS047293,"['3-Dimensional', 'Adoption', 'Anatomy', 'Architecture', 'Atlases', 'Automatic Data Processing', 'Automation', 'Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Classification', 'Clinical', 'Code', 'Cognitive', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Documentation', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Health', 'Human', 'Image', 'Infrastructure', 'Institutes', 'Internet', 'Joints', 'Laboratories', 'Learning', 'Link', 'Links List', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Measures', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Nature', 'Neurosciences', 'Newsletter', 'Paper', 'Plug-in', 'Process', 'Psyche structure', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Source', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Work', 'automated analysis', 'base', 'brain research', 'central database', 'cognitive neuroscience', 'computational neuroscience', 'cost', 'data archive', 'data structure', 'data visualization', 'design', 'experience', 'graphical user interface', 'imaging modality', 'independent component analysis', 'interest', 'learning strategy', 'light weight', 'mathematical methods', 'news', 'novel strategies', 'online course', 'open source', 'research study', 'response', 'signal processing', 'statistics', 'support tools', 'teaching laboratory', 'tool', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,593300,0.018582680654902393
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,9864664,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2019,269849,-0.0166237765800646
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",9789280,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Stream', 'Structure', 'System', 'Techniques', 'Time', 'Work', 'base', 'computer science', 'computerized tools', 'data modeling', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,21171,-0.00838290393977232
"Expert Guiding Technology to Help Individuals with Developmental Challenges Build Life and Vocational Skills Applied Behavior Analysis (ABA) remains the most effective and scientifically-validated approach to remediate the deficits due to Autism Spectrum Disorders (ASD) and intellectual disabilities (ID). There are serious challenges in delivering effective ABA: unavailability of effective treatment in many places; high instructor turnover; loss of program fidelity due to complexity and instructor variability; onerous data collection that directs attention away from the learner; and the time sink of creating required reports and charts that steals time away from instructional activities. A software platform named GAINS (Guidance, Assessment and Information System) is being developed that uniquely incorporates artificial intelligence to overcome problems in delivering ABA. GAINS is powered by expert guiding software that incorporates knowledge of ABA practice and curricula personalized for the individual with developmental challenges. Like Google Maps that guides you step-by-step and updates as you go along, GAINS guides instructors and caregivers and adapts to client responses on the fly. In this way, expert guiding technology reduces a priori training requirements in ABA while providing real- time apprenticeship coaching to overcome variability in instructor experience and improve program fidelity. Improved program fidelity promotes better learning outcomes of individuals with ASD and ID. The project will evaluate and iteratively innovate expert guiding technology to support the powerful, but difficult to implement, ABA technique of Task Analysis (TA). There are two overarching aims: 1) conduct scientifically-valid, clinical trials to evaluate the efficacy of expert guiding technology to support instructors to better help individuals with developmental challenges due to ASD and ID learn life and vocational skills and use the results in Phase I to develop larger, more comprehensive clinical trials to be conducted in Phase II; and 2) use clinical trials in Phase I and Phase II to more effectively identify and prioritize iterative innovations in expert guiding technology as part of successive Design Science Research Cycles. Single Case Research Designs (SCRD) will be used to evaluate expert guiding technology interventions to support Task Analysis. SCRDs are a viable alternative to large group studies such as randomized clinical trials. Single case studies involve repeated measures, and manipulation of an independent variable. SCRD studies allow for rigorous experimental evaluation of intervention effects and provide a strong basis for establishing causal inferences. Advances in design and analysis techniques for SCRD have made SCRD studies increasingly popular in educational and psychological research. Chimes Delaware will be the site for clinical trials. Chimes Delaware is one of the largest providers of community services for adults with intellectual, autism, and co-occurring disabilities. The project team has worked together for many years and is uniquely qualified. If successful, the increase of scientifically-validated technical capabilities of expert guiding technology will profoundly affect clinical practice. The clinical trials proposed in this project will provide new scientific knowledge on the efficacy of expert guiding technology to overcome problems in delivering quality ABA therapy. Iterative innovations of expert guiding technology will greatly increase the technical capabilities. If successful, the increase of scientifically-validated technical capabilities of expert guiding technology will profoundly affect clinical practice.",Expert Guiding Technology to Help Individuals with Developmental Challenges Build Life and Vocational Skills,9846769,R43MH121230,"['Adoption', 'Adult', 'Affect', 'Artificial Intelligence', 'Behavior', 'Caregivers', 'Case Study', 'Child', 'Client', 'Clinical', 'Clinical Trials', 'Community Services', 'Complex', 'Computer software', 'Conduct Clinical Trials', 'Cues', 'Data', 'Data Collection', 'Decision Modeling', 'Delaware', 'Development', 'Educational Curriculum', 'Evaluation', 'Failure', 'Gold', 'Hand', 'Health', 'Individual', 'Information Systems', 'Instruction', 'Intellectual functioning disability', 'International', 'Intervention', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Maps', 'Measures', 'Names', 'Phase', 'Provider', 'Psychological reinforcement', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Science', 'Techniques', 'Technology', 'Theft', 'Time', 'Toothbrushing', 'Toothpaste', 'Training', 'Update', 'Work', 'applied behavior analysis', 'apprenticeship', 'autism spectrum disorder', 'base', 'board certified behavior analyst', 'clinical practice', 'clinical research site', 'cost effective', 'design', 'directed attention', 'disability', 'effective therapy', 'experience', 'field study', 'improved', 'innovation', 'innovative technologies', 'instructor', 'intervention effect', 'learning outcome', 'member', 'programs', 'psychologic', 'response', 'skills', 'task analysis']",NIMH,GUIDING TECHNOLOGIES CORPORATION,R43,2019,282159,-0.05102863126145772
"Understanding Action Selection in the Tool Use Network Project Summary: Skilled use of tools is a defining achievement of human cognition, and is enabled by the storage of tool-specific action memories. Many tools are associated with more than one action, and most everyday tasks are associated with more than one tool. Limb apraxia is a common, disabling, and puzzling left-hemisphere disorder characterized by prominent deficits in activating and selecting task-appropriate tool actions. Little is known about the cognitive mechanisms and brain regions enabling such selection in the neurologically intact brain, or how these processes go awry in apraxia. In several other cognitive domains, it has been suggested that appropriate response selection occurs via biased competition—that is, the prioritization of competing incoming information to enable appropriate response selection. Capitalizing on the promise of such frameworks, we have developed a new functional-neuroanatomic model of biased competition in a specific left hemisphere Tool Use network. Called “Two Action Systems Plus” (2AS+), the model generates testable hypotheses about the major principles determining tool action selection, and their deficiencies in apraxia. Specifically, we hypothesize that 1) Competition between tool actions is influenced by the graded similarity of tool action representations, as implemented primarily by the left posterior temporal cortex (pTC), 2) The outcome of the competitive process is affected by the strength and timing of activation of tool action representations, and depends on the dynamic interplay of left pTC and the parietal lobes, 3) Outcome is further influenced by a mechanism that biases competition towards the tool action that is appropriate to goals and context, as implemented by the left inferior frontal gyrus (IFG) and its connections with the supramarginal gyrus (SMG), and 4) There are two subtypes of apraxia characterized by distinct failures in the competitive selection process: an anterior subtype characterized by inability to appropriately resolve tool action competition, and a posterior subtype reflecting weakened competition. These hypotheses will be tested using a number of complementary methods with healthy and brain-lesioned participants, including voxel-based lesion symptom mapping, resting functional connectivity, fMRI with multi-voxel pattern analyses, and eyetracking. By specifying when and how visuomotor information plays a role in tool representations, the proposed experiments promise to critically constrain “embodied” cognition theories claiming that tools automatically evoke their actions. The proposed research will also advance the theoretical understanding of tool action by anchoring relevant constructs in a cognitive-neuroanatomic model, clarify how action representations are organized and activated, and improve our understanding of the mechanisms affecting errors and re-learning in apraxia, with implications for rehabilitation. Project Narrative: Apraxia, a disorder of tool use, is a common and substantially disabling consequence of left hemisphere stroke, yet is relatively rarely studied and hence poorly understood. The proposed work will clarify the brain regions that are associated with the disorder, the task factors that may improve tool use abilities, and the ability of the damaged Tool Use system to learn after stroke. This information will serve as an important building block in the development of treatment strategies.",Understanding Action Selection in the Tool Use Network,9699553,R01NS099061,"['Achievement', 'Adopted', 'Affect', 'Anterior', 'Apraxias', 'Behavior', 'Brain', 'Brain region', 'Cheese', 'Cognition', 'Cognitive', 'Color', 'Disease', 'Failure', 'Functional Magnetic Resonance Imaging', 'Gestures', 'Goals', 'Grant', 'Hand', 'Human', 'Individual', 'Inferior frontal gyrus', 'Learning', 'Left', 'Lesion', 'Limb structure', 'Location', 'Machine Learning', 'Mediating', 'Memory', 'Methods', 'Modeling', 'Nature', 'Neurologic', 'Outcome', 'Parietal Lobe', 'Participant', 'Patients', 'Pattern', 'Play', 'Posture', 'Process', 'Production', 'Rehabilitation therapy', 'Research', 'Rest', 'Role', 'Source', 'Specific qualifier value', 'Stroke', 'Structure', 'Structure of supramarginal gyrus', 'Symptoms', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Work', 'base', 'clinically relevant', 'experience', 'experimental study', 'improved', 'novel', 'post stroke', 'response', 'theories', 'therapy development', 'tool', 'treatment strategy', 'visual motor']",NINDS,ALBERT EINSTEIN HEALTHCARE NETWORK,R01,2019,394895,-0.0293712771031163
"Administrative Supplement to the OAIC Pepper Center Coordinating Center We wish to advantage of 2 new key opportunities that could significantly enhance achievement of the overall goals of the OIAC Coordinating Center (OAIC CC) and 2 key, unexpected administrative needs. Project 1) Develop, test and implement an innovative set of tools to perform Integrative Data Analysis (IDA) for combining and analyzing independent data sets across the OAIC network An over-arching goal of the OAIC CC is to build collaborations between OAICs that unlock synergy. Each of the OAICs has many small/medium-sized completed studies relevant to the OAIC theme, and that have measured key domains of physical function. Combining these studies could provide large, powerful databases for answering critical questions not possible with individual studies. However, this is currently not possible because different measurement instruments are often used across centers and across studies. This project overcomes this critical limitation by taking advantage of 2 newly available technologies and an ongoing study. IDA is a set of strategies in which two or more independent data sets which contain measures addressing similar domains but using different measurement instruments are combined into one and then statistically analyzed. The proposed project is timely because it leverages an ongoing clinical study to validate new procedures for harmonizing measures of physical and cognitive function across 20 Pepper center studies. The resources created by the project will significantly enhance collaboration across the OAIC program network, benefiting researchers at all OAICs, and can be disseminated to other NIA center programs. Project 2) Develop a robust, interactive database of OAIC Program accomplishments that will automatically be updated via an efficient, streamlined, electronic annual reporting process.  It is widely believed that the NIA-funded Pepper Center program has been highly productive. However, there is no means of assessing the overall effectiveness of the Pepper Center, or of ‘cataloging’ its impressive accomplishments. This project will take advantage of new open-source technology to efficiently develop a robust, comprehensive, searchable, interactive database of past accomplishments. It will also develop a streamlined electronic Annual Directory Report template, and link it to the new OAIC database so that it is automatically updated each year. Achieving the goals of this project will reduce administrative burden for sites, facilitate NIA review of performance of centers, and create an annually updated database of OAIC accomplishments, projects, publications, and outcomes, and facilitate collaborations between centers and investigators across NIA programs. This application also requests support for 2 key, unexpected administrative needs that have arisen: 1) Increase in funding amount for the annual OAIC CC Multi-center pilot project. 2) Support for additional Pepper Centers that will soon be added to the OAIC network. Relevance Statement for OAIC Coordinating Center Administrative Supplement The Coordinating Center of the OAIC coordinates the activities of all the individual centers in the NIA- funded, OAIC network; its over-arching goal is to build collaborations between the individual OAICs and thereby unlock synergy and enable projects that could not be undertaken by any single OAIC center. This administrative supplement application proposes 2 developmental projects that will significantly enhance the capabilities of the OAIC to achieve these goals and which takes advantage of newly available methods and technology. This also includes additional support for the possible increase in the number of Pepper Centers and an increase in the pilot award budget.",Administrative Supplement to the OAIC Pepper Center Coordinating Center,9961004,U24AG059624,"['Achievement', 'Address', 'Administrative Supplement', 'Aging', 'Annual Reports', 'Award', 'Budgets', 'Capsicum', 'Cataloging', 'Catalogs', 'Clinical', 'Clinical Research', 'Cognition', 'Collaborations', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Directories', 'Effectiveness', 'Elderly', 'Equipment and supply inventories', 'Evaluation', 'Funding', 'Goals', 'Health', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Online Systems', 'Outcome', 'Participant', 'Performance', 'Physical Function', 'Pilot Projects', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Site', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Update', 'Walking', 'analytical method', 'analytical tool', 'base', 'cognitive function', 'cost effective', 'data modeling', 'forest', 'innovation', 'instrument', 'interest', 'lifestyle intervention', 'new technology', 'novel', 'open source', 'programs', 'recruit', 'response', 'synergism', 'theories', 'tool']",NIA,WAKE FOREST UNIVERSITY HEALTH SCIENCES,U24,2019,149775,-0.0011591196809262263
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,-0.00435882139985303
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9751297,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Consumption', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2019,77750,-0.0050047384218201985
"RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data Project Summary/Abstract  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allows the activity of small population of neurons in the human brain to be directly recorded. We use the term ECOG to refer to the entire range of invasive recording techniques (from subdural strips and grids to penetrating electrodes) that share the common attribute of recording neural activity from the human brain with high spatial and temporal resolution. While this ability has resulted in many high-impact advances in understanding fundamental mechanisms of brain function in health and disease, it generates staggering amounts of data as a single patient can be implanted with hundreds of electrodes, each sampled thousands of times a second for hours or even days. The difficulty of exploring these vast datasets is the rate-limiting step in using them to improve human health. We propose to overcome this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the unique properties of ECOG. We dub this software tool RAVE (“R Analysis and Visualization of Electrocorticography data”).  The first goal of Aim 1 is to release RAVE 1.0 to the entire ECOG community by month 6 of the first funding period. This will maximize transformative impact by putting the new tools in the hands of users as quickly as possible, facilitating rapid adoption. The design philosophy of RAVE is driven by three imperatives. The first is to keep users ""close to the data"" so that users may make discoveries about the brain without being misled by artifacts. The second imperative is rigorous statistical methodology. The final imperative is ""play well with others"". As described in Aim 2, our approach will make it easy to seamlessly incorporate new and existing analysis tools written in Matlab, C++, Python or R into RAVE, giving users the best of both worlds: advanced but easy-to-use visualization of results from ECOG experiments, whether they are analyzed with the off-the- shelf tools routines provided with RAVE or novel tools developed by others. Project Narrative  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allow the activity of small population of neurons in the human brain to be directly recorded with high spatial and temporal resolution. ECOG generates staggering amounts of data, and the rate-limiting step in generating new insights about the human brain is the difficulty in exploring this vast quantity of data. We propose to remove this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the analysis and visualization of ECOG data, known as RAVE (“R Analysis and Visualization of Electrocorticography data”).",RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data,9766391,R24MH117529,"['Adoption', 'Algorithms', 'Amalgam', 'Brain', 'Code', 'Communication', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrocorticogram', 'Electrodes', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hour', 'Human', 'Human Activities', 'Imagery', 'Implant', 'Implanted Electrodes', 'Laboratories', 'Language', 'Least-Squares Analysis', 'Letters', 'Literature', 'Machine Learning', 'Medicine', 'Methodology', 'Morphologic artifacts', 'Neurons', 'Neurosciences', 'Nightmare', 'Paper', 'Patients', 'Philosophy', 'Play', 'Plug-in', 'Population', 'Proliferating', 'Property', 'Pythons', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Rest', 'Sampling', 'Seeds', 'Software Design', 'Software Tools', 'Techniques', 'Time', 'United States National Institutes of Health', 'Variant', 'Visit', 'application programming interface', 'base', 'college', 'computer science', 'design', 'experience', 'experimental study', 'graphical user interface', 'improved', 'insight', 'interoperability', 'novel', 'open source', 'programs', 'relating to nervous system', 'statistics', 'temporal measurement', 'tool', 'wiki']",NIMH,BAYLOR COLLEGE OF MEDICINE,R24,2019,236620,0.0026797779997795963
"ClearScope Combined in vivo and ex vivo three‐dimensional (3D) whole‐brain imaging of non‐transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole‐brain datasets, the best approach is brain clearing followed by whole‐brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole‐brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo‐bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide‐spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state‐of‐the‐art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large‐scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,9677046,R44MH116827,"['3-Dimensional', 'Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Confocal Microscopy', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Dimensions', 'Human', 'Image', 'Immersion Investigative Technique', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'off-patent', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,699967,-0.015616509498316809
"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, involving a complicated interplay between functional information interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. func- tional and structural measures. However the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities is to miss a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimensional problem, requiring appropriate data reduction strategies. In the previous phase of the project we developed approaches based on multiset canonical correlation analysis (mCCA) and joint independent compo- nent analysis (jICA) that can capture high-dimensional, linear, relationships among 2 or more modalities, and which we showed can identify both modality-unique and modality-common features that are predictive of dis- ease. In this new phase of the project we will focus on two important areas. First, we will build on our previous success by extending our models to allow for incorporation of behavioral/cognitive constraints as well as devel- oping new approaches which leverage recent advances in deep learning enabling us to capture higher order relationships embedded in multimodal and multitask data. Secondly, we will address the key challenge of inte- grating possibly thousands of multimodal features by developing a new meta-modality framework which will enable us to bring together the existing and new features in an intuitive manner. This will also enable us to capture changes in multimodal information which might not be harmful separately but which together are jointly sufficient to convey risk of illness or to identify information flow through the meta-modal space for developing potential targets for treatment. We will apply these approaches to one of the largest multimodal imaging datasets of psychosis and mood disorders. Our proposed approach will be thoroughly evaluated using this large data set which includes multiple illnesses that have overlapping symptoms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar de- pression). As before, we will provide open source tools and release data throughout the duration of the project via a web portal and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 36 Project Narrative  The promise of multimodal imaging is clear, and we have shown the power of linear joint N-way analysis during the previous funding period. However this is just the beginning. In this renewal, we will build on and significantly expand the goals of the original aims by incorporating additional joint information (including dynamic and potentially nonlinear factors) as well as a framework for integrating the resulting information in order to enable decision making and identification of potential targets for further study or possible treatment. We will also disseminate our approaches through software tools and interactive web-based visualization of available data. 37",Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,9776502,R01EB006841,"['Address', 'Algorithms', 'Area', 'Behavioral', 'Biological Markers', 'Biology', 'Bipolar Disorder', 'Blood flow', 'Brain', 'Brain Diseases', 'Brain imaging', 'Classification', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Imaging technology', 'Intuition', 'Joints', 'Link', 'Measurable', 'Measures', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Multimodal Imaging', 'Neurobiology', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Psychotic Disorders', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Sample Size', 'Sampling', 'Schizophrenia', 'Series', 'Software Tools', 'Structure', 'Symptoms', 'Tars', 'Testing', 'Time', 'Training', 'Unipolar Depression', 'Validation', 'Visualization software', 'Work', 'base', 'clinical care', 'clinical phenotype', 'data reduction', 'data sharing', 'deep field survey', 'deep learning', 'deep neural network', 'design', 'gray matter', 'high dimensionality', 'imaging biomarker', 'imaging modality', 'improved', 'independent component analysis', 'multimodal data', 'multimodality', 'multitask', 'neuroinformatics', 'neuropsychiatric disorder', 'next generation', 'novel', 'novel strategies', 'open source', 'patient subsets', 'potential biomarker', 'repository', 'simulation', 'success', 'tool', 'translational impact', 'web portal', 'white matter']",NIBIB,GEORGIA STATE UNIVERSITY,R01,2019,400000,0.004804913221147833
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9750590,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,619917,-0.029149031096961847
"Developing new tools for high throughput analysis of microcircuits and synapse ultrastructure using tagged vesicular transporters and deep learning. PROJECT SUMMARY Synaptic dysfunction is a common feature of neuropsychiatric disease. For example, a hallmark of age-related neurodegenerative diseases such as Alzheimer’s and Parkinson’s is synaptic fibrilization and aggregation of key proteins that participate in synapse and cell loss. Maladaptive plastic changes in synapse structure and function underlie key aspects of behavioral and mood disorders ranging from addiction to depression, as well as neurodevelopmental diseases like schizophrenia and autism. It is for these reasons that many investigators across a range of neuroscience disciplines study the synapse, and the reason that new tools to study synapse structure and function within neural circuits of interest are sorely needed. Indeed, current tools to assess synapse structure in defined cell types are not readily compatible with state-of-the-art 3D volume approaches such as serial block face scanning electron microscopy, and are severely hampered by inadequate computational tools for quantitative assessment of these massive datasets. However, advances in molecular genetics, optics, engineering and computing provide new opportunities to develop information rich strategies to peer into the synapse. Here, we combine such advances to achieve a new state-of-the-art in imaging and analyzing microcircuit connectivity and synapse structure within neurotransmitter-defined neural networks. Specifically, we leverage the fact that the bulk of signaling across the synapse is mediated by a relatively small population of small molecule neurotransmitters that are synthesized and packaged into synaptic vesicles at the site of release in axonal compartments. The bulk of neurotransmission is thus dependent on just seven well- described vesicular transporters expressed in brain. Our overall goal is to build a rigorous, easily deployable, cell-type-specific, expandable, multi-functional toolkit for imaging and quantifying neurotransmitter-defined synaptic connections by both light and electron microscopy in mice. To accomplish this, we will use CRISPR/Cas9 to insert electron microscopy-compatible tags into native vesicular transporters (Aim 1), establish simplified procedures for their monochrome and ‘multicolor’ labeling in 3D ultrastructure (Aim 2), and computational tools for automated segmentation and quantitative analysis of key pre- and post-synaptic metrics (Aim 3). Though these Aims are independently meritorious, by synthesizing them we aim to generate a complete toolkit that will allow investigators to render neurotransmitter-defined circuit connections into 3D ultrastructure datasets with automated quantitative assessment of key features of pre- and post-synaptic structure. PROJECT NARRATIVE Synaptic and structural dysfunction are causally related to both the causes and symptoms of neuropsychiatric illness ranging from Alzheimer’s disease to addiction and depression. Modern advances in molecular genetics, engineering, materials, and computer sciences have created new opportunities to understand how brain dysfunction gives rise to disease. Here, we leverage these interdisciplinary advances to develop new probes, new methods, and new analysis pipelines to study the normal and pathological structure and function of synaptically coupled brain cells.",Developing new tools for high throughput analysis of microcircuits and synapse ultrastructure using tagged vesicular transporters and deep learning.,9822844,RF1MH120685,"['3-Dimensional', 'Acetylcholine', 'Alzheimer&apos', 's Disease', 'Amino Acids', 'Axon', 'Behavior Disorders', 'Brain', 'Brain region', 'CRISPR/Cas technology', 'Cells', 'Chelating Agents', 'Chemicals', 'Color', 'Communication', 'Complement', 'Complex', 'Coupled', 'Data Set', 'Dendritic Spines', 'Deposition', 'Discipline', 'Disease', 'Electron Microscopy', 'Electron energy loss spectroscopy', 'Electrophysiology (science)', 'Engineering', 'Face', 'Functional disorder', 'Genes', 'Genetic Engineering', 'Goals', 'Image', 'Image Analysis', 'Imaging Device', 'Immunoelectron Microscopy', 'Individual', 'Interneurons', 'Label', 'Lanthanoid Series Elements', 'Learning', 'Mediating', 'Memory', 'Mental Depression', 'Methods', 'Mitochondria', 'Modernization', 'Molecular Genetics', 'Mood Disorders', 'Movement', 'Mus', 'Nerve', 'Neurosciences', 'Neurotransmitters', 'Optics', 'Oxides', 'Parkinson Disease', 'Pathologic', 'Pattern', 'Performance', 'Physiological Processes', 'Population', 'Procedures', 'Process', 'Proteins', 'Purines', 'Recycling', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resolution', 'Respiration', 'Sampling', 'Scanning Electron Microscopy', 'Schizophrenia', 'Semantics', 'Shapes', 'Signal Transduction', 'Site', 'Slice', 'Specific qualifier value', 'Structure', 'Synapses', 'Synaptic Transmission', 'Synaptic Vesicles', 'Testing', 'Three-dimensional analysis', 'Time', 'Vertebral column', 'Vesicle', 'Viral', 'Viral Vector', 'Western Blotting', 'addiction', 'age related neurodegeneration', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain cell', 'brain dysfunction', 'cell type', 'cognitive function', 'computer science', 'computerized tools', 'deep learning', 'deep neural network', 'flexibility', 'high throughput analysis', 'imaging modality', 'improved', 'in vivo', 'interest', 'learning algorithm', 'light microscopy', 'materials science', 'monoamine', 'nanoscale', 'neural circuit', 'neural network', 'neural network architecture', 'neuronal circuitry', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neurotransmission', 'peer', 'polymerization', 'postsynaptic', 'reconstruction', 'repository', 'small molecule', 'synaptic function', 'tool']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",RF1,2019,2509965,-0.028791416868982424
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9750520,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2019,507856,0.009425945399875195
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,9703267,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'tool']",NICHD,DUKE UNIVERSITY,R25,2019,161462,-0.00540384447336739
"COINSTAC: Decentralized, Scalable Analysis of Loosely Coupled Data The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: Decentralized, Scalable Analysis of Loosely Coupled Data",9938885,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'Intelligence', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'commune', 'computational platform', 'computer framework', 'computing resources', 'connectome', 'cost', 'data anonymization', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'preservation', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2019,585151,0.008025181085539918
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,9818274,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2019,352996,-0.01269874224623139
"Augmented Reality Platform for Feedback and Assessment in STEM elementary education ABSTRACT This SBIR Phase I project will build evidence-based content, challenges and assessments that promote: simulation-based learning; troubleshooting and critical-thinking; and diversity and inclusion in STEM learning. The approach will be transferable by design to teaching and measuring learner performance across scientific disciplines. Emerging digital content in virtual (VR) and augmented reality (AR) is already transforming science, technology, engineering, and math (STEM) education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future. These technologies have promise in delivering simulation environments capable of nurturing deep learning and higher-level thinking in K-12 students through practical experience, hand-on exercises and real-life applications, such as troubleshooting. Digital AR and VR educational content is beginning to address and develop these skills, but a platform has yet to be developed to effectively enable broad adoption in elementary settings. Cost efficient methods to provide formative feedback and gather summative evaluations for Next Generation Science Standards (NGSS) is also an unmet need. The successful completion of the proposed project will provide an evidence-centered content delivery and assessment framework as well as tool for addressing NGSS performance expectations that is transferable across topic areas and readily scalable for large-scale national implementation. The content will intentionally incorporate aspects of context and diversity of characters to ensure inclusion of groups that are historically underrepresented – specifically females and ethnic minorities. NARRATIVE Success in the workforce of the future will require the high-level thinking skills that the Next Generation Science Standards (NGSS) emphasize. Emerging digital content in virtual (VR) and augmented reality (AR) is transforming science and engineering education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future, through practical simulation-based experiences, but these lack the capability for performance assessment crucial to teachers and decision makers. By providing a readily scalable and flexible platform, the proposed approach promises to accelerate access to high-quality, inclusive, and evidence-centered AR content delivery and assessment of NGSS standards which in turn provides students with the skills they need for success.",Augmented Reality Platform for Feedback and Assessment in STEM elementary education,9847434,R43GM134813,"['Address', 'Adoption', 'Area', 'Augmented Reality', 'Award', 'Businesses', 'Career Choice', 'Child', 'Critical Thinking', 'Data', 'Development', 'Discipline', 'E-learning', 'Education', 'Educational process of instructing', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exercise', 'Feedback', 'Female', 'Funding', 'Future', 'Hand', 'Indiana', 'Industry', 'K-12 student', 'Learning', 'Life', 'Longevity', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Next Generation Science Standards', 'Output', 'Perception', 'Performance', 'Phase', 'Problem Solving', 'Process', 'Reporting', 'Research', 'SECTM1 gene', 'Science', 'Science, Technology, Engineering and Mathematics', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Small Business Innovation Research Grant', 'Students', 'System', 'Technology', 'Testing', 'Thinking', 'Translating', 'Universities', 'Validation', 'Woman', 'Writing', 'Youth', 'base', 'cost efficient', 'deep learning', 'design', 'digital', 'digital media', 'educational atmosphere', 'engineering design', 'ethnic minority population', 'evidence base', 'expectation', 'experience', 'flexibility', 'girls', 'innovation', 'interest', 'mathematical learning', 'mobile application', 'pedagogy', 'prototype', 'simulation', 'simulation game', 'skills', 'success', 'teacher', 'theories', 'tool', 'virtual', 'virtual reality']",NIGMS,"EXPLORE INTERACTIVE, LLC",R43,2019,295622,-0.002424261561557421
"Structural Development of Human Fetal Brain Abstract Despite its critical significance, little is known about the most dynamic phase of brain development in infancy: 0-2 years. To change the status quo, comprehensive and quantitative infant brain atlases as reference standards for precision health are needed. In addition, diffusion MRI (dMRI) has entered a new era in which dynamic cortical internal microstructural complexity, indexed by e.g. cortical mean kurtosis derived from diffusion kurtosis imaging (DKI), can be studied in the living infant brain noninvasively using more advanced multi-shell dMRI. Furthermore, multi-modality measures offer unparalleled insights into mechanistic structure- function and structure-behavior relationships. Work in the current cycle has focused on structural development of human fetal and preterm brains. Based on high resolution diffusion tensor imaging (DTI) of 150 brains, we have established the atlases and quantified cortical microstructure with cortical fractional anisotropy, validated by histological images and correlated with transcriptomic (RNA) expression. Building upon this work, in the next cycle, we will focus on brain development in infancy, immediately after the fetal period. Specifically, the goal is to establish next-generation dMRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural mean kurtosis measurement by delineating its 4D spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). 160 typically developing infants at 1, 3, 6, 12, 18, 24 months will be recruited. Advanced “connectome-quality” multi-band high-resolution multi-shell dMRI, resting state fMRI (rs-fMRI) and structural MRI will be acquired. High-quality whole-head magnetoencephalography (MEG) will also be acquired. Anatomical labels of all 122 major gray and white matter structures will be built up based on high contrasts from DTI-derived maps. The measurements of DTI-derived metrics will be used for the quantitative components of DTI atlases and age-dependent white matter tract trajectories (Aim 1). Mean kurtosis of the 4th order kurtosis tensor has been shown to be sensitive to cortical internal microstructural changes of infant brains. The spatiotemporal sensitivity of mean kurtosis measures to infant age and cortical region will be investigated (Aim 2). Furthermore, we will establish mechanistic structure-function relationships with multi- modality imaging, including not only multi-shell dMRI, but also rs-fMRI and MEG, all optimized for infant brains (Aim 3). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants (e.g. Z-score maps). Infant cortical microstructure will be delineated noninvasively with 4D spatiotemporal frameworks. With multi-modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general. Narrative Title: Structural development of human fetal brain The goal is to establish next-generation diffusion MRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural measurement by delineating its four-dimensional spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants. With multi- modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general.",Structural Development of Human Fetal Brain,9775196,R01MH092535,"['2 year old', 'Age', 'Anatomy', 'Anisotropy', 'Architecture', 'Area', 'Atlases', 'Auditory', 'Behavior', 'Behavior assessment', 'Behavioral', 'Brain', 'Cerebral cortex', 'Characteristics', 'Clinical Research', 'Collaborations', 'Development', 'Developmental Process', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Fingerprint', 'Four-dimensional', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Human', 'Image', 'Infant', 'Infant Development', 'Infant Health', 'Intellectual functioning disability', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Measurement', 'Measures', 'Motor', 'Multimodal Imaging', 'Neurodevelopmental Disorder', 'Phase', 'Precision Health', 'RNA', 'Reference Standards', 'Research Personnel', 'Resolution', 'Rest', 'Risk Assessment', 'Sensorimotor functions', 'Sensory', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Time', 'Visual', 'Work', 'age related', 'artemis', 'autism spectrum disorder', 'base', 'connectome', 'fetal', 'gray matter', 'histological image', 'human fetal brain', 'indexing', 'infancy', 'insight', 'multimodality', 'neuroimaging', 'neuronal circuitry', 'next generation', 'novel', 'prisma', 'recruit', 'relating to nervous system', 'somatosensory', 'spatiotemporal', 'transcriptomics', 'white matter']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2019,537888,-0.01494053033534082
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9637403,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2019,388812,-0.0076114993366992855
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9653180,R01EY025332,"['3-Dimensional', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416574,0.020417505613266385
"Reproducible imaging-based brain growth charts for psychiatry ABSTRACT Major psychiatric illnesses are increasingly understood as disorders of brain development, which has led to large-scale studies of youth that combine multi-modal neuroimaging with clinical phenotyping. Together, such data have emphasized the promise of objective ‘growth charts’ of brain development. However, synergies across major efforts remains unrealized due to use of different clinical instruments, different scanning protocols, challenges in informatics, and difficulties in data integration. In this proposal, we will overcome these obstacles by leveraging advances in multivariate harmonization and analysis techniques to build highly reproducible growth charts of human brain development. To do this, we will aggregate and harmonize eight existing large-scale developmental imaging studies, comprising over 10,000 participants between the age of 5- 24 (Aim 1). We will use this harmonized data to build generalizable indices of normal network brain development (Aim 2). Finally, developmental abnormalities within specific brain networks will be linked to dimensions of psychopathology (Aim 3). Critically, all code, data, and derived indices will be shared publicly, creating a massive new resource to accelerate research in the developmental neuroscience community (Aim 4). In sum, this proposal will have provide a new data resource, yield reproducible growth charts of brain development, and delineate novel mechanisms regarding the developmental basis of psychopathology in youth. RELEVANCE Psychiatric illnesses often begin in childhood, adolescence, or young adulthood, and are increasingly conceptualized as disorders of brain development. Reproducible growth charts of bran development are critical for understanding both normal brain development and abnormalities associated with diverse psychopathology. Early interventions crafted using these growth charts would benefit the public health by reducing the huge disability associated with psychiatric disorders and limiting the costs to society at large.",Reproducible imaging-based brain growth charts for psychiatry,9810689,R01MH120482,"['Address', 'Adolescence', 'Age', 'Base of the Brain', 'Bayesian Method', 'Brain', 'Brain Diseases', 'Categories', 'Childhood', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Docking', 'Early Intervention', 'Failure', 'Fright', 'Functional Imaging', 'Grain', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Informatics', 'International', 'Life', 'Link', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Meta-Analysis', 'Modeling', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurosciences', 'Outcome', 'Participant', 'Phenotype', 'Process', 'Properdin', 'Protocols documentation', 'Psychiatry', 'Psychopathology', 'Public Health', 'Recording of previous events', 'Reproducibility', 'Research', 'Resources', 'Rest', 'Sampling', 'Scanning', 'Sex Differences', 'Site', 'Societies', 'Structure', 'Sum', 'Symptoms', 'Techniques', 'Training', 'Validation', 'Variant', 'Youth', 'aging brain', 'anxious', 'base', 'brain abnormalities', 'clinical phenotype', 'computing resources', 'cost', 'data archive', 'data integration', 'data resource', 'design', 'disability', 'externalizing behavior', 'image processing', 'imaging study', 'indexing', 'insight', 'instrument', 'learning strategy', 'multidimensional data', 'multimodality', 'neuroimaging', 'novel', 'portability', 'quality assurance', 'response', 'segregation', 'serial imaging', 'sex', 'somatosensory', 'synergism', 'theories', 'young adult']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,780855,-0.007926857714900645
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future. Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,9999822,R24MH114788,"['Archives', 'Atlases', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Management Resources', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Ecosystem', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Imagery', 'Individual', 'Ingestion', 'Institution', 'Internet', 'Knowledge', 'Location', 'Metadata', 'Modeling', 'Modification', 'Multiomic Data', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization software', 'Work', 'analysis pipeline', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data integration', 'data management', 'data pipeline', 'data resource', 'data submission', 'data visualization', 'data warehouse', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'innovative neurotechnologies', 'machine learning algorithm', 'member', 'multiple omics', 'neural circuit', 'next generation', 'online resource', 'operation', 'outcome forecast', 'programs', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2019,102318,-0.006974724267743304
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future.   Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,9748608,R24MH114788,"['Archives', 'Atlases', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Management Resources', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Ecosystem', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Imagery', 'Individual', 'Ingestion', 'Institution', 'Internet', 'Knowledge', 'Location', 'Metadata', 'Modeling', 'Modification', 'Multiomic Data', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization software', 'Work', 'analysis pipeline', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data integration', 'data management', 'data pipeline', 'data resource', 'data submission', 'data visualization', 'data warehouse', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'innovative neurotechnologies', 'machine learning algorithm', 'member', 'multiple omics', 'neural circuit', 'next generation', 'online resource', 'operation', 'outcome forecast', 'programs', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2019,1263611,-0.006974724267743304
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9787575,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2019,291536,-0.009926373698669406
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9752624,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'patient variability', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep physiology', 'spatial temporal variation', 'standard of care', 'statistics', 'surgery outcome', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2019,148964,-0.0065444769720501795
"A data science toolbox for analysis of Human Connectome Project diffusion MRI Project Summary/Abstract The connections between different brain regions play an important role in normal brain function. This project proposes to create an end-to-end pipeline for analysis of human white matter connections using “tractometry” methods. In tractometry, tissue properties are estimated in the long-range connections between remote brain regions. The project will focus on the analysis of the Human Connectome Project diffusion MRI dataset, which provides one of the largest available publicly available datasets of diffusion MRI from a sample of normal healthy individuals. Based on this dataset, we propose to create a normative distribution of tissue properties in the major white matter connections, to develop novel statistical methods to connect the properties of white matter connections to cognitive abilities, and to create visualization tools for further communication and exploration of the data. The tools created will be initially applied to the Human Connectome Project Dataset, but will also be useful in smaller studies on speciﬁc populations and in other large-scale datasets, such as the ABCD study. Project Narrative This project proposes to characterize the properties of long-range connections between human brain regions, using MRI data from the Human Connectome Project. Using novel data science tools that we will develop we will assemble a benchmark of the distribution of tissue properties in major brain connections, apply novel statistical methods that connect the properties of brain connections to cognitive abilities, and create visualization tools for further communication and exploration of this dataset and other similar datasets.",A data science toolbox for analysis of Human Connectome Project diffusion MRI,9886761,RF1MH121868,"['Algorithms', 'Anatomy', 'Atlases', 'Behavior', 'Benchmarking', 'Biophysics', 'Brain', 'Brain region', 'Clinical', 'Cloud Computing', 'Cognitive', 'Communication', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Drug or chemical Tissue Distribution', 'Emotional', 'Evaluation', 'Funding', 'Human', 'Imagery', 'Imaging technology', 'Individual', 'Individual Differences', 'Infrastructure', 'Internet', 'Knowledge', 'Lasso', 'Lead', 'Longevity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Online Systems', 'Play', 'Population', 'Problem Solving', 'Property', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensory', 'Statistical Data Interpretation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tissues', 'Translating', 'United States National Institutes of Health', 'Visual impairment', 'Visualization software', 'Work', 'analysis pipeline', 'base', 'behavior measurement', 'biophysical properties', 'blind', 'brain tract', 'clinical predictors', 'cognitive ability', 'cognitive skill', 'connectome', 'data visualization', 'human data', 'in vivo', 'individual variation', 'member', 'nervous system disorder', 'novel', 'open source', 'scale up', 'success', 'three dimensional structure', 'tool', 'tractography', 'white matter']",NIMH,UNIVERSITY OF WASHINGTON,RF1,2019,707444,-0.020362745580611012
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9700661,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2019,1217435,-0.01005928351298871
"Annual meeting of the Vision Sciences Society: Travel grants for junior investigators PROJECT SUMMARY/ABSTRACT The Vision Sciences Society is a nonprofit membership organization of nearly 2000 scientists interested in the functional aspects of vision. VSS was founded in 2001 with the purpose of bringing together scientists from a broad range of disciplines including visual psychophysics, visual neuroscience, computational vision and visual cognition. The scientific content of the meetings reflects the breadth of topics and interconnected ideas and approaches in modern vision science, from visual coding to perception, recognition and the visual control of action, as well as recent developments in cognitive psychology, computer vision and neuroimaging. Since its founding, VSS has provided a forum and framework for communicating advances in vision science, and VSS has become a flagship conference for the field. The interdisciplinary nature of VSS is reflected in the deliberately diverse membership of the Board of Directors and Abstract Review Committee, and by its formal relationship with the more clinically-oriented Association for Research in Vision and Ophthalmology. Many of the faculty from institutions in the United States who attend VSS are principal investigators of National Eye Institute grants; hence, the research objectives of the programs of the National Institutes of Health and of the National Eye Institute are well-represented in the program planning and individual presentations. Over 60% of participants are predoctoral and postdoctoral trainees. Of these 55% are US citizens. VSS provides multiple career development opportunities: (1) the platform and poster presentations provide a forum for trainees to showcase their work and receive feedback, (2) career-development workshops cover topics such as “Getting that Faculty Job”, “Reviewing and Responding to Reviews”, “The Public Face of your Science”, “Careers in Industry and Government”, “Faculty Careers at Primarily Undergraduate Institutions”, and include panel discussions with journal editors, NIH and NSF grant officers, and academic and industry representatives, (3) a “Meet the Professors” event in which trainees meet in small groups with members of the VSS Board and other professors for free-wheeling, open-ended discussions, and (4), a partnership with ARVO through which trainees from one society can carry out research or attend the meeting of the other. Informally, VSS provides opportunities for networking with peers and senior colleagues in a comfortable and engaging setting. The large contingent of early-stage investigators at VSS is a sign of the strong health of the field and the opportunity VSS provides for advancing the field. Our goal is to facilitate access and participation for this next generation of vision scientists. The purpose of this grant is to provide 35 travel awards (5 for ARVO affiliates) for early-career investigators to attend the 2019 meeting, with the focus on attracting and supporting a diverse pool of pre- doctoral students, postdoctoral trainees, and pre-tenure faculty who demonstrate potential for future success as vision researchers and whose research findings will be presented at the meeting. Funds are also requested to support childcare services for awardees and workshops and social events for all early-career participants. PROJECT NARRATIVE The Vision Science Society (VSS) organizes an annual meeting for presenting cutting edge research on the mechanisms and principles of normal and abnormal visual perception. The aging American population will experience an increasing rate of visual loss due to diseases and disorders of the eye and central visual pathway. Understanding the perceptual sequelae of and developing effective therapies for visual disorders requires knowledge in the diverse research domains sponsored by the annual meeting of VSS.",Annual meeting of the Vision Sciences Society: Travel grants for junior investigators,9763082,R13EY030356,"['3-Dimensional', 'Address', 'Aging', 'American', 'Area', 'Attention', 'Award', 'Binocular Vision', 'Blindness', 'Child Care', 'Clinical', 'Coffee', 'Cognitive Science', 'Color', 'Complement', 'Computer Simulation', 'Computer Vision Systems', 'Development', 'Discipline', 'Disease', 'Educational workshop', 'Event', 'Exhibits', 'Eye Movements', 'Eye diseases', 'Face', 'Faculty', 'Feedback', 'Female', 'Florida', 'Funding', 'Future', 'Goals', 'Government', 'Grant', 'Health', 'Hour', 'Human', 'Individual', 'Industry', 'Institution', 'Island', 'Journals', 'Knowledge', 'Light', 'Medal', 'Mediation', 'Mentors', 'Mentorship', 'Modernization', 'Motion Perception', 'Music', 'National Eye Institute', 'Nature', 'Occupations', 'Ophthalmology', 'Participant', 'Perception', 'Perceptual learning', 'Population', 'Principal Investigator', 'Psychophysics', 'Publishing', 'Research', 'Research Personnel', 'Resort', 'Review Committee', 'Science', 'Scientist', 'Services', 'Societies', 'Students', 'Time', 'Training', 'Travel', 'United States', 'United States National Institutes of Health', 'Vendor', 'Vision', 'Vision Disorders', 'Visual Illusions', 'Visual Pathways', 'Visual Perception', 'Visual Psychophysics', 'Work', 'care systems', 'career', 'career development', 'design', 'doctoral student', 'effective therapy', 'experience', 'face perception', 'fovea centralis', 'graduate student', 'interest', 'mathematical model', 'meetings', 'member', 'multisensory', 'neuroimaging', 'next generation', 'object recognition', 'peer', 'perceptual organization', 'posters', 'pre-doctoral', 'professor', 'programs', 'science and society', 'social', 'spatial vision', 'success', 'symposium', 'undergraduate student', 'vision science', 'visual coding', 'visual cognition', 'visual control', 'visual memory', 'visual neuroscience', 'visual processing', 'visual search']",NEI,UNIVERSITY OF NEVADA RENO,R13,2019,47210,0.006596379441319197
"Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases 7. Project Summary/Abstract There is an urgent need to support research that generates high-quality evidence to inform clinical decision making. Cluster randomized trials (CRTs) achieve the highest standard of evidence for the evaluation of community-level effectiveness of intervention strategies against infectious diseases. However, there is a need to develop new methods to improve the design and analysis of CRTs because unique and complicated analytical challenges arise in such settings. One such issue relates to the intraclass correlation coefficient (ICC), the degree to which individuals within a community are more similar to one another than to individuals in other communities. Design and analysis of CRTs must take into account the ICC. Lack of accurate information on the ICC jeopardizes the power of CRTs, leads to suboptimal choices of analysis methods and complicates the interpretation of study results. However, reliable information on the ICC is difficult to obtain. A robust and efficient approach for estimating ICCs is based on the second-order generalizing estimating equations. However, its use has been limited by considerable computational burden and poor convergence rates associated with the existing algorithms solving these equations. The first aim addresses these computational challenges. Missing data are ubiquitous and can lead to bias and loss of efficiency. The second aim proposes to develop novel robust and efficient methods for estimating ICCs in the presence of informative missing data. For infectious diseases, the underlying contact/transmission networks give rise to complicated correlation structure. The third aim is to develop network and epidemic models to project the ICC. User-friendly software will be developed to facilitate the implementation of new methods. An immediate application of the proposed methods is their application to the Botswana Combination Prevention Project to improve the estimation of intervention effect and to generate reliable ICC estimates for designing future CRTs in the same population. The proposed methods can be applied to other ongoing and future CRTs, and more broadly, to longitudinal studies and agreement studies where ICCs are also of great interest. The proposed research is significant, because success in addressing these issues will improve the ability to design efficient and well-powered CRTs and the precision in estimating the effects of intervention strategies. Innovation lies in the development of improved computing algorithms adapting approaches from deep learning, the use of semiparametric efficiency theory, and the integration of network modeling, epidemic modeling and statistical inference. The results of the proposed research will benefit both ongoing and future CRTs, permit more efficient use of the resources, and ultimately expedite the control of infectious diseases. 8. Project Narrative The proposed research is relevant to public health because improved methodologies for the design and analysis of cluster randomized trials will benefit both ongoing and future studies, permit more efficient use of the resources, and ultimately improve public health response intended to control the spread of infectious diseases. Thus, the proposed research is relevant to the part of NIAID’s mission that pertains to conducting and supporting research to prevent infectious diseases and to respond to emerging public health threats.",Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases,9785367,R01AI136947,"['AIDS prevention', 'Accounting', 'Address', 'Affect', 'Agreement', 'Algorithms', 'Americas', 'Area', 'Attention', 'Behavior Therapy', 'Botswana', 'Characteristics', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Data', 'Dependence', 'Development', 'Disease', 'Disease Outbreaks', 'Ebola virus', 'Effectiveness', 'Effectiveness of Interventions', 'Epidemic', 'Equation', 'Evaluation', 'Future', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Institute of Medicine (U.S.)', 'Intervention', 'Intervention Studies', 'Knowledge', 'Lead', 'Longitudinal Studies', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nosocomial Infections', 'Population', 'Prevention', 'Prevention strategy', 'Probability', 'Public Health', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Support', 'Resources', 'Role', 'Running', 'Science', 'Societies', 'Structure', 'System', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'base', 'clinical decision-making', 'collaboratory', 'deep learning', 'design', 'experience', 'high standard', 'improved', 'innovation', 'insight', 'interest', 'intervention effect', 'mathematical model', 'network models', 'novel', 'prevent', 'response', 'semiparametric', 'success', 'systems research', 'theories', 'transmission process', 'user friendly software']",NIAID,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2019,247413,-0.001220134158688555
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive, PhysioBank, was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. PhysioToolkit, its software collection, supports exploration and quantitative analyses of PhysioBank and similar data with a wide range of well-documented, rigorously tested open-source software that can be run on any platform. PhysioNet's team of researchers leverages results of other funded projects to drive the creation and enrichment of: i) Data collections that provide increasingly comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC III (Medical Information Mart for Intensive Care) Database of critical care patients; ii) Analytic methods that lead to more timely and accurate diagnoses of major public health problems (such as life-threatening cardiac arrhythmias, infant apneas, fall risk in older individuals and those with neurologic disease, and seizures), and iii) Elucidation of dynamical changes associated with a variety of pathophysiologic processes and aging (such as cardiopulmonary interactions during sleep disordered breathing syndromes); User interfaces, reference materials and services that add value and improve accessibility to PhysioNet's data and software (such as PhysioNetWorks, a virtual laboratory for data sharing). Impact: Cited in The White House Fact Sheet on Big Data Across the Federal Government (March 29, 2012), PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are inaccessible otherwise. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world- wide, growing community of researchers, clinicians, educators, students, and medical instrument and software developers, retrieve about 380 GB of data per day. By providing free access to its unique and wide-ranging data and software collections, PhysioNet is invaluable to studies that currently result in an impressive average of nearly 250 new scholarly articles per month by academic, clinical, and industry-affiliated researchers worldwide. Over the next year we aim to sustain and enhance PhysioNet's impact with new technology and data; and complete the 2019 PhysioNet/Computing in Cardiology Challenge on sepsis. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,9993811,R01GM104987,"['Aging', 'Algorithms', 'Apnea', 'Area', 'Arrhythmia', 'Big Data', 'Biomedical Research', 'Boston', 'Bypass', 'Cardiology', 'Cardiopulmonary', 'Categories', 'Clinical', 'Clinical Data', 'Cloud Service', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dedications', 'Development', 'Diagnostic radiologic examination', 'Entropy', 'FAIR principles', 'Federal Government', 'Functional disorder', 'Funding', 'Grant', 'Imagery', 'Individual', 'Industry', 'Infant', 'Infrastructure', 'Intensive Care', 'Israel', 'Journals', 'Laboratories', 'Lead', 'Licensing', 'Life', 'Link', 'Machine Learning', 'Maintenance', 'Medical', 'Medical center', 'Methods', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase Transition', 'Physiological', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Role', 'Running', 'Seizures', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Students', 'Switzerland', 'Syndrome', 'Testing', 'Thoracic Radiography', 'Time', 'United States National Institutes of Health', 'University Hospitals', 'Visit', 'accurate diagnosis', 'analytical method', 'clinical application', 'computerized data processing', 'computing resources', 'data archive', 'data sharing', 'experience', 'fall risk', 'heart rate variability', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'member', 'nervous system disorder', 'new technology', 'open source', 'preservation', 'repository', 'signal processing', 'software repository', 'symposium', 'time interval', 'virtual laboratory']",NIGMS,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2019,409563,-0.004478099718788683
"Flexible multivariate models for linking multi-scale connectome and genome data in Alzheimer's disease and related disorders Project Summary/Abstract  In the field of Alzheimer’s and related disorder, there has been very little work focusing on imaging genomics biomarker approaches, despite considerable promise. In part this is due to the fact that most studies have fo- cused on candidate gene approaches or those that do not capitalize on capturing (and amplifying) small effects spread across many sites. Even for genome wide studies, the vast majority of imaging genomic studies still rely on massive univariate analyses. The use of multivariate approaches provides a powerful tool for analyzing the data in the context of genomic and connectomic networks (i.e. weighted combinations of voxels and genetic variables). It is clear that imaging and genomic data are high dimensional and include complex relationships that are poorly understood. Multivariate data fusion models that have been proposed to date typically suffer from two key limitations: 1) they require the data dimensionality to match (i.e. 4D fMRI data has to be reduced to 1D to match with the 1D genomic data, and 2) models typically assume linear relationships despite evidence of non- linearity in brain imaging and genomic data. New methods are needed that can handle data that has mixed temporal dimensionality, e.g., single nucleotide polymorphisms (SNPs) do not change over time, brain structure changes slowly over time, while fMRI changes rapidly over time. Secondly, methods that can handle complex relationships, such as groups of networks that are tightly coupled or nonlinear relationships in the data. To ad- dress these challenges, we introduce a new framework called flexible subspace analysis (FSA) that can auto- matically identify subspaces (groupings of unimodal or multimodal components) in joint multimodal data. Our approach leverages the interpretability of source separation approaches and can include additional flexibility by allowing for a combination of shallow and ‘deep’ subspaces, thus leveraging the power of deep learning. We will apply the developed models to a large longitudinal dataset of individuals at various stages of cognitive impair- ment and dementia. Using follow-up outcomes data we will evaluate the predictive accuracy of a joint analysis compared to a unimodal analysis, as well as its ability to characterize various clinical subtypes including those driven by vascular effects including subcortical ischemic vascular dementia versus those that are more neuro- degenerative. We will evaluate the single subject predictive power of these profiles in independent data to max- imize generalization. All methods and results will be shared with the community. The combination of advanced algorithmic approach plus the large N data promises to advance our understanding of Alzheimer’s and related disorders in addition to providing new tools that can be widely applied to other studies of complex disease. 3 Project Narrative  It is clear that multimodal data fusion provides benefits over unimodal analysis, however existing approaches typically require the data to have matched dimensionality, leading to a loss of information. In addition, most models assume linear relationships, despite strong evidence of nonlinear relationships in the data. We propose to develop new flexible models to capture multi-scale brain imaging and genomics data which we will use to study a large data set of individuals with Alzheimer’s disease and Alzheimer’s disease related disorders. 2",Flexible multivariate models for linking multi-scale connectome and genome data in Alzheimer's disease and related disorders,9826772,RF1AG063153,"['3-Dimensional', 'Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Behavior', 'Benchmarking', 'Biological', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Candidate Disease Gene', 'Categories', 'Classification', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnostic', 'Dimensions', 'Disease', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Image', 'Impaired cognition', 'Individual', 'Joints', 'Lead', 'Linear Models', 'Link', 'Magnetic Resonance Imaging', 'Meta-Analysis', 'Methods', 'Modality', 'Modeling', 'Motivation', 'Nerve Degeneration', 'Neurobiology', 'Noise', 'Outcome', 'Pathway interactions', 'Pattern', 'Research Personnel', 'Rest', 'Sampling', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Structure', 'Subgroup', 'Time', 'Vascular Dementia', 'Work', 'base', 'blind', 'clinical subtypes', 'connectome', 'data anonymization', 'data warehouse', 'deep learning', 'flexibility', 'follow-up', 'functional genomics', 'genome-wide analysis', 'genomic biomarker', 'genomic data', 'longitudinal dataset', 'mild cognitive impairment', 'multidimensional data', 'multimodal data', 'multimodality', 'neurobehavioral', 'novel', 'patient subsets', 'statistics', 'structural genomics', 'subcortical ischemic vascular disease', 'tool', 'user friendly software', 'white matter damage']",NIA,GEORGIA STATE UNIVERSITY,RF1,2019,3319889,-0.07252575276873709
"Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION) PROJECT SUMMARY: Trauma to the spinal cord and brain (neurotrauma) together impact over 2.5 million people per year in the US, with economic costs of $80 billion in healthcare and loss-of-productivity. Yet precise pathophysiological processes impacting recovery remain poorly understood. This lack of knowledge limits the reliability of therapeutic development in animal models and limits translation across species and into humans. Part of the problem is that neurotrauma is intrinsically complex, involving heterogeneous damage to the central nervous system (CNS), the most complex organ system in the body. This results in a multifarious CNS syndrome spanning across heterogeneous data sources and multiple scales of analysis. Multi-scale heterogeneity makes spinal cord injury (SCI) and traumatic brain injury (TBI) difficult to understand using traditional analytical approaches that focus on a single endpoint for testing therapeutic efficacy. Single endpoint-testing provides a narrow window into the complex system of changes that describe the holistic syndromes of SCI and TBI. In this sense, complex neurotrauma is fundamentally a problem that requires big- data analytics to evaluate reproducibility in basic discovery and cross-species translation. For the proposed TOP-VISION cooperative agreement we will: 1) integrate preclinical neurotrauma data on a large-scale; 2) develop novel applications of cutting-edge multidimensional analytics to make sense of complex neurotrauma data; and 3) validate bio-functional patterns in targeted big-data-to-bench experiments in multi-PI single center (UG3 phase), and multicenter (UH3 phase) studies. The goal of the proposed project is to develop an integrated workflow for preclinical discovery, reproducibility testing, and translational discovery both within and across neurotrauma types. Our team is well-positioned to execute this project given that with prior NIH funding we built one of the largest multicenter, multispecies repositories of neurotrauma data to-date, housing detailed multidimensional outcome data on nearly N=5000 preclinical subjects and over 20,000 curated variables. We will leverage these existing data resources and apply recent innovations from data science to render complex multidimensional endpoint data into robust syndromic patterns that can be visualized and explored by researchers and clinicians for discovery, hypothesis-generation and ultimately translational outcome testing. PROJECT NARRATIVE: Multicenter, multispecies central nervous system (spinal cord and brain) injury data provides a unique and clinically-relevant opportunity to discover translational outcomes, if we can develop analytical workflows that fully harness these data. Our team has assembled one of largest repositories of such data spanning across spinal cord injury and traumatic brain injury models under prior NIH support. The proposed cooperative agreement will expand data-sharing and big-data analytical workflows to render raw neurotrauma data into novel insights to promote bench-to-bedside translation.",Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION),9675348,UG3NS106899,"['Address', 'Affect', 'Anatomy', 'Animal Model', 'Area', 'Behavioral', 'Big Data', 'Big Data Methods', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Collection', 'Data Element', 'Data Science', 'Data Sources', 'Detection', 'Drug Targeting', 'FAIR principles', 'Functional disorder', 'Funding', 'Generations', 'Goals', 'Healthcare', 'Heterogeneity', 'Housing', 'Human', 'Individual', 'Injury', 'Knowledge', 'Machine Learning', 'Medical', 'Meta-Analysis', 'Modeling', 'Modernization', 'Molecular', 'Multiple Trauma', 'Mus', 'Nervous System Trauma', 'Neuraxis', 'Outcome', 'Outcome Assessment', 'Pattern', 'Phase', 'Physiological', 'Positioning Attribute', 'Precision Health', 'Prevalence', 'Process', 'Rattus', 'Recovery', 'Recovery of Function', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sensitivity and Specificity', 'Severities', 'Site', 'Spinal Cord', 'Spinal Injuries', 'Spinal cord injury', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Trauma', 'Traumatic Brain Injury', 'Treatment Efficacy', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Validation', 'Weight', 'Work', 'bench to bedside', 'biobehavior', 'biomarker discovery', 'body system', 'clinically relevant', 'cost', 'data integration', 'data resource', 'data warehouse', 'economic cost', 'economic impact', 'experimental study', 'functional outcomes', 'innovation', 'insight', 'neuroinflammation', 'novel', 'pre-clinical', 'precision medicine', 'preclinical study', 'predictive modeling', 'productivity loss', 'repository', 'response to injury', 'spinal cord and brain injury', 'success', 'therapeutic development', 'therapeutic evaluation', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",UG3,2019,240508,0.006815857881675446
"Adaptive & Individualized AAC The heterogeneity of the more than 1.3% of Americans who suffer from severe physical impairments (SPIs) preclude the use of common augmentative or alternative communication (AAC) solutions such as manual signs, gestures or dexterous interaction with a touchscreen for communication. While efforts to develop alternative access methods through eye or head tracking have provided some communication advancements for these individuals, all current technologies suffer from the same fundamental limitation: existing AAC devices require patients to conform to generic communication access methods and interfaces rather than the device conforming to the user. Consequently, AAC users are forced to settle for interventions that require excessive training and cognitive workload only to deliver extremely slow information transfer rates (ITRs) and recurrent communication errors that ultimately deprive them of the fundamental human right of communication. To meet this health need, we propose the first smart-AAC system designed using individually adaptive access methods and AAC interfaces to accommodate the unique manifestations of motor impairments specific to each user. Preliminary research by our team of speech researchers at Madonna Rehabilitation Hospital (Communication Center Lab) and Boston University (STEPP Lab), utilizing wearable sensors developed by our group (Altec, Inc) have already demonstrated that metrics based on surface electromyographic (sEMG) and accelerometer measures of muscle activity and movement for head-mediated control can be combined with optimizable AAC interfaces to improve ITRs when compared with traditional unoptimized AAC devices. Leveraging this pilot work, our team is now proposing a Phase I project to demonstrate the proof-of-concept that a single sEMG/IMU hybrid sensor worn on the forehead can provide improvements in ITR and communication accuracy when integrated with an AAC interface that is optimized through machine learning algorithms. The prototype system will be tested and compared to a conventional (non-adaptable) interface in subjects with SPI at a collaborative clinical site. Assistance by our speech and expert-AAC collaborators will ensure that all phases of technology development are patient-centric and usable in the context of clinical care. In Phase II we will build upon this proof-of-concept to design a smart-AAC system with automated optimization software that achieves dynamic learning which adapts to intra-individual changes in function through disease progression or training as well as inter-individual differences in motor impairments for a diverse set of users with spinal cord injury, traumatic brain injury, cerebral palsy, ALS, and other SPIs. The innovation is the first and only AAC technology that combines advancements in wearable-sensor access with interfaces that are autonomously optimized to the user, thereby reducing the resources and training needed to achieve effective person-centric communication in SPI, through improved HMI performance and reduced workload. This project addresses the fundamental mission of NIDCD (National Institute for Deafness and Communication Disorders) to provide a direct means of assisting communication for people with severe physical impairments caused by stroke, high level spinal cord injury, neural degeneration, or neuromuscular disease. Leveraging wearable access technology (which has barely been explored for AAC users), we will develop a first-of-its-kind adaptive tablet interface tailored to individual users through advanced movement classification algorithms. Through these efforts, we aim to provide an improved Human Machine Interface (HMI) that is able to accommodate varying degrees of inter- and intra-subject residual motor function and context dependent impairments to provide individuals with SPI the opportunity for improved societal integration and quality of life.",Adaptive & Individualized AAC,9907832,R43DC018437,"['Accelerometer', 'Address', 'American', 'Boston', 'Cerebral Palsy', 'Child', 'Cognitive', 'Communication', 'Communication Methods', 'Communication impairment', 'Computer software', 'Custom', 'Development', 'Devices', 'Diagnosis', 'Disease Progression', 'Ensure', 'Eye', 'Facial Muscles', 'Fatigue', 'Forehead', 'Gestures', 'Goals', 'Head', 'Head Movements', 'Health', 'Heterogeneity', 'Hospitals', 'Human Rights', 'Hybrids', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Individual Differences', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Linguistics', 'Manuals', 'Measures', 'Mediating', 'Methods', 'Mission', 'Motor', 'Motor Manifestations', 'Movement', 'Muscle', 'National Institute on Deafness and Other Communication Disorders', 'Nerve Degeneration', 'Neuromuscular Diseases', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Population Heterogeneity', 'Quality of life', 'Recurrence', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Series', 'Signal Transduction', 'Speech', 'Spinal cord injury', 'Stroke', 'Surface', 'System', 'Tablets', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Traumatic Brain Injury', 'United States National Aeronautics and Space Administration', 'Universities', 'User-Computer Interface', 'Variant', 'Work', 'Workload', 'alternative communication', 'base', 'classification algorithm', 'clinical care', 'clinical research site', 'communication device', 'deafness', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'mathematical model', 'motor impairment', 'novel', 'prototype', 'rehabilitation engineering', 'rehabilitation science', 'sensor', 'sensor technology', 'signal processing', 'technology development', 'touchscreen', 'two-dimensional', 'wearable device']",NIDCD,"ALTEC, INC.",R43,2019,224701,-0.014868825001315042
"BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging Project Summary Electrophysiological recordings in humans and animals play an essential role in developing an understanding of the human brain. Signal recording technology spans the entire scale from invasive microelectrode single-unit recordings, through mesoscale macroelectrode measures of local field potentials, to whole-brain monitoring through measurement of scalp potentials (EEG) and extracranial magnetic fields (MEG). Analysis of these data presents a host of challenges, from low level noise removal and artifact rejection to sophisticated spatio-temporal modeling and statistical inference. The multidisciplinary neuroscience research community has an ongoing need for validated and documented open-source software to perform this analysis and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets this need. Brainstorm is a Matlab/Java multi-platform (Linux, MacOS, Windows) software package for analysis and visualization of electrophysiological data. The software is extensively documented through a series of detailed tutorials and actively supported through a user forum and a mailing list. Over the past 8 years we have registered 16,000 distinct users, provided hands on instruction to 1,200 trainees, and the software has been used and cited in ~600 journal papers. Brainstorm includes tools for importing MEG/EEG, intracranial EEG, animal electrophysiology, and near-infrared spectroscopy (NIRS) data from multiple vendors, extensive interactive features for data preprocessing, selection and visualization, coregistration to volume and surface MRIs and atlases, forward and inverse mapping of cortical current density, time-series and connectivity analysis, and a range of statistical tools. Data can be analyzed through a graphical interface or through scripted pipelines. The current proposal represents a plan to extend Brainstorm in a manner that leverages the unique features of our software and addresses important needs for large-scale data analysis. In this project we will continue to extend and support our software through the following three specific aims: (i) we will harness recent developments in distributed and shared data and high performance computing resources, together with standardization of data organization, to facilitate large-scale, reproducible analysis of electrophysiological data. (ii) We will also address the need for improved modeling resulting from the increasing use of both invasive recordings and direct brain stimulation through development of new modeling software for accurate computation of the intracranial electromagnetic fields produced by brain stimulation and neuronal activation. (iii) Finally, we will continue to add new functionality and to support the software through in-person training, online forums, documentation and other resources. Project Narrative Magnetoencephalography (MEG) and Electroencephalography (EEG) are absolutely non-invasive brain imaging tools, which provide information on the spatial distribution and precise temporal orchestration of human brain activity. In addition to basic neuroscience research, MEG and EEG can be also used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses, including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. The neuroscience research community has an ongoing need for validated and documented open-source software to perform these analyses and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets these needs with well-documented and tested novel analyses using MEG and EEG in combination with anatomical MRI and intracranial EEG data.",BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging,9720885,R01EB026299,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Archives', 'Area', 'Atlases', 'Basic Science', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Development', 'Diagnosis', 'Documentation', 'Educational workshop', 'Electrodes', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Electrophysiology (science)', 'Ensure', 'Environment', 'Epilepsy', 'Excision', 'Frequencies', 'Goals', 'Grant', 'High Performance Computing', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Institution', 'Java', 'Joints', 'Journals', 'Language Development', 'Lead', 'Libraries', 'Linux', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Paper', 'Pathway Analysis', 'Pattern', 'Persons', 'Play', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scalp structure', 'Schizophrenia', 'Series', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Standardization', 'Surface', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Universities', 'Vendor', 'Work', 'autism spectrum disorder', 'cloud storage', 'cognitive benefits', 'computerized tools', 'computing resources', 'cortex mapping', 'data resource', 'data sharing', 'data structure', 'data warehouse', 'density', 'design', 'electric field', 'graphical user interface', 'hands on instruction', 'improved', 'interoperability', 'magnetic field', 'multidisciplinary', 'neuroimaging', 'novel', 'open source', 'relating to nervous system', 'response', 'spatiotemporal', 'tool']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,637924,0.03137516017584278
"Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled Iifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. n/a",Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry,9903672,R01GM135927,"['Accelerometer', 'Activity Cycles', 'Algorithms', 'Arrhythmia', 'Awareness', 'Behavior', 'Behavior monitoring', 'Big Data', 'Body Temperature', 'Cellular Phone', 'Chemotherapy-Oncologic Procedure', 'Collection', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Devices', 'Dust', 'Encapsulated', 'Energy Metabolism', 'Geometry', 'Glean', 'Goals', 'Growth', 'Health', 'Health Status', 'Healthcare', 'Heart', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Individual', 'Lead', 'Life', 'Location', 'Mathematics', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Movement', 'National Institute of General Medical Sciences', 'Outcome', 'Participant', 'Pattern', 'Periodicity', 'Physical activity', 'Population', 'Research', 'Research Project Grants', 'Rest', 'Sampling', 'Series', 'Signal Transduction', 'Swimming', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'Vision', 'Walking', 'Water', 'Work', 'base', 'circadian', 'design', 'diaries', 'health related quality of life', 'heart rate monitor', 'insight', 'interest', 'mathematical methods', 'metastatic colorectal', 'multimodality', 'personalized intervention', 'post stroke', 'programs', 'sensor', 'statistics', 'tool', 'wearable device']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,316425,-0.003341293866033119
"PsyNeuLink:  A Block Modeling Environment for Cognitive Neuroscience and Computational Psychiatry Project Summary Paralleling the growth of neuroscience research, there has been an explosion in the development of computationally explicit models of the functions of core brain subsystems. Unfortunately, however, there has not been a commensurate development of the tools needed to share, validate, and compare such models, or integrate them into models of system-level function. Such sharing, evaluation, and integration are necessary if computational modeling efforts are to be useful not only in generating reliable and accurate accounts of how brain subsystems operate, but also of how they interact to give rise to higher cognitive functions, and how disruptions of such interactions may give rise to disturbances of mental function observed in psychiatric and neurological disorders. This proposal seeks to meet this need by developing PsyNeuLink: an open source, Python-based software environment that makes it easy to create new models, import and/or re-implement existing ones, integrate these within a single software environment that will facilitate head-to-head comparison of comparable models, the assembly of complementary models into system-level models, and serve as a common repository for the documentation and dissemination of such models for both research and didactic purposes (i.e., publication, education, etc.). These goals will be pursued under two Specific Aims: 1) Extend the scope of modeling efforts that PsyNeuLink can accommodate by: i) enhancing its application programmer interface (API) used to add new components and interfaces to statistical analysis tools and other modeling environments (such as PyTorch, Emergent and ACT-R; ii) enriching its Library by adding PsyNeuLink implementations of influential models of neural subsystems; and iii) developing a publicly available workbook of simulation exercises as both an introduction to PsyNeuLink and for use in Cognitive Neuroscience and Computational Psychiatry curricula. 2) Accelerate PsyNeuLink by developing a custom compiler that preserves its simplicity and flexibility, while dramatically increasing its speed, to make it suitable for simulation of large and complex system-level models, and for parameter estimation, model fitting, and model comparison. This project will exploit the power and accelerating use of Python, and modern just-in-time compilation methods to develop a tool designed specifically for the needs of systems-level Cognitive Neuroscience and Computational Psychiatry. This promises to open up new opportunities for research at the systems-level — a level of analysis that is crucial both for understanding how human mental function emerges from the interplay among neural subsystems, and how disturbances of individual neural subsystems impact this interplay, disruptions of which are almost certainly a critical factor in neurologic and psychiatric disorders. Project Narrative Paralleling the growth of neuroscience research has been an explosion in the development of computationally explicit models of the functions of core brain subsystems. Unfortunately, however, there has not been a commensurate development of the tools needed to share, validate, and compare such models, or integrate them into models of system-level function. This proposed project seeks to address this need by developing a standard software platform for the construction, documentation, sharing, and integration of computational models of brain function, that promises to accelerate the study of how system-level interactions give rise to mental function and, critically, the kinds of disruptions of such system-level interactions produced by disturbances of individual subsystems — disruptions that are sure to be a complex but critical factor in neurological and psychiatric disorders.",PsyNeuLink:  A Block Modeling Environment for Cognitive Neuroscience and Computational Psychiatry,9824928,R21MH117548,"['Acceleration', 'Address', 'Architecture', 'Attention', 'Basal Ganglia', 'Biological', 'Biological Models', 'Brain', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Custom', 'Data', 'Development', 'Documentation', 'Education', 'Educational Curriculum', 'Environment', 'Episodic memory', 'Evaluation', 'Exercise', 'Explosion', 'Foundations', 'Goals', 'Grain', 'Growth', 'Hippocampus (Brain)', 'Human', 'Individual', 'Influentials', 'Libraries', 'Literature', 'Maintenance', 'Manuals', 'Mental disorders', 'Methods', 'Modeling', 'Modernization', 'Neurosciences Research', 'Perceptual learning', 'Play', 'Prefrontal Cortex', 'Procedures', 'Psychiatry', 'Publications', 'Publishing', 'Pythons', 'Research', 'Role', 'Seeds', 'Short-Term Memory', 'Speed', 'Statistical Data Interpretation', 'System', 'Time', 'Writing', 'base', 'cognitive function', 'cognitive neuroscience', 'cognitive process', 'deep learning', 'deep neural network', 'design', 'flexibility', 'head-to-head comparison', 'improved', 'learning network', 'memory encoding', 'memory retrieval', 'mental function', 'nervous system disorder', 'neural model', 'open source', 'parallelization', 'preservation', 'programs', 'relating to nervous system', 'repository', 'simulation', 'tool', 'tool development']",NIMH,PRINCETON UNIVERSITY,R21,2019,253798,-0.003983230744090369
"ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032) Project Summary/Abstract Technology has the potential to accelerate clinical research and reduce the burden of participation in rare diseases such as Duchenne Muscular Dystrophy (DMD). DMD is an x-linked genetic disorder that results in progressive muscle weakness with loss of ambulation by 10-12 years of age, progression of arm weakness resulting in difficulty with self-feeding and other self-care activities in adolescence, and death resulting from cardiopulmonary insufficiency by age 30 years. Studies in rare diseases are inherently difficult due to a small recruitment pool and a limited number of sites that possess the experience and resources to participate as a study site. An outcome measure that quantifies change in both ambulant and non-ambulant individuals with minimal evaluator training could enable more efficient data collection in multi-site clinical trials. Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), has the potential to meet this need. ACTIVE is a 65-second game utilizing a skeletal-tracking algorithm to quantify workspace volume (WSV) elicited through maximal arm reaching overhead, side-to-side, and forward while also encouraging trunk lean in each direction. Our studies have shown that ACTIVE is valid and reliable in quantifying WSV in persons with DMD across the span of age and abilities. However, to increase access and portability of a tool for use across trial sites, it is critical that tool has sound scientific and technological construction. ACTIVE WSV was originally built upon the Microsoft Kinect and Kinect One for Xbox platforms. The skeletal tracking algorithm developed by Microsoft vastly exceeds all other programs as it had the full backing of the Microsoft machine. Unfortunately, the Kinect, in its additional sense, has been abandoned for more current artificial intelligence applications. The Microsoft Kinect Azure will soon be released with higher resolution and programming capabilities. Our full DDT submission has been delayed as each new camera release has required reprogramming of our software to ensure valid and reliable results. Our team has recently expanded to include software development partners, The Plan Works (thePlan), who have the technological expertise to alter our current codebase to ensure transfer of ACTIVE across camera sensor platforms is more efficient and reliable as we expect ongoing technological advances to provide opportunities for continued advances. To this end, our current application seeks support to verify the technology of the ACTIVE WSV system to 1) confirm the use of unique code that can be ported across platforms over time and 2) improving the ease of use and limit training needed at a growing number of inexperienced centers. Project Narrative Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), is a 65-second outcome assessment that quantifies a person’s workspace volume and has the potential to expand the enrollment pool by measuring both ambulant and non-ambulant subjects. While the scientific construction of the tool is sound, ongoing technological advances and changes have made it challenging to port our software across camera platforms. Our proposal seeks funding to support final software updates to ensure changes in technology components (i.e. camera sensor systems) or coding instability will not interfere with clinical trial data collection and allow us to complete our final submission package.",ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032),9989528,U01FD006883,[' '],FDA,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,U01,2019,215170,-0.0008792889067156346
"CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience The field of network neuroscience has developed powerful analysis tools for studying brain networks and holds promise for deepening our understanding of the role played by brain networks in health, disease, development, and cognition. Despite widespread interest, barriers exist that prevent these tools from having broader impact. These include (1) unstandardized practices for sharing and documenting software, (2) long delays from when a method is first introduced to when it becomes publicly available, and (3) gaps in theoretic knowledge and understanding leading to incorrect, delays due to mistakes, and errors in reported results. These barriers ultimately slow the rate of neuroscientific discovery and stall progress in applied domains. To overcome these challenges, we will use open science methods and cloud-computing, to increase the availability of network neuroscience tools. We will use the platform ""brainlife.io"" for sharing these tools, which will be packaged into self-contained, standardized, reproducible Apps, shared with and modified by a community of users, and integrated into existing brainlife.io analysis pipelines. Apps will also be accompanied by links to primary sources, in-depth tutorials, and documentation, and worked-through examples, highlighting their correct usage and offering solutions for mitigating possible pitfalls. In standardizing and packaging network neuroscience tools as Apps, this proposed research will engage a new generation of neuroscientists, providing them powerful new and leading to new discoveries. Second, the proposed research will contribute growing suite of modeling analysis that can be modified to suit specialized purposes. Finally, the Brainlife.io platform will serve as part of the infrastructure supporting neuroscience research. Altogether, these advances will lead to new opportunities in network neuroscience research and further stimulate its growth while increasing synergies with other domains in neuroscience. Structural and functional networks support cognitive processes. Miswiring networks lead to maladaptive behavior and neuropsychicatric disorders. Network neuroscience is a young field that provides a quantitative framework for modeling brain networks. This project will make network neuroscientific tools available to new users via open science and cloud-computing. New applications of these tools this will lead deeper insight into the role of networks in health as well as in clinical disorders.",CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience,9916138,R01EB029272,"['Address', 'Aging', 'Biophysics', 'Brain', 'Cloud Computing', 'Cognition', 'Communities', 'Complex Analysis', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Elements', 'France', 'Funding', 'Generations', 'Graph', 'Growth', 'Instruction', 'Knowledge', 'Language', 'Lead', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Mathematics', 'Methods', 'Modeling', 'Neurosciences', 'Pathway Analysis', 'Play', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Science', 'Sociology', 'Standardization', 'Structure', 'Study models', 'System', 'Techniques', 'Time', 'Training', 'analysis pipeline', 'brain computer interface', 'cloud based', 'cyber infrastructure', 'data sharing', 'experience', 'innovation', 'insight', 'learning strategy', 'network architecture', 'network models', 'neuroimaging', 'open data', 'prevent', 'relating to nervous system', 'statistics', 'tool']",NIBIB,INDIANA UNIVERSITY BLOOMINGTON,R01,2019,215134,0.01614674485061854
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community—the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit’s gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing. Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9570624,R44AG053890,"['3-Dimensional', 'Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Custom', 'Dependence', 'Devices', 'Electrical Engineering', 'Emotional', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Impairment', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Vision', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'rehabilitation technology', 'robot exoskeleton', 'usability']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2019,814735,-0.00036747285371204857
"Environmental Localization Mapping and Guidance for Visual Prosthesis Users Project Summary About 1.3 million Americans aged 40 and older are legally blind, a majority because of diseases with onset later in life, such as glaucoma and age-related macular degeneration. Second Sight has developed the world's first FDA approved retinal implant, Argus II, intended to restore some functional vision for people suffering from retinitis pigmentosa (RP). In this era of smart devices, generic navigation technology, such as GPS mapping apps for smartphones, can provide directions to help guide a blind user from point A to point B. However, these navigational aids do little to enable blind users to form an egocentric understanding of the surroundings, are not suited to navigation indoors, and do nothing to assist in avoiding obstacles to mobility. The Argus II, on the other hand, provides blind users with a limited visual representation of their surroundings that improves users' ability to orient themselves and traverse obstacles, yet lacks features for high-level navigation and semantic interpretation of the surroundings. The proposed research aims to address these limitations of the Argus II through a synergy of state-of-the-art stimultaneous localization and mapping (SLAM) and object recognition technologies. For the past three years, JHU/APL has collaborated with Second Sight to develop similar advanced vision-based capabilities for the Argus II, including capabilities for object recognition and obstacle detection by stereo vision. This proposal is driven by the hypothesis that navigation for users of retinal prosthetics can be greatly improved by incorporating SLAM and object recognition technology conveying environmental information via a retinal prosthesis and auditory feedback. SLAM enables the visual prosthesis system to construct a map of the user's environment and locate the user within that map. The system then provides object location and navigational cues via appropriate sensory modalities enabling the user to mentally form an egocentric map of the environment. We propose to develop and test a visual prosthesis system which 1) constructs a map of unfamiliar environments and localizes the user using SLAM technology 2) automatically identifies navigationally-relevant objects and landmarks using object recognition and 3) provides sensory feedback for navigation, obstacle avoidance, and object/landmark identification. Project Narrative The proposed system, when realized, will use advanced simultaneous localization and mapping, and object recognition techniques, to enable visual prosthesis users with unprecedented abilities to autonomously navigate and identify objects/landmarks in unfamiliar environments.",Environmental Localization Mapping and Guidance for Visual Prosthesis Users,9818350,R01EY029741,"['3-Dimensional', 'Address', 'Age related macular degeneration', 'Algorithms', 'American', 'Competence', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Detection', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Environment', 'Evaluation', 'FDA approved', 'Feedback', 'Glaucoma', 'Goals', 'Image', 'Implant', 'Late-Onset Disorder', 'Lead', 'Learning', 'Life', 'Location', 'Maps', 'Medical Device', 'Modality', 'Motion', 'Ocular Prosthesis', 'Patients', 'Performance', 'Psyche structure', 'Research', 'Retinitis Pigmentosa', 'Running', 'Semantics', 'Sensory', 'Societies', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vision', 'Visual', 'Volition', 'aged', 'auditory feedback', 'base', 'behavior test', 'blind', 'cognitive load', 'falls', 'human subject', 'improved', 'innovation', 'legally blind', 'navigation aid', 'object recognition', 'portability', 'prosthesis wearer', 'prototype', 'research and development', 'retina implantation', 'retinal prosthesis', 'sensory feedback', 'smartphone Application', 'synergism', 'visual feedback', 'visual information']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2019,641060,0.009300719521356669
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9733348,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Infrastructure', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'data sharing', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual technology']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2019,379357,0.007856104299823473
"Introducing Neuroscience and Neurocomputation Concepts to High School Students using Brain-based Neurorobots PROJECT SUMMARY Understanding the brain is a profound and fascinating challenge, captivating the scientific community and the public alike. The lack of effective treatment for most brain disorders makes the training of the next generation of neuroscientists, engineers and physicians a key concern. However, much neuroscience is perceived to be too difficult to be taught in school. To make neuroscience more accessible and engaging to students and teachers, Backyard Brains is developing neurorobots for education: fun and affordable robots with camera­eyes, wheels, WiFi and artificial software brains modeled on real biological brains. The neurorobot kit will allow students to investigate meaningful real­world questions about mind, brain and behavior by designing artificial brains that make the robot’s behavior life­like, sensory­guided and goal­directed. In Phase I of this project, students will work in groups to investigate the question “Why does my dog come to me when I call?” by designing neural networks that make the robot approach when called for. While the robot moves around in the classroom, students will be able to observe its visual sensory input and the flow of activity between its neurons on a smartphone or laptop, and interact with the brain using voice commands and a “reward button” that drives learning. By designing, testing and analysing neurorobot brains, students will acquire a practical understanding of neurons, synapses, neural networks, brain functions, and the relationship between brain and behavior, and develop important computational thinking skills and self­conception as neuroscientists. For Phase I we will develop neurorobot hardware and software, and collaborate with education specialists to develop and evaluate a short high­school instructional unit around neurorobots. Our overall Phase I goal is to demonstrate the feasibility and educational value of using neurorobots to teach high­school neuroscience. Our unique combination of low­cost robot hardware, innovative curriculum, and easy­to­use applications makes our product appealing to our large high­school, university, and amateur customer base. For Phase II we will expand the curriculum and the capabilities of our neurorobot kit, and create an online forum where students and teachers can share brains and discuss experiments. Our long­term aim is to encourage education policy makers to adopt neuroscience requirements by demonstrating an effective neuroscience curriculum organized around brain­based neurorobots. By combining neuroscience, a multidisciplinary field that spans biology, medicine, psychology, mathematics, and engineering, with robotics and a project­based approach to learning, our neurorobots and curriculum will improve STEM­education and inspire the next generation of scientists, engineers and physicians. PROJECT NARRATIVE Backyard Brains is developing neurorobots for education: engaging and affordable robots with artificial software brains based on the latest neuroscience research. The robots and associated lesson plans will enable students to learn neuroscience by creating artificial brains that make the robot’s behavior life­like, sensory­guided and goal­directed. By giving teachers and students access to neurorobotic technologies previously only available in research labs, we aim to inspire the next generation of scientists, engineers and physicians.",Introducing Neuroscience and Neurocomputation Concepts to High School Students using Brain-based Neurorobots,9763674,R43NS108850,"['Address', 'Adopted', 'Anatomy', 'Animals', 'Artificial Intelligence', 'Attitude', 'Auditory', 'Base of the Brain', 'Behavior', 'Binocular Vision', 'Biological', 'Biological Neural Networks', 'Biology', 'Brain', 'Brain Diseases', 'Canis familiaris', 'Cellular Phone', 'Color', 'Communication', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Conceptions', 'Data', 'Devices', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Engineering', 'Ensure', 'Eye', 'Future Teacher', 'Goals', 'High School Student', 'Instruction', 'Interneurons', 'Knowledge', 'Learning', 'Life', 'Locomotion', 'Mathematics', 'Medicine', 'Mind', 'Modeling', 'Motor', 'Nerve', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Next Generation Science Standards', 'Outcome', 'Output', 'Phase', 'Physicians', 'Policy Maker', 'Property', 'Psychology', 'Research', 'Rewards', 'Robot', 'Robotics', 'Role', 'Schools', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Sensory', 'Specialist', 'Students', 'Synapses', 'Technology', 'Testing', 'Training', 'Universities', 'Visual', 'Voice', 'Work', 'base', 'brain behavior', 'brain tract', 'commercialization', 'computational reasoning', 'cost', 'design', 'effective therapy', 'experience', 'experimental study', 'fascinate', 'gaze', 'graphical user interface', 'handheld mobile device', 'high school', 'improved', 'innovation', 'laptop', 'multidisciplinary', 'neural network', 'next generation', 'preference', 'project-based learning', 'science education', 'sensor', 'sensory input', 'skills', 'sound', 'success', 'teacher', 'tool', 'twelfth grade']",NINDS,"BACKYARD BRAINS, INC.",R43,2019,312460,-0.00014969074273984737
"Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies Project Summary Traditionally, environmental epidemiologic studies have focused on assessing risks related to a single pollutant at a time. This, however, does not reflect reality, since we are constantly exposed to multiple pollutants at once. It is very important, therefore, to be able to assess exposure to pollutant mixtures when conducting environmental epidemiologic methods. Doing so, however, is especially challenging, mainly due to the high dimension of the multi-pollutant exposure matrix (if the exposure of interest includes more than e.g. 5 or 10 chemicals) and because these pollutants are usually very highly correlated with each other. Although some methods are available to address these issues, they usually require strong assumptions and have severe limitations. With this study we propose to bypass most of these limitations by adapting and extending a novel and robust method to assess exposure to multiple pollutants, called Principal Component Pursuit (PCP). We will assess the performance of PCP synthetic datasets representing multiple potential scenarios and study designs, and compare our results to those obtained by existing methods. Subsequently, we will apply PCP to three important Public Health issues, i.e. to evaluate the associations between (i) in utero exposure to a mixture of PCBs and neurodevelopment, (ii) exposure to a metals mixture and cardiovascular health, and (iii) exposure to an air pollution mixture and emergency cardiovascular admissions. Finally, we will develop and share software so other researchers can freely use this novel, robust and flexible tool across a plethora of study designs and research questions. Our proposed work will be significant as it will provide epidemiologists with a novel and robust tool to assess exposure to environmental pollutant mixtures. Project Narrative We are constantly exposed to a mixture of environmental pollutants at once, but current epidemiologic methods either assess each pollutant separately, not capturing reality, or have severe limitations. With this study we propose to adapt a wildly popular method used in computer vision applications, called Principal Component Pursuit (PCP), and develop flexible extensions for many epidemiologic settings. We propose to assess the performance of this method, compare with existing methods and employ in real-life applications, as well as develop and share software so other research can also use this novel, robust and flexible tool.",Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies,9617736,R01ES028805,"['Accounting', 'Address', 'Admission activity', 'Air Pollutants', 'Air Pollution', 'Biological', 'Bypass', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chemicals', 'Child', 'Child Development', 'Child Health', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Detection', 'Dimensions', 'Disadvantaged', 'Educational workshop', 'Emergency Situation', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Pollutants', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Exposure to', 'Family', 'Geography', 'Health', 'Heart', 'Joints', 'Life', 'Measurement', 'Metal exposure', 'Metals', 'Methods', 'National Institute of Environmental Health Sciences', 'New York', 'New York City', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Poison', 'Polychlorinated Biphenyls', 'Public Health', 'Publishing', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Sample Size', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'System', 'Techniques', 'Time', 'Toxic effect', 'Toxicology', 'Work', 'cardiovascular health', 'cohort', 'design', 'epidemiology study', 'flexibility', 'health data', 'high dimensionality', 'interest', 'neurodevelopment', 'novel', 'policy implication', 'pollutant', 'prenatal exposure', 'programs', 'tool', 'user-friendly']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,600285,-0.006363316624610925
"Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration There is an enormous deficit in students’ understanding of fractions in the United States. Fifth grade fraction knowledge predicts high school math performance, even when controlling for working memory, whole number knowledge, IQ, reading ability, and demographic factors (Siegler et al., 2012). Therefore, addressing this deficit is a particularly important area for early intervention. With this Fast-Track grant, Deep Fractions Learning , we propose to transform the way in which students learn core math curriculum so that materials are more interactive and engaging, promote deeper learning of content, and are aligned with the Common Core. More specifically, we will develop and evaluate a digital curriculum for grades 3-5 covering the fractions domain that combines games, collaboration, and an inquiry approach. We propose to develop an innovative technology infrastructure that will integrate Teachley learning games, Success for All’s (SFA) cooperative learning framework, and rigorous lesson content. We will integrate research into the design process and work with Johns Hopkins University to evaluate the efficacy of the intervention. Outcomes. The intervention will encourage four direct outcomes for students, namely improved: 1) conceptual understanding of fractions, 2) procedural fluency with fractions operations, 3) mathematical justification, and 4) motivation. First, the curriculum will build both conceptual understanding and procedural fluency, providing strong visual models within engaging games that motivate students to practice. The collaborative learning model and inquiry approach will improve students’ mathematical justification. Finally, we encourage these outcomes within a motivational support structure designed to foster engagement and self-efficacy. Improving students’ academic outcomes and self-efficacy in the area of fractions during elementary school will promote later success in high school mathematics. Since each additional math class students complete in high school more than doubles the odds of college completion (Adelman, 2006), the intervention has the potential to make a real difference in whether students achieve sustainable careers versus being stuck in low-wage jobs. Fractions knowledge in the fifth grade strongly predicts high school math performance, even when controlling for working memory, whole number knowledge, IQ, reading ability, and demographic factors (Siegler et al., 2012). Intervention in this essential content area will improve students’ math ability in the short and long term, which in turn will lead to several positive distal outcomes, such as greater high school graduation rates and college attendance.","Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration",9789518,R44GM130162,"['Active Learning', 'Address', 'Area', 'Behavior', 'Child', 'Collaborations', 'Common Core', 'Control Groups', 'Demographic Factors', 'Distal', 'Early Intervention', 'Educational Curriculum', 'Ethnic Origin', 'Fostering', 'Goals', 'Graduation Rates', 'Grant', 'High School Student', 'Infrastructure', 'Instruction', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Maps', 'Mathematics', 'Mathematics Curriculum', 'Measures', 'Modeling', 'Motivation', 'Occupations', 'Online Systems', 'Outcome', 'Performance', 'Phase', 'Privatization', 'Process', 'Research', 'Sampling', 'Self Efficacy', 'Services', 'Short-Term Memory', 'Structure', 'Students', 'Treatment Efficacy', 'United States', 'Universities', 'Visual', 'Wages', 'Work', 'boys', 'career', 'college', 'dashboard', 'deep learning', 'design', 'digital', 'elementary school', 'fifth grade', 'fourth grade', 'girls', 'high school', 'improved', 'innovation', 'innovative technologies', 'mathematical ability', 'operation', 'prototype', 'reading ability', 'success', 'teacher', 'third grade', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2019,463456,-0.0011372426509798793
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9851024,R44GM130247,"['3-Dimensional', 'Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'machine vision', 'mid-career faculty', 'mixed reality', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2019,782476,0.007822028943013058
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9768578,U01MH117072,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'preservation', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2019,2003389,-0.04289567727301737
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9778578,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2019,225000,0.001597964578658145
"Automating whole brain connectomics: development, validation, and application of an open toolkit Project Summary/Abstract We have recently published a 3D electron microscopy volume of the whole fruit fly brain. However mapping of synaptic `wiring diagrams' or connectomes of neuronal circuits from this volume is currently completely manual and therefore slow. Our long-term goal is to increase understanding of how circuits process and transform information, both by accelerating connectomics mapping, and increasing the power and accessibility of analysis tools. The overall objectives in this application are to (i) provide newly available whole-brain segmentations to the user community, by extending the widely used, web-based circuit-mapping and analysis platform, CATMAID; and (ii) develop, validate, and apply new analysis tools for delivering insight into circuit structure. These objectives will be achieved through three specific aims: 1) Deploy automatic segmentations to a CATMAID server where members of the fly neurobiology community can create and manage their own collaborative projects; 2) Provide integrated, scalable, and cross-modal software for analysis of connectomes and neurogeometry; and 3) Complete proof-of-principle projects using this infrastructure, including the first whole-brain tractography database, a study of stereotypy in position, number and connectivity of tracts and identified cell types, and a complete map of microconnectivity in the calyx of the mushroom body. In Aim 1, two recently generated whole-brain segmentations of all neurites and all synaptic clefts will be skeletonized, imported into CATMAID, and provided for use by the fly neurobiologists (>20 labs immediately; the entire community shortly thereafter). In Aim 2, tools for shape-based neuron search will be integrated into CATMAID, allowing online databases of cell type morphology to assist the reconstruction workflow and find genetic driver lines for behavior and physiology experiments at the bench. Analysis software will be written for automated tractography, location of contralateral circuit element equivalents, and identification of synaptic partners. In Aim 3, this infrastructure will be used in proof-of-principle analyses designed to test and guide infrastructure development, while providing important biological contributions in their own right. The proposed research is innovative because it will: almost immediately provide segmentation-assisted circuit reconstruction to the fly community in the whole fly brain dataset; provide powerful new analysis tools; and enable individual labs to form and manage their own public or private collaborations in an expertly managed server environment. The proposed research is significant because acceleration of circuit mapping will greatly increase our understanding of information processing in the brain of an important animal model system, the fruit fly Drosophila melanogaster; further, these tools will be applicable to diverse brain tissues and organisms. Ultimately, this infrastructure will therefore contribute to a qualitatively improved understanding of how neuronal circuits process and store information across phyla. Project Narrative The proposed research is relevant to public health because it provides a new and cutting-edge strategy to accelerate mapping of brain circuits at a synaptic level, a prerequisite to understanding circuit function in normal and diseased brains. The proposed infrastructure is relevant to the part of the BRAIN Initiative's mission that pertains to revolutionizing our understanding of brain function through tool development and improved data analysis technologies.","Automating whole brain connectomics: development, validation, and application of an open toolkit",9822552,RF1MH120679,"['3-Dimensional', 'Acceleration', 'Adult', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Automated Annotation', 'BRAIN initiative', 'Behavior', 'Behavior Control', 'Biological', 'Biological Models', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Cell Count', 'Cells', 'Cerebral hemisphere', 'Collaborations', 'Communities', 'Complement', 'Computer software', 'Contralateral', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Drosophila genus', 'Drosophila melanogaster', 'Electron Microscopy', 'Electrophysiology (science)', 'Elements', 'Environment', 'Female', 'Generations', 'Genetic', 'Goals', 'Human', 'Image', 'Individual', 'Infrastructure', 'Letters', 'Location', 'Manuals', 'Maps', 'Measures', 'Memory', 'Mission', 'Modality', 'Modeling', 'Morphology', 'Motivation', 'Mushroom Bodies', 'Neurites', 'Neurobiology', 'Neurons', 'Online Systems', 'Organism', 'Pattern', 'Physiology', 'Positioning Attribute', 'Privatization', 'Process', 'Public Domains', 'Public Health', 'Publications', 'Publishing', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Services', 'Shapes', 'Skeleton', 'Structure', 'Synapses', 'Synaptic Cleft', 'Techniques', 'Technology', 'Testing', 'Validation', 'Work', 'base', 'brain tissue', 'cell type', 'connectome', 'deep learning', 'design', 'experimental study', 'fly', 'improved', 'information processing', 'infrastructure development', 'innovation', 'insight', 'light microscopy', 'member', 'microscopic imaging', 'neural circuit', 'neuronal circuitry', 'optical imaging', 'reconstruction', 'scaffold', 'stereotypy', 'tool', 'tool development', 'tractography']",NIMH,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,RF1,2019,1910784,-0.009831899787442405
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9772484,R42EY027651,"['Address', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'machine learning algorithm', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2019,648557,-0.015032238298669807
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9731544,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'repository', 'research and development', 'software development', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,350620,-0.01717218882066765
"The chondrocranium in craniofacial development and disease Most investigations of craniosynostosis focus on the dermatocranium, the second cranial skeleton to form during embryogenesis that comprises the dermal bones of the cranial vault and facial skeleton. A completely separate cranial skeleton, the chondrocranium, develops before the dermatocranium to support the embryonic brain and other sense organs. Historically, the chondrocranium has been studied across the vertebrates and is recognized as fundamental to craniofacial development, but it is not well known to craniofacial biologists and has never been studied in the laboratory mouse until now. The chondrocranium is formed of cartilage and though parts of it ossify endochondrally, other portions begin to degenerate by about embryonic day 15-16 in the mouse. By careful analysis of whole mount and histological specimens, we have documented the synchronized deterioration of select chondrocranial elements with the appearance and superimposition of particular dermal bones of the growing dermatocranium. These observations signal the existence of a mechanism for the coordinated, localized expansion (dermal bones) and resorption (cartilage) of two developmentally and evolutionarily separate skeletal systems. Our project, supported by strong preliminary data of the mouse chondrocranium, is designed to test a central hypothesis: that the chondrocranium serves as a structural and functional scaffold for the later development of dermatocranial elements including the formation of cranial vault sutures. Based on the common finding that boundaries between different cell populations often serve as tissue organizers, we recognize the establishment and maintenance of stable boundaries that restrict the mixing of different cell populations as critical to proper development, and propose a research design that interrogates the chondrocranial/dermatocranial boundary as significant to the coordinated development of the skull. We will interrogate cells at specific sites to determine the processes that function to maintain the boundaries. Then using the Fgfr2c+/C342Y mouse model for craniosynostosis, we will investigate relevant chondrocranial/dermatocranial boundaries operative in the development of two craniosynostosis phenotypes: premature closure of the coronal suture and abnormal growth of the midface. That the chondrocranium is composed of irregularly shaped cartilages, many of which are short-lived, requires that we conceive new tools for analysis. We will complete development of an innovative system to dissect and reconstruct the chondrocranium in silico from micro computed tomography images with tight temporal control, precisely delineate chondrocranial anatomy in 3D over embryonic time, and establish the role of the chondrocranium in development of the dermatocranium. Achieving our goals will enrich textbook knowledge of craniofacial development by defining the role of the chondrocranium in the production of dermatocranial phenotypes, provide information relative to the pathophysiology of countless craniofacial anomalies, and reveal potential avenues for the development of novel therapeutics. Craniofacial anomalies are common birth defects that require comprehensive, sometimes repetitive corrective surgeries to manage individual cases. To ameliorate the financial and emotional burden on patients and their families, efforts are aimed at the development of preventative therapies but these require a thorough understanding of craniofacial development. We offer novel information about the chondrocranium, the first embryonic cranial skeleton to develop, and focus on mechanisms operating within boundaries between it and the dermatocranium that are critical to craniofacial development, in normal individuals and in craniofacial disease.",The chondrocranium in craniofacial development and disease,9657003,R01DE027677,"['3-Dimensional', 'Acids', 'Affect', 'Age', 'Anatomy', 'Apert-Crouzon syndrome', 'Apoptosis', 'Appearance', 'Awareness', 'Birth', 'Bone Resorption', 'Brain', 'Cartilage', 'Cell Lineage', 'Cell physiology', 'Cells', 'Cephalic', 'Chondrichthyes', 'Chondrocranium', 'Complex', 'Computer Simulation', 'Congenital Abnormality', 'Craniofacial Abnormalities', 'Craniosynostosis', 'Data', 'Dermal', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Elements', 'Embryo', 'Embryonic Development', 'Embryonic Structures', 'Emotional', 'Ethnic group', 'Event', 'Face', 'Family', 'Functional disorder', 'Gene Expression', 'Goals', 'Graph', 'Growth', 'Image', 'Incidence', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory mice', 'Live Birth', 'Maintenance', 'Modernization', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Operative Surgical Procedures', 'Osteoblasts', 'Pathway interactions', 'Patients', 'Phenotype', 'Play', 'Population', 'Preventive therapy', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Regulation', 'Reproducibility', 'Research', 'Research Design', 'Role', 'Sense Organs', 'Signal Transduction', 'Site', 'Skeletal system', 'Skeleton', 'Staging System', 'Stains', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Tissues', 'Transgenic Mice', 'Vertebrates', 'X-Ray Computed Tomography', 'base', 'bone', 'cleft lip and palate', 'coronal suture', 'craniofacial', 'craniofacial development', 'cranium', 'deep learning', 'design', 'fibroblast growth factor receptor 2c', 'histological specimens', 'imaging Segmentation', 'innovation', 'molecular marker', 'mouse model', 'novel', 'novel therapeutics', 'osteogenic', 'premature', 'reconstruction', 'scaffold', 'sex', 'spatiotemporal', 'three-dimensional modeling', 'tool']",NIDCR,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2019,523782,-0.033277708778047047
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9700159,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2019,1290517,0.0013333752996137534
"Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data NARRATIVE SUMMARY The landscape of data formats is rapidly expanding, with image, text and other complex formats becoming available for health related outcomes. By considering such data within the context of observational causal inference, they can be leveraged to improve clinical decisions, help evaluate treatment efficacy by estimating individualized treatment effects and help develop intelligent therapeutic systems where individualized treatments can be deployed. In R01EB025021, we concentrate on understanding how nearly exact matching can be achieved in the presence of a large number of categorical covariates. The proposed approach (called FLAME - Fast Large Almost Matching Exactly) is able to quickly learn which categorical covariates are important and to produce high quality matches \citep{wang2017flame,dieng2018collapsing}. The main shortfall in the proposed work for R01EB025021 is that it does not naturally extend to more complex data types, it only works for categorical data in which each feature is meaningful. {\bf This proposal will develop new statistical and computational tools for causal analysis of complex data structures.} Our new approach is called {\emph Matching After Learning to Stretch (MALTS)}. For each unit (e.g. patient), we propose learn a latent representation of their covariate information and a distance metric on the latent space such that units that are matched tend to provide accurate estimates of treatment effect. MALTS can use deep learning to encode the latent representations for the units, or it can learn basis transformations in linear space (stretching and rotation matrices) for simpler continuous data types. We will develop the MALTS algorithm, and apply it in a medical context. Our goal is to construct high quality matches for the following types of data: (i) medical images, such as x-rays and CT scans, (ii) medical record data, (iii) time series data (continuous EEG data), (iv) a combination of any of the first three types of data. We aim to leverage the newly developed tools to continue our evaluation of the efficacy of isolation for flu-like ailments as well as to apply them more broadly to publicly available modern datasets such as the MIMIC III database. Reliable and consistent causal analysis of public health interventions requires the use of massive previously unavailable datastreams. For example, evaluation of the efficacy of isolation interventions on flu-like-illness spread must include information on friendships and interactions between individuals, biometric information, imaging, longitudinal health record data as well as standard demographic data. The proposed research provides machine learning and deep learning tools for properly employing this data for the identification and quantification of causal effects of such treatments that can lead to the development of better public health interventions.",Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data,9750434,R01EB025021,"['Algorithms', 'Biometry', 'Categories', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Electroencephalography', 'Friendships', 'Goals', 'Health', 'Image', 'Individual', 'Intervention', 'Lead', 'Learning', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Modernization', 'Outcome', 'Patients', 'Research', 'Roentgen Rays', 'Rotation', 'Series', 'Stretching', 'Structure', 'System', 'Text', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'X-Ray Computed Tomography', 'computerized tools', 'data format', 'deep learning', 'efficacy evaluation', 'flu', 'health record', 'improved', 'individualized medicine', 'novel strategies', 'public health intervention', 'tool', 'treatment effect']",NIBIB,DUKE UNIVERSITY,R01,2018,98714,-0.011516291191947334
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9507909,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Grain', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'cognitive development', 'computerized', 'cost', 'deep learning', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'sensor technology', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2018,203125,0.0008485621966077122
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9544939,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2018,210165,0.008280483434358322
"ADNI Psychometrics: fcMRI and Machine Learning Aim 2 Supplement Project Summary/Abstract This supplement is to a funded R01 called ADNI Psychometrics. This Supplement builds on the Second Specific Aim of the funded parent grant. That Aim focused on characterizing brain structure and functioning for people with different cognitively- defined subgroups of Alzheimer's disease. The Supplement adds one technique for analyzing the structural data we are already analyzing, and adds analyses of functional data we had not previously been planning to analyze. The new technique for structural data is machine learning. We have the opportunity to collaborate with a talented faculty member in Biomedical Informatics who has specific expertise in machine learning approaches to anatomical data (J Gennari). Dr. Genarri will supervise machine learning approaches to complement the various analytical approaches we already have underway for Aim 2. The new functional data analyses incorporate measurements of blood oxygen level dependent (BOLD) data from resting state functional connectivity MRI (fcMRI) data collected by ADNI. Those data enable the characterization of functional connectivity. There are many levels of correlation in the analyses of longitudinal fcMRI data, and another talented faculty member in Radiology has specific expertise in analyzing these data (T Madhyastha). Dr. Madhyastha will supervise analyses of longitudinal fcMRI data from the cognitively-defined subgroups of Aim 2, which will provide important additional information regarding whether the functional connectivity patterns of people in these subgroups are similar to or different from each other. Project Narrative This Supplement proposal builds on the second aim of R01 AG 029672, ""ADNI Psychometrics (P Crane, PI) , which is to use ADNI's rich neuroimaging data to compare metabolism and brain structure correlates of cognitively defined Alzheimer's disease subgroups. This proposal would add analyses of functional connectivity, and would add machine learning approaches to the analytic strategies already being pursued by the investigators. This Supplement Proposal would substantially augment the scientific value of the overall study.",ADNI Psychometrics: fcMRI and Machine Learning Aim 2 Supplement,9678230,R01AG029672,"['Alzheimer&apos', 's Disease', 'Anatomy', 'Attention', 'Brain', 'Clinical', 'Cognitive', 'Complement', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Enrollment', 'Faculty', 'Funding', 'Guidelines', 'International', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Memory', 'Metabolism', 'Modeling', 'Pattern', 'Psychometrics', 'Radiology Specialty', 'Research Personnel', 'Rest', 'Structure', 'Subgroup', 'Supervision', 'Talents', 'Techniques', 'Testing', 'Text', 'Visuospatial', 'biomedical informatics', 'blood oxygen level dependent', 'cerebral atrophy', 'clinical Diagnosis', 'clinical heterogeneity', 'disorder subtype', 'executive function', 'longitudinal analysis', 'member', 'neuroimaging', 'parent grant', 'response', 'tool']",NIA,UNIVERSITY OF WASHINGTON,R01,2018,251863,-0.030211703094716436
"Machine Learning for Generalized Multiscale Modeling Project Summary/Abstract  This project develops machine learning approaches that describe statistical systems in biology. By combining analytic results calculated from the exact probabilistic description of the system with machine learning inference, our new methods present exciting opportunities to model previously inaccessible complex dynamics. The resulting Boltzmann machine-like learning algorithms present a new class of modeling techniques based on the powerful in- ference of arti cial neural networks. Further development of this approach will bring the groundbreaking advances from the surge of recent interest in machine learning into the biological modeling eld. The mathematical methods we develop will be used to derive e cient algorithms for multiscale simulation, directly applicable to large scale biological modeling. In particular, the algorithms will be used to study the dynamics of stochastic biochemistry at synapses, with direct relevance to learning and memory formation in the brain. Current studies of these processes are limited by the long timescales involved and the highly spatially organized structures featured. In addition to leveraging the machine learning expertise we are developing, we also employ new electron microscopy datasets to produce 3D reconstructions of neural tissue with unprecedented accuracy. Consequentially, we will be able to study the fundamental mechanisms underlying synaptic plasticity, as well as the biochemical basis of oscillatory behavior in networks of neurons that occurs during sleep. Furthermore, the interactions of these highly stochastic ion channels with electrical in neurons will be explored through groundbreaking hybrid simulation environments. The software that we will develop combines existing popular simulation tools into multiscale approaches, and will be distributed as a powerful tool to the broader biological modeling community. Its usage in further computational experiments can present a key advancement in the development of pharmaceuticals, allowing the direct study of the interactions of biochemistry and whole neuron electrophysiology without making limiting assumptions to sim- plify the simulations. This has promising implications for intervening in age-related learning de cits, as well as in neurological disorders such as Alzheimers. Finally, this proposal will bring together our existing multiscale modeling community, the National Center for Multi-scale Modeling of Biological Systems (MMBioS), with the MSM consortium. The interactions of these organizations and their communities of expert researchers will foster new collaborative work on exciting multiscale problems in biology, including applications of the machine learning frameworks and software we are developing. 1 Project Narrative  A wide variety of biological systems can be described statistically, from molecular biochemistry up to the network level activity of neurons. This work develops machine learning approaches to approximate these systems, enabling new simulation methods that bridge di erent levels of description. The resulting computational studies aim to shed light on the basis of learning and computation in the brain, and will enable the development of pharmaceutical targets for learning de cits associated with aging and neurological disorders such as Alzheimers. 1",Machine Learning for Generalized Multiscale Modeling,9791802,R56AG059602,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Area', 'Behavior', 'Biochemical', 'Biochemistry', 'Biological Models', 'Biological Neural Networks', 'Biology', 'Brain', 'Calcium', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consequentialism', 'Coupling', 'Data Set', 'Development', 'Dimensions', 'Electron Microscopy', 'Electrophysiology (science)', 'Environment', 'Equation', 'Equilibrium', 'Evolution', 'Fostering', 'Hybrids', 'Image', 'Investigation', 'Ion Channel', 'Learning', 'Libraries', 'Light', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'National Institute of General Medical Sciences', 'Neurons', 'Neuropil', 'Neurosciences', 'Pharmacologic Substance', 'Physics', 'Population', 'Potassium Channel', 'Process', 'Pythons', 'Reaction', 'Research Personnel', 'Sleep', 'Structure', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Time', 'Tissues', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'age related', 'base', 'biological systems', 'calmodulin-dependent protein kinase II', 'computer studies', 'experimental study', 'information processing', 'insight', 'interest', 'mathematical methods', 'men who have sex with men', 'microscopic imaging', 'multi-scale modeling', 'nervous system disorder', 'particle', 'postsynaptic', 'reconstruction', 'relating to nervous system', 'simulation', 'software development', 'success', 'tool', 'working group']",NIA,UNIVERSITY OF CALIFORNIA-IRVINE,R56,2018,619053,-0.01613525898944786
"2018 OSA Optics and the Brain Conference FOA: PA-16-294 Opportunity Title: NIH Support for Conferences and Scientific Meetings (R13/U13) Agency: NIH - NINDS Proposal Title: 2018 OSA Optics and the Brain Conference Principal Investigator: Gregory J. Quarles, Ph.D., Chief Scientist, The Optical Society  2010 Massachusetts Ave, NW, Washington, DC  gquarles@osa.org, 202-416-1954 Project Summary /Abstract:  The 2018 OSA Biophotonics Congress: Biomedical Optics, 3-6 April 2018, Hollywood, FL, consists of four topical meetings. Within this congress, the Optics and the Brain Conference is specifically focused on cutting-edge research and innovative new tools and techniques that seek to increase fundamental knowledge about the brain and nervous system. This proposal is to provide registration and travel support for students, early career professionals, and underrepresented speakers that will present on optics and the brain topics within this meeting.  The 2018 OSA Optics and the Brain conference was founded in 2015 in response to the USA BRAIN Initiative and the European Human Brain Project. These initiatives have identified the urgent need for new technologies that can probe the working brain across all levels from single neurons to entire behaving organisms. Optics offers a unique toolkit for multiscale imaging the living and intact brain, while new genetic labeling strategies provide optical contrast to neural function and optogenetics permits the control of cellular function with light. Optics and the Brain is thus an important, highly interdisciplinary area of research that combines broad aspects of neuroscience, biology, medicine, physics, chemistry and engineering. This year the program is adding more topics to be able to better explore new tools, the use of artificial intelligence in machine learning and technologies that will allow doctors to explore larger, deeper sections of the brain.  The general purpose of this congress with co-located meetings is to create an inclusive, open forum for the presentation of high-quality scientific research through plenary and technical sessions, short courses, panels, networking and special events. This method of face-to-face information sharing allows researchers to learn what others in their field and related disciplines are doing and to efficiently learn about new research, tools, and techniques that might be relevant to their work. It allows conversations with colleagues from different institutions around the world and engenders far reaching scientific collaborations – both domestic and international. In addition, this meeting provides an opportunity for students and early career professionals to present their work, participate in professional development activities, and to hear from and network with internationally-renowned invited speakers who represent the broad diversity of optics and the brain related research. Ultimately this meeting, where best-in-class research is presented and discussed will advance knowledge in the field of biomedical optics and biophotonics and propel technological development forward. FOA: PA-16-294 Opportunity Title: NIH Support for Conferences and Scientific Meetings (R13/U13) Agency: NIH - NINDS Proposal Title: 2018 OSA Optics and the Brain Conference Principal Investigator: Gregory J. Quarles, Ph.D., Chief Scientist, The Optical Society  2010 Massachusetts Ave, NW, Washington, DC  gquarles@osa.org, 202-416-1954 Project Narrative The 2018 OSA Optics and the Brain Conference discusses a highly interdisciplinary area of research that combines broad aspects of neuroscience, biology, medicine, physics, chemistry and engineering. Optics offers a unique toolkit for multiscale imaging the living and intact brain, while new genetic labeling strategies provide optical contrast to neural function and optogenetics permits the control of cellular function with light. This conference brings together scientists from experts to students working in all aspects of optics and the brain and serves as a forum for discussion of existing and emerging techniques as well as future directions capable of shedding new light on the healthy and diseased brain.",2018 OSA Optics and the Brain Conference,9543785,R13NS106923,"['Academic Training', 'Area', 'Artificial Intelligence', 'BRAIN initiative', 'Biology', 'Biophotonics', 'Birds', 'Brain', 'Brain Diseases', 'Brain imaging', 'Career Mobility', 'Cell physiology', 'Chemistry', 'Collaborations', 'Congresses', 'Development', 'Digital Libraries', 'Discipline', 'Doctor of Philosophy', 'Engineering', 'Ensure', 'European', 'Event', 'Exhibits', 'Fostering', 'Future', 'Genetic', 'Goals', 'Grant', 'Hearing', 'Human', 'Image', 'Industry', 'Institution', 'International', 'Joints', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Massachusetts', 'Medical', 'Medicine', 'Methods', 'National Institute of Neurological Disorders and Stroke', 'Neurons', 'Neurophysiology - biologic function', 'Neurosciences', 'Optics', 'Organism', 'Outcome', 'Paper', 'Participant', 'Peer Review', 'Physicians', 'Physics', 'Principal Investigator', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Scientist', 'Services', 'Societies', 'Special Event', 'Students', 'Techniques', 'Technology', 'Time', 'Translating', 'Travel', 'Underrepresented Minority', 'United States National Institutes of Health', 'Washington', 'Work', 'academic standard', 'career', 'graduate student', 'indexing', 'innovation', 'meetings', 'new technology', 'optogenetics', 'posters', 'programs', 'response', 'symposium', 'tool']",NINDS,OPTICAL SOCIETY OF AMERICA,R13,2018,10000,-0.00824089462948412
"Pattern Analysis of fMRI via machine learning/sparse models: application to brain development Abstract Resting state fMRI (rsfMRI) provides reproducible, task-independent biomarkers of coherent functional activity linking different brain regions. The main goal of the proposed project is to leverage advances in signal processing and machine learning methods to derive clinically useful biomarkers based on patterns of functional connectivity, and to test these biomarkers in a large study of brain development. Central to our methodology are 1) computing a subject-specific functional parcellation of the brain, which defines nodes for characterizing individualized functional brain networks; 2) extracting sparse connectivity patterns for robustly representing brain networks; 3) capturing heterogeneity in brain networks across individuals in a given population; and 4) deriving individualized predictive indices of psychosis risk from brain connectivity in a large study of brain development. This novel suite of functional connectivity analysis tools will be developed and validated based on data from the Human Connectome Project and the Philadelphia Neurodevelopmental Cohort (PNC). Finally, these techniques will be applied to PNC data in order to delineate heterogeneity in network development in youth with psychosis-spectrum symptoms. Our hypothesis is that patterns of functional connectivity in adolescents with psychosis-spectrum symptoms will be different from those in typically developing adolescents, and this difference will display a high degree of heterogeneity that is linked to underlying heterogeneity in pathologic neurodevelopmental trajectories. Moreover, we expect that machine learning techniques will allow us to predict on an individual basis which adolescents with psychosis-spectrum symptoms will remain stable, which will revert to normal, and which will progress to psychosis, based on their baseline functional connectivity signatures. Our methods are generally applicable to rsfMRI studies for detecting and quantifying spatio-temporal functional connectivity patterns in diverse fields, including diagnosing brain abnormalities in neuropsychiatric diseases, and finding associations of functional connectivity with different cognitive functions. All methods will be made publicly available and form an important new resource for the broader neuroscience community. Project narrative This proposal develops a suite of advanced functional imaging pattern analysis methods, aiming to delineate heterogeneity in brain network development in youth with psychosis-spectrum symptoms, ultimately leading to early biomarkers of neuropsychiatric disorders. Methodologically, the proposed work leverages upon the strengths of sparse and non-negative decompositions of imaging data, which offer several advantages over conventional mass-univariate and linear multivariate methods. One of the largest and most comprehensive cohorts of 1,600 individuals ages 8 through 21 provides unique imaging and clinical data to support the application of these methods to brain development.",Pattern Analysis of fMRI via machine learning/sparse models: application to brain development,9486921,R01EB022573,"['Address', 'Adolescent', 'Age', 'Algorithms', 'Anatomy', 'Biological', 'Biological Markers', 'Brain', 'Brain region', 'Classification', 'Clinical Data', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neurosciences', 'Outcome', 'Pathologic', 'Pathway Analysis', 'Pattern', 'Pattern Recognition', 'Philadelphia', 'Population', 'Psychotic Disorders', 'Reproducibility', 'Resources', 'Rest', 'Risk', 'Sampling', 'Shapes', 'Subgroup', 'Symptoms', 'Techniques', 'Testing', 'Work', 'Youth', 'base', 'brain abnormalities', 'clinical biomarkers', 'cognitive function', 'cohort', 'connectome', 'early detection biomarkers', 'follow-up', 'human data', 'improved', 'indexing', 'interest', 'learning strategy', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'personalized predictions', 'signal processing', 'spatiotemporal', 'tool', 'trend']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,549838,-0.03283250925758898
"A Modular Automated Platform for Large-scale Drosophila Experiments and Handling PROJECT SUMMARY / ABSTRACT Animal model systems are a powerful tool researchers use to investigate almost all aspects of biology: genetics, development, neuroscience, disease, and more. And fruit flies – Drosophila melanogaster – with their small size, easy care, and remarkable array of available genetic toolkits, occupy a sweet spot on the model organism spectrum. Over 75% of human diseases with a genetic basis have an analogue in the fly, and Drosophila have been a part of the research for six Nobel prizes. Furthermore, the advent of CRISPR/cas9 and other modern genetic tools has opened the door to modeling other diseases and pathways, leading to greater use of Drosophila for drug screens. A great deal of the work (and the majority of the budget) involved in fly experiments is tedious manual labor, and with advances in computer vision, machine learning, and other analytic techniques, the stage is set to automate many phenotypic screens. In this Phase I SBIR, we propose a robotic system – modular automated platform for large-scale experiments (MAPLE) – that can accomplish a wide variety of fly-handling tasks in Drosophila labs. This robot is the fruit fly version of a liquid handling robot, with a large, open workspace that can house a plethora of modules and several manipulators that can move small parts and animals around that workspace. Building on a collaboration between the de Bivort Lab and FlySorter completed in 2017, we will design, fabricate and validate a commercial system that can collect virgin flies, run behavioral assays, conduct drug screens, and adapt to the needs of fly labs through easy-to-code Python scripts. By strategically combining modules and instructions to the robot, MAPLE can perform a wide variety of tasks in a fly lab, saving experimentalists from repetitive chores, cutting labor costs, and increasing scientific output. Just as pipette robots have become standard equipment in wet labs, we envision our fly handling robot will be the engine that powers Drosophila labs in academia and pharma, enabling new kinds of experiments and freeing researchers from the drudgery of fly pushing. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are a powerful model organism used in the study of disease, neuroscience, development, genetics, and recently in drug screens, too, largely through phenotypic screening. This labor-intensive work is time consuming and expensive, and ripe for automation. We propose a fly-handling robot – analogous to a liquid pipetting robot in a wet lab – that can perform a variety of tasks in Drosophila labs, free researchers from the drudgery of fly pushing, and enable a broader spectrum of experiments that will increase scientific knowledge.",A Modular Automated Platform for Large-scale Drosophila Experiments and Handling,9623017,R43MH119092,"['Academia', 'Address', 'Affect', 'Air', 'Anesthesia procedures', 'Animal Model', 'Animals', 'Architecture', 'Automation', 'Basic Science', 'Behavior', 'Behavioral Assay', 'Biological Models', 'Biology', 'Budgets', 'CRISPR/Cas technology', 'Carbon Dioxide', 'Caring', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Data Collection', 'Deposition', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Screening', 'Drug usage', 'Ensure', 'Equipment', 'Feedback', 'Genetic', 'Genetic Screening', 'Genetic study', 'Grant', 'Hand', 'Human', 'Instruction', 'Knowledge', 'Libraries', 'Liquid substance', 'Machine Learning', 'Manuals', 'Modeling', 'Modernization', 'Neurosciences', 'Nobel Prize', 'Organism', 'Output', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Protocols documentation', 'Pythons', 'Reagent', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Running', 'Savings', 'Scanning', 'Small Business Innovation Research Grant', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Transgenic Organisms', 'Travel', 'Universities', 'Update', 'Vacuum', 'Work', 'analog', 'bone', 'cost', 'design', 'drug discovery', 'experimental study', 'flexibility', 'fly', 'graduate student', 'health science research', 'human disease', 'improved', 'operation', 'programs', 'repository', 'robot control', 'screening', 'tool', 'touchscreen']",NIMH,"FLYSORTER, LLC",R43,2018,348007,-0.023079732840577495
"Assessing the Effects of Deep Brain Stimulation on Agency Project Summary Recent advances in neurotechnologies have provided us with the ability to modulate brain function by direct and indirect interventions. Deep Brain Stimulation (DBS) is one such intervention that has already been FDA-approved for certain disorders, and its use has already raised ethical questions about ways in which direct brain stimulation may affect personal identity, autonomy, authenticity and, more generally, agency. Thus far the neuroethical worries have been largely based on anecdotal clinical reports. Further neurotechnological interventions developed as part of the BRAIN initiative are bound to raise similar questions, but we lack a clear framework in which to think of the ethical consequences of these interventions. The overall goal of this project is to articulate such a framework, to enable us to better evaluate and respond to the neuroethical challenges raised by our abilities to alter brain function. The more concrete objectives of our proposal are to 1) develop comprehensive assessment tools to measure changes in agency due to direct brain interventions, 2) to use this tool to assess changes in agency due to brain interventions using DBS patient populations as a test case; and 3) to develop a database to house the data we acquire with these tools to allow us to catalogue the effects and side effects of DBS. This will also make it possible to correlate the effects of DBS with electrode placement and white matter tractography, enabling better prediction of outcomes and aid in understanding of the mechanisms by which DBS works. We will analyze this data machine with machine learning methods to inform a more comprehensive neuroethical analysis of how brain interventions affect agency. Our approach is innovative in that it applies neurophilosophical insights about agency and employs deep learning algorithms in constructing and evaluating these assessment instruments. This contribution is significant in that it will provide a broad based assessment tool and database that will be a resource for researchers and clinicians using DBS, which could be used to improve therapeutic approaches and informed consent. The data will also inform a framework for further neuroethical thought about brain interventions, allowing us to better identify, articulate and measure changes on “dimensions of agency.” Finally, the approach is generalizable, and thus could be adapted for use with other brain intervention techniques, such as brain-computer interfaces (BCIs) or pharmacological treatments.   Project Narrative: We aim to develop a computerized assessment tool (the Agency Assessment Tool, AAT) to be used by clinicians prior to and after brain interventions to measure changes in agency along multiple dimensions. We will also develop an anonymous database coupled to the AAT that will constitute a central repository for data documenting the effects of DBS. Machine learning methods will be used to build predictive models from the AAT data in order to provide neuroethically relevant predictive and diagnostic information about the effects of brain interventions on agency. ",Assessing the Effects of Deep Brain Stimulation on Agency,9609947,RF1MH117813,"['Address', 'Adverse effects', 'Affect', 'Algorithms', 'Assessment tool', 'BRAIN initiative', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Bioethics', 'Brain', 'Case Study', 'Catalogs', 'Characteristics', 'Clinical', 'Competence', 'Coupled', 'Data', 'Databases', 'Deep Brain Stimulation', 'Diagnostic', 'Dimensions', 'Disease', 'Electrodes', 'Elements', 'Ethicists', 'Ethics', 'FDA approved', 'Feeling', 'Goals', 'Human', 'Individual', 'Individuality', 'Informed Consent', 'Intervention', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Neuropsychology', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Outcome', 'Parkinson Disease', 'Patients', 'Personhood', 'Pharmacological Treatment', 'Pharmacology', 'Population', 'Questionnaires', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Site', 'Structure', 'Techniques', 'Testing', 'Therapeutic', 'Thinking', 'Treatment outcome', 'Variant', 'Work', 'base', 'brain computer interface', 'clinical decision-making', 'clinically relevant', 'computerized', 'data warehouse', 'deep learning', 'experience', 'improved', 'innovation', 'insight', 'learning strategy', 'lens', 'neurobehavioral', 'neuroethics', 'neuroregulation', 'neurosurgery', 'neurotechnology', 'novel therapeutic intervention', 'outcome prediction', 'patient population', 'predictive modeling', 'preimplantation', 'tool', 'tractography', 'treatment-resistant depression', 'white matter']",NIMH,DARTMOUTH COLLEGE,RF1,2018,239475,-0.007208747487047979
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9422606,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'deep learning', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'predictive modeling', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,451650,-0.040458349424483876
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,9622537,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2018,216724,0.005651265757652092
"Human and Machine Learning for Customized Control of Assistive Robots PROJECT SUMMARY This application will result in a technological platform that re-empowers persons with severe paralysis, by allowing them to independently control a wide spectrum of robotic actions. Severe paralysis is devastating, and chronic—and reliance on caregivers is persistent. Assistive machines such as wheelchairs and robotic arms offer a groundbreaking path to independence: where control over their environment and interactions is returned to the person.  However, to operate complex machines like robotic arms and hands typically poses a difﬁcult learning challenge and requires complex control signals—and the commercial control interfaces accessible to persons with severe paralysis (e.g. sip-and-puff, switch-based head arrays) are not adequate. As a result, assistive robotic arms remain largely inaccessible to those with severe paralysis—arguably the population who would beneﬁt from them most.  The purpose of the proposed study is to provide people with tetraplegia with the means to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. Control interfaces that generate a unique map from a user's body motions to control signals for a machine offer a customized interaction, however these interfaces have only been used to issue low-dimensional (2-D) control signals whereas more complex machines require higher-dimensional (e.g. 6-D) signals. We propose an approach that leverages robotics autonomy and machine learning in order to aid the end-user in learning how to issue effective higher-dimensional control signals through body motions. Speciﬁcally, initially the human issues a lower- dimensional control signal and robotics autonomy is used to bridge the gap by taking over whatever is not covered by the human's control signal. Help from the robotics autonomy is then progressively scaled back, automatically, to cover fewer and fewer control dimensions as the user becomes more skilled.  The ﬁrst piece to our approach deals with how to extract control signals from the human, using the body-machine interface. The development and optimization of decoding procedures for controlling a robotic arm using residual body motions will be addressed under Speciﬁc Aim 1. The second piece to our approach deals with how to interpret control signals from a human within a paradigm that shares control between the human and robotics autonomy. To identify which shared-control formulations most effectively utilize the human's control signals will be the topic of Speciﬁc Aim 2. The ﬁnal piece to our approach deals with how to adapt the shared-control paradigm so that more control is transferred to the human over time. This adaptation is necessary for the human's learning process, since the goal in the end is for the human to be able to fully control the robotic arm him/herself, and will be assessed under Speciﬁc Aim 3.  At the completion of this project, tetraplegic end-users will be able to operate a robotic arm using their residual body motions, through an interface that both promotes the use of residual body motions (and thus also recovery of motor skill) and adapts with the human as their abilities change over time. By leveraging adaptive robotics autonomy, our application moreover provides a safe mechanism to facilitate learning how to operate the robotic platform. Frequently the more severe a person's motor impairment, the less able they are to operate the very assistive machines, like powered wheelchairs and robotic arms, which might enhance their quality of life. The purpose of the proposed study is to provide people with tetraplegia with the means, through non-invasive technologies, to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. We propose and study an approach that leverages robot machine learning and autonomy in order to facilitate human motor learning of how to operate a robotic arm using a customized interface, in order to make powered assisted manipulation more accessible to people with severe paralysis. 1",Human and Machine Learning for Customized Control of Assistive Robots,9448794,R01EB024058,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Affect', 'Algorithms', 'Back', 'Caregivers', 'Cerebral Palsy', 'Chronic', 'Complex', 'Computers', 'Custom', 'Data', 'Development', 'Devices', 'Dimensions', 'Eating', 'Effectiveness', 'Environment', 'Exercise', 'Formulation', 'Fostering', 'Freedom', 'Future', 'Goals', 'Hand', 'Head', 'Health Benefit', 'Human', 'Learning', 'Left', 'Limb structure', 'Machine Learning', 'Maintenance', 'Maps', 'Mental Depression', 'Mental Health', 'Motion', 'Motivation', 'Motor', 'Motor Skills', 'Movement', 'Multiple Sclerosis', 'Neurologic', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Population', 'Posture', 'Powered wheelchair', 'Procedures', 'Process', 'Quadriplegia', 'Quality of life', 'Rehabilitation therapy', 'Residual state', 'Robot', 'Robotics', 'Self-Help Devices', 'Shoulder', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Spinal cord injured survivor', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Wheelchairs', 'Work', 'arm', 'base', 'body-machine interface', 'brain machine interface', 'empowerment', 'feeding', 'high dimensionality', 'improved', 'motor impairment', 'motor learning', 'motor recovery', 'n-dimensional', 'novel strategies', 'physical conditioning', 'psychologic', 'robot control', 'sensor', 'two-dimensional']",NIBIB,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R01,2018,331851,-0.015620403525063442
"Construction of a high-resolution human tractography atlas and its related toolbox PROJECT SUMMARY Mapping the human connectome and exploring its characteristics is one of the largest endeavors in the neuroscience field, but a detailed tractography atlas that provides the 3D trajectories in a standard space has yet to be constructed and validated. A tractography atlas can provide neuroanatomical insight into the structural organization of the human brain and allow for modeling, simulation, and confirmation of cortical connections to facilitate the new development of treatment and intervention for brain diseases. In this study, we propose to construct a high spatial and angular resolution tractography atlas using a large sample of the Human Connectome Project (HCP) diffusion MRI data, averaging them into a template for fiber tracking, validating the tracks by post-mortem Klingler microdissection on 100 cadavers under a neurosurgery microscope digitized using high resolution 3D scanners, and building a deep learning toolbox that allows for automatic track recognition in individuals. This study will construct the most detailed and accurate tractography of human connectome and provide a novel toolbox for future HCP data analysis. PROJECT NARRATIVE The proposed research will construct an atlas of human brain fiber pathways and a related toolbox for track- specific analysis, aiming to understand the structural characteristics of brain connections in healthy individuals and provide track-specific analysis for brain imaging data.",Construction of a high-resolution human tractography atlas and its related toolbox,9771640,R56MH113634,"['Algorithms', 'Aphasia', 'Architecture', 'Atlases', 'Autopsy', 'Base of the Brain', 'Brain', 'Brain Diseases', 'Brain Stem', 'Brain imaging', 'Brain scan', 'Cadaver', 'Cerebellum', 'Characteristics', 'Complement', 'Cranial Nerves', 'Data', 'Data Analyses', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Fiber', 'Future', 'Human', 'Individual', 'Intervention', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Memory', 'Microdissection', 'Microscope', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Parkinson Disease', 'Pathway interactions', 'Patients', 'Perception', 'Performance', 'Population', 'Records', 'Research', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Source', 'Structure', 'Surface', 'System', 'Thinking', 'Tissues', 'Training', 'Validation', 'Variant', 'base', 'brain abnormalities', 'brain research', 'clinical application', 'connectome', 'deep learning', 'deep neural network', 'digital', 'experience', 'human data', 'human subject', 'insight', 'models and simulation', 'neuropsychiatric disorder', 'neurosurgery', 'novel', 'therapy development', 'tool', 'tractography', 'virtual', 'white matter', 'young adult']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R56,2018,452250,-0.011077786714936429
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. Narrative There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9680657,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'professional atmosphere', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,449918,-0.011866898211754294
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9499823,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Research Infrastructure', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radiofrequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416374,0.027600979729868157
"Wireless Movement Sensing System for People with Severe Disabilities Abstract The ability of people with severe physical impairment to participate in family life, communication, work, or recreation is severely restricted without access to assistive technology (AT). Yet, as disability severity increases, so does the challenge to finding (1) an access movement that a person can perform to control AT and (2) an access technology that can detect the access movement. We propose to create a wireless movement sensing system that can learn a user’s access movement and then recognize that movement in order to wirelessly control assistive devices. Once we complete the technology development, we will measure the sensitivity and specificity of our wireless movement sensing system using the movements of ten people with SPI. We will present our results to AT experts during a focus group session and determine the perceived strengths and weaknesses of the technology. This Phase 1 research is proposed by a multidisciplinary research team consisting of AT engineers, AT clinicians, and a machine learning expert. Project Narrative The proposed movement sensing system adapts to the abilities of people with severe physical impairment and enables them to better control smart devices (e.g., computers, smartphones, etc.).",Wireless Movement Sensing System for People with Severe Disabilities,9554167,R43DC017791,"['Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Android', 'Arkansas', 'Beds', 'Bluetooth', 'Brain Stem Infarctions', 'Cellular Phone', 'Cerebral Palsy', 'Communication', 'Computer software', 'Computers', 'Custom', 'Data', 'Devices', 'Digit structure', 'Engineering', 'Etiology', 'Exhibits', 'Family', 'Fingers', 'Focus Groups', 'Generations', 'Hand', 'Hospitals', 'Impairment', 'Interdisciplinary Study', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Movement', 'Output', 'Participant', 'Performance', 'Persons', 'Phase', 'Positioning Attribute', 'Records', 'Recreation', 'Rehabilitation therapy', 'Research', 'Scanning', 'Self-Help Devices', 'Sensitivity and Specificity', 'Severities', 'Speech', 'Spinal cord injury', 'System', 'Tablets', 'Technology', 'Thumb structure', 'Training', 'Universities', 'Wheelchairs', 'Wireless Technology', 'Woman', 'Work', 'cost', 'disability', 'effectiveness measure', 'prototype', 'sensor', 'technology development', 'wearable device']",NIDCD,"INVOTEK, INC.",R43,2018,222217,-0.007466108556538169
"Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data Project Summary The immunology database and analysis portal (ImmPort, http://immport.niaid.nih.gov) is the NIAID-funded public resource for data archive and dissemination from clinical trials and mechanistic research projects. Among the current 291 studies archived in ImmPort, 114 are focused on vaccine responses (91 for influenza vaccine responses), which is the largest category when organized by research focus. As the most effective method of preventing infectious diseases, development of the next-generation vaccines is faced with the bottleneck that traditional empirical design becomes ineffective to stimulate human protective immunity against HIV, RSV, CMV, and other recent major public health threats. This project will focus on three important aspects of informatics approaches to secondary analysis of ImmPort data for influenza vaccination research: a) expanding the data analytical capabilities of ImmPort and ImmPortGalaxy through adding innovative computational methods for user-friendly unsupervised identification of cell populations, b) processing and analyzing a subset of the existing human influenza vaccination study data in ImmPort to identify cell-based biomarkers using the new computational methods, and c) returning data analysis results with data analytical provenance to ImmPort for dissemination of derived data, software tools, as well as semantic assertions of the identified biomarkers. Each aspect is one specific research aim in the proposed work. The project outcome will not only demonstrate the utility of the ImmPort data archive but also generate a foundation for the Human Vaccine Project (HVP) to establish pilot programs for influenza vaccine research, which currently include Vanderbilt University Medical Center; University of California San Diego (UCSD); Scripps Research Institute; La Jolla Institute of Allergy and Immunology; and J. Craig Venter Institute (JCVI). Once such computational analytical workflow is established, it can be applied to the secondary analysis of other ImmPort studies as well as to support the user-driven analytics of their own cytometry data. Each of the specific aims contains innovative methods or new applications of the existing methods. The computational method for population identification in Aim 1 is a newly developed constrained data clustering method, which combines advantages of unsupervised and supervised learning. Cutting-edge machine learning approaches including random forest will be used in Aim 2 for the identification of biomarkers across study cohorts, in addition to the traditional statistical hypothesis testing. Standardized knowledge representation to be developed in Aim 3 for cell-based biomarkers is also innovative, as semantic networks with inferring and deriving capabilities can be built based on the machine-readable knowledge assertions. The proposed work, when accomplished, will foster broader collaboration between ImmPort and the existing vaccine research consortia. It will also accelerate the deployment of up-to-date informatics software tools on ImmPortGalaxy. Project Narrative Flow cytometry (FCM) plays important roles in human influenza vaccination studies through interrogating immune cellular functions and quantifying the immune responses in different conditions. This project will extend the current data analytical capabilities of the Immunology Database and Analysis Portal (ImmPort) through adding novel data analytical methods and software tools for user-friendly identification of cell populations from FCM data in ImmPort influenza vaccine response studies. The derived data and the knowledge generated from the secondary analysis of the ImmPort vaccination study data will be deposited back to ImmPort and shared with the Human Vaccines Project (HVP) consortium for dissemination.",Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data,9577591,UH2AI132342,"['Academic Medical Centers', 'Address', 'Archives', 'Back', 'Biological Markers', 'California', 'Categories', 'Cells', 'Characteristics', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Cytomegalovirus', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Deposition', 'Development', 'Disease', 'Failure', 'Flow Cytometry', 'Fostering', 'Foundations', 'Funding', 'Genetic Transcription', 'HIV', 'Human', 'Hypersensitivity', 'Imagery', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunology', 'Incidence', 'Influenza', 'Influenza vaccination', 'Informatics', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Maps', 'Measles', 'Medical', 'Meta-Analysis', 'Metadata', 'Methods', 'Mumps', 'Names', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Play', 'Poliomyelitis', 'Population', 'Population Statistics', 'Prevalence', 'Prevention strategy', 'Process', 'Public Health', 'Readability', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Institute', 'Research Project Grants', 'Respiratory Syncytial Virus Vaccines', 'Respiratory syncytial virus', 'Role', 'Secondary to', 'Semantics', 'Smallpox', 'Software Tools', 'Source', 'Standardization', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Universities', 'Vaccination', 'Vaccine Design', 'Vaccine Research', 'Vaccines', 'Work', 'analytical method', 'base', 'biomarker discovery', 'biomarker identification', 'catalyst', 'cohort', 'comparative', 'computer infrastructure', 'computerized tools', 'data archive', 'data mining', 'data portal', 'data resource', 'design', 'experience', 'experimental study', 'forest', 'immune function', 'improved', 'influenza virus vaccine', 'information organization', 'innovation', 'neoplastic', 'news', 'novel', 'novel strategies', 'novel vaccines', 'prevent', 'programs', 'public-private partnership', 'response', 'response biomarker', 'secondary analysis', 'statistics', 'success', 'tool', 'user-friendly', 'vaccine development', 'vaccine response', 'vaccine trial', 'vaccine-induced immunity']",NIAID,"J. CRAIG VENTER INSTITUTE, INC.",UH2,2018,243750,-0.026862248759288627
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9548637,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2018,305372,0.012062994319409309
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9687220,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Research Infrastructure', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2018,330000,-0.03363132253251686
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9529742,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Biological Neural Networks', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Gray unit of radiation dose', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2018,77959,0.002572252640708679
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9711194,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2018,99914,-0.001906377465653615
"Device for real-time streaming of preclinical research data into a central cloud-based platform Project Summary BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. Traditionally researchers collect data from many disparate instruments and store data on PCs running single license software. Raw data is stored across several locations, analysis is restricted to the PC used to collect the data, and opportunities for collaboration, remote-participation, and data sharing are limited. BehaviorCloud is leveraging cloud data streaming and storage to overcome these barriers to discovery. In 2017 BehaviorCloud released a first version of the underlying cloud platform as well as BehaviorCloud Camera, an open-source “reference implementation” that demonstrates automated video tracking of animal behavior on the BehaviorCloud platform using a consumer-grade smartphone. This tool and the underlying platform are both in active use across academic and pharmaceutical labs. The aim of this Phase I SBIR application is to develop patent-pending “Bridge” technology that allows data streaming from third-party instrumentation into the central web platform. Researchers will bypass the original software and PCs associated with their instruments to control trials through their BehaviorCloud account and receive data back in real-time. BehaviorCloud will provide a public repository to aggregate all of these data and accelerate discovery by providing computational tools for large-scale meta-analysis and machine learning based predictive analytics. Project Narrative BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. The goal of this Phase I SBIR application is to develop the technology to enable streaming of data from all kinds of behavioral and phenotyping instrumentation into the BehaviorCloud platform. BehaviorCloud will aggregate these data into a repository and accelerate discovery by providing tools for collaboration and meta-analysis.",Device for real-time streaming of preclinical research data into a central cloud-based platform,9621228,R43OD025448,"['Adoption', 'Animal Behavior', 'Animal Experimentation', 'Animal Model', 'Area', 'Back', 'Behavioral', 'Bypass', 'Carbon Dioxide', 'Cellular Phone', 'Collaborations', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Development', 'Devices', 'Goals', 'Heart Rate', 'Information Systems', 'Internet', 'Intervention', 'Legal patent', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Meta-Analysis', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiological', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Research', 'Research Contracts', 'Research Personnel', 'Resources', 'Running', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Standardization', 'Stimulus', 'Stream', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'cloud based', 'cloud platform', 'computerized tools', 'control trial', 'data management', 'data sharing', 'data warehouse', 'design', 'experimental study', 'instrument', 'instrumentation', 'laptop', 'open source', 'phenotypic data', 'pre-clinical', 'pre-clinical research', 'prototype', 'repository', 'tool', 'wasting', 'web interface']",OD,"BEHAVIORCLOUD, LLC",R43,2018,220420,0.0006831843790088054
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9547466,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2018,347834,-0.005156844708701949
"C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative ABSTRACT The BRAIN Initiative is designed to leverage sophisticated neuromodulation, electrophysiological recording, and macroscale neuroimaging techniques in human and non-human animal models in order to develop a multilevel understanding of human brain function. However, the necessary tools for organizing, processing and analyzing neuroimaging data generated through these efforts are not widely available as coherent and easy-to- use software packages. Gaps are particularly apparent for nonhuman data (i.e., monkey, rodent), as most of the existing processing and analytic software packages are specifically designed for human imaging. Methods have been proposed for addressing the challenges inherent to the processing of nonhuman data (e.g., brain extraction, tissue segmentation, spatial normalization, brain parcellation, temporal denoising); to date, these have not been readily integrated into an easy-to-use, robust, and reproducible analysis package. Similarly, many of the sophisticated machine learning and modeling methods developed for neuroimaging analyses are inaccessible to most researchers because they have not been integrated into easy-to-use pipeline software. As a result, translational and comparative neuroimaging researchers patch together neuroinformatics pipelines that use various combinations of disparate software packages and in-house code. We propose to extend the Configurable Pipeline for the Analysis of Connectomes (C-PAC) open-source software to provide robust and reproducible pipelines for functional and structural MRI data. We will integrate the various disparate image processing and analysis methods used to handle the challenges of nonhuman imaging data, into a single, open source, configurable, easy-to-use end-to-end analysis pipeline package that is accessible locally or via the cloud. The end product will not only improve the quality, transparency and reproducibility of nonhuman translational and comparative imaging, but also enable new avenues of scientific inquiry through our inclusion of methods that are yet to be applied to nonhuman imaging data (e.g., gradient- based cortical parcellation methods, hyperalignment). Specific aims of the proposed work include to: 1) Integrate neuroimaging processing and analysis methods optimized for BRAIN Initiative data, 2) Implement strategies for carrying out comparative studies of human and non-human populations, and 3) Extend C-PAC to include cutting-edge analytical strategies for identifying mechanisms of brain function. All development will occur “in the open” using GitHub and other collaborative tools to maximally involve participation in the C-PAC project. Annual hackathons will be held to collaborate with investigators from BRAIN Initiative awards and other neuroinformatics development projects to integrate their tools with C-PAC. Hands-on training will be held to train investigators on optimal use of the newly developed tools. NARRATIVE New neuroimaging analysis software is needed to process and analyze the various human and non-human neuroimaging data collected through the BRAIN Initiative. We will address this need by extending the already mature C-PAC human brain imaging data analysis pipeline to include support for animal data, with a particular focus on providing methods for conducting comparative studies between species. The proposed work will also include a toolbox for helping to align electrophysiological data that is commonly collected in non-human studies, with the brain imaging data.","C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative",9591465,R24MH114806,"['Address', 'Adoption', 'Anatomy', 'Animal Model', 'Architecture', 'Award', 'Behavior', 'Brain', 'Brain imaging', 'Capital', 'Code', 'Communities', 'Comparative Study', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Documentation', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Funding', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measures', 'Methods', 'Modality', 'Modeling', 'Modification', 'Monkeys', 'Outcome', 'Output', 'Pattern', 'Persons', 'Phenotype', 'Population', 'Process', 'Pythons', 'Readability', 'Reproducibility', 'Research Personnel', 'Rodent', 'Scientific Inquiry', 'Software Design', 'Statistical Methods', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validity of Results', 'Work', 'animal data', 'base', 'brain research', 'cloud based', 'comparative', 'computing resources', 'connectome', 'cost', 'data sharing', 'data structure', 'design', 'flexibility', 'graphical user interface', 'hackathon', 'human imaging', 'image processing', 'improved', 'innovative neurotechnologies', 'investigator training', 'learning strategy', 'neuroimaging', 'neuroinformatics', 'neuroregulation', 'open source', 'software as a service', 'tool', 'unsupervised learning']",NIMH,"CHILD MIND INSTITUTE, INC.",R24,2018,507643,0.015067162291622202
"Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale Project Summary This project aims to leverage the best of both computational and human expertise in neuronal reconstruction towards the goal of accelerating global neuroscience discovery from internationally-sourced imaging data. We propose to create a cloud-based unified platform for converging 3-dimensional images of neurons onto a single analysis platform to (1) train and grow a new expert community of global reconstructors to work across the data from these groups, to (2) generate a community-sourced neuronal reconstruction database of open imaging data that can be incorporated into a 3-dimensional map of neuronal interconnectivity - onto which (3) novel annotations and more complex functional and molecular data can be overlaid. Our approach will evolve with the growing needs of the neuroscience community over time. To do this, in Aim One (Neuronal Reconstruction at Scale), we will test if the newly developed crowd-sourced game-based platform Mozak can develop a collective of new human experts at scale, capable of accelerating the rate of current reconstruction by at least an order of magnitude, at the same time as increasing the robustness, quality and unbiasedness of the final reconstructions. In Aim Two (Robust Multi-Purpose Annotation), we will enhance basic neuronal reconstruction by adding specific semantic annotation— including soma volume and morphological quantification, volumetric analysis, and ongoing features (e.g. dendritic spines, axonal varicosities) requested from the neuroscience community. Experienced and high-ranking members will be given the opportunity to advance through increasingly complex neurons into full arbor brain-wide neuronal projections and multiple clustered groups of neurons in localized circuits. Finally, in Aim 3 (Creation of a Research-Adaptive Data Repository), we aim to develop a database of neuronal images reconstructed using the Mozak interface that will directly serve the general and specific needs of different research groups. Our goal is to make this database dynamically adaptive — as new research questions will invariably bring new needs for additional annotations and cross-referencing with other data modalities. This highquality unbiased processing repository will also be perfectly suited for training sets for automated algorithms, and the generation of a 3-dimensional maps such as Allen Institute for Brain Science (AIBS) common coordinate framework. We expect that the computational reconstruction methods will further improve with the new large corpus of “gold standard” reconstructions. Collectively, the completion of these three aims will create an analysis suite as well as an online community of experts capable of performing in depth analysis of large-scale datasets that will significantly accelerate neuroscience research, enhance machine learning for reconstruction analysis, and create a common platform of baseline neuronal morphology data against which aberrantly functioning neurons can be analyzed. Project Narrative  This project will create a new central nexus point for neuronal reconstruction and semantic annotation (Mozak) that can be used by all research labs via an accessible online portal. We will develop a new cadre of neuronal reconstruction experts that will— in conjunction with automated tools that are enhanced by their work — drastically increase the volume, quality and robustness of neuron reconstructions and annotations. Mozak reconstructions will be shared with existing repositories and will be continually updated and re-annotated based on emerging needs of research - ensuring perpetual relevance, and allowing us to generate a platform to establish the range of “baseline” 3-dimensional readouts of neuronal morphology against which diseased or malfunctioning neurons can be analyzed and understood. 1",Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale,9594042,R01MH116247,"['3-Dimensional', 'Adopted', 'Algorithms', 'Area', 'Brain', 'Characteristics', 'Classification', 'Communities', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Dendritic Spines', 'Disease', 'Ensure', 'Future', 'Gap Junctions', 'Generations', 'Goals', 'Gold', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Institutes', 'International', 'Laboratories', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Molecular', 'Morphology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Output', 'Process', 'Research', 'Research Infrastructure', 'Science', 'Semantics', 'Slice', 'Source', 'Standardization', 'Structure', 'Techniques', 'Testing', 'Three-dimensional analysis', 'Time', 'Training', 'Update', 'Variant', 'Varicosity', 'Work', 'base', 'citizen science', 'cloud based', 'crowdsourcing', 'data warehouse', 'experience', 'improved', 'member', 'neuronal cell body', 'novel', 'online community', 'petabyte', 'programs', 'reconstruction', 'repository', 'tool', 'two-dimensional']",NIMH,UNIVERSITY OF WASHINGTON,R01,2018,661507,-0.005063557271196805
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9517044,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2018,790391,-0.014485696192279539
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9491911,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2018,199622,0.013975257102518068
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9589711,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2018,439996,0.01437705698681818
"Robust Control of the Stem Cell Niche Diana Arguijo has a unique background with a double major in biomedical engineering (BME) and electrical and computer engineering (ECE). Leveraging her strong mathematical background, she will develop computational techniques to identify patterns of epigenetic reprogramming during epithelial development and patterns of real- time electrical recoding of the GI tract reflective of sacral nerve modulation. Her work will provide insights into the robustness and plasticity of underlying biological control schemes. Diana Arguijo will develop machine-learning based computational techniques to analyze epigenetic reprogramming of epithelial development and electrical activities of the enteric nervous system. Her analyses will provide insights into the robustness and plasticity of tissue regulation.",Robust Control of the Stem Cell Niche,9731853,R35GM122465,"['Biological', 'Biomedical Engineering', 'Computational Technique', 'Computers', 'Development', 'Engineering', 'Enteric Nervous System', 'Epigenetic Process', 'Epithelial', 'Gastrointestinal tract structure', 'Machine Learning', 'Mathematics', 'Pattern', 'Regulation', 'Sacral nerve', 'Scheme', 'Time', 'Tissues', 'Work', 'base', 'insight', 'stem cell niche']",NIGMS,DUKE UNIVERSITY,R35,2018,42822,-0.049351717098942344
"Development of brain-computer interface methods to influence brain dynamics in stuttering Project summary Brain dynamics that drive variability within and between patients are an important, but poorly understood, element of many cognitive disorders. The long-term goal of this research project is to develop technology that will identify brain activity patterns associated with successful performance on a given task, and use this pattern as a target for brain-computer interface (BCI) training. The overarching hypothesis is that using BCI training to more often have a brain state that is spontaneously correlated to good performance will, in turn, improve overall performance. This approach could be developed into a powerful tool for rehabilitation and therapy for many neurological and psychiatric disorders. Here we will investigate persistent developmental stuttering (PDS) as a model to study brain dynamics associated with successful vs. unsuccessful performance. PDS is a speech disorder where fluent speech is punctuated to various degrees by stuttering. Individuals with PDS are otherwise neurologically in the normal range, which avoids complicating factors in most patient populations. Stuttering is intermittent; thus on some occasions the brain is in a state conducive to fluent speech and at other times it is not. We propose to use EEG activity shortly before speaking to predict whether somebody with PDS will stutter or speak fluently. Preliminary data are given to show proof of concept with traditional EEG analysis methods. This approach will be expanded by first using advanced methods such as common spatial pattern analysis and machine learning over multiple subject sessions to identify EEG signals that distinguish fluent vs. dysfluent trials (Aim 1). PDS subjects will then be trained to produce and maintain their EEG pattern that is most strongly associated with fluent speech by using BCI methods. We hypothesize that individuals will learn to modulate EEG features to be more consistent with fluent trials, which in turn will significantly reduce stuttering rate. After successful completion of this project we envision a new BCI-based intervention that can be used to encourage neural states conducive to fluent speech in those who stutter. The BCI intervention would complement traditional speech therapy using behavioral methods. The “two-step approach” of first identifying brain states associated with a patient’s best performance followed by BCI training to enter that state more often can be applied to rehabilitation in many other neurological and psychiatric disorders, such as Alzheimer’s disease, traumatic brain injury, and mood disorders, to name a few. Project narrative The goal of this project is to develop brain-computer interface technology to optimize brain function on an individual basis. This could have therapeutic applications to many neurological and psychiatric disorders, including stroke, Alzheimer’s disease, and traumatic brain injury.",Development of brain-computer interface methods to influence brain dynamics in stuttering,9530270,R21DC016353,"['Alzheimer&apos', 's Disease', 'Behavioral', 'Brain', 'Brain region', 'Cognition Disorders', 'Complement', 'Control Groups', 'Cues', 'Data', 'Development', 'Developmental Stuttering', 'Electroencephalography', 'Elements', 'Failure', 'Feedback', 'Frequencies', 'Goals', 'Individual', 'Intervention', 'Learning', 'Machine Learning', 'Memory', 'Mental disorders', 'Metaphor', 'Methods', 'Modeling', 'Mood Disorders', 'Names', 'Neurologic', 'Normal Range', 'Patients', 'Pattern', 'Performance', 'Physiology', 'Rehabilitation therapy', 'Research Project Grants', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Speech', 'Speech Disorders', 'Speech Therapy', 'Stroke', 'Stuttering', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Traumatic Brain Injury', 'Work', 'base', 'brain computer interface', 'improved', 'indexing', 'motor control', 'nervous system disorder', 'patient population', 'relating to nervous system', 'response', 'tool', 'visual feedback']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R21,2018,216658,-0.03675512067646026
"Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain Great discoveries in neuroscience hold promise for reducing the burden of many of the most disabling conditions that threaten human health on a global scale, including mental illnesses and addictions. Increasingly, exceptionally innovative science inspires hope that these devastating brain-based disorders may be prevented, treated, and even cured but, as the BRAIN 2025 Scientific Vision notes, a suite of novel ethical challenges confronts those engaged in innovative neuroscience. These concerns include the deepest questions about what defines humanity and personhood, what forms of novel inquiry may exceed ethically acceptable limits in society, and how to perform ethically sound studies with volunteers who may be vulnerable to exploitation in the research situation. Such issues are particularly salient in mental illness and addiction research because these conditions affect cognition, emotion, motivation, behavior, and self-governance of potential participants. Importantly, some of these ethical issues are amenable to empirical study, which can yield valuable insights and evidence-informed practices that strengthen and enable ethically sound human brain investigation. The overarching goal of this proposal is thus to accelerate neuroscience toward lessening the burden of mental illness and addiction through hypothesis-driven empirical ethics inquiry in three parts. First, we determine the distinct ethical issues and problems encountered in innovative neuroscience related to mental illness and addiction through semi-structured interviews with neuroscientists, neuroethicists, and institutional review board members. Informed by our past work and grounded in a rigorous conceptual model, we examine factors both negative and positive that influence research decisionmaking by people with mental illness and addiction in the context of innovative neuroscience research, and compare their decisionmaking with that of individuals with diabetes and healthy controls. Finally, we develop a new, low-burden screening tool to tailor and enhance the safeguard of informed consent in brain research, providing investigators with a practical, actionable, and protocol-adaptable method for strengthening positive-valence factors and ameliorate negative-valence factors affecting participant decisionmaking. Maximizing our established record of expertise in empirical ethics investigations and neuroethics, this sequence of projects leverages access to the exceptional neuroscience research conducted at Stanford University, including work by BRAIN initiative investigators; provides extensive, systematically collected data on influences on decisionmaking about innovative neuroscience research participation by individuals with mental or physical illness and healthy controls; and develops a new evidence-informed tool for use as a best practice in safeguarding human volunteers in cutting-edge neuroscience. Innovative neuroscience holds extraordinary promise for improving understanding of brain disorders that threaten human health, but as the BRAIN 2025 Scientific Vision notes, new ethical questions are emerging as scientists begin to solve the mysteries of the brain. A rigorous, hypothesis-driven approach to ethical dimensions of neuroscience inquiry is needed to provide investigators, IRBs, policymakers, and the public with evidence to better enable ethical participation in brain research. We develop new knowledge and a novel tool for use as a best practice in safeguarding volunteers in innovative neuroscience research, to ensure ethical participation, enhance trust in science, and accelerate discovery.",Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain,9564206,R01MH114856,"['Achievement', 'Affect', 'Artificial Intelligence', 'Base of the Brain', 'Behavior', 'Behavioral', 'Big Data', 'Brain', 'Brain Diseases', 'Cell model', 'Clinical Research', 'Cognition', 'Collection', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Ecology', 'Effectiveness', 'Emotions', 'Ensure', 'Ethical Issues', 'Ethics', 'Failure', 'Fostering', 'Fright', 'Genes', 'Goals', 'Gold', 'Health', 'Human', 'Human Genome Project', 'Human Volunteers', 'In Vitro', 'Individual', 'Informed Consent', 'Institutional Review Boards', 'Interview', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Motivation', 'Negative Valence', 'Neurosciences', 'Neurosciences Research', 'Participant', 'Personhood', 'Positive Valence', 'Process', 'Protocols documentation', 'Psyche structure', 'Public Health', 'Request for Applications', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Scientist', 'Screening procedure', 'Series', 'Societies', 'Structure', 'Surveys', 'Testing', 'Theoretical model', 'Translations', 'Trust', 'Universities', 'Vision', 'Work', 'addiction', 'base', 'brain machine interface', 'brain research', 'clinical care', 'decision research', 'design', 'evidence base', 'health disparity', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative neurotechnologies', 'insight', 'member', 'neuroethics', 'neuropsychiatry', 'neuroregulation', 'new technology', 'novel', 'optogenetics', 'patient engagement', 'prevent', 'programs', 'sound', 'standard measure', 'tool', 'vaccine development', 'volunteer']",NIMH,STANFORD UNIVERSITY,R01,2018,465508,0.008688715667479703
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9482419,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modality', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genetic architecture', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,455772,-0.009243170508472029
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment Project Summary NIH is increasing its investment in large mutli-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several open-source software systems. For example, the NIH NIAAA and BD2K funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements that called for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for multi-site QC workflows as that would require a unified platform, design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that supports simplified creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific findings findable, accessible, interoperable, and reusable.  Specifically, our multi-site open-source software platform for Medical Image Quality Assurance (mIQa) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system, machine learning to aid in QC process, and an interactive electronic notebook platform. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automating notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, mIQa is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop multi-site, open-source software for Medical Image Quality Assurance (mIQa) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. mIQa will enable efficient and accurate QC processing by levering open-source, state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive review and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment,9622218,R43MH119022,"['Active Learning', 'Address', 'Adolescence', 'Alcohols', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Environment', 'Evaluation', 'FAIR principles', 'Four-dimensional', 'Funding', 'Geography', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'International', 'Internet', 'Investments', 'Label', 'Libraries', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Visual', 'Work', 'Writing', 'application programming interface', 'base', 'cohesion', 'cost', 'dashboard', 'data access', 'data management', 'design', 'experience', 'flexibility', 'image archival system', 'imaging study', 'improved', 'innovation', 'member', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'prototype', 'quality assurance', 'research study', 'software systems', 'success', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R43,2018,225001,-0.018557870053355765
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future.   Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,9565669,R24MH114788,"['Algorithms', 'Archives', 'Atlases', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Ecosystem', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Imagery', 'Individual', 'Ingestion', 'Institution', 'Internet', 'Knowledge', 'Location', 'Machine Learning', 'Metadata', 'Modeling', 'Modification', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data integration', 'data management', 'data resource', 'data submission', 'data visualization', 'data warehouse', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'innovative neurotechnologies', 'member', 'multiple omics', 'neural circuit', 'next generation', 'online resource', 'operation', 'outcome forecast', 'programs', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2018,1293101,-0.006974724267743304
"The Blackfynn Platform for Rapid Data Integration and Collaboration Summary One in seven people worldwide suffers from a brain disorder, e.g., epilepsy, Parkinson's, stroke, or dementia. Development of future treatments depends on improving our understanding of brain function and disease, and validating new treatments critically depends on identifying the underlying biomarkers associated with different conditions. Biomarker discovery requires volume, quality, richness, and diversity of data. This Direct-to-Phase II project extends Blackfynn's cloud data management platform for team science, in order to support interactive data curation and integration and to facilitate biomarker discovery. Our first technical aim develops tools to help select, curate, assess, and regularize datasets: we develop novel “live” query capabilities to ensure users discover relevant data, develop mechanisms for using data's provenance to decide on trustworthiness, and build tools for mapping fields to common data elements. These capabilities address the critical, under-served problem of selecting the data to analyze. Our second technical aim develops techniques for incorporating algorithms to link and co-register across multi-modal data and metadata. Using ranking and machine learning, we can incorporate and combine state-of-the-art algorithms for finding data relationships, and we can link to remote data sources. These capabilities enable scientists to analyze richer datasets with multiple data modalities and properties – thus enabling them to discover more complex correlations and biomarkers. In our third aim, Blackfynn's new technical capabilities will be applied to challenges faced by Blackfynn partners, including problems assessing trustworthiness of data annotations, conducting image analysis, modeling epileptic networks, and identifying biomarkers for neuro-oncology indications. As part of this validation we will also develop HIPAA-compliant mechanisms for working with protected and de-identified data together. Together, these three thrusts will ensure that development of the Blackfynn platform results in tools and technologies that meaningfully accelerate scientific understanding and discovery over rich and complex data, leading to improved treatments for neurologic disease.   Narrative This Direct-to-Phase II project extends the Blackfynn cloud data management platform to enable biomarker discovery for research and development of improved drugs, devices and clinical care for patients with neurologic disease: it develops tools for assembling, evaluating, and rating data, and linking it across modalities and to external systems. It also validates the techniques' effectiveness using real challenges faced by Blackfynn partners, in imaging, epilepsy, and brain tumor research.",The Blackfynn Platform for Rapid Data Integration and Collaboration,9468362,R44DA044929,"['Address', 'Algorithms', 'Benchmarking', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain Neoplasms', 'Case Study', 'Clinical Pharmacology', 'Collaborations', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Provenance', 'Data Science', 'Data Set', 'Data Sources', 'Dementia', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Ensure', 'Epilepsy', 'Funding', 'Future', 'Health', 'Health Insurance Portability and Accountability Act', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mental Depression', 'Metadata', 'Modality', 'Modeling', 'National Institute of Neurological Disorders and Stroke', 'Neurosciences', 'Neurosciences Research', 'Notification', 'Ontology', 'Output', 'Parkinson Disease', 'Patient Care', 'Pharmaceutical Preparations', 'Phase', 'Plug-in', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Science', 'Scientist', 'Semantics', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Standardization', 'Stroke', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Trust', 'Use Effectiveness', 'Validation', 'Work', 'base', 'biomarker discovery', 'clinical application', 'clinical care', 'cloud platform', 'computer science', 'data access', 'data integration', 'data management', 'improved', 'indexing', 'nervous system disorder', 'neuro-oncology', 'neuroimaging', 'novel', 'novel therapeutics', 'open source', 'research and development', 'tool']",NIDA,"BLACKFYNN, INC.",R44,2018,696602,-0.0014948278311021704
"An integrated neural network analysis and video microscopy platform for fully automated particle tracking Project Summary/Abstract  Particle tracking (PT) is a biophysical tool for elucidating molecular interactions, transport phenomena of diverse species, and rheological properties of complex materials. PT experiments involve first obtaining high resolution videos that capture time-resolved increments of particles, followed by extraction of traces of entities of interest from videos in the form of spatial locations over time, a process we refer to as path conversion. Finally, quantitative analysis of the traces will yield diffusivities, viscoelasticity, etc.  Lung diseases, such as cystic fibrosis and COPD, are characterized by a highly viscoelastic mucus layer that is incapable of being cleared by mucociliary clearance. Not surprisingly, the viscoelasticity of mucus often directly reflects disease progression. A variety of mucolytics are being investigated, but due to the variable composition and properties of mucus between patients, effective mucolytics treatment will likely be different between individuals; too little/inappropriate mucolytics will not be effective in restoring mucus clearance, whereas too much may result in bronchorrhea. Although microbeads-based rheology has been performed on a variety of mucus specimens in basic research, the capacity for high throughput characterization of rheological properties of biological specimens in a clinical setting is currently not available. This limitation can be attributed to inefficiencies of path conversion: current PT software requires extensive human supervision/intervention to achieve accurate path conversion, not only resulting in poor reproducibility and throughput but also restricting its use to only expert labs. Our vision is to make PT as objective and easy to use as a simple plate reader that can be readily utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening), and research professionals. Towards this goal, we have created a neural network tracker (NNT) that automatically determines the location of all particles in each frame with zero user-input (i.e. no parameter for users to change), and retains the identity of all particles from frame to frame. The innovation is that NNT can robustly, reproducibly, and accurately track a wide range of 2D/3D videos with virtually no need for human intervention, achieving unparalleled time savings. We have already successfully deployed NNT over the Google cloud, which offers exceptional scalability. Nevertheless, for time-sensitive applications, such as an automated PT rheometer, the transfer of large video data files is likely prohibitive. Therefore, in this Phase I STTR, we seek to enable real-time NNT-based PT analysis on the local machine while video microscopy data is being acquired by the microscope, and allow data from PT analysis to drive the operation of the microscope. In Aim 1, we will integrate our NNT with a single objective fluorescence microscope system called Monoptes. Aim 2 will evaluate the performance of our NNT- Monoptes system. If successful, our technology would form the basis of a fully automated PT system capable of measuring rheological properties of fluids/materials or distribution of particle sizes in a 96-well plate format. Project Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately, its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a software that can consistently provide superior and truly automated tracking performance compared to current alternatives. In this proposal, we will integrate this latest advance with sophisticated instrumentation to develop a microscope system capable of fully automated particle tracking microscopy in a 96-well plate format. If successful, the instrument will likely be utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening of patients), and research professionals.",An integrated neural network analysis and video microscopy platform for fully automated particle tracking,9620574,R41GM130202,"['Acceleration', 'Adopted', 'Antibodies', 'Artificial Intelligence', 'Basic Science', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Cystic Fibrosis', 'Data', 'Data Files', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease Progression', 'Drug Carriers', 'Drug Screening', 'Effectiveness', 'Elasticity', 'Engineering', 'Gaussian model', 'Goals', 'HIV Infections', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Intervention', 'Liquid substance', 'Location', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microspheres', 'Motion', 'Mucociliary Clearance', 'Mucolytics', 'Mucous body substance', 'Output', 'Particle Size', 'Particulate', 'Pathway Analysis', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Positioning Attribute', 'Process', 'Property', 'Radial', 'Reader', 'Reproducibility', 'Research', 'Resolution', 'Respiratory physiology', 'Rheology', 'Risk', 'Running', 'Sampling', 'Savings', 'Series', 'Small Business Technology Transfer Research', 'Software Tools', 'Specimen', 'Spottings', 'Supervision', 'System', 'Technology', 'TensorFlow', 'Time', 'Video Microscopy', 'Viscosity', 'Vision', 'Woman', 'base', 'biophysical tools', 'cloud based', 'drug development', 'experimental study', 'fluorescence microscope', 'innovation', 'instrument', 'instrumentation', 'interest', 'movie', 'novel', 'operation', 'particle', 'patient screening', 'physical science', 'pre-clinical', 'submicron', 'virtual', 'viscoelasticity']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2018,224894,-0.009232731126792904
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9523223,K01ES025442,"['Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Competence', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Variant', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'exhaustion', 'experience', 'experimental study', 'human model', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2018,144298,0.008519383750219387
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9465330,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,503162,-0.013273795994693909
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9698505,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,50000,-0.013273795994693909
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,444363,-0.013180015535181843
"Dynamics of long range network interactions  in focal epilepsy PROJECT SUMMARY Epilepsy is the world’s most prominent serious brain disorder, affecting nearly 50 million people worldwide. For about 30% of these patients, seizures remain poorly controlled despite optimal medical management, with attendant effects on health and quality of life. In order to enable advances in the therapeutic management of epilepsy, a thorough understanding of how cellular processes that drive seizures are linked to large-scale network effects is needed. While seizures impact large brain areas and often multiple lobes, the driving processes span regions on the scale of millimeters. These have been well characterized in animal models, but the relevance to human seizures, i.e. how seizures are driven by brain signals from small-scale processes remains unclear. Instead, the view that naturally-occurring seizures may be attributable instead to large-scale neural mass effects (i.e., the epileptic network) is a subject of ongoing debate. Previously, we defined a key role for surround inhibition in shaping EEG recordings of seizures at the onset site and on small spatial scales. We now propose that surround inhibition has a dual role. On a millimeter scale, its abrupt failure permits the advance of a seizure. At long distances from the seizure focus, strong local inhibition serves to mask the excitatory effects of seizures and may help to hasten seizure termination, while weakened inhibition may permit emergence of ictal activity at a distant, noncontiguous seizure site. Multiple seizure foci may go unrecognized with standard EEG interpretation methods, and are likely a critical factor in epilepsy surgery failures. We hypothesize that once established, multiple ictal generators behave as delay-coupled oscillators, demonstrating activity that is synchronized or even temporally reversed. This results in complex and at times counterintuitive network behavior that can be challenging to reverse engineer from EEG recordings. Typically, however, even intracranial EEG recordings provide only a limited view of neural activity. In this project, an interdisciplinary research group with combined expertise in epilepsy, clinical neurophysiology, computational modeling, and mathematics will conduct a comprehensive study of the neuronal contributors to epileptic networks utilizing a unique combined dataset of simultaneous microelectrode and macroelectrode recordings of human seizures. Using a machine learning approach, we will apply this information to develop a multivariate EEG biomarker based on the inferred source of EEG discharges, high frequency oscillations, and very low frequency (DC) shifts and assess its predictive value for post-resection surgical outcome. We anticipate that the project will lead to a theoretical framework for rational development of innovative strategies for developing interventions to control seizures. PROJECT NARRATIVE This project aims to identify the cellular mechanisms of epileptic networks, a critical barrier to developing treatments based on epileptic network analysis and manipulation. An interdisciplinary team of researchers will address this problem by analyzing and modeling multiscale voltage data from epilepsy patients, and utilizing the results to develop a new multivariate biomarker for seizure-generating brain areas.",Dynamics of long range network interactions  in focal epilepsy,9687085,R01NS084142,"['Address', 'Affect', 'Animal Model', 'Area', 'Automobile Driving', 'Award', 'Behavior', 'Biological Markers', 'Biophysics', 'Brain', 'Brain Diseases', 'Cell physiology', 'Clinical', 'Collection', 'Complement', 'Complex', 'Computer Simulation', 'Coupled', 'Data', 'Data Set', 'Decision Making', 'Development', 'Distant', 'Electroencephalography', 'Electrophysiology (science)', 'Engineering', 'Epilepsy', 'Event', 'Excision', 'Failure', 'Focal Seizure', 'Foundations', 'Frequencies', 'Generations', 'Goals', 'Health', 'High Frequency Oscillation', 'Human', 'Impact Seizures', 'In Vitro', 'Incidence', 'Interdisciplinary Study', 'Intervention', 'Link', 'Lobe', 'Location', 'Machine Learning', 'Masks', 'Mathematics', 'Medical', 'Methods', 'Microelectrodes', 'Monitor', 'Neurons', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Pathologic', 'Pathway Analysis', 'Patients', 'Predictive Value', 'Procedures', 'Process', 'Quality of life', 'Research Personnel', 'Role', 'Sampling', 'Seizures', 'Shapes', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Study models', 'Techniques', 'Terminology', 'Testing', 'Therapeutic', 'Time', 'Travel', 'Universities', 'Weight', 'base', 'improved', 'innovation', 'millimeter', 'minimally invasive', 'multi-scale modeling', 'neurophysiology', 'parallel computer', 'relating to nervous system', 'surgery outcome', 'voltage']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,689291,-0.013778479939248502
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research PROJECT SUMMARY This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0™ that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud™ Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb’s DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PROJECT NARRATIVE PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9741597,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2018,99999,0.00536323312448836
"Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets Project Summary During the past three decades non-invasive functional brain imaging has developed immensely in terms of measurement technologies, analysis methods, and innovative paradigms to capture information about brain function both in healthy and diseased individuals. Although functional MRI (fMRI) has become very useful, it only provides indirect information about neuronal activity through the neurovascular coupling with a limited temporal resolution. Magnetoencephalography (MEG) and electroencephalography (EEG) remain the only available noninvasive techniques capable of directly measuring the electrophysiological activity with a millisecond resolution. During the past eight years we have developed, with NIH support, the MNE-Python software, which covers multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. To further extend our software to meet the needs of a growing user base and reflect recent developments in the MEG/EEG field we will pursue three specific Aims. In Aim 1 we will: (i) Create an all-embracing suite of noise cancellation tools incorporating and extending methods present in different MEG systems; (ii) Implement device independent methods for head-movement determination and compensation on the basis of head movement data recorded during a MEG session; (iii) Develop methods for automatic tagging of artifacts using machine learning approaches. In Aim 2 our focus is to extend the software to make modern distributed computing resources easily usable in processing and to allow for remote visualization without the need to move large amounts of data across the network. Finally, in Aim 3, we will continue to develop MNE-Python using best programming practices ensuring multiplatform compatibility, extensive web-based documentation, training and forums, and hands-on training workshops. As a result of these developments the MNE-Python will be able to effectively process large number of subjects and huge amounts data ensuing and from multi-site studies harmoniously across different MEG/EEG systems. Narrative MEG and EEG can be used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. However, widespread use of these methods especially in large populations has been problematic because of the lack of well-established analysis approaches, which map the sensor data into the brain space for detailed temporal, spatial, and connectivity analysis. This research will provide well-documented and tested novel analysis software to promote both basic neuroscience and clinical research applications using MEG and EEG.",Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets,9594591,R01NS104585,"['Adult', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Brain imaging', 'Brain region', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Collaborations', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Documentation', 'Ecosystem', 'Educational workshop', 'Electroencephalography', 'Electrophysiology (science)', 'Ensure', 'Epilepsy', 'Experimental Designs', 'Financial compensation', 'Functional Magnetic Resonance Imaging', 'Guidelines', 'Head', 'Head Movements', 'Hour', 'Human', 'Imagery', 'Individual', 'Laboratories', 'Language Development', 'Link', 'Machine Learning', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modernization', 'Morphologic artifacts', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Population', 'Process', 'Pythons', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Schizophrenia', 'Science', 'Scientist', 'Site', 'Statistical Data Interpretation', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visualization software', 'Writing', 'autism spectrum disorder', 'base', 'cloud based', 'cluster computing', 'computing resources', 'data acquisition', 'falls', 'human data', 'innovation', 'millisecond', 'multithreading', 'neurovascular coupling', 'novel', 'open source', 'pedagogy', 'sensor', 'sensor technology', 'software development', 'source localization', 'symposium', 'temporal measurement', 'tool', 'verification and validation']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,561118,0.017859509531928452
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9482420,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Home environment', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Mobile Health Application', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'recruit', 'responsible research conduct', 'scale up', 'sensor', 'sensor technology', 'skills', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2018,169419,0.00638527787440669
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9672008,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,347221,-0.001966578613527001
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9559873,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,300000,-0.001966578613527001
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9774474,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Eye', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'biomarker development', 'brain dysfunction', 'career', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistics', 'symposium', 'tool', 'usability']",NIEHS,VANDERBILT UNIVERSITY,K22,2018,200616,-0.00726623171065115
"EEGLAB: Software for Analysis of Human Brain Dynamics Electroencephalography (EEG), the first function brain activity imaging modality, has several natural advantages over metabolic brain imaging modalities. EEG is noninvasive, low cost, and lightweight enough to be highly mobile. Two major shifts in scientific perspective on the nature and use of human electrophysiological data are now ongoing. The first is a shift to using EEG data as a source-resolved, relatively high-resolution cortical source imaging modality. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) of the University of California, San Diego (UCSD), began as a set of EEG data analysis running on Matlab (The Mathworks, Inc.) released by Makeig on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now nearly twenty years later, the EEGLAB reference paper [4] has over 6,750 citations (now increasing by over 4 per day), the opt-in EEGLAB discussion email list links 6,000 researchers, the EEGLAB news list over 15,000 researchers, and an independent 2011 survey of 687 research respondents reported EEGLAB to be the software environment most widely used for electrophysiological data analysis in cognitive neuroscience. Our statistics show that after over the past four years, EEGLAB adoption is still growing steadily. Here, we will develop a framework for thorough comparison of preprocessing methods, and will apply machine learning methods on the large body of data collected by our laboratory to build optimized, automated data processing pipelines. We will greatly augment the power of the EEGLAB environment by providing a cross-study meta-analysis capability and will revise the software architecture to use a file and metadata organization compatible with the Brain Imaging Data Structure (BIDS) framework first developed for fMRI/MRI data archiving. These tools will integrate the HED annotating system allowing for meta-analysis across large corpus of studies. We will implement beamforming within EEGLAB. We will develop a hierarchical Bayesian framework for clustering effective sources on multiple measures across subjects and studies, and will develop tools to perform statistical testing on information flow measures at these scales. Although EEG and MEG recording have co- existed for four decades, little available software can combine both data types, recorded concurrently (`MEEG' data), to enhance source separation. We recently showed that ICA decomposition also allows joint MEEG effective source decomposition and will integrate MEG and joint MEEG data decomposition and imaging into the EEGLAB tool set. We will build tools to use MRI- and fMRI-derived anatomical atlases to inform the interpretation of EEG and MEG brain source dynamics. These radical improvements will further the use of non-invasive human electrophysiology for 3-D functional cortical brain imaging in the U.S. and worldwide, thereby accelerating progress in noninvasive basic and clinical human brain research using highly time- and space-resolved measures of brain electromagnetic dynamics. The EEGLAB signal processing environment is now used in many electrophysiological research and teaching laboratories worldwide. To accelerate progress in basic and clinical cognitive neuroscience, we will continue maintenance and development of the EEGLAB environment, introducing new tools for source separation and localization, source clustering, automatic artifact management, and across-studies meta-analysis, and will extend its scope to process magnetoencephalographic (MEG) and joint EEG/MEG data and to highlight parallels between EEG/MEG? ?source? ?dynamics? ?and? ?results? ?of? ?existing? ?research? ?using? ?fMRI? ?and? ?other? ?brain? ?imaging.",EEGLAB: Software for Analysis of Human Brain Dynamics,9597164,R01NS047293,"['3-Dimensional', 'Adoption', 'Anatomy', 'Architecture', 'Atlases', 'Automatic Data Processing', 'Automation', 'Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Classification', 'Clinical', 'Code', 'Cognitive', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Documentation', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Health', 'Human', 'Image', 'Institutes', 'Internet', 'Joints', 'Laboratories', 'Learning', 'Link', 'Links List', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Measures', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Nature', 'Neurosciences', 'Newsletter', 'Paper', 'Plug-in', 'Process', 'Psyche structure', 'Publishing', 'Reporting', 'Research', 'Research Infrastructure', 'Research Methodology', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Source', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Work', 'base', 'brain research', 'cognitive neuroscience', 'computational neuroscience', 'cost', 'data archive', 'data structure', 'data visualization', 'design', 'experience', 'graphical user interface', 'imaging modality', 'independent component analysis', 'interest', 'learning strategy', 'light weight', 'mathematical methods', 'news', 'novel strategies', 'online course', 'open source', 'research study', 'response', 'signal processing', 'statistics', 'support tools', 'teaching laboratory', 'tool', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,604808,0.018582680654902393
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning Project​ ​Summary/Abstract  There​ ​is​ ​an​ ​enormous​ ​need​ ​for​ ​qualified​ ​people​ ​to​ ​pursue​ ​careers​ ​in​ ​STEM​ ​(Noonan, 2017).​ ​However,​ ​the​ ​lack​ ​of​ ​a​ ​strong​ ​foundation​ ​in​ ​mathematics​ ​means​ ​students​ ​are​ ​less​ ​likely to​ ​pursue​ ​STEM​ ​majors​ ​and​ ​careers​ ​(Chen,​ ​2013;​ ​Griffith,​ ​2010;​ ​Huang,​ ​Taddese,​ ​&​ ​Walter,​ ​E, 2000;​ ​Kokkelenberg​ ​&​ ​Sinha,​ ​2010;​ ​Lowell​ ​et.​ ​al.,​ ​2009).​ ​Students​ ​from​ ​low-income​ ​families, women,​ ​and​ ​underrepresented​ ​minorities​ ​are​ ​also​ ​less​ ​likely​ ​to​ ​major​ ​in​ ​STEM​ ​(Bettinger,​ ​2010; Griffith,​ ​2010;​ ​Hill,​ ​Corbett​ ​&​ ​Rose,​ ​2010;​ ​Kokkelenberg​ ​&​ ​Sinha,​ ​2010).​ ​Improving​ ​math learning​ ​in​ ​the​ ​elementary​ ​grades​ ​is​ ​important​ ​to​ ​ensure​ ​children​ ​have​ ​the​ ​essential foundational​ ​skills​ ​and​ ​strong​ ​self-efficacy​ ​beliefs​ ​to​ ​be​ ​able​ ​to​ ​succeed​ ​with​ ​later​ ​mathematics and​ ​pursue​ ​careers​ ​in​ ​STEM.​ ​With​ ​this​ ​Fast-Track​ ​grant,​ ​​Class​ ​Store​ ​​(​CS​)​,​ ​we​ ​propose​ ​to transform​ ​the​ ​way​ ​in​ ​which​ ​students​ ​learn​ ​​Number​ ​and​ ​Operations​ ​in​ ​Base​ ​Ten.​​ ​​CS​ ​​will​ ​be​ ​​an engaging,​ ​commercially​ ​available,​ ​classroom-based​ ​economy​ ​game​ ​for​ ​tablets​ ​and Chromebooks​ ​that​ ​focuses​ ​on​ ​multi-digit​ ​operations.​ C​​ S​​ ​will​​ ​encourage​ ​conceptual understanding​ ​and​ ​build​ ​math​ ​self-efficacy​ ​for​ ​students​ ​in​ ​grades​ ​K-5​ ​within​ ​the​ ​context​ ​of​ ​a digital,​ ​classroom-based​ ​marketplace.​ ​Within​ ​the​ ​game,​ ​students​ ​will​ ​create​ ​stores,​ ​craft​ ​objects to​ ​sell,​ ​engage​ ​in​ ​selling/purchasing​ ​transactions,​ ​and​ ​work​ ​together​ ​to​ ​increase​ ​the​ ​value​ ​of​ ​the economy.​ ​In​ ​addition,​ ​the​ ​game​ ​will​ ​utilize​ ​​artificial​ ​intelligence​ ​(AI)​ ​to​ ​detect​ ​strategies​ ​students use​ ​and​ ​help​ ​teachers​ ​facilitate​ ​rich​ ​mathematical​ ​discussions​ ​thereby​ ​enhancing​ ​students’ reasoning​ ​skills.  Outcomes.​ ​​The​ ​proposal​ ​will​ ​encourage​ ​three​ ​main​ ​outcomes,​ ​namely:​ ​1)​ ​algorithms​ ​for detecting​ ​math​ ​strategies​ ​students​ ​use,​ ​2)​ ​a​ ​discussion​ ​support​ ​dashboard,​ ​and​ ​3)​ ​algorithms for​ ​predicting​ ​at-risk​ ​status.​ ​A​ ​key​ ​research​ ​aim​ ​is​ ​to​ ​determine​ ​whether​ ​the​ ​software​ ​can​ ​predict math​ ​strategies​ ​students​ ​use​ ​and​ ​detect​ ​which​ ​students​ ​are​ ​at-risk​ ​academically​ ​as​ ​compared to​ ​standardized​ ​assessment​ ​data,​ ​which​ ​will​ ​help​ ​teachers​ ​intervene​ ​appropriately.​ ​The discussion​ ​support​ ​dashboard​ ​will​ ​help​ ​to​ ​promote​ ​rich​ ​mathematical​ ​discussion,​ ​thereby improving​ ​students’​ ​mathematical​ ​justification​ ​and​ ​conceptual​ ​understanding.​ ​The​ ​engaging game​ ​will​ ​bolster​ ​students’​ ​motivation​ ​and​ ​self-efficacy​ ​in​ ​mathematics.  Improving​ ​students’​ ​academic​ ​outcomes​ ​and​ ​self-efficacy​ ​in​ ​base​ ​ten​ ​during​ ​elementary school​ ​will​ ​promote​ ​later​ ​success​ ​in​ ​high​ ​school​ ​mathematics.​ ​Since​ ​the​ ​number​ ​of​ ​advanced math​ ​classes​ ​students​ ​take​ ​is​ ​correlated​ ​with​ ​likelihood​ ​to​ ​complete​ ​a​ ​STEM​ ​degree,​ ​(Chen, 2013)​ ​a​ ​distal​ ​outcome​ ​of​ ​this​ ​proposal​ ​is​ ​increasing​ ​students​ ​pursuing​ ​careers​ ​in​ ​STEM. Project​ ​Narrative  There​ ​is​ ​an​ ​enormous​ ​need​ ​for​ ​students​ ​majoring​ ​in​ ​the​ ​fields​ ​of​ ​Science,​ ​Technology, Engineering​ ​and​ ​Mathematics​ ​(STEM),​ ​yet​ ​lacking​ ​a​ ​strong​ ​foundation​ ​in​ ​mathematics​ ​makes students,​ ​especially​ ​women,​ ​minorities​ ​and​ ​those​ ​from​ ​low-income​ ​backgrounds,​ ​less​ ​likely​ ​to pursue​ ​careers​ ​in​ ​STEM.​ ​​Class​ ​Store​​ ​will​ ​bolster​ ​students’​ ​mathematics​ ​abilities,​ ​including mathematical​ ​reasoning​ ​and​ ​self-efficacy,​ ​in​ ​the​ ​foundational​ ​area​ ​of​ N​​ umber​ ​and​ ​Operations​ ​in Base​ ​10​​ ​in​ ​the​ ​short​ ​and​ ​long​ ​term.​ ​This​ ​will,​ ​in​ ​turn,​ ​lead​ ​to​ ​several​ ​positive​ ​distal​ ​outcomes, such​ ​as​ ​increased​ ​STEM​ ​majors​ ​and​ ​careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9621064,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Childhood Cancer Survivor Study', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2018,149887,0.00740939700195251
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",9615324,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Stream', 'System', 'Techniques', 'Time', 'Work', 'base', 'computer science', 'computerized tools', 'data modeling', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,21379,-0.00838290393977232
"Understanding Action Selection in the Tool Use Network Project Summary: Skilled use of tools is a defining achievement of human cognition, and is enabled by the storage of tool-specific action memories. Many tools are associated with more than one action, and most everyday tasks are associated with more than one tool. Limb apraxia is a common, disabling, and puzzling left-hemisphere disorder characterized by prominent deficits in activating and selecting task-appropriate tool actions. Little is known about the cognitive mechanisms and brain regions enabling such selection in the neurologically intact brain, or how these processes go awry in apraxia. In several other cognitive domains, it has been suggested that appropriate response selection occurs via biased competition—that is, the prioritization of competing incoming information to enable appropriate response selection. Capitalizing on the promise of such frameworks, we have developed a new functional-neuroanatomic model of biased competition in a specific left hemisphere Tool Use network. Called “Two Action Systems Plus” (2AS+), the model generates testable hypotheses about the major principles determining tool action selection, and their deficiencies in apraxia. Specifically, we hypothesize that 1) Competition between tool actions is influenced by the graded similarity of tool action representations, as implemented primarily by the left posterior temporal cortex (pTC), 2) The outcome of the competitive process is affected by the strength and timing of activation of tool action representations, and depends on the dynamic interplay of left pTC and the parietal lobes, 3) Outcome is further influenced by a mechanism that biases competition towards the tool action that is appropriate to goals and context, as implemented by the left inferior frontal gyrus (IFG) and its connections with the supramarginal gyrus (SMG), and 4) There are two subtypes of apraxia characterized by distinct failures in the competitive selection process: an anterior subtype characterized by inability to appropriately resolve tool action competition, and a posterior subtype reflecting weakened competition. These hypotheses will be tested using a number of complementary methods with healthy and brain-lesioned participants, including voxel-based lesion symptom mapping, resting functional connectivity, fMRI with multi-voxel pattern analyses, and eyetracking. By specifying when and how visuomotor information plays a role in tool representations, the proposed experiments promise to critically constrain “embodied” cognition theories claiming that tools automatically evoke their actions. The proposed research will also advance the theoretical understanding of tool action by anchoring relevant constructs in a cognitive-neuroanatomic model, clarify how action representations are organized and activated, and improve our understanding of the mechanisms affecting errors and re-learning in apraxia, with implications for rehabilitation. Project Narrative: Apraxia, a disorder of tool use, is a common and substantially disabling consequence of left hemisphere stroke, yet is relatively rarely studied and hence poorly understood. The proposed work will clarify the brain regions that are associated with the disorder, the task factors that may improve tool use abilities, and the ability of the damaged Tool Use system to learn after stroke. This information will serve as an important building block in the development of treatment strategies.",Understanding Action Selection in the Tool Use Network,9494731,R01NS099061,"['Achievement', 'Adopted', 'Affect', 'Anterior', 'Apraxias', 'Behavior', 'Brain', 'Brain region', 'Cheese', 'Cognition', 'Cognitive', 'Color', 'Disease', 'Failure', 'Functional Magnetic Resonance Imaging', 'Gestures', 'Goals', 'Grant', 'Hand', 'Human', 'Income', 'Individual', 'Inferior frontal gyrus', 'Learning', 'Left', 'Lesion', 'Limb structure', 'Location', 'Machine Learning', 'Mediating', 'Memory', 'Methods', 'Modeling', 'Nature', 'Neurologic', 'Outcome', 'Parietal Lobe', 'Participant', 'Patients', 'Pattern', 'Play', 'Posture', 'Process', 'Production', 'Rehabilitation therapy', 'Research', 'Rest', 'Role', 'Source', 'Specific qualifier value', 'Stroke', 'Structure', 'Structure of supramarginal gyrus', 'Symptoms', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Work', 'base', 'clinically relevant', 'experience', 'experimental study', 'improved', 'novel', 'response', 'theories', 'therapy development', 'tool', 'treatment strategy', 'visual motor']",NINDS,ALBERT EINSTEIN HEALTHCARE NETWORK,R01,2018,381860,-0.0293712771031163
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,-0.00435882139985303
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9583854,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2018,74515,-0.0050047384218201985
"RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data Project Summary/Abstract  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allows the activity of small population of neurons in the human brain to be directly recorded. We use the term ECOG to refer to the entire range of invasive recording techniques (from subdural strips and grids to penetrating electrodes) that share the common attribute of recording neural activity from the human brain with high spatial and temporal resolution. While this ability has resulted in many high-impact advances in understanding fundamental mechanisms of brain function in health and disease, it generates staggering amounts of data as a single patient can be implanted with hundreds of electrodes, each sampled thousands of times a second for hours or even days. The difficulty of exploring these vast datasets is the rate-limiting step in using them to improve human health. We propose to overcome this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the unique properties of ECOG. We dub this software tool RAVE (“R Analysis and Visualization of Electrocorticography data”).  The first goal of Aim 1 is to release RAVE 1.0 to the entire ECOG community by month 6 of the first funding period. This will maximize transformative impact by putting the new tools in the hands of users as quickly as possible, facilitating rapid adoption. The design philosophy of RAVE is driven by three imperatives. The first is to keep users ""close to the data"" so that users may make discoveries about the brain without being misled by artifacts. The second imperative is rigorous statistical methodology. The final imperative is ""play well with others"". As described in Aim 2, our approach will make it easy to seamlessly incorporate new and existing analysis tools written in Matlab, C++, Python or R into RAVE, giving users the best of both worlds: advanced but easy-to-use visualization of results from ECOG experiments, whether they are analyzed with the off-the- shelf tools routines provided with RAVE or novel tools developed by others. Project Narrative  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allow the activity of small population of neurons in the human brain to be directly recorded with high spatial and temporal resolution. ECOG generates staggering amounts of data, and the rate-limiting step in generating new insights about the human brain is the difficulty in exploring this vast quantity of data. We propose to remove this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the analysis and visualization of ECOG data, known as RAVE (“R Analysis and Visualization of Electrocorticography data”).",RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data,9592408,R24MH117529,"['Adoption', 'Algorithms', 'Amalgam', 'Brain', 'Code', 'Communication', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrocorticogram', 'Electrodes', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hour', 'Human', 'Human Activities', 'Imagery', 'Implant', 'Implanted Electrodes', 'Laboratories', 'Language', 'Least-Squares Analysis', 'Letters', 'Literature', 'Machine Learning', 'Medicine', 'Methodology', 'Morphologic artifacts', 'Neurons', 'Neurosciences', 'Nightmare', 'Paper', 'Patients', 'Philosophy', 'Play', 'Plug-in', 'Population', 'Proliferating', 'Property', 'Pythons', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Rest', 'Sampling', 'Seeds', 'Software Design', 'Software Tools', 'Techniques', 'Time', 'United States National Institutes of Health', 'Variant', 'Visit', 'application programming interface', 'base', 'college', 'computer science', 'design', 'experience', 'experimental study', 'graphical user interface', 'improved', 'insight', 'interoperability', 'novel', 'open source', 'programs', 'relating to nervous system', 'statistics', 'temporal measurement', 'tool', 'wiki']",NIMH,BAYLOR COLLEGE OF MEDICINE,R24,2018,244545,0.0026797779997795963
"ClearScope Combined in vivo and ex vivo three‐dimensional (3D) whole‐brain imaging of non‐transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole‐brain datasets, the best approach is brain clearing followed by whole‐brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole‐brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo‐bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide‐spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state‐of‐the‐art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large‐scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,9559081,R44MH116827,"['Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biological Neural Networks', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Dimensions', 'Human', 'Image', 'Immersion Investigative Technique', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,556615,-0.015616509498316809
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9578938,R01AG059874,"['Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Characteristics', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,619917,-0.029149031096961847
"COINSTAC: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community be- comes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2). The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates a dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informat- ics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an inde- pendent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented stor- age vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and pri- vacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix fac- torization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. 4 Project Narrative  Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don’t have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this ‘missing data’ and allow for pooling of both open and ‘closed’ repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed compu- tational solution for a large toolkit of widely used algorithms. 3","COINSTAC: decentralized, scalable analysis of loosely coupled data",9717051,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2018,282320,0.008926583575288265
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9644103,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2018,519349,0.010009625551927576
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9473021,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2018,649098,0.008281842725388061
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9455331,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2018,388993,-0.0076114993366992855
"Structural Development of Human Fetal Brain Abstract Despite its critical significance, little is known about the most dynamic phase of brain development in infancy: 0-2 years. To change the status quo, comprehensive and quantitative infant brain atlases as reference standards for precision health are needed. In addition, diffusion MRI (dMRI) has entered a new era in which dynamic cortical internal microstructural complexity, indexed by e.g. cortical mean kurtosis derived from diffusion kurtosis imaging (DKI), can be studied in the living infant brain noninvasively using more advanced multi-shell dMRI. Furthermore, multi-modality measures offer unparalleled insights into mechanistic structure- function and structure-behavior relationships. Work in the current cycle has focused on structural development of human fetal and preterm brains. Based on high resolution diffusion tensor imaging (DTI) of 150 brains, we have established the atlases and quantified cortical microstructure with cortical fractional anisotropy, validated by histological images and correlated with transcriptomic (RNA) expression. Building upon this work, in the next cycle, we will focus on brain development in infancy, immediately after the fetal period. Specifically, the goal is to establish next-generation dMRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural mean kurtosis measurement by delineating its 4D spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). 160 typically developing infants at 1, 3, 6, 12, 18, 24 months will be recruited. Advanced “connectome-quality” multi-band high-resolution multi-shell dMRI, resting state fMRI (rs-fMRI) and structural MRI will be acquired. High-quality whole-head magnetoencephalography (MEG) will also be acquired. Anatomical labels of all 122 major gray and white matter structures will be built up based on high contrasts from DTI-derived maps. The measurements of DTI-derived metrics will be used for the quantitative components of DTI atlases and age-dependent white matter tract trajectories (Aim 1). Mean kurtosis of the 4th order kurtosis tensor has been shown to be sensitive to cortical internal microstructural changes of infant brains. The spatiotemporal sensitivity of mean kurtosis measures to infant age and cortical region will be investigated (Aim 2). Furthermore, we will establish mechanistic structure-function relationships with multi- modality imaging, including not only multi-shell dMRI, but also rs-fMRI and MEG, all optimized for infant brains (Aim 3). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants (e.g. Z-score maps). Infant cortical microstructure will be delineated noninvasively with 4D spatiotemporal frameworks. With multi-modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general. Narrative Title: Structural development of human fetal brain The goal is to establish next-generation diffusion MRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural measurement by delineating its four-dimensional spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants. With multi- modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general.",Structural Development of Human Fetal Brain,9539514,R01MH092535,"['2 year old', 'Age', 'Anatomy', 'Anisotropy', 'Architecture', 'Area', 'Atlases', 'Auditory', 'Behavior', 'Behavior assessment', 'Behavioral', 'Brain', 'Cerebral cortex', 'Characteristics', 'Clinical Research', 'Collaborations', 'Development', 'Developmental Process', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Fingerprint', 'Four-dimensional', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Human', 'Image', 'Infant', 'Infant Development', 'Infant Health', 'Intellectual functioning disability', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Measurement', 'Measures', 'Modality', 'Motor', 'Multimodal Imaging', 'Neurodevelopmental Disorder', 'Phase', 'Precision Health', 'RNA', 'Reference Standards', 'Research Personnel', 'Resolution', 'Rest', 'Risk Assessment', 'Sensorimotor functions', 'Sensory', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Time', 'Visual', 'Work', 'age related', 'artemis', 'autism spectrum disorder', 'base', 'connectome', 'fetal', 'gray matter', 'histological image', 'indexing', 'infancy', 'insight', 'neuroimaging', 'neuronal circuitry', 'next generation', 'novel', 'prisma', 'recruit', 'relating to nervous system', 'somatosensory', 'spatiotemporal', 'transcriptomics', 'white matter']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2018,622382,-0.01494053033534082
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9559052,R42EY027651,"['Address', 'Algorithms', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Machine Learning', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2018,849367,-0.015032238298669807
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9438535,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416574,0.020417505613266385
"Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction DESCRIPTION (provided by applicant): In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function. Although fMRI research has primarily focused on identifying brain regions that are activated during performance of cognitive tasks, there is growing interest in examining how cognitive functions emerge as a result of context-dependent, dynamic causal interactions between distributed brain regions. Devising and validating methods for investigating such interactions has therefore taken on great significance. The first major goal of this proposal is to address a critical need in fMRI research by developing novel algorithms for identifying context-dependent dynamic causal interactions between distributed brain regions. To this end, we will develop and validate novel computational methods using Multivariate Dynamical Systems based Markov chain Monte Carlo (MDS-MCMC) algorithms that overcome major limitations of existing methods for investigating dynamic causal interactions and connectivity in the human brain. A comprehensive validation framework will be use evaluate MDS-MCMC and compare it with existing dynamic causal estimation methods. The second major goal of this proposal is to use the MDS-MCMC framework to investigate dynamic causal interactions underlying cognition in normal healthy adults, and in patients with Parkinson's disease (PD). Cognitive impairment is one of the most devastating symptoms in PD. Once thought of as an insignificant feature of the disease, it is now clear that cognitive impairment is present in the majority of PD patients and that this impairment is significantly linked to increased disability and the risk of mortality, yetlittle is known about the brain basis of cognitive impairment in PD. The computational algorithms we develop, validate, and apply here will allow us to rigorously investigate brain dynamics support critical cognitive processes in the human brain, leading to a more complete understanding of fundamental mechanisms underlying human brain function and dysfunction. Our proposed studies will also, for the first time, examine casual interactions in simulated, open-source, opto-genetic, experimental and clinical brain imaging data using state-of-the-art sub-second high-temporal resolution fMRI, based on the Human Connectome Project (HCP). Critically, we will maintain a tight link between our computational and systems neuroscience goals algorithms to solve important problems in cognitive, systems and clinical neuroscience. Together, our proposed studies will lead to new and improved computational tools for examining dynamical causal interactions between distributed brain regions, with broad applications to the HCP and clinical neuroscience. The proposed studies are highly relevant to the mission of the NIH Innovations in Biomedical Computational Science and Technology and the Big Data to Knowledge Programs, which seek to encourage development and dissemination of innovative advanced computational tools for brain imaging and neuroscience. We will disseminate our algorithms and software to the research community via NITRC . PUBLIC HEALTH RELEVANCE: In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function and dysfunction. Although fMRI studies of brain function have primarily focused on identifying brain regions that are activated during performance of perceptual or cognitive tasks, there is growing consensus that cognitive functions emerge as a result of dynamic context-dependent interactions between multiple brain areas. Developing new computational methods for investigating causal interactions in fMRI data has therefore taken added significance; the overall goal of this proposal is to address this critical need by developing new methods for studying causal interactions and brain connectivity between distributed brain regions during cognition.",Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction,9521866,R01NS086085,"['Address', 'Adult', 'Algorithmic Software', 'Algorithms', 'Area', 'Basal Ganglia', 'Benchmarking', 'Big Data to Knowledge', 'Biomedical Computing', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive deficits', 'Communities', 'Computational Science', 'Computational algorithm', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Development', 'Disease', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Genetic', 'Goals', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual Differences', 'Link', 'Machine Learning', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Neurosciences', 'Parietal', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Play', 'Prefrontal Cortex', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Resource Sharing', 'Risk', 'Role', 'Short-Term Memory', 'Software Tools', 'Symptoms', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'brain dysfunction', 'cognitive function', 'cognitive load', 'cognitive performance', 'cognitive process', 'cognitive system', 'cognitive task', 'computerized tools', 'connectome', 'disability', 'dynamic system', 'imaging study', 'improved', 'in vivo', 'innovation', 'interest', 'mortality', 'neurophysiology', 'novel', 'open data', 'open source', 'optogenetics', 'programs', 'public health relevance', 'simulation', 'temporal measurement', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2018,554411,-0.0013386738887771865
"Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs PROJECT ABSTRACT Above-knee amputees often struggle to perform the varying activities of daily life with conventional prostheses. Emerging powered knee-ankle prostheses have motors that can restore normative biomechanics, but these devices are limited to a small set of pre-defined activities that must be tuned to the user by technical experts over several hours. The overall goal of this project is to model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning. The universal use of different task-specific controllers in current powered legs is a direct consequence of the prevailing paradigm for viewing human locomotion as a discrete set of activities. There is a fundamental gap in knowledge about how to analyze, model, and control continuously varying locomotion, which greatly limits the adaptability and agility of powered prostheses. The central hypothesis of this project is that continuously varying activities can be represented by a single mathematical model based on measureable physical quantities called task variables. The proposed project will be scientifically significant to understanding how humans continuously adapt to varying activities and environments, technologically significant to the design of agile, user-synchronized powered prosthetic legs, and clinically significant to the adoption of powered knee-ankle prostheses for improved community ambulation. The proposed model of human locomotion will enable new prosthetic strategies for controlling and adapting to the environment, which aligns with the missions of the NICHD/NCMRR Devices and Technology Development program area and the NIBIB Mathematical Modeling, Simulation, and Analysis program. The innovation of this work is encompassed in 1) a continuous paradigm for variable locomotor activities that challenges the existing discrete paradigm, 2) a unified task control methodology that drastically improves the agility of powered prosthetic legs, and 3) a partially automated tuning process that significantly reduces the time and technical expertise required to configure powered knee- ankle prostheses. This continuous task paradigm will provide new methods and models for studying human locomotion across tasks and task transitions. This innovation will address a key roadblock in control technology that currently restricts powered legs to a small set of activities that do not generalize well across users. The adaptability of the proposed control paradigm across users and activities will transform the prosthetics field with a new generation of “plug-and-play” powered legs for community ambulation. PROJECT NARRATIVE The proposed research is relevant to public health because the clinical application of variable-activity powered prosthetic legs can significantly improve community mobility and therefore quality of life for nearly a million American amputees. Recently developed powered knee-ankle prostheses are limited to a small set of pre- defined activities that require several hours of expert tuning for each user. This project will model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning, which aligns with the missions of the Devices and Technology Development program area of the NICHD National Center for Medical Rehabilitation Research and the Mathematical Modeling, Simulation, and Analysis program of the NIBIB.",Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs,9596236,R01HD094772,"['Address', 'Adoption', 'American', 'Amputees', 'Ankle', 'Area', 'Artificial Leg', 'Biomechanics', 'Clinical', 'Communities', 'Computer Simulation', 'Data', 'Degree program', 'Device or Instrument Development', 'Devices', 'Doctor of Philosophy', 'Electrical Engineering', 'Environment', 'Gait', 'Gait speed', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Hand', 'Home environment', 'Hour', 'Human', 'Human body', 'Joints', 'Knee', 'Knowledge', 'Lead', 'Leg', 'Life', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Measurable', 'Measures', 'Mechanics', 'Medical center', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motor', 'Motor Activity', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'Orthotic Devices', 'Outcome', 'Phase', 'Play', 'Process', 'Program Development', 'Prosthesis', 'Public Health', 'Quality of life', 'Rehabilitation Research', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Speed', 'Spinal cord injury', 'Stroke', 'Study models', 'System', 'Technical Expertise', 'Technology', 'Time', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'clinical application', 'clinically significant', 'design', 'exoskeleton', 'experience', 'human data', 'human model', 'improved', 'innovation', 'kinematics', 'mathematical model', 'multidisciplinary', 'orthotics', 'powered prosthesis', 'programs', 'prosthesis control', 'robot control', 'sensor', 'success', 'technology development', 'temporal measurement', 'trend']",NICHD,UNIVERSITY OF TEXAS DALLAS,R01,2018,474602,-0.0007219187448585005
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9679722,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Autistic Disorder', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2018,303226,-0.009926373698669406
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9491555,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Autistic Disorder', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2018,1717236,-0.01005928351298871
"Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery Abstract Intelligent intraoperative display of anatomic and physiologic information coupled to real time situational awareness to critical tissues will benefit all surgery. The current surgical vision is limited to naked human eyes in open surgery or more recently using laparoscopic digital imaging for minimally invasive surgery and robot assisted surgery. In laparoscopic vision, although the visualization of surface anatomy and tissue physiology in the surgical field-of-view has been enhanced by recent advances in optical imaging technology, the imaging paradigm still remains passive and still poses a significant challenge due to the inherent narrow peripheral vision and limited depth perception. We propose the next generation laparoscopic vision system that provides intelligent display of unrecognized tissue structures to human eyes. Our proposed use of a new paradigm and surgical vision technology (called ISVisionTM), equipped with modular plenoptic 3-D Color/HD camera and snapshot NIR hyperspectral imager, will permit a clear visualization of the critical target tissue-of-interest, surrounding anatomy into the operative field, and situational awareness for both the tool and tissue to the surgeon. Our Phase I effort comprises of engineering the clinically viable ISVision platform and testing the performance of its intraoperative use. Specifically, the ISVision system will clearly and precisely identify different tissue characteristics, accurately displaying physiologic information including tissue perfusion and blood flow. Following the Phase 1, we anticipate undertaking a Phase II project, during which we will develop a clinical grade ISVision system and investigate its performance and utility in the operating room. While the initial focus of the Phase I and II effort is on the complex surgery such as liver resection due to crucial nature of critical sub-surface structures located underneath liver hilum and parenchyma, the ISVision system will potentially play an enabling role in all surgeries and establish it as a vital component of the operating room of the future. Narrative Real-time display of the accurate anatomic and tissue physiology during surgery is necessary and crucial in improving surgical outcomes. This proposal aims to develop the next generation surgical vision system that provides intelligent display of unrecognized, unseen tissue structures to human eyes. The current state of the art technology still remains passive, focuses on anatomic display only. A new surgical vision technology, called ISVisionTM, will provide clear display of important anatomic structures, identify not only their distinct shape and position, and offer insightful intelligent function during surgical procedures. The academic partner in this proposal has developed a novel research prototype and has shown that the new imaging tool can enhance surgical vision beyond human visibility for preclinical testing. The small business partner backed by a Venture company from the Bay area has a strong background for successful commercialization. Together, we aim to convert the academic research prototype into a clinically viable market product that will significantly improve the safety, function, and outcome of surgery, not limited by surgeons’ visual perception, training or experience. The ISVision technology will make the surgery safer and more effective.","Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery",9781563,R41EB026402,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anastomosis - action', 'Anatomy', 'Area', 'Awareness', 'Back', 'Blood flow', 'Businesses', 'Characteristics', 'Child', 'Clinical', 'Clinical Engineering', 'Cognitive', 'Color', 'Complex', 'Complication', 'Conventional Surgery', 'Coupled', 'Depth Perception', 'Development', 'Engineering', 'Environment', 'Excision', 'Eye', 'Family suidae', 'Fostering', 'Future', 'Goals', 'Health system', 'Hemorrhage', 'Hepatic artery', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Imaging technology', 'Incubators', 'Individual', 'Injury', 'Intestines', 'Investments', 'Laparoscopes', 'Laparoscopy', 'Liver', 'Machine Learning', 'Measures', 'Modeling', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathologic', 'Pathway interactions', 'Pediatric Research', 'Performance', 'Perfusion', 'Peripheral', 'Phase', 'Physiological', 'Physiology', 'Play', 'Positioning Attribute', 'Pre-Clinical Model', 'Preclinical Testing', 'Process', 'Research', 'Robot', 'Robotics', 'Role', 'Safety', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Small Business Technology Transfer Research', 'Structure', 'Surface', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Vision', 'Visual Perception', 'Work', 'base', 'bile duct', 'clinical translation', 'commercialization', 'data acquisition', 'design', 'digital', 'digital imaging', 'experience', 'fluorescence imaging', 'graphical user interface', 'image guided', 'image processing', 'imager', 'imaging system', 'improved', 'interest', 'meetings', 'millisecond', 'minimally invasive', 'next generation', 'novel', 'optical imaging', 'performance tests', 'pre-clinical', 'prototype', 'research and development', 'robot assistance', 'sensor', 'soft tissue', 'surgery outcome', 'tool']",NIBIB,"ACTIV SURGICAL, INC",R41,2018,42000,-0.007703688605568737
"Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery Abstract Intelligent intraoperative display of anatomic and physiologic information coupled to real time situational awareness to critical tissues will benefit all surgery. The current surgical vision is limited to naked human eyes in open surgery or more recently using laparoscopic digital imaging for minimally invasive surgery and robot assisted surgery. In laparoscopic vision, although the visualization of surface anatomy and tissue physiology in the surgical field-of-view has been enhanced by recent advances in optical imaging technology, the imaging paradigm still remains passive and still poses a significant challenge due to the inherent narrow peripheral vision and limited depth perception. We propose the next generation laparoscopic vision system that provides intelligent display of unrecognized tissue structures to human eyes. Our proposed use of a new paradigm and surgical vision technology (called ISVisionTM), equipped with modular plenoptic 3-D Color/HD camera and snapshot NIR hyperspectral imager, will permit a clear visualization of the critical target tissue-of-interest, surrounding anatomy into the operative field, and situational awareness for both the tool and tissue to the surgeon. Our Phase I effort comprises of engineering the clinically viable ISVision platform and testing the performance of its intraoperative use. Specifically, the ISVision system will clearly and precisely identify different tissue characteristics, accurately displaying physiologic information including tissue perfusion and blood flow. Following the Phase 1, we anticipate undertaking a Phase II project, during which we will develop a clinical grade ISVision system and investigate its performance and utility in the operating room. While the initial focus of the Phase I and II effort is on the complex surgery such as liver resection due to crucial nature of critical sub-surface structures located underneath liver hilum and parenchyma, the ISVision system will potentially play an enabling role in all surgeries and establish it as a vital component of the operating room of the future. Narrative Real-time display of the accurate anatomic and tissue physiology during surgery is necessary and crucial in improving surgical outcomes. This proposal aims to develop the next generation surgical vision system that provides intelligent display of unrecognized, unseen tissue structures to human eyes. The current state of the art technology still remains passive, focuses on anatomic display only. A new surgical vision technology, called ISVisionTM, will provide clear display of important anatomic structures, identify not only their distinct shape and position, and offer insightful intelligent function during surgical procedures. The academic partner in this proposal has developed a novel research prototype and has shown that the new imaging tool can enhance surgical vision beyond human visibility for preclinical testing. The small business partner backed by a Venture company from the Bay area has a strong background for successful commercialization. Together, we aim to convert the academic research prototype into a clinically viable market product that will significantly improve the safety, function, and outcome of surgery, not limited by surgeons’ visual perception, training or experience. The ISVision technology will make the surgery safer and more effective.","Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery",9622159,R41EB026402,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anastomosis - action', 'Anatomy', 'Area', 'Awareness', 'Back', 'Blood flow', 'Businesses', 'Characteristics', 'Child', 'Clinical', 'Clinical Engineering', 'Cognitive', 'Color', 'Complex', 'Complication', 'Conventional Surgery', 'Coupled', 'Depth Perception', 'Development', 'Engineering', 'Environment', 'Excision', 'Eye', 'Family suidae', 'Fostering', 'Future', 'Goals', 'Health system', 'Hemorrhage', 'Hepatic artery', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Imaging technology', 'Incubators', 'Individual', 'Injury', 'Intestines', 'Investments', 'Laparoscopes', 'Laparoscopy', 'Liver', 'Machine Learning', 'Measures', 'Modeling', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathologic', 'Pathway interactions', 'Pediatric Research', 'Performance', 'Perfusion', 'Peripheral', 'Phase', 'Physiological', 'Physiology', 'Play', 'Positioning Attribute', 'Pre-Clinical Model', 'Preclinical Testing', 'Process', 'Research', 'Robot', 'Robotics', 'Role', 'Safety', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Small Business Technology Transfer Research', 'Structure', 'Surface', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Vision', 'Visual Perception', 'Work', 'base', 'bile duct', 'clinical translation', 'commercialization', 'data acquisition', 'design', 'digital', 'digital imaging', 'experience', 'fluorescence imaging', 'graphical user interface', 'image guided', 'image processing', 'imager', 'imaging system', 'improved', 'interest', 'meetings', 'millisecond', 'minimally invasive', 'next generation', 'novel', 'optical imaging', 'performance tests', 'pre-clinical', 'prototype', 'research and development', 'robot assistance', 'sensor', 'soft tissue', 'surgery outcome', 'tool']",NIBIB,"ACTIV SURGICAL, INC",R41,2018,200769,-0.007703688605568737
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9534672,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'patient variability', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'spatial temporal variation', 'standard of care', 'statistics', 'surgery outcome', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2018,148964,-0.0065444769720501795
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9552903,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'health care settings', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'preservation', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2018,740001,-0.01977955733702091
"Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases 7. Project Summary/Abstract There is an urgent need to support research that generates high-quality evidence to inform clinical decision making. Cluster randomized trials (CRTs) achieve the highest standard of evidence for the evaluation of community-level effectiveness of intervention strategies against infectious diseases. However, there is a need to develop new methods to improve the design and analysis of CRTs because unique and complicated analytical challenges arise in such settings. One such issue relates to the intraclass correlation coefficient (ICC), the degree to which individuals within a community are more similar to one another than to individuals in other communities. Design and analysis of CRTs must take into account the ICC. Lack of accurate information on the ICC jeopardizes the power of CRTs, leads to suboptimal choices of analysis methods and complicates the interpretation of study results. However, reliable information on the ICC is difficult to obtain. A robust and efficient approach for estimating ICCs is based on the second-order generalizing estimating equations. However, its use has been limited by considerable computational burden and poor convergence rates associated with the existing algorithms solving these equations. The first aim addresses these computational challenges. Missing data are ubiquitous and can lead to bias and loss of efficiency. The second aim proposes to develop novel robust and efficient methods for estimating ICCs in the presence of informative missing data. For infectious diseases, the underlying contact/transmission networks give rise to complicated correlation structure. The third aim is to develop network and epidemic models to project the ICC. User-friendly software will be developed to facilitate the implementation of new methods. An immediate application of the proposed methods is their application to the Botswana Combination Prevention Project to improve the estimation of intervention effect and to generate reliable ICC estimates for designing future CRTs in the same population. The proposed methods can be applied to other ongoing and future CRTs, and more broadly, to longitudinal studies and agreement studies where ICCs are also of great interest. The proposed research is significant, because success in addressing these issues will improve the ability to design efficient and well-powered CRTs and the precision in estimating the effects of intervention strategies. Innovation lies in the development of improved computing algorithms adapting approaches from deep learning, the use of semiparametric efficiency theory, and the integration of network modeling, epidemic modeling and statistical inference. The results of the proposed research will benefit both ongoing and future CRTs, permit more efficient use of the resources, and ultimately expedite the control of infectious diseases. 8. Project Narrative The proposed research is relevant to public health because improved methodologies for the design and analysis of cluster randomized trials will benefit both ongoing and future studies, permit more efficient use of the resources, and ultimately improve public health response intended to control the spread of infectious diseases. Thus, the proposed research is relevant to the part of NIAID’s mission that pertains to conducting and supporting research to prevent infectious diseases and to respond to emerging public health threats.",Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases,9661636,R01AI136947,"['AIDS prevention', 'Accounting', 'Address', 'Affect', 'Agreement', 'Algorithms', 'Americas', 'Area', 'Attention', 'Behavior Therapy', 'Botswana', 'Characteristics', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Data', 'Dependence', 'Development', 'Disease', 'Disease Outbreaks', 'Ebola virus', 'Effectiveness', 'Effectiveness of Interventions', 'Epidemic', 'Equation', 'Evaluation', 'Future', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Institute of Medicine (U.S.)', 'Intervention', 'Intervention Studies', 'Knowledge', 'Lead', 'Longitudinal Studies', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nosocomial Infections', 'Population', 'Prevention', 'Prevention strategy', 'Probability', 'Public Health', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Support', 'Resources', 'Role', 'Running', 'Science', 'Societies', 'Structure', 'System', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'base', 'clinical decision-making', 'collaboratory', 'deep learning', 'design', 'experience', 'high standard', 'improved', 'innovation', 'insight', 'interest', 'intervention effect', 'mathematical model', 'network models', 'novel', 'prevent', 'response', 'semiparametric', 'success', 'systems research', 'theories', 'transmission process', 'user friendly software']",NIAID,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2018,263913,-0.001220134158688555
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9483579,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Drug Screening', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2018,249000,-0.004738745155597785
"Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION) PROJECT SUMMARY: Trauma to the spinal cord and brain (neurotrauma) together impact over 2.5 million people per year in the US, with economic costs of $80 billion in healthcare and loss-of-productivity. Yet precise pathophysiological processes impacting recovery remain poorly understood. This lack of knowledge limits the reliability of therapeutic development in animal models and limits translation across species and into humans. Part of the problem is that neurotrauma is intrinsically complex, involving heterogeneous damage to the central nervous system (CNS), the most complex organ system in the body. This results in a multifarious CNS syndrome spanning across heterogeneous data sources and multiple scales of analysis. Multi-scale heterogeneity makes spinal cord injury (SCI) and traumatic brain injury (TBI) difficult to understand using traditional analytical approaches that focus on a single endpoint for testing therapeutic efficacy. Single endpoint-testing provides a narrow window into the complex system of changes that describe the holistic syndromes of SCI and TBI. In this sense, complex neurotrauma is fundamentally a problem that requires big- data analytics to evaluate reproducibility in basic discovery and cross-species translation. For the proposed TOP-VISION cooperative agreement we will: 1) integrate preclinical neurotrauma data on a large-scale; 2) develop novel applications of cutting-edge multidimensional analytics to make sense of complex neurotrauma data; and 3) validate bio-functional patterns in targeted big-data-to-bench experiments in multi-PI single center (UG3 phase), and multicenter (UH3 phase) studies. The goal of the proposed project is to develop an integrated workflow for preclinical discovery, reproducibility testing, and translational discovery both within and across neurotrauma types. Our team is well-positioned to execute this project given that with prior NIH funding we built one of the largest multicenter, multispecies repositories of neurotrauma data to-date, housing detailed multidimensional outcome data on nearly N=5000 preclinical subjects and over 20,000 curated variables. We will leverage these existing data resources and apply recent innovations from data science to render complex multidimensional endpoint data into robust syndromic patterns that can be visualized and explored by researchers and clinicians for discovery, hypothesis-generation and ultimately translational outcome testing. PROJECT NARRATIVE: Multicenter, multispecies central nervous system (spinal cord and brain) injury data provides a unique and clinically-relevant opportunity to discover translational outcomes, if we can develop analytical workflows that fully harness these data. Our team has assembled one of largest repositories of such data spanning across spinal cord injury and traumatic brain injury models under prior NIH support. The proposed cooperative agreement will expand data-sharing and big-data analytical workflows to render raw neurotrauma data into novel insights to promote bench-to-bedside translation.",Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION),9547665,UG3NS106899,"['Address', 'Affect', 'Anatomy', 'Animal Model', 'Area', 'Behavioral', 'Big Data', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analytics', 'Data Collection', 'Data Element', 'Data Science', 'Data Sources', 'Detection', 'Drug Targeting', 'FAIR principles', 'Functional disorder', 'Funding', 'Generations', 'Goals', 'Healthcare', 'Heterogeneity', 'Housing', 'Human', 'Individual', 'Injury', 'Knowledge', 'Machine Learning', 'Medical', 'Meta-Analysis', 'Modeling', 'Modernization', 'Molecular', 'Multiple Trauma', 'Mus', 'Nervous System Trauma', 'Neuraxis', 'Outcome', 'Outcome Assessment', 'Pattern', 'Phase', 'Physiological', 'Positioning Attribute', 'Precision Health', 'Prevalence', 'Process', 'Rattus', 'Recovery', 'Recovery of Function', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sensitivity and Specificity', 'Severities', 'Site', 'Spinal Cord', 'Spinal Injuries', 'Spinal cord injury', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Trauma', 'Traumatic Brain Injury', 'Treatment Efficacy', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Validation', 'Weight', 'Work', 'bench to bedside', 'biobehavior', 'biomarker discovery', 'body system', 'clinically relevant', 'cost', 'data integration', 'data resource', 'data sharing', 'data warehouse', 'economic cost', 'economic impact', 'experimental study', 'functional outcomes', 'innovation', 'insight', 'neuroinflammation', 'novel', 'pre-clinical', 'precision medicine', 'preclinical study', 'predictive modeling', 'productivity loss', 'repository', 'response to injury', 'spinal cord and brain injury', 'success', 'therapeutic development', 'therapeutic evaluation', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",UG3,2018,239813,0.006815857881675446
"BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging Project Summary Electrophysiological recordings in humans and animals play an essential role in developing an understanding of the human brain. Signal recording technology spans the entire scale from invasive microelectrode single-unit recordings, through mesoscale macroelectrode measures of local field potentials, to whole-brain monitoring through measurement of scalp potentials (EEG) and extracranial magnetic fields (MEG). Analysis of these data presents a host of challenges, from low level noise removal and artifact rejection to sophisticated spatio-temporal modeling and statistical inference. The multidisciplinary neuroscience research community has an ongoing need for validated and documented open-source software to perform this analysis and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets this need. Brainstorm is a Matlab/Java multi-platform (Linux, MacOS, Windows) software package for analysis and visualization of electrophysiological data. The software is extensively documented through a series of detailed tutorials and actively supported through a user forum and a mailing list. Over the past 8 years we have registered 16,000 distinct users, provided hands on instruction to 1,200 trainees, and the software has been used and cited in ~600 journal papers. Brainstorm includes tools for importing MEG/EEG, intracranial EEG, animal electrophysiology, and near-infrared spectroscopy (NIRS) data from multiple vendors, extensive interactive features for data preprocessing, selection and visualization, coregistration to volume and surface MRIs and atlases, forward and inverse mapping of cortical current density, time-series and connectivity analysis, and a range of statistical tools. Data can be analyzed through a graphical interface or through scripted pipelines. The current proposal represents a plan to extend Brainstorm in a manner that leverages the unique features of our software and addresses important needs for large-scale data analysis. In this project we will continue to extend and support our software through the following three specific aims: (i) we will harness recent developments in distributed and shared data and high performance computing resources, together with standardization of data organization, to facilitate large-scale, reproducible analysis of electrophysiological data. (ii) We will also address the need for improved modeling resulting from the increasing use of both invasive recordings and direct brain stimulation through development of new modeling software for accurate computation of the intracranial electromagnetic fields produced by brain stimulation and neuronal activation. (iii) Finally, we will continue to add new functionality and to support the software through in-person training, online forums, documentation and other resources. Project Narrative Magnetoencephalography (MEG) and Electroencephalography (EEG) are absolutely non-invasive brain imaging tools, which provide information on the spatial distribution and precise temporal orchestration of human brain activity. In addition to basic neuroscience research, MEG and EEG can be also used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses, including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. The neuroscience research community has an ongoing need for validated and documented open-source software to perform these analyses and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets these needs with well-documented and tested novel analyses using MEG and EEG in combination with anatomical MRI and intracranial EEG data.",BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging,9533856,R01EB026299,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Archives', 'Area', 'Atlases', 'Basic Science', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Development', 'Diagnosis', 'Documentation', 'Educational workshop', 'Electrodes', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Electrophysiology (science)', 'Ensure', 'Environment', 'Epilepsy', 'Excision', 'Frequencies', 'Goals', 'Grant', 'High Performance Computing', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Institution', 'Java', 'Joints', 'Journals', 'Language Development', 'Lead', 'Libraries', 'Linux', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Paper', 'Pathway Analysis', 'Pattern', 'Persons', 'Play', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scalp structure', 'Schizophrenia', 'Series', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Standardization', 'Surface', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Universities', 'Vendor', 'Work', 'autism spectrum disorder', 'cloud storage', 'cognitive benefits', 'computerized tools', 'computing resources', 'cortex mapping', 'data resource', 'data sharing', 'data structure', 'data warehouse', 'density', 'design', 'distributed data', 'electric field', 'graphical user interface', 'hands on instruction', 'improved', 'interoperability', 'magnetic field', 'multidisciplinary', 'neuroimaging', 'novel', 'open source', 'relating to nervous system', 'response', 'spatiotemporal', 'tool']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,678920,0.03137516017584278
"Continued Development of Infant Brain Analysis Tools Continued Development of Infant Brain Analysis Tools Abstract: The increasing availability of infant brain MR images, such as those that will be collected through the Baby Connectome Project (BCP, on which Dr. Shen is a Co-PI, focusing on data acquisition), affords unprecedented opportunities for precise charting of dynamic early brain developmental trajectories in understanding normative and aberrant growth. However, to fully benefit from these datasets, a major barrier that needs to be overcome is the critical lacking of computational tools for accurate processing and analysis of infant MRI data, which typically exhibit poor tissue contrast, large within tissue intensity variation, and regionally-heterogeneous and dynamic changes. To fill this critical gap, in 2012 we pioneered in creating an infant-centric MRI processing software package, called infant Brain Extraction and Analysis Tool (iBEAT), and a set of infant-specific atlases, called UNC 0-1-2 Infant Atlases, and further made them freely and publicly available via NITRC. Over the last 4 years, iBEAT and UNC 0-1-2 Infant Atlases have been downloaded 2900+ and 5600+ times, respectively, and contributed to 160+ independent research papers. As indicated by 30+ support letters, iBEAT is now driving the research for MRI studies of early brain development in many labs throughout the world. Results produced by iBEAT are also highlighted in the National Institute of Mental Health (NIMH)'s 2015-2020 Strategic Plan. This project is dedicated to the continuous development, hardening, and dissemination of iBEAT, by developing innovative software modules with comprehensive user support. To achieve this goal, we propose four aims. In Aim 1, we will create an innovative learning-based multi-source information integration framework for joint skull stripping and tissue segmentation for accurate structural measurements. Our method employs random forest to adaptively learn the optimal image appearance features from multimodality images and also informative context features from tissue probability maps. In Aim 2, we will construct longitudinal infant brain atlases at multiple time points (i.e., 1, 3, 6, 9, and 12 months of age) for both T1-/T2-weighted and diffusion-weighted MR images. We propose a longitudinally-consistent sparse representation technique to construct representative atlases with significantly improved structural details by explicitly dealing with possible misalignments between images even after registration. In Aim 3, we will develop a novel learning-based approach for cortical topology correction and integrate it, along with our infant-centric analysis tools and atlases for cortical surfaces, into iBEAT for precise mapping of dynamic and complex cortical changes in infants. Unlike existing tools that perform poorly for infant brains, we will incorporate infant-dedicated tools for topology correction, surface reconstruction, registration, parcellation, and measurements. We will further integrate longitudinal infant cortical surface atlases equipped with parcellations based on growth trajectories. In Aim 4, we will significantly enhance iBEAT in terms of its software functionalities as well as user support via systematic outreach and training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC. Project Narrative This project is dedicated to the continuous development, hardening, and dissemination of iBEAT by developing innovative software modules with comprehensive user support. In particular, we propose four aims: 1) Learning-Based Brain Segmentation; 2) Infant Brain Atlases in the First Year of Life; 3) Cortical Surface-Based Analysis; and 4) Enhancing User Experience and Training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC.",Continued Development of Infant Brain Analysis Tools,9613643,R01MH117943,"['2 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Appearance', 'Atlases', 'Automobile Driving', 'Base of the Brain', 'Brain', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Documentation', 'Education and Outreach', 'Environment', 'Exhibits', 'Goals', 'Growth', 'Human', 'Image', 'Infant', 'Infant Development', 'Joints', 'Label', 'Learning', 'Letters', 'Life', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Methods', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurodevelopmental Disorder', 'Online Systems', 'Paper', 'Play', 'Probability', 'Process', 'Publications', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Series', 'Shapes', 'Software Tools', 'Source', 'Speed', 'Strategic Planning', 'Structure', 'Surface', 'T2 weighted imaging', 'Techniques', 'Time', 'Tissues', 'Training', 'Variant', 'adaptive learning', 'base', 'computerized tools', 'connectome', 'cranium', 'critical period', 'data acquisition', 'diffusion weighted', 'experience', 'file format', 'forest', 'gray matter', 'imaging modality', 'imaging study', 'improved', 'innovation', 'interoperability', 'novel', 'postnatal', 'reconstruction', 'tool', 'white matter']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,466500,-0.013653895468994039
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9474120,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2018,364257,0.022487725832217868
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9568023,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2018,386960,0.007856104299823473
"Introducing Neuroscience and Neurocomputation Concepts to High School Students using Brain-based Neurorobots PROJECT SUMMARY Understanding the brain is a profound and fascinating challenge, captivating the scientific community and the public alike. The lack of effective treatment for most brain disorders makes the training of the next generation of neuroscientists, engineers and physicians a key concern. However, much neuroscience is perceived to be too difficult to be taught in school. To make neuroscience more accessible and engaging to students and teachers, Backyard Brains is developing neurorobots for education: fun and affordable robots with camera­eyes, wheels, WiFi and artificial software brains modeled on real biological brains. The neurorobot kit will allow students to investigate meaningful real­world questions about mind, brain and behavior by designing artificial brains that make the robot’s behavior life­like, sensory­guided and goal­directed. In Phase I of this project, students will work in groups to investigate the question “Why does my dog come to me when I call?” by designing neural networks that make the robot approach when called for. While the robot moves around in the classroom, students will be able to observe its visual sensory input and the flow of activity between its neurons on a smartphone or laptop, and interact with the brain using voice commands and a “reward button” that drives learning. By designing, testing and analysing neurorobot brains, students will acquire a practical understanding of neurons, synapses, neural networks, brain functions, and the relationship between brain and behavior, and develop important computational thinking skills and self­conception as neuroscientists. For Phase I we will develop neurorobot hardware and software, and collaborate with education specialists to develop and evaluate a short high­school instructional unit around neurorobots. Our overall Phase I goal is to demonstrate the feasibility and educational value of using neurorobots to teach high­school neuroscience. Our unique combination of low­cost robot hardware, innovative curriculum, and easy­to­use applications makes our product appealing to our large high­school, university, and amateur customer base. For Phase II we will expand the curriculum and the capabilities of our neurorobot kit, and create an online forum where students and teachers can share brains and discuss experiments. Our long­term aim is to encourage education policy makers to adopt neuroscience requirements by demonstrating an effective neuroscience curriculum organized around brain­based neurorobots. By combining neuroscience, a multidisciplinary field that spans biology, medicine, psychology, mathematics, and engineering, with robotics and a project­based approach to learning, our neurorobots and curriculum will improve STEM­education and inspire the next generation of scientists, engineers and physicians. PROJECT NARRATIVE Backyard Brains is developing neurorobots for education: engaging and affordable robots with artificial software brains based on the latest neuroscience research. The robots and associated lesson plans will enable students to learn neuroscience by creating artificial brains that make the robot’s behavior life­like, sensory­guided and goal­directed. By giving teachers and students access to neurorobotic technologies previously only available in research labs, we aim to inspire the next generation of scientists, engineers and physicians.",Introducing Neuroscience and Neurocomputation Concepts to High School Students using Brain-based Neurorobots,9622419,R43NS108850,"['Address', 'Adopted', 'Anatomy', 'Animals', 'Artificial Intelligence', 'Attitude', 'Auditory', 'Base of the Brain', 'Behavior', 'Binocular Vision', 'Biological', 'Biological Neural Networks', 'Biology', 'Brain', 'Brain Diseases', 'Canis familiaris', 'Cellular Phone', 'Color', 'Communication', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Conceptions', 'Data', 'Devices', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Engineering', 'Ensure', 'Eye', 'Future Teacher', 'Goals', 'High School Student', 'Instruction', 'Interneurons', 'Knowledge', 'Learning', 'Life', 'Locomotion', 'Mathematics', 'Medicine', 'Mind', 'Modeling', 'Motor', 'Nerve', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Next Generation Science Standards', 'Outcome', 'Output', 'Phase', 'Physicians', 'Policy Maker', 'Property', 'Psychology', 'Research', 'Rewards', 'Robot', 'Robotics', 'Role', 'Schools', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Sensory', 'Specialist', 'Students', 'Synapses', 'Technology', 'Testing', 'Training', 'Universities', 'Visual', 'Voice', 'Work', 'base', 'brain behavior', 'brain tract', 'commercialization', 'computational reasoning', 'cost', 'design', 'effective therapy', 'experience', 'experimental study', 'fascinate', 'gaze', 'graphical user interface', 'handheld mobile device', 'high school', 'improved', 'innovation', 'laptop', 'multidisciplinary', 'next generation', 'preference', 'project-based learning', 'science education', 'sensor', 'sensory input', 'skills', 'sound', 'success', 'teacher', 'tool', 'twelfth grade']",NINDS,"BACKYARD BRAINS, INC.",R43,2018,386013,-0.00014969074273984737
"Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies Project Summary Traditionally, environmental epidemiologic studies have focused on assessing risks related to a single pollutant at a time. This, however, does not reflect reality, since we are constantly exposed to multiple pollutants at once. It is very important, therefore, to be able to assess exposure to pollutant mixtures when conducting environmental epidemiologic methods. Doing so, however, is especially challenging, mainly due to the high dimension of the multi-pollutant exposure matrix (if the exposure of interest includes more than e.g. 5 or 10 chemicals) and because these pollutants are usually very highly correlated with each other. Although some methods are available to address these issues, they usually require strong assumptions and have severe limitations. With this study we propose to bypass most of these limitations by adapting and extending a novel and robust method to assess exposure to multiple pollutants, called Principal Component Pursuit (PCP). We will assess the performance of PCP synthetic datasets representing multiple potential scenarios and study designs, and compare our results to those obtained by existing methods. Subsequently, we will apply PCP to three important Public Health issues, i.e. to evaluate the associations between (i) in utero exposure to a mixture of PCBs and neurodevelopment, (ii) exposure to a metals mixture and cardiovascular health, and (iii) exposure to an air pollution mixture and emergency cardiovascular admissions. Finally, we will develop and share software so other researchers can freely use this novel, robust and flexible tool across a plethora of study designs and research questions. Our proposed work will be significant as it will provide epidemiologists with a novel and robust tool to assess exposure to environmental pollutant mixtures. Project Narrative We are constantly exposed to a mixture of environmental pollutants at once, but current epidemiologic methods either assess each pollutant separately, not capturing reality, or have severe limitations. With this study we propose to adapt a wildly popular method used in computer vision applications, called Principal Component Pursuit (PCP), and develop flexible extensions for many epidemiologic settings. We propose to assess the performance of this method, compare with existing methods and employ in real-life applications, as well as develop and share software so other research can also use this novel, robust and flexible tool.",Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies,9771688,R01ES028805,"['Accounting', 'Address', 'Admission activity', 'Air Pollutants', 'Air Pollution', 'Biological', 'Bypass', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chemicals', 'Child', 'Child Development', 'Child Health', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Detection', 'Dimensions', 'Disadvantaged', 'Educational workshop', 'Emergency Situation', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Pollutants', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Exposure to', 'Family', 'Geography', 'Health', 'Heart', 'Joints', 'Life', 'Measurement', 'Metal exposure', 'Metals', 'Methods', 'National Institute of Environmental Health Sciences', 'New York', 'New York City', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Poison', 'Polychlorinated Biphenyls', 'Public Health', 'Publishing', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Sample Size', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'System', 'Techniques', 'Time', 'Toxic effect', 'Toxicology', 'Work', 'cardiovascular health', 'cohort', 'design', 'epidemiology study', 'flexibility', 'health data', 'high dimensionality', 'interest', 'neurodevelopment', 'novel', 'policy implication', 'pollutant', 'prenatal exposure', 'programs', 'tool', 'user-friendly']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,30450,-0.006363316624610925
"Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies Project Summary Traditionally, environmental epidemiologic studies have focused on assessing risks related to a single pollutant at a time. This, however, does not reflect reality, since we are constantly exposed to multiple pollutants at once. It is very important, therefore, to be able to assess exposure to pollutant mixtures when conducting environmental epidemiologic methods. Doing so, however, is especially challenging, mainly due to the high dimension of the multi-pollutant exposure matrix (if the exposure of interest includes more than e.g. 5 or 10 chemicals) and because these pollutants are usually very highly correlated with each other. Although some methods are available to address these issues, they usually require strong assumptions and have severe limitations. With this study we propose to bypass most of these limitations by adapting and extending a novel and robust method to assess exposure to multiple pollutants, called Principal Component Pursuit (PCP). We will assess the performance of PCP synthetic datasets representing multiple potential scenarios and study designs, and compare our results to those obtained by existing methods. Subsequently, we will apply PCP to three important Public Health issues, i.e. to evaluate the associations between (i) in utero exposure to a mixture of PCBs and neurodevelopment, (ii) exposure to a metals mixture and cardiovascular health, and (iii) exposure to an air pollution mixture and emergency cardiovascular admissions. Finally, we will develop and share software so other researchers can freely use this novel, robust and flexible tool across a plethora of study designs and research questions. Our proposed work will be significant as it will provide epidemiologists with a novel and robust tool to assess exposure to environmental pollutant mixtures. Project Narrative We are constantly exposed to a mixture of environmental pollutants at once, but current epidemiologic methods either assess each pollutant separately, not capturing reality, or have severe limitations. With this study we propose to adapt a wildly popular method used in computer vision applications, called Principal Component Pursuit (PCP), and develop flexible extensions for many epidemiologic settings. We propose to assess the performance of this method, compare with existing methods and employ in real-life applications, as well as develop and share software so other research can also use this novel, robust and flexible tool.",Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies,9439949,R01ES028805,"['Accounting', 'Address', 'Admission activity', 'Air Pollutants', 'Air Pollution', 'Biological', 'Bypass', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chemicals', 'Child', 'Child Development', 'Child Health', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Detection', 'Dimensions', 'Disadvantaged', 'Educational workshop', 'Emergency Situation', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Pollutants', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Exposure to', 'Family', 'Geography', 'Health', 'Heart', 'Joints', 'Life', 'Measurement', 'Metal exposure', 'Metals', 'Methods', 'National Institute of Environmental Health Sciences', 'New York', 'New York City', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Poison', 'Polychlorinated Biphenyls', 'Public Health', 'Publishing', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Sample Size', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'System', 'Techniques', 'Time', 'Toxic effect', 'Toxicology', 'Work', 'cardiovascular health', 'cohort', 'design', 'epidemiology study', 'flexibility', 'health data', 'high dimensionality', 'interest', 'neurodevelopment', 'novel', 'policy implication', 'pollutant', 'prenatal exposure', 'programs', 'tool', 'user-friendly']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,519891,-0.006363316624610925
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9622753,R44GM130247,"['Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'Vision', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'mid-career faculty', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems', 'tool']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2018,224984,0.007822028943013058
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9440421,R01EY017835,"['Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Industrialization', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2018,585564,0.023481348593965695
"Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration Project​ ​Summary/Abstract  There​ ​is​ ​an​ ​enormous​ ​deficit​ ​in​ ​students’​ ​understanding​ ​of​ ​fractions​ ​in​ ​the​ ​United​ ​States. Fifth​ ​grade​ ​fraction​ ​knowledge​ ​predicts​ ​high​ ​school​ ​math​ ​performance,​ ​even​ ​when​ ​controlling for​ ​working​ ​memory,​ ​whole​ ​number​ ​knowledge,​ ​IQ,​ ​reading​ ​ability,​ ​and​ ​demographic​ ​factors (Siegler​ ​et​ ​al.,​ ​2012).​ ​Therefore,​ ​addressing​ ​this​ ​deficit​ ​is​ ​a​ ​particularly​ ​important​ ​area​ ​for​ ​early intervention.​ ​With​ ​this​ ​Fast-Track​ ​grant,​ ​​Deep​ ​Fractions​ ​Learning​,​ ​we​ ​propose​ ​to​ ​transform​ ​the way​ ​in​ ​which​ ​students​ ​learn​ ​core​ ​math​ ​curriculum​ ​so​ ​that​ ​materials​ ​are​ ​more​ ​interactive​ ​and engaging,​ ​promote​ ​deeper​ ​learning​ ​of​ ​content,​ ​and​ ​are​ ​aligned​ ​with​ ​the​ ​Common​ ​Core.​ ​More specifically,​ ​we​ ​will​ ​develop​ ​and​ ​evaluate​ ​a​ ​digital​ ​curriculum​ ​for​ ​grades​ ​3-5​ ​covering​ ​the fractions​ ​domain​ ​that​ ​combines​ ​games,​ ​collaboration,​ ​and​ ​an​ ​inquiry​ ​approach.​ ​We​ ​propose​ ​to develop​ ​an​ ​innovative​ ​technology​ ​infrastructure​ ​that​ ​will​ ​integrate​ ​Teachley​ ​learning​ ​games, Success​ ​for​ ​All’s​ ​(SFA)​ ​cooperative​ ​learning​ ​framework,​ ​and​ ​rigorous​ ​lesson​ ​content.​ ​We​ ​will integrate​ ​research​ ​into​ ​the​ ​design​ ​process​ ​and​ ​work​ ​with​ ​Johns​ ​Hopkins​ ​University​ ​to​ ​evaluate the​ ​efficacy​ ​of​ ​the​ ​intervention.  Outcomes.​ ​​The​ ​intervention​ ​will​ ​encourage​ ​four​ ​direct​ ​outcomes​ ​for​ ​students,​ ​namely improved:​ ​1)​ ​conceptual​ ​understanding​ ​of​ ​fractions,​ ​2)​ ​procedural​ ​fluency​ ​with​ ​fractions operations,​ ​3)​ ​mathematical​ ​justification,​ ​and​ ​4)​ ​motivation.​ ​First,​ ​the​ ​curriculum​ ​will​ ​build​ ​both conceptual​ ​understanding​ ​and​ ​procedural​ ​fluency,​ ​providing​ ​strong​ ​visual​ ​models​ ​within engaging​ ​games​ ​that​ ​motivate​ ​students​ ​to​ ​practice.​ ​The​ ​collaborative​ ​learning​ ​model​ ​and​ ​inquiry approach​​ ​​will​ ​improve​ ​students’​ ​mathematical​ ​justification.​ ​Finally,​ ​we​ ​encourage​ ​these outcomes​ ​within​ ​a​ ​motivational​ ​support​ ​structure​ ​designed​ ​to​ ​foster​ ​engagement​ ​and self-efficacy.  Improving​ ​students’​ ​academic​ ​outcomes​ ​and​ ​self-efficacy​ ​in​ ​the​ ​area​ ​of​ ​fractions​ ​during elementary​ ​school​ ​will​ ​promote​ ​later​ ​success​ ​in​ ​high​ ​school​ ​mathematics.​ ​Since​ ​each​ ​additional math​ ​class​ ​students​ ​complete​ ​in​ ​high​ ​school​ ​more​ ​than​ ​doubles​ ​the​ ​odds​ ​of​ ​college​ ​completion (Adelman,​ ​2006),​ ​the​ ​intervention​ ​has​ ​the​ ​potential​ ​to​ ​make​ ​a​ ​real​ ​difference​ ​in​ ​whether students​ ​achieve​ ​sustainable​ ​careers​ ​versus​ ​being​ ​stuck​ ​in​ ​low-wage​ ​jobs. Project​ ​Narrative  Fractions​ ​knowledge​ ​in​ ​the​ ​fifth​ ​grade​ ​strongly​ ​predicts​ ​high​ ​school​ ​math​ ​performance, even​ ​when​ ​controlling​ ​for​ ​working​ ​memory,​ ​whole​ ​number​ ​knowledge,​ ​IQ,​ ​reading​ ​ability,​ ​and demographic​ ​factors​ ​(Siegler​ ​et​ ​al.,​ ​2012).​ ​Intervention​ ​in​ ​this​ ​essential​ ​content​ ​area​ ​will improve​ ​students’​ ​math​ ​ability​ ​in​ ​the​ ​short​ ​and​ ​long​ ​term,​ ​which​ ​in​ ​turn​ ​will​ ​lead​ ​to​ ​several positive​ ​distal​ ​outcomes,​ ​such​ ​as​ ​greater​ ​high​ ​school​ ​graduation​ ​rates​ ​and​ ​college​ ​attendance.","Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration",9617983,R44GM130162,"['Active Learning', 'Address', 'Area', 'Behavior', 'Child', 'Childhood Cancer Survivor Study', 'Collaborations', 'Common Core', 'Control Groups', 'Demographic Factors', 'Distal', 'Early Intervention', 'Educational Curriculum', 'Ethnic Origin', 'Fostering', 'Goals', 'Graduation Rates', 'Grant', 'High School Student', 'Instruction', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Maps', 'Mathematics', 'Mathematics Curriculum', 'Measures', 'Modeling', 'Motivation', 'Occupations', 'Online Systems', 'Outcome', 'Performance', 'Phase', 'Privatization', 'Process', 'Research', 'Research Infrastructure', 'Sampling', 'Self Efficacy', 'Services', 'Short-Term Memory', 'Structure', 'Students', 'Treatment Efficacy', 'United States', 'Universities', 'Visual', 'Wages', 'Work', 'boys', 'career', 'college', 'dashboard', 'deep learning', 'design', 'digital', 'elementary school', 'fifth grade', 'fourth grade', 'girls', 'high school', 'improved', 'innovation', 'innovative technologies', 'mathematical ability', 'operation', 'prototype', 'reading ability', 'success', 'teacher', 'third grade', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2018,149650,-0.001086018758568441
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9584926,U01MH117072,"['Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2018,1882491,-0.04289567727301737
"Structural constraints on large-scale brain activity in psychosis associated with chromosome 22q11.2 deletion syndrome No abstract available Project Narrative Targeted, informed therapies in neuropsychiatric disease remain elusive in part due to a lack of understanding of how complex patterns of brain activity arise from stationary white matter architecture. We propose to apply a novel method based on machine learning and network science to provide a new perspective on structure-function relationships in healthy controls as well as a sample of patients with psychosis secondary to chromosome 22q11.2 deletion syndrome. Our study will leverage the presence of a consistent genetic lesion in this patient cohort to generate findings that could lay the groundwork for the development of interventions to restore healthy brain dynamics in individuals with psychosis-spectrum symptoms.",Structural constraints on large-scale brain activity in psychosis associated with chromosome 22q11.2 deletion syndrome,9682666,F30MH118871,"['22q11.2', 'Address', 'Architecture', 'Brain', 'Brain region', 'Chromosomes', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Complex', 'Conflict (Psychology)', 'Coupling', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Executive Dysfunction', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Genetic', 'Genetic Heterogeneity', 'Goals', 'Heterogeneity', 'Hippocampus (Brain)', 'Human', 'Individual', 'Lead', 'Lesion', 'Machine Learning', 'Measures', 'Membrane', 'Memory', 'Memory impairment', 'Methods', 'Molecular', 'Neurons', 'Occupational', 'Pathologic', 'Pathology', 'Pathway Analysis', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phenotype', 'Philadelphia', 'Physicians', 'Population', 'Prevalence', 'Probability', 'Property', 'Psychopathology', 'Psychotic Disorders', 'Reporting', 'Rest', 'Role', 'Sampling', 'Scanning', 'Schizophrenia', 'Science', 'Scientist', 'Secondary to', 'Self-Direction', 'Severities', 'Short-Term Memory', 'Structural defect', 'Structure', 'Structure-Activity Relationship', 'Symptoms', 'Task Performances', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'University Hospitals', 'Youth', 'base', 'brain abnormalities', 'brain dysfunction', 'career', 'cognitive control', 'cognitive neuroscience', 'cohort', 'conotruncal anomaly face syndrome', 'early onset', 'insight', 'learning network', 'multimodality', 'neuroimaging', 'neuroimaging marker', 'neuropsychiatric disorder', 'neuropsychiatry', 'neurotransmission', 'novel', 'psychotic symptoms', 'regional difference', 'selective attention', 'symptomatology', 'targeted treatment', 'therapy development', 'white matter']",NIMH,UNIVERSITY OF PENNSYLVANIA,F30,2018,49524,-0.013277954126926398
"Enabling Shared Analysis and Processing of Large Neurophysiology Data Project Summary / Abstract Understanding brain function is key to improving health care and advancing a number of scientific initiatives. The treatment of degenerative brain diseases such as Alzheimer's, Parkinson’s, and ALS is becoming increasingly important as the current US population ages and life expectancies increase. The costs of Alzheimer's and other dementias is estimated at over $200 billion in 2016 alone, not to mention the human devastation that these diseases incur. Autism, addiction, depression, epilepsy, traumatic brain injury, and pain treatment are just a few more of the critically important health concerns related to brain function. Cognitive science is also at the forefront of research into computational and autonomous systems, with the potential to revolutionize human computer interaction and tackle emerging global challenges. As a result of these and other significant opportunities the BRAIN (Brain Research through Advancing Innovative Neurotechnologies) Presidential initiative was created to improve the future health and competitiveness of the nation, with the fundamental goal of accelerating brain research. Consistent with this goal, the brain research community has developed the Neurodata Without Borders: Neurophysiology (NWB) file format and specification to support large-scale collaboration and research. This open format was created in 2014 and is already making an impact on cellular-based neurophysiology, with organizations such as the Allen Institute for Brain Science generating and sharing datasets such as the Allen Brain Observatory and the Allen Cell Types Database. Although this preliminary work is promising, progress in the research community is slowed by a lack of software tools to readily browse, process, analyse, and visualize NWB data, while promoting replicability. Thus this work aims to to produce such tools in support of the BRAIN initiative and other large-scale brain research programs by supporting and growing the NWB community. The work proposed here addresses three important workflows in cellular-based neurophysiology: o​ ptical physiology to image neurons under stimuli, silicon probe recordings to detect spike events from the surface of the cortex down through deeps​ structures, and​ in vitro slice electrophysiology to record t​ ime-varying stimulus and electrical response from a neuron​. Novel multiscale software tools will be created to enable efficient browsing, processing, analysis, and visualization of NWB-based brain data; linking experimental stimuli to observed responses. Conversion utilities will also be developed to convert existing data into NWB form. As the data is large, complex, and may be distributed across many sites, the software tools will be web-based, enabling researchers to remotely access and process data in a reproducible manner, and to use scalable cloud computing resources. The software will be released under open source licences and will be placed under formal software process to facilitate sharing across the research community. The tools will be conceived and created with the help of Allen scientists, who will also perform final validation using these three workflows. Project Narrative This research is aimed at better understanding brain function. Such knowledge may lead to improved therapies for degenerative brain diseases such as Alzheimer's, Parkinson’s, and ALS; and provide new treatments for autism, addiction, depression, epilepsy, traumatic brain injury, and pain treatment. These studies of brain science may also yield significant insights into computing areas such as robotics and computer vision, thereby providing both healthcare and economic benefits.",Enabling Shared Analysis and Processing of Large Neurophysiology Data,9515062,R44MH115731,"['Address', 'Adopted', 'Adoption', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Autistic Disorder', 'Base of the Brain', 'Behavior', 'Brain', 'Brain Diseases', 'Case Study', 'Cloud Computing', 'Cognition', 'Cognitive Science', 'Collaborations', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Epilepsy', 'Event', 'Foundations', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'Image', 'Imagery', 'In Vitro', 'Individual', 'Institutes', 'Knowledge', 'Laboratories', 'Lead', 'Licensing', 'Life Expectancy', 'Link', 'Mental Depression', 'Metadata', 'Methods', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Optics', 'Pain management', 'Parkinson Disease', 'Periodicity', 'Phase', 'Physiology', 'Pilot Projects', 'Population', 'Process', 'Pythons', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Robotics', 'Science', 'Scientist', 'Services', 'Silicon', 'Site', 'Slice', 'Software Tools', 'Standardization', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Traumatic Brain Injury', 'Validation', 'Visual', 'Visualization software', 'Work', 'addiction', 'analytical tool', 'base', 'brain research', 'cell type', 'community based participatory research', 'computer human interaction', 'computing resources', 'cost', 'data exchange', 'data format', 'data modeling', 'data sharing', 'data warehouse', 'design', 'distributed data', 'experimental study', 'falls', 'file format', 'hackathon', 'health care economics', 'improved', 'innovation', 'innovative neurotechnologies', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'open source', 'prevent', 'programs', 'relating to nervous system', 'research and development', 'response', 'success', 'terabyte', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R44,2018,728425,0.002032848799330802
"The chondrocranium in craniofacial development and disease Most investigations of craniosynostosis focus on the dermatocranium, the second cranial skeleton to form during embryogenesis that comprises the dermal bones of the cranial vault and facial skeleton. A completely separate cranial skeleton, the chondrocranium, develops before the dermatocranium to support the embryonic brain and other sense organs. Historically, the chondrocranium has been studied across the vertebrates and is recognized as fundamental to craniofacial development, but it is not well known to craniofacial biologists and has never been studied in the laboratory mouse until now. The chondrocranium is formed of cartilage and though parts of it ossify endochondrally, other portions begin to degenerate by about embryonic day 15-16 in the mouse. By careful analysis of whole mount and histological specimens, we have documented the synchronized deterioration of select chondrocranial elements with the appearance and superimposition of particular dermal bones of the growing dermatocranium. These observations signal the existence of a mechanism for the coordinated, localized expansion (dermal bones) and resorption (cartilage) of two developmentally and evolutionarily separate skeletal systems. Our project, supported by strong preliminary data of the mouse chondrocranium, is designed to test a central hypothesis: that the chondrocranium serves as a structural and functional scaffold for the later development of dermatocranial elements including the formation of cranial vault sutures. Based on the common finding that boundaries between different cell populations often serve as tissue organizers, we recognize the establishment and maintenance of stable boundaries that restrict the mixing of different cell populations as critical to proper development, and propose a research design that interrogates the chondrocranial/dermatocranial boundary as significant to the coordinated development of the skull. We will interrogate cells at specific sites to determine the processes that function to maintain the boundaries. Then using the Fgfr2c+/C342Y mouse model for craniosynostosis, we will investigate relevant chondrocranial/dermatocranial boundaries operative in the development of two craniosynostosis phenotypes: premature closure of the coronal suture and abnormal growth of the midface. That the chondrocranium is composed of irregularly shaped cartilages, many of which are short-lived, requires that we conceive new tools for analysis. We will complete development of an innovative system to dissect and reconstruct the chondrocranium in silico from micro computed tomography images with tight temporal control, precisely delineate chondrocranial anatomy in 3D over embryonic time, and establish the role of the chondrocranium in development of the dermatocranium. Achieving our goals will enrich textbook knowledge of craniofacial development by defining the role of the chondrocranium in the production of dermatocranial phenotypes, provide information relative to the pathophysiology of countless craniofacial anomalies, and reveal potential avenues for the development of novel therapeutics. Craniofacial anomalies are common birth defects that require comprehensive, sometimes repetitive corrective surgeries to manage individual cases. To ameliorate the financial and emotional burden on patients and their families, efforts are aimed at the development of preventative therapies but these require a thorough understanding of craniofacial development. We offer novel information about the chondrocranium, the first embryonic cranial skeleton to develop, and focus on mechanisms operating within boundaries between it and the dermatocranium that are critical to craniofacial development, in normal individuals and in craniofacial disease.",The chondrocranium in craniofacial development and disease,9496083,R01DE027677,"['Acids', 'Affect', 'Age', 'Anatomy', 'Apert-Crouzon syndrome', 'Apoptosis', 'Appearance', 'Awareness', 'Birth', 'Bone Resorption', 'Brain', 'Cartilage', 'Cell Lineage', 'Cell physiology', 'Cells', 'Cephalic', 'Chondrichthyes', 'Chondrocranium', 'Complex', 'Computer Simulation', 'Congenital Abnormality', 'Craniofacial Abnormalities', 'Craniosynostosis', 'Data', 'Dermal', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Elements', 'Embryo', 'Embryonic Development', 'Embryonic Structures', 'Emotional', 'Ethnic group', 'Event', 'Face', 'Family', 'Functional disorder', 'Gene Expression', 'Goals', 'Graph', 'Growth', 'Image', 'Incidence', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory mice', 'Live Birth', 'Maintenance', 'Modernization', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Operative Surgical Procedures', 'Osteoblasts', 'Pathway interactions', 'Patients', 'Phenotype', 'Play', 'Population', 'Preventive therapy', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Regulation', 'Reproducibility', 'Research', 'Research Design', 'Role', 'Sense Organs', 'Signal Transduction', 'Site', 'Skeletal system', 'Skeleton', 'Staging System', 'Stains', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Tissues', 'Transgenic Mice', 'Vertebrates', 'X-Ray Computed Tomography', 'base', 'bone', 'cleft lip and palate', 'coronal suture', 'craniofacial', 'craniofacial development', 'cranium', 'deep learning', 'design', 'fibroblast growth factor receptor 2c', 'histological specimens', 'imaging Segmentation', 'innovation', 'molecular marker', 'mouse model', 'novel', 'novel therapeutics', 'osteogenic', 'premature', 'reconstruction', 'scaffold', 'sex', 'spatiotemporal', 'three-dimensional modeling', 'tool']",NIDCR,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2018,533846,-0.033277708778047047
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9281577,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2018,1320387,0.0013333752996137534
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,9133939,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Conscious', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Foundations', 'GTP-Binding Protein alpha Subunits, Gs', 'Hand functions', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Subconscious', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'robot control', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2017,133916,0.015452473390648824
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9215686,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cells', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Education', 'Educational Curriculum', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'public health relevance', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2017,59383,-0.008587363491563908
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9346652,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2017,204981,0.008280483434358322
"Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes Abstract: Particle tracking (PT) is a powerful biophysical tool for elucidating molecular interactions, transport phenomena and rheological properties in complex biological environments. Unfortunately, PT remains a niche tool in life and physical sciences with a limited user base, in large part due to significant time and technical constraints in extracting accurate time-variant positional data from recorded movies. These constraints are exacerbated in experiments with low signal-to-noise ratios or substantial heterogeneity, as frequently encountered with nanoparticles and pathogens in biological fluids. Currently available software that attempts to automate the movie analysis process rely almost exclusively on assigning static image filters based on specific intensity, pixel size and signal-to-noise ratio thresholds. Unfortunately, when applied to actual experimental data with substantial spatial and temporal heterogeneity, the current software generally produces substantial numbers of false positives (i.e. tracking artifacts) or false negatives (i.e. missing actual traces), and frequently both. Frequent user intervention is thus required to ensure accurate tracking even when using sophisticated tracking software, markedly reducing experimental throughput and resulting in substantial user- to-user variations in analyzed data. The time required for accurate particle tracking analysis makes PT experiments exceedingly expensive compared to other commonly used experimental techniques in life sciences. These same tracking analysis limitations have effectively precluded investigators from undertaking more sophisticated 3D PT, even though the microscopy capability to obtain such movies is readily available and critical scientific insights can be gained from 3D PT. To circumvent the challenges with currently available particle tracking software, we have developed a new approach for particle identification and tracking, based on machine learning and convolutional neural networks (CNN). CNN is a type of feed-forward artificial neural network designed to process information in a layered network of connections that mimics the organization of real neural networks in the mammalian retina and visual cortex. Unlike most CNN imaging models that are trained to make predictions on static images, we have trained our CNN to input adjacent frames so that each prediction includes information from the past and future, thus effectively performing convolutions in both space and time to infer particle locations. Similar principles of image analysis are now being harnessed by developers of autonomous vehicle technologies to distinguish the motions of different objects on the road. We have applied our CNN tracking algorithm to a wide range of 2D movies capturing dynamic motions of nanoparticles, viruses and highly motile bacteria, achieving at least 30-fold time savings with virtually no need for human intervention while maintaining robust tracking performance (i.e. low false positive and low false negative rates). In this STTR proposal, we seek to focus on further optimization and testing of our neural network tracking platform for 2D PT, including the use of cloud computing (Aim 1), and extending our neural network tracker to enable accurate 3D PT (Aim 2). Our vision is to popularize PT as a research tool among researchers by minimizing the time and labor costs associated with PT analysis. Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a computational neural network that can recognize objects in much the same way as the human eye, and which consistently provided superior and truly automated tracking performance compared to current alternatives. This STTR will establish the feasibility of using our computational neural network for robust 2D and 3D particle tracking analysis.","Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes",9347679,R41GM123897,"['Adopted', 'Advanced Development', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Bacteria', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Classification', 'Cloud Computing', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diffuse', 'Ensure', 'Environment', 'Eye', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Performance', 'Phase', 'Photobleaching', 'Process', 'Property', 'Radial', 'Research', 'Research Personnel', 'Retina', 'Savings', 'Scientist', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Software Tools', 'Spottings', 'Students', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Virus', 'Vision', 'Visual Cortex', 'Work', 'base', 'biophysical tools', 'cell motility', 'cloud based', 'cost', 'design', 'experimental study', 'feeding', 'field study', 'graduate student', 'improved', 'insight', 'interest', 'macromolecule', 'movie', 'nanoparticle', 'novel strategies', 'particle', 'pathogen', 'physical science', 'response', 'spatiotemporal', 'submicron', 'terabyte', 'tool', 'virtual']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2017,224997,-0.006048942915220488
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9373088,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Cereals', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Darkness', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Technology', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'behavioral study', 'cognitive development', 'computerized', 'cost', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2017,243750,0.0008485621966077122
"Pattern Analysis of fMRI via machine learning/sparse models: application to brain development Abstract Resting state fMRI (rsfMRI) provides reproducible, task-independent biomarkers of coherent functional activity linking different brain regions. The main goal of the proposed project is to leverage advances in signal processing and machine learning methods to derive clinically useful biomarkers based on patterns of functional connectivity, and to test these biomarkers in a large study of brain development. Central to our methodology are 1) computing a subject-specific functional parcellation of the brain, which defines nodes for characterizing individualized functional brain networks; 2) extracting sparse connectivity patterns for robustly representing brain networks; 3) capturing heterogeneity in brain networks across individuals in a given population; and 4) deriving individualized predictive indices of psychosis risk from brain connectivity in a large study of brain development. This novel suite of functional connectivity analysis tools will be developed and validated based on data from the Human Connectome Project and the Philadelphia Neurodevelopmental Cohort (PNC). Finally, these techniques will be applied to PNC data in order to delineate heterogeneity in network development in youth with psychosis-spectrum symptoms. Our hypothesis is that patterns of functional connectivity in adolescents with psychosis-spectrum symptoms will be different from those in typically developing adolescents, and this difference will display a high degree of heterogeneity that is linked to underlying heterogeneity in pathologic neurodevelopmental trajectories. Moreover, we expect that machine learning techniques will allow us to predict on an individual basis which adolescents with psychosis-spectrum symptoms will remain stable, which will revert to normal, and which will progress to psychosis, based on their baseline functional connectivity signatures. Our methods are generally applicable to rsfMRI studies for detecting and quantifying spatio-temporal functional connectivity patterns in diverse fields, including diagnosing brain abnormalities in neuropsychiatric diseases, and finding associations of functional connectivity with different cognitive functions. All methods will be made publicly available and form an important new resource for the broader neuroscience community. Project narrative This proposal develops a suite of advanced functional imaging pattern analysis methods, aiming to delineate heterogeneity in brain network development in youth with psychosis-spectrum symptoms, ultimately leading to early biomarkers of neuropsychiatric disorders. Methodologically, the proposed work leverages upon the strengths of sparse and non-negative decompositions of imaging data, which offer several advantages over conventional mass-univariate and linear multivariate methods. One of the largest and most comprehensive cohorts of 1,600 individuals ages 8 through 21 provides unique imaging and clinical data to support the application of these methods to brain development.",Pattern Analysis of fMRI via machine learning/sparse models: application to brain development,9307803,R01EB022573,"['Address', 'Adolescent', 'Age', 'Algorithms', 'Anatomy', 'Biological', 'Biological Markers', 'Brain', 'Brain region', 'Classification', 'Clinical Data', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neurosciences', 'Outcome', 'Pathologic', 'Pathway Analysis', 'Pattern', 'Pattern Recognition', 'Philadelphia', 'Population', 'Psychotic Disorders', 'Reproducibility', 'Resources', 'Rest', 'Risk', 'Sampling', 'Shapes', 'Subgroup', 'Symptoms', 'Techniques', 'Testing', 'Work', 'Youth', 'base', 'brain abnormalities', 'clinical biomarkers', 'cognitive function', 'cohort', 'connectome', 'follow-up', 'human data', 'improved', 'indexing', 'interest', 'learning strategy', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'signal processing', 'spatiotemporal', 'tool', 'trend']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2017,549838,-0.03283250925758898
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9213309,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,451650,-0.040458349424483876
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9349475,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2017,305372,0.012062994319409309
"User-driven fitting of hearing aids and other assistive hearing devices Hearing aids are the principal tool today for ameliorating age-related hearing loss and its significant social, cognitive and functional costs to patients and society at large. However, many individuals who are prescribed hearing aids do not use them at all, or use them only occasionally. Most reasons behind the “hearing aid in the drawer” phenomenon relate to the characteristics of the sound produced, and could, in theory, be addressed with the correct signal processing strategy. The problem persists despite the increased complexity and power of new devices, for three reasons: (a) The hearing aid parameters, as set in the clinic, introduce distortion or render audible many sounds that the hearing impaired user had become accustomed to not hearing. The novelty is often so uncomfortable for the user as to discard the device. (b) The optimum parameters vary depending on the listening task and environment. Under some conditions, a device with parameters designed for a different condition will perform worse than no device at all. (c) The clinical fitting is derived from a non-ideal way to assess auditory function (the pure- tone audiogram). The optimum parameters for the actual impairment may be different from those of the prescribed fitting. Although it is true that the physiological mechanisms make it impossible to process sound so as to completely reverse the effect of sensorineural hearing loss, a device that delivers some benefit at all times is likely to be used all the time. The goal is to develop a hearing aid that can adaptively change its parameters to address the problems above, and will be accomplished with a novel fitting approach that rapidly presents a number of parameter settings to the user and lets the user guide the system toward the optimal settings for each listening situation. This requires the development of machine-learning algorithms to effectively search the parameter space and user interface devices and instructions that are easy for the patient to use. The focus of this Phase I proposal is the development of the algorithms and the adaptive user-driven fitting program, and to compare the proposed fitting with the traditional audiogram-based fitting across measures of functional hearing (ability to recognize speech in noise) and subjective preference. A hearing aid user is often dissatisfied with the sound quality of their device, despite its sophistication and adjustment by a trained audiologist. The problem can be mitigated by letting the user fine-tune the device for maximum comfort in everyday use. We will apply modern machine learning methods to develop a program for efficient user-driven fitting of hearing assistive devices.",User-driven fitting of hearing aids and other assistive hearing devices,9409910,R43DC016251,"['Address', 'Algorithms', 'Audiometry', 'Auditory', 'Back', 'Books', 'Cellular Phone', 'Characteristics', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Development', 'Devices', 'Environment', 'Future', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intuition', 'Knowledge', 'Likelihood Functions', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Music', 'Noise', 'Outcome', 'Patients', 'Performance', 'Phase', 'Physiological', 'Presbycusis', 'Process', 'Protocols documentation', 'Psychology', 'Psychophysics', 'Relaxation', 'Reproducibility', 'Self-Help Devices', 'Sensorineural Hearing Loss', 'Societies', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Update', 'base', 'cohort', 'cost', 'design', 'hearing impairment', 'improved', 'learning strategy', 'models and simulation', 'novel', 'performance tests', 'preference', 'programs', 'response', 'signal processing', 'simulation', 'social', 'sound', 'success', 'theories', 'tool', 'vector']",NIDCD,"CARAWAY SOFTWARE, INC.",R43,2017,224966,0.005715589037571926
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9312420,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2017,200225,-0.001906377465653615
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9383718,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2017,359872,-0.005156844708701949
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9517179,U54EB020403,"['AIDS/HIV problem', 'Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2017,81900,-0.014485696192279539
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9302420,U54EB020403,"['AIDS/HIV problem', 'Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2017,2369482,-0.014485696192279539
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9278954,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2017,205185,0.013975257102518068
"ISPW8 Conference: Designing the next generation of closed loop seizure control Project Summary The overall objective of this effort is to convene “ISPW8: Designing the next generation of closed loop seizure control”, that will take place August 20-23, 2017 at the University of Minnesota in Minneapolis. This conference is the next in a series of seizure prediction workshops that started in 2002, and has become the premier international venue for quantitative epilepsy research. The goal of this upcoming meeting is to focus on the development of all stages of a next-generation seizure control device. The first day will have two didactic sessions, one focusing on the clinical aspects of epilepsy, the other on Big Data analytic techniques. The body of the conference will be organized around themes motivated by the three stages of closed loop intervention: 1) input: sensing and biomarkers, 2) processing: system analysis, 3) output: intervention. The theme of the second day of will be on multimodal sensors and biomarkers of epilepsy, focused especially on developing new technology. The theme of the third day will be on utilizing advanced machine learning, statistics, and computational models, to understand and characterize the large datasets from high resolution technology. The final day will be on novel interventions and control theory: new strategies for implantable anti-seizure interventions and methods for optimizing them, as well as implementation into closed loop control devices. “Provocative sessions” at the end of each day will focus on unpublished research and hypotheses followed by discussion and debate. Through this conference we aim to build bridges between the many disciplines that comprise this unique field: theoretical, computational, experimental, clinical, and industry, while also preparing the next wave of young researchers. The overall goal is to develop improved quantitative methods to predict, quantify, characterize, and control seizures. NIH funding is sought for travel support to encourage US participation. Project Relevance/Project Narrative We plan to convene an international meeting to address questions at the intersection of clinical neurophysiology, engineering, computational and epilepsy neuroscience using emerging technologies and quantitative methods. The objectives of this interdisciplinary group – and the themes of the meeting – are to take our growing understanding of the mechanisms and dynamics that lead to seizures at all scales of brain from neuron to organism, and develop successful technologies and therapies for observing, predicting and treating pharmacoresistant epilepsy syndromes.",ISPW8 Conference: Designing the next generation of closed loop seizure control,9398788,R13NS101927,"['Address', 'Behavior', 'Big Data', 'Biological Markers', 'Brain', 'Canis familiaris', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Computer Simulation', 'Data Analytics', 'Data Set', 'Detection', 'Development', 'Devices', 'Discipline', 'Educational workshop', 'Electroencephalography', 'Emerging Technologies', 'Engineering', 'Epilepsy', 'Evaluation', 'Fostering', 'Foundations', 'Funding', 'Goals', 'High Frequency Oscillation', 'Industry', 'International', 'Intervention', 'Lead', 'Machine Learning', 'Mentors', 'Methods', 'Minnesota', 'Modeling', 'Neurologist', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Paper', 'Participant', 'Pattern', 'Physiology', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Seizures', 'Seminal', 'Series', 'Students', 'Surgeon', 'Syndrome', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Travel', 'Underrepresented Groups', 'United States National Institutes of Health', 'Universities', 'career', 'computerized data processing', 'computerized tools', 'control theory', 'cost', 'data modeling', 'data sharing', 'design', 'graduate student', 'improved', 'interest', 'international partnership', 'meetings', 'member', 'multimodality', 'neurophysiology', 'new technology', 'next generation', 'novel', 'peer', 'physiologic model', 'sensor', 'statistics', 'success', 'symposium', 'tool']",NINDS,UNIVERSITY OF MINNESOTA,R13,2017,15000,0.00033015062014937025
"Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain Great discoveries in neuroscience hold promise for reducing the burden of many of the most disabling conditions that threaten human health on a global scale, including mental illnesses and addictions. Increasingly, exceptionally innovative science inspires hope that these devastating brain-based disorders may be prevented, treated, and even cured but, as the BRAIN 2025 Scientific Vision notes, a suite of novel ethical challenges confronts those engaged in innovative neuroscience. These concerns include the deepest questions about what defines humanity and personhood, what forms of novel inquiry may exceed ethically acceptable limits in society, and how to perform ethically sound studies with volunteers who may be vulnerable to exploitation in the research situation. Such issues are particularly salient in mental illness and addiction research because these conditions affect cognition, emotion, motivation, behavior, and self-governance of potential participants. Importantly, some of these ethical issues are amenable to empirical study, which can yield valuable insights and evidence-informed practices that strengthen and enable ethically sound human brain investigation. The overarching goal of this proposal is thus to accelerate neuroscience toward lessening the burden of mental illness and addiction through hypothesis-driven empirical ethics inquiry in three parts. First, we determine the distinct ethical issues and problems encountered in innovative neuroscience related to mental illness and addiction through semi-structured interviews with neuroscientists, neuroethicists, and institutional review board members. Informed by our past work and grounded in a rigorous conceptual model, we examine factors both negative and positive that influence research decisionmaking by people with mental illness and addiction in the context of innovative neuroscience research, and compare their decisionmaking with that of individuals with diabetes and healthy controls. Finally, we develop a new, low-burden screening tool to tailor and enhance the safeguard of informed consent in brain research, providing investigators with a practical, actionable, and protocol-adaptable method for strengthening positive-valence factors and ameliorate negative-valence factors affecting participant decisionmaking. Maximizing our established record of expertise in empirical ethics investigations and neuroethics, this sequence of projects leverages access to the exceptional neuroscience research conducted at Stanford University, including work by BRAIN initiative investigators; provides extensive, systematically collected data on influences on decisionmaking about innovative neuroscience research participation by individuals with mental or physical illness and healthy controls; and develops a new evidence-informed tool for use as a best practice in safeguarding human volunteers in cutting-edge neuroscience. Innovative neuroscience holds extraordinary promise for improving understanding of brain disorders that threaten human health, but as the BRAIN 2025 Scientific Vision notes, new ethical questions are emerging as scientists begin to solve the mysteries of the brain. A rigorous, hypothesis-driven approach to ethical dimensions of neuroscience inquiry is needed to provide investigators, IRBs, policymakers, and the public with evidence to better enable ethical participation in brain research. We develop new knowledge and a novel tool for use as a best practice in safeguarding volunteers in innovative neuroscience research, to ensure ethical participation, enhance trust in science, and accelerate discovery.",Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain,9419223,R01MH114856,"['Achievement', 'Affect', 'Artificial Intelligence', 'Base of the Brain', 'Behavior', 'Behavioral', 'Big Data', 'Brain', 'Brain Diseases', 'Cell model', 'Clinical Research', 'Cognition', 'Collection', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Ecology', 'Effectiveness', 'Emotions', 'Ensure', 'Ethical Issues', 'Ethics', 'Failure', 'Fostering', 'Fright', 'Genes', 'Goals', 'Gold', 'Health', 'Human', 'Human Genome Project', 'Human Volunteers', 'In Vitro', 'Individual', 'Informed Consent', 'Institutional Review Boards', 'Interview', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Motivation', 'Negative Valence', 'Neurosciences', 'Neurosciences Research', 'Participant', 'Patients', 'Personhood', 'Positive Valence', 'Process', 'Protocols documentation', 'Psyche structure', 'Public Health', 'Request for Applications', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Scientist', 'Series', 'Societies', 'Structure', 'Surveys', 'Testing', 'Theoretical model', 'Translations', 'Trust', 'Universities', 'Vision', 'Work', 'addiction', 'base', 'brain machine interface', 'brain research', 'clinical care', 'decision research', 'design', 'evidence base', 'health disparity', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative neurotechnologies', 'insight', 'member', 'neuroethics', 'neuropsychiatry', 'neuroregulation', 'new technology', 'novel', 'optogenetics', 'prevent', 'programs', 'screening', 'sound', 'standard measure', 'tool', 'vaccine development', 'volunteer']",NIMH,STANFORD UNIVERSITY,R01,2017,223908,0.008688715667479703
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9324260,R01EB022574,"['Address', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Evaluation', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modality', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'base', 'connectome', 'cost', 'data acquisition', 'density', 'functional outcomes', 'genome-wide', 'genomic data', 'high dimensionality', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'multimodality', 'neuroimaging', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'software systems', 'tool', 'tractography', 'trait', 'white matter', 'whole genome']",NIBIB,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2017,101908,-0.009243170508472029
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future.   Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,9413774,R24MH114788,"['Algorithms', 'Archives', 'Atlases', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Ecosystem', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Imagery', 'Individual', 'Ingestion', 'Institution', 'Internet', 'Knowledge', 'Location', 'Machine Learning', 'Metadata', 'Modification', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data integration', 'data management', 'data modeling', 'data resource', 'data visualization', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'innovative neurotechnologies', 'member', 'neural circuit', 'next generation', 'online resource', 'operation', 'outcome forecast', 'programs', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2017,1247018,-0.006974724267743304
"The Blackfynn Platform for Rapid Data Integration and Collaboration Summary One in seven people worldwide suffers from a brain disorder, e.g., epilepsy, Parkinson's, stroke, or dementia. Development of future treatments depends on improving our understanding of brain function and disease, and validating new treatments critically depends on identifying the underlying biomarkers associated with different conditions. Biomarker discovery requires volume, quality, richness, and diversity of data. This Direct-to-Phase II project extends Blackfynn's cloud data management platform for team science, in order to support interactive data curation and integration and to facilitate biomarker discovery. Our first technical aim develops tools to help select, curate, assess, and regularize datasets: we develop novel “live” query capabilities to ensure users discover relevant data, develop mechanisms for using data's provenance to decide on trustworthiness, and build tools for mapping fields to common data elements. These capabilities address the critical, under-served problem of selecting the data to analyze. Our second technical aim develops techniques for incorporating algorithms to link and co-register across multi-modal data and metadata. Using ranking and machine learning, we can incorporate and combine state-of-the-art algorithms for finding data relationships, and we can link to remote data sources. These capabilities enable scientists to analyze richer datasets with multiple data modalities and properties – thus enabling them to discover more complex correlations and biomarkers. In our third aim, Blackfynn's new technical capabilities will be applied to challenges faced by Blackfynn partners, including problems assessing trustworthiness of data annotations, conducting image analysis, modeling epileptic networks, and identifying biomarkers for neuro-oncology indications. As part of this validation we will also develop HIPAA-compliant mechanisms for working with protected and de-identified data together. Together, these three thrusts will ensure that development of the Blackfynn platform results in tools and technologies that meaningfully accelerate scientific understanding and discovery over rich and complex data, leading to improved treatments for neurologic disease.   Narrative This Direct-to-Phase II project extends the Blackfynn cloud data management platform to enable biomarker discovery for research and development of improved drugs, devices and clinical care for patients with neurologic disease: it develops tools for assembling, evaluating, and rating data, and linking it across modalities and to external systems. It also validates the techniques' effectiveness using real challenges faced by Blackfynn partners, in imaging, epilepsy, and brain tumor research.",The Blackfynn Platform for Rapid Data Integration and Collaboration,9343385,R44DA044929,"['Address', 'Algorithms', 'Benchmarking', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain Neoplasms', 'Case Study', 'Clinical Pharmacology', 'Collaborations', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Provenance', 'Data Science', 'Data Set', 'Data Sources', 'Dementia', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Ensure', 'Epilepsy', 'Funding', 'Future', 'Health', 'Health Insurance Portability and Accountability Act', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mental Depression', 'Metadata', 'Modality', 'Modeling', 'National Institute of Neurological Disorders and Stroke', 'Neurosciences', 'Neurosciences Research', 'Notification', 'Ontology', 'Output', 'Parkinson Disease', 'Patient Care', 'Pharmaceutical Preparations', 'Phase', 'Plug-in', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Science', 'Scientist', 'Semantics', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Standardization', 'Stroke', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Trust', 'Use Effectiveness', 'Validation', 'Work', 'base', 'biomarker discovery', 'clinical application', 'clinical care', 'cloud platform', 'computer science', 'data access', 'data integration', 'data management', 'improved', 'indexing', 'nervous system disorder', 'neuro-oncology', 'neuroimaging', 'novel', 'novel therapeutics', 'open source', 'research and development', 'tool']",NIDA,"BLACKFYNN, INC.",R44,2017,652921,-0.0014948278311021704
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability. PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.",Capti Screen Reading Assistant for Goal Directed Web Browsing,9199231,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2017,500000,0.010992540119764294
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9310000,K01ES025442,"['Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Competence', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Variant', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'exhaustion', 'experience', 'experimental study', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2017,144298,0.008519383750219387
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,56360,-0.013180015535181843
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,454865,-0.013180015535181843
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9354497,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2017,739402,0.005905148660259709
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9313495,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Home environment', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Recruitment Activity', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'responsible research conduct', 'scale up', 'sensor', 'skills', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2017,186245,0.00638527787440669
"Understanding Action Selection in the Tool Use Network Project Summary: Skilled use of tools is a defining achievement of human cognition, and is enabled by the storage of tool-specific action memories. Many tools are associated with more than one action, and most everyday tasks are associated with more than one tool. Limb apraxia is a common, disabling, and puzzling left-hemisphere disorder characterized by prominent deficits in activating and selecting task-appropriate tool actions. Little is known about the cognitive mechanisms and brain regions enabling such selection in the neurologically intact brain, or how these processes go awry in apraxia. In several other cognitive domains, it has been suggested that appropriate response selection occurs via biased competition—that is, the prioritization of competing incoming information to enable appropriate response selection. Capitalizing on the promise of such frameworks, we have developed a new functional-neuroanatomic model of biased competition in a specific left hemisphere Tool Use network. Called “Two Action Systems Plus” (2AS+), the model generates testable hypotheses about the major principles determining tool action selection, and their deficiencies in apraxia. Specifically, we hypothesize that 1) Competition between tool actions is influenced by the graded similarity of tool action representations, as implemented primarily by the left posterior temporal cortex (pTC), 2) The outcome of the competitive process is affected by the strength and timing of activation of tool action representations, and depends on the dynamic interplay of left pTC and the parietal lobes, 3) Outcome is further influenced by a mechanism that biases competition towards the tool action that is appropriate to goals and context, as implemented by the left inferior frontal gyrus (IFG) and its connections with the supramarginal gyrus (SMG), and 4) There are two subtypes of apraxia characterized by distinct failures in the competitive selection process: an anterior subtype characterized by inability to appropriately resolve tool action competition, and a posterior subtype reflecting weakened competition. These hypotheses will be tested using a number of complementary methods with healthy and brain-lesioned participants, including voxel-based lesion symptom mapping, resting functional connectivity, fMRI with multi-voxel pattern analyses, and eyetracking. By specifying when and how visuomotor information plays a role in tool representations, the proposed experiments promise to critically constrain “embodied” cognition theories claiming that tools automatically evoke their actions. The proposed research will also advance the theoretical understanding of tool action by anchoring relevant constructs in a cognitive-neuroanatomic model, clarify how action representations are organized and activated, and improve our understanding of the mechanisms affecting errors and re-learning in apraxia, with implications for rehabilitation. Project Narrative: Apraxia, a disorder of tool use, is a common and substantially disabling consequence of left hemisphere stroke, yet is relatively rarely studied and hence poorly understood. The proposed work will clarify the brain regions that are associated with the disorder, the task factors that may improve tool use abilities, and the ability of the damaged Tool Use system to learn after stroke. This information will serve as an important building block in the development of treatment strategies.",Understanding Action Selection in the Tool Use Network,9336000,R01NS099061,"['Achievement', 'Adopted', 'Affect', 'Anterior', 'Apraxias', 'Behavior', 'Brain', 'Brain region', 'Cheese', 'Cognition', 'Cognitive', 'Color', 'Disease', 'Failure', 'Functional Magnetic Resonance Imaging', 'Gestures', 'Goals', 'Grant', 'Hand', 'Human', 'Income', 'Individual', 'Inferior frontal gyrus', 'Learning', 'Left', 'Lesion', 'Limb structure', 'Location', 'Machine Learning', 'Mediating', 'Memory', 'Methods', 'Modeling', 'Nature', 'Neurologic', 'Outcome', 'Parietal Lobe', 'Participant', 'Patients', 'Pattern', 'Play', 'Posture', 'Process', 'Production', 'Rehabilitation therapy', 'Research', 'Rest', 'Role', 'Source', 'Specific qualifier value', 'Stroke', 'Structure', 'Structure of supramarginal gyrus', 'Symptoms', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Work', 'base', 'clinically relevant', 'experience', 'experimental study', 'improved', 'novel', 'response', 'theories', 'therapy development', 'tool', 'treatment strategy', 'visual motor']",NINDS,ALBERT EINSTEIN HEALTHCARE NETWORK,R01,2017,418122,-0.0293712771031163
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9268713,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Data Sources', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2017,655080,0.008281842725388061
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9407137,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Persons', 'Phase', 'Phonation', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2017,159267,0.010009625551927576
"Large-Scale Semiparametric Graphical Models with Applications to Neuroscience DESCRIPTION: The objective of this proposal is to develop and theoretically evaluate a unified set of statistical, computational, and software tools to address data mining and discovery science challenges in the analysis of existing vast amounts of publicly available neuroimaging data. In particular, we propose to develop scalable and robust semiparametric solutions for high-throughput estimation of resting-state brain connectivity networks, both at the individual and population levels, with the flexibility of incorporating covariate information.  The work will contribute meaningfully to the theory and methods for large-scale semiparametric graphical models and will apply these methods to the largest collections of resting-state fMRI data available. The proposed methods and theory include key directions of research for brain network estimation and mining. First, we pro- pose novel methods for subject-specific network estimation, such as would be needed for biomarker development in functional brain imaging. Secondly, we define and propose to evaluate and implement methods for studying population-level graphs, which study collections of graphs. Thirdly, we propose the use of estimated graphs in predictive modeling. Finally, all of these methods will have complementary software and web services development. Most notably, the idea of population graphs allows for the creation of functional brain network atlases.  In summary, the work of this proposal will result in a unified framework for the analysis of modern neuroimaging data via graphical models. Our methods will further be agnostic to intricacies of the technology, thus making it portable across settings and applicable outside of the field of functional brain imaging. The methods will be carefully evaluated via theory, simulation and data-based application evidence. PUBLIC HEALTH RELEVANCE: Modern neuroimaging data are often Big, Complex, Noisy and Dependent. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of network estimation and mining based on neuroimaging data. Our proposed work represents a significant step forward over the current methodology and has the potential to be applied to analyze a wide range of scientific problems beyond brain imaging data analysis.",Large-Scale Semiparametric Graphical Models with Applications to Neuroscience,9208798,R01MH102339,"['Address', 'Algorithmic Software', 'Algorithms', 'Atlases', 'Attention deficit hyperactivity disorder', 'Big Data', 'Brain', 'Brain Diseases', 'Brain imaging', 'Characteristics', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Discovery', 'Data Set', 'Databases', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Documentation', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Graph', 'Heterogeneity', 'Image', 'Individual', 'Internet', 'Machine Learning', 'Mathematics', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Neurosciences', 'Online Systems', 'Pattern', 'Population', 'Population Study', 'Rest', 'Sampling', 'Science', 'Signal Transduction', 'Site', 'Software Tools', 'Statistical Methods', 'Tail', 'Technology', 'Work', 'base', 'biomarker development', 'brain research', 'cloud based', 'computerized tools', 'data mining', 'flexibility', 'high dimensionality', 'interest', 'neuroimaging', 'non-Gaussian model', 'novel', 'portability', 'predictive modeling', 'psychologic', 'public health relevance', 'semiparametric', 'simulation', 'theories', 'user friendly software', 'web services']",NIMH,PRINCETON UNIVERSITY,R01,2017,109672,0.019681878015180905
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers. PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9330810,UH2CA203710,"['Algorithms', 'Artificial Intelligence', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Classification', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Image Analysis', 'Institutes', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Nonprofit Organizations', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Specificity', 'Statistical Models', 'Students', 'Technology', 'Territoriality', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'fine art', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'virtual', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2017,320900,-0.013117402326724896
"Structural Development of Human Fetal Brain Abstract Despite its critical significance, little is known about the most dynamic phase of brain development in infancy: 0-2 years. To change the status quo, comprehensive and quantitative infant brain atlases as reference standards for precision health are needed. In addition, diffusion MRI (dMRI) has entered a new era in which dynamic cortical internal microstructural complexity, indexed by e.g. cortical mean kurtosis derived from diffusion kurtosis imaging (DKI), can be studied in the living infant brain noninvasively using more advanced multi-shell dMRI. Furthermore, multi-modality measures offer unparalleled insights into mechanistic structure- function and structure-behavior relationships. Work in the current cycle has focused on structural development of human fetal and preterm brains. Based on high resolution diffusion tensor imaging (DTI) of 150 brains, we have established the atlases and quantified cortical microstructure with cortical fractional anisotropy, validated by histological images and correlated with transcriptomic (RNA) expression. Building upon this work, in the next cycle, we will focus on brain development in infancy, immediately after the fetal period. Specifically, the goal is to establish next-generation dMRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural mean kurtosis measurement by delineating its 4D spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). 160 typically developing infants at 1, 3, 6, 12, 18, 24 months will be recruited. Advanced “connectome-quality” multi-band high-resolution multi-shell dMRI, resting state fMRI (rs-fMRI) and structural MRI will be acquired. High-quality whole-head magnetoencephalography (MEG) will also be acquired. Anatomical labels of all 122 major gray and white matter structures will be built up based on high contrasts from DTI-derived maps. The measurements of DTI-derived metrics will be used for the quantitative components of DTI atlases and age-dependent white matter tract trajectories (Aim 1). Mean kurtosis of the 4th order kurtosis tensor has been shown to be sensitive to cortical internal microstructural changes of infant brains. The spatiotemporal sensitivity of mean kurtosis measures to infant age and cortical region will be investigated (Aim 2). Furthermore, we will establish mechanistic structure-function relationships with multi- modality imaging, including not only multi-shell dMRI, but also rs-fMRI and MEG, all optimized for infant brains (Aim 3). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants (e.g. Z-score maps). Infant cortical microstructure will be delineated noninvasively with 4D spatiotemporal frameworks. With multi-modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general. Narrative Title: Structural development of human fetal brain The goal is to establish next-generation diffusion MRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural measurement by delineating its four-dimensional spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants. With multi- modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general.",Structural Development of Human Fetal Brain,9357665,R01MH092535,"['2 year old', 'Age', 'Anatomy', 'Anisotropy', 'Architecture', 'Area', 'Atlases', 'Auditory', 'Behavior', 'Behavior assessment', 'Behavioral', 'Brain', 'Cerebral cortex', 'Characteristics', 'Clinical Research', 'Collaborations', 'Development', 'Developmental Process', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Fetal Development', 'Fingerprint', 'Four-dimensional', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Health', 'Human', 'Image', 'Infant', 'Infant Development', 'Infant Health', 'Intellectual functioning disability', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Measurement', 'Measures', 'Modality', 'Motor', 'Multimodal Imaging', 'Neurodevelopmental Disorder', 'Phase', 'RNA', 'Recruitment Activity', 'Reference Standards', 'Research Personnel', 'Resolution', 'Rest', 'Risk Assessment', 'Sensorimotor functions', 'Sensory', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Time', 'Visual', 'Work', 'age related', 'artemis', 'autism spectrum disorder', 'base', 'connectome', 'fetal', 'gray matter', 'histological image', 'indexing', 'infancy', 'insight', 'neuroimaging', 'neuronal circuitry', 'next generation', 'novel', 'prisma', 'relating to nervous system', 'somatosensory', 'spatiotemporal', 'transcriptomics', 'white matter']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2017,630526,-0.01494053033534082
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9238777,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2017,416574,0.020417505613266385
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9322204,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'spatial temporal variation', 'standard of care', 'statistics', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2017,148964,-0.0065444769720501795
"Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction DESCRIPTION (provided by applicant): In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function. Although fMRI research has primarily focused on identifying brain regions that are activated during performance of cognitive tasks, there is growing interest in examining how cognitive functions emerge as a result of context-dependent, dynamic causal interactions between distributed brain regions. Devising and validating methods for investigating such interactions has therefore taken on great significance. The first major goal of this proposal is to address a critical need in fMRI research by developing novel algorithms for identifying context-dependent dynamic causal interactions between distributed brain regions. To this end, we will develop and validate novel computational methods using Multivariate Dynamical Systems based Markov chain Monte Carlo (MDS-MCMC) algorithms that overcome major limitations of existing methods for investigating dynamic causal interactions and connectivity in the human brain. A comprehensive validation framework will be use evaluate MDS-MCMC and compare it with existing dynamic causal estimation methods. The second major goal of this proposal is to use the MDS-MCMC framework to investigate dynamic causal interactions underlying cognition in normal healthy adults, and in patients with Parkinson's disease (PD). Cognitive impairment is one of the most devastating symptoms in PD. Once thought of as an insignificant feature of the disease, it is now clear that cognitive impairment is present in the majority of PD patients and that this impairment is significantly linked to increased disability and the risk of mortality, yetlittle is known about the brain basis of cognitive impairment in PD. The computational algorithms we develop, validate, and apply here will allow us to rigorously investigate brain dynamics support critical cognitive processes in the human brain, leading to a more complete understanding of fundamental mechanisms underlying human brain function and dysfunction. Our proposed studies will also, for the first time, examine casual interactions in simulated, open-source, opto-genetic, experimental and clinical brain imaging data using state-of-the-art sub-second high-temporal resolution fMRI, based on the Human Connectome Project (HCP). Critically, we will maintain a tight link between our computational and systems neuroscience goals algorithms to solve important problems in cognitive, systems and clinical neuroscience. Together, our proposed studies will lead to new and improved computational tools for examining dynamical causal interactions between distributed brain regions, with broad applications to the HCP and clinical neuroscience. The proposed studies are highly relevant to the mission of the NIH Innovations in Biomedical Computational Science and Technology and the Big Data to Knowledge Programs, which seek to encourage development and dissemination of innovative advanced computational tools for brain imaging and neuroscience. We will disseminate our algorithms and software to the research community via NITRC . PUBLIC HEALTH RELEVANCE: In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function and dysfunction. Although fMRI studies of brain function have primarily focused on identifying brain regions that are activated during performance of perceptual or cognitive tasks, there is growing consensus that cognitive functions emerge as a result of dynamic context-dependent interactions between multiple brain areas. Developing new computational methods for investigating causal interactions in fMRI data has therefore taken added significance; the overall goal of this proposal is to address this critical need by developing new methods for studying causal interactions and brain connectivity between distributed brain regions during cognition.",Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction,9301657,R01NS086085,"['Address', 'Adult', 'Algorithmic Software', 'Algorithms', 'Area', 'Basal Ganglia', 'Benchmarking', 'Big Data to Knowledge', 'Biomedical Computing', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive deficits', 'Communities', 'Computational Science', 'Computational algorithm', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Development', 'Disease', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Genetic', 'Goals', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual Differences', 'Link', 'Machine Learning', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Neurosciences', 'Parietal', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Play', 'Prefrontal Cortex', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Resource Sharing', 'Risk', 'Role', 'Short-Term Memory', 'Software Tools', 'Symptoms', 'System', 'Task Performances', 'Technology', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'brain dysfunction', 'cognitive function', 'cognitive load', 'cognitive performance', 'cognitive process', 'cognitive system', 'cognitive task', 'computerized tools', 'connectome', 'disability', 'dynamic system', 'imaging study', 'improved', 'in vivo', 'innovation', 'interest', 'mortality', 'neurophysiology', 'novel', 'open data', 'open source', 'optogenetics', 'programs', 'public health relevance', 'simulation', 'temporal measurement', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2017,554411,-0.0013386738887771865
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,9310382,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Crystallization', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Genetic', 'Genetic Structures', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Imaging Device', 'Internships', 'Investigation', 'K-12 student', 'Knowledge', 'Link', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Mosaicism', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Statistical Data Interpretation', 'Statistical Models', 'Structure', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'experimental study', 'feeding', 'fluorescence imaging', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'neuroinformatics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'role model', 'simulation', 'spatiotemporal', 'synergism', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2017,323033,-0.003945026604728852
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9409171,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Biological Preservation', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Scanning', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2017,749900,-0.01977955733702091
"EEGLAB: Software for Analysis of Human Brain Dynamics DESCRIPTION (provided by applicant): A major shift in scientific perspective on the nature and use of electrophysiological brain data is now ongoing a shift from measurement and visualization of individual channel signals (in the 'recording channel space') to visualizing and interpreting the data directly within a suitable inverse model representing activity reaching the electrodes by volume conduction from a set of effective data sources in native 'brain source space'. An equivalent shift, via the development and exploitation of an appropriate inverse imaging model, made possible the phenomenon of structural and functional magnetic resonance imaging (fMRI). While the electrophysiological inverse problem is still difficult, dramatic progress has been and is being made through combined use of multimodal imaging and modern statistical signal processing methods. Recovering the considerable degree of spatial source resolution available in high-density scalp electroencephalographic (EEG) and other electrophysiological data, while retaining its natural advantage over other functional imaging methods in temporal resolution, has begun to yield a steady stream of new information about patterns of distributed brain processing supporting human behavior and experience. Relative to other brain imaging modalities, EEG has substantial and increasing cost and mobility advantages, making promotion of new EEG methods for source space analysis of increasing interest and importance for brain and health research. However, applying new source signal and signal processing models to electrophysiological data is complex and increasingly involves application of modern mathematical methods whose details are not within the training of most health research professionals. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University of California San Diego, began as a set of EEG data analysis running on MATLAB (The Mathworks, Inc.) released on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now, more than ten years later, the EEGLAB reference paper (Delorme & Makeig, 2004) has over 2,350 Google scholar citations (increasing at above 1 per day), the opt-in EEGLAB discussion email list links over 5,000 researchers, the news list over 9,000, and a recent survey of 687 researcher respondents reports EEGLAB to be the software environment most widely used for electrophysiological data analysis worldwide. EEGLAB is thus now a de facto standard supporting a wide range of EEG and other electrophysiological research studies and teaching labs. At least 35 EEGLAB plug-in toolsets have now been released by researchers from many laboratories. Under NIH PAR 11-028 we propose renewal funding to further develop and maintain the EEGLAB software framework. We propose new and better tools for brain source and source network modeling and localization, an expanded online EEGLAB course and workshop, better statistical inference modeling of group data, and new support for automated source decomposition, measure computation, data duration, and data sharing. PUBLIC HEALTH RELEVANCE: A major shift in scientific perspective on the nature and use of human electrophysiological data is now accelerating from measuring and visualizing individual scalp channel signals to directly visualizing and interpreting their brain sources. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University Of California San Diego (UCSD), supports a large number of EEG and related electrophysiological research studies and teaching labs. We propose continued funding to further develop and maintain the EEGLAB environment.",EEGLAB: Software for Analysis of Human Brain Dynamics,9310366,R01NS047293,"['Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Clinical', 'Cloud Computing', 'Code', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Educational process of instructing', 'Educational workshop', 'Electrodes', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Electroplating', 'Environment', 'Event', 'Event-Related Potentials', 'Eye', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Health', 'Human', 'Image', 'Imagery', 'Individual', 'Internet', 'Joints', 'Laboratories', 'Links List', 'Machine Learning', 'Measurement', 'Measures', 'Memory', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Multimodal Imaging', 'Nature', 'Neurosciences', 'Output', 'Paper', 'Pattern', 'Performance', 'Physiology', 'Plug-in', 'Privatization', 'Procedures', 'Psyche structure', 'Reporting', 'Research', 'Research Activity', 'Research Methodology', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Scalp structure', 'Signal Transduction', 'Software Framework', 'Source', 'Speed', 'Stream', 'Surveys', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'brain health', 'computational neuroscience', 'computing resources', 'cost', 'cranium', 'data sharing', 'density', 'design', 'experience', 'experimental study', 'flexibility', 'imaging modality', 'improved', 'innovation', 'interest', 'learning strategy', 'mathematical methods', 'network models', 'news', 'online course', 'open source', 'public health relevance', 'research study', 'signal processing', 'source localization', 'symposium', 'temporal measurement', 'tool', 'web site', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2017,475233,0.023171171580739405
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9303234,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2017,249000,-0.004738745155597785
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community—the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit’s gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing. Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9474743,R44AG053890,"['Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Custom', 'Dependence', 'Devices', 'Electrical Engineering', 'Emotional', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Impairment', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Vision', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'rehabilitation technology', 'robot exoskeleton', 'usability']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2017,562410,-0.00036747285371204857
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9292314,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2017,364423,0.022487725832217868
"Neuronal Network Analysis Tools for Large Calcium Imaging Datasets No abstract available Project Narrative Recently, we have shown that we can image 100s to 1000s of neurons concurrently in awake, behaving animals using wide-field calcium imaging. The goal of this research proposal is to develop scalable, robust analysis methods to analyze neuronal networks and sub-networks of this size and scale. These analysis methods will have the potential to connect our understanding of network function at the cellular level with network function at the whole-brain level.",Neuronal Network Analysis Tools for Large Calcium Imaging Datasets,9470517,F31NS105420,"['Address', 'Animals', 'Area', 'Back', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Brain region', 'Calcium', 'Calcium Spikes', 'Cells', 'Chemicals', 'Classification', 'Classification Scheme', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Detection', 'Foundations', 'Genetic', 'Genetic Markers', 'Goals', 'Hippocampus (Brain)', 'Image', 'Individual', 'Interneurons', 'Label', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Memory', 'Methods', 'Monitor', 'Mus', 'Neurons', 'Neurosciences', 'Parvalbumins', 'Pathway Analysis', 'Process', 'Reporting', 'Research Personnel', 'Research Proposals', 'Resolution', 'Rest', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Transgenic Mice', 'Work', 'awake', 'cell type', 'conditioning', 'experimental study', 'imaging modality', 'insight', 'interest', 'mouse model', 'network models', 'novel', 'response', 'tool']",NINDS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),F31,2017,30011,-0.013193869738721116
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9414126,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissue imaging', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2017,395542,0.007856104299823473
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9251284,R01EY017835,"['Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Industrialization', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2017,580671,0.023481348593965695
"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, involving a complicated interplay between functional information interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. func- tional and structural measures. However the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities is to miss a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimensional problem, requiring appropriate data reduction strategies. In the previous phase of the project we developed approaches based on multiset canonical correlation analysis (mCCA) and joint independent compo- nent analysis (jICA) that can capture high-dimensional, linear, relationships among 2 or more modalities, and which we showed can identify both modality-unique and modality-common features that are predictive of dis- ease. In this new phase of the project we will focus on two important areas. First, we will build on our previous success by extending our models to allow for incorporation of behavioral/cognitive constraints as well as devel- oping new approaches which leverage recent advances in deep learning enabling us to capture higher order relationships embedded in multimodal and multitask data. Secondly, we will address the key challenge of inte- grating possibly thousands of multimodal features by developing a new meta-modality framework which will enable us to bring together the existing and new features in an intuitive manner. This will also enable us to capture changes in multimodal information which might not be harmful separately but which together are jointly sufficient to convey risk of illness or to identify information flow through the meta-modal space for developing potential targets for treatment. We will apply these approaches to one of the largest multimodal imaging datasets of psychosis and mood disorders. Our proposed approach will be thoroughly evaluated using this large data set which includes multiple illnesses that have overlapping symptoms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar de- pression). As before, we will provide open source tools and release data throughout the duration of the project via a web portal and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 36 Project Narrative  The promise of multimodal imaging is clear, and we have shown the power of linear joint N-way analysis during the previous funding period. However this is just the beginning. In this renewal, we will build on and significantly expand the goals of the original aims by incorporating additional joint information (including dynamic and potentially nonlinear factors) as well as a framework for integrating the resulting information in order to enable decision making and identification of potential targets for further study or possible treatment. We will also disseminate our approaches through software tools and interactive web-based visualization of available data. 37",Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,9562203,R01EB006841,"['Address', 'Algorithms', 'Area', 'Behavioral', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Bipolar Disorder', 'Blood flow', 'Brain', 'Brain Diseases', 'Brain imaging', 'Classification', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Imaging technology', 'Intuition', 'Joints', 'Learning', 'Link', 'Measurable', 'Measures', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Multimodal Imaging', 'Neurobiology', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Psychotic Disorders', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Sample Size', 'Sampling', 'Schizophrenia', 'Series', 'Software Tools', 'Symptoms', 'Tars', 'Testing', 'Time', 'Training', 'Unipolar Depression', 'Validation', 'Visualization software', 'Work', 'base', 'clinical care', 'clinical phenotype', 'data reduction', 'data sharing', 'deep field survey', 'design', 'gray matter', 'high dimensionality', 'imaging biomarker', 'imaging modality', 'improved', 'independent component analysis', 'multimodality', 'multitask', 'neuroinformatics', 'neuropsychiatric disorder', 'next generation', 'novel', 'novel strategies', 'open source', 'potential biomarker', 'repository', 'simulation', 'success', 'tool', 'translational impact', 'web portal', 'white matter']",NIBIB,THE MIND RESEARCH NETWORK,R01,2017,162344,0.004804913221147833
"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, involving a complicated interplay between functional information interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. func- tional and structural measures. However the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities is to miss a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimensional problem, requiring appropriate data reduction strategies. In the previous phase of the project we developed approaches based on multiset canonical correlation analysis (mCCA) and joint independent compo- nent analysis (jICA) that can capture high-dimensional, linear, relationships among 2 or more modalities, and which we showed can identify both modality-unique and modality-common features that are predictive of dis- ease. In this new phase of the project we will focus on two important areas. First, we will build on our previous success by extending our models to allow for incorporation of behavioral/cognitive constraints as well as devel- oping new approaches which leverage recent advances in deep learning enabling us to capture higher order relationships embedded in multimodal and multitask data. Secondly, we will address the key challenge of inte- grating possibly thousands of multimodal features by developing a new meta-modality framework which will enable us to bring together the existing and new features in an intuitive manner. This will also enable us to capture changes in multimodal information which might not be harmful separately but which together are jointly sufficient to convey risk of illness or to identify information flow through the meta-modal space for developing potential targets for treatment. We will apply these approaches to one of the largest multimodal imaging datasets of psychosis and mood disorders. Our proposed approach will be thoroughly evaluated using this large data set which includes multiple illnesses that have overlapping symptoms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar de- pression). As before, we will provide open source tools and release data throughout the duration of the project via a web portal and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 36 Project Narrative  The promise of multimodal imaging is clear, and we have shown the power of linear joint N-way analysis during the previous funding period. However this is just the beginning. In this renewal, we will build on and significantly expand the goals of the original aims by incorporating additional joint information (including dynamic and potentially nonlinear factors) as well as a framework for integrating the resulting information in order to enable decision making and identification of potential targets for further study or possible treatment. We will also disseminate our approaches through software tools and interactive web-based visualization of available data. 37",Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,9332389,R01EB006841,"['Address', 'Algorithms', 'Area', 'Behavioral', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Bipolar Disorder', 'Blood flow', 'Brain', 'Brain Diseases', 'Brain imaging', 'Classification', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Imaging technology', 'Intuition', 'Joints', 'Learning', 'Link', 'Measurable', 'Measures', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Multimodal Imaging', 'Neurobiology', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Psychotic Disorders', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Sample Size', 'Sampling', 'Schizophrenia', 'Series', 'Software Tools', 'Symptoms', 'Tars', 'Testing', 'Time', 'Training', 'Unipolar Depression', 'Validation', 'Visualization software', 'Work', 'base', 'clinical care', 'clinical phenotype', 'data reduction', 'data sharing', 'deep field survey', 'design', 'gray matter', 'high dimensionality', 'imaging biomarker', 'imaging modality', 'improved', 'independent component analysis', 'multimodality', 'multitask', 'neuroinformatics', 'neuropsychiatric disorder', 'next generation', 'novel', 'novel strategies', 'open source', 'potential biomarker', 'repository', 'simulation', 'success', 'tool', 'translational impact', 'web portal', 'white matter']",NIBIB,THE MIND RESEARCH NETWORK,R01,2017,400000,0.004804913221147833
"Enabling Shared Analysis and Processing of Large Neurophysiology Data Project Summary / Abstract Understanding brain function is key to improving health care and advancing a number of scientific initiatives. The treatment of degenerative brain diseases such as Alzheimer's, Parkinson’s, and ALS is becoming increasingly important as the current US population ages and life expectancies increase. The costs of Alzheimer's and other dementias is estimated at over $200 billion in 2016 alone, not to mention the human devastation that these diseases incur. Autism, addiction, depression, epilepsy, traumatic brain injury, and pain treatment are just a few more of the critically important health concerns related to brain function. Cognitive science is also at the forefront of research into computational and autonomous systems, with the potential to revolutionize human computer interaction and tackle emerging global challenges. As a result of these and other significant opportunities the BRAIN (Brain Research through Advancing Innovative Neurotechnologies) Presidential initiative was created to improve the future health and competitiveness of the nation, with the fundamental goal of accelerating brain research. Consistent with this goal, the brain research community has developed the Neurodata Without Borders: Neurophysiology (NWB) file format and specification to support large-scale collaboration and research. This open format was created in 2014 and is already making an impact on cellular-based neurophysiology, with organizations such as the Allen Institute for Brain Science generating and sharing datasets such as the Allen Brain Observatory and the Allen Cell Types Database. Although this preliminary work is promising, progress in the research community is slowed by a lack of software tools to readily browse, process, analyse, and visualize NWB data, while promoting replicability. Thus this work aims to to produce such tools in support of the BRAIN initiative and other large-scale brain research programs by supporting and growing the NWB community. The work proposed here addresses three important workflows in cellular-based neurophysiology: o​ ptical physiology to image neurons under stimuli, silicon probe recordings to detect spike events from the surface of the cortex down through deeps​ structures, and​ in vitro slice electrophysiology to record t​ ime-varying stimulus and electrical response from a neuron​. Novel multiscale software tools will be created to enable efficient browsing, processing, analysis, and visualization of NWB-based brain data; linking experimental stimuli to observed responses. Conversion utilities will also be developed to convert existing data into NWB form. As the data is large, complex, and may be distributed across many sites, the software tools will be web-based, enabling researchers to remotely access and process data in a reproducible manner, and to use scalable cloud computing resources. The software will be released under open source licences and will be placed under formal software process to facilitate sharing across the research community. The tools will be conceived and created with the help of Allen scientists, who will also perform final validation using these three workflows. Project Narrative This research is aimed at better understanding brain function. Such knowledge may lead to improved therapies for degenerative brain diseases such as Alzheimer's, Parkinson’s, and ALS; and provide new treatments for autism, addiction, depression, epilepsy, traumatic brain injury, and pain treatment. These studies of brain science may also yield significant insights into computing areas such as robotics and computer vision, thereby providing both healthcare and economic benefits.",Enabling Shared Analysis and Processing of Large Neurophysiology Data,9409114,R44MH115731,"['Address', 'Adopted', 'Adoption', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Autistic Disorder', 'Base of the Brain', 'Behavior', 'Brain', 'Brain Diseases', 'Case Study', 'Cloud Computing', 'Cognition', 'Cognitive Science', 'Collaborations', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Epilepsy', 'Event', 'Foundations', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'Image', 'Imagery', 'In Vitro', 'Individual', 'Institutes', 'Knowledge', 'Laboratories', 'Lead', 'Licensing', 'Life Expectancy', 'Link', 'Mental Depression', 'Metadata', 'Methods', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Optics', 'Pain management', 'Parkinson Disease', 'Periodicity', 'Phase', 'Physiology', 'Pilot Projects', 'Population', 'Process', 'Pythons', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Robotics', 'Science', 'Scientist', 'Services', 'Silicon', 'Site', 'Slice', 'Software Tools', 'Standardization', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Traumatic Brain Injury', 'Validation', 'Visual', 'Visualization software', 'Work', 'addiction', 'analytical tool', 'base', 'brain research', 'cell type', 'community based participatory research', 'computer human interaction', 'computing resources', 'cost', 'data exchange', 'data format', 'data modeling', 'data sharing', 'design', 'distributed data', 'experimental study', 'falls', 'file format', 'hackathon', 'health care economics', 'improved', 'innovation', 'innovative neurotechnologies', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'open source', 'prevent', 'programs', 'relating to nervous system', 'research and development', 'response', 'success', 'terabyte', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R44,2017,747542,0.002032848799330802
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9021663,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'exercise program', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2016,59383,-0.008587363491563908
"Training a new generation of computational neuroscientists bridging neurobiology The  Training  Program  in  Computational  Neuroscience  (TPCN)  will  support  integrated   undergraduate  and graduate training in computational neuroscience at New York University. The program will be hosted  by the Center for Neural Science (CNS), with participation of faculty in the Departments of  Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of  Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is  one of a few universities with a critical mass of computational neuroscientists. NYU has had a  Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has  hired three computational neuroscientists. (2) CNS  established an undergraduate major in  neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now  has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and  the School of Medicine has greatly expanded our teaching and research capabilities in the  neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As  NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS   and  the  School  of  Medicine),  this training grant will ensure that computational modeling,  which has become indispensible in neuroscience, will be front-and-center in the integrated graduate  program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to  Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with  these connections will give our students ample opportunities to acquire machine learning techniques  for data analysis and learn about brain-like AI algorithms. The proposed  training  program will support coherent undergraduate  and  graduate  training  in   computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship  methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human  factors in academic practice; (c) there will be post-mortems after seminars by outside speakers.  (2) Computational psychiatry: We propose new courses and research opportunities that are designed  specifically to link cognitive function and the neurobiology of neural circuits. We propose  innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit  modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees  for jobs not only in academia, but  also  in  medical  and  industry research. To achieve this, we  will utilize our strength in machine learning and data science to broaden computational  neuroscience training. The Program Directors have complementary strengths and will have  complementary roles in the program. Wang will supervise graduate trainees and focus on training in  mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry.  Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9316750,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Mathematics', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'computational neuroscience', 'computer science', 'design', 'innovation', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education']",NIDA,NEW YORK UNIVERSITY,R90,2016,204981,0.008280483434358322
"Pattern Analysis of fMRI via machine learning/sparse models: application to brain development Abstract Resting state fMRI (rsfMRI) provides reproducible, task-independent biomarkers of coherent functional activity linking different brain regions. The main goal of the proposed project is to leverage advances in signal processing and machine learning methods to derive clinically useful biomarkers based on patterns of functional connectivity, and to test these biomarkers in a large study of brain development. Central to our methodology are 1) computing a subject-specific functional parcellation of the brain, which defines nodes for characterizing individualized functional brain networks; 2) extracting sparse connectivity patterns for robustly representing brain networks; 3) capturing heterogeneity in brain networks across individuals in a given population; and 4) deriving individualized predictive indices of psychosis risk from brain connectivity in a large study of brain development. This novel suite of functional connectivity analysis tools will be developed and validated based on data from the Human Connectome Project and the Philadelphia Neurodevelopmental Cohort (PNC). Finally, these techniques will be applied to PNC data in order to delineate heterogeneity in network development in youth with psychosis-spectrum symptoms. Our hypothesis is that patterns of functional connectivity in adolescents with psychosis-spectrum symptoms will be different from those in typically developing adolescents, and this difference will display a high degree of heterogeneity that is linked to underlying heterogeneity in pathologic neurodevelopmental trajectories. Moreover, we expect that machine learning techniques will allow us to predict on an individual basis which adolescents with psychosis-spectrum symptoms will remain stable, which will revert to normal, and which will progress to psychosis, based on their baseline functional connectivity signatures. Our methods are generally applicable to rsfMRI studies for detecting and quantifying spatio-temporal functional connectivity patterns in diverse fields, including diagnosing brain abnormalities in neuropsychiatric diseases, and finding associations of functional connectivity with different cognitive functions. All methods will be made publicly available and form an important new resource for the broader neuroscience community. Project narrative This proposal develops a suite of advanced functional imaging pattern analysis methods, aiming to delineate heterogeneity in brain network development in youth with psychosis-spectrum symptoms, ultimately leading to early biomarkers of neuropsychiatric disorders. Methodologically, the proposed work leverages upon the strengths of sparse and non-negative decompositions of imaging data, which offer several advantages over conventional mass-univariate and linear multivariate methods. One of the largest and most comprehensive cohorts of 1,600 individuals ages 8 through 21 provides unique imaging and clinical data to support the application of these methods to brain development.",Pattern Analysis of fMRI via machine learning/sparse models: application to brain development,9155330,R01EB022573,"['Address', 'Adolescent', 'Age', 'Algorithms', 'Anatomy', 'Biological', 'Biological Markers', 'Brain', 'Brain region', 'Classification', 'Clinical Data', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heterogeneity', 'Image', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neurosciences', 'Outcome', 'Pathologic', 'Pathway Analysis', 'Pattern', 'Pattern Recognition', 'Philadelphia', 'Population', 'Psychotic Disorders', 'Resources', 'Rest', 'Risk', 'Sampling', 'Shapes', 'Subgroup', 'Symptoms', 'Techniques', 'Testing', 'Work', 'Youth', 'abstracting', 'base', 'brain abnormalities', 'clinical biomarkers', 'cognitive function', 'cohort', 'connectome', 'follow-up', 'human data', 'improved', 'indexing', 'interest', 'learning strategy', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'signal processing', 'tool', 'trend']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2016,491014,-0.03283250925758898
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9058040,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Health', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,451650,-0.040458349424483876
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9322706,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Camping', 'Code', 'Cognition', 'Communities', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'base', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2016,316840,0.012062994319409309
"A Machine-Learning Based Software Widget for Resolving Metabolite Identities Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites covering a substantial fraction of the small molecules present in a biological sample. This presents an exciting opportunity to develop potentially transformative approaches to study cells and organisms. One major challenge in realizing this potential lies in processing and analyzing the data. A typical dataset from an untargeted experiment contains many of thousands of “features,” each of which could correspond to a unique metabolite. Analyzing such datasets to obtain meaningful biological information depends on reliably and efficiently resolving the chemical identities of the detected features. Currently, in silico fragmentation methods predict candidate metabolites that are scored and ranked based on how well the fragmentation explains the observed MS/MS spectrum, and on other factors influencing fragmentation such as bond dissociation energies and ionization conditions. Deciding which candidate metabolites is the best match for a particular feature in the context of the biological sample, however, is a daunting task. Extensive testing of candidate metabolites against chemical standards library may be prohibitive in terms of cost and efforts. We seek to develop software-enabled workflows centered on resolving metabolite identities. Our approach is to exploit knowledge of the biological context of a sample to identify the metabolites. Recognizing that the metabolites present in a sample result from enzyme-catalyzed biochemical reactions active in the corresponding biological system, we employ topological analysis and inference to best map the metabolites implied by the detected features to metabolic pathways that are feasible based on the genome(s) of cells in the biological system. Aim 1 develops a computational method based on Bayesian-inference to enhance candidate metabolite rankings that are obtained via in silico fragmentation analysis. Our method utilizes all available information (database lookups, in silico fragmentation analysis, and network/pathway context) to maximally inform and adjust the rankings. Aim 2 will build software widgets to implement the metabolite identification workflow within a data-analytics framework. As the analytics framework, we will use Orange, which allows the user to create interactive data analysis pipelines through a plug-and-play graphical user interface (GUI). Aim 3 will validate the computational method and software widget implementation. Experimental validation will utilize high-purity standards to confirm (or reject) the computationally assigned metabolite identities. Widget implementation will be evaluated through a focus group discussion with the widget users in the labs directed by the PIs. As project outcomes, we anticipate both a methodological advance in analyzing mass signature data as well as a suite of easily accessible software in the form of widgets. Metabolomics is concerned with the comprehensive characterization of the small molecule metabolites in biological systems. Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites. Prospectively, advanced computational tools and software for metabolomics data analysis can aid discovery efforts aimed at identifying novel bioactive metabolites that could be developed into diagnostic indicators or therapeutic agents. ",A Machine-Learning Based Software Widget for Resolving Metabolite Identities,9223450,R03CA211839,"['Address', 'Algorithms', 'Attention', 'Automatic Data Processing', 'Bayesian Analysis', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Cells', 'Chemicals', 'Classification', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Databases', 'Diagnostic', 'Dissociation', 'Environment', 'Enzymes', 'Feedback', 'Focus Groups', 'Genes', 'Genome', 'Goals', 'Human', 'Knowledge', 'Libraries', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Nuclear Magnetic Resonance', 'Oranges', 'Organism', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Play', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Statistical Data Interpretation', 'Statistical Models', 'Surveys', 'Testing', 'Therapeutic Agents', 'Time', 'Uncertainty', 'Validation', 'Visual', 'base', 'biological systems', 'chemical standard', 'computerized tools', 'cost', 'database query', 'flexibility', 'functional outcomes', 'graphical user interface', 'heuristics', 'inhibitor/antagonist', 'instrument', 'ionization', 'mass spectrometer', 'member', 'metabolomics', 'novel', 'programs', 'protein expression', 'research study', 'small molecule', 'software development']",NCI,TUFTS UNIVERSITY MEDFORD,R03,2016,147569,-0.007643305004152325
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9108710,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'cluster merger', 'computer science', 'connectome', 'diagnostic biomarker', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2016,2369463,-0.014485696192279539
"Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics Project Summary (Abstract)  Human brain connectomics and imaging genomics are two emerging research fields enabled by recent advances in multi-modal neuroimaging and high throughput omics technologies. Integrating brain imaging genomics and connectomics holds great promise for a systematic characterization of both the human brain connectivity and the connectivity-based neurobiological pathway from its genetic architecture to its influences on cognition and behavior. Rich multi-modal neuroimaging data coupled with high density omics data are available from large-scale landmark studies such as the NIH Human Connectome Project (HCP) and Alzheimer's Disease Neuroimaging Initiative (ADNI). The unprecedented scale and complexity of these data sets, however, have presented critical computational bottlenecks requiring new concepts and enabling tools.  To bridge the gap, this project is proposed to develop and validate novel integrative bioinformatics approaches to human brain genomics and connectomics, and has three aims. Aim 1 is to develop a novel computational pipeline for a systematic characterization of structural connectome optimized for imaging genomics, where special consideration will be taken to address important issues including reliable tractography and network construction, systematic extraction of network attributes, identification of important network components (e.g., hubs, communities and rich clubs), prioritization of network attributes towards genomic analysis, and identification of outcome-relevant network measures. Aim 2 is to develop novel bioinformatics strategies to determining genetic basis of structural connectome, including novel approaches for analyzing graph-based phenotype data and learning outcome-relevant associations, and an ensemble of effective learning modules to handle a comprehensive set of scenarios on mining genome-connectome associations at the genome-wide connectome-wide scale. Aim 3 is to develop a visual analytic software system for interactive visual exploration and mining of fiber-tracts and brain networks with their genetic determinants and functional outcomes, where new visualization and exploration methods will be implemented for seamlessly combining human expertise and machine intelligence to enable novel contextually meaningful discoveries.  This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale genomics and connectomics data. The availability of these powerful methods and tools is critical for full knowledge discovery and exploitation of major connectomics and imaging genomics initiatives such as HCP and ADNI. In addition, they can also help enable new computational applications in many other biomedical research areas where integrative analysis of connectomics and genomics data are of interest. Via thorough test and evaluation on HCP and ADNI data, these methods and tools will be demonstrated to have considerable potential for a better understanding of the interplay between genes, brain connectivity and function, and thus be expected to impact biomedical research in general and benefit public health outcomes. Public Health Relevance (Narrative) Integrating human connectomics and brain imaging genomics offers enormous potential, allowing us to perform systems biology approaches of the brain to better understand the interplay between genes, brain connectivity, and phenotypic outcomes (e.g., cognition, behavior, disorder). This proposal seeks to develop novel bioinformatics methods and software tools for integrative study of human connectomics and brain imaging genomics. These methods and tools can be applied to: (1) study normal brain functions to impact biomedical research in general, and (2) study brain disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Integrative Bioinformatics Approaches to Human Brain Genomics and Connectomics,9155025,R01EB022574,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Artificial Intelligence', 'Beds', 'Behavior', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cognition', 'Communities', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Fiber', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genomics', 'Graph', 'Human', 'Image', 'Imagery', 'Individual', 'Joints', 'Knowledge Discovery', 'Learning', 'Learning Module', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modeling', 'Nervous system structure', 'Neurobiology', 'Outcome', 'Pathway interactions', 'Pattern', 'Phenotype', 'Property', 'Public Health', 'Research', 'Sample Size', 'Single Nucleotide Polymorphism', 'Software Tools', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Visual', 'abstracting', 'base', 'brain tract', 'connectome', 'cost', 'data acquisition', 'density', 'evaluation/testing', 'functional outcomes', 'genome-wide', 'genomic data', 'improved', 'innovation', 'insight', 'interest', 'learning outcome', 'learning strategy', 'neuroimaging', 'novel', 'novel strategies', 'public health relevance', 'software systems', 'tool', 'trait', 'white matter', 'whole genome']",NIBIB,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2016,500696,-0.009243170508472029
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,9098683,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2016,490980,-0.017407486725678285
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9099840,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Applied Skills', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Health', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2016,144298,0.008519383750219387
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,677628,-0.013180015535181843
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability.         PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.        ",Capti Screen Reading Assistant for Goal Directed Web Browsing,9048176,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Learning', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'empowered', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2016,500000,0.010992540119764294
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently.         PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.        ",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9138555,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'United States National Institutes of Health', 'Work', 'analytical tool', 'animal data', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'meetings', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'research study', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2016,750063,0.005905148660259709
"Longitudinal brain development and clinical outcomes in ADHD from 7-17 years ﻿    DESCRIPTION (provided by applicant): ADHD is has long been believed to include brain-based pathophysiology, but the newest approaches to describing atypical brain organization in ADHD are just emerging and are thus far limited to cross-sectional studies. The present study has as its principal aims three objectives. First, it aims to characterize ADHD's brain organization longitudinally from childhood through adolescence, during a period of time in which ADHD youth enter very high risk for negative life outcomes, poor health outcomes, and comorbid behavioral, mood, and substance use disorders. In particular, the project aims to determine specified circuits, unique brain networks, and brain wide topological properties that relate to clinical course and outcome. Second, the proposal aims to bridge these developmental brain features with an enriched conception of phenotype, examining symptom domains, comorbidity, and measures of executive, reward, and emotional functioning in relation to specified brain metrics and targets. Third, it seeks to move the field forward in regard to clinica prediction by considering heterogeneity in two ways. One way is to examine novel typologies of ADHD based on differential brain organization across development. The other way is to utilize multiple methods to enhance prediction of clinical course. The significance of this effort lies bot in its unprecedented ability to characterize ADHD neurobiology over time with methods of brain characterization that have not been examined in ADHD longitudinally in this way before, and in its effort to move brain imaging into the realm of clinical prediction using a longitudinal design. The project is innovative in regard to implementing network and topology features of brain analysis in a multi-wave design, and tightly linking these to well defined, multi-level clinical course. The approach entails tracking of an already developed novel cohort of 376 children in a cross-lagged longitudinal design, enabling characterization of development from age 7-19 years. Brain organization will be operationalized with both diffusion tensor imaging and resting state functional connectivity. Youth will be characterized annually in relation to clinical symptoms, comorbidity, impairment, cognitive functioning, reward discounting, and emotion regulation and functioning. Analytic approaches will span brain circuit, network, and topological measurements using novel graph theoretical analyses to characterize brain systems. Clinical prediction will be undertaken using machine learning methodologies. Clinical typologies will be evaluated using both novel community detection procedures and more standard mixture model analysis of brain features. Finally, latent class trajectory models will be used to identify distint developmental types of ADHD if they exist. The prior grant period has been productive and this work builds on those findings to strengthen inference regarding the relation of brain organization to ADHD clinical features, course, and outcome. The Aims directly match key priorities of the NIMH strategic plan. If successful, the project hopes to break the impasse facing the field with regard to clinical utility of the growing grasp of atypical brain physiology in ADHD. PUBLIC HEALTH RELEVANCE: Much has been learned about brain correlates of ADHD, but this work has not yet affected clinical practice. The present project would characterize individual variation in ADHD brain development and attempt to use those findings to enhance clinical prediction. It thus aims to move the field closer to clinical application of brain imaging information of ADHD.",Longitudinal brain development and clinical outcomes in ADHD from 7-17 years,9208912,R56MH086654,"['19 year old', 'Adolescence', 'Affect', 'Age', 'Alcohol or Other Drugs use', 'Amygdaloid structure', 'Attention', 'Attention deficit hyperactivity disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Brain Mapping', 'Brain imaging', 'Child', 'Childhood', 'Classification', 'Clinical', 'Cognitive', 'Communities', 'Comorbidity', 'Conceptions', 'Cross-Sectional Studies', 'Data', 'Detection', 'Development', 'Developmental Course', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Disease remission', 'Dorsal', 'Emotional', 'Emotions', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Grant', 'Graph', 'Health', 'Heterogeneity', 'Impairment', 'Impulsivity', 'Incentives', 'Individual', 'Informal Social Control', 'Knowledge', 'Learning', 'Life', 'Link', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Neurobiology', 'Outcome', 'Parietal', 'Pattern', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Procedures', 'Property', 'Rest', 'Rewards', 'Sampling', 'Specific qualifier value', 'Strategic Planning', 'Structure', 'Subgroup', 'Substance Use Disorder', 'Symptoms', 'Syndrome', 'System', 'Thick', 'Time', 'To specify', 'Typology', 'Variant', 'Work', 'Youth', 'associated symptom', 'base', 'clinical application', 'clinical practice', 'cognitive control', 'cognitive function', 'cohort', 'design', 'discounting', 'emotion regulation', 'graph theory', 'grasp', 'high risk', 'improved', 'inattention', 'innovation', 'longitudinal design', 'novel', 'novel strategies', 'predict clinical outcome', 'public health relevance', 'time use']",NIMH,OREGON HEALTH & SCIENCE UNIVERSITY,R56,2016,769969,-0.013021711051886115
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,9336584,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,28000,0.024920032179193946
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9136188,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'human-robot interaction', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,274076,0.024535614896216792
"Understanding Action Selection in the Tool Use Network Project Summary: Skilled use of tools is a defining achievement of human cognition, and is enabled by the storage of tool-specific action memories. Many tools are associated with more than one action, and most everyday tasks are associated with more than one tool. Limb apraxia is a common, disabling, and puzzling left-hemisphere disorder characterized by prominent deficits in activating and selecting task-appropriate tool actions. Little is known about the cognitive mechanisms and brain regions enabling such selection in the neurologically intact brain, or how these processes go awry in apraxia. In several other cognitive domains, it has been suggested that appropriate response selection occurs via biased competition—that is, the prioritization of competing incoming information to enable appropriate response selection. Capitalizing on the promise of such frameworks, we have developed a new functional-neuroanatomic model of biased competition in a specific left hemisphere Tool Use network. Called “Two Action Systems Plus” (2AS+), the model generates testable hypotheses about the major principles determining tool action selection, and their deficiencies in apraxia. Specifically, we hypothesize that 1) Competition between tool actions is influenced by the graded similarity of tool action representations, as implemented primarily by the left posterior temporal cortex (pTC), 2) The outcome of the competitive process is affected by the strength and timing of activation of tool action representations, and depends on the dynamic interplay of left pTC and the parietal lobes, 3) Outcome is further influenced by a mechanism that biases competition towards the tool action that is appropriate to goals and context, as implemented by the left inferior frontal gyrus (IFG) and its connections with the supramarginal gyrus (SMG), and 4) There are two subtypes of apraxia characterized by distinct failures in the competitive selection process: an anterior subtype characterized by inability to appropriately resolve tool action competition, and a posterior subtype reflecting weakened competition. These hypotheses will be tested using a number of complementary methods with healthy and brain-lesioned participants, including voxel-based lesion symptom mapping, resting functional connectivity, fMRI with multi-voxel pattern analyses, and eyetracking. By specifying when and how visuomotor information plays a role in tool representations, the proposed experiments promise to critically constrain “embodied” cognition theories claiming that tools automatically evoke their actions. The proposed research will also advance the theoretical understanding of tool action by anchoring relevant constructs in a cognitive-neuroanatomic model, clarify how action representations are organized and activated, and improve our understanding of the mechanisms affecting errors and re-learning in apraxia, with implications for rehabilitation. Project Narrative: Apraxia, a disorder of tool use, is a common and substantially disabling consequence of left hemisphere stroke, yet is relatively rarely studied and hence poorly understood. The proposed work will clarify the brain regions that are associated with the disorder, the task factors that may improve tool use abilities, and the ability of the damaged Tool Use system to learn after stroke. This information will serve as an important building block in the development of treatment strategies.",Understanding Action Selection in the Tool Use Network,9213205,R01NS099061,"['Achievement', 'Adopted', 'Affect', 'Anterior', 'Apraxias', 'Behavior', 'Brain', 'Brain region', 'Cheese', 'Cognition', 'Cognitive', 'Color', 'Development', 'Disease', 'Failure', 'Functional Magnetic Resonance Imaging', 'Gestures', 'Goals', 'Grant', 'Hand', 'Human', 'Individual', 'Inferior frontal gyrus', 'Learning', 'Left', 'Lesion', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Mediating', 'Memory', 'Methods', 'Modeling', 'Nature', 'Outcome', 'Parietal Lobe', 'Participant', 'Patients', 'Pattern', 'Play', 'Posture', 'Process', 'Production', 'Rehabilitation therapy', 'Research', 'Rest', 'Role', 'Source', 'Specific qualifier value', 'Stroke', 'Structure', 'Structure of supramarginal gyrus', 'Symptoms', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Work', 'base', 'clinically relevant', 'experience', 'improved', 'novel', 'research study', 'response', 'theories', 'tool', 'treatment strategy', 'visual motor']",NINDS,ALBERT EINSTEIN HEALTHCARE NETWORK,R01,2016,431274,-0.0293712771031163
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",9148070,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2016,47190,0.008645596845317807
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions. PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",9349858,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'field study', 'handheld equipment', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'standard of care', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2016,25000,0.006795012812032077
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort. PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,9145739,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Data Analytics', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Health', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'field study', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2016,355735,-0.003572853131719967
"An Open Source Precision Medicine Platform for Cloud Operating Systems ﻿    DESCRIPTION (provided by applicant):  Rapid improvements in DNA sequencing and synthesis have the potential to usher in a new era of precision medicine. To realize this vision, however, we must re-imagine the computational and storage infrastructure used to manage and extract actionable results from the massive data sets made possible by widely available advances in DNA sequencing and synthetic biology. In conjunction with the Global Alliance for Genomics and Health (GA4GH), we propose to build the Arvados platform so that a new ecosystem of clinical decision support applications will be able to navigate petabytes of global biomedical data and search millions of genomes in real-time (seconds). Our team has a proven track record of commercial success and high impact scientific research. Commercialization of this free and open-source software (FOSS) platform, which will be greatly accelerated by this grant, will permit organizations to seamlessly span on-premise & hosted cloud- operating systems and vastly simplify data-management & computation, all while facilitating compliance with institutional policies and regulatory requirements.         PUBLIC HEALTH RELEVANCE:  The delivery of healthcare based on molecular data specific to an individual patient (i.e. precision medicine) will require the creation of a new ecosystem of Clinical Decision Support (CDS) applications. This work will provide a platform that will make the development of such applications faster, easier, and less expensive.        ",An Open Source Precision Medicine Platform for Cloud Operating Systems,9140741,R44GM109737,"['Address', 'Adopted', 'Big Data', 'Bioinformatics', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Collaborations', 'Communities', 'Computer software', 'Contractor', 'DNA Sequence', 'DNA biosynthesis', 'Data', 'Data Set', 'Databases', 'Development', 'Distributed Systems', 'Ecosystem', 'Feedback', 'Fostering', 'Funding', 'Galaxy', 'Genome', 'Genomics', 'Grant', 'Health', 'Healthcare', 'Human', 'Industry', 'Information Technology', 'Institutional Policy', 'International', 'Internet', 'Language', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Measures', 'Medicine', 'Memory', 'Molecular', 'Operating System', 'Phase', 'Policies', 'Production', 'Publications', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resources', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Source Code', 'System', 'Technology', 'Time', 'Training Support', 'Vision', 'Work', 'base', 'big biomedical data', 'cloud platform', 'commercialization', 'data management', 'genome sequencing', 'genomic data', 'health care delivery', 'individual patient', 'meetings', 'new technology', 'next generation sequencing', 'open source', 'operation', 'petabyte', 'portability', 'precision medicine', 'public health relevance', 'repository', 'screening', 'success', 'symposium', 'synthetic biology', 'terabyte', 'web services', 'whole genome']",NIGMS,"CUROVERSE, INC.",R44,2016,985339,-0.011274584642034747
"Large-Scale Semiparametric Graphical Models with Applications to Neuroscience DESCRIPTION: The objective of this proposal is to develop and theoretically evaluate a unified set of statistical, computational, and software tools to address data mining and discovery science challenges in the analysis of existing vast amounts of publicly available neuroimaging data. In particular, we propose to develop scalable and robust semiparametric solutions for high-throughput estimation of resting-state brain connectivity networks, both at the individual and population levels, with the flexibility of incorporating covariate information.  The work will contribute meaningfully to the theory and methods for large-scale semiparametric graphical models and will apply these methods to the largest collections of resting-state fMRI data available. The proposed methods and theory include key directions of research for brain network estimation and mining. First, we pro- pose novel methods for subject-specific network estimation, such as would be needed for biomarker development in functional brain imaging. Secondly, we define and propose to evaluate and implement methods for studying population-level graphs, which study collections of graphs. Thirdly, we propose the use of estimated graphs in predictive modeling. Finally, all of these methods will have complementary software and web services development. Most notably, the idea of population graphs allows for the creation of functional brain network atlases.  In summary, the work of this proposal will result in a unified framework for the analysis of modern neuroimaging data via graphical models. Our methods will further be agnostic to intricacies of the technology, thus making it portable across settings and applicable outside of the field of functional brain imaging. The methods will be carefully evaluated via theory, simulation and data-based application evidence. PUBLIC HEALTH RELEVANCE: Modern neuroimaging data are often Big, Complex, Noisy and Dependent. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of network estimation and mining based on neuroimaging data. Our proposed work represents a significant step forward over the current methodology and has the potential to be applied to analyze a wide range of scientific problems beyond brain imaging data analysis.",Large-Scale Semiparametric Graphical Models with Applications to Neuroscience,8998688,R01MH102339,"['Address', 'Algorithms', 'Atlases', 'Attention deficit hyperactivity disorder', 'Big Data', 'Brain', 'Brain Diseases', 'Brain imaging', 'Characteristics', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Discovery', 'Data Set', 'Databases', 'Dependence', 'Development', 'Disease', 'Documentation', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Graph', 'Health', 'Heterogeneity', 'Image', 'Individual', 'Internet', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Neurosciences', 'Pattern', 'Population', 'Process', 'Rest', 'Sampling', 'Science', 'Signal Transduction', 'Site', 'Software Tools', 'Statistical Methods', 'Tail', 'Technology', 'Work', 'abstracting', 'base', 'biomarker development', 'brain research', 'cloud based', 'data mining', 'flexibility', 'interest', 'neuroimaging', 'novel', 'predictive modeling', 'psychologic', 'semiparametric', 'simulation', 'study population', 'theories', 'user friendly software', 'web services']",NIMH,PRINCETON UNIVERSITY,R01,2016,368829,0.019681878015180905
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9100683,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Left', 'Letters', 'Linear Models', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2016,680020,0.008281842725388061
"Structural Development of Human Fetal Brain Abstract Despite its critical significance, little is known about the most dynamic phase of brain development in infancy: 0-2 years. To change the status quo, comprehensive and quantitative infant brain atlases as reference standards for precision health are needed. In addition, diffusion MRI (dMRI) has entered a new era in which dynamic cortical internal microstructural complexity, indexed by e.g. cortical mean kurtosis derived from diffusion kurtosis imaging (DKI), can be studied in the living infant brain noninvasively using more advanced multi-shell dMRI. Furthermore, multi-modality measures offer unparalleled insights into mechanistic structure- function and structure-behavior relationships. Work in the current cycle has focused on structural development of human fetal and preterm brains. Based on high resolution diffusion tensor imaging (DTI) of 150 brains, we have established the atlases and quantified cortical microstructure with cortical fractional anisotropy, validated by histological images and correlated with transcriptomic (RNA) expression. Building upon this work, in the next cycle, we will focus on brain development in infancy, immediately after the fetal period. Specifically, the goal is to establish next-generation dMRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural mean kurtosis measurement by delineating its 4D spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). 160 typically developing infants at 1, 3, 6, 12, 18, 24 months will be recruited. Advanced “connectome-quality” multi-band high-resolution multi-shell dMRI, resting state fMRI (rs-fMRI) and structural MRI will be acquired. High-quality whole-head magnetoencephalography (MEG) will also be acquired. Anatomical labels of all 122 major gray and white matter structures will be built up based on high contrasts from DTI-derived maps. The measurements of DTI-derived metrics will be used for the quantitative components of DTI atlases and age-dependent white matter tract trajectories (Aim 1). Mean kurtosis of the 4th order kurtosis tensor has been shown to be sensitive to cortical internal microstructural changes of infant brains. The spatiotemporal sensitivity of mean kurtosis measures to infant age and cortical region will be investigated (Aim 2). Furthermore, we will establish mechanistic structure-function relationships with multi- modality imaging, including not only multi-shell dMRI, but also rs-fMRI and MEG, all optimized for infant brains (Aim 3). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants (e.g. Z-score maps). Infant cortical microstructure will be delineated noninvasively with 4D spatiotemporal frameworks. With multi-modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general. Narrative Title: Structural development of human fetal brain The goal is to establish next-generation diffusion MRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural measurement by delineating its four-dimensional spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants. With multi- modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general.",Structural Development of Human Fetal Brain,9247587,R01MH092535,"['2 year old', 'Age', 'Anisotropy', 'Architecture', 'Area', 'Atlases', 'Auditory', 'Behavior', 'Behavior assessment', 'Behavioral', 'Brain', 'Cerebral cortex', 'Characteristics', 'Clinical Research', 'Collaborations', 'Development', 'Developmental Process', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Fingerprint', 'Four-dimensional', 'Functional Magnetic Resonance Imaging', 'Genetic Transcription', 'Goals', 'Head', 'Health', 'Human', 'Image', 'Infant', 'Infant Development', 'Infant Health', 'Intellectual functioning disability', 'Label', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Measurement', 'Measures', 'Modality', 'Motor', 'Neurodevelopmental Disorder', 'Phase', 'Recruitment Activity', 'Reference Standards', 'Research Personnel', 'Resolution', 'Rest', 'Risk Assessment', 'Sensorimotor functions', 'Sensory', 'Staging', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Time', 'Visual', 'Work', 'abstracting', 'age related', 'aging brain', 'artemis', 'autism spectrum disorder', 'base', 'connectome', 'fetal', 'gray matter', 'histological image', 'imaging modality', 'indexing', 'infancy', 'insight', 'neuroimaging', 'neuronal circuitry', 'next generation', 'novel', 'prisma', 'relating to nervous system', 'somatosensory', 'spatiotemporal', 'transcriptomics', 'white matter']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2016,504581,-0.01494053033534082
"Enabling access to printed text for blind people via assisted mobile OCR DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality. PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.",Enabling access to printed text for blind people via assisted mobile OCR,8989105,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Augmented Reality', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Health', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2016,230563,0.00238415653604037
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9147594,K01ES026839,"['Accounting', 'Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Health', 'High Frequency Oscillation', 'Hybrids', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resected', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'programs', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep epilepsy', 'spatial temporal variation', 'standard of care', 'statistics', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2016,148644,-0.0065444769720501795
"Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction DESCRIPTION (provided by applicant): In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function. Although fMRI research has primarily focused on identifying brain regions that are activated during performance of cognitive tasks, there is growing interest in examining how cognitive functions emerge as a result of context-dependent, dynamic causal interactions between distributed brain regions. Devising and validating methods for investigating such interactions has therefore taken on great significance. The first major goal of this proposal is to address a critical need in fMRI research by developing novel algorithms for identifying context-dependent dynamic causal interactions between distributed brain regions. To this end, we will develop and validate novel computational methods using Multivariate Dynamical Systems based Markov chain Monte Carlo (MDS-MCMC) algorithms that overcome major limitations of existing methods for investigating dynamic causal interactions and connectivity in the human brain. A comprehensive validation framework will be use evaluate MDS-MCMC and compare it with existing dynamic causal estimation methods. The second major goal of this proposal is to use the MDS-MCMC framework to investigate dynamic causal interactions underlying cognition in normal healthy adults, and in patients with Parkinson's disease (PD). Cognitive impairment is one of the most devastating symptoms in PD. Once thought of as an insignificant feature of the disease, it is now clear that cognitive impairment is present in the majority of PD patients and that this impairment is significantly linked to increased disability and the risk of mortality, yetlittle is known about the brain basis of cognitive impairment in PD. The computational algorithms we develop, validate, and apply here will allow us to rigorously investigate brain dynamics support critical cognitive processes in the human brain, leading to a more complete understanding of fundamental mechanisms underlying human brain function and dysfunction. Our proposed studies will also, for the first time, examine casual interactions in simulated, open-source, opto-genetic, experimental and clinical brain imaging data using state-of-the-art sub-second high-temporal resolution fMRI, based on the Human Connectome Project (HCP). Critically, we will maintain a tight link between our computational and systems neuroscience goals algorithms to solve important problems in cognitive, systems and clinical neuroscience. Together, our proposed studies will lead to new and improved computational tools for examining dynamical causal interactions between distributed brain regions, with broad applications to the HCP and clinical neuroscience. The proposed studies are highly relevant to the mission of the NIH Innovations in Biomedical Computational Science and Technology and the Big Data to Knowledge Programs, which seek to encourage development and dissemination of innovative advanced computational tools for brain imaging and neuroscience. We will disseminate our algorithms and software to the research community via NITRC . PUBLIC HEALTH RELEVANCE: In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function and dysfunction. Although fMRI studies of brain function have primarily focused on identifying brain regions that are activated during performance of perceptual or cognitive tasks, there is growing consensus that cognitive functions emerge as a result of dynamic context-dependent interactions between multiple brain areas. Developing new computational methods for investigating causal interactions in fMRI data has therefore taken added significance; the overall goal of this proposal is to address this critical need by developing new methods for studying causal interactions and brain connectivity between distributed brain regions during cognition.",Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction,9086441,R01NS086085,"['Address', 'Adult', 'Algorithmic Software', 'Algorithms', 'Area', 'Basal Ganglia', 'Base of the Brain', 'Benchmarking', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive deficits', 'Communities', 'Computational Science', 'Computational algorithm', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Development', 'Disease', 'Experimental Genetics', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Human', 'Impaired cognition', 'Impairment', 'Individual Differences', 'Lead', 'Link', 'Machine Learning', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Neurosciences', 'Parietal', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Play', 'Prefrontal Cortex', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Resource Sharing', 'Risk', 'Role', 'Short-Term Memory', 'Software Tools', 'Symptoms', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'brain dysfunction', 'cognitive function', 'cognitive load', 'cognitive process', 'cognitive system', 'cognitive task', 'computerized tools', 'connectome', 'disability', 'dynamic system', 'improved', 'in vivo', 'innovation', 'interest', 'mortality', 'novel', 'open data', 'open source', 'optogenetics', 'programs', 'public health relevance', 'simulation', 'temporal measurement', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2016,554411,-0.0013386738887771865
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.                ",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9030162,R01EY025332,"['3D Print', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image', 'Information Systems', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'research study', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2016,416574,0.020417505613266385
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,9097814,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Genetic', 'Genetic Structures', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Internships', 'K-12 student', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Staging', 'Statistical Data Interpretation', 'Statistical Models', 'Structure', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'fluorescence imaging', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'neuroinformatics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'quantitative imaging', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2016,323032,-0.003945026604728852
"EEGLAB: Software for Analysis of Human Brain Dynamics DESCRIPTION (provided by applicant): A major shift in scientific perspective on the nature and use of electrophysiological brain data is now ongoing a shift from measurement and visualization of individual channel signals (in the 'recording channel space') to visualizing and interpreting the data directly within a suitable inverse model representing activity reaching the electrodes by volume conduction from a set of effective data sources in native 'brain source space'. An equivalent shift, via the development and exploitation of an appropriate inverse imaging model, made possible the phenomenon of structural and functional magnetic resonance imaging (fMRI). While the electrophysiological inverse problem is still difficult, dramatic progress has been and is being made through combined use of multimodal imaging and modern statistical signal processing methods. Recovering the considerable degree of spatial source resolution available in high-density scalp electroencephalographic (EEG) and other electrophysiological data, while retaining its natural advantage over other functional imaging methods in temporal resolution, has begun to yield a steady stream of new information about patterns of distributed brain processing supporting human behavior and experience. Relative to other brain imaging modalities, EEG has substantial and increasing cost and mobility advantages, making promotion of new EEG methods for source space analysis of increasing interest and importance for brain and health research. However, applying new source signal and signal processing models to electrophysiological data is complex and increasingly involves application of modern mathematical methods whose details are not within the training of most health research professionals. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University of California San Diego, began as a set of EEG data analysis running on MATLAB (The Mathworks, Inc.) released on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now, more than ten years later, the EEGLAB reference paper (Delorme & Makeig, 2004) has over 2,350 Google scholar citations (increasing at above 1 per day), the opt-in EEGLAB discussion email list links over 5,000 researchers, the news list over 9,000, and a recent survey of 687 researcher respondents reports EEGLAB to be the software environment most widely used for electrophysiological data analysis worldwide. EEGLAB is thus now a de facto standard supporting a wide range of EEG and other electrophysiological research studies and teaching labs. At least 35 EEGLAB plug-in toolsets have now been released by researchers from many laboratories. Under NIH PAR 11-028 we propose renewal funding to further develop and maintain the EEGLAB software framework. We propose new and better tools for brain source and source network modeling and localization, an expanded online EEGLAB course and workshop, better statistical inference modeling of group data, and new support for automated source decomposition, measure computation, data duration, and data sharing. PUBLIC HEALTH RELEVANCE: A major shift in scientific perspective on the nature and use of human electrophysiological data is now accelerating from measuring and visualizing individual scalp channel signals to directly visualizing and interpreting their brain sources. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University Of California San Diego (UCSD), supports a large number of EEG and related electrophysiological research studies and teaching labs. We propose continued funding to further develop and maintain the EEGLAB environment.",EEGLAB: Software for Analysis of Human Brain Dynamics,9099954,R01NS047293,"['Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Clinical', 'Cloud Computing', 'Code', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Educational process of instructing', 'Educational workshop', 'Electrodes', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Event-Related Potentials', 'Eye', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Health', 'Human', 'Image', 'Imagery', 'Individual', 'Internet', 'Joints', 'Laboratories', 'Links List', 'Machine Learning', 'Measurement', 'Measures', 'Memory', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multimodal Imaging', 'Nature', 'Neurosciences', 'Output', 'Paper', 'Pattern', 'Performance', 'Physiology', 'Plug-in', 'Positioning Attribute', 'Procedures', 'Process', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Scalp structure', 'Signal Transduction', 'Software Framework', 'Source', 'Speed', 'Stream', 'Surveys', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'brain health', 'computational neuroscience', 'computing resources', 'cost', 'cranium', 'data sharing', 'density', 'design', 'experience', 'flexibility', 'imaging modality', 'improved', 'innovation', 'interest', 'learning strategy', 'mathematical methods', 'network models', 'news', 'online course', 'open source', 'research study', 'signal processing', 'symposium', 'temporal measurement', 'tool', 'web site', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2016,480520,0.023171171580739405
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8989994,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Imaging Device', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'spectrograph', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2016,230028,-0.003392513311242414
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9213710,R00AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2016,249000,-0.004738745155597785
"Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero DESCRIPTION (provided by applicant): Accurate mapping of normal and abnormal patterns of brain development in fetuses and premature neonates is a key factor in the early detection of developmental disorders as well as understanding how external factors can influence early brain growth. The combination of fast multi-slice MRI techniques with computer vision algorithms has recently provided the ability to reliably image 3D brain structure in-utero providing valuable information inaccessible to ultrasound imaging. To complement this new structural information, recently there has been increasing interest in the use of functional MR imaging (fMRI) to map the development of resting state brain function in children, premature neonates and, most recently, fetuses in-utero. This work has revealed signs of a predictable developmental path in the formation of resting state patterns of brain activity present in adults and abnormalities in these patterns in children have been linked with neurological and neuropsychiatric conditions in later life. Such fMRI methods, previously used in adults and children, could provide a unique new window into functional activity in the developing fetal brain. However, the imaging techniques required suffer from an important limitation for use in the fetus: they make use of repeated acquisitions where subtle changes in MR signal provide the measure of interest. Fetal head motion within the scanner perturbs both measurement location and signal level due to the changing relationship between fetal anatomy, maternal anatomy and the scanner. Based on our preliminary results, in this proposal we plan to develop a set of new signal and geometry correction methods specifically for fetal fMRI that combine novel acquisition techniques with post-processing algorithms to provide a new route to addressing these unique problems. This will allow us to collect the first accurate functional MRI data from a range of un-sedated fetuses in ages and activity levels seen in clinical studies. We will develop and validate these methods together with complementary pattern analysis techniques specifically aimed at motion scattered data and employ them to build the first combined 4D structure-function map of brain development in-utero. This will show for the first time the temporal and spatial relationship between structural changes and the development of resting state patterns of brain activity covering the critical age of first clinical MRI scan and the following period of cortical folding. his will help answer such questions as: which tissue zones of the fetal brain such activity begins, and whether the functional patterns are related to the timing of the formation of specific cortical folds. We will collect a range of data that captures fetuses both at different ages and different states of activity representing those seen in typical clinical studies, and in addition collect valuable outcome measures on the babies after birth against which in-utero measure will be evaluated. We release the data to the community as a whole in the form of an open-access 4D atlas. This combined structure-function data will provide a unique new reference for both neuroscience and, in the longer term, clinical evaluation of brain health during pregnancy and premature birth. PUBLIC HEALTH RELEVANCE: Clinically, improved in-utero evaluation of the fetal brain is a key concern for obstetricians and pediatricians in managing complex pregnancies and there is also now an increasing public health awareness of the influence of the in-utero environment, in terms of factors such as stress and diet, on long-term health in adult life. Functional connectivit imaging of the brain in childhood has revealed the presence of early markers of later cognitive and neuropsychological problems. The ability to map these same properties in utero, promises to provide a rich set of very specific early markers that can be used to understand the impact of the in-utero environment on brain function and feasibly provide a route to the use of early neuro-protective agents and procedures early in childhood.",Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero,9067148,R01EB017133,"['Accounting', 'Acoustic Stimulation', 'Acoustics', 'Address', 'Adult', 'Age', 'Algorithms', 'Anatomy', 'Atlases', 'Awareness', 'Biological Markers', 'Birth', 'Brain', 'Brain Mapping', 'Brain imaging', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Dependency', 'Detection', 'Development', 'Diet', 'Early Diagnosis', 'Early identification', 'Echo-Planar Imaging', 'Elderly', 'Environment', 'Evaluation', 'Fetal Heart Rate', 'Fetal Movement', 'Fetus', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Gestational Age', 'Goals', 'Growth', 'Head', 'Health', 'Heart Rate', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Left', 'Life', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Midbrain structure', 'Morphologic artifacts', 'Motion', 'Neonatal', 'Network-based', 'Neurologic', 'Neurosciences', 'Outcome Measure', 'Pattern', 'Positioning Attribute', 'Predisposition', 'Pregnancy', 'Premature Birth', 'Procedures', 'Process', 'Property', 'Protective Agents', 'Protocols documentation', 'Public Health', 'Recording of previous events', 'Reporting', 'Rest', 'Route', 'Scheme', 'Series', 'Signal Transduction', 'Slice', 'Source', 'Staging', 'Stimulus', 'Stress', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'base', 'brain health', 'brain tissue', 'design', 'developmental disease', 'experience', 'fetal', 'heart rate monitor', 'imaging modality', 'imaging system', 'improved', 'in utero', 'interest', 'neuropsychiatry', 'neuropsychological', 'novel', 'pediatrician', 'population based', 'premature neonates', 'research clinical testing', 'spatial relationship', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2016,642962,-0.024805737859410155
"Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr) EMPIRICAL TESTING AND ENHANCEMENT OF WEB-BASED ABSTRACT SCREENING TOOL (ABSTRACKR)  In this year-long project, we aim to empirically assess the performance and efficiency of state-of-the-art information analysis technologies to assist the production of systematic reviews and meta-analyses that are increasingly being used as a foundation for evidence-based medicine and stakeholder-driven comparative effectiveness reviews. We have developed AbstrackrTM (hereon, Abstrackr), a human-guided computerized abstract screening tool that aims to reduce the need to perform a tedious but crucial step of manually screening many thousands of abstracts generated by literature searches in order to retrieve a small fraction potentially relevant for further analysis. Abstrackr makes use of machine learning techniques, and is offered as a free web-based tool that enables management of the screening process.  We also aim to revise the web-interface of Abstrackr to make it more intuitive, user friendly, and add documentation and functionalities requested by users; and to revise Abstrackr’s back-end, which includes the way the software parses and analyses citations, fits machine learning models, and makes computations, to make it more efficient. These revisions will ensure that the tool becomes more robust, and that it remains usable for larger projects and for many teams.  The proposed work will be carried out by the developers of Abstrackr, comprising a highly experienced team of systematic review investigators and computer scientists at Brown University and the University of Texas at Austin, who have been working together for at least seven years. We will pursue dissemination of the findings of this assessment and of the revised tool through numerous channels including, but not limited to publication, presentation at conferences, exploring interest in its wider adoption by the Agency for Healthcare Research and Quality Evidence-based Practice Center Program, Cochrane Collaboration, and other groups conducting systematic reviews. We will also continue to make all code available online. Our aims are to: Aim 1. Empirically measure the efficiency and accuracy of the prediction algorithms in Abstrackr in the computer-assisted semi-automated screening of citations for eligibility in systematic reviews. Aim 2. Improve and add to the functionality of the Web-based Abstrackr software, based in part on enhancements suggested by a panel of identified heavy users. Systematic reviewing is a scientific approach to objectively summarizing the effectiveness and safety of existing treatments for diseases, a prerequisite for informed healthcare decision-making and systematic reviewers must read many thousands of medical study abstracts, the vast majority of which are completely irrelevant to the review at hand. This is hugely laborious and time consuming. We propose to assess the performance and efficiency of a computerized system that automatically excludes a large number of the irrelevant abstracts, thereby accelerating the process and expediting the application of the systematic review findings to patient care, and to augment the functionality of its public implementation.",Empiric Testing and enhancement of web-based abstract screening tool(Abstrackr),9168247,R03HS024812,[' '],AHRQ,BROWN UNIVERSITY,R03,2016,99999,-0.00994651361291604
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility ﻿    DESCRIPTION (provided by applicant): Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community-the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit's gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing.         PUBLIC HEALTH RELEVANCE: Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.        ",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9140712,R44AG053890,"['Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Dependence', 'Devices', 'Electrical Engineering', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Marketing', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'public health relevance', 'rehabilitation technology', 'robot exoskeleton', 'usability', 'vision aid']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2016,224990,-6.063423536938551e-05
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers.         PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1        ",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9076876,UH2CA203710,"['Algorithms', 'Arts', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Code', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Institutes', 'Intelligence', 'Lead', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Statistical Models', 'Students', 'Technology', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2016,320900,-0.013117402326724896
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9024545,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Health', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Thinking', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2016,576055,0.023481348593965695
"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, involving a complicated interplay between functional information interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. func- tional and structural measures. However the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities is to miss a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimensional problem, requiring appropriate data reduction strategies. In the previous phase of the project we developed approaches based on multiset canonical correlation analysis (mCCA) and joint independent compo- nent analysis (jICA) that can capture high-dimensional, linear, relationships among 2 or more modalities, and which we showed can identify both modality-unique and modality-common features that are predictive of dis- ease. In this new phase of the project we will focus on two important areas. First, we will build on our previous success by extending our models to allow for incorporation of behavioral/cognitive constraints as well as devel- oping new approaches which leverage recent advances in deep learning enabling us to capture higher order relationships embedded in multimodal and multitask data. Secondly, we will address the key challenge of inte- grating possibly thousands of multimodal features by developing a new meta-modality framework which will enable us to bring together the existing and new features in an intuitive manner. This will also enable us to capture changes in multimodal information which might not be harmful separately but which together are jointly sufficient to convey risk of illness or to identify information flow through the meta-modal space for developing potential targets for treatment. We will apply these approaches to one of the largest multimodal imaging datasets of psychosis and mood disorders. Our proposed approach will be thoroughly evaluated using this large data set which includes multiple illnesses that have overlapping symptoms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar de- pression). As before, we will provide open source tools and release data throughout the duration of the project via a web portal and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 36 Project Narrative  The promise of multimodal imaging is clear, and we have shown the power of linear joint N-way analysis during the previous funding period. However this is just the beginning. In this renewal, we will build on and significantly expand the goals of the original aims by incorporating additional joint information (including dynamic and potentially nonlinear factors) as well as a framework for integrating the resulting information in order to enable decision making and identification of potential targets for further study or possible treatment. We will also disseminate our approaches through software tools and interactive web-based visualization of available data. 37",Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,9185800,R01EB006841,"['Address', 'Algorithms', 'Area', 'Attention', 'Behavioral', 'Biological Markers', 'Biological Neural Networks', 'Biology', 'Bipolar Disorder', 'Blood flow', 'Brain', 'Brain Diseases', 'Brain imaging', 'Classification', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Imaging technology', 'Joints', 'Learning', 'Link', 'Measurable', 'Measures', 'Mental Depression', 'Mental disorders', 'Methods', 'Mining', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Multimodal Imaging', 'Neurobiology', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Psychotic Disorders', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Sample Size', 'Sampling', 'Schizophrenia', 'Series', 'Shipping', 'Ships', 'Software Tools', 'Symptoms', 'Tars', 'Testing', 'Time', 'Training', 'Unipolar Depression', 'Validation', 'Work', 'abstracting', 'base', 'clinical care', 'clinical phenotype', 'data reduction', 'data sharing', 'deep field survey', 'design', 'gray matter', 'imaging biomarker', 'imaging modality', 'improved', 'multitask', 'neuroinformatics', 'neuropsychiatric disorder', 'next generation', 'novel', 'novel strategies', 'open source', 'potential biomarker', 'repository', 'simulation', 'success', 'tool', 'web portal', 'white matter change']",NIBIB,THE MIND RESEARCH NETWORK,R01,2016,400000,0.004804913221147833
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8914675,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Health', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2015,136355,0.015452473390648824
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,8813596,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'quantitative imaging', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2015,59383,-0.008587363491563908
"Face De-Identification for Research and Clinical Use DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis. PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.",Face De-Identification for Research and Clinical Use,8908047,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Health', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'sex', 'social stigma', 'targeted imaging', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2015,193512,-0.03802332503370484
"4D Software Tools for Longitudinal Prediction of Brain Disease     DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders.          PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.            ",4D Software Tools for Longitudinal Prediction of Brain Disease,8814543,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,477101,-0.040458349424483876
"THS: Using Twitter and Big Data Analytics to Track and Predict Health Conditions ﻿    DESCRIPTION (provided by applicant): U.S. health officials are struggling to manage health conditions, and disease outbreaks (e.g., flu) affecting underserved communities. Yet, early warnings can be found in public postings made by citizens of these communities in social apps like Twitter. Recent studies from the Pew Research Center indicate that minorities are as likely to own a mobile phone as non-minorities, and are avid users of social apps. Since public Twitter posts can be searched and accessed without having a ""friendship"" relation with the author, this platform could provide health officials with the analytics capability to track which diseases are being discussed in a given region and at a specific time. Unfortunately, the software tools to perform these analytic tasks are still in the early stages of development. Very often, the expertise to use the required big data software and machine learning programs is not readily available, limiting access to officials working with underserved communities. In this project, we seek to conduct basic research aimed at designing, implementing and testing an open-source research prototype for an integrated and scalable platform to search Twitter posts, and analyze their contents in search for clues about health conditions, thereby understanding the health issues affecting underserved communities, and making predictions about possible health conditions that might affect them in the future. In Aim 1, we will build an automated Twitter data warehouse to collect, index, and query public posts. In Aim 2, we will build a predictive analytics engine that uses social data to make predictions about possible outbreaks of conditions, regions that might be affected and at-risk groups. Finally, in Aim 3, we will build mobile and web apps, with a map-based interface, to query and visualize the health data. The value- added capability of our system is the ability to work as an integrated system to help analyze tweets, visualize data along disease and spatio-temporal attributes, and make predictive analytics, all under one roof. This could have a significant impact on public health disease tracking and response. The University of Puerto Rico, Mayagüez (UPRM) is a Hispanic serving institution, with the second largest Hispanic serving engineering school in the U.S. and with 35% female enrollment. This AREA project provides a unique opportunity to train students in social media analysis, big data systems, machine learning, and predictive analytics.    PUBLIC HEALTH RELEVANCE: U.S. health officials are struggling to manage health conditions, and disease outbreaks (e.g., flu) affecting underserved communities. Yet, early warnings can be found in public postings made by citizens of these communities in social apps like Twitter. In this project we shall build an open-source system to search public Twitter posts, and analyze their contents in search for clues about health conditions, thereby understanding the health issues affecting underserved communities, and making predictions about possible health conditions that might affect them in the future.  ",THS: Using Twitter and Big Data Analytics to Track and Predict Health Conditions,9022751,R15LM012275,"['Affect', 'Algorithms', 'Basic Science', 'Big Data', 'Car Phone', 'Collection', 'Communities', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outbreaks', 'Engineering', 'Enrollment', 'Ensure', 'Environment', 'Ethnic group', 'Female', 'Friendships', 'Future', 'Glosso-Sterandryl', 'Government Officials', 'Health', 'Hispanic-serving Institution', 'Hispanics', 'Image', 'Income', 'Information Systems', 'Institution', 'Internet', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Minority', 'Names', 'Preventive', 'Public Health', 'Puerto Rico', 'Research', 'Research Personnel', 'Risk', 'Schools', 'Software Tools', 'Staging', 'Students', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'cloud based', 'commercialization', 'design', 'flu', 'health data', 'indexing', 'innovation', 'novel', 'open source', 'programs', 'prototype', 'public health relevance', 'response', 'social', 'software systems', 'trend']",NLM,UNIVERSITY OF PUERTO RICO MAYAGUEZ,R15,2015,312651,-0.0037146927497080976
"Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials ﻿    DESCRIPTION (provided by applicant):  A ""meta-study"" (or ""meta-analysis"") collects and analyzes many studies on the same topic to understand if there is a meaningful, overall result. Meta-studies can support (or refute) interventions, spur new investigations, and lead to novel clinical guidelines. However, constructing meta-studies is a time intensive process of searching the literature, compiling the results, and performing the statistical analysis. Due to the time commitment that is required, many topics are unexplored, and many meta-studies are not kept up-to-date with the latest published results. Finally, a number of (unknown) biases, via subjective choices during the meta-study, may influence the results. Our long-term goal is to automate, as much as possible, the meta-study process. This should decrease subjective bias; increase the dissemination of evidence, especially for diseases and interventions that receive less attention; and allow for the automatic updating of meta-studies as new results are published. We propose a computer system that uses statistical machine learning to gather and group studies focused on similar interventions and outcomes; extract the necessary results from the text; and analyze the results using standard meta-analysis techniques. The final output will be presented in a spreadsheet-like Web-interface where users can explore and even change the data and meta-analyses. Our team uniquely blends technical expertise in machine learning with leadership in publishing meta-studies about Inflammatory Bowel Disease (IBD), our disease of focus for our Phase I feasibility study. We are therefore qualified technically and able to ensure that the techniques generate valid and accurate meta-studies. Our Phase I results will define the current state-of-the-art for this novel task. Further, although we will initially focus n IBD, our Phase I results will demonstrate that our approach can generalize to other diseases, eventually applying to any intervention and any disease. The feasibility shown by our Phase I results will motivate our Phase II effort where we will focus on dramatically improving the approach, yielding broad coverage of all medical literature and generating human-quality meta-studies. We note that by the end of Phase I we should have a viable end-to-end prototype, focused on IBD, which we can begin taking to market. The final product should significantly benefit our target markets given the Phase II emphasis to improve the technology, user experience, and scope of covered diseases. PUBLIC HEALTH RELEVANCE:  A meta-analysis collects and analyzes the results from multiple studies that are all focused on the same topic, and it can confirm (or refute) the overall effect across the studies, lead to changes in clinical guidelines, or spur new directions for research. However, generating a meta-analysis is an extremely time-consuming process, so many diseases are not covered, and most meta-analyses are not updated to reflect the latest published studies. This work begins to automate the process of creating meta-analyses, overcoming these difficulties in order to make the results published in the medical literature more accessible.",Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials,8977531,R43LM012210,"['Adverse event', 'Algorithms', 'Attention', 'Clinical', 'Computer Systems', 'Computer software', 'Data', 'Data Aggregation', 'Diabetes Mellitus', 'Disease', 'Disease remission', 'Dourine', 'Ensure', 'Evidence Based Medicine', 'Feasibility Studies', 'Goals', 'Grouping', 'Guidelines', 'Hand', 'Health', 'Human', 'Inflammatory Bowel Diseases', 'Intervention', 'Intervention Studies', 'Investigation', 'Lead', 'Leadership', 'Literature', 'Lupus', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Meta-Analysis', 'Modeling', 'Odds Ratio', 'Outcome', 'Outcome Study', 'Output', 'Pattern', 'Performance', 'Phase', 'Placebos', 'Population Sizes', 'Process', 'Publishing', 'Qualifying', 'Randomized Controlled Trials', 'Research', 'Research Personnel', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Text', 'Time', 'Update', 'Work', 'abstracting', 'base', 'experience', 'falls', 'improved', 'novel', 'primary outcome', 'programs', 'prototype', 'software development', 'text searching', 'web interface']",NLM,INFERLINK CORPORATION,R43,2015,150000,0.0005840205543078332
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",8935792,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Internet', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'cluster merger', 'computer science', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2015,2366897,-0.014485696192279539
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,8981015,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2015,508997,-0.017407486725678285
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,8935820,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Health', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2015,146944,0.008519383750219387
"Protect Privacy of Healthcare Data in the Cloud DESCRIPTION (provided by applicant): Cloud computing is gain popularity due to its cost-effective storage and computation. There are few studies on how to leverage cloud computing resources to facilitate healthcare research in a privacy preserving manner. This project proposes an advanced framework that combines rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment. Comparing to traditional centralized data anonymization, we are facing major challenges such as lack of global knowledge and the difficulty to enforce consistency. We adopt differential privacy as our privacy criteria and will leverage homomorphic encryption and Yao's garbled circuit protocol to build secure yet scalable information exchange to overcome the barrier. Project narrative Sustainability and privacy are critical concerns in handling large and growing healthcare data. New challenges emerge as new paradigms like cloud computing become popular for cost-effective storage and computation. This project will develop an advanced framework to combine rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment.",Protect Privacy of Healthcare Data in the Cloud,8925916,R21LM012060,"['Adopted', 'Algorithms', 'Cloud Computing', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Environment', 'Goals', 'Health Services Research', 'Healthcare', 'Individual', 'Institution', 'Intuition', 'Knowledge', 'Laplacian', 'Machine Learning', 'Modeling', 'Privacy', 'Protocols documentation', 'Provider', 'Records', 'Research Infrastructure', 'Research Personnel', 'Secure', 'Security', 'Services', 'Societies', 'Techniques', 'Technology', 'Trust', 'Work', 'base', 'computing resources', 'cost', 'cost effective', 'data sharing', 'encryption', 'light weight', 'novel', 'predictive modeling', 'privacy protection', 'research study', 'tool']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2015,192613,-0.01267420785440177
"Development and Dissemination of Robust Brain MRI Measurement Tools DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: Summary. Neuroimaging provides a safe, non-invasive measurement of the whole brain, and has enabled large clinical and research studies for brain development, aging, and disorders. However, many disorders, i.e., major neurodegenerative and neuropsychiatric disorders, cause complex spatiotemporal patterns of brain alteration, which are often difficult to identify visually and compare over time. To address this critical issu, in the renewal phase of this project, we will continue to work with GE Research to develop and disseminate a software package for brain measurement, comparison, and diagnosis. The new tools include 1) a novel tree-based registration and multi-atlases-based segmentation method for precise measurement of brain alteration patterns, and 2) novel pattern classification and regression methods for early detection and longitudinal monitoring of brain disorders. Aims. Currently, most existing atlas-based labeling methods simply warp each atlas independently to the individual brain for multi-atlases-based structural labeling. This could lead to 1) inaccurate labeling due to possible large registration error when the atlases are very different from the target individual brain, and 2) inconsistent labeling of the same brain structure across different individuals due to independent labeling of each individual brain. The first goal of this project is hence to develop a novel tree-based registration and multi-atlases -based segmentation method for simultaneous registration and joint labeling of all individual brains by concurrent consideration of all atlases. With measurements of brain structures and their alteration patterns, univariate analysis methods are often used to understand how the disease affects brain structure and function at a group level. Although this can lead to better understanding of neurological pathology of brain disorders, more sophisticated image analysis methods are urgently needed for quantitative assessment and early diagnosis of brain abnormality at an individual level. Thus, the second goal of this project is to develop various novel machine learning methods for early diagnosis of brain disorders and better quantification of brain abnormality at an individual level. Specifically, we will take Alzheimer's disease (AD), which is the most common form of dementia, as an example for demonstrating the performance of our proposed methods in early diagnosis of AD, as well as in prediction of long-term outcomes of individuals with mild cognitive impairment (MCI). The last goal of this project is to build, for ou developed methods, the respective software modules for the 3D Slicer (a free open-source software package with a flexible modular platform for medical image analysis and visualization, http://www.slicer.org/), to promote the potential clinical applications by using tools in 3D Slicer for preprocessing of patient data and our tools for diagnosis. Again, this software development work will be performed in collaboration with our current collaborator, GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC) that is focused on developing 3D Slicer. Both source code and pre-compiled programs will be made freely available. Applications. These methods can find their applications in diverse fields, i.e., quantifying brain abnormality of neurological diseases (i.e., AD and schizophrenia), measuring effects of different pharmacological interventions on the brain, and finding associations between structural and cognitive function variables. Description of Project This project aims to develop a novel method for accurate measurement of brain structure and function by groupwise registration and joint labeling of all individual images via multiple manual-labeled atlases. Moreover, several novel tools for brain abnormality measurement will also be developed for early detection and progression monitoring of brain disorders using both multimodal imaging and non-imaging data. By successful development of these brain measurement tools, the respective software modules will be developed and further incorporated into 3D Slicer via collaboration with GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC). Both source code and pre-compiled programs will be made freely available.",Development and Dissemination of Robust Brain MRI Measurement Tools,8923269,R01EB006733,"['Address', 'Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Engineering', 'Functional Magnetic Resonance Imaging', 'Goals', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Multimodal Imaging', 'Nerve Degeneration', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Research', 'Sampling', 'Schizophrenia', 'Slice', 'Source Code', 'Staging', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Update', 'Work', 'abstracting', 'base', 'clinical application', 'cognitive function', 'disease diagnosis', 'flexibility', 'image registration', 'image visualization', 'information classification', 'mild cognitive impairment', 'nervous system disorder', 'neuroimaging', 'neurological pathology', 'neuropsychiatry', 'novel', 'open source', 'programs', 'research study', 'software development', 'spatiotemporal', 'symposium', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,497189,-0.02178762518436726
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8920573,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,3412,0.024920032179193946
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9050942,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Solutions', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,280721,0.024535614896216792
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics. n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8792208,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2015,248295,-0.011303891064457021
"Providing Access to Appliance Displays for Visually Impaired Users DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8916115,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Health', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'contrast enhanced', 'contrast imaging', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2015,368560,0.017249119920066846
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions.                 PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.             ","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",8981552,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2015,149265,0.006795012812032077
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",8980210,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Solutions', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2015,56042,0.008645596845317807
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort.         PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.                ",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,8936340,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Plastics', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Solutions', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'public health relevance', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY,U01,2015,362070,-0.003572853131719967
"Large-Scale Semiparametric Graphical Models with Applications to Neuroscience DESCRIPTION: The objective of this proposal is to develop and theoretically evaluate a unified set of statistical, computational, and software tools to address data mining and discovery science challenges in the analysis of existing vast amounts of publicly available neuroimaging data. In particular, we propose to develop scalable and robust semiparametric solutions for high-throughput estimation of resting-state brain connectivity networks, both at the individual and population levels, with the flexibility of incorporating covariate information.  The work will contribute meaningfully to the theory and methods for large-scale semiparametric graphical models and will apply these methods to the largest collections of resting-state fMRI data available. The proposed methods and theory include key directions of research for brain network estimation and mining. First, we pro- pose novel methods for subject-specific network estimation, such as would be needed for biomarker development in functional brain imaging. Secondly, we define and propose to evaluate and implement methods for studying population-level graphs, which study collections of graphs. Thirdly, we propose the use of estimated graphs in predictive modeling. Finally, all of these methods will have complementary software and web services development. Most notably, the idea of population graphs allows for the creation of functional brain network atlases.  In summary, the work of this proposal will result in a unified framework for the analysis of modern neuroimaging data via graphical models. Our methods will further be agnostic to intricacies of the technology, thus making it portable across settings and applicable outside of the field of functional brain imaging. The methods will be carefully evaluated via theory, simulation and data-based application evidence. PUBLIC HEALTH RELEVANCE: Modern neuroimaging data are often Big, Complex, Noisy and Dependent. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of network estimation and mining based on neuroimaging data. Our proposed work represents a significant step forward over the current methodology and has the potential to be applied to analyze a wide range of scientific problems beyond brain imaging data analysis.",Large-Scale Semiparametric Graphical Models with Applications to Neuroscience,8795225,R01MH102339,"['Address', 'Algorithms', 'Atlases', 'Attention deficit hyperactivity disorder', 'Big Data', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Characteristics', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Dependence', 'Development', 'Disease', 'Documentation', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Graph', 'Health', 'Heterogeneity', 'Image', 'Individual', 'Internet', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Neurosciences', 'Pattern', 'Population', 'Population Study', 'Process', 'Rest', 'Sampling', 'Science', 'Signal Transduction', 'Site', 'Software Tools', 'Solutions', 'Statistical Methods', 'Tail', 'Technology', 'Work', 'abstracting', 'base', 'brain research', 'cloud based', 'data mining', 'flexibility', 'interest', 'neuroimaging', 'novel', 'predictive modeling', 'psychologic', 'simulation', 'theories', 'user friendly software', 'web services']",NIMH,PRINCETON UNIVERSITY,R01,2015,369756,0.019681878015180905
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities.         PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.                ","COINSTAC: decentralized, scalable analysis of loosely coupled data",8975906,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Left', 'Letters', 'Linear Models', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Solutions', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'computing resources', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2015,727692,0.008281842725388061
"Improving the Detection of Activation in High Resolution fMRI using Multivariate DESCRIPTION (provided by applicant): The overall goal of this project is to develop a local multivariate analysis software package for fMRI data analysis. It will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods. This project will lead to better brain activation maps and thus promote the discovery of currently unknown aspects of brain function. Mass-univariate analysis, such as the general linear model (GLM), is the prevailing fMRI data analysis method. However, it suffers from blurring of edges of activation and potential elimination of the detection of weak activated regions due to routinely applied fixed isotropic spatial Gaussian smoothing. Local multivariate methods such as canonical correlation analysis (CCA) and its variants have been shown to significantly increase the detection power of fMRI activations and improve activation maps. As an advantage, CCA uses adaptive spatial filtering kernels to accurately extract the signal better in a noisy environment. However, there are several drawbacks, particularly low spatial specificity, long computational time, and single-factor experimental design limitation. Furthermore, a parametric estimation method does not exist to determine the family-wise error rate, no extension to group analysis has been investigated, and no studies extending local CCA to nonlinear CCA for fMRI data using kernel methods have been systematically carried out. All these drawbacks prevent local CCA methods from being widely accepted in neuroscience research in fMRI. In this proposal, our goals are to eliminate these drawbacks using novel local multivariate analysis methods (based on CCA) and to develop a software tool to widen its broader application in the neuroscience research community. We expect this software tool to be particularly valuable for neuroscience research where detections of weak activations or spatially localized patterns of activations are desired. As high resolution imaging and computer power advance, we expect an increase in demand for this software tool, thus advancing new discoveries of brain function and more precise spatial localization of activations. As a particular application, we will focus on studying memory actions using a novel event-related recognition paradigm to investigate the effects of familiarity and recollection in subregions of the medial temporal lobes (MTL) for high resolution fMRI. This research will advance our understanding of hippocampal/MTL contributions to memory, which can substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer¿s disease, schizophrenia, and major depression. More generally, it will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods. PUBLIC HEALTH RELEVANCE: The proposed research is highly relevant to public health because advanced mathematical and statistical methods will allow better analysis of high-resolution fMRI data leading to better characterization of cortical function. For this project we choose to focus on studying memory activation in the medial temporal lobes using high-resolution imaging and multivariate analysis which could substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer's disease, schizophrenia, and major depression. Our proposed fMRI analysis methods also have great potential for significantly advancing our understanding of other neurological and psychiatric conditions.",Improving the Detection of Activation in High Resolution fMRI using Multivariate,8841351,R01EB014284,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Environment', 'Estimation Techniques', 'Event', 'Experimental Designs', 'Face', 'Familiarity', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Hemorrhage', 'Hippocampus (Brain)', 'Image Analysis', 'Individual', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Major Depressive Disorder', 'Maps', 'Medial', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multivariate Analysis', 'Neighborhoods', 'Neurologic', 'Neurosciences Research', 'Occupations', 'Pattern', 'Problem Solving', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Software Tools', 'Solutions', 'Specificity', 'Statistical Methods', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Variant', 'Weight', 'base', 'density', 'digital imaging', 'improved', 'interest', 'mathematical methods', 'memory recognition', 'mild cognitive impairment', 'novel', 'prevent', 'statistics', 'theories', 'tool', 'user friendly software']",NIBIB,CLEVELAND CLINIC LERNER COM-CWRU,R01,2015,275802,0.008044240188181931
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals.         PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.                ",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9041723,K01ES026839,"['Accounting', 'Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resected', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Solutions', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Work', 'base', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep epilepsy', 'spatial temporal variation', 'standard of care', 'statistics', 'tool', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2015,138213,-0.0065444769720501795
"Enabling access to printed text for blind people via assisted mobile OCR     DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality.         PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.                ",Enabling access to printed text for blind people via assisted mobile OCR,8812658,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Solutions', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'public health relevance', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2015,191510,0.00238415653604037
"Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction DESCRIPTION (provided by applicant): In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function. Although fMRI research has primarily focused on identifying brain regions that are activated during performance of cognitive tasks, there is growing interest in examining how cognitive functions emerge as a result of context-dependent, dynamic causal interactions between distributed brain regions. Devising and validating methods for investigating such interactions has therefore taken on great significance. The first major goal of this proposal is to address a critical need in fMRI research by developing novel algorithms for identifying context-dependent dynamic causal interactions between distributed brain regions. To this end, we will develop and validate novel computational methods using Multivariate Dynamical Systems based Markov chain Monte Carlo (MDS-MCMC) algorithms that overcome major limitations of existing methods for investigating dynamic causal interactions and connectivity in the human brain. A comprehensive validation framework will be use evaluate MDS-MCMC and compare it with existing dynamic causal estimation methods. The second major goal of this proposal is to use the MDS-MCMC framework to investigate dynamic causal interactions underlying cognition in normal healthy adults, and in patients with Parkinson's disease (PD). Cognitive impairment is one of the most devastating symptoms in PD. Once thought of as an insignificant feature of the disease, it is now clear that cognitive impairment is present in the majority of PD patients and that this impairment is significantly linked to increased disability and the risk of mortality, yetlittle is known about the brain basis of cognitive impairment in PD. The computational algorithms we develop, validate, and apply here will allow us to rigorously investigate brain dynamics support critical cognitive processes in the human brain, leading to a more complete understanding of fundamental mechanisms underlying human brain function and dysfunction. Our proposed studies will also, for the first time, examine casual interactions in simulated, open-source, opto-genetic, experimental and clinical brain imaging data using state-of-the-art sub-second high-temporal resolution fMRI, based on the Human Connectome Project (HCP). Critically, we will maintain a tight link between our computational and systems neuroscience goals algorithms to solve important problems in cognitive, systems and clinical neuroscience. Together, our proposed studies will lead to new and improved computational tools for examining dynamical causal interactions between distributed brain regions, with broad applications to the HCP and clinical neuroscience. The proposed studies are highly relevant to the mission of the NIH Innovations in Biomedical Computational Science and Technology and the Big Data to Knowledge Programs, which seek to encourage development and dissemination of innovative advanced computational tools for brain imaging and neuroscience. We will disseminate our algorithms and software to the research community via NITRC . PUBLIC HEALTH RELEVANCE: In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function and dysfunction. Although fMRI studies of brain function have primarily focused on identifying brain regions that are activated during performance of perceptual or cognitive tasks, there is growing consensus that cognitive functions emerge as a result of dynamic context-dependent interactions between multiple brain areas. Developing new computational methods for investigating causal interactions in fMRI data has therefore taken added significance; the overall goal of this proposal is to address this critical need by developing new methods for studying causal interactions and brain connectivity between distributed brain regions during cognition.",Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction,8866489,R01NS086085,"['Address', 'Adult', 'Algorithmic Software', 'Algorithms', 'Area', 'Basal Ganglia', 'Base of the Brain', 'Benchmarking', 'Big Data', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive deficits', 'Communities', 'Computational Science', 'Computational algorithm', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Development', 'Disease', 'Experimental Genetics', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Human', 'Impaired cognition', 'Impairment', 'Individual Differences', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Neurosciences', 'Parietal', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Play', 'Prefrontal Cortex', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Resource Sharing', 'Risk', 'Role', 'Short-Term Memory', 'Software Tools', 'Symptoms', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'cognitive function', 'cognitive load', 'cognitive process', 'cognitive system', 'cognitive task', 'computerized tools', 'disability', 'improved', 'in vivo', 'innovation', 'interest', 'mortality', 'novel', 'open source', 'optogenetics', 'programs', 'public health relevance', 'simulation', 'temporal measurement', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2015,507610,-0.0013386738887771865
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8920676,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'quantitative imaging', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2015,323033,-0.003945026604728852
IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS. Surveillance Epidemiology and End Results (SEER) Electronic Data Capture Software Support and Installations. n/a,IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS.,9162089,61201500033I,"['Artificial Intelligence', 'Award', 'Computer software', 'Contracts', 'Data', 'Diagnostic Imaging', 'Electronics', 'Hour', 'Laboratories', 'Maintenance', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2015,1135265,-0.015195368834612876
"EEGLAB: Software for Analysis of Human Brain Dynamics DESCRIPTION (provided by applicant): A major shift in scientific perspective on the nature and use of electrophysiological brain data is now ongoing a shift from measurement and visualization of individual channel signals (in the 'recording channel space') to visualizing and interpreting the data directly within a suitable inverse model representing activity reaching the electrodes by volume conduction from a set of effective data sources in native 'brain source space'. An equivalent shift, via the development and exploitation of an appropriate inverse imaging model, made possible the phenomenon of structural and functional magnetic resonance imaging (fMRI). While the electrophysiological inverse problem is still difficult, dramatic progress has been and is being made through combined use of multimodal imaging and modern statistical signal processing methods. Recovering the considerable degree of spatial source resolution available in high-density scalp electroencephalographic (EEG) and other electrophysiological data, while retaining its natural advantage over other functional imaging methods in temporal resolution, has begun to yield a steady stream of new information about patterns of distributed brain processing supporting human behavior and experience. Relative to other brain imaging modalities, EEG has substantial and increasing cost and mobility advantages, making promotion of new EEG methods for source space analysis of increasing interest and importance for brain and health research. However, applying new source signal and signal processing models to electrophysiological data is complex and increasingly involves application of modern mathematical methods whose details are not within the training of most health research professionals. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University of California San Diego, began as a set of EEG data analysis running on MATLAB (The Mathworks, Inc.) released on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now, more than ten years later, the EEGLAB reference paper (Delorme & Makeig, 2004) has over 2,350 Google scholar citations (increasing at above 1 per day), the opt-in EEGLAB discussion email list links over 5,000 researchers, the news list over 9,000, and a recent survey of 687 researcher respondents reports EEGLAB to be the software environment most widely used for electrophysiological data analysis worldwide. EEGLAB is thus now a de facto standard supporting a wide range of EEG and other electrophysiological research studies and teaching labs. At least 35 EEGLAB plug-in toolsets have now been released by researchers from many laboratories. Under NIH PAR 11-028 we propose renewal funding to further develop and maintain the EEGLAB software framework. We propose new and better tools for brain source and source network modeling and localization, an expanded online EEGLAB course and workshop, better statistical inference modeling of group data, and new support for automated source decomposition, measure computation, data duration, and data sharing. PUBLIC HEALTH RELEVANCE: A major shift in scientific perspective on the nature and use of human electrophysiological data is now accelerating from measuring and visualizing individual scalp channel signals to directly visualizing and interpreting their brain sources. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University Of California San Diego (UCSD), supports a large number of EEG and related electrophysiological research studies and teaching labs. We propose continued funding to further develop and maintain the EEGLAB environment.",EEGLAB: Software for Analysis of Human Brain Dynamics,8900348,R01NS047293,"['Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Clinical', 'Cloud Computing', 'Code', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Educational process of instructing', 'Educational workshop', 'Electrodes', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Event-Related Potentials', 'Eye', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Health', 'Human', 'Image', 'Imagery', 'Individual', 'Internet', 'Joints', 'Laboratories', 'Links List', 'Machine Learning', 'Measurement', 'Measures', 'Memory', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multimodal Imaging', 'Nature', 'Neurosciences', 'Output', 'Paper', 'Pattern', 'Performance', 'Physiology', 'Plug-in', 'Positioning Attribute', 'Procedures', 'Process', 'Relative (related person)', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Scalp structure', 'Signal Transduction', 'Source', 'Speed', 'Stream', 'Surveys', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'computational neuroscience', 'computing resources', 'cost', 'cranium', 'data sharing', 'density', 'design', 'experience', 'flexibility', 'imaging modality', 'improved', 'innovation', 'interest', 'mathematical methods', 'network models', 'news', 'open source', 'research study', 'signal processing', 'symposium', 'temporal measurement', 'tool', 'web site', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2015,484584,0.023171171580739405
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8798661,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'spectrograph', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2015,228148,-0.003392513311242414
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8775624,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2015,90000,-0.004738745155597785
"Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero DESCRIPTION (provided by applicant): Accurate mapping of normal and abnormal patterns of brain development in fetuses and premature neonates is a key factor in the early detection of developmental disorders as well as understanding how external factors can influence early brain growth. The combination of fast multi-slice MRI techniques with computer vision algorithms has recently provided the ability to reliably image 3D brain structure in-utero providing valuable information inaccessible to ultrasound imaging. To complement this new structural information, recently there has been increasing interest in the use of functional MR imaging (fMRI) to map the development of resting state brain function in children, premature neonates and, most recently, fetuses in-utero. This work has revealed signs of a predictable developmental path in the formation of resting state patterns of brain activity present in adults and abnormalities in these patterns in children have been linked with neurological and neuropsychiatric conditions in later life. Such fMRI methods, previously used in adults and children, could provide a unique new window into functional activity in the developing fetal brain. However, the imaging techniques required suffer from an important limitation for use in the fetus: they make use of repeated acquisitions where subtle changes in MR signal provide the measure of interest. Fetal head motion within the scanner perturbs both measurement location and signal level due to the changing relationship between fetal anatomy, maternal anatomy and the scanner. Based on our preliminary results, in this proposal we plan to develop a set of new signal and geometry correction methods specifically for fetal fMRI that combine novel acquisition techniques with post-processing algorithms to provide a new route to addressing these unique problems. This will allow us to collect the first accurate functional MRI data from a range of un-sedated fetuses in ages and activity levels seen in clinical studies. We will develop and validate these methods together with complementary pattern analysis techniques specifically aimed at motion scattered data and employ them to build the first combined 4D structure-function map of brain development in-utero. This will show for the first time the temporal and spatial relationship between structural changes and the development of resting state patterns of brain activity covering the critical age of first clinical MRI scan and the following period of cortical folding. his will help answer such questions as: which tissue zones of the fetal brain such activity begins, and whether the functional patterns are related to the timing of the formation of specific cortical folds. We will collect a range of data that captures fetuses both at different ages and different states of activity representing those seen in typical clinical studies, and in addition collect valuable outcome measures on the babies after birth against which in-utero measure will be evaluated. We release the data to the community as a whole in the form of an open-access 4D atlas. This combined structure-function data will provide a unique new reference for both neuroscience and, in the longer term, clinical evaluation of brain health during pregnancy and premature birth. PUBLIC HEALTH RELEVANCE: Clinically, improved in-utero evaluation of the fetal brain is a key concern for obstetricians and pediatricians in managing complex pregnancies and there is also now an increasing public health awareness of the influence of the in-utero environment, in terms of factors such as stress and diet, on long-term health in adult life. Functional connectivit imaging of the brain in childhood has revealed the presence of early markers of later cognitive and neuropsychological problems. The ability to map these same properties in utero, promises to provide a rich set of very specific early markers that can be used to understand the impact of the in-utero environment on brain function and feasibly provide a route to the use of early neuro-protective agents and procedures early in childhood.",Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero,8856234,R01EB017133,"['Accounting', 'Acoustic Stimulation', 'Acoustics', 'Address', 'Adult', 'Age', 'Algorithms', 'Anatomy', 'Atlases', 'Awareness', 'Biological Markers', 'Birth', 'Brain', 'Brain Mapping', 'Brain imaging', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Dependency', 'Detection', 'Development', 'Diet', 'Early Diagnosis', 'Early identification', 'Echo-Planar Imaging', 'Elderly', 'Environment', 'Evaluation', 'Fetal Heart Rate', 'Fetal Movement', 'Fetus', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Gestational Age', 'Goals', 'Growth', 'Head', 'Health', 'Heart Rate', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Left', 'Life', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Midbrain structure', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neonatal', 'Network-based', 'Neurologic', 'Neurosciences', 'Outcome Measure', 'Pattern', 'Positioning Attribute', 'Predisposition', 'Pregnancy', 'Premature Birth', 'Prematurity of fetus', 'Procedures', 'Process', 'Property', 'Protective Agents', 'Protocols documentation', 'Public Health', 'Recording of previous events', 'Reporting', 'Rest', 'Route', 'Scheme', 'Series', 'Signal Transduction', 'Slice', 'Source', 'Staging', 'Stimulus', 'Stress', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'base', 'brain tissue', 'design', 'developmental disease', 'experience', 'fetal', 'imaging modality', 'imaging system', 'improved', 'in utero', 'interest', 'neonate', 'neuropsychiatry', 'neuropsychological', 'novel', 'pediatrician', 'population based', 'premature', 'research clinical testing', 'spatial relationship', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2015,614823,-0.024805737859410155
"Quantitative Methods for Neuroimaging Studies of Interventions in Aging    DESCRIPTION (provided by applicant): This proposal for an NIH Mentored Quantitative Research Career Award requests support for Dr. Yongmei Michelle Wang as she embarks on a faculty career focused on imaging studies which examine the influence of longitudinal interventions on brain structure and function, and its relationship to cognition and performance, in older adults. The application proposes a research career development plan in the field of neuroimaging, bridging engineering, statistics, and neuroscience. The plan includes two overlapping phases: 1) a didactic phase that emphasizes training, including coursework and laboratory work in the area of cognitive neuroscience, imaging, aging, and interventions to complement Dr. Wang's doctoral training in Electrical Engineering and existing experience in Statistics; and 2) a development phase that focuses on intense development of the proposed research. These two phases will be closely supervised by the mentor and advisor in the area of cognitive neuroscience, brain plasticity, biomedical imaging, aging and interventions. Neuroimaging techniques, such as magnetic resonance imaging (MRI) and functional MRI (fMRI), have been shown to be powerful for characterizing and understanding the structure and function of the human brain. There remains a need, however, for robust and efficient statistical image analysis methods due to the limitations of existing approaches. It is crucial that these analysis techniques be developed with a full understanding of the neuroimaging methods used and the relevant cognitive neuroscience. We propose to develop, implement, and validate integrated computational algorithms for reliable and sensitive analysis of brain MRI and fMRI images, with the following specific aims: 1) Develop, validate and combine novel and efficient univariate and multivariate morphometry analysis methods. 2) Develop and evaluate integrated functional hemodynamic response and connectivity study approaches. 3) Apply these methods to the MRI and fMRI data being collected from separately funded NIA project of the mentor, to examine the effects of aerobic fitness training on brain structure and function of older adults; the neuroscience hypothesis to be tested are: improvements in aerobic fitness, over the course of a 1 year intervention, will result in i) increases in gray and white matter volume and shape changes of subcortical structures of the human brain; and ii) changes in the underlying neural circuits. 4) Develop a brain image analysis toolbox implementing the above methods.        PUBLIC HEALTH RELEVANCE: The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.              PROJECT NARRATIVE The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.",Quantitative Methods for Neuroimaging Studies of Interventions in Aging,8723715,K25AG033725,"['Adult', 'Aerobic', 'Age', 'Aging', 'Algorithms', 'American', 'Area', 'Attention', 'Award', 'Awareness', 'Bayesian Method', 'Behavior', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Computational algorithm', 'Conflict (Psychology)', 'Data', 'Detection', 'Deterioration', 'Development', 'Development Plans', 'Dimensions', 'Economic Burden', 'Elderly', 'Electrical Engineering', 'Engineering', 'Exhibits', 'Faculty', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Health', 'Hippocampus (Brain)', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Intervention', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Markov Chains', 'Medial', 'Memory', 'Mentors', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Multivariate Analysis', 'Neurosciences', 'Noise', 'Parietal', 'Participant', 'Pattern', 'Performance', 'Phase', 'Physical activity', 'Population', 'Prefrontal Cortex', 'Public Health', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Risk Behaviors', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Statistical Methods', 'Structure', 'Surface', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'age related', 'aging brain', 'aging mind', 'attentional control', 'base', 'bioimaging', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'cognitive performance', 'cognitive process', 'executive function', 'experience', 'fitness', 'flexibility', 'gray matter', 'healthy aging', 'hemodynamics', 'imaging biomarker', 'improved', 'interest', 'intervention effect', 'morphometry', 'neural circuit', 'neuroimaging', 'new technology', 'novel', 'public health relevance', 'quantitative imaging', 'relating to nervous system', 'relational memory', 'research study', 'response', 'sedentary', 'shape analysis', 'social', 'spatial memory', 'statistics', 'therapy design', 'tool', 'white matter', 'young adult']",NIA,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K25,2015,150833,-0.008538072512311477
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8795182,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2015,195445,0.018764259543869635
"Large-scale Automated Synthesis of Functional Neuroimaging Data DESCRIPTION (provided by applicant): The explosive growth of the human neuroimaging literature has led to major advances in understanding of normal and abnormal human brain function, but has also made aggregation and synthesis of neuroimaging findings increasingly difficult. The goal of this project is to develop an automated software platform for large-scale synthesis of human functional neuroimaging studies. Our work builds directly on an existing software platform (NeuroSynth) and involves key extensions and improvements that focus on (i) aggregation, (ii) coding, (iii) synthesis, and (iv) sharing of functional neuroimaging data. In Aim 1, we will use computational linguistics and bioinformatics data mining techniques to develop new algorithms for automatically extracting activation foci and associated metadata from published neuroimaging articles. In Aim 2, we will use topic-modeling techniques such as Latent Dirichlet Analysis in combination with existing cognitive ontologies such as the Cognitive Atlas to develop structured representations of automatically extracted neuroimaging data. In Aim 3, we will improve the meta-analysis and classification capacities of our existing platform by implementing a state-of- the-art hierarchical Bayesian meta-analysis method recently developed by the research team. Finally, in Aim 4, we will develop a state-of-the-art web interface (://neurosynth.org) that supports real-time, in-browser access to the data, results, and tools produced in Aims 1 - 3. Realizing these objectives will introduce powerful new tools for organizing and synthesizing the neuroimaging literature on an unprecedented scale. These tools will be freely and publicly available to anyone with an internet connection, enabling rapid and efficient application to a broad range of clinical and basic research applications. Functional neuroimaging techniques such as fMRI have opened a new frontier in efforts to investigate and understand the neural mechanisms of normal and abnormal cognition. However, the rapidly expanding scope of the literature makes distillation and synthesis of brain imaging findings increasingly challenging. The goal of this project is to develop a new software platform for automated aggregation, synthesis, and sharing of published neuroimaging results, with the potential to advance understanding of mechanisms underlying mental health disorders.",Large-scale Automated Synthesis of Functional Neuroimaging Data,8894083,R01MH096906,"['Algorithms', 'Atlases', 'Basic Science', 'Bayesian Method', 'Bayesian Modeling', 'Bioinformatics', 'Biometry', 'Brain', 'Brain imaging', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognition', 'Cognitive', 'Communities', 'Computational Linguistics', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Development', 'Ensure', 'Environment', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'High Performance Computing', 'Human', 'Individual', 'Interdisciplinary Study', 'Internet', 'Joints', 'Journals', 'Language', 'Literature', 'Manuals', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Neurosciences', 'Ontology', 'Paper', 'Performance', 'Population', 'Publishing', 'Qualifying', 'Research', 'Research Personnel', 'Resources', 'Sample Size', 'Specificity', 'Structure', 'Techniques', 'Text', 'Time', 'Training', 'Validation', 'Work', 'awake', 'base', 'cognitive function', 'cognitive process', 'data mining', 'frontier', 'improved', 'information organization', 'interoperability', 'knowledge base', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'open source', 'psychologic', 'theories', 'tool', 'web interface']",NIMH,"UNIVERSITY OF TEXAS, AUSTIN",R01,2015,547000,0.012962139735182924
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,8815314,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Health', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Injury', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'falls', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2015,550561,0.023481348593965695
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair     DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning.          PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.             ",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8838311,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Build-it', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Reliance', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2014,155663,0.015452473390648824
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8628140,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2014,59383,-0.008587363491563908
"Face De-Identification for Research and Clinical Use     DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis.         PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.            ",Face De-Identification for Research and Clinical Use,8772435,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'public health relevance', 'sex', 'social stigma', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2014,194915,-0.03802332503370484
"GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY     DESCRIPTION:  Many complex diseases such as cancer, cardiovascular disorders, and schizophrenia may be understood as failures in the functioning of nested hierarchies of biomolecular and cellular networks. These nested hierarchies control a range of processes including the differentiation and migration of cells, remodeling of extracellular matrices and tissues, and information encoding in neuronal subsystems. Washington University has established expertise in cutting edge imaging, molecular biology and genomic technologies synergistic with computational approaches such as machine learning and unraveling the principles of hierarchical organization and dynamics of complex systems. This collective expertise is being leveraged to develop new drugs, improve our ability to interpret sophisticated imaging data, understand how populations of neurons act collectively to accomplish complex tasks, and model the onset and progression of complex diseases as dynamical rewiring of hierarchical, multi-scale networks. Biological network analyses provide a rich set of tools for organizing and interpreting the vast quantities of data produced by state-of-the-art experimental protocols. The rapid advancement of computationally intensive research in these areas is outstripping the capabilities of CPU-based high performance computing (HPC) systems. This application would support the acquisition and integration of a large-scale IBM high performance cluster of Graphics Processor Units (GPUs) to be added as an upgrade to the existing IBM-designed Heterogeneous High Performance Computing environment to form a state-of-the-art hybrid computing capability. Such a resource is essential to match the growing need for high performance computing at Washington University and to support state of the art research software applications that are optimized for GPU computing. The acquisition and integration of a high performance GPU cluster will solve critical computing challenges that exist within Washington University's growing NIH research portfolio. The proposed state-of-the-art hybrid GPU/CPU computing capabilities will be deployed within the framework of a stable, productive and rapidly growing resource center. The addition of high-capacity GPU computing capabilities will allow critical calculation to be performed in hours instead of days and enable substantial increases in productivity for existing projects covering a broad range of application areas as well as enabling new research directions.             n/a",GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY,8640341,S10OD018091,"['Area', 'Biological', 'Biology', 'Cardiovascular Diseases', 'Complex', 'Computer Systems', 'Computer software', 'Data', 'Disease', 'Environment', 'Extracellular Matrix', 'Failure', 'Genomics', 'High Performance Computing', 'Hour', 'Hybrids', 'Image', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular Biology', 'Neurons', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Productivity', 'Protocols documentation', 'Research', 'Resources', 'Schizophrenia', 'System', 'Technology', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'cell motility', 'computing resources', 'design', 'improved', 'innovation', 'tool']",OD,WASHINGTON UNIVERSITY,S10,2014,597700,-0.007291725248935983
"The Crystallography of Macromolecules    DESCRIPTION (provided by applicant): The proposal ""The Crystallography of Macromolecules"" addresses the limitations of diffraction data analysis methods in the field of X-ray crystallography. The significance of this work is determined by the importance of the technique, which generates uniquely-detailed information about cellular processes at the atomic level. The structural results obtained with crystallography are used to explain and validate results obtain by other biophysical, biochemical and cell biology techniques, to generate hypotheses for detailed studies of cellular process and to guide drug design studies - all of which are highly relevant to NIH mission. The proposal focuses on method development to address a frequent situation, where the crystal size and order is insufficient to obtain a structure from a single crystal. This is particularly frequent in cases of large eukaryotic complexes and membrane proteins, where the structural information is the most valuable to the NIH mission. The diffraction power of a single crystal is directly related to the microscopic order and size of that specimen. It is also one of the main correlates of structure solution success. The method used to solve the problem of data insufficiency in the case of a single crystal is to use multiple crystals and to average data between them, which allows to retrieve even very low signals. However, different crystals of the same protein, even if they are very similar i.e. have the same crystal lattice symmetry and very similar unit cell dimensions, still are characterized by a somewhat different order. This non-isomorphism is often high enough to make their solution with averaged data impossible. Moreover, the use of multiple data sets complicates decision making as each of the datasets contains different information and it is not clear when and how to combine them. The proposed solution relies on hierarchical analysis. First, the shape of the diffraction spot profiles will be modeled using a novel approach (Aim 1). This will form the ground for the next step, in which deconvolution of overlapping Bragg spot profiles from multiple lattices will be achieved (Aim 2). An additional benefit of algorithms developed in Aim 1 is that they will automatically derive the integration parameters and identify artifacts, making the whole process more robust. This is particularly significant for high-throughput and multiple crystal analysis. In Aim 3, comparison of data from multiple crystals will be performed to identify subsets of data that should be merged to produce optimal results. The critical aspect of this analysis will be the identification and assessment of non- isomorphism between datasets. The experimental decision-making strategy is the subject of Aim 4. The Support Vector Machine (SVM) method will be used to evaluate the suitability of available datasets for possible methods of structure solution. In cases of insufficient data it will identify the most significant factor that needs to be improved. Aim 5 is to simplify navigation of data reduction and to integrate the results of previous aims with other improvements in hardware and computing.        The goal of the proposal is to develop methods for analysis of X-ray diffraction data with a particular focus on the novel analysis of diffraction spot shape and the streamlining of data analysis in multi-crystal modes. The development of such methods is essential to advance structural studies in thousands of projects, which individually are important for NIH mission.           ",The Crystallography of Macromolecules,8657051,R01GM053163,"['Address', 'Algorithms', 'Biochemical', 'Budgets', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Complex', 'Computer software', 'Computers', 'Crystallography', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Development', 'Drug Design', 'Evaluation', 'Funding', 'Geometry', 'Goals', 'Image', 'Machine Learning', 'Membrane Proteins', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Output', 'Pattern', 'Problem Solving', 'Procedures', 'Process', 'Proteins', 'Relative (related person)', 'Research', 'Shapes', 'Signal Transduction', 'Solutions', 'Specimen', 'Spottings', 'Structure', 'Techniques', 'Technology', 'Twin Multiple Birth', 'United States National Institutes of Health', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'base', 'beamline', 'cell dimension', 'data reduction', 'detector', 'experience', 'improved', 'indexing', 'macromolecule', 'method development', 'novel', 'novel strategies', 'programs', 'success', 'user-friendly']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2014,320096,-0.02583997302670392
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",8774373,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Internet', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2014,2087641,-0.014485696192279539
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8734495,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Learning Module', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'handheld mobile device', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'signal processing', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2014,417876,0.005998610722516747
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8689173,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2014,202714,-0.008608743343428994
"Scalable Biomedical Pattern Recognition Via Deep Learning DESCRIPTION (provided by applicant): Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.  The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is  being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.  Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.  In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes. Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,9302040,R21LM011664,[' '],NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2014,7696,-0.008608743343428994
"Micromachined microphones with in-plane and out-of-plane directivity  Project Summary We aim to introduce to the hearing-assistive device industry the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or ""window"" of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired ""rocking"" style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. In Phase II, we aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete 3-axis pressure gradient sensor. PUBLIC HEALTH RELEVANCE: Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the ""cocktail party"" effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified - making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.            ",Micromachined microphones with in-plane and out-of-plane directivity,8648777,R43DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Goals', 'Hearing', 'Hearing Aids', 'Industry', 'Investigation', 'Laboratories', 'Microfabrication', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Phase', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Structure', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'public health relevance', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R43,2014,149828,-0.016527516963919856
"Nonparametric Bayes Methods for Big Data in Neuroscience     DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond.         PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.            ",Nonparametric Bayes Methods for Big Data in Neuroscience,8830000,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Commit', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2014,151804,0.008519383750219387
"Protect Privacy of Healthcare Data in the Cloud     DESCRIPTION (provided by applicant): Cloud computing is gain popularity due to its cost-effective storage and computation. There are few studies on how to leverage cloud computing resources to facilitate healthcare research in a privacy preserving manner. This project proposes an advanced framework that combines rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment. Comparing to traditional centralized data anonymization, we are facing major challenges such as lack of global knowledge and the difficulty to enforce consistency. We adopt differential privacy as our privacy criteria and will leverage homomorphic encryption and Yao's garbled circuit protocol to build secure yet scalable information exchange to overcome the barrier.             Project narrative Sustainability and privacy are critical concerns in handling large and growing healthcare data. New challenges emerge as new paradigms like cloud computing become popular for cost-effective storage and computation. This project will develop an advanced framework to combine rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment.",Protect Privacy of Healthcare Data in the Cloud,8810023,R21LM012060,"['Adopted', 'Algorithms', 'Cloud Computing', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Environment', 'Goals', 'Health Services Research', 'Healthcare', 'Individual', 'Institution', 'Intuition', 'Knowledge', 'Machine Learning', 'Modeling', 'Privacy', 'Protocols documentation', 'Provider', 'Records', 'Research Infrastructure', 'Research Personnel', 'Secure', 'Security', 'Services', 'Societies', 'Techniques', 'Technology', 'Trust', 'Work', 'base', 'computing resources', 'cost', 'cost effective', 'data sharing', 'encryption', 'light weight', 'novel', 'predictive modeling', 'research study', 'tool']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2014,183155,-0.01267420785440177
"Development and Dissemination of Robust Brain MRI Measurement Tools     DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: Summary. Neuroimaging provides a safe, non-invasive measurement of the whole brain, and has enabled large clinical and research studies for brain development, aging, and disorders. However, many disorders, i.e., major neurodegenerative and neuropsychiatric disorders, cause complex spatiotemporal patterns of brain alteration, which are often difficult to identify visually and compare over time. To address this critical issu, in the renewal phase of this project, we will continue to work with GE Research to develop and disseminate a software package for brain measurement, comparison, and diagnosis. The new tools include 1) a novel tree-based registration and multi-atlases-based segmentation method for precise measurement of brain alteration patterns, and 2) novel pattern classification and regression methods for early detection and longitudinal monitoring of brain disorders. Aims. Currently, most existing atlas-based labeling methods simply warp each atlas independently to the individual brain for multi-atlases-based structural labeling. This could lead to 1) inaccurate labeling due to possible large registration error when the atlases are very different from the target individual brain, and 2) inconsistent labeling of the same brain structure across different individuals due to independent labeling of each individual brain. The first goal of this project is hence to develop a novel tree-based registration and multi-atlases -based segmentation method for simultaneous registration and joint labeling of all individual brains by concurrent consideration of all atlases. With measurements of brain structures and their alteration patterns, univariate analysis methods are often used to understand how the disease affects brain structure and function at a group level. Although this can lead to better understanding of neurological pathology of brain disorders, more sophisticated image analysis methods are urgently needed for quantitative assessment and early diagnosis of brain abnormality at an individual level. Thus, the second goal of this project is to develop various novel machine learning methods for early diagnosis of brain disorders and better quantification of brain abnormality at an individual level. Specifically, we will take Alzheimer's disease (AD), which is the most common form of dementia, as an example for demonstrating the performance of our proposed methods in early diagnosis of AD, as well as in prediction of long-term outcomes of individuals with mild cognitive impairment (MCI). The last goal of this project is to build, for ou developed methods, the respective software modules for the 3D Slicer (a free open-source software package with a flexible modular platform for medical image analysis and visualization, http://www.slicer.org/), to promote the potential clinical applications by using tools in 3D Slicer for preprocessing of patient data and our tools for diagnosis. Again, this software development work will be performed in collaboration with our current collaborator, GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC) that is focused on developing 3D Slicer. Both source code and pre-compiled programs will be made freely available. Applications. These methods can find their applications in diverse fields, i.e., quantifying brain abnormality of neurological diseases (i.e., AD and schizophrenia), measuring effects of different pharmacological interventions on the brain, and finding associations between structural and cognitive function variables.          Description of Project This project aims to develop a novel method for accurate measurement of brain structure and function by groupwise registration and joint labeling of all individual images via multiple manual-labeled atlases. Moreover, several novel tools for brain abnormality measurement will also be developed for early detection and progression monitoring of brain disorders using both multimodal imaging and non-imaging data. By successful development of these brain measurement tools, the respective software modules will be developed and further incorporated into 3D Slicer via collaboration with GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC). Both source code and pre-compiled programs will be made freely available.            ",Development and Dissemination of Robust Brain MRI Measurement Tools,8725502,R01EB006733,"['Address', 'Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Engineering', 'Functional Magnetic Resonance Imaging', 'Goals', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Multimodal Imaging', 'Nerve Degeneration', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Research', 'Sampling', 'Schizophrenia', 'Simulate', 'Slice', 'Source Code', 'Staging', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Update', 'Work', 'abstracting', 'base', 'clinical application', 'cognitive function', 'disease diagnosis', 'flexibility', 'image registration', 'image visualization', 'information classification', 'mild cognitive impairment', 'nervous system disorder', 'neuroimaging', 'neurological pathology', 'neuropsychiatry', 'novel', 'open source', 'programs', 'research study', 'software development', 'spatiotemporal', 'symposium', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2014,499381,-0.02178762518436726
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8704450,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2014,51689,0.024920032179193946
"Building an open-source cloud-based computational platform to improve data access   We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members.  One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. This proposal aims to fill this gap by developing a robust platform that integrates state-of-the-art open-source technologies for data storage, data access, data mining and analysis, annotation, visualization and reporting.  We previously developed a cloud-based BioDatomics platform for Next Generation Sequencing (NGS), BioDX, which has been successful and has been used commercially by several clients. This proposal aims to develop a new platform leveraging our experience with the BioDX platform that integrates: data storage and real-time data querying using Cloudera Impala; powerful and customizable analytics tools using R and its derivative Bioconductor suite of programs for bioinformatics; annotation integration and reporting which is an existing feature of BioDX; and a visual programming interface that will simplify and enhance the development and maintenance of reproducible analytics workflows. We believe this powerful integrated data platform, if successful, will enable real-time collaboration, dramatically reduce data repository costs, and increase the efficiency and efficacy of data analyses for translating experimental data into actionable research products.  We are committed to analyzing stakeholder needs and optimizing hardware, software and information technology systems to meet their demands. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools.  The initial phase of work will involve development of the platform, optimizing performance on the cloud and testing the integration of new technology. BioDatomics is committed to funding the next phase of work which will include usability testing and finalizing a commercial product, following which full commercialization will proceed. Preliminary commercialization plans have demonstrated that the project has the capacity to generate a million dollars in revenue during the first full year after commercial release.  The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This open source platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders. PUBLIC HEALTH RELEVANCE: One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools. The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders.            ",Building an open-source cloud-based computational platform to improve data access,8647860,R43DA036970,"['Academia', 'Apache Indians', 'Bioconductor', 'Bioinformatics', 'Biological', 'Businesses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Clinical', 'Clinical Research', 'Collaborations', 'Commit', 'Complex', 'Computer software', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Drug Industry', 'Environment', 'Expenditure', 'Funding', 'Genomics', 'Government Agencies', 'Growth', 'Imagery', 'Industry', 'Information Dissemination', 'Information Systems', 'Java', 'Language', 'Licensing', 'Link', 'Machine Learning', 'Maintenance', 'Marketing', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Target', 'Mutation', 'Online Systems', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Programming Languages', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk Behaviors', 'Savings', 'Services', 'Software Engineering', 'Software Tools', 'Solutions', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Substance Addiction', 'Substance Use Disorder', 'Substance abuse problem', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Visual', 'Work', 'base', 'beneficiary', 'cloud based', 'commercialization', 'computer infrastructure', 'cost', 'cost effective', 'data mining', 'drug discovery', 'experience', 'improved', 'mathematical model', 'meetings', 'member', 'models and simulation', 'new technology', 'next generation sequencing', 'novel', 'open source', 'programs', 'public health relevance', 'substance abuse treatment', 'success', 'tool', 'usability', 'user-friendly']",NIDA,"BIODATOMICS, LLC",R43,2014,195584,-0.003390201045930936
"Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices     DESCRIPTION (provided by applicant): The inability to access information on printed signs directly impacts the mobility independence of the over 1.2 million blind persons in the U.S. Many previously proposed technological solutions to this problem either required physical modifications to the environment (talking signs or the placement of coded markers) or required the user to carry around specialized computational equipment, which can be stigmatizing. A recently pursued strategy is to utilize the computational capabilities of smart phones and techniques from computer vision to allow blind persons to read signs at a distance using commercially available, non-stigmatizing, smart- phones. However, despite the fact that sophisticated algorithms exist to recognize and extract sign text from cluttered video input (as evidenced, for example, by mapping services such as Google Maps automatically locating and blurring out only license plate text in street-view maps) current mobile solutions for reading sign text at a distance perform relatively poorly. This poor performance is largely because until recently, smart-phone processors have simply not been able to execute state-of-the-art computer vision text extraction and recognition algorithms at real-time rates, which forced previous mobile sign readers to utilize older, simplistic, less effective algorithms. Next-generation smart-phones run on fundamentally different, hybrid processor architectures (such as the Tegra 4, Snapdragon 800, both released in 2013) with dedicated embedded graphical processing units (GPUs) and multi-core CPUs, which make them ideal for high-performance, vision-heavy computation. In this study, we propose to develop a smart-phone-based system for finding and reading signs at a distance which significantly outperforms previous such readers by implementing state-of-the-art text extraction algorithms on modern smart-phone hybrid GPU/CPU processor architectures. In Phase I, the proposed system will be developed and tested with blind users. In Phase II, feedback from user testing will be integrated into system design and the performance will be improved to permit operation in extremely challenging (such as low light) environments.         PUBLIC HEALTH RELEVANCE: Over 1.2 million people in the US are blind, and lack of safe and independent mobility substantially impacts the quality of life of this population. Printed textual signs, which are ubiquitously used in sighted navigation, are inaccessible to visually impaired persons, and this lack of access to environmental information contributes significantly to the mobility problem. This research would help develop a system whereby blind persons could use commercially available smart-phones to locate and read sign text at a distance.            ",Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices,8779810,R43EY024800,"['Acceleration', 'Access to Information', 'Algorithms', 'Antirrhinum', 'Architecture', 'Back', 'Code', 'Computer Vision Systems', 'Distant', 'Environment', 'Equipment', 'Eye', 'Feedback', 'Hybrids', 'Licensing', 'Light', 'Literature', 'Maps', 'Modification', 'Performance', 'Phase', 'Population', 'Printing', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Research Institute', 'Risk', 'Running', 'SKI gene', 'Self-Help Devices', 'Services', 'Solutions', 'System', 'Techniques', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Vision', 'Visually Impaired Persons', 'assistive device/technology', 'authority', 'base', 'blind', 'design', 'experience', 'handheld mobile device', 'improved', 'next generation', 'operation', 'phase 1 study', 'public health relevance', 'volunteer']",NEI,"LYNNTECH, INC.",R43,2014,229742,0.00144679356661556
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8631080,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2014,250003,-0.011303891064457021
"HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/ This proposal describes enhancements to Viocare’s Mobile Food Intake Visual and Voice Recognizer (FIVR)  System, a novel combination of innovative technologies including computer vision and speech recognition to  measure dietary intake using a mobile phone. FIVR uses a mobile phone’s camera to capture a short video  of foods to be consumed, which is then verbally-annotated on the mobile phone by the user. These video  and audio files are processed through a real-time backend server speech and image recognition engine for  food recognition and portion size measurement. This project will extend FIVR’s capabilities to analyze more  foods, enhance the analysis and reporting tools, expand system support tools, and develop interfaces to a  diverse set of clinical and research systems. A final evaluation of the FIVR system will be conducted at The  Ohio State University to assess the usability and accuracy of food intake tracking with a group of 100 freeliving  subjects, comparing 4 days of FIVR food intake data to 4 days of 24 hour recalls collected using  ASA24 data. The resulting FIVR product will be a unique food intake tracker that combines selfadministration,  automation (vision), and backend coding to collect food intake records to generate a detailed  nutritional analysis. n/a","HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/",8947304,61201400054C,"['Architecture', 'Automation', 'Car Phone', 'Clinical Research', 'Code', 'Collection', 'Computer Vision Systems', 'Computerized Medical Record', 'Data', 'Databases', 'Diet', 'Dietary intake', 'Eating', 'Evaluation', 'Food', 'Health', 'Hour', 'Image', 'Individual', 'Location', 'Measurement', 'Measures', 'Methods', 'Nutritional', 'Ohio', 'Output', 'Patients', 'Performance', 'Procedures', 'Process', 'Records', 'Reporting', 'Research Personnel', 'Speech', 'Support System', 'System', 'Systems Analysis', 'Time', 'Universities', 'Vision', 'Visual', 'Voice', 'innovative technologies', 'mobile application', 'novel', 'speech recognition', 'tool', 'usability']",NCI,"VIOCARE, INC.",N44,2014,1000000,-0.009416116221757129
"Providing Access to Appliance Displays for Visually Impaired Users     DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8712492,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2014,368560,0.017249119920066846
"Large-Scale Semiparametric Graphical Models with Applications to Neuroscience     DESCRIPTION: The objective of this proposal is to develop and theoretically evaluate a unified set of statistical, computational, and software tools to address data mining and discovery science challenges in the analysis of existing vast amounts of publicly available neuroimaging data. In particular, we propose to develop scalable and robust semiparametric solutions for high-throughput estimation of resting-state brain connectivity networks, both at the individual and population levels, with the flexibility of incorporating covariate information.  The work will contribute meaningfully to the theory and methods for large-scale semiparametric graphical models and will apply these methods to the largest collections of resting-state fMRI data available. The proposed methods and theory include key directions of research for brain network estimation and mining. First, we pro- pose novel methods for subject-specific network estimation, such as would be needed for biomarker development in functional brain imaging. Secondly, we define and propose to evaluate and implement methods for studying population-level graphs, which study collections of graphs. Thirdly, we propose the use of estimated graphs in predictive modeling. Finally, all of these methods will have complementary software and web services development. Most notably, the idea of population graphs allows for the creation of functional brain network atlases.  In summary, the work of this proposal will result in a unified framework for the analysis of modern neuroimaging data via graphical models. Our methods will further be agnostic to intricacies of the technology, thus making it portable across settings and applicable outside of the field of functional brain imaging. The methods will be carefully evaluated via theory, simulation and data-based application evidence.         PUBLIC HEALTH RELEVANCE: Modern neuroimaging data are often Big, Complex, Noisy and Dependent. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of network estimation and mining based on neuroimaging data. Our proposed work represents a significant step forward over the current methodology and has the potential to be applied to analyze a wide range of scientific problems beyond brain imaging data analysis.                ",Large-Scale Semiparametric Graphical Models with Applications to Neuroscience,8611397,R01MH102339,"['Address', 'Algorithms', 'Atlases', 'Attention deficit hyperactivity disorder', 'Big Data', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Characteristics', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Dependence', 'Development', 'Disease', 'Documentation', 'Exhibits', 'Functional Magnetic Resonance Imaging', 'Graph', 'Heterogeneity', 'Image', 'Individual', 'Internet', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Neurosciences', 'Pattern', 'Population', 'Population Study', 'Process', 'Rest', 'Sampling', 'Science', 'Signal Transduction', 'Site', 'Software Tools', 'Solutions', 'Statistical Methods', 'Tail', 'Technology', 'Work', 'abstracting', 'base', 'brain research', 'cloud based', 'data mining', 'flexibility', 'interest', 'neuroimaging', 'novel', 'predictive modeling', 'psychologic', 'public health relevance', 'simulation', 'theories', 'user friendly software', 'web services']",NIMH,PRINCETON UNIVERSITY,R01,2014,378911,0.019681878015180905
"Improving the Detection of Activation in High Resolution fMRI using Multivariate     DESCRIPTION (provided by applicant): The overall goal of this project is to develop a local multivariate analysis software package for fMRI data analysis. It will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods. This project will lead to better brain activation maps and thus promote the discovery of currently unknown aspects of brain function. Mass-univariate analysis, such as the general linear model (GLM), is the prevailing fMRI data analysis method. However, it suffers from blurring of edges of activation and potential elimination of the detection of weak activated regions due to routinely applied fixed isotropic spatial Gaussian smoothing. Local multivariate methods such as canonical correlation analysis (CCA) and its variants have been shown to significantly increase the detection power of fMRI activations and improve activation maps. As an advantage, CCA uses adaptive spatial filtering kernels to accurately extract the signal better in a noisy environment. However, there are several drawbacks, particularly low spatial specificity, long computational time, and single-factor experimental design limitation. Furthermore, a parametric estimation method does not exist to determine the family-wise error rate, no extension to group analysis has been investigated, and no studies extending local CCA to nonlinear CCA for fMRI data using kernel methods have been systematically carried out. All these drawbacks prevent local CCA methods from being widely accepted in neuroscience research in fMRI. In this proposal, our goals are to eliminate these drawbacks using novel local multivariate analysis methods (based on CCA) and to develop a software tool to widen its broader application in the neuroscience research community. We expect this software tool to be particularly valuable for neuroscience research where detections of weak activations or spatially localized patterns of activations are desired. As high resolution imaging and computer power advance, we expect an increase in demand for this software tool, thus advancing new discoveries of brain function and more precise spatial localization of activations. As a particular application, we will focus on studying memory actions using a novel event-related recognition paradigm to investigate the effects of familiarity and recollection in subregions of the medial temporal lobes (MTL) for high resolution fMRI. This research will advance our understanding of hippocampal/MTL contributions to memory, which can substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer¿s disease, schizophrenia, and major depression. More generally, it will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods.         PUBLIC HEALTH RELEVANCE: The proposed research is highly relevant to public health because advanced mathematical and statistical methods will allow better analysis of high-resolution fMRI data leading to better characterization of cortical function. For this project we choose to focus on studying memory activation in the medial temporal lobes using high-resolution imaging and multivariate analysis which could substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer's disease, schizophrenia, and major depression. Our proposed fMRI analysis methods also have great potential for significantly advancing our understanding of other neurological and psychiatric conditions.                ",Improving the Detection of Activation in High Resolution fMRI using Multivariate,8656325,R01EB014284,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Environment', 'Estimation Techniques', 'Event', 'Experimental Designs', 'Face', 'Familiarity', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hemorrhage', 'Hippocampus (Brain)', 'Image Analysis', 'Individual', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Major Depressive Disorder', 'Maps', 'Medial', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multivariate Analysis', 'Neighborhoods', 'Neurologic', 'Neurosciences Research', 'Occupations', 'Pattern', 'Problem Solving', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Software Tools', 'Solutions', 'Specificity', 'Statistical Methods', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Variant', 'Weight', 'base', 'density', 'digital imaging', 'improved', 'interest', 'mathematical methods', 'memory recognition', 'mild cognitive impairment', 'novel', 'prevent', 'public health relevance', 'statistics', 'theories', 'tool', 'user friendly software']",NIBIB,RYERSON  UNIVERSITY,R01,2014,65141,0.008044240188181931
"Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction     DESCRIPTION (provided by applicant): In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function. Although fMRI research has primarily focused on identifying brain regions that are activated during performance of cognitive tasks, there is growing interest in examining how cognitive functions emerge as a result of context-dependent, dynamic causal interactions between distributed brain regions. Devising and validating methods for investigating such interactions has therefore taken on great significance. The first major goal of this proposal is to address a critical need in fMRI research by developing novel algorithms for identifying context-dependent dynamic causal interactions between distributed brain regions. To this end, we will develop and validate novel computational methods using Multivariate Dynamical Systems based Markov chain Monte Carlo (MDS-MCMC) algorithms that overcome major limitations of existing methods for investigating dynamic causal interactions and connectivity in the human brain. A comprehensive validation framework will be use evaluate MDS-MCMC and compare it with existing dynamic causal estimation methods. The second major goal of this proposal is to use the MDS-MCMC framework to investigate dynamic causal interactions underlying cognition in normal healthy adults, and in patients with Parkinson's disease (PD). Cognitive impairment is one of the most devastating symptoms in PD. Once thought of as an insignificant feature of the disease, it is now clear that cognitive impairment is present in the majority of PD patients and that this impairment is significantly linked to increased disability and the risk of mortality, yetlittle is known about the brain basis of cognitive impairment in PD. The computational algorithms we develop, validate, and apply here will allow us to rigorously investigate brain dynamics support critical cognitive processes in the human brain, leading to a more complete understanding of fundamental mechanisms underlying human brain function and dysfunction. Our proposed studies will also, for the first time, examine casual interactions in simulated, open-source, opto-genetic, experimental and clinical brain imaging data using state-of-the-art sub-second high-temporal resolution fMRI, based on the Human Connectome Project (HCP). Critically, we will maintain a tight link between our computational and systems neuroscience goals algorithms to solve important problems in cognitive, systems and clinical neuroscience. Together, our proposed studies will lead to new and improved computational tools for examining dynamical causal interactions between distributed brain regions, with broad applications to the HCP and clinical neuroscience. The proposed studies are highly relevant to the mission of the NIH Innovations in Biomedical Computational Science and Technology and the Big Data to Knowledge Programs, which seek to encourage development and dissemination of innovative advanced computational tools for brain imaging and neuroscience. We will disseminate our algorithms and software to the research community via NITRC .         PUBLIC HEALTH RELEVANCE: In the past two decades, functional magnetic resonance imaging (fMRI) has emerged as a powerful tool for investigating human brain function and dysfunction. Although fMRI studies of brain function have primarily focused on identifying brain regions that are activated during performance of perceptual or cognitive tasks, there is growing consensus that cognitive functions emerge as a result of dynamic context-dependent interactions between multiple brain areas. Developing new computational methods for investigating causal interactions in fMRI data has therefore taken added significance; the overall goal of this proposal is to address this critical need by developing new methods for studying causal interactions and brain connectivity between distributed brain regions during cognition.                ",Methods for Dynamic Causal Interactions in Human Brain Function and Dysfunction,8774725,R01NS086085,"['Address', 'Adult', 'Algorithmic Software', 'Algorithms', 'Area', 'Basal Ganglia', 'Base of the Brain', 'Benchmarking', 'Big Data', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Computational Science', 'Computational algorithm', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Development', 'Disease', 'Experimental Genetics', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Human', 'Impaired cognition', 'Impairment', 'Individual Differences', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Neurosciences', 'Parietal', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Play', 'Prefrontal Cortex', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resource Sharing', 'Risk', 'Role', 'Short-Term Memory', 'Simulate', 'Software Tools', 'Symptoms', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'cognitive function', 'cognitive system', 'computerized tools', 'disability', 'improved', 'in vivo', 'innovation', 'interest', 'mortality', 'novel', 'open source', 'optogenetics', 'programs', 'public health relevance', 'simulation', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2014,449410,-0.0013386738887771865
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development     DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation.             n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8697162,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Simulate', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2014,333533,-0.003945026604728852
"Manipulating Neural Tissue with Ultra-Short Laser Pulses    DESCRIPTION (provided by applicant):  We seek to renew our joint discovery and technology based bioengineering research partnership (BRP).  Our program advances the use of amplified ultrashort laser pulses as a tool to manipulate living and histological tissue.  This unique technology, pioneered by the BRP team, permits tissue to be cut on the micrometer scale by light-fueled plasma-meditated ablation.  Cutting occurs without thermal damage and can be combined with spectroscopic feedback to identify and limit the region being perturbed.  We advance this technology in new ways, including the use of temporal focusing for deep ablation, and apply it to three key test beds.  The first is construction of the angiotome, i.e., a complete vectorized map of cortical vasculature; here we use plasma mediated ablation to automate a form of block-face imaging along with novel algorithms to filter and vectorize features in the data.  The second is the study of neuronal viability in response to perturbations of subcortical blood flow; here we use plasma-mediated ablation to block flow in individual targeted microvessels that lie below the cortical surface.  The third test bed is the automation of cranial and spinal surgery; we combine plasma-mediated ablation with laser-induced breakdown spectroscopy to cut bone yet avoid injury to soft tissue.  These investigations are particularly relevant to diagnosing and understanding microinfarctions, i.e., damage to the brain as the result of damage to single cortical vessels, that accumulate with age and trauma.        Program Director (Last, first, middle): Kleinfeld, David, Kaufhold, John and Squier, Jeffrey. These studies advance the use of light to image and manipulate the flow of blood in the brain. We make use of rats and mice as model systems for our experiments. The new capabilities from the proposed work hold two promises for advances in medicine: One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma. The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.",Manipulating Neural Tissue with Ultra-Short Laser Pulses,8729873,R01EB003832,"['3-Dimensional', 'Ablation', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Automation', 'Beds', 'Biological Models', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Cephalic', 'Cessation of life', 'Craniotomy', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Face', 'Feedback', 'Fluorescence', 'Functional Imaging', 'Future', 'Generations', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Joints', 'Label', 'Laminectomy', 'Lasers', 'Lateral', 'Lead', 'Learning', 'Lesion', 'Life', 'Light', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Mediating', 'Medical Imaging', 'Medicine', 'Metabolism', 'Methodology', 'Mitochondria', 'Modeling', 'Mus', 'Neocortex', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Organelles', 'Pattern', 'Physiologic pulse', 'Plasma', 'Process', 'Rattus', 'Reperfusion Therapy', 'Research', 'Resolution', 'Role', 'Scanning', 'Shapes', 'Spectrum Analysis', 'Speed', 'Spinal', 'Stroke', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Ursidae Family', 'Veins', 'Work', 'arteriole', 'base', 'bone', 'brain cell', 'capillary', 'design', 'hemodynamics', 'meetings', 'millimeter', 'neurosurgery', 'novel', 'programs', 'reconstruction', 'relating to nervous system', 'research study', 'response', 'second harmonic', 'soft tissue', 'tool', 'two-photon']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,812810,-0.015512849264957107
"EEGLAB: Software for Analysis of Human Brain Dynamics     DESCRIPTION (provided by applicant): A major shift in scientific perspective on the nature and use of electrophysiological brain data is now ongoing a shift from measurement and visualization of individual channel signals (in the 'recording channel space') to visualizing and interpreting the data directly within a suitable inverse model representing activity reaching the electrodes by volume conduction from a set of effective data sources in native 'brain source space'. An equivalent shift, via the development and exploitation of an appropriate inverse imaging model, made possible the phenomenon of structural and functional magnetic resonance imaging (fMRI). While the electrophysiological inverse problem is still difficult, dramatic progress has been and is being made through combined use of multimodal imaging and modern statistical signal processing methods. Recovering the considerable degree of spatial source resolution available in high-density scalp electroencephalographic (EEG) and other electrophysiological data, while retaining its natural advantage over other functional imaging methods in temporal resolution, has begun to yield a steady stream of new information about patterns of distributed brain processing supporting human behavior and experience. Relative to other brain imaging modalities, EEG has substantial and increasing cost and mobility advantages, making promotion of new EEG methods for source space analysis of increasing interest and importance for brain and health research. However, applying new source signal and signal processing models to electrophysiological data is complex and increasingly involves application of modern mathematical methods whose details are not within the training of most health research professionals. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University of California San Diego, began as a set of EEG data analysis running on MATLAB (The Mathworks, Inc.) released on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now, more than ten years later, the EEGLAB reference paper (Delorme & Makeig, 2004) has over 2,350 Google scholar citations (increasing at above 1 per day), the opt-in EEGLAB discussion email list links over 5,000 researchers, the news list over 9,000, and a recent survey of 687 researcher respondents reports EEGLAB to be the software environment most widely used for electrophysiological data analysis worldwide. EEGLAB is thus now a de facto standard supporting a wide range of EEG and other electrophysiological research studies and teaching labs. At least 35 EEGLAB plug-in toolsets have now been released by researchers from many laboratories. Under NIH PAR 11-028 we propose renewal funding to further develop and maintain the EEGLAB software framework. We propose new and better tools for brain source and source network modeling and localization, an expanded online EEGLAB course and workshop, better statistical inference modeling of group data, and new support for automated source decomposition, measure computation, data duration, and data sharing.         PUBLIC HEALTH RELEVANCE: A major shift in scientific perspective on the nature and use of human electrophysiological data is now accelerating from measuring and visualizing individual scalp channel signals to directly visualizing and interpreting their brain sources. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University Of California San Diego (UCSD), supports a large number of EEG and related electrophysiological research studies and teaching labs. We propose continued funding to further develop and maintain the EEGLAB environment.            ",EEGLAB: Software for Analysis of Human Brain Dynamics,8681549,R01NS047293,"['Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Clinical', 'Cloud Computing', 'Code', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Educational process of instructing', 'Educational workshop', 'Electrodes', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Event-Related Potentials', 'Eye', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Health', 'Human', 'Image', 'Imagery', 'Individual', 'Internet', 'Joints', 'Laboratories', 'Links List', 'Machine Learning', 'Measurement', 'Measures', 'Memory', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multimodal Imaging', 'Nature', 'Neurosciences', 'Output', 'Paper', 'Pattern', 'Performance', 'Physiology', 'Plug-in', 'Positioning Attribute', 'Procedures', 'Process', 'Relative (related person)', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Scalp structure', 'Signal Transduction', 'Source', 'Speed', 'Stream', 'Surveys', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'computational neuroscience', 'computing resources', 'cost', 'cranium', 'data sharing', 'density', 'design', 'experience', 'flexibility', 'imaging modality', 'improved', 'innovation', 'interest', 'mathematical methods', 'network models', 'news', 'open source', 'public health relevance', 'research study', 'signal processing', 'symposium', 'tool', 'web site', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,484354,0.023171171580739405
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8786916,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2014,248999,-0.003392513311242414
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through  multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8618418,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2014,90000,-0.004738745155597785
"Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero     DESCRIPTION (provided by applicant): Accurate mapping of normal and abnormal patterns of brain development in fetuses and premature neonates is a key factor in the early detection of developmental disorders as well as understanding how external factors can influence early brain growth. The combination of fast multi-slice MRI techniques with computer vision algorithms has recently provided the ability to reliably image 3D brain structure in-utero providing valuable information inaccessible to ultrasound imaging. To complement this new structural information, recently there has been increasing interest in the use of functional MR imaging (fMRI) to map the development of resting state brain function in children, premature neonates and, most recently, fetuses in-utero. This work has revealed signs of a predictable developmental path in the formation of resting state patterns of brain activity present in adults and abnormalities in these patterns in children have been linked with neurological and neuropsychiatric conditions in later life. Such fMRI methods, previously used in adults and children, could provide a unique new window into functional activity in the developing fetal brain. However, the imaging techniques required suffer from an important limitation for use in the fetus: they make use of repeated acquisitions where subtle changes in MR signal provide the measure of interest. Fetal head motion within the scanner perturbs both measurement location and signal level due to the changing relationship between fetal anatomy, maternal anatomy and the scanner. Based on our preliminary results, in this proposal we plan to develop a set of new signal and geometry correction methods specifically for fetal fMRI that combine novel acquisition techniques with post-processing algorithms to provide a new route to addressing these unique problems. This will allow us to collect the first accurate functional MRI data from a range of un-sedated fetuses in ages and activity levels seen in clinical studies. We will develop and validate these methods together with complementary pattern analysis techniques specifically aimed at motion scattered data and employ them to build the first combined 4D structure-function map of brain development in-utero. This will show for the first time the temporal and spatial relationship between structural changes and the development of resting state patterns of brain activity covering the critical age of first clinical MRI scan and the following period of cortical folding. his will help answer such questions as: which tissue zones of the fetal brain such activity begins, and whether the functional patterns are related to the timing of the formation of specific cortical folds. We will collect a range of data that captures fetuses both at different ages and different states of activity representing those seen in typical clinical studies, and in addition collect valuable outcome measures on the babies after birth against which in-utero measure will be evaluated. We release the data to the community as a whole in the form of an open-access 4D atlas. This combined structure-function data will provide a unique new reference for both neuroscience and, in the longer term, clinical evaluation of brain health during pregnancy and premature birth.         PUBLIC HEALTH RELEVANCE: Clinically, improved in-utero evaluation of the fetal brain is a key concern for obstetricians and pediatricians in managing complex pregnancies and there is also now an increasing public health awareness of the influence of the in-utero environment, in terms of factors such as stress and diet, on long-term health in adult life. Functional connectivit imaging of the brain in childhood has revealed the presence of early markers of later cognitive and neuropsychological problems. The ability to map these same properties in utero, promises to provide a rich set of very specific early markers that can be used to understand the impact of the in-utero environment on brain function and feasibly provide a route to the use of early neuro-protective agents and procedures early in childhood.                ",Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero,8688242,R01EB017133,"['Accounting', 'Acoustic Stimulation', 'Acoustics', 'Address', 'Adult', 'Age', 'Algorithms', 'Anatomy', 'Atlases', 'Awareness', 'Biological Markers', 'Birth', 'Brain', 'Brain Mapping', 'Brain imaging', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Dependency', 'Detection', 'Development', 'Diet', 'Early Diagnosis', 'Early identification', 'Echo-Planar Imaging', 'Elderly', 'Environment', 'Evaluation', 'Fetal Heart Rate', 'Fetal Movement', 'Fetus', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Gestational Age', 'Goals', 'Growth', 'Head', 'Health', 'Heart Rate', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Left', 'Life', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Midbrain structure', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neonatal', 'Network-based', 'Neurologic', 'Neurosciences', 'Outcome Measure', 'Pattern', 'Positioning Attribute', 'Predisposition', 'Pregnancy', 'Premature Birth', 'Prematurity of fetus', 'Procedures', 'Process', 'Property', 'Protective Agents', 'Protocols documentation', 'Public Health', 'Recording of previous events', 'Reporting', 'Rest', 'Route', 'Scheme', 'Series', 'Signal Transduction', 'Slice', 'Source', 'Staging', 'Stimulus', 'Stress', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'base', 'brain tissue', 'design', 'developmental disease', 'experience', 'fetal', 'imaging modality', 'improved', 'in utero', 'interest', 'neonate', 'neuropsychiatry', 'neuropsychological', 'novel', 'pediatrician', 'population based', 'premature', 'public health relevance', 'research clinical testing', 'spatial relationship', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2014,602789,-0.024805737859410155
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a  web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8609036,R44EY020082,"['Advertisements', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2014,357073,0.018764259543869635
"Large-scale Automated Synthesis of Functional Neuroimaging Data     DESCRIPTION (provided by applicant): The explosive growth of the human neuroimaging literature has led to major advances in understanding of normal and abnormal human brain function, but has also made aggregation and synthesis of neuroimaging findings increasingly difficult. The goal of this project is to develop an automated software platform for large-scale synthesis of human functional neuroimaging studies. Our work builds directly on an existing software platform (NeuroSynth) and involves key extensions and improvements that focus on (i) aggregation, (ii) coding, (iii) synthesis, and (iv) sharing of functional neuroimaging data. In Aim 1, we will use computational linguistics and bioinformatics data mining techniques to develop new algorithms for automatically extracting activation foci and associated metadata from published neuroimaging articles. In Aim 2, we will use topic-modeling techniques such as Latent Dirichlet Analysis in combination with existing cognitive ontologies such as the Cognitive Atlas to develop structured representations of automatically extracted neuroimaging data. In Aim 3, we will improve the meta-analysis and classification capacities of our existing platform by implementing a state-of- the-art hierarchical Bayesian meta-analysis method recently developed by the research team. Finally, in Aim 4, we will develop a state-of-the-art web interface (://neurosynth.org) that supports real-time, in-browser access to the data, results, and tools produced in Aims 1 - 3. Realizing these objectives will introduce powerful new tools for organizing and synthesizing the neuroimaging literature on an unprecedented scale. These tools will be freely and publicly available to anyone with an internet connection, enabling rapid and efficient application to a broad range of clinical and basic research applications.          Functional neuroimaging techniques such as fMRI have opened a new frontier in efforts to investigate and understand the neural mechanisms of normal and abnormal cognition. However, the rapidly expanding scope of the literature makes distillation and synthesis of brain imaging findings increasingly challenging. The goal of this project is to develop a new software platform for automated aggregation, synthesis, and sharing of published neuroimaging results, with the potential to advance understanding of mechanisms underlying mental health disorders.                ",Large-scale Automated Synthesis of Functional Neuroimaging Data,8672688,R01MH096906,"['Algorithms', 'Atlases', 'Basic Science', 'Bayesian Method', 'Bayesian Modeling', 'Bioinformatics', 'Biometry', 'Brain', 'Brain imaging', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognition', 'Cognitive', 'Communities', 'Computational Linguistics', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Development', 'Ensure', 'Environment', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'High Performance Computing', 'Human', 'Individual', 'Interdisciplinary Study', 'Internet', 'Joints', 'Journals', 'Language', 'Literature', 'Manuals', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Neurosciences', 'Ontology', 'Paper', 'Performance', 'Population', 'Process', 'Publishing', 'Qualifying', 'Research', 'Research Personnel', 'Resources', 'Sample Size', 'Specificity', 'Structure', 'Techniques', 'Text', 'Time', 'Training', 'Validation', 'Work', 'awake', 'base', 'cognitive function', 'data mining', 'frontier', 'improved', 'information organization', 'interoperability', 'knowledge base', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'open source', 'psychologic', 'theories', 'tool', 'web interface']",NIMH,"UNIVERSITY OF TEXAS, AUSTIN",R01,2014,603330,0.012962139735182924
"Designing Visually Accessible Spaces  Title: Designing Visually Accessible Spaces NIH Program Announcement: 10-234 Bioengineering Research Partnerships (BRP)[R01] Abstract Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities, and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area). This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals: 1) Empirical: determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces. 2) Computational: develop working models to predict low vision visibility and navigability in real-world spaces. 3) Deployment: translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility. The key scientific personnel in our partnership come from three institutions: University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare. This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare). We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.                ",Designing Visually Accessible Spaces,8630772,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Image', 'Indiana', 'Individual', 'Injury', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Simulate', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'falls', 'hazard', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2014,595880,0.023615916930915876
"Improving the Detection of Activation in High Resolution fMRI using Multivariate No abstract available PUBLIC HEALTH RELEVANCE: The proposed research is highly relevant to public health because advanced mathematical and statistical methods will allow better analysis of high-resolution fMRI data leading to better characterization of cortical function. For this project we choose to focus on studying memory activation in the medial temporal lobes using high-resolution imaging and multivariate analysis which could substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer's disease, schizophrenia, and major depression. Our proposed fMRI analysis methods also have great potential for significantly advancing our understanding of other neurological and psychiatric conditions.",Improving the Detection of Activation in High Resolution fMRI using Multivariate,8920855,R01EB014284,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Environment', 'Estimation Techniques', 'Event', 'Experimental Designs', 'Face', 'Familiarity', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Hemorrhage', 'Hippocampus (Brain)', 'Image Analysis', 'Individual', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Major Depressive Disorder', 'Maps', 'Medial', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multivariate Analysis', 'Neighborhoods', 'Neurologic', 'Neurosciences Research', 'Occupations', 'Pattern', 'Problem Solving', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Software Tools', 'Solutions', 'Specificity', 'Statistical Methods', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Variant', 'Weight', 'base', 'density', 'digital imaging', 'improved', 'interest', 'mathematical methods', 'memory recognition', 'mild cognitive impairment', 'novel', 'prevent', 'statistics', 'theories', 'tool', 'user friendly software']",NIBIB,CLEVELAND CLINIC LERNER COM-CWRU,R01,2014,130281,-0.011460652481701647
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8414506,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2013,59383,-0.008587363491563908
"Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation     DESCRIPTION (provided by applicant): Over 3 million emergency intubations are performed in the US every year and failure rates can be as high as 50% (3-5). Success is highly dependent on how frequently the responder performs this life-saving procedure on humans (6). Brio Device, LLC, an airway management medical device company, is addressing the need to decouple the success of the procedure from the experience of the user with their ""smart"" intubation device which integrates anatomic structure recognition algorithms and visual guidance feedback with an articulating stylet. Brio's intubation device is specifically designed fo the needs of emergency responders, such as paramedics, emergency department personnel, code teams in hospitals and military medics, who often arrive at the patient first. The smart intubation device will reduce failure rates by providing the user with visual instruction of the correct path to the trachea as he places the endotracheal tube. The guidance software uses machine learning and computer vision algorithms to recognize the anatomy and determine the path to insert the tube. Ultimately, the intubation device will include both a guidance display on an LCD screen and an optical stylet that has single-axis angulation control of the distal tip. For the purpose of this Phase I study, a laptop or desktop computer will be used for the image processing and the guidance display that accompanies the articulating stylet. The long-term goal is to create a device that is compact, light-weight and portable to suit the needs of ambulances and hospital crash carts.  The hypothesis for this study is that by incorporating a video guidance display with an articulating stylet, inexperienced users will be more successful in correctly placing the endotracheal tube using this device compared to direct laryngoscopy. To achieve this goal, image processing and machine learning algorithms will be developed to recognize key anatomic structures in the airway. Software will also be developed determine the path the tube should follow and to display this information for the user. Finally, the efficacy of the device will be validated in airway simulation mannequins with medical students serving as the inexperienced users. Phase II will focus on integrating the guidance software, articulating optical stylet and display into a portable device with embedded hardware and software contained within the stylet handle. At completion of Phase II, the device will be ready for clinica trials and FDA testing.  Brio will enter the $20 billion airway market with its intubation device. Initial sales will begin with anesthesiologists who are early adopters of new technology to assist with difficult airways. Brio will market its product to ~327,000 clinicians who use intubation devices. The U.S. addressable market for emergency intubation is ~$900M for the 41,000 ambulances and 5,800 emergency departments and hospital code teams.         PUBLIC HEALTH RELEVANCE: In this SBIR Phase I, Brio Device, LLC plans to create and evaluate a device that improves the success rate of emergency intubations by coupling a smart guidance display with a user-controlled single-axis articulating stylet. Emergency intubations are often performed in challenging situations by personnel who do the procedure infrequently. Since failure rates are as high as 50% and approximately 180,000 deaths occur each year from failed pre-hospital intubations, a device is needed to provide visual guidance information to assist the users and increase their success rates in emergency situations.            ",Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation,8453607,R43HL114160,"['Accident and Emergency department', 'Address', 'Algorithms', 'Ambulances', 'Anatomic structures', 'Anatomy', 'Brain Death', 'Brain Injuries', 'Cessation of life', 'Clinical Trials', 'Code', 'Computer Vision Systems', 'Computer software', 'Computers', 'Coupling', 'Critical Care', 'Destinations', 'Devices', 'Distal', 'Emergency Situation', 'Failure', 'Feasibility Studies', 'Feedback', 'Goals', 'Hospitals', 'Human', 'Human Resources', 'Image', 'Imagery', 'Instruction', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Laryngoscopy', 'Left', 'Life', 'Light', 'Location', 'Lung', 'Machine Learning', 'Manikins', 'Marketing', 'Medical Device', 'Medical Students', 'Military Hospitals', 'Military Personnel', 'Optics', 'Outcome', 'Outcome Measure', 'Oxygen', 'Paramedical Personnel', 'Patients', 'Phase', 'Physicians', 'Procedures', 'Resuscitation', 'Sales', 'Small Business Innovation Research Grant', 'Structure', 'System', 'Testing', 'Time', 'Trachea', 'Tube', 'Visual', 'commercial application', 'design', 'endotracheal', 'experience', 'flexibility', 'image processing', 'improved', 'information display', 'laptop', 'light weight', 'new technology', 'novel', 'phase 1 study', 'public health relevance', 'secondary outcome', 'simulation', 'success']",NHLBI,"BRIO DEVICE, LLC",R43,2013,244710,0.005899400783091218
"Brain Science Computer Cluster     DESCRIPTION (provided by applicant): Computational requirements of contemporary brain science research often exceed financial and resource management limits of individual investigator laboratories. Many contemporary neuroscience research projects require analysis of large data sets with advanced statistical methods and anatomical reconstruction techniques. These methods require high speed computational and graphics engines operating in a multiple processor environments equipped with large capacity, high-speed storage devices. A limitation in the Brown brain science effort at understanding neural processing is the lack of a readily accessible high-speed computational resource. A central computational resource based on a unified cluster of contemporary Linux CPUs and GPUs will serve the computational needs of a core group of brain science investigators at Brown without compromising individual access common to stand-alone workstations. The requested computer cluster has system software that automatically balances CPU and GPU usage, thereby ensuring maximum access to the computational resource for all users. Intensive 3D graphics are off-loaded either to GPUs or to client workstations, thereby further reducing the central computational load. Commercial or open-source software with an open operating environment will be used for analysis using standard and novel statistical and machine learning approaches to assess significance of large data sets. This proposal details the architecture and benefits of a contemporary computational resource for the major and minor users, and more generally the Brown brain science community. The resource was designed to fill immediate and near-term computational and storage needs of a core group of Brown brain scientists. The system can be readily expansion as needs, either computational, storage, or new users, arise. Expansion of the existing core investigators group can occur easily since the computational power or storage capacity of the system can be readily enhanced at relatively low cost. The flexible nature of the system will serve a variety of research needs of the Brown brain science community. The computational resource is expected to bring together researchers at Brown working on the common problem of neural processing.             n/a",Brain Science Computer Cluster,8447697,S10OD016366,"['Architecture', 'Brain', 'Client', 'Communities', 'Computer software', 'Data Set', 'Devices', 'Ensure', 'Environment', 'Equilibrium', 'Individual', 'Laboratories', 'Linux', 'Machine Learning', 'Methods', 'Minor', 'Nature', 'Neurosciences Research', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Speed', 'Statistical Methods', 'System', 'Techniques', 'Work', 'base', 'computer cluster', 'computing resources', 'cost', 'design', 'flexibility', 'novel', 'open source', 'reconstruction', 'relating to nervous system', 'software systems']",OD,BROWN UNIVERSITY,S10,2013,599598,0.014665555047199363
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8507287,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2013,240369,-0.031113136342338376
"The Crystallography of Macromolecules    DESCRIPTION (provided by applicant): The proposal ""The Crystallography of Macromolecules"" addresses the limitations of diffraction data analysis methods in the field of X-ray crystallography. The significance of this work is determined by the importance of the technique, which generates uniquely-detailed information about cellular processes at the atomic level. The structural results obtained with crystallography are used to explain and validate results obtain by other biophysical, biochemical and cell biology techniques, to generate hypotheses for detailed studies of cellular process and to guide drug design studies - all of which are highly relevant to NIH mission. The proposal focuses on method development to address a frequent situation, where the crystal size and order is insufficient to obtain a structure from a single crystal. This is particularly frequent in cases of large eukaryotic complexes and membrane proteins, where the structural information is the most valuable to the NIH mission. The diffraction power of a single crystal is directly related to the microscopic order and size of that specimen. It is also one of the main correlates of structure solution success. The method used to solve the problem of data insufficiency in the case of a single crystal is to use multiple crystals and to average data between them, which allows to retrieve even very low signals. However, different crystals of the same protein, even if they are very similar i.e. have the same crystal lattice symmetry and very similar unit cell dimensions, still are characterized by a somewhat different order. This non-isomorphism is often high enough to make their solution with averaged data impossible. Moreover, the use of multiple data sets complicates decision making as each of the datasets contains different information and it is not clear when and how to combine them. The proposed solution relies on hierarchical analysis. First, the shape of the diffraction spot profiles will be modeled using a novel approach (Aim 1). This will form the ground for the next step, in which deconvolution of overlapping Bragg spot profiles from multiple lattices will be achieved (Aim 2). An additional benefit of algorithms developed in Aim 1 is that they will automatically derive the integration parameters and identify artifacts, making the whole process more robust. This is particularly significant for high-throughput and multiple crystal analysis. In Aim 3, comparison of data from multiple crystals will be performed to identify subsets of data that should be merged to produce optimal results. The critical aspect of this analysis will be the identification and assessment of non- isomorphism between datasets. The experimental decision-making strategy is the subject of Aim 4. The Support Vector Machine (SVM) method will be used to evaluate the suitability of available datasets for possible methods of structure solution. In cases of insufficient data it will identify the most significant factor that needs to be improved. Aim 5 is to simplify navigation of data reduction and to integrate the results of previous aims with other improvements in hardware and computing.        The goal of the proposal is to develop methods for analysis of X-ray diffraction data with a particular focus on the novel analysis of diffraction spot shape and the streamlining of data analysis in multi-crystal modes. The development of such methods is essential to advance structural studies in thousands of projects, which individually are important for NIH mission.           ",The Crystallography of Macromolecules,8470172,R01GM053163,"['Address', 'Algorithms', 'Anisotropy', 'Biochemical', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Complex', 'Computer software', 'Computers', 'Crystallography', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Decision Making', 'Dependence', 'Development', 'Dimensions', 'Drug Design', 'Evaluation', 'Funding', 'Goals', 'Ice', 'Image', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Noise', 'Output', 'Pattern', 'Phase', 'Problem Solving', 'Procedures', 'Process', 'Proteins', 'Quality Indicator', 'Radiation', 'Relative (related person)', 'Research', 'Resolution', 'Rotation', 'Shapes', 'Signal Transduction', 'Site', 'Solutions', 'Solvents', 'Specimen', 'Spottings', 'Structure', 'System', 'Techniques', 'Technology', 'Twin Multiple Birth', 'United States National Institutes of Health', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'base', 'beamline', 'cell dimension', 'data reduction', 'detector', 'experience', 'improved', 'independent component analysis', 'indexing', 'macromolecule', 'method development', 'novel', 'novel strategies', 'programs', 'research study', 'statistics', 'success', 'user-friendly']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2013,309127,-0.02583997302670392
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8521782,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'computerized data processing', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2013,424766,0.005998610722516747
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8566062,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2013,175500,-0.008608743343428994
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.           The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8389864,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2013,499358,-2.482668955544601e-05
"Development and Dissemination of Robust Brain MRI Measurement Tools     DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: Summary. Neuroimaging provides a safe, non-invasive measurement of the whole brain, and has enabled large clinical and research studies for brain development, aging, and disorders. However, many disorders, i.e., major neurodegenerative and neuropsychiatric disorders, cause complex spatiotemporal patterns of brain alteration, which are often difficult to identify visually and compare over time. To address this critical issu, in the renewal phase of this project, we will continue to work with GE Research to develop and disseminate a software package for brain measurement, comparison, and diagnosis. The new tools include 1) a novel tree-based registration and multi-atlases-based segmentation method for precise measurement of brain alteration patterns, and 2) novel pattern classification and regression methods for early detection and longitudinal monitoring of brain disorders. Aims. Currently, most existing atlas-based labeling methods simply warp each atlas independently to the individual brain for multi-atlases-based structural labeling. This could lead to 1) inaccurate labeling due to possible large registration error when the atlases are very different from the target individual brain, and 2) inconsistent labeling of the same brain structure across different individuals due to independent labeling of each individual brain. The first goal of this project is hence to develop a novel tree-based registration and multi-atlases -based segmentation method for simultaneous registration and joint labeling of all individual brains by concurrent consideration of all atlases. With measurements of brain structures and their alteration patterns, univariate analysis methods are often used to understand how the disease affects brain structure and function at a group level. Although this can lead to better understanding of neurological pathology of brain disorders, more sophisticated image analysis methods are urgently needed for quantitative assessment and early diagnosis of brain abnormality at an individual level. Thus, the second goal of this project is to develop various novel machine learning methods for early diagnosis of brain disorders and better quantification of brain abnormality at an individual level. Specifically, we will take Alzheimer's disease (AD), which is the most common form of dementia, as an example for demonstrating the performance of our proposed methods in early diagnosis of AD, as well as in prediction of long-term outcomes of individuals with mild cognitive impairment (MCI). The last goal of this project is to build, for ou developed methods, the respective software modules for the 3D Slicer (a free open-source software package with a flexible modular platform for medical image analysis and visualization, http://www.slicer.org/), to promote the potential clinical applications by using tools in 3D Slicer for preprocessing of patient data and our tools for diagnosis. Again, this software development work will be performed in collaboration with our current collaborator, GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC) that is focused on developing 3D Slicer. Both source code and pre-compiled programs will be made freely available. Applications. These methods can find their applications in diverse fields, i.e., quantifying brain abnormality of neurological diseases (i.e., AD and schizophrenia), measuring effects of different pharmacological interventions on the brain, and finding associations between structural and cognitive function variables.          Description of Project This project aims to develop a novel method for accurate measurement of brain structure and function by groupwise registration and joint labeling of all individual images via multiple manual-labeled atlases. Moreover, several novel tools for brain abnormality measurement will also be developed for early detection and progression monitoring of brain disorders using both multimodal imaging and non-imaging data. By successful development of these brain measurement tools, the respective software modules will be developed and further incorporated into 3D Slicer via collaboration with GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC). Both source code and pre-compiled programs will be made freely available.            ",Development and Dissemination of Robust Brain MRI Measurement Tools,8530230,R01EB006733,"['Address', 'Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Engineering', 'Functional Magnetic Resonance Imaging', 'Goals', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Multimodal Imaging', 'Nerve Degeneration', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Research', 'Sampling', 'Schizophrenia', 'Simulate', 'Slice', 'Source Code', 'Staging', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Update', 'Work', 'abstracting', 'base', 'clinical application', 'cognitive function', 'disease diagnosis', 'flexibility', 'image registration', 'image visualization', 'information classification', 'mild cognitive impairment', 'nervous system disorder', 'neuroimaging', 'neurological pathology', 'neuropsychiatry', 'novel', 'open source', 'programs', 'research study', 'software development', 'spatiotemporal', 'symposium', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2013,468755,-0.02178762518436726
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.            ",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8650411,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'high school', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2013,81362,0.024920032179193946
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8599834,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2013,249999,-0.011303891064457021
"Providing Access to Appliance Displays for Visually Impaired Users  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays. This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image. For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast. These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view. Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users. Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures. The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.                ",Providing Access to Appliance Displays for Visually Impaired Users,8579051,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2013,376082,0.01701859395499681
"Improving the Detection of Activation in High Resolution fMRI using Multivariate     DESCRIPTION (provided by applicant): The overall goal of this project is to develop a local multivariate analysis software package for fMRI data analysis. It will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods. This project will lead to better brain activation maps and thus promote the discovery of currently unknown aspects of brain function. Mass-univariate analysis, such as the general linear model (GLM), is the prevailing fMRI data analysis method. However, it suffers from blurring of edges of activation and potential elimination of the detection of weak activated regions due to routinely applied fixed isotropic spatial Gaussian smoothing. Local multivariate methods such as canonical correlation analysis (CCA) and its variants have been shown to significantly increase the detection power of fMRI activations and improve activation maps. As an advantage, CCA uses adaptive spatial filtering kernels to accurately extract the signal better in a noisy environment. However, there are several drawbacks, particularly low spatial specificity, long computational time, and single-factor experimental design limitation. Furthermore, a parametric estimation method does not exist to determine the family-wise error rate, no extension to group analysis has been investigated, and no studies extending local CCA to nonlinear CCA for fMRI data using kernel methods have been systematically carried out. All these drawbacks prevent local CCA methods from being widely accepted in neuroscience research in fMRI. In this proposal, our goals are to eliminate these drawbacks using novel local multivariate analysis methods (based on CCA) and to develop a software tool to widen its broader application in the neuroscience research community. We expect this software tool to be particularly valuable for neuroscience research where detections of weak activations or spatially localized patterns of activations are desired. As high resolution imaging and computer power advance, we expect an increase in demand for this software tool, thus advancing new discoveries of brain function and more precise spatial localization of activations. As a particular application, we will focus on studying memory actions using a novel event-related recognition paradigm to investigate the effects of familiarity and recollection in subregions of the medial temporal lobes (MTL) for high resolution fMRI. This research will advance our understanding of hippocampal/MTL contributions to memory, which can substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer¿s disease, schizophrenia, and major depression. More generally, it will provide psychologists and neuroscientists a more powerful tool to analyze their fMRI data using advanced multivariate methods.         PUBLIC HEALTH RELEVANCE: The proposed research is highly relevant to public health because advanced mathematical and statistical methods will allow better analysis of high-resolution fMRI data leading to better characterization of cortical function. For this project we choose to focus on studying memory activation in the medial temporal lobes using high-resolution imaging and multivariate analysis which could substantially advance our understanding of the memory deficits associated with a number of debilitating neurological and psychiatric conditions that show abnormalities in these regions, including mild cognitive impairment (MCI), Alzheimer's disease, schizophrenia, and major depression. Our proposed fMRI analysis methods also have great potential for significantly advancing our understanding of other neurological and psychiatric conditions.                ",Improving the Detection of Activation in High Resolution fMRI using Multivariate,8438968,R01EB014284,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Environment', 'Estimation Techniques', 'Event', 'Experimental Designs', 'Face', 'Familiarity', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hemorrhage', 'Hippocampus (Brain)', 'Image Analysis', 'Individual', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Major Depressive Disorder', 'Maps', 'Medial', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multivariate Analysis', 'Neighborhoods', 'Neurologic', 'Neurosciences Research', 'Occupations', 'Pattern', 'Problem Solving', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Software Tools', 'Solutions', 'Specificity', 'Statistical Methods', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Variant', 'Weight', 'base', 'density', 'digital imaging', 'improved', 'interest', 'memory recognition', 'mild cognitive impairment', 'novel', 'prevent', 'public health relevance', 'statistics', 'theories', 'tool', 'user friendly software']",NIBIB,RYERSON  UNIVERSITY,R01,2013,279190,0.008044240188181931
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.       PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.            ",Perception of Tactile Graphics,8417005,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'public health relevance', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2013,53942,-0.013947656555488294
"EEGLAB: Software for Analysis of Human Brain Dynamics     DESCRIPTION (provided by applicant): A major shift in scientific perspective on the nature and use of electrophysiological brain data is now ongoing a shift from measurement and visualization of individual channel signals (in the 'recording channel space') to visualizing and interpreting the data directly within a suitable inverse model representing activity reaching the electrodes by volume conduction from a set of effective data sources in native 'brain source space'. An equivalent shift, via the development and exploitation of an appropriate inverse imaging model, made possible the phenomenon of structural and functional magnetic resonance imaging (fMRI). While the electrophysiological inverse problem is still difficult, dramatic progress has been and is being made through combined use of multimodal imaging and modern statistical signal processing methods. Recovering the considerable degree of spatial source resolution available in high-density scalp electroencephalographic (EEG) and other electrophysiological data, while retaining its natural advantage over other functional imaging methods in temporal resolution, has begun to yield a steady stream of new information about patterns of distributed brain processing supporting human behavior and experience. Relative to other brain imaging modalities, EEG has substantial and increasing cost and mobility advantages, making promotion of new EEG methods for source space analysis of increasing interest and importance for brain and health research. However, applying new source signal and signal processing models to electrophysiological data is complex and increasingly involves application of modern mathematical methods whose details are not within the training of most health research professionals. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University of California San Diego, began as a set of EEG data analysis running on MATLAB (The Mathworks, Inc.) released on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now, more than ten years later, the EEGLAB reference paper (Delorme & Makeig, 2004) has over 2,350 Google scholar citations (increasing at above 1 per day), the opt-in EEGLAB discussion email list links over 5,000 researchers, the news list over 9,000, and a recent survey of 687 researcher respondents reports EEGLAB to be the software environment most widely used for electrophysiological data analysis worldwide. EEGLAB is thus now a de facto standard supporting a wide range of EEG and other electrophysiological research studies and teaching labs. At least 35 EEGLAB plug-in toolsets have now been released by researchers from many laboratories. Under NIH PAR 11-028 we propose renewal funding to further develop and maintain the EEGLAB software framework. We propose new and better tools for brain source and source network modeling and localization, an expanded online EEGLAB course and workshop, better statistical inference modeling of group data, and new support for automated source decomposition, measure computation, data duration, and data sharing.         PUBLIC HEALTH RELEVANCE: A major shift in scientific perspective on the nature and use of human electrophysiological data is now accelerating from measuring and visualizing individual scalp channel signals to directly visualizing and interpreting their brain sources. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) at the University Of California San Diego (UCSD), supports a large number of EEG and related electrophysiological research studies and teaching labs. We propose continued funding to further develop and maintain the EEGLAB environment.            ",EEGLAB: Software for Analysis of Human Brain Dynamics,8579850,R01NS047293,"['Behavior', 'Brain', 'Brain imaging', 'California', 'Clinical', 'Code', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Educational process of instructing', 'Educational workshop', 'Electrodes', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Event-Related Potentials', 'Eye', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Health', 'Human', 'Image', 'Imagery', 'Individual', 'Internet', 'Joints', 'Laboratories', 'Links List', 'Machine Learning', 'Measurement', 'Measures', 'Memory', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'Multimodal Imaging', 'Nature', 'Neurosciences', 'Output', 'Paper', 'Pattern', 'Performance', 'Physiology', 'Plug-in', 'Positioning Attribute', 'Procedures', 'Process', 'Relative (related person)', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Scalp structure', 'Signal Transduction', 'Source', 'Speed', 'Stream', 'Surveys', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'computational neuroscience', 'computerized data processing', 'computing resources', 'cost', 'cranium', 'data sharing', 'density', 'design', 'experience', 'flexibility', 'imaging modality', 'improved', 'innovation', 'interest', 'network models', 'news', 'open source', 'public health relevance', 'research study', 'symposium', 'tool', 'web site', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,484646,0.023171171580739405
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development     DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation.             n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8644396,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Simulate', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGE MASON UNIVERSITY,R01,2013,322109,-0.003945026604728852
"Manipulating Neural Tissue with Ultra-Short Laser Pulses    DESCRIPTION (provided by applicant):  We seek to renew our joint discovery and technology based bioengineering research partnership (BRP).  Our program advances the use of amplified ultrashort laser pulses as a tool to manipulate living and histological tissue.  This unique technology, pioneered by the BRP team, permits tissue to be cut on the micrometer scale by light-fueled plasma-meditated ablation.  Cutting occurs without thermal damage and can be combined with spectroscopic feedback to identify and limit the region being perturbed.  We advance this technology in new ways, including the use of temporal focusing for deep ablation, and apply it to three key test beds.  The first is construction of the angiotome, i.e., a complete vectorized map of cortical vasculature; here we use plasma mediated ablation to automate a form of block-face imaging along with novel algorithms to filter and vectorize features in the data.  The second is the study of neuronal viability in response to perturbations of subcortical blood flow; here we use plasma-mediated ablation to block flow in individual targeted microvessels that lie below the cortical surface.  The third test bed is the automation of cranial and spinal surgery; we combine plasma-mediated ablation with laser-induced breakdown spectroscopy to cut bone yet avoid injury to soft tissue.  These investigations are particularly relevant to diagnosing and understanding microinfarctions, i.e., damage to the brain as the result of damage to single cortical vessels, that accumulate with age and trauma.      PUBLIC HEALTH RELEVANCE:  These studies advance the use of light to image and manipulate the flow of blood in the brain.  We make use of rats and mice as model systems for our experiments.  The new capabilities from the proposed work hold two promises for advances in medicine:  One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma.  The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.              Program Director (Last, first, middle): Kleinfeld, David, Kaufhold, John and Squier, Jeffrey. These studies advance the use of light to image and manipulate the flow of blood in the brain. We make use of rats and mice as model systems for our experiments. The new capabilities from the proposed work hold two promises for advances in medicine: One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma. The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.",Manipulating Neural Tissue with Ultra-Short Laser Pulses,8537158,R01EB003832,"['3-Dimensional', 'Ablation', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Automation', 'Beds', 'Biological Models', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Cephalic', 'Cessation of life', 'Craniotomy', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Face', 'Feedback', 'Fluorescence', 'Functional Imaging', 'Future', 'Generations', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Joints', 'Label', 'Laminectomy', 'Lasers', 'Lateral', 'Lead', 'Learning', 'Lesion', 'Life', 'Light', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Mediating', 'Medical Imaging', 'Medicine', 'Metabolism', 'Methodology', 'Mitochondria', 'Modeling', 'Mus', 'Neocortex', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Organelles', 'Pattern', 'Physiologic pulse', 'Plasma', 'Process', 'Rattus', 'Reperfusion Therapy', 'Research', 'Resolution', 'Role', 'Scanning', 'Shapes', 'Spectrum Analysis', 'Speed', 'Spinal', 'Stroke', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Ursidae Family', 'Veins', 'Work', 'arteriole', 'base', 'bone', 'brain cell', 'capillary', 'design', 'hemodynamics', 'meetings', 'millimeter', 'neurosurgery', 'novel', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'research study', 'response', 'second harmonic', 'soft tissue', 'tool', 'two-photon']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,826572,-0.013738458954063233
"Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment    DESCRIPTION (provided by applicant): Functional neuroimaging studies of the human brain have become increasingly important in the understanding of normal and pathological processes of cognition. Sophisticated statistical analytic frameworks have been developed to locate signal change and define brain networks involved in various tasks. However, in subtle cognitive impairment-e.g., exposure-related illness, early stages of degenerative diseases, injury, secondary illness following adjuvant therapy for cancer-these methods tend to have low sensitivity for detecting small changes in brain states resulting from mild brain dysfunction. An understanding of disease mechanism or progression of subtle cognitive dysfunction requires a novel statistical analytic framework with improved sensitivity to measure small changes in brain states. We have developed an innovative methodology that we successfully applied in measures of regional cerebral blood flow experiments. These methods use well established spatial modeling procedures, new to the functional brain imaging field, to derive statistically optimal spatial summaries within effective resolution groups or ""kriging"", shown by preliminary studies to improve signal detection sensitivity and mitigate the multiple testing burden. Within this new spatial modeling framework, we propose to extend the kriging methodology to fMRI and EEG, modify existing techniques for characterizing brain networks of connectivity (e.g., kriging-based independent components analysis), and integrate the imaging modalities using a statistical classifier based on derived inputs of data driven effective resolution groups. Our primary goal is to develop this analysis framework to provide insight into the neurophysiological mechanisms of mild cognitive dysfunction. Achieving this goal may suggest treatments to alleviate symptoms, prevent progression, or at minimum, provide an informed clinical management of cognitively impaired patients.        Cognitive impairment is a major health concern, affecting people of all ages. Causes range from traumatic injury to toxin exposures, including chemotherapy for cancer treatment, to degenerative diseases. Mechanisms of damage or disease remain difficult to establish using current methods in functional brain imaging studies due to an inability to measure very small changes in brain states. We propose a new analytic framework using existing technology to improve the ability to measure subtle changes important in the understanding of disease pathology of impaired cognition and to greatly facilitate the integration of information from several imaging modalities with potential implications for clinical management and treatment.            ",Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment,8445205,R21EB014563,"['Adjuvant Therapy', 'Affect', 'Age', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrovascular Circulation', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Treatment', 'Cognition', 'Data', 'Databases', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Injury', 'Ions', 'Lead', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Neurocognitive', 'Neurotoxins', 'Outcome', 'Output', 'Pathologic Processes', 'Pathology', 'Patients', 'Procedures', 'Process', 'Property', 'Reliance', 'Research Personnel', 'Resolution', 'Sampling', 'Secondary to', 'Semantic memory', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Spin Labels', 'Staging', 'Statistical Methods', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Weight', 'Work', 'base', 'behavior measurement', 'behavior test', 'cancer therapy', 'case-based', 'chemobrain', 'chemotherapy', 'data reduction', 'executive function', 'image registration', 'imaging modality', 'improved', 'independent component analysis', 'innovation', 'insight', 'mild cognitive impairment', 'neurocognitive test', 'neuroimaging', 'neurophysiology', 'novel', 'prevent', 'research study', 'single photon emission computed tomography', 'tool', 'treatment strategy']",NIBIB,UNIVERSITY OF TEXAS DALLAS,R21,2013,184069,-0.005058160367936565
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.        The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8383103,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2013,222916,-0.014757457425084062
"Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development    DESCRIPTION (provided by applicant): Selective potentiators of the metabotropic glutamate receptor subtype mGluR5 have exciting potential for development of novel treatment strategies for schizophrenia and other disorders that disrupt cognitive func-tion. The latest generation of selective mGluR5 potentiators is based on the lead compound CDPPB and features systemically active compounds with long half-lives that cross the blood-brain barrier. A high-throughput screen (HTS) for mGluR5 potentiators at Vanderbilt's screening center revealed a large and diverse set of about 1400 substances (1% hit rate) whose activity was validated in independent experiments.  A previous exploratory research grant ""Novel Schizophrenia Therapeutics by Virtual High-Throughput Screening"" (R21 MH082254) enabled testing of 813 compounds predicted through cheminformatics. 252 of these compounds were confirmed as active PAMs equaling an enrichment of >30 when compared with the original screen. The present proposal seeks to leverage these proof-of-principle results for the development of a tailored cheminformatics framework for drug discovery of allosteric modulators of brain GPCRs, apply these tools to inform an existing therapeutic discovery program of mGluR5 potentiators at Vanderbilt University, and disseminate the methods broadly through the NIH molecular libraries program.  The central hypothesis of this proposal is that the complex relationship between chemical structure and biological activity of mGluR5 potentiators observed in this HTS can be used to generate a pharmacophore of the mGluR5 allosteric site. This map of steric and electronic features necessary for optimal interaction of modulators with mGluR5 will not only inform our understanding of the allosteric modulation of brain GPCRs. The methods proposed overcome limitations of present cheminformatics techniques by enabling identification of novel chemotypes through virtual screening (scaffold hoping), and allowing design of focused libraries in hit-to- lead optimization of novel schizophrenia therapeutics.  The generalizbility of the approach will be tested through application on negative modulators of mGluR5, a potential novel treatment strategy of fragile X syndrome, a CNS disorder associated with autism spectrum disorders (ASD) among multiple other symptoms. The developed applications will be made freely and readily accessible for academic research. The employed QSAR models require no crystal structure of the target brain GPCR. Hence the method can be readily applied to membrane proteins-such as GPCRs-which are target of 40-50% of modern medicinal drugs.       PUBLIC HEALTH RELEVANCE: Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.         ",Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development,8416380,R01MH090192,"['Algorithms', 'Allosteric Site', 'Benchmarking', 'Biological', 'Blood - brain barrier anatomy', 'Brain', 'Central Nervous System Diseases', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chemosensitization', 'Cognitive', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consensus', 'Databases', 'Descriptor', 'Development', 'Disease', 'Education', 'Electronics', 'Fragile X Syndrome', 'G Protein-Coupled Receptor Genes', 'Generations', 'Hand', 'Humulus', 'Internet', 'Lead', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Mental disorders', 'Metabotropic Glutamate Receptors', 'Methods', 'Modeling', 'Molecular', 'Molecular Bank', 'Pharmaceutical Preparations', 'Pharmacology', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Project Grants', 'Scheme', 'Schizophrenia', 'Site', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Universities', 'Walking', 'Work', 'autism spectrum disorder', 'base', 'chemical synthesis', 'cheminformatics', 'cognitive function', 'comparative', 'design', 'drug discovery', 'experience', 'high throughput screening', 'nervous system disorder', 'novel', 'pharmacophore', 'programs', 'public health relevance', 'research study', 'scaffold', 'screening', 'therapeutic development', 'therapeutic target', 'tool', 'treatment strategy', 'virtual']",NIMH,VANDERBILT UNIVERSITY,R01,2013,370544,-0.0366300564432389
"Quantitative Methods for Neuroimaging Studies of Interventions in Aging    DESCRIPTION (provided by applicant): This proposal for an NIH Mentored Quantitative Research Career Award requests support for Dr. Yongmei Michelle Wang as she embarks on a faculty career focused on imaging studies which examine the influence of longitudinal interventions on brain structure and function, and its relationship to cognition and performance, in older adults. The application proposes a research career development plan in the field of neuroimaging, bridging engineering, statistics, and neuroscience. The plan includes two overlapping phases: 1) a didactic phase that emphasizes training, including coursework and laboratory work in the area of cognitive neuroscience, imaging, aging, and interventions to complement Dr. Wang's doctoral training in Electrical Engineering and existing experience in Statistics; and 2) a development phase that focuses on intense development of the proposed research. These two phases will be closely supervised by the mentor and advisor in the area of cognitive neuroscience, brain plasticity, biomedical imaging, aging and interventions. Neuroimaging techniques, such as magnetic resonance imaging (MRI) and functional MRI (fMRI), have been shown to be powerful for characterizing and understanding the structure and function of the human brain. There remains a need, however, for robust and efficient statistical image analysis methods due to the limitations of existing approaches. It is crucial that these analysis techniques be developed with a full understanding of the neuroimaging methods used and the relevant cognitive neuroscience. We propose to develop, implement, and validate integrated computational algorithms for reliable and sensitive analysis of brain MRI and fMRI images, with the following specific aims: 1) Develop, validate and combine novel and efficient univariate and multivariate morphometry analysis methods. 2) Develop and evaluate integrated functional hemodynamic response and connectivity study approaches. 3) Apply these methods to the MRI and fMRI data being collected from separately funded NIA project of the mentor, to examine the effects of aerobic fitness training on brain structure and function of older adults; the neuroscience hypothesis to be tested are: improvements in aerobic fitness, over the course of a 1 year intervention, will result in i) increases in gray and white matter volume and shape changes of subcortical structures of the human brain; and ii) changes in the underlying neural circuits. 4) Develop a brain image analysis toolbox implementing the above methods.       PUBLIC HEALTH RELEVANCE: The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.              PROJECT NARRATIVE The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.",Quantitative Methods for Neuroimaging Studies of Interventions in Aging,8520136,K25AG033725,"['Adult', 'Aerobic', 'Age', 'Aging', 'Algorithms', 'American', 'Area', 'Attention', 'Award', 'Awareness', 'Bayesian Method', 'Behavior', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Computational algorithm', 'Conflict (Psychology)', 'Data', 'Detection', 'Deterioration', 'Development', 'Development Plans', 'Dimensions', 'Economic Burden', 'Elderly', 'Electrical Engineering', 'Engineering', 'Exhibits', 'Faculty', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Health', 'Hippocampus (Brain)', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Intervention', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Markov Chains', 'Medial', 'Memory', 'Mentors', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Multivariate Analysis', 'Neurosciences', 'Noise', 'Parietal', 'Participant', 'Pattern', 'Performance', 'Phase', 'Physical activity', 'Population', 'Prefrontal Cortex', 'Process', 'Public Health', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Risk Behaviors', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Statistical Methods', 'Structure', 'Surface', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'age related', 'aging brain', 'aging mind', 'base', 'bioimaging', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'executive function', 'experience', 'fitness', 'flexibility', 'gray matter', 'healthy aging', 'hemodynamics', 'improved', 'interest', 'intervention effect', 'morphometry', 'neural circuit', 'neuroimaging', 'new technology', 'novel', 'public health relevance', 'relating to nervous system', 'relational memory', 'research study', 'response', 'sedentary', 'shape analysis', 'social', 'statistics', 'therapy design', 'tool', 'white matter', 'young adult']",NIA,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K25,2013,150833,-0.008538072512311477
"Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero     DESCRIPTION (provided by applicant): Accurate mapping of normal and abnormal patterns of brain development in fetuses and premature neonates is a key factor in the early detection of developmental disorders as well as understanding how external factors can influence early brain growth. The combination of fast multi-slice MRI techniques with computer vision algorithms has recently provided the ability to reliably image 3D brain structure in-utero providing valuable information inaccessible to ultrasound imaging. To complement this new structural information, recently there has been increasing interest in the use of functional MR imaging (fMRI) to map the development of resting state brain function in children, premature neonates and, most recently, fetuses in-utero. This work has revealed signs of a predictable developmental path in the formation of resting state patterns of brain activity present in adults and abnormalities in these patterns in children have been linked with neurological and neuropsychiatric conditions in later life. Such fMRI methods, previously used in adults and children, could provide a unique new window into functional activity in the developing fetal brain. However, the imaging techniques required suffer from an important limitation for use in the fetus: they make use of repeated acquisitions where subtle changes in MR signal provide the measure of interest. Fetal head motion within the scanner perturbs both measurement location and signal level due to the changing relationship between fetal anatomy, maternal anatomy and the scanner. Based on our preliminary results, in this proposal we plan to develop a set of new signal and geometry correction methods specifically for fetal fMRI that combine novel acquisition techniques with post-processing algorithms to provide a new route to addressing these unique problems. This will allow us to collect the first accurate functional MRI data from a range of un-sedated fetuses in ages and activity levels seen in clinical studies. We will develop and validate these methods together with complementary pattern analysis techniques specifically aimed at motion scattered data and employ them to build the first combined 4D structure-function map of brain development in-utero. This will show for the first time the temporal and spatial relationship between structural changes and the development of resting state patterns of brain activity covering the critical age of first clinical MRI scan and the following period of cortical folding. his will help answer such questions as: which tissue zones of the fetal brain such activity begins, and whether the functional patterns are related to the timing of the formation of specific cortical folds. We will collect a range of data that captures fetuses both at different ages and different states of activity representing those seen in typical clinical studies, and in addition collect valuable outcome measures on the babies after birth against which in-utero measure will be evaluated. We release the data to the community as a whole in the form of an open-access 4D atlas. This combined structure-function data will provide a unique new reference for both neuroscience and, in the longer term, clinical evaluation of brain health during pregnancy and premature birth.         PUBLIC HEALTH RELEVANCE: Clinically, improved in-utero evaluation of the fetal brain is a key concern for obstetricians and pediatricians in managing complex pregnancies and there is also now an increasing public health awareness of the influence of the in-utero environment, in terms of factors such as stress and diet, on long-term health in adult life. Functional connectivit imaging of the brain in childhood has revealed the presence of early markers of later cognitive and neuropsychological problems. The ability to map these same properties in utero, promises to provide a rich set of very specific early markers that can be used to understand the impact of the in-utero environment on brain function and feasibly provide a route to the use of early neuro-protective agents and procedures early in childhood.                ",Motion Robust Mapping of Human Brain Functional Connectivity Changes in Utero,8509448,R01EB017133,"['Accounting', 'Acoustic Stimulation', 'Acoustics', 'Address', 'Adult', 'Age', 'Algorithms', 'Anatomy', 'Atlases', 'Awareness', 'Biological Markers', 'Birth', 'Brain', 'Brain Mapping', 'Brain imaging', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Dependency', 'Detection', 'Development', 'Diet', 'Early Diagnosis', 'Early identification', 'Echo-Planar Imaging', 'Elderly', 'Environment', 'Evaluation', 'Fetal Heart Rate', 'Fetal Movement', 'Fetus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Goals', 'Growth', 'Head', 'Health', 'Heart Rate', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Left', 'Life', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Midbrain structure', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neonatal', 'Network-based', 'Neurologic', 'Neurosciences', 'Outcome Measure', 'Pattern', 'Positioning Attribute', 'Predisposition', 'Pregnancy', 'Premature Birth', 'Prematurity of fetus', 'Procedures', 'Process', 'Property', 'Protective Agents', 'Protocols documentation', 'Public Health', 'Recording of previous events', 'Reporting', 'Rest', 'Route', 'Scheme', 'Series', 'Signal Transduction', 'Slice', 'Source', 'Staging', 'Stimulus', 'Stress', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Work', 'base', 'brain tissue', 'design', 'developmental disease', 'experience', 'fetal', 'imaging modality', 'improved', 'in utero', 'interest', 'neonate', 'neuropsychiatry', 'neuropsychological', 'novel', 'pediatrician', 'population based', 'premature', 'public health relevance', 'research clinical testing', 'spatial relationship', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2013,650062,-0.024805737859410155
"Context Understanding Technology to improve internet accessibility for users with     DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization.         PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.                ",Context Understanding Technology to improve internet accessibility for users with,8459121,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'public health relevance', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2013,371933,0.018764259543869635
"Advanced training platform and methodologies for emergency responders and skilled     DESCRIPTION (provided by applicant): There is a need to be able to deliver just-in-time training and reference materials for first responders and skilled support personnel. Mobile computing platforms are becoming ubiquitous and provide an ideal means to reach users at any time in any location. The process of translating existing reference materials into mobile-friendly formats is currently manual and very labor intensive. Nicolalde R&D LLC is well under way to commercialize its mTraining mobile technology and service prototyped during a phase I SBIR from NIEHS. The mTraining technology is an objective and checklist-based method for delivering just-in-time training and reference materials, making it an effective Electronic Performance Support System (EPSS) for providing workers easy access to information after training, and on site prior to or during an assignment. It provides short, incident specific awareness and safety training that can be delivered prior to responding to an emergency situation. The proposed development under this phase II SBIR includes: a) a back-end document processing engine that is able to automatically parse, analyze, mark-up, and organize documents so that their content is easily cross-referenced, linked and re-organized for effective delivery on a mobile training platform or other electronic medium. This will be connected to a server and database architecture to facilitate its operation and support storing and accessing content; b) the front-end interface for the mobile training platform (mTraining) was prototyped in Phase I of this project for delivering training content to emergency responders, skilled support personnel, and volunteers before or during an incident. The improved back-end architecture will support intelligent search capabilities for a large repository of training documents with different structures. This capability relies on the document processing engine's ability to semi-automatically extract relevant data and automatically translate this data into a structured format. This data can then be used for display in the mobile application, stored into databases, and automatically populated into ontologies. Throughout this project the participatory-based design paradigm has been used for facilitating the integration of user requirements and the fast prototyping and testing of design alternatives. This approach will continue to be utilized in Phase 2 of the project.         PUBLIC HEALTH RELEVANCE: The proposed research and development will advance the field of environmental health and safety training by bringing to it new and innovative advanced training technologies that are based on the mobile and just-in-time paradigm. Furthermore, the research and development proposed herein will advance the mobile information technology field by developing robust and scalable tools for processing and linking information residing in different source documents that are semantically related.            ",Advanced training platform and methodologies for emergency responders and skilled,8518023,R44ES020135,"['Access to Information', 'Architecture', 'Awareness', 'Back', 'Case Study', 'Data', 'Databases', 'Development', 'Educational Curriculum', 'Educational Materials', 'Electronics', 'Emergency Situation', 'Environmental Health', 'Focus Groups', 'Human Resources', 'Information Technology', 'Link', 'Location', 'Manuals', 'Medical', 'Medical Students', 'Methodology', 'Methods', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Ontology', 'Performance', 'Phase', 'Process', 'Provider', 'Research Infrastructure', 'Retrieval', 'Safety', 'Semantics', 'Services', 'Simulate', 'Site', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Time Management', 'Training', 'Training and Education', 'Translating', 'Update', 'base', 'computer based Semantic Analysis', 'design', 'emergency service responder', 'improved', 'innovation', 'interest', 'operation', 'public health relevance', 'repository', 'research and development', 'response', 'tool', 'usability', 'volunteer']",NIEHS,"NICOLALDE R AND D, LLC",R44,2013,142612,-0.0025350265217759667
"Large-scale Automated Synthesis of Functional Neuroimaging Data     DESCRIPTION (provided by applicant): The explosive growth of the human neuroimaging literature has led to major advances in understanding of normal and abnormal human brain function, but has also made aggregation and synthesis of neuroimaging findings increasingly difficult. The goal of this project is to develop an automated software platform for large-scale synthesis of human functional neuroimaging studies. Our work builds directly on an existing software platform (NeuroSynth) and involves key extensions and improvements that focus on (i) aggregation, (ii) coding, (iii) synthesis, and (iv) sharing of functional neuroimaging data. In Aim 1, we will use computational linguistics and bioinformatics data mining techniques to develop new algorithms for automatically extracting activation foci and associated metadata from published neuroimaging articles. In Aim 2, we will use topic-modeling techniques such as Latent Dirichlet Analysis in combination with existing cognitive ontologies such as the Cognitive Atlas to develop structured representations of automatically extracted neuroimaging data. In Aim 3, we will improve the meta-analysis and classification capacities of our existing platform by implementing a state-of- the-art hierarchical Bayesian meta-analysis method recently developed by the research team. Finally, in Aim 4, we will develop a state-of-the-art web interface (://neurosynth.org) that supports real-time, in-browser access to the data, results, and tools produced in Aims 1 - 3. Realizing these objectives will introduce powerful new tools for organizing and synthesizing the neuroimaging literature on an unprecedented scale. These tools will be freely and publicly available to anyone with an internet connection, enabling rapid and efficient application to a broad range of clinical and basic research applications.          Functional neuroimaging techniques such as fMRI have opened a new frontier in efforts to investigate and understand the neural mechanisms of normal and abnormal cognition. However, the rapidly expanding scope of the literature makes distillation and synthesis of brain imaging findings increasingly challenging. The goal of this project is to develop a new software platform for automated aggregation, synthesis, and sharing of published neuroimaging results, with the potential to advance understanding of mechanisms underlying mental health disorders.                ",Large-scale Automated Synthesis of Functional Neuroimaging Data,8523981,R01MH096906,"['Algorithms', 'Atlases', 'Basic Science', 'Bioinformatics', 'Biometry', 'Brain', 'Brain imaging', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognition', 'Cognitive', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Development', 'Ensure', 'Environment', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'High Performance Computing', 'Human', 'Individual', 'Interdisciplinary Study', 'Internet', 'Joints', 'Journals', 'Language', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Neurosciences', 'Ontology', 'Paper', 'Performance', 'Population', 'Process', 'Publishing', 'Qualifying', 'Research', 'Research Personnel', 'Resources', 'Sample Size', 'Specificity', 'Structure', 'Techniques', 'Text', 'Time', 'Training', 'Validation', 'Work', 'awake', 'base', 'cognitive function', 'data mining', 'frontier', 'improved', 'information organization', 'interoperability', 'knowledge base', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'open source', 'psychologic', 'theories', 'tool', 'web interface']",NIMH,UNIVERSITY OF COLORADO,R01,2013,565156,0.012962139735182924
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data.  PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.          ",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8520329,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2013,301072,-0.034382612424640205
Regulation of Alternative Cleavage and Polyadenylation No abstract available n/a,Regulation of Alternative Cleavage and Polyadenylation,8720197,R01GM084089,"['3&apos', ' Untranslated Regions', 'Address', 'Affect', 'Biochemical', 'Biological', 'Biological Assay', 'Cell Line', 'Classification', 'Code', 'Complementary DNA', 'Computational Molecular Biology', 'DNA Microarray Chip', 'Data', 'Databases', 'Elements', 'Event', 'Evolution', 'Exons', 'Expressed Sequence Tags', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Gene Mutation', 'Genes', 'Genetic Polymorphism', 'Genome', 'Goals', 'Human', 'Indium', 'Introns', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Messenger RNA', 'Metabolism', 'MicroRNAs', 'Modeling', 'Molecular Biology', 'Molecular Biology Techniques', 'Mus', 'Mutagenesis', 'Mutation', 'Pattern', 'Phylogenetic Analysis', 'Poly A', 'Polyadenylation', 'Polyadenylation Pathway', 'Proteins', 'RNA', 'RNA Binding', 'RNA Interference', 'RNA Splicing', 'RNA-Binding Proteins', 'Regulation', 'Regulatory Element', 'Relative (related person)', 'Reporter', 'Site', 'Statistical Models', 'Structure', 'System', 'Technology', 'Tissues', 'Trees', 'Untranslated Regions', 'Validation', 'Variant', 'base', 'human disease', 'improved', 'preference', 'research study', 'serial analysis of gene expression', 'tool']",NIGMS,RBHS-NEW JERSEY MEDICAL SCHOOL,R01,2013,259660,-0.04018381713748396
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8288148,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2012,250764,-0.031113136342338376
"The Crystallography of Macromolecules    DESCRIPTION (provided by applicant): The proposal ""The Crystallography of Macromolecules"" addresses the limitations of diffraction data analysis methods in the field of X-ray crystallography. The significance of this work is determined by the importance of the technique, which generates uniquely-detailed information about cellular processes at the atomic level. The structural results obtained with crystallography are used to explain and validate results obtain by other biophysical, biochemical and cell biology techniques, to generate hypotheses for detailed studies of cellular process and to guide drug design studies - all of which are highly relevant to NIH mission. The proposal focuses on method development to address a frequent situation, where the crystal size and order is insufficient to obtain a structure from a single crystal. This is particularly frequent in cases of large eukaryotic complexes and membrane proteins, where the structural information is the most valuable to the NIH mission. The diffraction power of a single crystal is directly related to the microscopic order and size of that specimen. It is also one of the main correlates of structure solution success. The method used to solve the problem of data insufficiency in the case of a single crystal is to use multiple crystals and to average data between them, which allows to retrieve even very low signals. However, different crystals of the same protein, even if they are very similar i.e. have the same crystal lattice symmetry and very similar unit cell dimensions, still are characterized by a somewhat different order. This non-isomorphism is often high enough to make their solution with averaged data impossible. Moreover, the use of multiple data sets complicates decision making as each of the datasets contains different information and it is not clear when and how to combine them. The proposed solution relies on hierarchical analysis. First, the shape of the diffraction spot profiles will be modeled using a novel approach (Aim 1). This will form the ground for the next step, in which deconvolution of overlapping Bragg spot profiles from multiple lattices will be achieved (Aim 2). An additional benefit of algorithms developed in Aim 1 is that they will automatically derive the integration parameters and identify artifacts, making the whole process more robust. This is particularly significant for high-throughput and multiple crystal analysis. In Aim 3, comparison of data from multiple crystals will be performed to identify subsets of data that should be merged to produce optimal results. The critical aspect of this analysis will be the identification and assessment of non- isomorphism between datasets. The experimental decision-making strategy is the subject of Aim 4. The Support Vector Machine (SVM) method will be used to evaluate the suitability of available datasets for possible methods of structure solution. In cases of insufficient data it will identify the most significant factor that needs to be improved. Aim 5 is to simplify navigation of data reduction and to integrate the results of previous aims with other improvements in hardware and computing.        The goal of the proposal is to develop methods for analysis of X-ray diffraction data with a particular focus on the novel analysis of diffraction spot shape and the streamlining of data analysis in multi-crystal modes. The development of such methods is essential to advance structural studies in thousands of projects, which individually are important for NIH mission.           ",The Crystallography of Macromolecules,8269876,R01GM053163,"['Address', 'Algorithms', 'Anisotropy', 'Biochemical', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Complex', 'Computer software', 'Computers', 'Crystallography', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Decision Making', 'Dependence', 'Development', 'Dimensions', 'Drug Design', 'Evaluation', 'Funding', 'Goals', 'Ice', 'Image', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Noise', 'Output', 'Pattern', 'Phase', 'Problem Solving', 'Procedures', 'Process', 'Proteins', 'Quality Indicator', 'Radiation', 'Relative (related person)', 'Research', 'Resolution', 'Rotation', 'Shapes', 'Signal Transduction', 'Site', 'Solutions', 'Solvents', 'Specimen', 'Spottings', 'Structure', 'System', 'Techniques', 'Technology', 'Twin Multiple Birth', 'United States National Institutes of Health', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'base', 'beamline', 'cell dimension', 'data reduction', 'detector', 'experience', 'improved', 'independent component analysis', 'indexing', 'macromolecule', 'method development', 'novel', 'novel strategies', 'programs', 'research study', 'statistics', 'success', 'user-friendly']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2012,323305,-0.02583997302670392
"Fusion of Electromagnetic Brain Imaging and fMRI    DESCRIPTION (provided by applicant): Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. We propose to develop state-of-the-art multimodal functional imaging fusion algorithms for accurate visualization of the brain's dynamic activity and high spatial and temporal resolution. We propose to develop algorithms that combine complementary high spatial resolution of functional MRI (fMRI) and high-temporal resolution of magnetoencephalography (MEG) and electroencephalography (EEG) data for high-fidelity reconstruction of brain activity. In recent years, our research group has developed a suite of novel and powerful algorithms for MEG/EEG imaging superior to existing benchmark algorithms, and we have compared these results with electrocorticography (ECOG). Specifically, our algorithms can solve for many brain sources, including sources located far from the sensors, in the presence of large interference from unrelated brain sources using fast and robust probabilistic inference techniques. Here, we propose to extend this success in M/EEG inverse algorithms into the domain of multimodal imaging data fusion. Our overall goal here is to ultimately produce robust, high fidelity videos of event-related brain activation at a sub-millimeter and sub-millisecond resolution from noisy MEG/EEG and fMRI data using state-of-the-art machine learning algorithms. Specifically, we propose to extend a powerful new algorithm that we have recently developed, called Champagne, into two new fusion algorithms that combine fMRI, MEG and EEG data in different ways. Performance of both algorithms will first be rigorously evaluated in simulations, including performance comparisons with existing benchmark fusion algorithms. Algorithms will then tested for consistency on four fMRI-MEG+EEG datasets from healthy controls obtained for identical paradigms (auditory, motor, picture naming and verb-generation) and two fMRI-EEG datasets (face and motion perception). Additional validation studies will also be performed on fMRI-MEG/EEG datasets obtained from epilepsy patients and compared to electrocorticography (ECoG). Following successful testing and evaluation, all algorithms developed in this grant proposal, as well as example validation datasets, will be distributed using NUTMEG (nutmeg.berkeley.edu), an open-source software toolbox that we have developed.        Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. With the development of appropriate analytical tools, multimodal functional brain imaging is in the process of revolutionizing the diagnosis and treatment of a variety of neurological and psychiatric disorders such as autism, schizophrenia, dementia, and epilepsy that affect tens of millions of Americans.         ",Fusion of Electromagnetic Brain Imaging and fMRI,8320120,R21NS076171,"['Affect', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Autistic Disorder', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cognitive', 'Computer software', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Electrocorticogram', 'Electroencephalography', 'Electromagnetics', 'Epilepsy', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Human', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Motion Perception', 'Motor', 'Multimodal Imaging', 'Names', 'Nutmeg - dietary', 'Patients', 'Pattern', 'Performance', 'Process', 'Research', 'Resolution', 'Scalp structure', 'Schizophrenia', 'Signal Transduction', 'Source', 'Specific qualifier value', 'Surface', 'Techniques', 'Testing', 'Time', 'Validation', 'Variant', 'analytical tool', 'base', 'blood oxygen level dependent', 'cognitive system', 'evaluation/testing', 'face perception', 'foot', 'hemodynamics', 'imaging modality', 'improved', 'magnetic field', 'millimeter', 'millisecond', 'nervous system disorder', 'novel', 'open source', 'reconstruction', 'relating to nervous system', 'sensor', 'simulation', 'spatiotemporal', 'success', 'tool', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2012,193125,0.0037919437364833286
"Real-Time Automated Detection of Craving States with fMRI and EEG  Project Summary/Abstract Neurofeedback by real time functional MRI (rt-fMRI) has potential for addiction research and treatment that will be realized only if the feedback given the subject is related meaningfully to the cognitive states that must be controlled. The mental operations of the brain are too distributed to be represented by the raw rt-fMRI signal in any one brain region or small group of regions. Our aims are to: 1) Use computational machine learning to rapidly detect patterned activation in the rt-fMRI signal that better expresses cognitive state; 2) augment these data with concurrently-collected electroencephalographic (EEG) data; 3) develop an atlas of brain data that identifies brain patterns with cognitive states relevant to addiction and drug abuse research and 4) to explore rt-fMRI neurofeedback using this rt-fMRI/EEG machine learning method. Our approach will be to first create rapid algorithms for pattern matching that are fast compared with the imaging, thereby allowing ""real-time"" application. To do so we will select features from the images that express the differences among state concisely (more technically, we will use a method known as independent components analysis to reduce the data dimensionality.) We will similarly condense the EEG features by studying them by the location of their sources within the brain, and by examining the frequencies that they contain. We will run experiments on volunteers designed to help us see their tendency to make impulsive choices - which is known to relate to their likelihood to become drug users, as well as experiments that track changes in their brain as they control their craving urges. For these studies we will look at heavy cigarette users. Cigarette use on its own is a serious health burden to the nation, and it is also an excellent model for addiction more generally, as it is known to have many neural features in common with use of other drugs of abuse, such as cocaine and methamphetamine. This is a phased innovation proposal. The first phase will be focused on the developments of the rt-fMRI analysis and instrumentation technology. On its successful completion, based on specific milestones, we will move to the more applied work with human subjects.  Project Narrative Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.",Real-Time Automated Detection of Craving States with fMRI and EEG,8288263,R33DA026109,"['Abstinence', 'Address', 'Affective', 'Algorithms', 'Anterior', 'Atlases', 'Base of the Brain', 'Behavior', 'Brain', 'Brain region', 'Cigarette', 'Classification', 'Clinical', 'Cocaine', 'Cognitive', 'Complex', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Dimensions', 'Discrimination', 'Drug abuse', 'Drug user', 'Electroencephalogram', 'Electroencephalography', 'Electrophysiology (science)', 'Epilepsy', 'Feedback', 'Four-dimensional', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Galvanic Skin Response', 'Generations', 'Goals', 'Health', 'Healthcare', 'Image', 'Imaging technology', 'Impulsivity', 'Intervention', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical', 'Methamphetamine', 'Methods', 'Modeling', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Proxy', 'Psyche structure', 'Reporter', 'Reporting', 'Research', 'Rest', 'Running', 'Scalp structure', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Stimulus', 'Study Subject', 'Technology', 'Testing', 'Time', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'abstracting', 'addiction', 'base', 'blind', 'chronic pain', 'cingulate cortex', 'cognitive control', 'craving', 'data space', 'design', 'discounting', 'drug of abuse', 'effective intervention', 'human subject', 'improved', 'independent component analysis', 'innovation', 'instrument', 'instrumentation', 'interest', 'machine abstracting', 'method development', 'mind control', 'neurofeedback', 'neuroimaging', 'novel', 'operation', 'programs', 'relating to nervous system', 'research study', 'response', 'symposium', 'tool', 'trend', 'virtual', 'volunteer']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R33,2012,566794,-0.002844890522217634
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.      PUBLIC HEALTH RELEVANCE:    The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.                 The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8198847,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2012,499358,0.0011374827312359236
"Development and Dissemination of Robust Brain MRI Measurement Tools     DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: Summary. Neuroimaging provides a safe, non-invasive measurement of the whole brain, and has enabled large clinical and research studies for brain development, aging, and disorders. However, many disorders, i.e., major neurodegenerative and neuropsychiatric disorders, cause complex spatiotemporal patterns of brain alteration, which are often difficult to identify visually and compare over time. To address this critical issu, in the renewal phase of this project, we will continue to work with GE Research to develop and disseminate a software package for brain measurement, comparison, and diagnosis. The new tools include 1) a novel tree-based registration and multi-atlases-based segmentation method for precise measurement of brain alteration patterns, and 2) novel pattern classification and regression methods for early detection and longitudinal monitoring of brain disorders. Aims. Currently, most existing atlas-based labeling methods simply warp each atlas independently to the individual brain for multi-atlases-based structural labeling. This could lead to 1) inaccurate labeling due to possible large registration error when the atlases are very different from the target individual brain, and 2) inconsistent labeling of the same brain structure across different individuals due to independent labeling of each individual brain. The first goal of this project is hence to develop a novel tree-based registration and multi-atlases -based segmentation method for simultaneous registration and joint labeling of all individual brains by concurrent consideration of all atlases. With measurements of brain structures and their alteration patterns, univariate analysis methods are often used to understand how the disease affects brain structure and function at a group level. Although this can lead to better understanding of neurological pathology of brain disorders, more sophisticated image analysis methods are urgently needed for quantitative assessment and early diagnosis of brain abnormality at an individual level. Thus, the second goal of this project is to develop various novel machine learning methods for early diagnosis of brain disorders and better quantification of brain abnormality at an individual level. Specifically, we will take Alzheimer's disease (AD), which is the most common form of dementia, as an example for demonstrating the performance of our proposed methods in early diagnosis of AD, as well as in prediction of long-term outcomes of individuals with mild cognitive impairment (MCI). The last goal of this project is to build, for ou developed methods, the respective software modules for the 3D Slicer (a free open-source software package with a flexible modular platform for medical image analysis and visualization, http://www.slicer.org/), to promote the potential clinical applications by using tools in 3D Slicer for preprocessing of patient data and our tools for diagnosis. Again, this software development work will be performed in collaboration with our current collaborator, GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC) that is focused on developing 3D Slicer. Both source code and pre-compiled programs will be made freely available. Applications. These methods can find their applications in diverse fields, i.e., quantifying brain abnormality of neurological diseases (i.e., AD and schizophrenia), measuring effects of different pharmacological interventions on the brain, and finding associations between structural and cognitive function variables.        PUBLIC HEALTH RELEVANCE: Description of Project This project aims to develop a novel method for accurate measurement of brain structure and function by groupwise registration and joint labeling of all individual images via multiple manual-labeled atlases. Moreover, several novel tools for brain abnormality measurement will also be developed for early detection and progression monitoring of brain disorders using both multimodal imaging and non-imaging data. By successful development of these brain measurement tools, the respective software modules will be developed and further incorporated into 3D Slicer via collaboration with GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC). Both source code and pre-compiled programs will be made freely available.              Description of Project This project aims to develop a novel method for accurate measurement of brain structure and function by groupwise registration and joint labeling of all individual images via multiple manual-labeled atlases. Moreover, several novel tools for brain abnormality measurement will also be developed for early detection and progression monitoring of brain disorders using both multimodal imaging and non-imaging data. By successful development of these brain measurement tools, the respective software modules will be developed and further incorporated into 3D Slicer via collaboration with GE Research, which is a part of the engineering core of the National Alliance for Medical Image Computing (NA-MIC). Both source code and pre-compiled programs will be made freely available.            ",Development and Dissemination of Robust Brain MRI Measurement Tools,8390370,R01EB006733,"['Address', 'Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Classification', 'Clinical', 'Clinical Research', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Engineering', 'Functional Magnetic Resonance Imaging', 'Goals', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Multimodal Imaging', 'Nerve Degeneration', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Research', 'Sampling', 'Schizophrenia', 'Simulate', 'Slice', 'Source Code', 'Staging', 'Structure', 'Testing', 'Time', 'Training', 'Trees', 'Update', 'Work', 'abstracting', 'base', 'clinical application', 'cognitive function', 'disease diagnosis', 'flexibility', 'image registration', 'image visualization', 'information classification', 'mild neurocognitive impairment', 'nervous system disorder', 'neuroimaging', 'neurological pathology', 'neuropsychiatry', 'novel', 'open source', 'programs', 'research study', 'software development', 'spatiotemporal', 'symposium', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2012,531904,-0.012733949938230795
"OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN This proposal describes plans to enhance Viocare¿s Mobile Food Intake Visual and Voice Recognizer (FIVR) System. FIVR, an active Genes, Environment and Health Initiative (GEI) project, is a novel combination of innovative technologies including computer vision and speech recognition to measure dietary intake using a mobile phone. Version 1 of FIVR uses a mobile phone¿s embedded camera to capture a short video of food to be consumed. The food to be eaten is annotated verbally on the mobile phone by the user. These video and audio files are sent to a backend server for real-time food recognition and portion size measurement through speech recognition and image analysis. This project will develop specifications to extend FIVR¿s capabilities to standardize, store, and analyze more diverse food images, such as 3D photos; to collect other food data; to enhance the analysis tools; and for interfaces to a variety of clinical/research systems. The FIVR Version 2 functional prototype will be developed to use 3D dietary images as input. A final evaluation of the FIVR V2 prototype will be conducted to assess the accuracy and feasibility of the 3D image diet capture with a group of 9 subjects in a controlled feeding study. n/a","OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN",8554263,61201200042C,"['Car Phone', 'Clinical Research', 'Computer Vision Systems', 'Data', 'Diet', 'Dietary intake', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Food', 'Genes', 'Health', 'Image', 'Image Analysis', 'Measurement', 'Measures', 'Phase', 'Reporting', 'Small Business Innovation Research Grant', 'System', 'Three-Dimensional Image', 'Time', 'Visual', 'Voice', 'feeding', 'innovative technologies', 'novel', 'prototype', 'speech recognition', 'tool']",NCI,"VIOCARE, INC.",N43,2012,200000,-0.011493751274365086
"Vision Without Sight: Exploring the Environment with a Portable Camera  Vision without Sight: Exploring the Environment with a Portable Camera Project Summary As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his colaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specificaly examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.  Vision without Sight: Exploring the Environment with a Portable Camera Project Narrative The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cel phones but are typicaly designed for normaly sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population",Vision Without Sight: Exploring the Environment with a Portable Camera,8334623,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Telephone', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2012,229834,0.027614198602419458
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.      PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.              Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.",Perception of Tactile Graphics,8265243,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'public health relevance', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2012,52190,-0.006621158861123299
"Manipulating Neural Tissue with Ultra-Short Laser Pulses    DESCRIPTION (provided by applicant):  We seek to renew our joint discovery and technology based bioengineering research partnership (BRP).  Our program advances the use of amplified ultrashort laser pulses as a tool to manipulate living and histological tissue.  This unique technology, pioneered by the BRP team, permits tissue to be cut on the micrometer scale by light-fueled plasma-meditated ablation.  Cutting occurs without thermal damage and can be combined with spectroscopic feedback to identify and limit the region being perturbed.  We advance this technology in new ways, including the use of temporal focusing for deep ablation, and apply it to three key test beds.  The first is construction of the angiotome, i.e., a complete vectorized map of cortical vasculature; here we use plasma mediated ablation to automate a form of block-face imaging along with novel algorithms to filter and vectorize features in the data.  The second is the study of neuronal viability in response to perturbations of subcortical blood flow; here we use plasma-mediated ablation to block flow in individual targeted microvessels that lie below the cortical surface.  The third test bed is the automation of cranial and spinal surgery; we combine plasma-mediated ablation with laser-induced breakdown spectroscopy to cut bone yet avoid injury to soft tissue.  These investigations are particularly relevant to diagnosing and understanding microinfarctions, i.e., damage to the brain as the result of damage to single cortical vessels, that accumulate with age and trauma.      PUBLIC HEALTH RELEVANCE:  These studies advance the use of light to image and manipulate the flow of blood in the brain.  We make use of rats and mice as model systems for our experiments.  The new capabilities from the proposed work hold two promises for advances in medicine:  One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma.  The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.              Program Director (Last, first, middle): Kleinfeld, David, Kaufhold, John and Squier, Jeffrey. These studies advance the use of light to image and manipulate the flow of blood in the brain. We make use of rats and mice as model systems for our experiments. The new capabilities from the proposed work hold two promises for advances in medicine: One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma. The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.",Manipulating Neural Tissue with Ultra-Short Laser Pulses,8319531,R01EB003832,"['3-Dimensional', 'Ablation', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Automation', 'Beds', 'Biological Models', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Cephalic', 'Cessation of life', 'Craniotomy', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Face', 'Feedback', 'Fluorescence', 'Functional Imaging', 'Future', 'Generations', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Joints', 'Label', 'Laminectomy', 'Lasers', 'Lateral', 'Lead', 'Learning', 'Lesion', 'Life', 'Light', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Mediating', 'Medical Imaging', 'Medicine', 'Metabolism', 'Methodology', 'Mitochondria', 'Modeling', 'Mus', 'Neocortex', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Organelles', 'Pattern', 'Physiologic pulse', 'Plasma', 'Process', 'Rattus', 'Reperfusion Therapy', 'Research', 'Resolution', 'Role', 'Scanning', 'Shapes', 'Spectrum Analysis', 'Speed', 'Spinal', 'Stroke', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Ursidae Family', 'Veins', 'Work', 'arteriole', 'base', 'bone', 'brain cell', 'capillary', 'design', 'hemodynamics', 'meetings', 'millimeter', 'neurosurgery', 'novel', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'research study', 'response', 'second harmonic', 'soft tissue', 'tool', 'two-photon']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,892777,-0.013738458954063233
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma  ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans.  PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8209138,K99EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2012,89325,-0.003392513311242414
"Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment    DESCRIPTION (provided by applicant): Functional neuroimaging studies of the human brain have become increasingly important in the understanding of normal and pathological processes of cognition. Sophisticated statistical analytic frameworks have been developed to locate signal change and define brain networks involved in various tasks. However, in subtle cognitive impairment-e.g., exposure-related illness, early stages of degenerative diseases, injury, secondary illness following adjuvant therapy for cancer-these methods tend to have low sensitivity for detecting small changes in brain states resulting from mild brain dysfunction. An understanding of disease mechanism or progression of subtle cognitive dysfunction requires a novel statistical analytic framework with improved sensitivity to measure small changes in brain states. We have developed an innovative methodology that we successfully applied in measures of regional cerebral blood flow experiments. These methods use well established spatial modeling procedures, new to the functional brain imaging field, to derive statistically optimal spatial summaries within effective resolution groups or ""kriging"", shown by preliminary studies to improve signal detection sensitivity and mitigate the multiple testing burden. Within this new spatial modeling framework, we propose to extend the kriging methodology to fMRI and EEG, modify existing techniques for characterizing brain networks of connectivity (e.g., kriging-based independent components analysis), and integrate the imaging modalities using a statistical classifier based on derived inputs of data driven effective resolution groups. Our primary goal is to develop this analysis framework to provide insight into the neurophysiological mechanisms of mild cognitive dysfunction. Achieving this goal may suggest treatments to alleviate symptoms, prevent progression, or at minimum, provide an informed clinical management of cognitively impaired patients.      PUBLIC HEALTH RELEVANCE: Cognitive impairment is a major health concern, affecting people of all ages. Causes range from traumatic injury to toxin exposures, including chemotherapy for cancer treatment, to degenerative diseases. Mechanisms of damage or disease remain difficult to establish using current methods in functional brain imaging studies due to an inability to measure very small changes in brain states. We propose a new analytic framework using existing technology to improve the ability to measure subtle changes important in the understanding of disease pathology of impaired cognition and to greatly facilitate the integration of information from several imaging modalities with potential implications for clinical management and treatment.              Cognitive impairment is a major health concern, affecting people of all ages. Causes range from traumatic injury to toxin exposures, including chemotherapy for cancer treatment, to degenerative diseases. Mechanisms of damage or disease remain difficult to establish using current methods in functional brain imaging studies due to an inability to measure very small changes in brain states. We propose a new analytic framework using existing technology to improve the ability to measure subtle changes important in the understanding of disease pathology of impaired cognition and to greatly facilitate the integration of information from several imaging modalities with potential implications for clinical management and treatment.            ",Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment,8229843,R21EB014563,"['Adjuvant Therapy', 'Affect', 'Age', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrovascular Circulation', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Treatment', 'Cognition', 'Data', 'Databases', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Injury', 'Ions', 'Lead', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Neurocognitive', 'Neurotoxins', 'Outcome', 'Output', 'Pathologic Processes', 'Pathology', 'Patients', 'Procedures', 'Process', 'Property', 'Reliance', 'Research Personnel', 'Resolution', 'Sampling', 'Secondary to', 'Semantic memory', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Spin Labels', 'Staging', 'Statistical Methods', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Weight', 'Work', 'base', 'behavior measurement', 'behavior test', 'cancer therapy', 'case-based', 'chemobrain', 'chemotherapy', 'data reduction', 'executive function', 'image registration', 'imaging modality', 'improved', 'independent component analysis', 'innovation', 'insight', 'mild neurocognitive impairment', 'neurocognitive test', 'neuroimaging', 'neurophysiology', 'novel', 'prevent', 'research study', 'single photon emission computed tomography', 'tool', 'treatment strategy']",NIBIB,UT SOUTHWESTERN MEDICAL CENTER,R21,2012,173138,-0.007986172304984752
"Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development    DESCRIPTION (provided by applicant): Selective potentiators of the metabotropic glutamate receptor subtype mGluR5 have exciting potential for development of novel treatment strategies for schizophrenia and other disorders that disrupt cognitive func-tion. The latest generation of selective mGluR5 potentiators is based on the lead compound CDPPB and features systemically active compounds with long half-lives that cross the blood-brain barrier. A high-throughput screen (HTS) for mGluR5 potentiators at Vanderbilt's screening center revealed a large and diverse set of about 1400 substances (1% hit rate) whose activity was validated in independent experiments.  A previous exploratory research grant ""Novel Schizophrenia Therapeutics by Virtual High-Throughput Screening"" (R21 MH082254) enabled testing of 813 compounds predicted through cheminformatics. 252 of these compounds were confirmed as active PAMs equaling an enrichment of >30 when compared with the original screen. The present proposal seeks to leverage these proof-of-principle results for the development of a tailored cheminformatics framework for drug discovery of allosteric modulators of brain GPCRs, apply these tools to inform an existing therapeutic discovery program of mGluR5 potentiators at Vanderbilt University, and disseminate the methods broadly through the NIH molecular libraries program.  The central hypothesis of this proposal is that the complex relationship between chemical structure and biological activity of mGluR5 potentiators observed in this HTS can be used to generate a pharmacophore of the mGluR5 allosteric site. This map of steric and electronic features necessary for optimal interaction of modulators with mGluR5 will not only inform our understanding of the allosteric modulation of brain GPCRs. The methods proposed overcome limitations of present cheminformatics techniques by enabling identification of novel chemotypes through virtual screening (scaffold hoping), and allowing design of focused libraries in hit-to- lead optimization of novel schizophrenia therapeutics.  The generalizbility of the approach will be tested through application on negative modulators of mGluR5, a potential novel treatment strategy of fragile X syndrome, a CNS disorder associated with autism spectrum disorders (ASD) among multiple other symptoms. The developed applications will be made freely and readily accessible for academic research. The employed QSAR models require no crystal structure of the target brain GPCR. Hence the method can be readily applied to membrane proteins-such as GPCRs-which are target of 40-50% of modern medicinal drugs.      PUBLIC HEALTH RELEVANCE: Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.           PROJECT NARRATIVE  Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.",Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development,8212449,R01MH090192,"['Algorithms', 'Allosteric Site', 'Benchmarking', 'Biological', 'Blood - brain barrier anatomy', 'Brain', 'Central Nervous System Diseases', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chemosensitization', 'Cognitive', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consensus', 'Databases', 'Descriptor', 'Development', 'Disease', 'Education', 'Electronics', 'Fragile X Syndrome', 'G Protein-Coupled Receptor Genes', 'Generations', 'Hand', 'Humulus', 'Internet', 'Lead', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Mental disorders', 'Metabotropic Glutamate Receptors', 'Methods', 'Modeling', 'Molecular', 'Molecular Bank', 'Pharmaceutical Preparations', 'Pharmacology', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Project Grants', 'Scheme', 'Schizophrenia', 'Screening procedure', 'Site', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Universities', 'Walking', 'Work', 'autism spectrum disorder', 'base', 'chemical synthesis', 'cheminformatics', 'cognitive function', 'comparative', 'design', 'drug discovery', 'experience', 'high throughput screening', 'nervous system disorder', 'novel', 'pharmacophore', 'programs', 'public health relevance', 'research study', 'scaffold', 'therapeutic development', 'therapeutic target', 'tool', 'treatment strategy', 'virtual']",NIMH,VANDERBILT UNIVERSITY,R01,2012,385984,-0.03154077950250032
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8473426,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2012,407051,0.025518924541197516
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,-0.015245176643005889
"Quantitative Methods for Neuroimaging Studies of Interventions in Aging    DESCRIPTION (provided by applicant): This proposal for an NIH Mentored Quantitative Research Career Award requests support for Dr. Yongmei Michelle Wang as she embarks on a faculty career focused on imaging studies which examine the influence of longitudinal interventions on brain structure and function, and its relationship to cognition and performance, in older adults. The application proposes a research career development plan in the field of neuroimaging, bridging engineering, statistics, and neuroscience. The plan includes two overlapping phases: 1) a didactic phase that emphasizes training, including coursework and laboratory work in the area of cognitive neuroscience, imaging, aging, and interventions to complement Dr. Wang's doctoral training in Electrical Engineering and existing experience in Statistics; and 2) a development phase that focuses on intense development of the proposed research. These two phases will be closely supervised by the mentor and advisor in the area of cognitive neuroscience, brain plasticity, biomedical imaging, aging and interventions. Neuroimaging techniques, such as magnetic resonance imaging (MRI) and functional MRI (fMRI), have been shown to be powerful for characterizing and understanding the structure and function of the human brain. There remains a need, however, for robust and efficient statistical image analysis methods due to the limitations of existing approaches. It is crucial that these analysis techniques be developed with a full understanding of the neuroimaging methods used and the relevant cognitive neuroscience. We propose to develop, implement, and validate integrated computational algorithms for reliable and sensitive analysis of brain MRI and fMRI images, with the following specific aims: 1) Develop, validate and combine novel and efficient univariate and multivariate morphometry analysis methods. 2) Develop and evaluate integrated functional hemodynamic response and connectivity study approaches. 3) Apply these methods to the MRI and fMRI data being collected from separately funded NIA project of the mentor, to examine the effects of aerobic fitness training on brain structure and function of older adults; the neuroscience hypothesis to be tested are: improvements in aerobic fitness, over the course of a 1 year intervention, will result in i) increases in gray and white matter volume and shape changes of subcortical structures of the human brain; and ii) changes in the underlying neural circuits. 4) Develop a brain image analysis toolbox implementing the above methods.       PUBLIC HEALTH RELEVANCE: The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.              PROJECT NARRATIVE The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.",Quantitative Methods for Neuroimaging Studies of Interventions in Aging,8318665,K25AG033725,"['Adult', 'Aerobic', 'Age', 'Aging', 'Algorithms', 'American', 'Area', 'Attention', 'Award', 'Awareness', 'Bayesian Method', 'Behavior', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Computational algorithm', 'Conflict (Psychology)', 'Data', 'Detection', 'Deterioration', 'Development', 'Development Plans', 'Dimensions', 'Economic Burden', 'Elderly', 'Electrical Engineering', 'Engineering', 'Exhibits', 'Faculty', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Health', 'Hippocampus (Brain)', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Intervention', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Markov Chains', 'Medial', 'Memory', 'Mentors', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Multivariate Analysis', 'Neurosciences', 'Noise', 'Parietal', 'Participant', 'Pattern', 'Performance', 'Phase', 'Physical activity', 'Population', 'Prefrontal Cortex', 'Process', 'Public Health', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Risk Behaviors', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Statistical Methods', 'Structure', 'Surface', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'age related', 'aging brain', 'aging mind', 'base', 'bioimaging', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'executive function', 'experience', 'fitness', 'flexibility', 'gray matter', 'healthy aging', 'hemodynamics', 'improved', 'interest', 'intervention effect', 'morphometry', 'neural circuit', 'neuroimaging', 'new technology', 'novel', 'public health relevance', 'relating to nervous system', 'relational memory', 'research study', 'response', 'sedentary', 'shape analysis', 'social', 'statistics', 'therapy design', 'tool', 'white matter', 'young adult']",NIA,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K25,2012,150833,-0.008538072512311477
"Large-scale Automated Synthesis of Functional Neuroimaging Data     DESCRIPTION (provided by applicant): The explosive growth of the human neuroimaging literature has led to major advances in understanding of normal and abnormal human brain function, but has also made aggregation and synthesis of neuroimaging findings increasingly difficult. The goal of this project is to develop an automated software platform for large-scale synthesis of human functional neuroimaging studies. Our work builds directly on an existing software platform (NeuroSynth) and involves key extensions and improvements that focus on (i) aggregation, (ii) coding, (iii) synthesis, and (iv) sharing of functional neuroimaging data. In Aim 1, we will use computational linguistics and bioinformatics data mining techniques to develop new algorithms for automatically extracting activation foci and associated metadata from published neuroimaging articles. In Aim 2, we will use topic-modeling techniques such as Latent Dirichlet Analysis in combination with existing cognitive ontologies such as the Cognitive Atlas to develop structured representations of automatically extracted neuroimaging data. In Aim 3, we will improve the meta-analysis and classification capacities of our existing platform by implementing a state-of- the-art hierarchical Bayesian meta-analysis method recently developed by the research team. Finally, in Aim 4, we will develop a state-of-the-art web interface (://neurosynth.org) that supports real-time, in-browser access to the data, results, and tools produced in Aims 1 - 3. Realizing these objectives will introduce powerful new tools for organizing and synthesizing the neuroimaging literature on an unprecedented scale. These tools will be freely and publicly available to anyone with an internet connection, enabling rapid and efficient application to a broad range of clinical and basic research applications.        PUBLIC HEALTH RELEVANCE: Functional neuroimaging techniques such as fMRI have opened a new frontier in efforts to investigate and understand the neural mechanisms of normal and abnormal cognition. However, the rapidly expanding scope of the literature makes distillation and synthesis of brain imaging findings increasingly challenging. The goal of this project is to develop a new software platform for automated aggregation, synthesis, and sharing of published neuroimaging results, with the potential to advance understanding of mechanisms underlying mental health disorders.                  Functional neuroimaging techniques such as fMRI have opened a new frontier in efforts to investigate and understand the neural mechanisms of normal and abnormal cognition. However, the rapidly expanding scope of the literature makes distillation and synthesis of brain imaging findings increasingly challenging. The goal of this project is to develop a new software platform for automated aggregation, synthesis, and sharing of published neuroimaging results, with the potential to advance understanding of mechanisms underlying mental health disorders.                ",Large-scale Automated Synthesis of Functional Neuroimaging Data,8397498,R01MH096906,"['Algorithms', 'Atlases', 'Basic Science', 'Bioinformatics', 'Biometry', 'Brain', 'Brain imaging', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognition', 'Cognitive', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Development', 'Ensure', 'Environment', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'High Performance Computing', 'Human', 'Individual', 'Interdisciplinary Study', 'Internet', 'Joints', 'Journals', 'Language', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Neurosciences', 'Ontology', 'Paper', 'Performance', 'Population', 'Process', 'Publishing', 'Qualifying', 'Research', 'Research Personnel', 'Resources', 'Sample Size', 'Specificity', 'Structure', 'Techniques', 'Text', 'Time', 'Training', 'Validation', 'Work', 'awake', 'base', 'cognitive function', 'data mining', 'frontier', 'improved', 'information organization', 'interoperability', 'knowledge base', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'open source', 'psychologic', 'theories', 'tool', 'web interface']",NIMH,UNIVERSITY OF COLORADO,R01,2012,723109,0.008456942442772354
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8281471,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2012,272755,-0.034382612424640205
"CASE STUDIES IN BAYESIAN STATISTICS AND MACHINE LEARNING    DESCRIPTION (provided by applicant): Case Studies in Bayesian Statistics and Machine Learning I continues in the tradition of the Case Studies in Bayesian Statistics series. The original series of workshops were held in odd years at Carnegie Mellon University in the early fall. The first edition of the new workshop will be held at Carnegie Mellon University on October 14-15, 2011. The highest level goal of the workshop series is to generate and present successful solutions to difficult substantive problems in a wide variety of areas. The specific objectives of the workshop are to 1. Present and discuss solutions to challenging scientific problems that illustrate the potential for statistical machine learning approaches in substantive research; 2. Present an opportunity for statisticians and computer scientists to present applications-oriented research  that changes the way that data are analyzed in scientific fields; 3. Stimulate discussion of the challenges of the analysis of high-dimensional and complex datasets in a scientifically useful manner; 4. Encourage young researchers, including graduate students, to present their applied work; 5. Provide a small meeting atmosphere to facilitate the interaction of young researchers with senior colleagues; 6. Expose young researchers to important challenges and opportunities in collaborative research; 7. Include as participants women, under-represented minorities and persons with disabilities who might benefit from the small workshop environment; 8. Encourage dissemination of the findings presented at the workshop via well-documented and peer- reviewed journal articles.      PUBLIC HEALTH RELEVANCE: Bayesian and statistical machine learning approaches are essential for the analysis of data in the health sciences, particularly in complex diseases like cancer. The proposed workshop will highlight interesting applications of Bayesian and statistical machine learning, particularly in bioinformatics and imaging, which are relevant to cancer research and provide a venue for important collaboration amongst junior and senior researchers in statistics, computer science, and other disciplines.           Bayesian and statistical machine learning approaches are essential for the analysis of data in the health sciences, particularly in complex diseases like cancer. The proposed workshop will highlight interesting applications of Bayesian and statistical machine learning, particularly in bioinformatics and imaging, which are relevant to cancer research and provide a venue for important collaboration amongst junior and senior researchers in statistics, computer science, and other disciplines.         ",CASE STUDIES IN BAYESIAN STATISTICS AND MACHINE LEARNING,8203089,R13CA144626,"['Area', 'Bioinformatics', 'Case Study', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Data Analyses', 'Data Set', 'Disabled Persons', 'Discipline', 'Disease', 'Educational workshop', 'Environment', 'Fostering', 'Goals', 'Hand', 'Health Sciences', 'Image', 'Institutes', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Participant', 'Peer Review', 'Research', 'Research Personnel', 'Scientist', 'Series', 'Solutions', 'Underrepresented Minority', 'Universities', 'Woman', 'Work', 'anticancer research', 'computer science', 'data modeling', 'falls', 'graduate student', 'interest', 'journal article', 'meetings', 'peer', 'planetary Atmosphere', 'statistics', 'symposium']",NCI,CARNEGIE-MELLON UNIVERSITY,R13,2011,7500,-0.024814899236433693
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.          PROJECT NARRATIVE:  There is a considerable need for improved educational software for mathematics in general, but the problem of  quality educational software materials for the blind and visually impaired is particularly acute. A weak  mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or  even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of  science, technology, engineering and mathematics. Through previous federally-supported research, Quantum  Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI)  tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power  and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8055353,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Health', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2011,394165,0.013833640239951827
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.           Project Narrative The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.",Scalable Learning with Ensemble Techniques and Parallel Computing,8045486,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Biological Sciences', 'Biomedical Research', 'Classification', 'Communication', 'Communities', 'Community Financing', 'Companions', 'Complex', 'Computer software', 'Consult', 'Crowding', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Health', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'new technology', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2011,374673,-0.004574715080834356
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,8142000,R01EY016093,"['Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Peripheral', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,1141143,0.012604180852127576
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8062031,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Health', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2011,359403,-0.015143964954971383
"The Crystallography of Macromolecules    DESCRIPTION (provided by applicant): The proposal ""The Crystallography of Macromolecules"" addresses the limitations of diffraction data analysis methods in the field of X-ray crystallography. The significance of this work is determined by the importance of the technique, which generates uniquely-detailed information about cellular processes at the atomic level. The structural results obtained with crystallography are used to explain and validate results obtain by other biophysical, biochemical and cell biology techniques, to generate hypotheses for detailed studies of cellular process and to guide drug design studies - all of which are highly relevant to NIH mission. The proposal focuses on method development to address a frequent situation, where the crystal size and order is insufficient to obtain a structure from a single crystal. This is particularly frequent in cases of large eukaryotic complexes and membrane proteins, where the structural information is the most valuable to the NIH mission. The diffraction power of a single crystal is directly related to the microscopic order and size of that specimen. It is also one of the main correlates of structure solution success. The method used to solve the problem of data insufficiency in the case of a single crystal is to use multiple crystals and to average data between them, which allows to retrieve even very low signals. However, different crystals of the same protein, even if they are very similar i.e. have the same crystal lattice symmetry and very similar unit cell dimensions, still are characterized by a somewhat different order. This non-isomorphism is often high enough to make their solution with averaged data impossible. Moreover, the use of multiple data sets complicates decision making as each of the datasets contains different information and it is not clear when and how to combine them. The proposed solution relies on hierarchical analysis. First, the shape of the diffraction spot profiles will be modeled using a novel approach (Aim 1). This will form the ground for the next step, in which deconvolution of overlapping Bragg spot profiles from multiple lattices will be achieved (Aim 2). An additional benefit of algorithms developed in Aim 1 is that they will automatically derive the integration parameters and identify artifacts, making the whole process more robust. This is particularly significant for high-throughput and multiple crystal analysis. In Aim 3, comparison of data from multiple crystals will be performed to identify subsets of data that should be merged to produce optimal results. The critical aspect of this analysis will be the identification and assessment of non- isomorphism between datasets. The experimental decision-making strategy is the subject of Aim 4. The Support Vector Machine (SVM) method will be used to evaluate the suitability of available datasets for possible methods of structure solution. In cases of insufficient data it will identify the most significant factor that needs to be improved. Aim 5 is to simplify navigation of data reduction and to integrate the results of previous aims with other improvements in hardware and computing.      PUBLIC HEALTH RELEVANCE: The goal of the proposal is to develop methods for analysis of X-ray diffraction data with a particular focus on the novel analysis of diffraction spot shape and the streamlining of data analysis in multi-crystal modes. The development of such methods is essential to advance structural studies in thousands of projects, which individually are important for NIH mission.             The goal of the proposal is to develop methods for analysis of X-ray diffraction data with a particular focus on the novel analysis of diffraction spot shape and the streamlining of data analysis in multi-crystal modes. The development of such methods is essential to advance structural studies in thousands of projects, which individually are important for NIH mission.           ",The Crystallography of Macromolecules,8108523,R01GM053163,"['Address', 'Algorithms', 'Anisotropy', 'Biochemical', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Complex', 'Computer software', 'Computers', 'Crystallography', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Decision Making', 'Dependence', 'Development', 'Dimensions', 'Drug Design', 'Evaluation', 'Funding', 'Goals', 'Ice', 'Image', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Noise', 'Output', 'Pattern', 'Phase', 'Problem Solving', 'Procedures', 'Process', 'Proteins', 'Quality Indicator', 'Radiation', 'Relative (related person)', 'Research', 'Resolution', 'Rotation', 'Shapes', 'Signal Transduction', 'Site', 'Solutions', 'Solvents', 'Specimen', 'Spottings', 'Structure', 'System', 'Techniques', 'Technology', 'Twin Multiple Birth', 'United States National Institutes of Health', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'base', 'beamline', 'cell dimension', 'data reduction', 'detector', 'experience', 'improved', 'independent component analysis', 'indexing', 'macromolecule', 'method development', 'novel', 'novel strategies', 'programs', 'research study', 'statistics', 'success', 'user-friendly']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2011,341852,-0.022365671694181598
"Real-Time Automated Detection of Craving States with fMRI and EEG    DESCRIPTION (provided by applicant):  Neurofeedback by real time functional MRI (rt-fMRI) has potential for addiction research and treatment that will be realized only if the feedback given the subject is related meaningfully to the cognitive states that must be controlled. The mental operations of the brain are too distributed to be represented by the raw rt-fMRI signal in any one brain region or small group of regions. Our aims are to: 1) Use computational machine learning to rapidly detect patterned activation in the rt-fMRI signal that better expresses cognitive state; 2) augment these data with concurrently-collected electroencephalographic (EEG) data; 3) develop an atlas of brain data that identifies brain patterns with cognitive states relevant to addiction and drug abuse research and 4) to explore rt-fMRI neurofeedback using this rt-fMRI/EEG machine learning method. Our approach will be to first create rapid algorithms for pattern matching that are fast compared with the imaging, thereby allowing ""real-time"" application. To do so we will select features from the images that express the differences among state concisely (more technically, we will use a method known as independent components analysis to reduce the data dimensionality.) We will similarly condense the EEG features by studying them by the location of their sources within the brain, and by examining the frequencies that they contain. We will run experiments on volunteers designed to help us see their tendency to make impulsive choices - which is known to relate to their likelihood to become drug users, as well as experiments that track changes in their brain as they control their craving urges. For these studies we will look at heavy cigarette users. Cigarette use on its own is a serious health burden to the nation, and it is also an excellent model for addiction more generally, as it is known to have many neural features in common with use of other drugs of abuse, such as cocaine and methamphetamine. This is a phased innovation proposal. The first phase will be focused on the developments of the rt-fMRI analysis and instrumentation technology. On its successful completion, based on specific milestones, we will move to the more applied work with human subjects.      PUBLIC HEALTH RELEVANCE:  Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.           Project Narrative Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.",Real-Time Automated Detection of Craving States with fMRI and EEG,8104246,R33DA026109,"['Abstinence', 'Address', 'Affective', 'Algorithms', 'Anterior', 'Atlases', 'Base of the Brain', 'Behavior', 'Brain', 'Brain region', 'Cigarette', 'Classification', 'Clinical', 'Cocaine', 'Cognitive', 'Complex', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Dimensions', 'Discrimination', 'Drug abuse', 'Drug user', 'Electroencephalogram', 'Electroencephalography', 'Electrophysiology (science)', 'Epilepsy', 'Feedback', 'Four-dimensional', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Galvanic Skin Response', 'Generations', 'Goals', 'Health', 'Healthcare', 'Image', 'Imaging technology', 'Impulsivity', 'Intervention', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical', 'Methamphetamine', 'Methods', 'Modeling', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Proxy', 'Psyche structure', 'Reporter', 'Reporting', 'Research', 'Rest', 'Running', 'Scalp structure', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Stimulus', 'Study Subject', 'Technology', 'Testing', 'Time', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'abstracting', 'addiction', 'base', 'blind', 'chronic pain', 'cingulate cortex', 'cognitive control', 'craving', 'data space', 'design', 'discounting', 'drug of abuse', 'effective intervention', 'human subject', 'improved', 'independent component analysis', 'innovation', 'instrument', 'instrumentation', 'interest', 'machine abstracting', 'method development', 'mind control', 'neurofeedback', 'neuroimaging', 'novel', 'operation', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'symposium', 'tool', 'trend', 'virtual', 'volunteer']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R33,2011,575153,-0.0062426938072097735
"Fusion of Electromagnetic Brain Imaging and fMRI    DESCRIPTION (provided by applicant): Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. We propose to develop state-of-the-art multimodal functional imaging fusion algorithms for accurate visualization of the brain's dynamic activity and high spatial and temporal resolution. We propose to develop algorithms that combine complementary high spatial resolution of functional MRI (fMRI) and high-temporal resolution of magnetoencephalography (MEG) and electroencephalography (EEG) data for high-fidelity reconstruction of brain activity. In recent years, our research group has developed a suite of novel and powerful algorithms for MEG/EEG imaging superior to existing benchmark algorithms, and we have compared these results with electrocorticography (ECOG). Specifically, our algorithms can solve for many brain sources, including sources located far from the sensors, in the presence of large interference from unrelated brain sources using fast and robust probabilistic inference techniques. Here, we propose to extend this success in M/EEG inverse algorithms into the domain of multimodal imaging data fusion. Our overall goal here is to ultimately produce robust, high fidelity videos of event-related brain activation at a sub-millimeter and sub-millisecond resolution from noisy MEG/EEG and fMRI data using state-of-the-art machine learning algorithms. Specifically, we propose to extend a powerful new algorithm that we have recently developed, called Champagne, into two new fusion algorithms that combine fMRI, MEG and EEG data in different ways. Performance of both algorithms will first be rigorously evaluated in simulations, including performance comparisons with existing benchmark fusion algorithms. Algorithms will then tested for consistency on four fMRI-MEG+EEG datasets from healthy controls obtained for identical paradigms (auditory, motor, picture naming and verb-generation) and two fMRI-EEG datasets (face and motion perception). Additional validation studies will also be performed on fMRI-MEG/EEG datasets obtained from epilepsy patients and compared to electrocorticography (ECoG). Following successful testing and evaluation, all algorithms developed in this grant proposal, as well as example validation datasets, will be distributed using NUTMEG (nutmeg.berkeley.edu), an open-source software toolbox that we have developed.      PUBLIC HEALTH RELEVANCE: Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. With the development of appropriate analytical tools, multimodal functional brain imaging is in the process of revolutionizing the diagnosis and treatment of a variety of neurological and psychiatric disorders such as autism, schizophrenia, dementia, and epilepsy that affect tens of millions of Americans.           Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. With the development of appropriate analytical tools, multimodal functional brain imaging is in the process of revolutionizing the diagnosis and treatment of a variety of neurological and psychiatric disorders such as autism, schizophrenia, dementia, and epilepsy that affect tens of millions of Americans.         ",Fusion of Electromagnetic Brain Imaging and fMRI,8247368,R21NS076171,"['Affect', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Autistic Disorder', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cognitive', 'Computer software', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Electrocorticogram', 'Electroencephalography', 'Electromagnetics', 'Epilepsy', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Human', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Motion Perception', 'Motor', 'Multimodal Imaging', 'Names', 'Nutmeg - dietary', 'Patients', 'Pattern', 'Performance', 'Process', 'Research', 'Resolution', 'Scalp structure', 'Schizophrenia', 'Signal Transduction', 'Source', 'Specific qualifier value', 'Surface', 'Techniques', 'Testing', 'Time', 'Validation', 'Variant', 'analytical tool', 'base', 'blood oxygen level dependent', 'cognitive system', 'evaluation/testing', 'face perception', 'foot', 'hemodynamics', 'imaging modality', 'improved', 'magnetic field', 'millimeter', 'millisecond', 'nervous system disorder', 'novel', 'open source', 'reconstruction', 'relating to nervous system', 'sensor', 'simulation', 'spatiotemporal', 'success', 'tool', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2011,231750,0.001864268761304529
"NLP for Augmentative and Alternative Communication in Adults    DESCRIPTION (provided by applicant):  This proposal relates to the technology of Augmentative and Alternative Communication (AAC).  The research, to be developed over the three-year course of this project, relates to increasing communication speed for adult users of typing-based AAC devices. The proposed method has commonalities both with chatter bots and more sophisticated automated question answering systems. In particular, we propose to develop a program that will mine a very large database of stored interactions for sentences that are similar to the sentence currently being uttered by the interlocutor, and propose a set of plausible responses for the AAC user. The outcome of this research will be a system that improves over the current state of the art in whole utterance approaches in AAC, making use of sophisticated natural language processing techniques.    Through this research and its practical application to helping real people with real communications needs, as well as coursework, seminars, participation in the AAC and disabilities community in Portland, OR, and intensive one-on-one meetings with his mentor Dr. Melanie Fried-Oken, the PI will accrue substantial clinical experience in AAC, and will gain a deep understanding of how technology can be used to help people.      PUBLIC HEALTH RELEVANCE: The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.              The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.            ",NLP for Augmentative and Alternative Communication in Adults,8189460,K25DC011308,"['Address', 'Adult', 'Area', 'Clinical', 'Communication', 'Communication Aids for Disabled', 'Communication Disability', 'Communities', 'Computers', 'Data', 'Databases', 'Devices', 'Environment', 'Food', 'Generations', 'Hobbies', 'Interview', 'Length', 'Measures', 'Mentors', 'Methods', 'Mining', 'Modeling', 'Modification', 'Names', 'Natural Language Processing', 'Oregon', 'Outcomes Research', 'Participant', 'Play', 'Questionnaires', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Restaurants', 'Role', 'Savings', 'Self Assessment', 'Simulate', 'Source', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Travel', 'Universities', 'alternative communication', 'base', 'efficacy testing', 'experience', 'improved', 'literate', 'meetings', 'movie', 'novel', 'practical application', 'programs', 'response', 'satisfaction', 'speech recognition', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,K25,2011,162459,-0.008082060280046247
"Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones    DESCRIPTION (provided by applicant): Magnetoencephalography (MEG) and related electroencephalography (EEG) use an array of sensors to non-invasively measure electromagnetic (EM) fields produced by synchronous current activity within the brain. While the temporal resolution is excellent relative to other functional imaging modalities, accurately localizing in 3D space the sources of brain activity involves solving a difficult, underdetermined inverse problem. Existing localization methods used clinically and for research purposes maintain significant shortcomings, including the inability to resolve complex source configurations, bias caused by source correlations, and sensitivity to sources of noise and interference. The latter can arise from eye blinks, heart beats, sensor imperfections, and industrial noise as well as from spontaneous background brain activity not associated with the brain sources of interest. Additionally, prototype algorithms ostensibly designed to deal with some of these issues are heuristic in nature and have not been rigorously evaluated or compared, making their ultimate utility difficult to assess for neuroelectromagnetic imaging practitioners. The proposed research plan addresses all of these concerns by developing a principled localization scheme that unifies and extends existing localization strategies using modern concepts from Bayesian statistics and machine learning. Based on the notion of automatic relevance determination (ARD), brain regions with probable (relevant) activity are located with high spatial resolution. Interference sources are effectively removed by integrating with a variation factor analysis model. To quantify the improvement afforded by the proposed methodology, source location estimates will be compared with standard algorithms using realistic simulations, near-ground-truth data obtained from invasive electrocorticographic (ECoG) recordings, and surgical data. The result will be implemented as a user-friendly localization toolbox and made freely available to the community by integrating with existing open-source functional brain imaging software. Non-invasive mapping of brain activity with high spatio-temporal resolution has important consequences for basic neuroscience studies of human cognition. It also has profound implications for the diagnosis, characterization and treatment of various neurological, neurooncological, mental health, developmental, and communication disorders. For example, localizations of brain sources are used to map cognitive function in epileptogenic areas and in neighboring brain regions. Such brain mapping procedures are then useful to guide neurosurgical planning, navigation, and resection and to minimize post-operative deficits.           n/a",Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones,7942859,F32NS061395,"['Academia', 'Address', 'Algorithms', 'Area', 'Automation', 'Bayesian Method', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Engineering', 'Blinking', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Clinical', 'Code', 'Cognition', 'Cognitive Science', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Developmental Communication Disorders', 'Diagnosis', 'Diffuse', 'Electroencephalography', 'Electromagnetic Fields', 'Epilepsy', 'Evaluation', 'Event', 'Excision', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Failure', 'Frequencies', 'Functional Imaging', 'Heart', 'Human', 'Image', 'Individual', 'Interdisciplinary Study', 'Intractable Epilepsy', 'Language', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Morphologic artifacts', 'Motor', 'Nature', 'Neurologic', 'Neurosciences', 'Noise', 'Occupations', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Radiology Specialty', 'Relative (related person)', 'Research', 'Research Training', 'Resected', 'Resolution', 'Scalp structure', 'Scheme', 'Science', 'Series', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Statistical Methods', 'Surface', 'Surrogate Markers', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'career', 'cognitive function', 'computerized data processing', 'cost', 'design', 'genetic pedigree', 'heuristics', 'human CYP2B6 protein', 'human subject', 'imaging modality', 'interest', 'neurophysiology', 'open source', 'operation', 'prototype', 'reconstruction', 'sensor', 'simulation', 'statistics', 'user friendly software', 'user-friendly', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2011,19755,-0.003994688371266411
"Vision Without Sight: Exploring the Environment with a Portable Camera    DESCRIPTION (provided by applicant): As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his collaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specific examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.      PUBLIC HEALTH RELEVANCE: The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population              The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population            ",Vision Without Sight: Exploring the Environment with a Portable Camera,8097202,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2011,205070,0.019392231623083022
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8089310,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2011,252290,0.0005834452043385965
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma    DESCRIPTION (provided by applicant) This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Computational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, and progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans.      PUBLIC HEALTH RELEVANCE:  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.            Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.         ",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,7871151,K99EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Science', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2011,89922,-0.0013396829772089156
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.      PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.              Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.            ",Perception of Tactile Graphics,8060259,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2011,48398,-0.006621158861123299
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,-0.030900427870435728
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,8143297,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'animal tissue', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2011,132786,-0.009734520990825397
"Manipulating Neural Tissue with Ultra-Short Laser Pulses    DESCRIPTION (provided by applicant):  We seek to renew our joint discovery and technology based bioengineering research partnership (BRP).  Our program advances the use of amplified ultrashort laser pulses as a tool to manipulate living and histological tissue.  This unique technology, pioneered by the BRP team, permits tissue to be cut on the micrometer scale by light-fueled plasma-meditated ablation.  Cutting occurs without thermal damage and can be combined with spectroscopic feedback to identify and limit the region being perturbed.  We advance this technology in new ways, including the use of temporal focusing for deep ablation, and apply it to three key test beds.  The first is construction of the angiotome, i.e., a complete vectorized map of cortical vasculature; here we use plasma mediated ablation to automate a form of block-face imaging along with novel algorithms to filter and vectorize features in the data.  The second is the study of neuronal viability in response to perturbations of subcortical blood flow; here we use plasma-mediated ablation to block flow in individual targeted microvessels that lie below the cortical surface.  The third test bed is the automation of cranial and spinal surgery; we combine plasma-mediated ablation with laser-induced breakdown spectroscopy to cut bone yet avoid injury to soft tissue.  These investigations are particularly relevant to diagnosing and understanding microinfarctions, i.e., damage to the brain as the result of damage to single cortical vessels, that accumulate with age and trauma.      PUBLIC HEALTH RELEVANCE:  These studies advance the use of light to image and manipulate the flow of blood in the brain.  We make use of rats and mice as model systems for our experiments.  The new capabilities from the proposed work hold two promises for advances in medicine:  One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma.  The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.              Program Director (Last, first, middle): Kleinfeld, David, Kaufhold, John and Squier, Jeffrey. These studies advance the use of light to image and manipulate the flow of blood in the brain. We make use of rats and mice as model systems for our experiments. The new capabilities from the proposed work hold two promises for advances in medicine: One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma. The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.",Manipulating Neural Tissue with Ultra-Short Laser Pulses,8134363,R01EB003832,"['3-Dimensional', 'Ablation', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Automation', 'Beds', 'Biological Models', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Cephalic', 'Cessation of life', 'Craniotomy', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Face', 'Feedback', 'Fluorescence', 'Functional Imaging', 'Future', 'Generations', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Joints', 'Label', 'Laminectomy', 'Lasers', 'Lateral', 'Lead', 'Learning', 'Lesion', 'Life', 'Light', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Mediating', 'Medical Imaging', 'Medicine', 'Metabolism', 'Methodology', 'Mitochondria', 'Modeling', 'Mus', 'Neocortex', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Organelles', 'Pattern', 'Physiologic pulse', 'Plasma', 'Process', 'Rattus', 'Reperfusion Therapy', 'Research', 'Resolution', 'Role', 'Scanning', 'Shapes', 'Spectrum Analysis', 'Speed', 'Spinal', 'Stroke', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Ursidae Family', 'Veins', 'Work', 'arteriole', 'base', 'bone', 'brain cell', 'capillary', 'design', 'hemodynamics', 'meetings', 'millimeter', 'neurosurgery', 'novel', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'research study', 'response', 'second harmonic', 'soft tissue', 'tool', 'two-photon']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,932015,-0.013738458954063233
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,8059576,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological Models', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'gamma-Aminobutyric Acid', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2011,1244329,-0.002042667406319782
"Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development    DESCRIPTION (provided by applicant): Selective potentiators of the metabotropic glutamate receptor subtype mGluR5 have exciting potential for development of novel treatment strategies for schizophrenia and other disorders that disrupt cognitive func-tion. The latest generation of selective mGluR5 potentiators is based on the lead compound CDPPB and features systemically active compounds with long half-lives that cross the blood-brain barrier. A high-throughput screen (HTS) for mGluR5 potentiators at Vanderbilt's screening center revealed a large and diverse set of about 1400 substances (1% hit rate) whose activity was validated in independent experiments.  A previous exploratory research grant ""Novel Schizophrenia Therapeutics by Virtual High-Throughput Screening"" (R21 MH082254) enabled testing of 813 compounds predicted through cheminformatics. 252 of these compounds were confirmed as active PAMs equaling an enrichment of >30 when compared with the original screen. The present proposal seeks to leverage these proof-of-principle results for the development of a tailored cheminformatics framework for drug discovery of allosteric modulators of brain GPCRs, apply these tools to inform an existing therapeutic discovery program of mGluR5 potentiators at Vanderbilt University, and disseminate the methods broadly through the NIH molecular libraries program.  The central hypothesis of this proposal is that the complex relationship between chemical structure and biological activity of mGluR5 potentiators observed in this HTS can be used to generate a pharmacophore of the mGluR5 allosteric site. This map of steric and electronic features necessary for optimal interaction of modulators with mGluR5 will not only inform our understanding of the allosteric modulation of brain GPCRs. The methods proposed overcome limitations of present cheminformatics techniques by enabling identification of novel chemotypes through virtual screening (scaffold hoping), and allowing design of focused libraries in hit-to- lead optimization of novel schizophrenia therapeutics.  The generalizbility of the approach will be tested through application on negative modulators of mGluR5, a potential novel treatment strategy of fragile X syndrome, a CNS disorder associated with autism spectrum disorders (ASD) among multiple other symptoms. The developed applications will be made freely and readily accessible for academic research. The employed QSAR models require no crystal structure of the target brain GPCR. Hence the method can be readily applied to membrane proteins-such as GPCRs-which are target of 40-50% of modern medicinal drugs.      PUBLIC HEALTH RELEVANCE: Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.           PROJECT NARRATIVE  Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.",Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development,8055043,R01MH090192,"['Algorithms', 'Allosteric Site', 'Benchmarking', 'Biological', 'Blood - brain barrier anatomy', 'Brain', 'Central Nervous System Diseases', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chemosensitization', 'Cognitive', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consensus', 'Databases', 'Descriptor', 'Development', 'Disease', 'Education', 'Electronics', 'Fragile X Syndrome', 'G Protein-Coupled Receptor Genes', 'Generations', 'Hand', 'Humulus', 'Internet', 'Lead', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Mental disorders', 'Metabotropic Glutamate Receptors', 'Methods', 'Modeling', 'Molecular', 'Molecular Bank', 'Pharmaceutical Preparations', 'Pharmacology', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Project Grants', 'Scheme', 'Schizophrenia', 'Screening procedure', 'Site', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Universities', 'Walking', 'Work', 'autism spectrum disorder', 'base', 'chemical synthesis', 'cheminformatics', 'cognitive function', 'comparative', 'design', 'drug discovery', 'experience', 'high throughput screening', 'nervous system disorder', 'novel', 'pharmacophore', 'programs', 'public health relevance', 'research study', 'scaffold', 'therapeutic development', 'therapeutic target', 'tool', 'treatment strategy', 'virtual']",NIMH,VANDERBILT UNIVERSITY,R01,2011,384954,-0.03154077950250032
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8133823,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2011,776548,0.025518924541197516
"Quantitative Methods for Neuroimaging Studies of Interventions in Aging    DESCRIPTION (provided by applicant): This proposal for an NIH Mentored Quantitative Research Career Award requests support for Dr. Yongmei Michelle Wang as she embarks on a faculty career focused on imaging studies which examine the influence of longitudinal interventions on brain structure and function, and its relationship to cognition and performance, in older adults. The application proposes a research career development plan in the field of neuroimaging, bridging engineering, statistics, and neuroscience. The plan includes two overlapping phases: 1) a didactic phase that emphasizes training, including coursework and laboratory work in the area of cognitive neuroscience, imaging, aging, and interventions to complement Dr. Wang's doctoral training in Electrical Engineering and existing experience in Statistics; and 2) a development phase that focuses on intense development of the proposed research. These two phases will be closely supervised by the mentor and advisor in the area of cognitive neuroscience, brain plasticity, biomedical imaging, aging and interventions. Neuroimaging techniques, such as magnetic resonance imaging (MRI) and functional MRI (fMRI), have been shown to be powerful for characterizing and understanding the structure and function of the human brain. There remains a need, however, for robust and efficient statistical image analysis methods due to the limitations of existing approaches. It is crucial that these analysis techniques be developed with a full understanding of the neuroimaging methods used and the relevant cognitive neuroscience. We propose to develop, implement, and validate integrated computational algorithms for reliable and sensitive analysis of brain MRI and fMRI images, with the following specific aims: 1) Develop, validate and combine novel and efficient univariate and multivariate morphometry analysis methods. 2) Develop and evaluate integrated functional hemodynamic response and connectivity study approaches. 3) Apply these methods to the MRI and fMRI data being collected from separately funded NIA project of the mentor, to examine the effects of aerobic fitness training on brain structure and function of older adults; the neuroscience hypothesis to be tested are: improvements in aerobic fitness, over the course of a 1 year intervention, will result in i) increases in gray and white matter volume and shape changes of subcortical structures of the human brain; and ii) changes in the underlying neural circuits. 4) Develop a brain image analysis toolbox implementing the above methods.       PUBLIC HEALTH RELEVANCE: The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.              PROJECT NARRATIVE The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.",Quantitative Methods for Neuroimaging Studies of Interventions in Aging,8137829,K25AG033725,"['Adult', 'Aerobic', 'Age', 'Aging', 'Algorithms', 'American', 'Area', 'Attention', 'Award', 'Awareness', 'Bayesian Method', 'Behavior', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Computational algorithm', 'Conflict (Psychology)', 'Data', 'Detection', 'Deterioration', 'Development', 'Development Plans', 'Dimensions', 'Economic Burden', 'Elderly', 'Electrical Engineering', 'Engineering', 'Exhibits', 'Faculty', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Health', 'Hippocampus (Brain)', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Intervention', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Markov Chains', 'Medial', 'Memory', 'Mentors', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Multivariate Analysis', 'Neurosciences', 'Noise', 'Parietal', 'Participant', 'Pattern', 'Performance', 'Phase', 'Physical activity', 'Population', 'Prefrontal Cortex', 'Process', 'Public Health', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Risk Behaviors', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Statistical Methods', 'Structure', 'Surface', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'age related', 'aging brain', 'aging mind', 'base', 'bioimaging', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'executive function', 'experience', 'fitness', 'flexibility', 'gray matter', 'healthy aging', 'hemodynamics', 'improved', 'interest', 'intervention effect', 'morphometry', 'neural circuit', 'neuroimaging', 'new technology', 'novel', 'public health relevance', 'relating to nervous system', 'relational memory', 'research study', 'response', 'sedentary', 'shape analysis', 'social', 'statistics', 'therapy design', 'tool', 'white matter', 'young adult']",NIA,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K25,2011,150833,-0.008538072512311477
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,8098196,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Health', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'NMR Spectroscopy', 'Negative Staining', 'Neighborhoods', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2011,311172,-0.034382612424640205
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8109271,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2011,205267,-0.032964492201260596
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,8037680,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2011,513228,0.018209250600776678
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8043275,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2010,394165,0.013833640239951827
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,8013208,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2010,376899,-0.0032522082908518052
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7904837,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,1196495,0.012604180852127576
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8068069,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,51400,-0.015143964954971383
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7828142,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,338802,-0.015143964954971383
"Real-Time Automated Detection of Craving States with fMRI and EEG    DESCRIPTION (provided by applicant):  Neurofeedback by real time functional MRI (rt-fMRI) has potential for addiction research and treatment that will be realized only if the feedback given the subject is related meaningfully to the cognitive states that must be controlled. The mental operations of the brain are too distributed to be represented by the raw rt-fMRI signal in any one brain region or small group of regions. Our aims are to: 1) Use computational machine learning to rapidly detect patterned activation in the rt-fMRI signal that better expresses cognitive state; 2) augment these data with concurrently-collected electroencephalographic (EEG) data; 3) develop an atlas of brain data that identifies brain patterns with cognitive states relevant to addiction and drug abuse research and 4) to explore rt-fMRI neurofeedback using this rt-fMRI/EEG machine learning method. Our approach will be to first create rapid algorithms for pattern matching that are fast compared with the imaging, thereby allowing ""real-time"" application. To do so we will select features from the images that express the differences among state concisely (more technically, we will use a method known as independent components analysis to reduce the data dimensionality.) We will similarly condense the EEG features by studying them by the location of their sources within the brain, and by examining the frequencies that they contain. We will run experiments on volunteers designed to help us see their tendency to make impulsive choices - which is known to relate to their likelihood to become drug users, as well as experiments that track changes in their brain as they control their craving urges. For these studies we will look at heavy cigarette users. Cigarette use on its own is a serious health burden to the nation, and it is also an excellent model for addiction more generally, as it is known to have many neural features in common with use of other drugs of abuse, such as cocaine and methamphetamine. This is a phased innovation proposal. The first phase will be focused on the developments of the rt-fMRI analysis and instrumentation technology. On its successful completion, based on specific milestones, we will move to the more applied work with human subjects.      PUBLIC HEALTH RELEVANCE:  Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.           Project Narrative Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.",Real-Time Automated Detection of Craving States with fMRI and EEG,8087592,R33DA026109,"['Abstinence', 'Address', 'Affective', 'Algorithms', 'Anterior', 'Atlases', 'Base of the Brain', 'Behavior', 'Brain', 'Brain region', 'Cigarette', 'Classification', 'Clinical', 'Cocaine', 'Cognitive', 'Complex', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Dimensions', 'Discrimination', 'Drug abuse', 'Drug user', 'Electroencephalogram', 'Electroencephalography', 'Electrophysiology (science)', 'Epilepsy', 'Feedback', 'Four-dimensional', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Galvanic Skin Response', 'Generations', 'Goals', 'Health', 'Healthcare', 'Image', 'Imaging technology', 'Impulsivity', 'Intervention', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical', 'Methamphetamine', 'Methods', 'Modeling', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Proxy', 'Psyche structure', 'Reporter', 'Reporting', 'Research', 'Rest', 'Running', 'Scalp structure', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Stimulus', 'Study Subject', 'Technology', 'Testing', 'Time', 'Traumatic Brain Injury', 'Work', 'abstracting', 'addiction', 'base', 'blind', 'chronic pain', 'cingulate cortex', 'cognitive control', 'craving', 'data space', 'design', 'discounting', 'drug of abuse', 'effective intervention', 'human subject', 'improved', 'independent component analysis', 'innovation', 'instrument', 'instrumentation', 'interest', 'method development', 'mind control', 'neurofeedback', 'neuroimaging', 'novel', 'operation', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'symposium', 'tool', 'trend', 'virtual', 'volunteer']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R33,2010,593360,-0.0062426938072097735
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7754089,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2010,2037327,-0.0003884512278637026
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,8115481,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'operation', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2010,99989,-0.0013164102094096115
"Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually There are more than 10 million blind and visually impaired people living in America today. Recent technology developments in computer vision, digital cameras, and portable computers make it possible to assist these individuals by developing camera-based products that combine computer vision technology with other existing products.  Although a number of reading assistants have been designed specifically for people who are blind or visually impaired, reading text from complex backgrounds or non-flat surfaces is very challenging and has not yet been successfully addressed. Many everyday tasks involve these challenging conditions, such as reading instructions on vending machines, titles of books aligned on a shelf, instructions on medicine bottles or labels on soup cans.  This proposal focuses on the development of new computer vision algorithms to recognize text from complex backgrounds: 1) from backgrounds with multiple different colors (e.g .. the titles of books lined up on a shelf) and 2) from non-flat surfaces (e.g .. labels on medicine bottles or soup cans). The newly developed computer vision techniques will be integrated with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed by a portable computer (PDA or cell phone), while the speech display will be outputted via mini speakers, earphones, or Bluetooth device. A practical reading system prototype will be produced to read text from complex backgrounds and non-flat surfaces. The system will be cost-effective since it requires only a head mounted camera (<US$100 for 1M resolution), a wearable computer (<US$300), and two mini-speakers or earphones. The price of ""ReadIRlS"" [74] OCR software is under $150 and the ""TextAloud"" speech synthesis software is about $30 [75].  This project will be executed over two years at the City College of New York (CCNY) and Lighthouse International, New York. CCNY, located in the Harlem neighborhood of New York City, is designated as both a Minority Institution and a Hispanic-serving Institution (37% Hispanic and 27% African American). Lighthouse International is a leading non-profit organization dedicated to preserving vision and to providing critically needed vision and rehabilitation services to help people of all ages overcome the challenges of vision loss. During the two years, we will 1) develop new algorithms to recognize text from backgrounds with multiple different colors; 2) develop new algorithms to recognize text from non-flat surfaces; and 3) develop a cost-effective prototype reading system for blind users by integrating with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. The effectiveness of the prototype and algorithms will be evaluated by people with normal vision and people with vision impairment. A database of text on complex backgrounds (multiple colors and non-flat surfaces) will be created for algorithm and system evaluation. The database will be made available to research communities in the areas of computer vision and vision rehabilitation science. In summary, this effort will provide a research-based foundation to inform the design of next generation reading assistants for blind persons, as well as produce a practical prototype to help the blind user read text from complex backgrounds in real-world environments. PROJECT NARRATIVE  The goal of the proposed research is to develop new computer vision algorithms for camera-based text recognition from complex backgrounds and non-flat surfaces, as well as produce a practical reading system prototype in combination with off-the-shelf  optical character recognition (OCR) and speech-synthesis software products, to help blind or visually impaired people read instructions on vending machines, titles of books aligned on a shelf, labels on medicine bottles or soup cans, etc. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed in realtime through a portable computer, such as a mini laptop or a personal digital assistant (PDA). The speech display will be outputted via mini speakers, earphones, or Bluetooth device.",Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually,7977496,R21EY020990,"['Address', 'African American', 'Age', 'Algorithms', 'Americas', 'Area', 'Blindness', 'Books', 'Cellular Phone', 'Cities', 'Color', 'Communities', 'Complex', 'Computer Systems Development', 'Computer Vision Systems', 'Computer software', 'Computers', 'Databases', 'Development', 'Devices', 'Effectiveness', 'Environment', 'Evaluation', 'Event', 'Facial Expression Recognition', 'Foundations', 'Goals', 'Grant', 'Head', 'Hispanics', 'Image', 'Impairment', 'Individual', 'Institution', 'Instruction', 'International', 'Label', 'Letters', 'Life', 'Mails', 'Marketing', 'Medicine', 'Methods', 'Minority', 'Neighborhoods', 'New York', 'New York City', 'Nonprofit Organizations', 'Output', 'Personal Digital Assistant', 'Price', 'Printing', 'Reading', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Resolution', 'Running', 'Scientist', 'Shapes', 'Solutions', 'Speech', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thick', 'Time', 'United States National Institutes of Health', 'Vertebral column', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Writing', 'base', 'blind', 'college', 'computer generated', 'computer human interaction', 'cost', 'design', 'digital', 'experience', 'laptop', 'next generation', 'optical character recognition', 'prototype', 'rehabilitation science', 'rehabilitation service', 'research and development', 'sunglasses', 'technology development', 'visual information']",NEI,CITY COLLEGE OF NEW YORK,R21,2010,190000,-0.007724539942223259
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8055745,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Arts', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2010,256288,0.0005834452043385965
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7799708,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2010,427932,0.008351760252262948
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    IQ Engines' mobile visual search technology will enable the visually impaired to access real-time information about physical objects using their mobile phone camera. The mobile phone provides a visually-driven hyperlink between the physical and digital world: point the camera at an object and get information (for example product information or navigation information). The mobile phone camera is a powerful yet underutilized tool for the visually impaired. Our proposal has two specific aims. Working directly with the visually impaired community, we will build a prototype mobile visual search application that meets their accessibility and use requirements. Our second aim is to improve upon the state of the art for 3D object recognition. We will investigate a novel combination of sparse image representation, feature matching algorithm, and geometric verification in order to advance the performance of 3D object matching. While state-of-the-art image intelligence is robust enough to enable rapid and accurate image search of flat feature-rich objects, current computer vision pales in comparison to the abilities of biological vision systems to recognize 3-dimensional objects. Our underlying goal is to bring inspiration from recent advances in theoretical neuroscience and apply them to image and video search solutions.      PUBLIC HEALTH RELEVANCE:    Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.           Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.",Mobile Search for the Visually Impaired,7909025,R43EY019790,"['3-Dimensional', 'Algorithms', 'Arts', 'Biological', 'Breathing', 'Car Phone', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Databases', 'Feedback', 'Funding', 'Future', 'Goals', 'Image', 'Intelligence', 'Internet', 'Letters', 'Modeling', 'Neurosciences', 'Ocular Prosthesis', 'Performance', 'Research', 'Solutions', 'Speech Synthesizers', 'System', 'Technology', 'Text', 'Time', 'Vision', 'Visual', 'Visual Aid', 'Visual impairment', 'Work', 'base', 'blind', 'cost', 'digital', 'improved', 'meetings', 'novel', 'object recognition', 'prototype', 'public health relevance', 'technology development', 'tool', 'visual search']",NEI,"IQ ENGINES, INC.",R43,2010,138770,0.00025165288802203405
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7765534,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2010,324963,-0.005789420676117226
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7941984,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2010,303186,-0.009734520990825397
"A Texture Analysis/Synthesis Model of Visual Crowding    DESCRIPTION (provided by applicant): Identifying a visual stimulus can be substantially impaired by the mere presence of additional stimuli in the immediate vicinity. This phenomenon is called ""crowding,"" and it powerfully limits visual perception in many circumstances, especially in the peripheral visual field. There is a rich body of literature detailing the phenomenology of crowding, but we do not know why crowding occurs. We lack a computational model that can predict what information will be available to an observer in an arbitrary crowded display. A popular hypothesis is that crowding results from obligatory ""texture processing,"" but there have been few efforts to formalize and test what this might mean, despite broad agreement that crowding reflects some form of ""excessive integration."" Dr. Rosenholtz has extensive experience with computational models of texture processing, which are a powerful means of defining the exact nature of ""texture processing"" and testing the ability of such models to explain and predict visual behavior. The proposed research has 3 aims: (1) To clarify and formalize the hypothesis that crowding is due to a ""texture"" - i.e. statistical -- representation of the crowded stimuli. (2) To collect behavioral data from a wider variety of displays and tasks than is typically studied in crowding. (3) To develop and validate the first general-purpose model of visual crowding. To achieve these aims, Dr. Rosenholtz will apply state-of-the-art computational tools for texture synthesis to ""crowded"" stimuli. ""Texturizing"" crowded arrays of stimuli affords a tool for visualizing the information available in a crowded display and a vocabulary for describing its representational content. Thus, Dr. Rosenholtz will attack the problem of crowding through a useful synthesis of computer graphics, computer vision, and psychophysics. PUBLIC HEALTH RELEVANCE: Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.            Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.",A Texture Analysis/Synthesis Model of Visual Crowding,7903934,R21EY019366,"['Age related macular degeneration', 'Agreement', 'Amblyopia', 'Area', 'Arts', 'Attention', 'Behavior', 'Behavioral', 'Binding', 'Cells', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Crowding', 'Data', 'Databases', 'Discrimination', 'Disease', 'Elderly', 'Eye Movements', 'Face', 'Failure', 'Functional disorder', 'Gender', 'Goals', 'Gray unit of radiation dose', 'Human', 'Imagery', 'Individual', 'Joints', 'Lesion', 'Letters', 'Literature', 'Location', 'Masks', 'Methods', 'Modeling', 'Nature', 'Patients', 'Perception', 'Performance', 'Peripheral', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Resolution', 'Saccades', 'Severities', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Work', 'base', 'clinically significant', 'computerized tools', 'design', 'experience', 'improved', 'neglect', 'novel', 'object recognition', 'public health relevance', 'research study', 'response', 'statistics', 'theories', 'tool', 'vision aid', 'visual information', 'visual search', 'visual stimulus']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2010,166320,-0.004914821827576911
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7808779,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2010,1249881,-0.002042667406319782
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,-0.030900427870435728
"Manipulating Neural Tissue with Ultra-Short Laser Pulses    DESCRIPTION (provided by applicant):  We seek to renew our joint discovery and technology based bioengineering research partnership (BRP).  Our program advances the use of amplified ultrashort laser pulses as a tool to manipulate living and histological tissue.  This unique technology, pioneered by the BRP team, permits tissue to be cut on the micrometer scale by light-fueled plasma-meditated ablation.  Cutting occurs without thermal damage and can be combined with spectroscopic feedback to identify and limit the region being perturbed.  We advance this technology in new ways, including the use of temporal focusing for deep ablation, and apply it to three key test beds.  The first is construction of the angiotome, i.e., a complete vectorized map of cortical vasculature; here we use plasma mediated ablation to automate a form of block-face imaging along with novel algorithms to filter and vectorize features in the data.  The second is the study of neuronal viability in response to perturbations of subcortical blood flow; here we use plasma-mediated ablation to block flow in individual targeted microvessels that lie below the cortical surface.  The third test bed is the automation of cranial and spinal surgery; we combine plasma-mediated ablation with laser-induced breakdown spectroscopy to cut bone yet avoid injury to soft tissue.  These investigations are particularly relevant to diagnosing and understanding microinfarctions, i.e., damage to the brain as the result of damage to single cortical vessels, that accumulate with age and trauma.      PUBLIC HEALTH RELEVANCE:  These studies advance the use of light to image and manipulate the flow of blood in the brain.  We make use of rats and mice as model systems for our experiments.  The new capabilities from the proposed work hold two promises for advances in medicine:  One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma.  The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.              Program Director (Last, first, middle): Kleinfeld, David, Kaufhold, John and Squier, Jeffrey. These studies advance the use of light to image and manipulate the flow of blood in the brain. We make use of rats and mice as model systems for our experiments. The new capabilities from the proposed work hold two promises for advances in medicine: One is an understanding of micro- infarctions - lesions of individual blood vessels in cortex that lead to the death of brain cells- that accrue with age and trauma. The second is an understanding of the normal patterns of blood flow throughout the brain, which provide the basis for interpreting medical images of brain function.",Manipulating Neural Tissue with Ultra-Short Laser Pulses,7988297,R01EB003832,"['3-Dimensional', 'Ablation', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Automation', 'Beds', 'Biological Models', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Cephalic', 'Cessation of life', 'Craniotomy', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dimensions', 'Feedback', 'Fluorescence', 'Functional Imaging', 'Future', 'Generations', 'Goals', 'Health', 'Histocompatibility Testing', 'Histology', 'Image', 'Impaired cognition', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Joints', 'Label', 'Laminectomy', 'Lasers', 'Lateral', 'Lead', 'Learning', 'Lesion', 'Life', 'Light', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Mediating', 'Medical Imaging', 'Medicine', 'Metabolism', 'Methodology', 'Mitochondria', 'Modeling', 'Mus', 'Neocortex', 'Neurons', 'Operative Surgical Procedures', 'Optics', 'Organelles', 'Pattern', 'Physiologic pulse', 'Plasma', 'Process', 'Rattus', 'Reperfusion Therapy', 'Research', 'Resolution', 'Role', 'Scanning', 'Shapes', 'Spectrum Analysis', 'Speed', 'Spinal', 'Stroke', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Ursidae Family', 'Veins', 'Work', 'arteriole', 'base', 'bone', 'brain cell', 'capillary', 'design', 'hemodynamics', 'meetings', 'millimeter', 'neurosurgery', 'novel', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'research study', 'response', 'second harmonic', 'soft tissue', 'tool', 'two-photon']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,994058,-0.013738458954063233
"Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development    DESCRIPTION (provided by applicant): Selective potentiators of the metabotropic glutamate receptor subtype mGluR5 have exciting potential for development of novel treatment strategies for schizophrenia and other disorders that disrupt cognitive func-tion. The latest generation of selective mGluR5 potentiators is based on the lead compound CDPPB and features systemically active compounds with long half-lives that cross the blood-brain barrier. A high-throughput screen (HTS) for mGluR5 potentiators at Vanderbilt's screening center revealed a large and diverse set of about 1400 substances (1% hit rate) whose activity was validated in independent experiments.  A previous exploratory research grant ""Novel Schizophrenia Therapeutics by Virtual High-Throughput Screening"" (R21 MH082254) enabled testing of 813 compounds predicted through cheminformatics. 252 of these compounds were confirmed as active PAMs equaling an enrichment of >30 when compared with the original screen. The present proposal seeks to leverage these proof-of-principle results for the development of a tailored cheminformatics framework for drug discovery of allosteric modulators of brain GPCRs, apply these tools to inform an existing therapeutic discovery program of mGluR5 potentiators at Vanderbilt University, and disseminate the methods broadly through the NIH molecular libraries program.  The central hypothesis of this proposal is that the complex relationship between chemical structure and biological activity of mGluR5 potentiators observed in this HTS can be used to generate a pharmacophore of the mGluR5 allosteric site. This map of steric and electronic features necessary for optimal interaction of modulators with mGluR5 will not only inform our understanding of the allosteric modulation of brain GPCRs. The methods proposed overcome limitations of present cheminformatics techniques by enabling identification of novel chemotypes through virtual screening (scaffold hoping), and allowing design of focused libraries in hit-to- lead optimization of novel schizophrenia therapeutics.  The generalizbility of the approach will be tested through application on negative modulators of mGluR5, a potential novel treatment strategy of fragile X syndrome, a CNS disorder associated with autism spectrum disorders (ASD) among multiple other symptoms. The developed applications will be made freely and readily accessible for academic research. The employed QSAR models require no crystal structure of the target brain GPCR. Hence the method can be readily applied to membrane proteins-such as GPCRs-which are target of 40-50% of modern medicinal drugs.      PUBLIC HEALTH RELEVANCE: Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.           PROJECT NARRATIVE  Ligands for specific mGluR subtypes have potential for treatment of a wide variety of neurological and psychiatric disorders. We will use computational methods identify potentiators of mGluR5, compounds that have exciting potential as treatment strategy for schizophrenia. In silico hit compounds will be experimentally validated and enter hit-to-lead optimization.",Cheminformatics of Allosteric mGluR Modulation promotes Therapeutic Development,7863437,R01MH090192,"['Algorithms', 'Allosteric Site', 'Benchmarking', 'Biological', 'Blood - brain barrier anatomy', 'Brain', 'Central Nervous System Diseases', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chemosensitization', 'Cognitive', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consensus', 'Databases', 'Descriptor', 'Development', 'Disease', 'Education', 'Electronics', 'Fragile X Syndrome', 'G Protein-Coupled Receptor Genes', 'Generations', 'Half-Life', 'Hand', 'Humulus', 'Internet', 'Lead', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Maps', 'Membrane Proteins', 'Mental disorders', 'Metabotropic Glutamate Receptors', 'Methods', 'Modeling', 'Molecular Bank', 'Neurologic', 'Pharmaceutical Preparations', 'Pharmacology', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Project Grants', 'Scheme', 'Schizophrenia', 'Screening procedure', 'Site', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Universities', 'Walking', 'Work', 'autism spectrum disorder', 'base', 'chemical synthesis', 'cheminformatics', 'comparative', 'design', 'drug discovery', 'experience', 'high throughput screening', 'novel', 'pharmacophore', 'programs', 'public health relevance', 'research study', 'scaffold', 'therapeutic development', 'therapeutic target', 'tool', 'treatment strategy', 'virtual']",NIMH,VANDERBILT UNIVERSITY,R01,2010,387385,-0.03154077950250032
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,7913126,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Businesses', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Methods', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Project Grants', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'design', 'digital', 'experience', 'falls', 'innovation', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition']",NEI,BLINDSIGHT CORPORATION,R44,2010,656703,0.025518924541197516
"Quantitative Methods for Neuroimaging Studies of Interventions in Aging    DESCRIPTION (provided by applicant): This proposal for an NIH Mentored Quantitative Research Career Award requests support for Dr. Yongmei Michelle Wang as she embarks on a faculty career focused on imaging studies which examine the influence of longitudinal interventions on brain structure and function, and its relationship to cognition and performance, in older adults. The application proposes a research career development plan in the field of neuroimaging, bridging engineering, statistics, and neuroscience. The plan includes two overlapping phases: 1) a didactic phase that emphasizes training, including coursework and laboratory work in the area of cognitive neuroscience, imaging, aging, and interventions to complement Dr. Wang's doctoral training in Electrical Engineering and existing experience in Statistics; and 2) a development phase that focuses on intense development of the proposed research. These two phases will be closely supervised by the mentor and advisor in the area of cognitive neuroscience, brain plasticity, biomedical imaging, aging and interventions. Neuroimaging techniques, such as magnetic resonance imaging (MRI) and functional MRI (fMRI), have been shown to be powerful for characterizing and understanding the structure and function of the human brain. There remains a need, however, for robust and efficient statistical image analysis methods due to the limitations of existing approaches. It is crucial that these analysis techniques be developed with a full understanding of the neuroimaging methods used and the relevant cognitive neuroscience. We propose to develop, implement, and validate integrated computational algorithms for reliable and sensitive analysis of brain MRI and fMRI images, with the following specific aims: 1) Develop, validate and combine novel and efficient univariate and multivariate morphometry analysis methods. 2) Develop and evaluate integrated functional hemodynamic response and connectivity study approaches. 3) Apply these methods to the MRI and fMRI data being collected from separately funded NIA project of the mentor, to examine the effects of aerobic fitness training on brain structure and function of older adults; the neuroscience hypothesis to be tested are: improvements in aerobic fitness, over the course of a 1 year intervention, will result in i) increases in gray and white matter volume and shape changes of subcortical structures of the human brain; and ii) changes in the underlying neural circuits. 4) Develop a brain image analysis toolbox implementing the above methods.       PUBLIC HEALTH RELEVANCE: The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.              PROJECT NARRATIVE The development of quantitative image analysis methodology for the characterization of brain structural and functional changes caused by interventions (such as fitness) on the aging brain is of tremendous importance to understanding the effects of interventions on brain, and to the design of interventions that optimize the effects on cognition and brain health.",Quantitative Methods for Neuroimaging Studies of Interventions in Aging,7989936,K25AG033725,"['Adult', 'Aerobic', 'Age', 'Aging', 'Algorithms', 'American', 'Area', 'Attention', 'Award', 'Awareness', 'Bayesian Method', 'Behavior', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Computational algorithm', 'Conflict (Psychology)', 'Data', 'Detection', 'Deterioration', 'Development', 'Development Plans', 'Dimensions', 'Economic Burden', 'Elderly', 'Electrical Engineering', 'Engineering', 'Exhibits', 'Faculty', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Gray unit of radiation dose', 'Health', 'Hippocampus (Brain)', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Intervention', 'Intervention Studies', 'Knowledge', 'Laboratories', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Markov Chains', 'Medial', 'Memory', 'Mentors', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Multivariate Analysis', 'Neurosciences', 'Noise', 'Parietal', 'Participant', 'Pattern', 'Performance', 'Phase', 'Physical activity', 'Population', 'Process', 'Public Health', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Risk Behaviors', 'Role', 'Sample Size', 'Sampling', 'Scheme', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Statistical Methods', 'Structure', 'Surface', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'age related', 'aging brain', 'aging mind', 'base', 'bioimaging', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'executive function', 'experience', 'fitness', 'flexibility', 'healthy aging', 'hemodynamics', 'improved', 'interest', 'intervention effect', 'morphometry', 'neural circuit', 'neuroimaging', 'new technology', 'novel', 'public health relevance', 'relating to nervous system', 'relational memory', 'research study', 'response', 'sedentary', 'shape analysis', 'social', 'statistics', 'therapy design', 'tool', 'white matter', 'young adult']",NIA,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K25,2010,150781,-0.008538072512311477
"Enhancing 3dsvm to improve its interoperability and dissemination    DESCRIPTION (provided by applicant): This research plan outlines crucial software enhancements to a program called 3dsvm, which is a command line program and graphical user interface (gui) plugin for AFNI (Cox, 1996). 3dsvm performs support vector machine (SVM) analysis on fMRI data, which constitutes one important approach to performing multivariate supervised learning of neuroimaging data. 3dsvm originally provided the ability to analyze fMRI data as described in (LaConte et al., 2005). Since its first distribution as a part of AFNI, it has been steadily extended to provide new functionality including regression and non-linear kernels, as well as multiclass classification capabilities. In addition to its integration into AFNI, features that make 3dsvm particularly well suited for fMRI analysis are that it is easy to spatially mask voxels (to include/exclude them in the SVM analysis) as well as to flexibly select subsets of a dataset to use as training or testing samples. It has been used to generate results for our own work and for collaborative efforts and has been cited as a resource by others (Mur et al. 2009; Hanke et al. 2009). Despite many positive aspects of 3dsvm, the priorities of PAR-07-417 address a genuine need that this software project has - the ability to focus on improvements that will increase its dissemination and interoperability. A major motivation for PAR-07-417 is to facilitate the improved interface, characterization, and documentation to enhance the extent of sharing and to provide the groundwork for future extensions. Our aims are well aligned with this program announcement. Further, there is a growing need in the neuroimaging community for tools such as 3dsvm. Since 3dsvm is not a new project, is tightly integrated into the software environment of AFNI, and can be further integrated to enable better functionality to support needs as diverse as NIfTI format capabilities to rtFMRI, this proposed project will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.      PUBLIC HEALTH RELEVANCE: This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.           NARRATIVE This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.",Enhancing 3dsvm to improve its interoperability and dissemination,8278135,R03EB012464,[' '],NIBIB,VIRGINIA POLYTECHNIC INST AND ST UNIV,R03,2010,156500,0.022426784703018145
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8136874,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,125017,-0.005392102578261588
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8143048,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,76123,-0.005392102578261588
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7876805,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,676574,-0.005392102578261588
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7910730,P41HG004059,[' '],NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2010,1093220,0.00409538317088695
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,7901378,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'Muscle Rigidity', 'NMR Spectroscopy', 'Negative Staining', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'public health relevance', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2010,273363,-0.034382612424640205
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8101448,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Arts', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2010,187999,-0.032964492201260596
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7777764,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2010,527186,0.018209250600776678
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,7608855,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2009,164486,0.013833640239951827
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7668573,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,1187062,0.012604180852127576
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7922310,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,152260,0.012604180852127576
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7577491,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2009,342223,-0.015143964954971383
"Real-Time Automated Detection of Craving States with fMRI and EEG    DESCRIPTION (provided by applicant):  Neurofeedback by real time functional MRI (rt-fMRI) has potential for addiction research and treatment that will be realized only if the feedback given the subject is related meaningfully to the cognitive states that must be controlled. The mental operations of the brain are too distributed to be represented by the raw rt-fMRI signal in any one brain region or small group of regions. Our aims are to: 1) Use computational machine learning to rapidly detect patterned activation in the rt-fMRI signal that better expresses cognitive state; 2) augment these data with concurrently-collected electroencephalographic (EEG) data; 3) develop an atlas of brain data that identifies brain patterns with cognitive states relevant to addiction and drug abuse research and 4) to explore rt-fMRI neurofeedback using this rt-fMRI/EEG machine learning method. Our approach will be to first create rapid algorithms for pattern matching that are fast compared with the imaging, thereby allowing ""real-time"" application. To do so we will select features from the images that express the differences among state concisely (more technically, we will use a method known as independent components analysis to reduce the data dimensionality.) We will similarly condense the EEG features by studying them by the location of their sources within the brain, and by examining the frequencies that they contain. We will run experiments on volunteers designed to help us see their tendency to make impulsive choices - which is known to relate to their likelihood to become drug users, as well as experiments that track changes in their brain as they control their craving urges. For these studies we will look at heavy cigarette users. Cigarette use on its own is a serious health burden to the nation, and it is also an excellent model for addiction more generally, as it is known to have many neural features in common with use of other drugs of abuse, such as cocaine and methamphetamine. This is a phased innovation proposal. The first phase will be focused on the developments of the rt-fMRI analysis and instrumentation technology. On its successful completion, based on specific milestones, we will move to the more applied work with human subjects.      PUBLIC HEALTH RELEVANCE:  Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.           Project Narrative Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.",Real-Time Automated Detection of Craving States with fMRI and EEG,7690912,R21DA026109,"['Abstinence', 'Address', 'Affective', 'Algorithms', 'Anterior', 'Atlases', 'Base of the Brain', 'Behavior', 'Brain', 'Brain region', 'Cigarette', 'Classification', 'Clinical', 'Cocaine', 'Cognitive', 'Complex', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Dimensions', 'Discrimination', 'Drug abuse', 'Drug user', 'Electroencephalogram', 'Electroencephalography', 'Electrophysiology (science)', 'Epilepsy', 'Feedback', 'Four-dimensional', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Galvanic Skin Response', 'Generations', 'Goals', 'Health', 'Healthcare', 'Image', 'Imaging technology', 'Impulsivity', 'Intervention', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical', 'Methamphetamine', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Proxy', 'Psyche structure', 'Reporter', 'Reporting', 'Research', 'Rest', 'Running', 'Scalp structure', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Stimulus', 'Study Subject', 'Technology', 'Testing', 'Time', 'Traumatic Brain Injury', 'Work', 'abstracting', 'addiction', 'base', 'blind', 'chronic pain', 'cingulate cortex', 'cognitive control', 'craving', 'data space', 'design', 'discounting', 'drug of abuse', 'effective intervention', 'human subject', 'improved', 'independent component analysis', 'innovation', 'instrument', 'instrumentation', 'interest', 'method development', 'mind control', 'neurofeedback', 'neuroimaging', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'symposium', 'tool', 'trend', 'virtual', 'volunteer']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2009,307644,-0.0062426938072097735
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7582301,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2009,2057843,-0.0003884512278637026
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7633119,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2009,18437,-0.01156334191196503
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7652508,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2009,363929,-0.0013164102094096115
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7669241,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Reader', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computer infrastructure', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'meetings', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web site', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2009,829379,0.00409538317088695
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7921192,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Reader', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computer infrastructure', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'meetings', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web site', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2009,250001,0.00409538317088695
"Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones    DESCRIPTION (provided by applicant): Magnetoencephalography (MEG) and related electroencephalography (EEG) use an array of sensors to non-invasively measure electromagnetic (EM) fields produced by synchronous current activity within the brain. While the temporal resolution is excellent relative to other functional imaging modalities, accurately localizing in 3D space the sources of brain activity involves solving a difficult, underdetermined inverse problem. Existing localization methods used clinically and for research purposes maintain significant shortcomings, including the inability to resolve complex source configurations, bias caused by source correlations, and sensitivity to sources of noise and interference. The latter can arise from eye blinks, heart beats, sensor imperfections, and industrial noise as well as from spontaneous background brain activity not associated with the brain sources of interest. Additionally, prototype algorithms ostensibly designed to deal with some of these issues are heuristic in nature and have not been rigorously evaluated or compared, making their ultimate utility difficult to assess for neuroelectromagnetic imaging practitioners. The proposed research plan addresses all of these concerns by developing a principled localization scheme that unifies and extends existing localization strategies using modern concepts from Bayesian statistics and machine learning. Based on the notion of automatic relevance determination (ARD), brain regions with probable (relevant) activity are located with high spatial resolution. Interference sources are effectively removed by integrating with a variation factor analysis model. To quantify the improvement afforded by the proposed methodology, source location estimates will be compared with standard algorithms using realistic simulations, near-ground-truth data obtained from invasive electrocorticographic (ECoG) recordings, and surgical data. The result will be implemented as a user-friendly localization toolbox and made freely available to the community by integrating with existing open-source functional brain imaging software. Non-invasive mapping of brain activity with high spatio-temporal resolution has important consequences for basic neuroscience studies of human cognition. It also has profound implications for the diagnosis, characterization and treatment of various neurological, neurooncological, mental health, developmental, and communication disorders. For example, localizations of brain sources are used to map cognitive function in epileptogenic areas and in neighboring brain regions. Such brain mapping procedures are then useful to guide neurosurgical planning, navigation, and resection and to minimize post-operative deficits.           n/a",Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones,7751495,F32NS061395,"['Academia', 'Address', 'Algorithms', 'Area', 'Arts', 'Automation', 'Bayesian Method', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Engineering', 'Blinking', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Clinical', 'Code', 'Cognition', 'Cognitive Science', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Developmental Communication Disorders', 'Diagnosis', 'Diffuse', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Epilepsy', 'Evaluation', 'Event', 'Excision', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Failure', 'Frequencies', 'Functional Imaging', 'Heart', 'Human', 'Image', 'Individual', 'Interdisciplinary Study', 'Intractable Epilepsy', 'Language', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Morphologic artifacts', 'Motor', 'Nature', 'Neurologic', 'Neurosciences', 'Noise', 'Nutmeg - dietary', 'Occupations', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Radiology Specialty', 'Relative (related person)', 'Research', 'Research Training', 'Resected', 'Resolution', 'Scalp structure', 'Scheme', 'Science', 'Series', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Statistical Methods', 'Surface', 'Surrogate Markers', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'career', 'cognitive function', 'computerized data processing', 'cost', 'design', 'genetic pedigree', 'heuristics', 'human CYP2B6 protein', 'human subject', 'imaging modality', 'interest', 'neurophysiology', 'open source', 'prototype', 'reconstruction', 'sensor', 'simulation', 'statistics', 'user friendly software', 'user-friendly', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2009,46257,-0.003994688371266411
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7663288,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Computer Systems Development', 'Computer software', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Source', 'Structure', 'System', 'Systems Integration', 'Technology', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'meetings', 'models and simulation', 'open source', 'outreach', 'protein complex', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,437938,-0.0049778011370379925
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7589644,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,426946,0.008351760252262948
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7583948,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2009,328593,-0.005789420676117226
"Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid    DESCRIPTION (provided by applicant): The objective of this project is the development of an innovative technique to avoid disclosure of confidential data in public use tabular data. Our proposed technique, called Optimal Data Switching (OS), overcomes the limitations and disadvantages found in currently deployed disclosure limitation methods. Statistical databases for public use pose a critical problem of identifying how to make the data available for analysis without disclosing information that would infringe on privacy, violate confidentiality, or endanger national security. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. Yet, the possibility of extracting certain sensitive elements of information from the data can jeopardize the welfare of these organizations and potentially, in some instances, the welfare of the society in which they operate. The challenge is, therefore, to represent the data in a form that permits accurate analysis for supporting research, decision-making and policy initiatives, while preventing an unscrupulous or ill-intentioned party from exploiting the data for harmful consequences. Our goal is to build on the latest advances in optimization, to which the OptTek Systems, Inc. (OptTek) research team has made pioneering contributions, to provide a framework based on optimal data switching, enabling the Centers for Disease Control and Prevention (CDC) and other organizations to effectively meet the challenge of confidentiality protection. The framework we propose is structured to be easy to use in a wide array of application settings and diverse user environments, from client-server to web-based, regardless of whether the micro-data is continuous, ordinal, binary, or any combination of these types. The successful development of such a framework, and the computer-based method for implementing it, is badly needed and will be of value to many types of organizations, not only in the public sector but also in the private sector, for whom the incentive to publish data is both economic as well as scientific. Examples in the public sector are evident, where organizations like CDC and the U.S. Census Bureau exist for the purpose of collecting, analyzing and publishing data for analysis by other parties. Numerous examples are also encountered in the private sector, notably in banking and financial services, healthcare (including drug companies and medical research institutions), market research, oil exploration, computational biology, renewable and sustainable energy, retail sales, product development, and a wide variety of other areas. PUBLIC HEALTH RELEVANCE: In the process of accumulating and disseminating public health data for reporting purposes, various uses, and statistical analysis, we must guarantee that individual records describing each person or establishment are protected. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. This project proposes the development of a robust methodology and practical framework to deliver an efficient and effective tool to protect the confidentiality in published tabular data.                      n/a",Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid,7790821,R43MH086138,"['Accounting', 'American', 'Area', 'Cells', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Computational Biology', 'Confidentiality', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Disadvantaged', 'Disclosure', 'Economics', 'Elements', 'Ensure', 'Environment', 'Goals', 'Health Personnel', 'Healthcare', 'Incentives', 'Individual', 'Inferior', 'Institution', 'Machine Learning', 'Market Research', 'Medical Research', 'Methodology', 'Methods', 'National Security', 'Oils', 'Online Systems', 'Persons', 'Pharmaceutical Preparations', 'Policies', 'Policy Making', 'Privacy', 'Private Sector', 'Problem Solving', 'Process', 'Property', 'Provider', 'Public Health', 'Public Sector', 'Publishing', 'Records', 'Research', 'Research Methodology', 'Research Support', 'Respondent', 'Sales', 'Services', 'Social Welfare', 'Societies', 'Solutions', 'Structure', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'computer framework', 'data mining', 'flexibility', 'innovation', 'interest', 'meetings', 'prevent', 'product development', 'public health relevance', 'tool']",NIMH,"OPTTEK SYSTEMS, INC.",R43,2009,4047,-0.005375506573332917
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of  computer scientists, software engineers, and medical investigators who develop computational tools for the  analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure  and environment for the development of computational algorithms and open source technologies, and then  oversee the training and dissemination of these tools to the medical research community. This world-class  software and development environment serves as a foundation for accelerating the development and  deployment of computational tools that are readily accessible to the medical research community. The team  combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state  of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed,  open-source environment) to enable computational examination of both basic neurosience and neurologicat  disorders. In developing this infrastructure resource, the team will significantly expand upon proven open  systems technology and platforms. The driving biological projects will come initially from the study of  schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open  systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures  and connectivity patterns in the brain, derangements of which have long been thought to play a role in the  etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range  of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially  including microscopic, genomic, and other image data. It will apply to image data from individual  )atients,and to studies executed across large poplulations. The data will be taken from subjects across a  Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7915998,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Genomics', 'Goals', 'Healthcare', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2009,3720664,-0.006729564252347417
"A Texture Analysis/Synthesis Model of Visual Crowding    DESCRIPTION (provided by applicant): Identifying a visual stimulus can be substantially impaired by the mere presence of additional stimuli in the immediate vicinity. This phenomenon is called ""crowding,"" and it powerfully limits visual perception in many circumstances, especially in the peripheral visual field. There is a rich body of literature detailing the phenomenology of crowding, but we do not know why crowding occurs. We lack a computational model that can predict what information will be available to an observer in an arbitrary crowded display. A popular hypothesis is that crowding results from obligatory ""texture processing,"" but there have been few efforts to formalize and test what this might mean, despite broad agreement that crowding reflects some form of ""excessive integration."" Dr. Rosenholtz has extensive experience with computational models of texture processing, which are a powerful means of defining the exact nature of ""texture processing"" and testing the ability of such models to explain and predict visual behavior. The proposed research has 3 aims: (1) To clarify and formalize the hypothesis that crowding is due to a ""texture"" - i.e. statistical -- representation of the crowded stimuli. (2) To collect behavioral data from a wider variety of displays and tasks than is typically studied in crowding. (3) To develop and validate the first general-purpose model of visual crowding. To achieve these aims, Dr. Rosenholtz will apply state-of-the-art computational tools for texture synthesis to ""crowded"" stimuli. ""Texturizing"" crowded arrays of stimuli affords a tool for visualizing the information available in a crowded display and a vocabulary for describing its representational content. Thus, Dr. Rosenholtz will attack the problem of crowding through a useful synthesis of computer graphics, computer vision, and psychophysics. PUBLIC HEALTH RELEVANCE: Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.            Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.",A Texture Analysis/Synthesis Model of Visual Crowding,7740891,R21EY019366,"['Age related macular degeneration', 'Agreement', 'Amblyopia', 'Area', 'Arts', 'Attention', 'Behavior', 'Behavioral', 'Binding', 'Cells', 'Classification', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Crowding', 'Data', 'Databases', 'Discrimination', 'Disease', 'Elderly', 'Eye Movements', 'Face', 'Failure', 'Functional disorder', 'Gender', 'Goals', 'Gray unit of radiation dose', 'Human', 'Imagery', 'Individual', 'Joints', 'Lesion', 'Letters', 'Literature', 'Location', 'Masks', 'Methods', 'Modeling', 'Nature', 'Patients', 'Perception', 'Performance', 'Peripheral', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Resolution', 'Saccades', 'Severities', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Work', 'base', 'clinically significant', 'computerized tools', 'design', 'experience', 'improved', 'neglect', 'novel', 'object recognition', 'public health relevance', 'research study', 'response', 'statistics', 'theories', 'tool', 'vision aid', 'visual information', 'visual search', 'visual stimulus']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2009,168000,-0.004914821827576911
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7616844,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2009,1255061,-0.002042667406319782
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7804332,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2009,363247,-0.009734520990825397
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,-0.017468048114522624
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7915039,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,168580,-0.005392102578261588
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7643324,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,815277,-0.005392102578261588
"Improved algorithms for macromolecular structure determination by cryo-EM and NMR    DESCRIPTION (provided by applicant): Single-particle electron cryomicroscopy (cryo-EM) and 2D NMR spectroscopy are methods for observing the three-dimensional structures of large and small macromolecules. respectively. We propose to develop and apply novel algorithms for solving the difficult mathematical problems posed by these techniques of structural biology. In cryo-EM the experimental data consist of noisy, random projection images of macromolecular ""particles"", and the problem is finding the 3D structure which is consistent with these images. Present reconstruction techniques rely on user input or ad hoc models to initiate a refinement cycle. We propose a new algorithm, ""globally consistent angular reconstitution"" (GCAR) that provides an unbiased and direct solution to the reconstruction problem. We further propose an extension to GCAR to handle heterogeneous particle populations. We also will pursue a powerful new approach to determining class averages, ""triplet class averaging"". This should allow GCAR to be used with data having very low signal-to-noise ratios, as is commonly obtained. The experimental data from NMR consist of estimates of local distances between atoms, and the goal is to find a globally consistent coordinate system. The same theory behind GCAR, involving the properties of sparse linear operators, can be applied to obtain a fast and direct solution to the distance geometry problem. We will develop and implement all of these algorithms and test them with experimental cryo-EM and NMR data. PUBLIC HEALTH RELEVANCE:  Determining the structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, as well as the first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to increase the power of two structure-determination methods, cryo-EM and NMR.           n/a",Improved algorithms for macromolecular structure determination by cryo-EM and NMR,7787325,R01GM090200,"['Affinity', 'Algorithms', 'Area', 'Biological Process', 'Chemicals', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Databases', 'Discipline', 'Drug Design', 'Failure', 'Filtration', 'Goals', 'Heterogeneity', 'Hydrogen Bonding', 'Image', 'Individual', 'Knowledge', 'Least-Squares Analysis', 'Link', 'Maps', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Structure', 'Muscle Rigidity', 'NMR Spectroscopy', 'Negative Staining', 'Noise', 'Performance', 'Population', 'Potassium Channel', 'Procedures', 'Property', 'Proteins', 'Radial', 'Recovery', 'Relative (related person)', 'Research', 'Risk', 'Signal Transduction', 'Simulate', 'Solutions', 'Spiders', 'Structure', 'System', 'Techniques', 'Testing', 'Torsion', 'Triplet Multiple Birth', 'Variant', 'base', 'data mining', 'high risk', 'image processing', 'improved', 'macromolecule', 'mathematical theory', 'novel', 'novel strategies', 'particle', 'performance tests', 'programs', 'protein structure', 'public health relevance', 'receptor', 'reconstitution', 'reconstruction', 'structural biology', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2009,293039,-0.034382612424640205
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7586102,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'depressed', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2009,522802,0.018209250600776678
"Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex In 3-month paid research experiences, over two summers, 4  talented undergraduate engineering and computer science students will be recruited to contribute in a substantial way to the progress of sub-aims of my parent New Innovator (DP2) Award;  the DP2's main specific aims are to develop novel microscopes (Aim 1) and analytical tools (Aim 2) to study membrane trafficking at the cell cortex (Aim 3).  Specifically, students will work on one of two projects: i)  Design and construct and improve electronic circuits to control the galvometric XY mirror on our multi-angle FRAP/TIRFM (Aim 1B) and/or new auto-sensing calibration devices (Aim 2) or ii) Develop models or software to visualize and track vesicles in 3D by multi-angle TIRFM (Aim 2 ). Their advances will directly benefits goals of the DP2 and the new electronics and software's performance will be benchmarked and iteratively improved. Training and oversight will come from the PI and the DP2-supported senior scientist, Dr. Polejaev.  Students will benefit from the infrastructure of the Yale 'CINEMA' lab imaging center, which is under the PI's directorship.         Two outstanding US engineering students have already been identified, Noah Pestana and Isaac Anderson, both of whom have expressed a high interest in participating this summer on projects (i) and (ii), respectively. In the second summer, a particular emphasis will be made to recruit minority undergraduate students through the Yale 'STARS' program for minorities.   All proposed activity are within the scope of the parent DP2 and capitalizes on early successes and will accelerate the tempo of two of the approved specific aims. Consistent with the recovery act's goal, this funding will provide full-time summer employment for 4 undergraduate students and accelerate scientific achievement of the parent DP2 award.  n/a",Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex,7892704,DP2OD002980,"['1-Phosphatidylinositol 3-Kinase', 'Abbreviations', 'Accounting', 'Acoustics', 'Address', 'Adipocytes', 'Affect', 'Algorithms', 'Area', 'Arts', 'Attenuated', 'Automobile Driving', 'Award', 'Back', 'Binding', 'Biochemical', 'Biochemistry', 'Biological', 'Biology', 'Boxing', 'Buffers', 'Caliber', 'Calibration', 'Cell Line', 'Cell membrane', 'Cell surface', 'Cells', 'Cellular biology', 'Clathrin', 'Cluster Analysis', 'Collaborations', 'Collection', 'Collimator', 'Color', 'Coma', 'Communities', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computers', 'Conflict (Psychology)', 'Confocal Microscopy', 'Coupled', 'Coupling', 'Cues', 'Cytoskeleton', 'Data', 'Data Set', 'Defect', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Dimerization', 'Disadvantaged', 'Discipline', 'Docking', 'Down-Regulation', 'Drops', 'Dyes', 'Employee Strikes', 'Endocytosis', 'Engineering', 'Ensure', 'Environment', 'Event', 'Exocytosis', 'Eye', 'Face', 'Feedback', 'Fiber', 'Figs - dietary', 'Flare', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Recovery After Photobleaching', 'Fluorescent Dyes', 'Functional disorder', 'Funding', 'Genetic Screening', 'Germany', 'Glass', 'Glucose Transporter', 'Glycerol', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Insulin', 'Interdisciplinary Study', 'Investments', 'Joints', 'Kinetics', 'Knowledge', 'Label', 'Laboratories', 'Lasers', 'Learning', 'Legal patent', 'Length', 'Life', 'Light', 'Lighting', 'Link', 'Lipids', 'Location', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Masks', 'Measures', 'Mediating', 'Membrane', 'Membrane Microdomains', 'Membrane Protein Traffic', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Microtubules', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motivation', 'Motor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Optics', 'Organelles', 'PTEN gene', 'Paper', 'Parasites', 'Pathway interactions', 'Penetration', 'Performance', 'Phosphatidylinositols', 'Phosphotransferases', 'Photobleaching', 'Physiologic pulse', 'Planet Mars', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Private Sector', 'Probability', 'Process', 'Proteins', 'Publications', 'Pupil', 'Quantum Dots', 'RNA Interference', 'Radial', 'Randomized', 'Reagent', 'Recruitment Activity', 'Refractive Indices', 'Regulation', 'Relative (related person)', 'Reporter', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seminal', 'Series', 'Side', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Simulate', 'Site', 'Small Interfering RNA', 'Solid', 'Solutions', 'Sorting - Cell Movement', 'Source', 'Spain', 'Spatial Distribution', 'Specific qualifier value', 'Specimen', 'Speed', 'Spottings', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Thick', 'Time', 'Total Internal Reflection Fluorescent', 'Touch sensation', 'Training', 'Transfection', 'Tubulin', 'Vesicle', 'Visual', 'Wolves', 'Work', 'analytical method', 'basal insulin', 'base', 'blood glucose regulation', 'cell cortex', 'cell motility', 'cell type', 'cellular imaging', 'density', 'design', 'extracellular', 'flexibility', 'flotillin', 'fluorescence imaging', 'fluorescence microscope', 'fluorophore', 'handbook', 'holistic approach', 'image processing', 'improved', 'innovation', 'insight', 'instrument', 'instrumentation', 'insulin signaling', 'interest', 'lens', 'medical schools', 'meetings', 'micromanipulator', 'migration', 'millisecond', 'nanometer', 'novel', 'object shape', 'photoactivation', 'prototype', 'receptor', 'research study', 'response', 'scaffold', 'simulation', 'single molecule', 'success', 'tool', 'trafficking', 'trans-Golgi Network', 'trend', 'user-friendly', 'virtual']",OD,YALE UNIVERSITY,DP2,2009,50463,-0.003748088757398369
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7404392,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2008,383858,0.011880856402395305
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7433144,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Class', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Computers', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Numbers', 'Performance', 'Personal Satisfaction', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Public Health', 'Randomized', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'Voting', 'Work', 'base', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R44,2008,25548,-0.0032522082908518052
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7500697,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2008,1146026,0.012604180852127576
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7431959,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Condition', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Numbers', 'Patients', 'Play', 'Population', 'Process', 'Public Health', 'Rate', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'particle', 'size', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2008,376423,-0.015143964954971383
"A Simulation Tool to Enable Identification of Critical Network Interactions Using    DESCRIPTION (provided by applicant): One of the main challenges in the discovery of intracellular biomarkers and identification of therapeutic targets is the lack of a mechanistic understanding of the complex underlying pathways. The tremendous increase in both the quantity and diversity of cellular data represents a significant challenge to researchers seeking to construct biologically relevant interaction maps, and objectively extract specific actionable information. Machine learning based clustering algorithms serve as a preliminary statistical data analysis metric, but they fail to capture the data in the proper biological context. While chemical kinetics based models have proved to be effective in elucidating the pathway mechanisms, accurate estimates for the model parameters are severely lacking and are often impossible to obtain owing to the inherent difficulties involved in making dynamic measurements of specific intracellular phenomena. Additionally, methods for rational prioritization and selection of critical intracellular interactions (in the absence of kinetic information) are sorely lacking. Therefore, there is a clear need for innovative software tools that enable quantitative analysis of available microarray data in a biological pathway context, ultimately leading to the objective identification of critical biological interactions, providing a direction for more focused future efforts. We propose to address this challenge by developing an automated software platform that utilizes microarray data to select and merge relevant canonical biological pathway models thereby placing significantly expressed genes in their biological context. The analysis software will utilize a microarray expression-weighted metric to objectively rank the most critical interactions within the network model using a novel chemical kinetics-free Boolean dynamics algorithm. In the Phase I effort, we will develop a software tool composed of an R library that enables the automated generation of a pathway model from a given microarray dataset. Additionally, a methodology, and associated R library will be developed to objectively rank critical interactions in the pathway model, using a microarray data expression-weighted metric. Demonstration and validation of proposed algorithm will be carried out using a well characterized lipopolysaccharide (LPS) stimulated RAW 264.7 macrophage system. In Phase II, we will extend the scope of the algorithmic framework to include proteomic and metabolomic weighting in the objective ranking of critical interactions, and add workflow improvements through the addition of a graphical user interface (GUI). Experimental verification and validation of critical interactions identified in Phase I will be carried out using gene-silencing techniques. We also intend to establish collaborative partnerships with commercial entities. The proposing team has extensive experience in the areas of systems biology and bioinformatics (CFDRC) and microarray data analysis (Shawn Levy, University of Vanderbilt). CFDRC has a strong track record in the commercialization of software and hardware. PUBLIC HEALTH RELEVANCE:  Recently, there has been a tremendous increase in both the amount and diversity of cellular data available to researchers, representing a clear need for the development of advanced computational analysis software to enable the discovery of biomarkers of disease states, and identification of new therapeutic targets. However, currently available analysis tools do not consider the data in a proper biological context. This research proposes to develop an automated software platform that utilizes available data to develop and analyze mathematical models of complex processes in an automated fashion, resulting in the identification of critical intracellular processes.             n/a",A Simulation Tool to Enable Identification of Critical Network Interactions Using,7482734,R43GM084890,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Biological Markers', 'Complex', 'Computer Analysis', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Future', 'Gene Silencing', 'Generations', 'Genes', 'Genomics', 'Kinetics', 'Lead', 'Libraries', 'Lipopolysaccharides', 'Machine Learning', 'Maps', 'Measurement', 'Methodology', 'Methods', 'Metric', 'Microarray Analysis', 'Modeling', 'Nature', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Process', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Software Tools', 'Statistical Data Interpretation', 'System', 'Systems Biology', 'Techniques', 'Title', 'Universities', 'Urination', 'Validation', 'Weight', 'base', 'chemical kinetics', 'commercialization', 'editorial', 'experience', 'graphical user interface', 'innovation', 'macrophage', 'mathematical model', 'metabolomics', 'network models', 'novel', 'novel therapeutics', 'simulation', 'therapeutic target', 'tool']",NIGMS,CFD RESEARCH CORPORATION,R43,2008,99571,-0.02094333919334335
"Real-Time Automated Detection of Craving States with fMRI and EEG    DESCRIPTION (provided by applicant):  Neurofeedback by real time functional MRI (rt-fMRI) has potential for addiction research and treatment that will be realized only if the feedback given the subject is related meaningfully to the cognitive states that must be controlled. The mental operations of the brain are too distributed to be represented by the raw rt-fMRI signal in any one brain region or small group of regions. Our aims are to: 1) Use computational machine learning to rapidly detect patterned activation in the rt-fMRI signal that better expresses cognitive state; 2) augment these data with concurrently-collected electroencephalographic (EEG) data; 3) develop an atlas of brain data that identifies brain patterns with cognitive states relevant to addiction and drug abuse research and 4) to explore rt-fMRI neurofeedback using this rt-fMRI/EEG machine learning method. Our approach will be to first create rapid algorithms for pattern matching that are fast compared with the imaging, thereby allowing ""real-time"" application. To do so we will select features from the images that express the differences among state concisely (more technically, we will use a method known as independent components analysis to reduce the data dimensionality.) We will similarly condense the EEG features by studying them by the location of their sources within the brain, and by examining the frequencies that they contain. We will run experiments on volunteers designed to help us see their tendency to make impulsive choices - which is known to relate to their likelihood to become drug users, as well as experiments that track changes in their brain as they control their craving urges. For these studies we will look at heavy cigarette users. Cigarette use on its own is a serious health burden to the nation, and it is also an excellent model for addiction more generally, as it is known to have many neural features in common with use of other drugs of abuse, such as cocaine and methamphetamine. This is a phased innovation proposal. The first phase will be focused on the developments of the rt-fMRI analysis and instrumentation technology. On its successful completion, based on specific milestones, we will move to the more applied work with human subjects.      PUBLIC HEALTH RELEVANCE:  Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.           Project Narrative Our research aims to develop and characterize a means of rapidly detecting brain states relevant to addiction research through the use of magnetic resonance imaging and electroencephalography. We are interested specifically in states and markers of impulsivity and cigarette craving. Our goal ultimately is to have a tool that can be used in the context of neurofeedback, allowing human subject or patient to receive an indication of activity in their brains associated with these states and to enable them to learn to control these cognitive/affective states by controlling the brain activity.",Real-Time Automated Detection of Craving States with fMRI and EEG,7588944,R21DA026109,"['Abstinence', 'Address', 'Affective', 'Algorithms', 'Anterior', 'Atlases', 'Base of the Brain', 'Behavior', 'Brain', 'Brain region', 'Cigarette', 'Classification', 'Clinical', 'Cocaine', 'Cognitive', 'Complex', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Dimensions', 'Discrimination', 'Disease', 'Drug Addiction', 'Drug abuse', 'Drug user', 'Electroencephalogram', 'Electroencephalography', 'Electrophysiology (science)', 'Feedback', 'Four-dimensional', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Galvanic Skin Response', 'Generations', 'Goals', 'Health', 'Healthcare', 'Image', 'Imaging technology', 'Impulsivity', 'Intervention', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical', 'Methamphetamine', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Post-Traumatic Epilepsy', 'Proxy', 'Psyche structure', 'Public Health', 'Reporter', 'Reporting', 'Research', 'Rest', 'Running', 'Scalp structure', 'Schizophrenia', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Stimulus', 'Study Subject', 'Technology', 'Testing', 'Time', 'Traumatic Brain Injury', 'Work', 'abstracting', 'addiction', 'base', 'blind', 'chronic pain', 'cingulate cortex', 'cognitive control', 'craving', 'data space', 'design', 'discounting', 'drug of abuse', 'human subject', 'improved', 'independent component analysis', 'innovation', 'instrument', 'instrumentation', 'interest', 'method development', 'mind control', 'neuroimaging', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'symposium', 'tool', 'trend', 'virtual', 'volunteer']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2008,283172,-0.0062426938072097735
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7367958,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2008,2037396,-0.0003884512278637026
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7489320,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Range', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'concept', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2008,52898,-0.01156334191196503
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7495734,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2008,353327,-0.0013164102094096115
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7371085,K12MH069281,"['Anatomy', 'Area', 'Artificial Intelligence', 'Base of the Brain', 'Biomedical Engineering', 'Biomedical Informatics Research Network', 'Brain', 'Brain imaging', 'Caliber', 'Class', 'Clinical', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Development', 'Discipline', 'Educational Activities', 'Exposure to', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Laboratories', 'Mentored Research Scientist Development Award', 'Mentors', 'Methodology', 'Monitor', 'Neurosciences', 'Numbers', 'Operative Surgical Procedures', 'Physicians', 'Procedures', 'Program Development', 'Psyche structure', 'Range', 'Rate', 'Recruitment Activity', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'SECTM1 gene', 'Science', 'Scientist', 'Surface', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Woman', 'base', 'bioimaging', 'biomedical informatics', 'brain morphology', 'career', 'cationic antimicrobial protein CAP 37', 'clinical application', 'cognitive neuroscience', 'computer science', 'imaging informatics', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'post-doctoral training', 'programs', 'research and development', 'response', 'skills']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2008,462488,-0.004454288859620078
"Brain abnormality in unaffected family members of schizophrenic patients    DESCRIPTION (provided by applicant): This R03 proposal aims at developing a methodological framework for nonlinear multivariate analysis, using a non-linear pattern classification method, to identify and quantify subtle and spatially-complex brain abnormalities in unaffected family members of schizophrenia patients. Compared to conventional methods based on regions of interest (ROI) that rely only on a few pre-selected manually-labeled ROIs, this automated method will consider all brain regions simultaneously for identification of complex patterns of brain abnormality that cannot be necessarily summarized by a few pre-defined ROIs. Accordingly, a major methodological challenge to be addressed in this project is the development of statistical image analysis and data mining methods for estimating the collection of brain regions or networks that jointly form patterns to characterize schizophrenia as uniquely as possible. Patterns determined by comparison of confirmed schizophrenia patients and healthy controls will be examined on unaffected family members of patients, to test whether individuals that are genetically related to patients display, to some extent, endophenotypes of schizophrenia. Also, unaffected family members will be further compared with patients to identify the morphological profiles that seem directly associated with the phenotype of schizophrenia. The performance of the proposed nonlinear pattern analysis and classification method will be tested on an existing schizophrenia dataset in the Schizophrenia Research Center at the University of Pennsylvania. Although not an immediate goal of this specific proposal, the long-term objective of the proposed work is to apply this automated methodology to various studies, including (1) a large-scale genetic study of schizophrenia involving informative samples, in order to examine questions that cannot be addressed with conventional ROI-based analysis; (2) the quantification and recognition of endophenotypes of schizophrenia in unaffected individuals, which can potentially pave the way for the detection of adolescents that possess brain endophenotypes that put them at risk; (3) clinical studies investigating the added value of quantifying endophenotypes of schizophrenia for clinical diagnosis, especially in difficult cases or outside environments with well-trained psychiatrists, in which unbiased computer-based methods can potentially greatly assist in clinical evaluation and diagnosis.           n/a",Brain abnormality in unaffected family members of schizophrenic patients,7325760,R03MH076970,"['Address', 'Adolescent', 'Adoption', 'Affect', 'Brain', 'Brain imaging', 'Brain region', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computers', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Environment', 'Family member', 'First Degree Relative', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Hand', 'Image Analysis', 'Individual', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medial', 'Methodology', 'Methods', 'Multivariate Analysis', 'Neuroanatomy', 'Patient Education', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phenotype', 'Play', 'Psychiatrist', 'Relative Risks', 'Research', 'Risk', 'Role', 'Sampling', 'Schizophrenia', 'Structure', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Universities', 'Work', 'base', 'clinical Diagnosis', 'data mining', 'endophenotype', 'gray matter', 'interest', 'lateral ventricle', 'member', 'research clinical testing']",NIMH,UNIVERSITY OF PENNSYLVANIA,R03,2008,65055,0.0018398036270865436
"Brain abnormality in unaffected family members of schizophrenic patients    DESCRIPTION (provided by applicant): This R03 proposal aims at developing a methodological framework for nonlinear multivariate analysis, using a non-linear pattern classification method, to identify and quantify subtle and spatially-complex brain abnormalities in unaffected family members of schizophrenia patients. Compared to conventional methods based on regions of interest (ROI) that rely only on a few pre-selected manually-labeled ROIs, this automated method will consider all brain regions simultaneously for identification of complex patterns of brain abnormality that cannot be necessarily summarized by a few pre-defined ROIs. Accordingly, a major methodological challenge to be addressed in this project is the development of statistical image analysis and data mining methods for estimating the collection of brain regions or networks that jointly form patterns to characterize schizophrenia as uniquely as possible. Patterns determined by comparison of confirmed schizophrenia patients and healthy controls will be examined on unaffected family members of patients, to test whether individuals that are genetically related to patients display, to some extent, endophenotypes of schizophrenia. Also, unaffected family members will be further compared with patients to identify the morphological profiles that seem directly associated with the phenotype of schizophrenia. The performance of the proposed nonlinear pattern analysis and classification method will be tested on an existing schizophrenia dataset in the Schizophrenia Research Center at the University of Pennsylvania. Although not an immediate goal of this specific proposal, the long-term objective of the proposed work is to apply this automated methodology to various studies, including (1) a large-scale genetic study of schizophrenia involving informative samples, in order to examine questions that cannot be addressed with conventional ROI-based analysis; (2) the quantification and recognition of endophenotypes of schizophrenia in unaffected individuals, which can potentially pave the way for the detection of adolescents that possess brain endophenotypes that put them at risk; (3) clinical studies investigating the added value of quantifying endophenotypes of schizophrenia for clinical diagnosis, especially in difficult cases or outside environments with well-trained psychiatrists, in which unbiased computer-based methods can potentially greatly assist in clinical evaluation and diagnosis.           n/a",Brain abnormality in unaffected family members of schizophrenic patients,7663443,R03MH076970,"['Address', 'Adolescent', 'Adoption', 'Affect', 'Brain', 'Brain imaging', 'Brain region', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computers', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Environment', 'Family member', 'First Degree Relative', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Hand', 'Image Analysis', 'Individual', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medial', 'Methodology', 'Methods', 'Multivariate Analysis', 'Neuroanatomy', 'Patient Education', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phenotype', 'Play', 'Psychiatrist', 'Relative Risks', 'Research', 'Risk', 'Role', 'Sampling', 'Schizophrenia', 'Structure', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Universities', 'Work', 'base', 'clinical Diagnosis', 'data mining', 'endophenotype', 'gray matter', 'interest', 'lateral ventricle', 'member', 'research clinical testing']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,R03,2008,12825,0.0018398036270865436
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7446299,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Count', 'Custom', 'Daily', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Public Health', 'Range', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Standards of Weights and Measures', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'desire', 'image processing', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,421791,0.008351760252262948
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7457647,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,437938,-0.0049778011370379925
"Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid    DESCRIPTION (provided by applicant): The objective of this project is the development of an innovative technique to avoid disclosure of confidential data in public use tabular data. Our proposed technique, called Optimal Data Switching (OS), overcomes the limitations and disadvantages found in currently deployed disclosure limitation methods. Statistical databases for public use pose a critical problem of identifying how to make the data available for analysis without disclosing information that would infringe on privacy, violate confidentiality, or endanger national security. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. Yet, the possibility of extracting certain sensitive elements of information from the data can jeopardize the welfare of these organizations and potentially, in some instances, the welfare of the society in which they operate. The challenge is, therefore, to represent the data in a form that permits accurate analysis for supporting research, decision-making and policy initiatives, while preventing an unscrupulous or ill-intentioned party from exploiting the data for harmful consequences. Our goal is to build on the latest advances in optimization, to which the OptTek Systems, Inc. (OptTek) research team has made pioneering contributions, to provide a framework based on optimal data switching, enabling the Centers for Disease Control and Prevention (CDC) and other organizations to effectively meet the challenge of confidentiality protection. The framework we propose is structured to be easy to use in a wide array of application settings and diverse user environments, from client-server to web-based, regardless of whether the micro-data is continuous, ordinal, binary, or any combination of these types. The successful development of such a framework, and the computer-based method for implementing it, is badly needed and will be of value to many types of organizations, not only in the public sector but also in the private sector, for whom the incentive to publish data is both economic as well as scientific. Examples in the public sector are evident, where organizations like CDC and the U.S. Census Bureau exist for the purpose of collecting, analyzing and publishing data for analysis by other parties. Numerous examples are also encountered in the private sector, notably in banking and financial services, healthcare (including drug companies and medical research institutions), market research, oil exploration, computational biology, renewable and sustainable energy, retail sales, product development, and a wide variety of other areas. PUBLIC HEALTH RELEVANCE: In the process of accumulating and disseminating public health data for reporting purposes, various uses, and statistical analysis, we must guarantee that individual records describing each person or establishment are protected. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. This project proposes the development of a robust methodology and practical framework to deliver an efficient and effective tool to protect the confidentiality in published tabular data.                      n/a",Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid,7535414,R43MH086138,"['Accounting', 'American', 'Area', 'Cells', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Computational Biology', 'Confidentiality', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Decision Analysis', 'Decision Making', 'Development', 'Disadvantaged', 'Disclosure', 'Economics', 'Elements', 'Ensure', 'Environment', 'Goals', 'Health Personnel', 'Healthcare', 'Incentives', 'Individual', 'Inferior', 'Institution', 'Machine Learning', 'Market Research', 'Medical Research', 'Methodology', 'Methods', 'National Security', 'Oils', 'Online Systems', 'Persons', 'Pharmaceutical Preparations', 'Policies', 'Policy Making', 'Privacy', 'Private Sector', 'Problem Solving', 'Process', 'Property', 'Provider', 'Public Health', 'Public Sector', 'Publishing', 'Purpose', 'Records', 'Research', 'Research Methodology', 'Respondent', 'Sales', 'Services', 'Social Welfare', 'Societies', 'Solutions', 'Structure', 'Support of Research', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'computer framework', 'data mining', 'desire', 'innovation', 'interest', 'prevent', 'tool']",NIMH,"OPTTEK SYSTEMS, INC.",R43,2008,99843,-0.005375506573332917
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7350139,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Condition', 'Count', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Numbers', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Rate', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'size', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2008,322249,-0.005789420676117226
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7316099,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY,R01,2008,476784,-0.013205139526685493
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to build and test a ""Smart Telescope,"" a device for persons with low vision that uses computer vision algorithms to search for, detect and enhance targets such as text and faces to aid in everyday tasks such as travel, navigation and social interactions. The practical, cosmetically acceptable packaging will consist of a miniature camera and visual display discreetly mounted on spectacles or a hat, and a compact computing device and set of controls that fit into a pocket. The Smart Telescope advances today's state of the art in assistive devices for low vision by automatically searching for, detecting and enhancing target objects even when they fill only a small portion of the device's field of view, without the user having to point the device directly or accurately at the target as with optical telescopes. The Smart Telescope is small and lightweight, but large enough for the elderly to handle and control; simple to operate and easy to carry, store, recharge, don and remove. Advanced options are hidden during day-to-day use, but easy to access when necessary. In Phase I, we developed and evaluated a working prototype and received enthusiastic feedback from subjects in our target population. In Phase II we propose to prototype a commercially viable consumer version of the Smart Telescope. The Phase II work plan has four tracks: 1) User interaction and interface design, 2) physical design and configuration, 3) software design and development, and 4) hardware design and development. Smith-Kettlewell's Rehabilitation Engineering Research Center (RERC) will provide expertise for the human factors portions of the project. Blindsight will design and build the device hardware from off-the-shelf components with the help of Bolton Engineering. Low vision experts Drs. Don Fletcher, Melissa Chun and Ian Bailey will work with the RERC to guarantee a practical product for the target audience. The overall aim is to create a commercial version of the proposed device for persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems, increasing mobility and independence for those with acuity between approximately 20/200 and 20/600. At under $1,000, the total market for such a device is estimated at up to 300,000, i.e., 10% of low vision persons in the United States. The commercial version of the Smart Telescope will significantly increase mobility and independence for persons with visual acuity between approximately 20/200 and 20/600, aiding them in everyday tasks such as travel, navigation, and social interactions. It will advance today's state of the art in assistive devices for low vision by improving on and surpassing the capabilities of the traditional optical telescope, greatly benefiting persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems.          n/a",A Smart Telescope for Low Vision,7486800,R44EY014487,"['Algorithms', 'Arts', 'Cataract', 'Computer Vision Systems', 'Contrast Sensitivity', 'Development', 'Devices', 'Diabetic Retinopathy', 'Elderly', 'Engineering', 'Eye', 'Eyeglasses', 'Face', 'Feedback', 'Glaucoma', 'Human', 'Macular degeneration', 'Marketing', 'Melissa', 'Optics', 'Persons', 'Phase', 'Research', 'Self-Help Devices', 'Social Interaction', 'Software Design', 'Target Populations', 'Testing', 'Text', 'Today', 'Travel', 'United States', 'Vision', 'Visual', 'Visual Acuity', 'Visual impairment', 'Work', 'day', 'design', 'improved', 'low vision telescope', 'prototype', 'rehabilitation engineering']",NEI,BLINDSIGHT CORPORATION,R44,2008,434041,0.019908784823263033
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688808,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,100000,-0.006729564252347417
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688368,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,50000,-0.006729564252347417
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7409622,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic Models', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Localized', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Range', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'USA Georgia', 'Western Asia Georgia', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2008,1249160,-0.002042667406319782
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,-0.017468048114522624
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7748401,R44GM083965,"['Learning', 'Techniques', 'parallel computing']",NIGMS,INSILICOS,R44,2008,143361,-0.0032522082908518052
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,-0.02690771812623586
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7433931,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2008,322087,-0.007006931427307602
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.       n/a",Bioconductor: an open computing resource for genomics,7495201,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Class', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Numbers', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Range', 'Reader', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'size', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2008,805222,0.010626951865181079
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7479786,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,3534631,-0.004362363672179761
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7665248,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,80289,-0.005392102578261588
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7489821,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,1042528,-0.005392102578261588
"Webcam Interface for Audio/touch Graphics Access by Blind People    DESCRIPTION (provided by applicant):  The goal of this project is to develop a compact inexpensive alternative to the bulky expensive touchpads now required by blind people for audio/touch access to graphical information. Audio/touch is known to provide excellent access to computer-literate blind people as well as people with dyslexia or other severe print disabilities. Preparing Audio/touch materials was very expensive until ViewPlus introduced the IVEO Scalable Vector Graphic (SVG) Authoring/conversion software in 2005. IVEO permits virtually any graphical information to be created or converted/imported easily to a well- structured highly accessible SVG format. Tactile copy was also very expensive before 2000 when ViewPlus introduced the Tiger embossing Windows printers that ""print"" by embossing. The new ViewPlus Emprint printer/embossers emboss and also print color images, creating color tactile images particularly useful for people with dyslexia and a number of other print disabilities. An audio/touch user reads an IVEO SVG graphic using the free IVEO Viewer, a tactile copy of the image, and a touchpad. The user places the tactile graphic on the touchpad and presses a point of interest. The touchpad communicates the position of that point back to the computer, and the IVEO Viewer speaks the appropriate information. Tactile text made from mainstream graphics has a distinctive pattern. When a user presses, that text is spoken by the IVEO Viewer. When the user presses a graphic object having a SVG title within the file, that title will be spoken. Objects may also have arbitrarily long description fields that can be spoken and browsed. All spoken information can be displayed on an attached braille display if desired. Graphical information is ubiquitous today, but almost none is accessible to blind people. Government agencies, libraries, companies, and agencies serving people with disabilities could easily send highly accessible IVEO graphics files and tactile graphic copies to clients with disabilities, but there is a ""chicken and egg"" dilemma that must be overcome before they are likely to do so. Few blind people have a touchpad (which cost $500 or more), so few could use that information. The specific aim of this Phase I proposal is to develop an affordable webcam-based prototype as an alternative to touchpads. It is based on an inexpensive webcam that is focused on the graphic and follows a finger. A touchpad press is emulated in this prototype by pressing some computer key with the other hand. This project could be the key to bringing accessible graphics to all blind computer users and is clearly of interest to NEI whose mission statement includes mental health and quality of life of blind people. PUBLIC HEALTH RELEVANCE:  This proposal is relevant to the mission of the National Eye Institute, because it could be the key to making nearly all graphical information easily accessible to people who are blind or have other severe print disabilities. Graphical information is ubiquitous in the world today but is not presently accessible to blind people except through expensive and time-consuming conversion by trained transcribers. Making all graphical information accessible would have an obviously highly beneficial direct effect on education and professional opportunities, mental health, and quality of life of blind people. Mental health and quality of life issues for blind people are parts of the mission of the National Eye Institute.          n/a",Webcam Interface for Audio/touch Graphics Access by Blind People,7480812,R43EY018973,"['Back', 'Braille Display', 'Businesses', 'Chickens', 'Client', 'Color', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consultations', 'Development', 'Devices', 'Disabled Persons', 'Dyslexia', 'Event', 'Fingers', 'Goals', 'Government Agencies', 'Hand', 'Home environment', 'Image', 'Information Systems', 'Institution', 'Internet', 'Libraries', 'Link', 'Mainstreaming', 'Marketing', 'Mental Health', 'Methods', 'Mission', 'Modeling', 'Mus', 'National Eye Institute', 'Numbers', 'Oregon', 'Pattern', 'Phase', 'Positioning Attribute', 'Printing', 'Professional Education', 'Public Health', 'Publications', 'Quality of life', 'Range', 'Reading', 'Site', 'Structure', 'Structure of nail of finger', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Tigers', 'Time', 'Title', 'Today', 'Touch sensation', 'Training', 'Universities', 'Visual', 'Visually Impaired Persons', 'base', 'blind', 'braille', 'cost', 'desire', 'digital', 'disability', 'egg', 'interest', 'literate', 'print disabilities', 'programs', 'prototype', 'research and development', 'tool', 'touchpad', 'vector']",NEI,"VIEWPLUS TECHNOLOGIES, INC.",R43,2008,100001,-7.379976207951876e-05
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7477498,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2008,365248,0.0071573757550337826
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7351808,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Condition', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Range', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Models', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'concept', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2008,482736,0.018209250600776678
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7458835,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,503603,0.0031827271026316105
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7688793,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,58299,0.0031827271026316105
"MBRS IMSD Program at the University of Kansas    DESCRIPTION (provided by applicant):  Within the three short years since the University of Kansas (KU) IMSD program began, twelve minority students, including six American Indians, will have applied to graduate school. This is a continuation proposal to allow us to build on these successes. KU IMSD works in concert with other NIH funded programs (Bridge, RISE, IRACDA) and takes full advantage of the juxtaposition of a Research I Institution (KU) and one of the largest tribal colleges (Haskell Indian Nations University). KU IMSD consists of four components: 1) providing research experiences to American Indian and other minority students, with a particular a focus on recruiting Haskell students from the Bridge or RISE program; 2) enhancing and modifying the curriculum; 3) offering an interdisciplinary seminar series and 4) providing financial aid and mentoring. The undergraduate research experience takes a broad, interdisciplinary approach to placing students into one of 77 possible KU labs and includes opportunities for students to share their research results at local and national meetings. The program will also support several American Indian graduate students who have obtained BA's from Haskell. IMSD supported curricular enhancements that have shown remarkable results over the past three years will be continued for gatekeeper courses in biology, chemistry and math. In biology alone, the average grade point average of American Indian students who completed the introductory biology course has increased from 0.86 to 2.94 over the past six years. An integrative seminar series will bring together students from the IMSD, Bridge, and RISE programs to foster community and learning. Support from KU IMSD for undergraduate researchers will be a cornerstone in providing financial support along with KU scholarships targeted for American Indian students. Mentoring will be provided from faculty (research advisors), the IMSD Program Coordinator (individual and group meetings) and peers (other IMSD students). Evaluation and tracking procedures will allow for regular adjustment of activities during the course of the program and assessment of whether goals have been met. If funded for another four years, the KU/Haskell collaboration provides the opportunity to significantly impact the number of American Indian scientists in this country.         n/a",MBRS IMSD Program at the University of Kansas,7389728,R25GM062232,"['Address', 'Administrative Personnel', 'Administrator', 'Adopted', 'Advertising', 'Alaska', 'Algorithms', 'American Indians', 'Appendix', 'Area', 'Arrhythmia', 'Artificial Intelligence', 'Arts', 'Attention', 'Authorization documentation', 'Behavior', 'Behavioral Sciences', 'Biodiversity', 'Biogenesis', 'Bioinformatics', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Books', 'Bovine Spongiform Encephalopathy', 'Budgets', 'Calculi', 'Cells', 'Chaos Theory', 'Characteristics', 'Charge', 'Chemistry', 'Cities', 'Class', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Conservatism', 'Country', 'Coupled', 'DNA', 'DNA Structure', 'Daily', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Depth', 'Development', 'Discipline', 'Disease', 'Distant', 'Doctor of Philosophy', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Engineering', 'Enrollment', 'Environment', 'Equilibrium', 'Ethics', 'Evaluation', 'Event', 'Exercise', 'Exposure to', 'Faculty', 'Family', 'Feedback', 'Feeling', 'Fees', 'Film', 'Financial Support', 'Fostering', 'Foundations', 'Friends', 'Funding', 'Future', 'GYPA gene', 'Gatekeeping', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Glycophorin A', 'Goals', 'Grant', 'Graph', 'Group Meetings', 'Growth', 'Habits', 'Hand', 'Health', 'Health Sciences', 'Heart', 'Helix (Snails)', 'Home environment', 'Hour', 'Housing', 'Human', 'Human Resources', 'Humanities', 'Indigenous', 'Individual', 'Informatics', 'Information Systems', 'Institutes', 'Institution', 'Internet', 'Internships', 'Invasive', 'Journals', 'Judgment', 'Kansas', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Light', 'Link', 'Literature', 'Malignant Neoplasms', 'Mathematics', 'Medical', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Minority', 'Minority Groups', 'Modeling', 'Modems', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Monitor', 'Motivation', 'Museums', 'Music', 'Mutation', 'National Institute of General Medical Sciences', 'Natural History', 'Newsletter', 'Numbers', 'Oklahoma', 'Oral', 'Oral cavity', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Pamphlets', 'Paper', 'Parents', 'Participant', 'Performance', 'Personality', 'Pharmaceutical Chemistry', 'Placement', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Poverty', 'Preparation', 'Principal Investigator', 'Problem Solving', 'Procedures', 'Process', 'Productivity', 'Program Development', 'Progress Reports', 'Proteins', 'Published Comment', 'Purpose', 'Qualifying', 'Quantum Mechanics', 'RNA', 'Race', 'Radio', 'Range', 'Reading', 'Recommendation', 'Records', 'Recruitment Activity', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Review Committee', 'Rewards', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Selection Criteria', 'Series', 'Services', 'Shock', 'Site', 'Slide', 'Snow', 'Social Functioning', 'Source', 'Sports', 'Standards of Weights and Measures', 'Students', 'Supervision', 'Support Groups', 'Surveys', 'Techniques', 'Technology', 'Text', 'Textbooks', 'Thinking', 'Time', 'Time Management', 'Today', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Update', 'Ursidae Family', 'Visit', 'Visualization software', 'Wages', 'Week', 'Work', 'Writing', 'abstracting', 'aging nutrition', 'analytical method', 'base', 'biomedical scientist', 'career', 'cohort', 'college', 'computer generated', 'computer science', 'concept', 'cost', 'court', 'data acquisition', 'day', 'digital', 'ear helix', 'expectation', 'experience', 'falls', 'follow-up', 'gene therapy', 'high school', 'i(19)', 'image visualization', 'improved', 'instructor', 'interdisciplinary approach', 'interest', 'lectures', 'member', 'novel', 'peer', 'posters', 'preference', 'professor', 'programs', 'protein structure', 'role model', 'satisfaction', 'size', 'skills', 'success', 'symposium', 'theories', 'tool', 'tribal college']",NIGMS,UNIVERSITY OF KANSAS LAWRENCE,R25,2008,373102,0.000704709849954295
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,-0.012286561174123424
"Machine Learning Applied to Automated Planar Patch Clamps    DESCRIPTION (provided by applicant): The introduction of automated planar patch clamp instruments over the past two years has increased the throughput of voltage clamp ion channel assays by a factor of at least ten. This is possible because the automated systems can perform assays in parallel using16 and 384-well plates. While the drug discovery industry has embraced this new technology, the enthusiasm has been tempered by the modest success rates of the assays and by the high cost of the consumable patch substrate. Currently, typical success rates for a standard ion channel assay, using, for example, the Q-Patch from Sophion Biosciences, the Port-a-Patch system from Nanion Biosciences, or the PatchXpress from Molecular Devices Corp., is around 50%. In other words, for every16 channel chip used in these systems, only eight will produce useable data. This effectively doubles the price of each data point over what is ideally possible. In order for a planar patch clamp experiment to succeed, several events need to occur (assuming that the cell expresses the appropriate ion channels in functional states): the cell of interest must form a high-resistance seal with the planar substrate, the whole-cell configuration must be achieved, and fluidic pathways must be intact so that compounds of interest maybe applied to the cell. A failure of anyone of these steps will result in no data collected from that well. We propose to optimize the first two steps in this process, namely, seal formation and entry into whole-cell recording configuration. We will use machine learning approaches to examine how a human patch clamp expert interacts with the patch clamp system in order to develop a model that will provide parameters that can be used to more efficiently and successfully provide useable whole-cell recording configuration. It is important to note that the model that we derive from our approach will not actually copy what the expert does, but will attempt to optimize the process based on cues that mayor may not be consciously monitored by the expert. The Specific Aims of the Phase I component will be to: (1) integrate recording capabilities into existing automated patch clamp software from Nanion, (2) evaluate the success rate of the procedure specified by our machine learning analysis, and (3) develop stand-alone software for use specifically with manual patch clamp setups and for exploration of the potential benefits of using machine learning via expert training in other applications. In Phase II we propose to develop the proof-of-concept software into a user-friendly commercial software module which we will offer to existing and potential automated patch clamp companies. We will also simplify and streamline the user interface of this software as a stand-alone component for manual patch clamp systems. Developing drugs that target ion channels has been hindered by the expense of the consumables used in automated patch clamp screening devices. We propose to develop a method, using machine learning techniques which may increase the success rate of these instruments and therefore lower the overall cost of ion channel drug discovery.          n/a",Machine Learning Applied to Automated Planar Patch Clamps,7220448,R43EB007148,"['Biological Assay', 'Cells', 'Chemistry', 'Computer software', 'Condition', 'Cues', 'Data', 'Devices', 'Drug Delivery Systems', 'Employee Strikes', 'Event', 'Failure', 'Goals', 'Housing', 'Human', 'Industry', 'Ion Channel', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Pathway interactions', 'Performance', 'Phase', 'Price', 'Procedures', 'Process', 'Programmed Learning', 'Protocols documentation', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Running', 'Sales', 'Scientist', 'Screening procedure', 'Software Engineering', 'Solutions', 'Specific qualifier value', 'Spottings', 'Standards of Weights and Measures', 'Suction', 'Surface', 'System', 'Techniques', 'Testing', 'Training', 'Visual', 'Whole-Cell Recordings', 'Work', 'Writing', 'base', 'cell type', 'concept', 'cost', 'drug discovery', 'improved', 'instrument', 'interest', 'new technology', 'patch clamp', 'programs', 'research study', 'seal', 'success', 'tool', 'user-friendly', 'voltage', 'voltage clamp']",NIBIB,BLATZ SCIENTIFIC,R43,2007,199389,-0.04051847602109897
"Computer Vision Methods for the Real Time Assessment of Dietary Intake    DESCRIPTION (provided by applicant): Obesity is a leading cause of preventable death and disability in the U.S. Self- monitoring of all foods and beverages consumed is central to weight loss and maintenance efforts; however, this places a heavy burden on the user. These same burdens also impede nutritional research. The proposed research is for the testing of a semi-automated, objective, near real-time computer vision and pattern recognition approach to the measurement of dietary intake. In the proposed product, cell phone pictures of meals and snacks will be analyzed by software in an attempt to automatically recognize as many items as possible. A small number of intelligent yes/no questions will help provide additional information when necessary in order to meet the accuracy demands of the target application. Following identification of the items, the software will estimate the portion sizes of all identified items. The experiments comprising this Phase I SBIR are (a) extract the most informative sets of features using a large number of food and beverage items taken from an existing database of real world meal images, (b) compare the accuracy of candidate pattern recognition approaches to identify items based on the extracted features, (c) identify the most feasible algorithms for estimating portion size, and (d) test usability and user acceptance with a simulated version of the product. Phase II will (a) apply the approach to a greater variety of food and beverage items, (b) improve automated analysis, and (c) compare the approach to existing assessment instruments. This research will extend defense- and security-related technologies to the assessment and treatment of obesity.          n/a",Computer Vision Methods for the Real Time Assessment of Dietary Intake,7405586,R43CA124265,"['Address', 'Adherence', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Biometry', 'Body Weight decreased', 'Calculi', 'Cellular Phone', 'Cessation of life', 'Class', 'Coin', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Decision Trees', 'Diabetic Diet', 'Diet Records', 'Dietary intake', 'Disease', 'Eating', 'Eating Behavior', 'Face', 'Feedback', 'Fingerprint', 'Food', 'Food and Beverages', 'Goals', 'Habits', 'Health', 'Image', 'Individual', 'Information Theory', 'Intake', 'Iris', 'Life', 'Life Style', 'Lighting', 'Machine Learning', 'Maintenance', 'Marketing', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Numbers', 'Nutritional', 'Nutritionist', 'Obesity', 'Obesity associated disease', 'Pattern Recognition', 'Phase', 'Placement', 'Principal Investigator', 'Public Health', 'Research', 'Research Personnel', 'Security', 'Shapes', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Three-Dimensional Image', 'Time', 'Training', 'Treatment Protocols', 'United States', 'Wing', 'base', 'design', 'digital imaging', 'disability', 'improved', 'innovation', 'instrument', 'interest', 'obesity treatment', 'research study', 'size', 'usability']",NCI,"MEDIABALANCE, INC.",R43,2007,191710,0.006453389290745706
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7220194,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2007,366168,0.011880856402395305
"A Non-invasive Single-trial In-vivo Neuroimaging System    DESCRIPTION (provided by applicant):    The overall goal of this project is to develop an integrated single-trial system for neuroimaging which combines high-density electroencephalography (EEG) with simultaneous functional magnetic resonance imaging (fMRI), and to use this system to investigate variability in neural processing. The high-temporal resolution of EEG will enable the detection of signal variability in single-trial events, and this information will be used as the input function for analysis of simultaneously acquired event-related fMRI (efMRl). We hypothesize that using single-trial EEG derived regressors for efMRI (stEEG/fMRI) will yield high spatial and high temporal resolution information about the functional neuroanatomy involved in cognitive processing. This will enable construction of unique EEG derived tMRI activation maps which are not based on pre-defined labels or observed behavioral responses but rather on task and subject specific electrophysiological source variability. The broad impact of this work will be development of a new non-invasive imaging system (stEEG/fMRI) for the cognitive neurosciences as well as a clinical tool for diagnosis and monitoring of a broad spectrum of neurological diseases. The R21 effort focuses on development of a high density (64 channels) EEG/fMRI integrated system for single-trial analysis, and characterization of possible differences between the EEG recorded in an MR environment and that recorded in a standard environment. The R33 will then demonstrate the use of stEEG/fMRI in a pilot study of cognitive aging. R21Aims: 1. Develop an in-magnet 64 channel EEG system for single-trial analysis of event-related potentials recorded concurrently with fMRI. 2. Assess the quality of EEG collected inside the MR scanner compared to that collected in a shielded EEG room, using a series of predefined protocols for characterizing the effects of the auditory and magnetic environments on EEG and ERP wave forms. 3. Validate that EEG recorded simultaneously with fMRI is of a high enough quality to detect task relevant single-trial signatures using supervised machine learning. R33 Aims: 1.Use single-trial EEG-derived regressors, constructed via supervised machine learning, to construct efMRI activation maps (stEEG/fMRI activation maps) for auditory oddball and Eriksen flanker tasks. 2.Use alpha power as a complementary regressor within stEEG/fMRI for capturing additional single-trial variance in the hemodynamic response. 3.Demonstrate that stEEG/tMRI activations maps yield new information for discriminating young and old adult populations, as compared to traditional efMRI and P3 and ERN ERP analysis. n/a",A Non-invasive Single-trial In-vivo Neuroimaging System,7274139,R33EB004730,"['Auditory', 'Behavioral', 'Clinical', 'Cognitive', 'Cognitive aging', 'Detection', 'Development', 'Diagnosis', 'Elderly', 'Electroencephalography', 'Environment', 'Event', 'Event-Related Potentials', 'Facility Construction Funding Category', 'Functional Magnetic Resonance Imaging', 'Goals', 'Image', 'Invasive', 'Label', 'Machine Learning', 'Magnetism', 'Maps', 'Monitor', 'Neuroanatomy', 'Pilot Projects', 'Population', 'Process', 'Protocols documentation', 'Resolution', 'Series', 'Signal Transduction', 'Source', 'Standards of Weights and Measures', 'System', 'Work', 'base', 'cognitive neuroscience', 'density', 'hemodynamics', 'in vivo', 'nervous system disorder', 'neuroimaging', 'relating to nervous system', 'response', 'tool']",NIBIB,COLUMBIA UNIV NEW YORK MORNINGSIDE,R33,2007,432581,0.005127368052458386
"A RuleFit Product for Classification and Regression Prediction and data exploration are important aspects of modern commercial and scientific life. Regression methods predict dependent variables (e.g., tumor growth, severity of disease), while classification methods predict class membership (e.g., tumor or disease type). Both use a vector of independent variables to make the predictions. Because they are often superior predictors, can handle large numbers observations and large numbers of variables, can often yield insight into the data not provided by other methods, and because they can adapt to arbitrarily complex relationships, modern machine learning methods based on tree ensembles such as RANDOM FORESTS and MART have become leading modern analytical methods. Here we propose to commercially implement RULEFIT, a recent innovative method extending the RANDOM FORESTS and MART approaches, that shows strong evidence of being consistently more accurate than either ensemble. RULEFIT also includes groundbreaking new methods for variable selection in the face of huge numbers of predictors, and for identifying interactions, and ranking their importance. Optionally, RULEFIT extracts ""rules"" of special interest: succinct statements of conditions under which an outcome is especially likely or unlikely, or especially large or small. The primary output of RULEFIT is a numeric value reecting a prediction of the value of the dependent variable or the probability of a class membership. RULEFIT is likely to become a leading technique in the machine learning and statistics. It builds on RANDOM FORESTS and MART and includes all their useful benefits such as variable selection, data exploration, data reduction, outlier detection, and missing value imputation, while enhancing and extending these benefits.  COMMERCIAL POTENTIAL The market for advanced analytical tools has been growing strongly over the last decade and the growth shows no signs of diminishing. Modelers and data analysts in both university- based and commercial settings are increasingly aware of the power and value of new analytical tools derived from modern statistics and machine learning research. The increased accuracy of the new methods and the acceleration they provide to the analysis of complex data are fueling demand for this new technology. The advances embedded in the proposed product represent substantial improvements to existing technology and include methods to solve vexing problems in contemporary data analysis, and thus should find a welcoming market.  There are further reasons to forecast robust commercial potential for this product. The applicant organization has a strong track record in the industry and is widely recognized as a developer of high quality software. We have been working with consultant Friedman since 1990 and have gained exclusive rights to the proprietary sourcecode for a number of his innovations. These include CART, MARS, MART and PRIM. With the addition of RULEFIT and its associated sub-components, these products represent a unique collection of pedigreed tools. We have also forged a similar relationship with the (late) Leo Breiman and have the exclusive rights to commercialization of Breiman's Random Forests sourcecode. Our proposed package thus occupies a distinctive position in machine learning software which cannot be replicated by other vendors. Keywords: machine learning; classi?cation; prediction; supervised learning; variable importance; inter- action detection; Justi?cation Dr. Steinberg has extensive experience in software development for advanced statistical and machine learning methods, particularly in the area of classi?cation and regression trees, sur- vival analysis, adaptive modeling, RANDOM FORESTS and MART. He will oversee all aspects of the project. He will will work with Dr. Cardell, Professor Friedman, Mr. Colla, and with the Salford Systems software development engineer in creating and studying the software and methods used in this proposal. He will also be responsible for the architecture of the Phase I software. Professor Friedman and Dr. Cardell will provide technical support as follows: Dr. Fried- man is an expert on machine learning methods and is one of the developers of the RULEFIT technique. Regular consultation with him will be in this area. Dr. Cardell is an expert in asymptotic theory, and in the design of Monte Carlo and other tests for the evaluation of ma- chine learning algorithms. He also has extensive experience in machine learning, including adaptive modeling, neural networks, logistic regression, and classi?cation methods. He will review core algorithms of RULEFIT for possible improvement and extension and design the Monte Carlo tests. Mr. Colla has extensive experience in software development and with machine learning methods, including work on the commercial implementations of CART, MARS, RANDOM FORESTS, and MART. Working with Dr. Cardell, he will be responsible for much of the new software coding. 5 Project Description Page 7 Principal Investigator/Program Director (Last, first, middle): Steinberg, Dan Prediction models based upon classification and regression tree ensembles have become important in medical and other research. There are currently no commercial products available that implement the proposed RuleFit methodology. These methods have significant advantages over existing techniques, and will aid researchers in obtaining the best possible predictions.   n/a",A RuleFit Product for Classification and Regression,7268612,R43CA124294,"['Acceleration', 'Agreement', 'Algorithms', 'Architecture', 'Area', 'Beds', 'Build-it', 'Cations', 'Class', 'Classification', 'Code', 'Collection', 'Comparative Study', 'Complex', 'Computer software', 'Condition', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Detection', 'Disease', 'Disease regression', 'Engineering', 'Evaluation', 'Face', 'Generations', 'Growth', 'Industry', 'Information Systems', 'Investigation', 'Learning', 'Left', 'Life', 'Linear Models', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Neural Network Simulation', 'Numbers', 'Outcome', 'Output', 'Painless', 'Pattern', 'Performance', 'Phase', 'Plant Leaves', 'Play', 'Positioning Attribute', 'Principal Investigator', 'Probability', 'Rate', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Rights', 'Role', 'Sampling', 'Severity of illness', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Trees', 'Universities', 'Variant', 'Vendor', 'Work', 'analytical method', 'analytical tool', 'base', 'commercialization', 'data mining', 'data structure', 'design', 'evaluation/testing', 'experience', 'forest', 'forging', 'graphical user interface', 'innovation', 'insight', 'interest', 'loss of function', 'man', 'new technology', 'novel', 'professor', 'programs', 'prototype', 'relating to nervous system', 'research study', 'software development', 'statistics', 'theories', 'tool', 'tumor', 'tumor growth', 'vector']",NCI,SALFORD SYSTEMS,R43,2007,91700,0.0028160519290470524
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7172503,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2007,1159531,0.012604180852127576
"The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments    DESCRIPTION (provided by applicant): The goal of this research is to create software that uses mathematical algorithms to detect medical billing coding errors prior to payment. The well-publicized failure of current healthcare cost containment technologies to prevent improper payments in both the commercial healthcare market and the federal Medicare program highlights the urgent need for a new approach to the growing problem of out of control medical costs. A recent federal study by the GAO estimated that improper payments by Medicare alone were in excess of 21 billion dollars, a truly staggering 48.1 percent of all improper payments by federal programs. Like SPAM, whose dynamic nature makes static or post hoc remedies ineffective, effective cost containment in one area often merely leads to the creation of new areas of abuse. Clearly, the ideal solution is a system that can evaluate the fairness of payments before they are made, and that can respond to dynamic patterns of abuse. The first step in creating such a system is the creation of robust method for sorting bills for appropriate rule-based analysis on the basis of the type of bill. Currently neither Medicare nor major insurers are capable of making this classification reliably except through the use of inefficient, static rules and the use of manual sorting--a costly and inefficient approach to assuring timely payment to hospitals and medical providers. We propose a novel method for using mathematical algorithms that utilize machine-learning (ML) methods to address the problem of medical bill categorization, the first step in coding error detection. Specifically, we propose the evaluation of a variety of genetic algorithms that are well adapted to the problems of large, dynamic datasets and can be ""trained"" using real world correctly coded datasets in healthcare claims. This work is particularly timely due to recent Medicare contracting reform. Using more than 50 contractors and carriers, bill classification is largely determined by the carrier's contract. Centralizing this process to only four payment centers will require the classification system we propose. [This research is directed toward the development of software applications that will detect billing errors and perform proper edits to payment of medical bills. Current anticipated changes and reforms in the Medicare system will require these systems, which do not currently exist in the public or private sector.]             n/a",The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments,7316071,R43LM009190,"['Address', 'Age', 'Algorithms', 'Area', 'Arts', 'Classification', 'Code', 'Collaborations', 'Computer Simulation', 'Computer software', 'Contractor', 'Contracts', 'Cost Control', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Development', 'Elements', 'Environment', 'Evaluation', 'Failure', 'Genetic Programming', 'Goals', 'Health Care Costs', 'Health Care Fraud', 'Health Personnel', 'Healthcare', 'Healthcare Market', 'Healthcare Systems', 'Hospitals', 'Industry', 'Inpatients', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Manuals', 'Mathematics', 'Medical', 'Medicare', 'Methods', 'Mining', 'Modeling', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Pattern', 'Phase', 'Policies', 'Population', 'Prevention', 'Private Sector', 'Process', 'Provider', 'Rate', 'Reporting', 'Research', 'Running', 'Small Business Technology Transfer Research', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Training', 'Work', 'base', 'college', 'computerized', 'cost', 'design', 'experience', 'improved', 'mathematical algorithm', 'novel', 'novel strategies', 'payment', 'prevent', 'programs', 'size', 'software development', 'stem', 'success']",NLM,"QMEDTRIX SYSTEMS, INC.",R43,2007,92482,-0.01544498365833692
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7246847,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2007,2183988,-0.0003884512278637026
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7275769,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Range', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'concept', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2007,51278,-0.01156334191196503
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7318595,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2007,372000,-0.0013164102094096115
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7293650,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Class', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Numbers', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Range', 'Reader', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'size', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web-accessible']",NHGRI,FRED HUTCHINSON CAN RES CTR,P41,2007,796910,0.00409538317088695
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7189144,K12MH069281,"['Anatomy', 'Area', 'Artificial Intelligence', 'Base of the Brain', 'Biomedical Engineering', 'Biomedical Informatics Research Network', 'Brain', 'Brain imaging', 'Caliber', 'Class', 'Clinical', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Development', 'Discipline', 'Educational Activities', 'Exposure to', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Laboratories', 'Mentored Research Scientist Development Award', 'Mentors', 'Methodology', 'Monitor', 'Neurosciences', 'Numbers', 'Operative Surgical Procedures', 'Physicians', 'Procedures', 'Program Development', 'Psyche structure', 'Range', 'Rate', 'Recruitment Activity', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'SECTM1 gene', 'Science', 'Scientist', 'Surface', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Woman', 'base', 'bioimaging', 'biomedical informatics', 'brain morphology', 'career', 'cationic antimicrobial protein CAP 37', 'clinical application', 'cognitive neuroscience', 'computer science', 'imaging informatics', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'post-doctoral training', 'programs', 'research and development', 'response', 'skills']",NIMH,MASSACHUSETTS GENERAL HOSP,K12,2007,450967,-0.004454288859620078
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7269383,R01RR014477,[' '],NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2007,307022,-0.02901468470770454
"Comparative Visualization and Analysis for GCxGC    DESCRIPTION (provided by applicant): Project Summary. This project will investigate and develop effective information technologies for comparative analysis and visualization of complex data generated by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is an emerging technology that provides an order-of-magnitude greater separation capacity, significantly better signal-to-noise ratio, and higher dimensional retention-structure relations than traditional GC. The principal challenge for utilization of GCxGC, in a wide range of public-health and other applications, is the difficulty of analyzing and interpreting the large, complex data it generates. The quantity and complexity of GCxGC data necessitates the investigation and development of new information technologies. This project will develop and demonstrate innovative methods and tools for comparative analysis of GCxGC datasets. The expected results of this research and development include a PCA-based method for chemical fingerprinting, decision trees with chemical constraints for sample classification, genetic programming for template and constraint-based matching and classification, and visualization methods for comparative GCxGC analyses. These methods will be implemented in commercial software that will support researchers and laboratory analysts in a wide range of commercial applications, including health care, environmental monitoring, and chemical processing. The power of GCxGC, supported by effective information technologies, will enable better understanding of chemical compositions and processes, a foundation for future scientific advances and discoveries. Relevance to Public Health. Today, a few advanced laboratories are pioneering GCxGC for a variety of applications such as environmental monitoring of exposure profiles in air, soil, food, and water; identification and quantification of toxic products in blood, urine, milk, and breath samples; and qualitative and quantitative metabolomics to provide a holistic view of the biochemical status or biochemical phenotype of an organism. Many analyses in these applications require detailed chemical comparisons of samples, e.g..monitoring changes, comparison to reference standards, chemical matching or ""fingerprinting"", and classification. GCxGC is a powerful new technology for such comparative analyses. This proposal will provide innovative information technologies to support users in these applications.           n/a",Comparative Visualization and Analysis for GCxGC,7270029,R44RR020256,"['Air', 'Archives', 'Biochemical', 'Blood', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Trees', 'Development', 'Emerging Technologies', 'Environmental Monitoring', 'Fingerprint', 'Food', 'Foundations', 'Future', 'Gas Chromatography', 'Genetic Programming', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Information Technology', 'Investigation', 'Laboratories', 'Language', 'Machine Learning', 'Marketing', 'Methods', 'Milk', 'Monitor', 'Noise', 'Organism', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Process', 'Public Health', 'Range', 'Reference Standards', 'Reporting', 'Research Personnel', 'Sales', 'Sampling', 'Schedule', 'Scientific Advances and Accomplishments', 'Signal Transduction', 'Software Tools', 'Soil', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Today', 'Trademark', 'Urine', 'Water', 'base', 'chemical fingerprinting', 'commercial application', 'comparative', 'innovation', 'innovative technologies', 'instrument', 'metabolomics', 'new technology', 'research and development', 'tool', 'two-dimensional']",NCRR,"GC IMAGE, LLC",R44,2007,239373,-0.0026878249651116795
"Developing computerized tools for cryosurgery planning    DESCRIPTION (provided by applicant):    Cryosurgery has been known as an invasive surgical technique since 1961, when Cooper and Lee invented the first cryoprobe. In the 1990s, new developments in Joule-Thomson cooling (the cooling effect associated with a sudden relief of a pressurized gas) led to a dramatic decrease in the size of cryoprobes and an increase in the number of cryoprobes that could be used simultaneously. A dozen or more cryoprobes operating simultaneously in a single prostate cryosurgery is already common practice. If localized effectively, one of the primary benefits of using a large number of miniaturized cryoprobes is superior control over the freezing process.   Currently, the process of selecting the correct placement of the cryoprobes for a specific procedure is an art held by the cryosurgeon, based on the surgeon's own experience and rules of thumb. Cryoprobes are typically operated in a trial-and-error fashion, until the entire target volume is thought to be frozen. Currently, there are no means to determine the optimal locations for the cryoprobes. Suboptimal cryoprobe localization may leave regions in the target volume unfrozen, may lead to cryoinjury of healthy surrounding tissues, may require an unnecessarily large number of cryoprobes, may increase the duration of the surgical procedure, and may increase the likelihood of post cryosurgery complications, all of which affect the quality and cost of the medical treatment. Computerized planning tools would help to alleviate these difficulties.   The ""cryoheater,"" a new device for cryosurgery control has recently been presented by the research team. The cryoheater is a temperature controlled electrical heater. In broad terms, cryoheaters can dramatically increase the ability to control the shape and size of the frozen region, however, to achieve the full benefits of cryoheaters, computerized planning tools for cryoheater localization are necessary.   Our goal is to develop computerized planning tools for cryosurgery that are suitable for all available cooling techniques. The proposed research includes: (1) Development of an efficient numerical scheme for bioheat transfer simulations of cyroprocedures, (2) Development of an efficient optimization technique based on a force-field analogy. (3) Development of knowledge-based optimization techniques. (4) Experimental verification of the planning tool.       Besides planning, another important application of the proposed tool is the training of cryosurgeons. The proposed tool will provide cryosurgeons with the ability to visualize the 3D volumetric nature of the freezing process.   Likewise, it will allow the surgeon to explore the performance of various configurations of cryoprobes and cryoheaters, and observe the defects that would result from each. Such visualization capabilities will provide surgeons with insights into the physics of cryosurgery that are difficult to obtain from physical experiments or surgical practice.         n/a",Developing computerized tools for cryosurgery planning,7210691,R01EB003563,"['Affect', 'Arts', 'Biological', 'Catheters', 'Computational Technique', 'Condition', 'Cool-X-A', 'Cryosurgery', 'Defect', 'Depth', 'Development', 'Devices', 'Europe', 'Feasibility Studies', 'Freezing', 'Frequencies', 'Furuncles', 'Gases', 'Goals', 'Heating', 'Imagery', 'Imaging Device', 'Invasive', 'Lasers', 'Lead', 'Learning', 'Left', 'Liquid substance', 'Localized', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modems', 'Nature', 'Nitrogen', 'Numbers', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Physics', 'Placement', 'Procedures', 'Process', 'Prostate', 'Publishing', 'Purpose', 'Radio', 'Reporting', 'Research', 'Research Proposals', 'Scheme', 'Shapes', 'Simulate', 'Solutions', 'Source', 'Surgeon', 'Techniques', 'Temperature', 'Thermal Ablation Therapy', 'Thinking', 'Thumb structure', 'Time', 'Tissues', 'Training', 'Ultrasonography', 'Urethra', 'base', 'clinical application', 'computerized', 'computerized tools', 'cost', 'experience', 'insight', 'knowledge base', 'miniaturize', 'research study', 'simulation', 'size', 'thermal seeds', 'three-dimensional modeling', 'tool']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2007,87443,-0.013493705819391187
"Brain abnormality in unaffected family members of schizophrenic patients    DESCRIPTION (provided by applicant): This R03 proposal aims at developing a methodological framework for nonlinear multivariate analysis, using a non-linear pattern classification method, to identify and quantify subtle and spatially-complex brain abnormalities in unaffected family members of schizophrenia patients. Compared to conventional methods based on regions of interest (ROI) that rely only on a few pre-selected manually-labeled ROIs, this automated method will consider all brain regions simultaneously for identification of complex patterns of brain abnormality that cannot be necessarily summarized by a few pre-defined ROIs. Accordingly, a major methodological challenge to be addressed in this project is the development of statistical image analysis and data mining methods for estimating the collection of brain regions or networks that jointly form patterns to characterize schizophrenia as uniquely as possible. Patterns determined by comparison of confirmed schizophrenia patients and healthy controls will be examined on unaffected family members of patients, to test whether individuals that are genetically related to patients display, to some extent, endophenotypes of schizophrenia. Also, unaffected family members will be further compared with patients to identify the morphological profiles that seem directly associated with the phenotype of schizophrenia. The performance of the proposed nonlinear pattern analysis and classification method will be tested on an existing schizophrenia dataset in the Schizophrenia Research Center at the University of Pennsylvania. Although not an immediate goal of this specific proposal, the long-term objective of the proposed work is to apply this automated methodology to various studies, including (1) a large-scale genetic study of schizophrenia involving informative samples, in order to examine questions that cannot be addressed with conventional ROI-based analysis; (2) the quantification and recognition of endophenotypes of schizophrenia in unaffected individuals, which can potentially pave the way for the detection of adolescents that possess brain endophenotypes that put them at risk; (3) clinical studies investigating the added value of quantifying endophenotypes of schizophrenia for clinical diagnosis, especially in difficult cases or outside environments with well-trained psychiatrists, in which unbiased computer-based methods can potentially greatly assist in clinical evaluation and diagnosis.           n/a",Brain abnormality in unaffected family members of schizophrenic patients,7195436,R03MH076970,"['Address', 'Adolescent', 'Adoption', 'Affect', 'Brain', 'Brain imaging', 'Brain region', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computers', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Environment', 'Family member', 'First Degree Relative', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Hand', 'Image Analysis', 'Individual', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medial', 'Methodology', 'Methods', 'Multivariate Analysis', 'Neuroanatomy', 'Patient Education', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phenotype', 'Play', 'Psychiatrist', 'Relative Risks', 'Research', 'Risk', 'Role', 'Sampling', 'Schizophrenia', 'Structure', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Universities', 'Work', 'base', 'clinical Diagnosis', 'data mining', 'endophenotype', 'gray matter', 'interest', 'lateral ventricle', 'member', 'research clinical testing']",NIMH,UNIVERSITY OF PENNSYLVANIA,R03,2007,78604,0.0018398036270865436
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7287965,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,446875,-0.0049778011370379925
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7194202,R01EY015888,"['Agnosia', 'Area', 'Awareness', 'Color', 'Communication', 'Computer Vision Systems', 'Condition', 'Conscious', 'Cues', 'Development', 'Disease', 'Distant', 'Dyslexia', 'Elements', 'Goals', 'Grouping', 'Image', 'Lateral', 'Lead', 'Literature', 'Location', 'Measurable', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Nature', 'Neighborhoods', 'Paint', 'Perception', 'Process', 'Rate', 'Research', 'Research Personnel', 'Source', 'Staging', 'Stimulus', 'Structure', 'Textbooks', 'Texture', 'Time', 'Vision', 'Visual', 'Visual Fields', 'Visual system structure', 'base', 'design', 'interest', 'millisecond', 'neurophysiology', 'novel', 'perceptual organization', 'receptive field', 'relating to nervous system', 'research study', 'visual process', 'visual processing']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2007,216928,-0.009945510525407934
The RPI Exploratory Center for Cheminformatics (RMI) No abstract available n/a,The RPI Exploratory Center for Cheminformatics (RMI),7472067,P20HG003899,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2007,364010,0.002652650185531963
Carolina Exploratory Center for Cheminformatics Research No abstract available n/a,Carolina Exploratory Center for Cheminformatics Research,7472715,P20HG003898,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,P20,2007,373960,0.002652650185531963
MACE - Michigan Alliance for Cheminformatic Exploration No abstract available n/a,MACE - Michigan Alliance for Cheminformatic Exploration,7472717,P20HG003890,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Michigan', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIVERSITY OF MICHIGAN,P20,2007,271370,0.007077287803927043
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7151198,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2007,471644,-0.013205139526685493
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7295688,R21EY017003,"['Access to Information', 'Address', 'Algorithms', 'Auditory', 'Bar Codes', 'Canes', 'Canis familiaris', 'Cellular Phone', 'Clutterings', 'Cognitive', 'Color', 'Complement component C1s', 'Computer Vision Systems', 'Computer software', 'Condition', 'Consultations', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Elderly', 'Employment', 'Environment', 'Exhibits', 'Feedback', 'Future', 'Goals', 'Home environment', 'Housing', 'Image', 'Individual', 'Instruction', 'Label', 'Localized', 'Location', 'Modality', 'Museums', 'Paper', 'Pattern', 'Persons', 'Population', 'Printing', 'Psychoacoustics', 'Quality of life', 'Range', 'Rate', 'Reading', 'Research', 'Running', 'Scanning', 'Semantics', 'Shapes', 'Source', 'Speech', 'Standards of Weights and Measures', 'Stress', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'age group', 'base', 'blind', 'braille', 'concept', 'cost', 'design', 'interest', 'legally blind', 'meter', 'novel', 'optical character recognition', 'programs', 'prototype', 'research study', 'size', 'skills', 'sound', 'success', 'symposium', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2007,193398,0.009585850728603483
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to build and test a ""Smart Telescope,"" a device for persons with low vision that uses computer vision algorithms to search for, detect and enhance targets such as text and faces to aid in everyday tasks such as travel, navigation and social interactions. The practical, cosmetically acceptable packaging will consist of a miniature camera and visual display discreetly mounted on spectacles or a hat, and a compact computing device and set of controls that fit into a pocket. The Smart Telescope advances today's state of the art in assistive devices for low vision by automatically searching for, detecting and enhancing target objects even when they fill only a small portion of the device's field of view, without the user having to point the device directly or accurately at the target as with optical telescopes. The Smart Telescope is small and lightweight, but large enough for the elderly to handle and control; simple to operate and easy to carry, store, recharge, don and remove. Advanced options are hidden during day-to-day use, but easy to access when necessary. In Phase I, we developed and evaluated a working prototype and received enthusiastic feedback from subjects in our target population. In Phase II we propose to prototype a commercially viable consumer version of the Smart Telescope. The Phase II work plan has four tracks: 1) User interaction and interface design, 2) physical design and configuration, 3) software design and development, and 4) hardware design and development. Smith-Kettlewell's Rehabilitation Engineering Research Center (RERC) will provide expertise for the human factors portions of the project. Blindsight will design and build the device hardware from off-the-shelf components with the help of Bolton Engineering. Low vision experts Drs. Don Fletcher, Melissa Chun and Ian Bailey will work with the RERC to guarantee a practical product for the target audience. The overall aim is to create a commercial version of the proposed device for persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems, increasing mobility and independence for those with acuity between approximately 20/200 and 20/600. At under $1,000, the total market for such a device is estimated at up to 300,000, i.e., 10% of low vision persons in the United States. The commercial version of the Smart Telescope will significantly increase mobility and independence for persons with visual acuity between approximately 20/200 and 20/600, aiding them in everyday tasks such as travel, navigation, and social interactions. It will advance today's state of the art in assistive devices for low vision by improving on and surpassing the capabilities of the traditional optical telescope, greatly benefiting persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems.          n/a",A Smart Telescope for Low Vision,7327116,R44EY014487,"['Algorithms', 'Arts', 'Back', 'Cataract', 'Clutterings', 'Computer Vision Systems', 'Contrast Sensitivity', 'Development', 'Devices', 'Diabetic Retinopathy', 'Elderly', 'Engineering', 'Eye', 'Eyeglasses', 'Face', 'Feedback', 'Glaucoma', 'Human', 'Lighting', 'Location', 'Macular degeneration', 'Marketing', 'Melissa', 'Motion', 'Optics', 'Peripheral', 'Persons', 'Phase', 'Reading', 'Research', 'Self-Help Devices', 'Social Interaction', 'Software Design', 'Target Populations', 'Testing', 'Text', 'Today', 'Travel', 'United States', 'Vision', 'Visual', 'Visual Acuity', 'Visual impairment', 'Work', 'day', 'design', 'improved', 'low vision telescope', 'monocular', 'prototype', 'rehabilitation engineering']",NEI,BLINDSIGHT CORPORATION,R44,2007,448477,0.019908784823263033
"Generation and Description of Dendritic Morphology    DESCRIPTION (provided by applicant): This continuing project is directed at describing dendrite structure in a compact yet sufficiently complete and detailed fashion to allow the computer generation of morphologically accurate neuronal models. Dendrite morphology plays a fundamental role in physiological and pathological brain function by subserving and shaping network connectivity and by integrating the complex pattern of synaptic inputs received by the neuron. A parsimonious and algorithmic description of dendritic shape is a crucial step towards the quantitative characterization of the structure-activity relationship in the nervous system and it constitutes an effective way to represent, compress, store, exchange, and amplify extremely complex neuroanatomical data. Neuroanatomical algorithms and models have been developed to simulate and quantitatively analyze the three-dimensional structure of dendritic trees in the same format used to represent experimentally reconstructed neurons.      The specific aims of this project are: (1) to expand and improve neuroanatomically plausible algorithms of dendritic structure and development by including determinants of three-dimensional branch orientation and dependence of growth upon local and global influences (e.g. diameter and neuronal size, respectively); (2) to enhance and distribute the analysis, modeling, and data basing software in order to provide experimental and computational neuroscientists with web-based tools to query, retrieve, measure, classify, and synthesize dendritic morphology data; (3) to continue the experimental reconstruction and analysis of hippocampal pyramidal cells and spinal motoneurons with different experimental protocols and in early postnatal periods; and to integrate these data with detailed biophysical models of neuronal electrophysiology. The informatics and neuroscience components of this research are deeply intertwined and span a variety of scientific approaches, including ""wet"" experiments, computational simulations, statistical analysis and data mining. This will require the design and implementation of novel neuroinformatics tools for data handling and integration, and their distribution to the wider neuroscience community.         n/a",Generation and Description of Dendritic Morphology,7233290,R01NS039600,"['Algorithms', 'Archives', 'Atlases', 'Brain', 'Caliber', 'Cells', 'Class', 'Classification', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Developmental Process', 'Electrophysiology (science)', 'Environment', 'Generations', 'Goals', 'Growth', 'Hippocampus (Brain)', 'Image', 'Imagery', 'Informatics', 'Internet', 'Java', 'Lead', 'Length', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Microscopic', 'Mining', 'Modeling', 'Morphology', 'Motor Neurons', 'Neonatal', 'Nervous system structure', 'Neurons', 'Neurosciences', 'One-Step dentin bonding system', 'Online Systems', 'Pattern', 'Physiological', 'Play', 'Protocols documentation', 'Pyramidal Cells', 'Research', 'Research Personnel', 'Research Proposals', 'Role', 'Series', 'Shapes', 'Simulate', 'Software Tools', 'Spinal', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Synapses', 'System', 'Techniques', 'Trees', 'data mining', 'data modeling', 'density', 'design', 'digital', 'improved', 'insight', 'models and simulation', 'neuroinformatics', 'novel', 'postnatal', 'programs', 'reconstruction', 'research study', 'simulation', 'size', 'software development', 'three dimensional structure', 'three-dimensional modeling', 'tool', 'user-friendly', 'virtual']",NINDS,GEORGE MASON UNIVERSITY,R01,2007,61912,-0.008999904411042767
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7125319,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic Models', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Localized', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Range', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'USA Georgia', 'Western Asia Georgia', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2007,1322181,-0.002042667406319782
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7244058,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2007,328325,-0.007006931427307602
"Bayesian Methods and Experimental Design for Molecular Biology Experiments    DESCRIPTION (provided by applicant): The goal of this proposal is to provide a suite of software tools for bioinformatics and systems biology researchers who are using molecular biology (Omics) data to identify the best experimental design and to analyze the resulting experimental data using Bayesian tools. A common problem for most bioinformatics experiments is low power due to low replication. This problem can be alleviated economically when an increase in adoption and use of a specific platform leads to a decrease in associated costs, thereby enabling an increase in samples allocated per treatment. Yet, many bioinformatics experiments remain underpowered as researchers use the offsets of decreased costs to explore more complex questions. When designing an experiment, the allocation of samples to treatment regimens, and the choice of treatments to test, are traditionally the only variables to manipulate. Bayesian experimental design provides a framework to find the optimal design out of n possible designs subject to a utility function that can include such items as time and material costs.      Bayesian statistical methods have been gaining substantial favor in bioinformatics and systems biology as they provide a highly flexible framework for fitting and exploring complex models. Bayesian models also provides to domain experts such as biologists and physicians easily interpretable models through posterior probabilities which are more naturally understood than the traditional p-value. While a number of open source tools based on Bayesian models are available, most are applied best in the context of a specific research data analysis problem or model and are not integrated into a single, complete system for data analysis.      We propose to research and develop a statistical analysis software package S+OBAYES (for S-PLUS and R) with generalized tools for Bayesian design of experiments, empirical and fully Bayesian analysis, and modeling and simulation using modern commercial software development practices. These tools will provide functionality for finding the optimal choice and layout of experimental treatments for molecular biology experiments and for fitting Bayesian linear and non-linear models to a variety of data types including time series. We propose to validate the software in molecular biology research problems such as the detection of differential gene, protein, and metabolite abundance. The benefits of this work will be a commercial-quality software package with validated statistical methodology and interactive visualization tools that will appeal to molecular biologists and systems biology investigators. The results of the proposed work will expedite discoveries in basic science, early disease detection, and drug discovery and development.          n/a",Bayesian Methods and Experimental Design for Molecular Biology Experiments,7325828,R43GM083023,"['Address', 'Adoption', 'Algorithms', 'Animal Genetics', 'Arizona', 'Basic Science', 'Bayesian Analysis', 'Bayesian Method', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biometry', 'Biotechnology', 'Cations', 'Chromosome Mapping', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Government', 'Government Agencies', 'Health', 'Imagery', 'Industry', 'Information Systems', 'Institution', 'Iowa', 'Libraries', 'Linear Models', 'Machine Learning', 'Manuals', 'Manuscripts', 'Maps', 'Marketing', 'Mass Spectrum Analysis', 'Measures', 'Medical Informatics', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular', 'Molecular Biology', 'Non-linear Models', 'Numbers', 'Pathway interactions', 'Phase', 'Physicians', 'Population Study', 'Principal Investigator', 'Probability', 'Property', 'Proteome', 'Proteomics', 'Proxy', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Rice', 'Risk Factors', 'SNP genotyping', 'Sampling', 'Science', 'Scientist', 'Series', 'Services', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Software Validation', 'Solutions', 'Speed', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Systems Biology', 'Techniques', 'Telecommunications', 'Testing', 'Time', 'Time Series Analysis', 'Training', 'Treatment Protocols', 'Universities', 'Validation', 'Washington', 'Wisconsin', 'Work', 'animal breeding', 'base', 'cost', 'design', 'drug discovery', 'experience', 'human subject', 'improved', 'interest', 'lecturer', 'models and simulation', 'open source', 'professor', 'programs', 'protein metabolite', 'research and development', 'research study', 'skills', 'software development', 'statistics', 'success', 'theories', 'tool', 'treatment effect']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,103995,-0.016011435647661217
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7494181,U54EB005149,"['Address', 'Affect', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Appearance', 'Area', 'Atlases', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Cells', 'Characteristics', 'Clinical', 'Clinical Data', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Complex', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Coupling', 'Data', 'Data Correlations', 'Data Sources', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Elements', 'Ensure', 'Epilepsy', 'Feedback', 'Fiber', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imagery', 'Imaging Techniques', 'Individual', 'Knowledge', 'Life', 'Link', 'Localized', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modification', 'Morphology', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Organ', 'Other Imaging Modalities', 'Output', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Range', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Schizophrenia', 'Science', 'Services', 'Shapes', 'Software Engineering', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Distributions', 'Structure', 'Syndrome', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Textiles', 'Time', 'Tissues', 'Today', 'USA Georgia', 'Utah', 'Visible Radiation', 'Vision', 'Western Asia Georgia', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'design', 'disability', 'experience', 'image registration', 'insight', 'interest', 'mathematical model', 'neuroimaging', 'novel', 'prenatal', 'research study', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion', 'white matter']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,87500,-0.004362363672179761
"National Alliance for Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (NAMIC)(RMI),7271955,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,3888915,-0.004362363672179761
"Smart Wheelchair Component System    DESCRIPTION (provided by applicant):  Independent mobility is critical to individuals of any age. While the needs of many individuals with disabilities can be satisfied with power wheelchairs, some members of the disabled community find it difficult or impossible to operate a standard power wheelchair. This population includes, but is not limited to, individuals with low vision, visual field neglect, spasticity, tremors, or cognitive deficits. The goal of this project is to develop a set of components that can be added to standard power wheelchairs to convert them into ""smart"" wheelchairs which can assist the user in navigation and obstacle avoidance. During Phase I, a prototype of the Smart Wheelchair Component System (SWCS) was developed from a laptop computer and a collection of sonar, infrared and bump sensors. The evaluation activities performed during Phase I demonstrated that the system is compatible with multiple brands of wheelchairs, can accept both continuous and switch-based input, and can support front-, mid-, and rear-wheel drive wheelchairs. During Phase II, we propose to refine the system hardware and software; replace the laptop computer with an embedded microprocessor; fabricate enclosures for the system components; and develop tools to support clinicians in installing and configuring the system. The system will be evaluated in tests involving potential users, clinicians, and wheelchair design standards. The final product will be a market-ready modular system which can be attached to a variety of standard power wheelchairs. This product has the potential to increase the independence and quality of life of many wheelchair users and potential wheelchair users whose disabilities limit their capacity for independent wheelchair navigation.       n/a",Smart Wheelchair Component System,7237214,R44HD040023,"['Adult', 'Age', 'Child', 'Client', 'Cognitive deficits', 'Collection', 'Communities', 'Compatible', 'Computer Vision Systems', 'Computer software', 'Computers', 'Condition', 'Destinations', 'Development', 'Disabled Persons', 'Disadvantaged', 'Documentation', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Individual', 'Joystick', 'Laboratories', 'Learning', 'Location', 'Locomotion', 'Manufacturer Name', 'Marketing', 'Methods', 'Microprocessor', 'Numbers', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Powered wheelchair', 'Production', 'Quality of life', 'Range', 'Relative (related person)', 'Research Personnel', 'Robot', 'Self Perception', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Touch sensation', 'Travel', 'Tremor', 'Visual Fields', 'Visual impairment', 'Wheelchairs', 'Work', 'base', 'data acquisition', 'design', 'disability', 'laptop', 'member', 'neglect', 'peer', 'prototype', 'sensor', 'sonar', 'tool']",NICHD,AT SCIENCES,R44,2007,387828,0.010226823637472371
"Mobile Food Intake Visualization and Voice Recognize (FIVR) Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives. n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7490204,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,3000,-0.0061212500838551944
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7340845,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,1039742,-0.005392102578261588
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7326673,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2007,386674,0.0071573757550337826
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7172766,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Condition', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Range', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Models', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'concept', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2007,487230,0.018209250600776678
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7284239,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2007,588968,0.0031827271026316105
"MBRS IMSD Program at the University of Kansas    DESCRIPTION (provided by applicant):  Within the three short years since the University of Kansas (KU) IMSD program began, twelve minority students, including six American Indians, will have applied to graduate school. This is a continuation proposal to allow us to build on these successes. KU IMSD works in concert with other NIH funded programs (Bridge, RISE, IRACDA) and takes full advantage of the juxtaposition of a Research I Institution (KU) and one of the largest tribal colleges (Haskell Indian Nations University). KU IMSD consists of four components: 1) providing research experiences to American Indian and other minority students, with a particular a focus on recruiting Haskell students from the Bridge or RISE program; 2) enhancing and modifying the curriculum; 3) offering an interdisciplinary seminar series and 4) providing financial aid and mentoring. The undergraduate research experience takes a broad, interdisciplinary approach to placing students into one of 77 possible KU labs and includes opportunities for students to share their research results at local and national meetings. The program will also support several American Indian graduate students who have obtained BA's from Haskell. IMSD supported curricular enhancements that have shown remarkable results over the past three years will be continued for gatekeeper courses in biology, chemistry and math. In biology alone, the average grade point average of American Indian students who completed the introductory biology course has increased from 0.86 to 2.94 over the past six years. An integrative seminar series will bring together students from the IMSD, Bridge, and RISE programs to foster community and learning. Support from KU IMSD for undergraduate researchers will be a cornerstone in providing financial support along with KU scholarships targeted for American Indian students. Mentoring will be provided from faculty (research advisors), the IMSD Program Coordinator (individual and group meetings) and peers (other IMSD students). Evaluation and tracking procedures will allow for regular adjustment of activities during the course of the program and assessment of whether goals have been met. If funded for another four years, the KU/Haskell collaboration provides the opportunity to significantly impact the number of American Indian scientists in this country.         n/a",MBRS IMSD Program at the University of Kansas,7209749,R25GM062232,"['Address', 'Administrative Personnel', 'Administrator', 'Adopted', 'Advertising', 'Alaska', 'Algorithms', 'American Indians', 'Appendix', 'Area', 'Arrhythmia', 'Artificial Intelligence', 'Arts', 'Attention', 'Authorization documentation', 'Behavior', 'Behavioral Sciences', 'Biodiversity', 'Biogenesis', 'Bioinformatics', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Books', 'Bovine Spongiform Encephalopathy', 'Budgets', 'Calculi', 'Cells', 'Chaos Theory', 'Characteristics', 'Charge', 'Chemistry', 'Cities', 'Class', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Conservatism', 'Country', 'Coupled', 'DNA', 'DNA Structure', 'Daily', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Depth', 'Development', 'Discipline', 'Disease', 'Distant', 'Doctor of Philosophy', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Engineering', 'Enrollment', 'Environment', 'Equilibrium', 'Ethics', 'Evaluation', 'Event', 'Exercise', 'Exposure to', 'Faculty', 'Family', 'Feedback', 'Feeling', 'Fees', 'Film', 'Financial Support', 'Fostering', 'Foundations', 'Friends', 'Funding', 'Future', 'GYPA gene', 'Gatekeeping', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Glycophorin A', 'Goals', 'Grant', 'Graph', 'Group Meetings', 'Growth', 'Habits', 'Hand', 'Health', 'Health Sciences', 'Heart', 'Helix (Snails)', 'Home environment', 'Hour', 'Housing', 'Human', 'Human Resources', 'Humanities', 'Indigenous', 'Individual', 'Informatics', 'Information Systems', 'Institutes', 'Institution', 'Internet', 'Internships', 'Invasive', 'Journals', 'Judgment', 'Kansas', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Light', 'Link', 'Literature', 'Malignant Neoplasms', 'Mathematics', 'Medical', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Minority', 'Minority Groups', 'Modeling', 'Modems', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Monitor', 'Motivation', 'Museums', 'Music', 'Mutation', 'National Institute of General Medical Sciences', 'Natural History', 'Newsletter', 'Numbers', 'Oklahoma', 'Oral', 'Oral cavity', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Pamphlets', 'Paper', 'Parents', 'Participant', 'Performance', 'Personality', 'Pharmaceutical Chemistry', 'Placement', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Poverty', 'Preparation', 'Principal Investigator', 'Problem Solving', 'Procedures', 'Process', 'Productivity', 'Program Development', 'Progress Reports', 'Proteins', 'Published Comment', 'Purpose', 'Qualifying', 'Quantum Mechanics', 'RNA', 'Race', 'Radio', 'Range', 'Reading', 'Recommendation', 'Records', 'Recruitment Activity', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Review Committee', 'Rewards', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Selection Criteria', 'Series', 'Services', 'Shock', 'Site', 'Slide', 'Snow', 'Social Functioning', 'Source', 'Sports', 'Standards of Weights and Measures', 'Students', 'Supervision', 'Support Groups', 'Surveys', 'Techniques', 'Technology', 'Text', 'Textbooks', 'Thinking', 'Time', 'Time Management', 'Today', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Update', 'Ursidae Family', 'Visit', 'Visualization software', 'Wages', 'Week', 'Work', 'Writing', 'abstracting', 'aging nutrition', 'analytical method', 'base', 'biomedical scientist', 'career', 'cohort', 'college', 'computer generated', 'computer science', 'concept', 'cost', 'court', 'data acquisition', 'day', 'digital', 'ear helix', 'expectation', 'experience', 'falls', 'follow-up', 'gene therapy', 'high school', 'i(19)', 'image visualization', 'improved', 'instructor', 'interdisciplinary approach', 'interest', 'lectures', 'member', 'novel', 'peer', 'posters', 'preference', 'professor', 'programs', 'protein structure', 'role model', 'satisfaction', 'size', 'skills', 'success', 'symposium', 'theories', 'tool', 'tribal college']",NIGMS,UNIVERSITY OF KANSAS LAWRENCE,R25,2007,430160,0.000704709849954295
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7111722,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2006,314029,-0.02901468470770454
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,7287568,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,38558,0.0010359528592120376
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,7004518,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2006,457462,0.013339943170448376
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6985348,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2006,475410,-0.013205139526685493
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7143942,R21EY017003,"['clinical research', 'computers', 'reading', 'semantics', 'touch', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,224601,0.009585850728603483
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,7015648,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2006,500182,0.002225217461877506
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,7109207,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,649537,0.009347752084583289
"New Wavelet-based and Source Separation Methods for fMRI  DESCRIPTION (provided by applicant): Available methods of analysis for functional Magnetic Resonance Imaging offer a wealth of possibilities to researchers using this neuroimaging modality. However, these tools suffer from the inherent low signal to noise ratio of the data, and from the limitations of widely used model-based approaches. These problems have been addressed by the community and the literature now describes numerous methods that can remove part of the noise and extract brain activity pattern in a data-driven fashion. This project focuses on the design of optimized algorithms for the estimation and removal of the noise, on the understanding of the applicability of existing data-driven approaches, and on the development of new blind source separation methods for fMRI data. Particular attention will be given to quantification of the gains provided by the newly proposed methods by working on simulated datasets and specifically designed fMRI experiments. The first specific aim is to use a spatio-temporal four-dimensional multiresolution analysis to define an ""'ideal denoising"" scheme for a given study. It will make extensive use of the concept of best wavelet packet basis, which allows the most efficient representation of a signal. The concept wilt first be validated on fMRI rest datasets, and its efficiency will then be measured on simulated and actual data. The second specific aim focuses on blind source separation methods. An in depth study of Independent Component Analysis will be carried out to precisely define its field of applicability on fMRI data. By using sparsity together with time-frequency methods, we will develop new source separation algorithms and will demonstrate their robustness on both simulated and real data.   n/a",New Wavelet-based and Source Separation Methods for fMRI,7107885,R01MH067204,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'clinical research', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'functional magnetic resonance imaging', 'human subject', 'mathematics', 'phantom model', 'technology /technique development']",NIMH,PRINCETON UNIVERSITY,R01,2006,385718,0.014939177465852447
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,7015012,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2006,142642,-0.007357887264313248
"Improved Methods for Single Subject FMRI Analysis    DESCRIPTION (provided by applicant): Mental illness is a great burden for the affected individual and economically costly for society. The annual cost of mental disorders has been estimated to be $150 billion, increasing every year, and this total does not include more than three million people receiving disability benefits due to mental disorders. It is imperative that we prioritize research efforts focused on understanding brain function in order to improve diagnostic strategies and discover more effective therapies. Functional Magnetic Resonance Imaging (fMRI) is a powerful tool to visualize and measure typical and atypical cognitive processing. However, many important cognitive processing systems, such as those associated with memory, language, emotion and executive control, only produce small BOLD signals and thus measurements are noisy and have low statistical confidence. Hence, fMRI has not been readily adopted for clinical diagnosis of individual patients. I propose to develop greatly improved methods to suppress the noise sources in fMRI data in order to transform fMRI from a research tool about populations to a consistent and accurate diagnostic tool to study individual cognitive functions. Using the strategy that every noise suppression algorithm must perform well to reliably detect single trial fMRI BOLD signals, I developed visualization methods to ""see"" deeply into fMRI data to evaluate the quality of the data at every step of fMRI data processing. The preliminary studies indicate that there are clear opportunities to improve fMRI image analysis techniques. The proposed research will first develop and test methods to improve suppression of errors from motion and physiological fluctuations. Then it will translate this research by combining these techniques with pattern recognition to characterize individual cognitive activation patterns in typical and atypical populations. My quantitative science expertise is in image processing, algorithm design, and pattern recognition. The research directly supports my interdisciplinary career development with hands-on experience in experiment planning, fMRI scanner operation, neuroscience coursework, and new software methods for application to severely brain disordered populations. In particular, the subjects for this research will include important clinical psychiatric populations with disorders such as fragile X syndrome, Turner syndrome, autism, Williams syndrome, depression, and bipolar disorder, so that all newly developed methods can be immediately put into practice.           n/a",Improved Methods for Single Subject FMRI Analysis,7075928,K25MH077309,"['artificial intelligence', 'bioimaging /biomedical imaging', 'body movement', 'brain disorder diagnosis', 'clinical research', 'cognition', 'cognition disorders', 'computer assisted diagnosis', 'computer program /software', 'developmental disease /disorder', 'dyslexia', 'functional magnetic resonance imaging', 'human data', 'human subject', 'image enhancement', 'image processing', 'learning disorders', 'mental disorder diagnosis', 'mental retardation', 'patient oriented research']",NIMH,STANFORD UNIVERSITY,K25,2006,162340,-0.0011465743077466188
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,7243612,R33RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R33,2006,350636,-0.014711566617435305
"Intelligent Tutor for WMD EMS Incident Management    DESCRIPTION (provided by applicant): We propose to develop EMS/IM ITS, a suite of simulation-based intelligent tutoring systems and scenarios that will enable practice-based learning of WMD emergency medical services incident management principles and skills, including situation assessment, decision-making, and real-time execution of EMS tasks within an incident command structure. To support practical and economical development of many EMS/IM ITS training scenarios, we will also develop software tools and development methods that enable efficient authoring of new scenarios and adaptation/enhancement of existing scenarios by instructors or subject matter experts, without programming. We will leverage our tutoring system development tools and our experience developing tutoring systems for medical training, command and control, and tactical decision-making. The National Incident Management System (NIMS) was mandated by HSPD-5 to provide a comprehensive, national approach to domestic incident management, so that all levels of government across the nation could work efficiently and effectively together to prepare for, respond to, and recover from domestic incidents. We believe that EMS/IM ITS can contribute to NIMS by providing scenario-based learning of incident management principles for medical first responders, consistent with NIMS, and tailorable via scenario authoring to the specific circumstances and incident management plans of each government organization. This proposed Phase I effort will lay the groundwork for the Phase II effort, by producing 1) requirements and design of the system to be developed during Phase II, 2) a software prototype that illustrates our concept, and 3) a formative evaluation of the prototype and design that provides a basis for estimating the feasibility and effectiveness of the operational system that would be developed during Phase II.             n/a",Intelligent Tutor for WMD EMS Incident Management,7115108,R43ES014801,"['artificial intelligence', 'computer assisted instruction', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'educational resource design /development', 'emergency service /first responder', 'health care personnel education', 'health care professional practice', 'health services research tag', 'medical education', 'method development', 'patient care management', 'training']",NIEHS,"STOTTLER HENKE ASSOCIATES, INC.",R43,2006,99999,-0.005914130204543599
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,7109311,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"CHATTEN ASSOCIATES, INC.",R44,2006,400929,0.007150770945863758
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,7096566,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,214738,-0.0008186707548340853
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7056141,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2006,439784,-0.004454288859620078
"A Non-invasive Single-trial In-vivo Neuroimaging System    DESCRIPTION (provided by applicant):    The overall goal of this project is to develop an integrated single-trial system for neuroimaging which combines high-density electroencephalography (EEG) with simultaneous functional magnetic resonance imaging (fMRI), and to use this system to investigate variability in neural processing. The high-temporal resolution of EEG will enable the detection of signal variability in single-trial events, and this information will be used as the input function for analysis of simultaneously acquired event-related fMRI (efMRl). We hypothesize that using single-trial EEG derived regressors for efMRI (stEEG/fMRI) will yield high spatial and high temporal resolution information about the functional neuroanatomy involved in cognitive processing. This will enable construction of unique EEG derived tMRI activation maps which are not based on pre-defined labels or observed behavioral responses but rather on task and subject specific electrophysiological source variability. The broad impact of this work will be development of a new non-invasive imaging system (stEEG/fMRI) for the cognitive neurosciences as well as a clinical tool for diagnosis and monitoring of a broad spectrum of neurological diseases. The R21 effort focuses on development of a high density (64 channels) EEG/fMRI integrated system for single-trial analysis, and characterization of possible differences between the EEG recorded in an MR environment and that recorded in a standard environment. The R33 will then demonstrate the use of stEEG/fMRI in a pilot study of cognitive aging. R21Aims: 1. Develop an in-magnet 64 channel EEG system for single-trial analysis of event-related potentials recorded concurrently with fMRI. 2. Assess the quality of EEG collected inside the MR scanner compared to that collected in a shielded EEG room, using a series of predefined protocols for characterizing the effects of the auditory and magnetic environments on EEG and ERP wave forms. 3. Validate that EEG recorded simultaneously with fMRI is of a high enough quality to detect task relevant single-trial signatures using supervised machine learning. R33 Aims: 1.Use single-trial EEG-derived regressors, constructed via supervised machine learning, to construct efMRI activation maps (stEEG/fMRI activation maps) for auditory oddball and Eriksen flanker tasks. 2.Use alpha power as a complementary regressor within stEEG/fMRI for capturing additional single-trial variance in the hemodynamic response. 3.Demonstrate that stEEG/tMRI activations maps yield new information for discriminating young and old adult populations, as compared to traditional efMRI and P3 and ERN ERP analysis. n/a",A Non-invasive Single-trial In-vivo Neuroimaging System,7273057,R33EB004730,"['aging', 'auditory threshold', 'bioimaging /biomedical imaging', 'brain electrical activity', 'clinical research', 'cognition', 'electroencephalography', 'evoked potentials', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'learning', 'loudness', 'neural information processing', 'neuroanatomy', 'neuroimaging', 'noninvasive diagnosis', 'technology /technique development']",NIBIB,COLUMBIA UNIV NEW YORK MORNINGSIDE,R33,2006,444914,0.005127368052458386
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,7057358,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2006,180672,0.011971317246448647
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7037390,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2006,215583,-0.009945510525407934
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7104243,U54EB005149,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'bioinformatics', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2006,3809481,-0.004362363672179761
"Temporally Adaptive fMRI DESCRIPTION (provided by applicant):    This research plan envisages a methodological advance in functional MRI (fMRI) to allow for adaptive stimulus presentation derived directly from the acquired image data. Adaptation of stimuli will be accomplished by modeling fMRI to classify brain states during the image reconstruction process, and subsequently modulating a visual display. This emphasis on image-based prediction constitutes a fundamental shift from the conventional approach of using temporal changes in images to detect spatial ""hot spots"". This research will generate significant insights and development of capabilities for adaptive fMRI experiments using prediction of brain states. This has several significant applications. Primary among these is the potential contribution to designing much more flexible experiments to enhance our basic understanding of brain function. Also relevant are biofeedback rehabilitation, therapeutic meditation, learning studies, sports therapy or other virtual reality-based training, and lie-detection. Moreover this approach will provide spatially resolved data that complements ongoing EEG-based brain computer interface (BCI) research.  The experimental plan incorporates a constructive progression that first develops offtine predictive algorithms to a range, of fMRI experminents, secondly treats the case of measurable human learning characterized by offline analysis, and ifinally utilizes these initial studies to characterize system comprising a real-time machine learning algorithm coupled with a responsive human volunteer.  Long-term goal: Initiate a research program that will enhance current spatial mapping studies by allowing for temporal classification of brain states based on image data and biofeedback capabilities for adaptive fMRI experiments.  Specific Aims:  1) Characterize the relationship between choice of fMRI task and choice of predictive technique to examine the importance of the particular predictive model, the connection between task difficulty and modeling accuracy, and the amount of training data required to build accurate predictive models.  2) Analyze fMRi data from a motor-learning task to study how behaviorally demonstrated learning by a subject corresponds with changes in the image data, and if this effect is directly observable using predictive models.  3) Develop capabilities to perform real-time feedback of stimulus based on interaction between a predictive algorithm and subject adaptation. n/a",Temporally Adaptive fMRI,7001247,R21NS050183,"['behavior prediction', 'behavior test', 'behavioral /social science research tag', 'biofeedback', 'bioimaging /biomedical imaging', 'brain mapping', 'choice', 'clinical research', 'functional magnetic resonance imaging', 'human subject', 'learning', 'mathematical model', 'model design /development', 'preference', 'psychological models', 'statistics /biometry', 'stimulus /response', 'time resolved data']",NINDS,EMORY UNIVERSITY,R21,2006,172749,-0.0011941059770401935
"MobileEye OCR for the Visually Impaired    DESCRIPTION (provided by applicant): In this SBIR we propose to demonstrate the technical feasibility of Mobile OCR, a portable software system which makes use of existing personal devices to provide access to textual materials for the elderly or the visually impaired. The system will help these low vision individuals with basic daily activities, such as shopping, preparing meals, taking medication, and reading traffic signs. It will step beyond our proposed MobileEyes vision enhancement system to apply cutting edge recognition technology for mobile devices. The system will use common camera phone hardware to capture and enhance textual information, perform Optical Character Recognition (OCR) and provide audio or visual feedback. Our research will focus on implementing and integrating new vision enhancement and analysis techniques on limited resource mobile devices. Specifically, we will develop algorithms for detection and rectification of text on planes and generalized cylinders subject to perspective distortions, implement more robust and efficient algorithms and systems for stabilization and enhancement of text blocks, provide mobile OCR on complex textured backgrounds, and implement these techniques on small devices across a variety of platforms. The recognized text will be presented through Text-to-Speech (TTS), or displayed on the device with enhanced quality which can be easily read by low vision users. Phase I will focus on demonstrating the technical feasibility of our approach, and will incorporate a performance measurement methodology to quantitatively evaluate progress and evaluate our system against other approaches. In comparison to existing vision enhancement devices, such as magnifying glasses, telescopes, and text reading devices such as scanner-based OCR, our solution has several advantages: 1) it makes use of a single, portable device (camera cell phone) that is commonly available and typically already carried for its telecommunications capabilities; 2) it can be used selectively by users so they will not be overwhelmed by irrelevant information; and 3) it can be integrated directly with other applications for specialized tasks. Our research results will impact the millions of low-vision individuals and the blind, as well as vision and computer vision researchers. Our team is uniquely qualified to explore the feasibility of extending visual applications to these devices, and provide a platform for integrating future vision algorithms.         n/a",MobileEye OCR for the Visually Impaired,7053650,R43EY017216,"['reading', 'solutions', 'vision']",NEI,"APPLIED MEDIA ANALYSIS, LLC",R43,2006,104935,0.022366319391277756
"Accessible Artificial Intelligence Tutoring Software DESCRIPTION (provided by applicant): Quantum has successfully developed, tested and brought to the classroom the first artificial intelligence (Al) tutoring systems in chemistry education. This work successfully addressed several longstanding, clearly articulated needs for improved interactive educational software. A leading distributor for the U.S. and Canada, Science Kit & Boreal Laboratories, as well as prominent textbook publisher, Holt, Rinehart and Winston, have entered into long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. The aim of this Phase I SBIR proposal is to bring the full power and benefits of this cutting-edge new educational technology to students who are blind and visually impaired. There is a considerable need for improved educational software for science education in general, but the problem of quality educational software materials for the blind is known to be particularly acute. Certain unique attributes of the Quantum Al Tutors make them potentially very well suited for full accessibility to the blind using Internet-capable screen reader technology. The potential technological innovation here is the development of advanced Al tutoring technology that has accessibility built into its framework design. If successful, an immediate outcome will be the first Al tutoring systems that are accessible to blind students, delivered through the Internet. A formulation of an Al tutoring methodology with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. This project can only be accomplished by working intimately with experts in education for the blind, and Quantum has arranged a number of important partnerships in this respect, for research as well as commercialization of the resulting technology, including: the National Federation of the Blind, the American Printing House for the Blind, Pearson Learning Group, Bartimaeus Group and Henter Mathematics. n/a",Accessible Artificial Intelligence Tutoring Software,6880607,R43EY016251,"['Internet', 'artificial intelligence', 'blind aid', 'chemistry', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'educational resource design /development', 'science education', 'technology /technique development']",NEI,"QUANTUM SIMULATIONS, INC.",R43,2005,100721,0.01551607841286215
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6916483,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,321788,-0.02901468470770454
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6910621,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,245768,0.0010359528592120376
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6995047,R43EY014487,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'data collection', 'digital imaging', 'functional ability', 'human subject', 'image processing', 'medical rehabilitation related tag', 'patient oriented research', 'portable biomedical equipment', 'questionnaires', 'vision aid', 'vision disorders', 'visual fields', 'visual perception', 'visual threshold', 'visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2005,144106,0.004495995168771959
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6832762,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2005,461157,0.013339943170448376
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6841137,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2005,473795,-0.013205139526685493
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6944025,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2005,5000,-0.006191766058857239
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6946761,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2005,100000,-0.01167370615008854
"Linking Information, Families and Technology (LIFT) DESCRIPTION (provided by applicant): KIT Solutions, a private firm specializing in developing intelligent, Knowledge-based Information Technology (KIT) solutions for the field of health and human services will partner with the University of Pittsburgh, Office of Child Development (OCD) to develop a Web-based, interactive software application of a Family Support Management Information System (FS MIS) for nationwide dissemination. This innovation is called Linking Information, Families and Technology (LIFT).  Family support centers, like other human service programs and agencies across the country, are being required to implement best practices and document the impact of their services to funders, policy makers, and the community. However, most family centers do not have a state-of-the-art web-based information system available to them that integrates best practice, expert knowledge, and daily management functions. The proposed LIFT system will address these critical needs and has great potential for nationwide commercial distribution. The combination of KIT'S proven record of developing knowledge based information technology and OCD's over 20 years of research and practice in family support services will greatly enhances the chance of success for this business venture. In Phase I of the project, we will produce prototype software demonstrating the benefit, usability, and feasibility of a web-based, interactive, intelligent system for use by family support centers across the nation. The extent of which LIFT enables family center staff to build skill, capacity, access information and expert knowledge, to enhance their work will be the focus of this phase. In Phase II, we will fully develop the prototype LIFT to a commercial grade web application for nationwide dissemination and further validate the commercial potential and impact of LIFT, using a quasiexperimental design, which will involve a large number of users across multiple sites. In Phase III, we will seek private funding for marketing the system to the national market. We intend to use the Microsoft.Net Platform and follow XML web service concepts to develop the proposed innovation. Collection of a subscription fee will be used to support the maintenance and future development of the system. n/a","Linking Information, Families and Technology (LIFT)",6990440,R43HD049229,"['Internet', 'artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'family', 'focus groups', 'human subject', 'information dissemination', 'social service']",NICHD,"KIT SOLUTIONS, INC.",R43,2005,104545,-0.005895231771601161
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,6863029,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2005,498368,0.002225217461877506
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,6953037,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,647432,0.009347752084583289
"New Wavelet-based and Source Separation Methods for fMRI  DESCRIPTION (provided by applicant): Available methods of analysis for functional Magnetic Resonance Imaging offer a wealth of possibilities to researchers using this neuroimaging modality. However, these tools suffer from the inherent low signal to noise ratio of the data, and from the limitations of widely used model-based approaches. These problems have been addressed by the community and the literature now describes numerous methods that can remove part of the noise and extract brain activity pattern in a data-driven fashion. This project focuses on the design of optimized algorithms for the estimation and removal of the noise, on the understanding of the applicability of existing data-driven approaches, and on the development of new blind source separation methods for fMRI data. Particular attention will be given to quantification of the gains provided by the newly proposed methods by working on simulated datasets and specifically designed fMRI experiments. The first specific aim is to use a spatio-temporal four-dimensional multiresolution analysis to define an ""'ideal denoising"" scheme for a given study. It will make extensive use of the concept of best wavelet packet basis, which allows the most efficient representation of a signal. The concept wilt first be validated on fMRI rest datasets, and its efficiency will then be measured on simulated and actual data. The second specific aim focuses on blind source separation methods. An in depth study of Independent Component Analysis will be carried out to precisely define its field of applicability on fMRI data. By using sparsity together with time-frequency methods, we will develop new source separation algorithms and will demonstrate their robustness on both simulated and real data.   n/a",New Wavelet-based and Source Separation Methods for fMRI,6949109,R01MH067204,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'clinical research', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'functional magnetic resonance imaging', 'human subject', 'mathematics', 'phantom model', 'technology /technique development']",NIMH,PRINCETON UNIVERSITY,R01,2005,395000,0.014939177465852447
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6952455,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2005,671838,-0.0021951446254101586
"Multi-microphone long probe for OAE acquisition DESCRIPTION (provided by applicant): The development of an innovative multi-microphone probe and acquisition system for recording otoacoustic emissions {OAEs} with advanced noise cancellation algorithms, increased frequency and intensity ranges and pressurization capabilities is proposed. Two advanced noise cancellation algorithm will be implemented: 1) a multi-reference adaptive noise cancellation (ANC) network and 2) two-dimensional filtering. These algorithms will utilize the independent measurements provided by the multiple microphones in order to reduce noise contaminants. Each microphone or microphone groupings will be connected to individual analog-to-digital (A/D) converters in order to allow for the implementation of the digital signal processing algorithms. The pressurization capabilities of the probe will allow implementation of tympanometry and the acquisition of OAEs while compensating for pressure imbalances between the outer and middle ear. Results from a prototype single microphone long probe are presented demonstrating that the design concept is valid and provides good quality OAE recordings while reducing the undesirable effects of the metal response. The proposed probe will also improve upon the limited dynamic and frequency range of current OAE probes. The probe is expected to be able to provide stimulus levels of up to 90 dB HL and a frequency response of up to 24 kHz. During Phase I, various probes will be constructed and tested under different noise conditions in adult and infant subjects. During Phase II, the pressurization capabilities of the new probe will be further developed and examined. The optimal probe designed will be implemented along with the optimal noise cancellation algorithm and tested in a comprehensive clinical study incorporating the pressurization capabilities of the probe. n/a",Multi-microphone long probe for OAE acquisition,6933674,R43DC007543,"['adult human (21+)', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'ear disorder diagnosis', 'infant human (0-1 year)', 'mathematics', 'noise', 'otoacoustic emission', 'sound frequency']",NIDCD,INTELLIGENT HEARING SYSTEMS,R43,2005,100000,-0.004367913498920297
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6879624,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2005,206550,-0.006236300123605024
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6850134,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2005,297104,-0.01469325773114299
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,6863529,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2005,143096,-0.007357887264313248
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6914863,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2005,167918,-0.014711566617435305
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,7287646,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"CHATTEN ASSOCIATES, INC.",R44,2005,91900,0.007150770945863758
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,6993754,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"ASTRO-MED, INC.",R44,2005,306142,0.007150770945863758
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,6920594,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2005,255198,-0.0008186707548340853
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,6870217,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2005,428924,-0.004454288859620078
"A Non-invasive Single-trial In-vivo Neuroimaging System    DESCRIPTION (provided by applicant):    The overall goal of this project is to develop an integrated single-trial system for neuroimaging which combines high-density electroencephalography (EEG) with simultaneous functional magnetic resonance imaging (fMRI), and to use this system to investigate variability in neural processing. The high-temporal resolution of EEG will enable the detection of signal variability in single-trial events, and this information will be used as the input function for analysis of simultaneously acquired event-related fMRI (efMRl). We hypothesize that using single-trial EEG derived regressors for efMRI (stEEG/fMRI) will yield high spatial and high temporal resolution information about the functional neuroanatomy involved in cognitive processing. This will enable construction of unique EEG derived tMRI activation maps which are not based on pre-defined labels or observed behavioral responses but rather on task and subject specific electrophysiological source variability. The broad impact of this work will be development of a new non-invasive imaging system (stEEG/fMRI) for the cognitive neurosciences as well as a clinical tool for diagnosis and monitoring of a broad spectrum of neurological diseases. The R21 effort focuses on development of a high density (64 channels) EEG/fMRI integrated system for single-trial analysis, and characterization of possible differences between the EEG recorded in an MR environment and that recorded in a standard environment. The R33 will then demonstrate the use of stEEG/fMRI in a pilot study of cognitive aging. R21Aims: 1. Develop an in-magnet 64 channel EEG system for single-trial analysis of event-related potentials recorded concurrently with fMRI. 2. Assess the quality of EEG collected inside the MR scanner compared to that collected in a shielded EEG room, using a series of predefined protocols for characterizing the effects of the auditory and magnetic environments on EEG and ERP wave forms. 3. Validate that EEG recorded simultaneously with fMRI is of a high enough quality to detect task relevant single-trial signatures using supervised machine learning. R33 Aims: 1.Use single-trial EEG-derived regressors, constructed via supervised machine learning, to construct efMRI activation maps (stEEG/fMRI activation maps) for auditory oddball and Eriksen flanker tasks. 2.Use alpha power as a complementary regressor within stEEG/fMRI for capturing additional single-trial variance in the hemodynamic response. 3.Demonstrate that stEEG/tMRI activations maps yield new information for discriminating young and old adult populations, as compared to traditional efMRI and P3 and ERN ERP analysis. n/a",A Non-invasive Single-trial In-vivo Neuroimaging System,6942570,R21EB004730,"['aging', 'auditory threshold', 'bioimaging /biomedical imaging', 'brain electrical activity', 'clinical research', 'cognition', 'electroencephalography', 'evoked potentials', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'learning', 'loudness', 'neural information processing', 'neuroanatomy', 'neuroimaging', 'noninvasive diagnosis', 'technology /technique development']",NIBIB,COLUMBIA UNIV NEW YORK MORNINGSIDE,R21,2005,198617,0.005127368052458386
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,6891373,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2005,175413,0.011971317246448647
"Computer cluster for computational biology DESCRIPTION (provided by applicant):    The present application aims to establish a computer Cluster for Computational Biology and Bioinformatic (CCBB). The cluster will consists of 256 dual nodes connected with Giganet switches to enable rapid communication between the processors. The cluster will enable the integration of the two approaches and make it possible to effectively address the highly demanding computational tasks of the field. It will serve a small group of investigators, supported by the NIH, and their close collaborators. The hardware needs of computational biology and bioinformatic applications, and of the team of investigators listed in this application can be summarized as follows:   1. Significant computer power for complex and expensive simulations.   2. Large storage capacity for the whole cluster (shared) and (separately) for the individual nodes.   3. Large and rapidly accessible memory for effective statistical analysis, application of machine learning techniques, and biological discovery.   4. Fast network for information updates across the network.   In addition CCBB will have high level of databases and software integration including   1. Updates of important ""mirrors"" of shared databases (such as NR, swissprot, human EST, human genome, protein databank, etc.)   2. Local installation and frequent upgrade of widely used software packages (e.g. BLAST, Pfam, CHARMm etc.)   3. Help in porting novel software for optimal use on the CCBB hardware platform.   The combined unification of optimal hardware and software for computational biology and bioinformatic will make the new cluster; an outstanding resource for NIH related research n/a",Computer cluster for computational biology,6877645,S10RR020889,"['bioinformatics', 'biomedical equipment purchase', 'computational biology', 'computer network', 'computer program /software', 'computer system hardware', 'computers']",NCRR,CORNELL UNIVERSITY ITHACA,S10,2005,500000,-0.010547426337105271
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6910762,P30EY006883,"['biomedical facility', 'health science research', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2005,611743,0.015320512609451052
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,6924971,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2005,222488,-0.009945510525407934
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),6950028,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2005,3800000,-0.004362363672179761
"Temporally Adaptive fMRI DESCRIPTION (provided by applicant):    This research plan envisages a methodological advance in functional MRI (fMRI) to allow for adaptive stimulus presentation derived directly from the acquired image data. Adaptation of stimuli will be accomplished by modeling fMRI to classify brain states during the image reconstruction process, and subsequently modulating a visual display. This emphasis on image-based prediction constitutes a fundamental shift from the conventional approach of using temporal changes in images to detect spatial ""hot spots"". This research will generate significant insights and development of capabilities for adaptive fMRI experiments using prediction of brain states. This has several significant applications. Primary among these is the potential contribution to designing much more flexible experiments to enhance our basic understanding of brain function. Also relevant are biofeedback rehabilitation, therapeutic meditation, learning studies, sports therapy or other virtual reality-based training, and lie-detection. Moreover this approach will provide spatially resolved data that complements ongoing EEG-based brain computer interface (BCI) research.  The experimental plan incorporates a constructive progression that first develops offtine predictive algorithms to a range, of fMRI experminents, secondly treats the case of measurable human learning characterized by offline analysis, and ifinally utilizes these initial studies to characterize system comprising a real-time machine learning algorithm coupled with a responsive human volunteer.  Long-term goal: Initiate a research program that will enhance current spatial mapping studies by allowing for temporal classification of brain states based on image data and biofeedback capabilities for adaptive fMRI experiments.  Specific Aims:  1) Characterize the relationship between choice of fMRI task and choice of predictive technique to examine the importance of the particular predictive model, the connection between task difficulty and modeling accuracy, and the amount of training data required to build accurate predictive models.  2) Analyze fMRi data from a motor-learning task to study how behaviorally demonstrated learning by a subject corresponds with changes in the image data, and if this effect is directly observable using predictive models.  3) Develop capabilities to perform real-time feedback of stimulus based on interaction between a predictive algorithm and subject adaptation. n/a",Temporally Adaptive fMRI,6854105,R21NS050183,"['behavior prediction', 'behavior test', 'behavioral /social science research tag', 'biofeedback', 'bioimaging /biomedical imaging', 'brain mapping', 'choice', 'clinical research', 'functional magnetic resonance imaging', 'human subject', 'learning', 'mathematical model', 'model design /development', 'preference', 'psychological models', 'statistics /biometry', 'stimulus /response', 'time resolved data']",NINDS,EMORY UNIVERSITY,R21,2005,205820,-0.0011941059770401935
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6799187,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,321983,-0.02901468470770454
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6774688,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,242058,0.0010359528592120376
"LiFESim: Software for health science education (NCRR)    DESCRIPTION (provided by applicant): Stottler Henke Associates in collaboration with Teachers College, Columbia University, proposes to build a software system for teaching scientific inquiry in the context of nutrition science, The goal of the proposed research is to develop a computer based instructional system - called LiFESim - that teaches accurate and detailed information about food and the food system -- from production of food on the farm through food processing and transportation, to impacts of food on personal health and on the natural environment in terms of waste and pollution. The software will complement an existing health science curriculum, developed at Teachers College for 4th-6th graders, called ""Linking Food and the Environment"" or LIFE, developed from an NIH Science Education Partnership Award (SEPA) RR 12374 (1997-2004). Our system will be based on the paradigm of role-playing simulation used in such popular computer games as SimCity and The Sims: students using the software assume roles in a simulated environment and learn from the consequences of the decisions that they make in those roles. Using the simulation paradigm students will be able to explore the dynamics of large-scale systems, such as those the food transportation system in ways that are not possible with the existing curriculum. For example, the simulation would allow students to explore the impact of changes in transportation patterns on food delivery. Our system will provide explicit coaching in applying scientific methods for investigation. We will also explore learning strategies that will encourage students to critically examine - and hopefully improve - their dietary choices. We will complement simulation-based learning with two other artificial intelligence based methodologies - the use of lifelike pedagogical agents, and the use of case-based reasoning. During Phase I, we will develop a set of detailed instructional goals, use these to develop an initial system design, develop a limited prototype of the system, and then develop and perform an informal pilot study to evaluate the viability of our design. The pilot study will be conducted over a one-month period at schools in Hayward, California and New York City. Our Phase II effort will focus on developing an extensive design and performing detailed use testing of the system developed during Phase I.         n/a",LiFESim: Software for health science education (NCRR),6790401,R43RR019780,"['artificial intelligence', 'bioengineering /biomedical engineering', 'clinical research', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'education evaluation /planning', 'educational resource design /development', 'environmental contamination', 'food', 'food processing /preparation', 'health education', 'human subject', 'interactive multimedia', 'nutrition', 'nutrition related tag', 'science education']",NCRR,"STOTTLER HENKE ASSOCIATES, INC.",R43,2004,100000,0.009243252674205272
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6739928,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2004,462571,0.013339943170448376
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6733239,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2004,499766,-0.013205139526685493
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6793307,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2004,5000,-0.006191766058857239
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6805962,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2004,100000,-0.01167370615008854
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6703756,R44CA093112,"['artificial intelligence', 'clinical research', 'computer data analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'mathematics', 'statistics /biometry']",NCI,"CYTEL, INC",R44,2004,411387,0.007430159063855101
"AI Software for Science Education Related to Drug Abuse DESCRIPTION (provided by applicant): This Phase I SBIR proposal is aimed at advancing the state of the art in chemistry education software in a critically important respect demanded by students, teachers, administrators and Quantum Simulations, Inc. customers. The focus of this innovation is the development of meaningful interactive tutoring and assessment capabilities for chemistry problem solving. Empowerment of students to make the proper decisions about drugs through experiencing the scientific process requires a solid education in basic chemistry. Chemical formulas comprise much of the fundamental ""language"" of chemistry in which students must be fluent in order to succeed. The topic of writing and understanding chemical formulas, a cornerstone of all general chemistry classes, is a reasonable starting point for the development of an AI assessment system for student learning in chemistry. A solid understanding of chemical formulas is a prerequisite to success in chemistry required not only for literacy to make informed decisions about drugs from a scientific standpoint, but also to enable and prepare students to pursue careers in research related to drug abuse. Quantum has already successfully developed and commercialized an ITS for writing chemical formulas which will be used as the starting point for the present work. The proposed technology will benefit all students; however, it is specifically targeted to help those who have the greatest need, such as students of average or marginal performance and students from historically underserved groups, by lowering barriers to accessing high-quality science instructional software.  Quantum customers include textbook publishers, software providers, hardware vendors and distance learning companies. A prominent textbook publisher, Holt, Rinehart and Winston, has entered into two long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. Quantum intends to employ an identical business model to commercialize the results of this project. n/a",AI Software for Science Education Related to Drug Abuse,6831228,R43DA018455,"['adolescence (12-20)', 'artificial intelligence', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'drug abuse education', 'educational resource design /development', 'human subject', 'science education']",NIDA,"QUANTUM SIMULATIONS, INC.",R43,2004,61750,-0.013106507458368676
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,6802141,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,668796,0.009347752084583289
"New Wavelet-based and Source Separation Methods for fMRI  DESCRIPTION (provided by applicant): Available methods of analysis for functional Magnetic Resonance Imaging offer a wealth of possibilities to researchers using this neuroimaging modality. However, these tools suffer from the inherent low signal to noise ratio of the data, and from the limitations of widely used model-based approaches. These problems have been addressed by the community and the literature now describes numerous methods that can remove part of the noise and extract brain activity pattern in a data-driven fashion. This project focuses on the design of optimized algorithms for the estimation and removal of the noise, on the understanding of the applicability of existing data-driven approaches, and on the development of new blind source separation methods for fMRI data. Particular attention will be given to quantification of the gains provided by the newly proposed methods by working on simulated datasets and specifically designed fMRI experiments. The first specific aim is to use a spatio-temporal four-dimensional multiresolution analysis to define an ""'ideal denoising"" scheme for a given study. It will make extensive use of the concept of best wavelet packet basis, which allows the most efficient representation of a signal. The concept wilt first be validated on fMRI rest datasets, and its efficiency will then be measured on simulated and actual data. The second specific aim focuses on blind source separation methods. An in depth study of Independent Component Analysis will be carried out to precisely define its field of applicability on fMRI data. By using sparsity together with time-frequency methods, we will develop new source separation algorithms and will demonstrate their robustness on both simulated and real data.   n/a",New Wavelet-based and Source Separation Methods for fMRI,6797879,R01MH067204,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'clinical research', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'functional magnetic resonance imaging', 'human subject', 'mathematics', 'phantom model', 'technology /technique development']",NIMH,PRINCETON UNIVERSITY,R01,2004,395000,0.014939177465852447
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6888368,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2004,416347,-0.0021951446254101586
"Wireless EEG/PSG System with Novel Artifact Removal DESCRIPTION (provided by applicant): EEG is a valuable non-invasive clinical tool in numerous applications, from the diagnosis and treatment of brain diseases to the clinical monitoring of neurological injuries, sleep disorders and depth of anesthesia.  However, EEG signals are very susceptible to various artifacts which seriously impede the EEG interpretation and compromise its therapeutic capabilities. Methods currently employed for removing artifacts from EEG recordings are not clinically effective or feasible for real-time and long-term neuro-monitoring. Hence, the overall goal of this project is to develop a novel, high-fidelity artifact identification and removal technique that will be specifically useful for ambulatory EEG recording and intervention.      The proposed novel artifact removal technique is based on the Wavelet-Based Artifact Removal (WBAR) method, which exploits the excellent time-frequency localization of artifacts provided by the wavelet decomposition. The WBAR method is computationally very efficient and allows for simultaneous, real-time removal of a variety of EEG artifacts. It has been recently developed by the PI and tested for a single EEG channel in an extensive clinical study as part of a novel depth-of-anesthesia monitor.       The WBAR method will be improved by combining it with the Wavelet Neural Networks for the precise artifact classification, and recursive EEG Parameterization methods for the reliable estimation of the corrupted EEG components. The combination of these methods will result in fully automated, real-timeartifact removal technique that maximally preserves valid EEG information.       The development and implementation of this novel method will greatly enhance the functionality and  utilization of Cleveland Medical Devices' entire line of ambulatory wireless EEG/PSG systems. n/a",Wireless EEG/PSG System with Novel Artifact Removal,6792393,R43NS046978,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'brain electrical activity', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'electroencephalography', 'human subject', 'patient monitoring device', 'patient oriented research', 'polysomnography', 'portable biomedical equipment', 'sleep']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R43,2004,204478,-0.032360615231822126
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6743701,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2004,201780,-0.006236300123605024
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6701378,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,297104,-0.01469325773114299
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6849505,R01AR042739,"['artificial intelligence', 'bone density', 'bone fracture', 'clinical research', 'computer assisted diagnosis', 'densitometry', 'diagnosis design /evaluation', 'disease /disorder proneness /risk', 'hip', 'human subject', 'information systems', 'limbs', 'mathematical model', 'noninvasive diagnosis', 'osteoporosis', 'photon absorptiometry', 'radiography', 'spine', 'women&apos', 's health']",NIAMS,UNIVERSITY OF CHICAGO,R01,2004,105415,-0.01469325773114299
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6810083,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2004,178840,-0.014711566617435305
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6801171,R01EY013875,"['blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer program /software', 'cues', 'human subject', 'reading', 'vision aid', 'vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,329706,0.008631691867498598
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,6700018,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2004,311472,-0.004454288859620078
"A Non-invasive Single-trial In-vivo Neuroimaging System    DESCRIPTION (provided by applicant):    The overall goal of this project is to develop an integrated single-trial system for neuroimaging which combines high-density electroencephalography (EEG) with simultaneous functional magnetic resonance imaging (fMRI), and to use this system to investigate variability in neural processing. The high-temporal resolution of EEG will enable the detection of signal variability in single-trial events, and this information will be used as the input function for analysis of simultaneously acquired event-related fMRI (efMRl). We hypothesize that using single-trial EEG derived regressors for efMRI (stEEG/fMRI) will yield high spatial and high temporal resolution information about the functional neuroanatomy involved in cognitive processing. This will enable construction of unique EEG derived tMRI activation maps which are not based on pre-defined labels or observed behavioral responses but rather on task and subject specific electrophysiological source variability. The broad impact of this work will be development of a new non-invasive imaging system (stEEG/fMRI) for the cognitive neurosciences as well as a clinical tool for diagnosis and monitoring of a broad spectrum of neurological diseases. The R21 effort focuses on development of a high density (64 channels) EEG/fMRI integrated system for single-trial analysis, and characterization of possible differences between the EEG recorded in an MR environment and that recorded in a standard environment. The R33 will then demonstrate the use of stEEG/fMRI in a pilot study of cognitive aging. R21Aims: 1. Develop an in-magnet 64 channel EEG system for single-trial analysis of event-related potentials recorded concurrently with fMRI. 2. Assess the quality of EEG collected inside the MR scanner compared to that collected in a shielded EEG room, using a series of predefined protocols for characterizing the effects of the auditory and magnetic environments on EEG and ERP wave forms. 3. Validate that EEG recorded simultaneously with fMRI is of a high enough quality to detect task relevant single-trial signatures using supervised machine learning. R33 Aims: 1.Use single-trial EEG-derived regressors, constructed via supervised machine learning, to construct efMRI activation maps (stEEG/fMRI activation maps) for auditory oddball and Eriksen flanker tasks. 2.Use alpha power as a complementary regressor within stEEG/fMRI for capturing additional single-trial variance in the hemodynamic response. 3.Demonstrate that stEEG/tMRI activations maps yield new information for discriminating young and old adult populations, as compared to traditional efMRI and P3 and ERN ERP analysis. n/a",A Non-invasive Single-trial In-vivo Neuroimaging System,6829951,R21EB004730,"['aging', 'auditory threshold', 'bioimaging /biomedical imaging', 'brain electrical activity', 'clinical research', 'cognition', 'electroencephalography', 'evoked potentials', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'learning', 'loudness', 'neural information processing', 'neuroanatomy', 'neuroimaging', 'noninvasive diagnosis', 'technology /technique development']",NIBIB,COLUMBIA UNIV NEW YORK MORNINGSIDE,R21,2004,188133,0.005127368052458386
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,6795629,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2004,367302,0.011971317246448647
"Tree Ensemble Regression and Classification Methods    DESCRIPTION (provided by applicant):    This SBIR aims to produce next generation classification and regression software based upon ensembles of decision trees: bagging, random forests, and boosting. The prediction accuracy of these methods has caused much excitement in the machine learning community, and both challenges and complements the data modeling culture prevalent among biostatisticians. Recent research extends the methodology to likelihood based methods used in biostatistics, leading to models for survival data and generalized forest models. Generalized forest models extend regression forests in the same way that generalized linear models extend linear models.      This software would apply broadly, including to medical diagnosis, prognostic modeling, and detecting cancer; and for modeling patient characteristics like blood pressure, discrete responses in clinical trials, and count data.      Phase I work will prototype software for survival data, and investigate the performance of ensemble methods on simulated and real data. For survival applications, we will assess out-of-bag estimates of performance, and investigate measures of variable importance and graphics that help clinicians understand the results. Experience writing prototypes and using them on data will lead to a preliminary software design that serves as the foundation of Phase II work.      Phase II will expand upon this work to create commercial software. We will research and implement algorithms for a wider range of applications including generalized forest models, classification, and least squares regression. We will also implement robust loss criteria that enable good performance on noisy data, and make adaptations to handle large data sets.      This proposed software will enable medical researchers to obtain high prediction accuracy, and complement traditional tools like discriminant analysis, linear and logistic regression models, and the Cox model.         n/a",Tree Ensemble Regression and Classification Methods,6832086,R43CA105724,"['clinical research', 'computer assisted medical decision making', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'method development', 'model design /development', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer remission /regression', 'prognosis', 'statistics /biometry']",NCI,INSIGHTFUL CORPORATION,R43,2004,99937,0.003908837045493301
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6766751,P30EY006883,"['biomedical facility', 'health science research', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2004,593925,0.015320512609451052
"National Alliance for Medical Imaging Computing (RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (RMI),6847712,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2004,100000,-0.004362363672179761
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6682996,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' automated data processing', ' chemical structure', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' crystallization', ' data collection methodology /evaluation', ' image processing', ' mathematics', ' method development', ' protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,298672,-0.02901468470770454
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6617187,R01EY014162,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye refractometry', ' human data', ' image processing', ' ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,241570,0.0010359528592120376
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6710523,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,139234,0.004495995168771959
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6665322,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,245656,0.004495995168771959
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6644867,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2003,5000,-0.006191766058857239
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6622262,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2003,373280,-0.008780481801652746
"BioMediator: Biologic Data Integration & Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration & Analysis System,6681249,R01HG002288,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' information retrieval', ' molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2003,100000,-0.01167370615008854
"Vector Quantization for Image Pattern Recognition    DESCRIPTION (provided by applicant):    This Phase-I SBIR application addresses the increasingly significant challenges faced by pathologists and clinicians in manually inspecting microscope slides. Microscopic inspection suffers from being labor-intensive, subjective, expensive and limited by the need for physical access to the glass slide specimen of interest. The obstacle to automated microscopic inspection has been the inability to efficiently digitize entire microscope specimens at high resolutions. Aperio has developed the ScanScope (R), a novel microscope slide scanner that makes it practical - for the first time - to rapidly create virtual microscope slides at high resolutions. Virtual slides set the stage for automating microscopic inspection using automated pattern recognition. This research aims to adapt and optimize Aperio's existing and novel algorithms for vector quantization (VQ) to the problem of automatic pattern recognition in virtual slides. VQ is a general mathematical technique for encoding bitstreams using a vocabulary. The primary aim is to demonstrate the feasibility of using VQ for pattern recognition in a practical and well-characterized application: automatically finding virtually all micrometastasis clusters in cytology specimens. This proposed research represents a first attempt to automate pattern recognition in virtual slides using VQ.         n/a",Vector Quantization for Image Pattern Recognition,6695147,R43EB001617,"['artificial intelligence', ' automated data processing', ' bioimaging /biomedical imaging', ' cell line', ' computer system design /evaluation', ' cytology', ' digital imaging', ' high throughput technology', ' metastasis', ' microscopy', ' nomenclature']",NIBIB,"APERIO TECHNOLOGIES, INC.",R43,2003,97269,-0.0006021085537545574
"Adult Optical Non-Invasive Brain Oxygenation Monitor    DESCRIPTION (provided by applicant):  There is a need for a non-invasive and continuous bedside monitor for brain oxygenation for adult human patients. Near-infrared spectroscopy (NIRS) is an optically based technique that could meet such demand.  However, NIRS instruments have yet to achieve their initially expected potential of becoming routine clinical monitors complementary to pulse oximetry. One major challenge is to develop an optical transducer probe and a corresponding algorithm to solve the problem of interference from extracerebral tissue (skin, scalp, and skull) in adult NIRS applications. Another major challenge is to develop an algorithm that will be able to absolutely quantify the optical signals to derive quantitative variables or indices that are of clinical significance. Our goal is to resolve these challenges to develop an NIRS monitor that will determine absolute brain hemoglobin oxygen saturation on adult patients.  The primary objectives of this SBIR proposal are: 1) Design and construct an NIRS monitor for use on adult human patients; 2) Determine the optimum adult NIRS probe configuration to minimize extracerebral interference 3) Evaluate and validate novel adult NIRS algorithms that further minimize extracerebral interference and determine absolute brain oxygen saturation.         n/a",Adult Optical Non-Invasive Brain Oxygenation Monitor,6585412,R43NS045488,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' brain circulation', ' infrared spectrometry', ' noninvasive diagnosis', ' optics', ' oxygen transport', ' patient monitoring device', ' respiratory oxygenation', ' swine']",NINDS,"CAS MEDICAL SYSTEMS, INC.",R43,2003,100000,-0.003204808087613746
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6587476,R44CA093112,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' human data', ' mathematical model', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R44,2003,400084,0.007430159063855101
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6626050,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2003,386197,-0.0046279411997428395
"Software to Handle Missing Values in Large Data DESCRIPTION (provided by applicant):    This SBIR aims to produce commercial software for handling missing data in large data sets, where the goal is data mining and knowledge discovery. There may be a large number of subjects, variables, or both. Examples include microarray data, surveys, genomic data, and high throughput screening data.      Handling missing data is one important step of careful data preparation, which is key to the success of an entire project. Missing values often arise in medical data. This is an obstacle because many data mining tools either require complete data or are not robust to missing data.      Principled methods of handling missing data are computationally intensive. Therefore computational feasibility is a challenge to handling missing values in large data sets.      Phase I work will explore strategies such as sampling, constraining parameters, and monotone data algorithms for model based techniques. Factor analysis and multivariate linear mixed effects models will be used to reduce the number of parameters. A variable-by-variable approach using a popular data mining technique, recursive partitioning, will also be used to impute missing values.      For each of the methods, we will write prototype software and test performance on missing data patterns simulated on real data. Several ad hoc techniques will serve as a baseline for comparison.   Experience writing prototypes and using them in simulations will lead to preliminary software design that will serve as the foundation of Phase II work.       This proposed software will enable medical researchers to gain more from their data mining efforts: maximally extracting information and achieving unbiased predictions, despite missing data. n/a",Software to Handle Missing Values in Large Data,6690119,R43RR017862,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' human data', ' mathematical model', ' statistics /biometry']",NCRR,INSIGHTFUL CORPORATION,R43,2003,99847,-0.0007419132661229871
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6667132,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2003,209800,0.0037740181428108583
"New Wavelet-based and Source Separation Methods for fMRI  DESCRIPTION (provided by applicant): Available methods of analysis for functional Magnetic Resonance Imaging offer a wealth of possibilities to researchers using this neuroimaging modality. However, these tools suffer from the inherent low signal to noise ratio of the data, and from the limitations of widely used model-based approaches. These problems have been addressed by the community and the literature now describes numerous methods that can remove part of the noise and extract brain activity pattern in a data-driven fashion. This project focuses on the design of optimized algorithms for the estimation and removal of the noise, on the understanding of the applicability of existing data-driven approaches, and on the development of new blind source separation methods for fMRI data. Particular attention will be given to quantification of the gains provided by the newly proposed methods by working on simulated datasets and specifically designed fMRI experiments. The first specific aim is to use a spatio-temporal four-dimensional multiresolution analysis to define an ""'ideal denoising"" scheme for a given study. It will make extensive use of the concept of best wavelet packet basis, which allows the most efficient representation of a signal. The concept wilt first be validated on fMRI rest datasets, and its efficiency will then be measured on simulated and actual data. The second specific aim focuses on blind source separation methods. An in depth study of Independent Component Analysis will be carried out to precisely define its field of applicability on fMRI data. By using sparsity together with time-frequency methods, we will develop new source separation algorithms and will demonstrate their robustness on both simulated and real data.   n/a",New Wavelet-based and Source Separation Methods for fMRI,6663283,R01MH067204,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain imaging /visualization /scanning', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' functional magnetic resonance imaging', ' human subject', ' mathematics', ' phantom model', ' technology /technique development']",NIMH,PRINCETON UNIVERSITY,R01,2003,395000,0.014939177465852447
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6702676,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,205127,-0.01469325773114299
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6628097,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2003,297104,-0.01469325773114299
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6629976,R01HD041386,"['Internet', ' artificial intelligence', ' attitude', ' behavior prediction', ' behavior test', ' behavioral /social science research tag', ' clinical research', ' computer human interaction', ' cues', ' data collection methodology /evaluation', ' human subject', ' imagery', ' interactive multimedia', ' mathematics', ' population survey', ' questionnaires', ' space perception', ' visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2003,205876,-0.006236300123605024
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6646557,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2003,237000,-0.020567714525324975
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6666671,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,327524,0.008631691867498598
"Toxicological Evaluation Neuralnet Tools (TENT)  DESCRIPTION (provided by applicant):  YAHSGS' Toxicological Evaluation Neuralnet Tools (TEND is designed to advance the state-of-the-art in the prediction of toxicological end points for new or untested chemicals, drugs, and compounds. TENT deploys computational neural nets (CNN), innovative computational chemistry methods, and modem statistical regression methods into interactive modules that determine (a) a chemical's 3-D structure and physical chemistry properties, (b) Quantitative Structure Activity Relationships, (C) mechanistic modes leading to toxicological responses via microassay database analysis, and (d) a broad spectrum of toxicological properties via CNN 3-D structural similarity analyses. TENTs output includes physical chemistry properties, 3-D structure, predicted toxicological impacts, and confidence level associated with each. It is anticipated that TENT will become one of the primary tools used by (a) researchers in human health and toxicological fields, (b) pharmaceutical companies to screen out drugs early in the development process prior to expending hundreds of millions on clinical in vivo and in vitro testing, (C) by companies developing new chemicals, chemical compounds, and chemically treated materials to determine potential toxicological impacts including those caused by environmental changes during and after usage, (d) companies striving to show compliance with ISO 14000 for materials used in their products, and (e) federal and military organizations for chemicals and materials contemplated for use in their mission areas. Industry experts predict that the market for TENT-type tools and applications will reach $8 -$10 billion by 2006 and three times that amount by 2016. The benefits that the US should receive from TENT could include (a) a greatly enhanced understanding of potential toxicological impacts from pharmaceuticals, chemicals, and chemically treated materials (4 out of 5 chemicals in industrial use currently have not undergone adequate testing due to time and expense), (b) companies will avoid billions of dollars in clinical testing for chemicals and drugs that ultimately fail (the funds saved can be applied to the development of new and better materials that help mankind and the environment that might otherwise go unfunded), and (c) TENT can substantially reduce the number of laboratory animals used for clinical testing.   n/a",Toxicological Evaluation Neuralnet Tools (TENT),6550075,R43ES011918,"['alternatives to animals in research', ' chemical structure function', ' computational neuroscience', ' computer program /software', ' computer simulation', ' method development', ' microarray technology', ' molecular dynamics', ' neurotoxicology', ' statistics /biometry', ' three dimensional imaging /topography', ' toxicant screening']",NIEHS,"YAHSGS, LLC",R43,2003,84450,-0.01705904443495131
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6635595,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2003,576626,0.015320512609451052
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6580977,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2002,246164,0.004495995168771959
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6522796,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2002,5000,-0.006191766058857239
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6444337,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2002,362409,-0.008780481801652746
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6485420,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2002,380192,-0.0046279411997428395
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6538226,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2002,66954,-0.01342365347334531
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6490198,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2002,331492,-0.019865056327630477
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6569890,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2002,139082,0.004247082811031991
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6534517,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2002,404087,-0.04948458407837448
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6581049,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2002,249727,0.0037740181428108583
"New Wavelet-based and Source Separation Methods for fMRI  DESCRIPTION (provided by applicant): Available methods of analysis for functional Magnetic Resonance Imaging offer a wealth of possibilities to researchers using this neuroimaging modality. However, these tools suffer from the inherent low signal to noise ratio of the data, and from the limitations of widely used model-based approaches. These problems have been addressed by the community and the literature now describes numerous methods that can remove part of the noise and extract brain activity pattern in a data-driven fashion. This project focuses on the design of optimized algorithms for the estimation and removal of the noise, on the understanding of the applicability of existing data-driven approaches, and on the development of new blind source separation methods for fMRI data. Particular attention will be given to quantification of the gains provided by the newly proposed methods by working on simulated datasets and specifically designed fMRI experiments. The first specific aim is to use a spatio-temporal four-dimensional multiresolution analysis to define an ""'ideal denoising"" scheme for a given study. It will make extensive use of the concept of best wavelet packet basis, which allows the most efficient representation of a signal. The concept wilt first be validated on fMRI rest datasets, and its efficiency will then be measured on simulated and actual data. The second specific aim focuses on blind source separation methods. An in depth study of Independent Component Analysis will be carried out to precisely define its field of applicability on fMRI data. By using sparsity together with time-frequency methods, we will develop new source separation algorithms and will demonstrate their robustness on both simulated and real data.   n/a",New Wavelet-based and Source Separation Methods for fMRI,6554738,R01MH067204,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain imaging /visualization /scanning', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' functional magnetic resonance imaging', ' human subject', ' mathematics', ' method development', ' phantom model', ' technology /technique development']",NIMH,PRINCETON UNIVERSITY,R01,2002,395000,0.014939177465852447
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6497411,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,297104,-0.01469325773114299
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6558149,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2002,10000,-0.01469325773114299
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6526274,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2002,237000,-0.020567714525324975
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6520234,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2002,163400,-0.0023448867369945197
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6547549,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2002,338540,0.008631691867498598
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6518379,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2002,559831,0.015320512609451052
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6525584,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2002,128860,0.0005904579312843596
ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION No abstract available n/a,ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION,6394754,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' chemical structure', ' computer system design /evaluation', ' crystallization', ' method development']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,232402,0.005069466162761423
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6421360,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2001,5000,-0.006191766058857239
"Markov Chain Monte Carlo and Exact Logistic Regression   DESCRIPTION (provided by applicant): Logistic regression is a very popular           model for the analysis of binary data with widespread applicability in the           physical, behavioral and biomedical sciences. Parameter inference for this           model is usually based on maximizing the unconditional likelihood function.          However unconditional maximum likelihood inference can produce inconsistent          point estimates, inaccurate p-values and inaccurate confidence intervals for         small or unbalanced data sets and for data sets with a large number of               parameters relative to the number of observations. Sometimes the method fails        entirely as no estimates can be found that maximize the unconditional                likelihood function. A methodologically sound alternative approach that has          none of the aforementioned drawbacks is the exact conditional approach in which      one generates the permutation distributions of the sufficient statistics for         the parameters of interest conditional on fixing the sufficient statistics of        the remaining nuisance parameters at their observed values. The major stumbling      block to this approach is the heavy computational burden it imposes. Monte           Carlo methods attempt to overcome this problem by sampling from the reference        set of possible permutations instead of enumerating them all. Two competing          Monte Carlo methods are network based sampling and Markov Chain Monte Carlo          (MCMC) sampling. Network sampling suffers from memory limitations while MCMC         sampling can produce incorrect results if the Markov chain is not ergodic or if      the process is not in the steady state. We propose a novel approach which            combines the network and MCMC sampling, draws upon the strengths of each of          them and overcomes their individual limitations. We propose to implement this        hybrid network-MCMC method in our LogXact software and as an external procedure      in the SAS system.                                                                   PROPOSED COMMERCIAL APPLICATION:  There is great demand for logistic regression software that can handle small, sparse or  unbalanced data sets by exact methods.  Our LogXact package is the only software that  can provide exact inference for data sets which are not ""toy problems"".  Yet even  LogXact quickly breaks down on moderate sized problems.  The new generation of hybrid  network-MCMC algorithms will handle substantially larger problems that nevertheless need  exact inference.  The commercial potential is considerable since such data sets are common  in scientific studies.                                                                                      n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6404971,R43CA093112,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R43,2001,113111,0.0018525604080845282
"Simulation Algorithms for Spatial Pattern Recognition   DESCRIPTION (provided by applicant): A new generation of satellites is imaging       the earth's surface with unprecedented spatial and spectral resolution. With         the ability to identify local features related to environmental exposures, this      high-resolution imagery is gong to revolutionize health risk assessment. The         realization of this potential depends critically on our ability to recognize         spatial patterns on these large images. This project will develop fast spatial       null models for use in statistical pattern recognition, and will accomplish 4        aims.                                                                                                                                                                     (1) Implement fast simulation algorithms conditioned on properties of the data,      and on spatial functions;                                                            (2) Assess project feasibility by evaluating the performance of these                algorithms on existing high-resolution, hyperspectral imagery;                       (3) Implement the simulation algorithms in 2 commercial spatial analysis             software packages;                                                                   (4) Apply the software and methods to demonstrate the approach and unique            benefits for risk assessment.                                                                                                                                             The phase 1 research will address the first two aims; aims three and four will       be accomplished in phase 2 once feasibility is demonstrated. The technologic         and scientific innovations from this project are expected to greatly enhance         our ability to extract knowledge from high resolution imagery.                       PROPOSED COMMERCIAL APPLICATION:  The imminent launch of over a dozen satellites capable of high-resolution imagery is giving  health researchers powerful new data for relating environmental features to health   outcomes, but existing software packages cannot undertake spatial analysis of these  extraordinarly large data sets.   The fast simulation algorithms from this research will  be incorporated into 2 commercial software packages, providing advanced spatial  analysis for large imagery.                                                                                     n/a",Simulation Algorithms for Spatial Pattern Recognition,6401389,R43CA092807,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' image processing', ' imaging /visualization /scanning', ' statistics /biometry']",NCI,BIOMEDWARE,R43,2001,170490,-0.009910938222864023
"Advanced Vision Intervention Algorithm(AVIA)   Description (from the investigator's abstract): The objective of this                application is to implement an iterative, nine-step advanced vision                  intervention algorithm (AVIA) in software to optimize the predictability of          virtually any current or anticipated customized human vision intervention            method. The software program will use the investigator's Visual Optics class         library, as well as new software for the ray transfer element, database              analysis routines, and the ray tracing surface optimization algorithm. The           program will allow, but not require, exam data from commercially available           ophthalmic instruments such as corneal topography and wavefront aberration for       input in the optical modeling of an individual's eye. This algorithm is, to the      investigator's knowledge, the only formal framework designed specifically to         optimize the predictability of surgical and non-surgical correction methods. It      is not only a technological innovation in its own right, it also makes the most      of the current and future vision correction methods to which it is applied.          PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",Advanced Vision Intervention Algorithm(AVIA),6403968,R43EY013666,"['artificial intelligence', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' eye surgery', ' laser therapy', ' ophthalmoscopy', ' statistics /biometry', ' vision disorders']",NEI,"SARVER AND ASSOCIATES, INC.",R43,2001,99785,0.01657516497565685
"PHYSIOLOGICAL CONTROLLER FOR ROTARY BLOOD PUMPS   DESCRIPTION (Verbatim From Applicant's Abstract): As the prospects of a              mechanical replacement for a failing human heart are fast becoming a reality,        and patients are indeed returning home to regain a ""normal"" lifestyle, the           limitations of this technology upon quality of life are becoming more apparent.      To address many of these limitations, investigators are developing                   next-generation ventricular assist devices. Based on turbopump technology,           these new devices offer smaller size, greater efficiency (hence smaller              batteries), high reliability, and are more cost effective as compared to their       pulsatile predecessessors. For all the virtues of these new turbopumps, they         bring with additional challenges. Arguably the most urgent is the need for           added intelligence."" These, relatively stupid, devices are highly dependent on       feedback-control to provide physiological response. Unfortunately, developers        have yet to wage a systematic assault on this problem. Preoccupied with              apparently more urgent issues, such as biocompatibility etc., there has been         relatively little attention or resources directed at developing a physiological      controller.                                                                                                                                                               For the past eight years, the P.I. has had an interest in this problem, and has      conducted basic and applied research towards developing control algorithms. He       now proposes to devise a general-purpose controller product, which can be            incorporated into a variety of rotary pump systems for clinical use.                                                                                                      The goal of the Phase-I effort proposed herein are to design a robust control        algorithm which may then be implemented, in Phase-Il, into an applications           specific integrated circuit. The P.I. envisions that this chip would be              made available to device developers much like control circuits produced by           Intel, Motorola, Texas Instruments, etc., are adopted by a wide variety of           users for their specific products.                                                   PROPOSED COMMERCIAL APPLICATION:  Direct application to virtually all rotary-type blood pumps for critical care and chronic use.  The P.I. envisions that the Antakamatics control chip would be made available to device  developers much like integrated circuits producted by Intel, Motorola, Texas Instruments,   etc. are adopted by a wide variety of users for their specific products.  The market for  this product is estimated to exceed 200,000 units per annum, and there currently exists  no competing product.                                                                                     n/a",PHYSIOLOGICAL CONTROLLER FOR ROTARY BLOOD PUMPS,6292387,R43HL066656,"['artificial intelligence', ' auxiliary heart prosthesis', ' biomedical device power system', ' biomedical equipment development', ' cardiac output', ' circulatory assist', ' computer system design /evaluation', ' electrophysiology', ' microprocessor /microchip']",NHLBI,"ANTAKAMATICS, INC.",R43,2001,98465,0.0018224189231114763
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6343026,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2001,376147,-0.019865056327630477
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6340157,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2001,68753,-0.01342365347334531
"Neural Network System for Detection of EEG Microsleeps   DESCRIPTION (Verbatim from the Applicant's Abstract): A software system based        on Artificial Neuro-fuzzy hybrid technology will be developed for automatic          detection of microsleep events from EEG data. The software system will be            designed for used as a model-free and rule-free classification tool that             achieves generalization power through learning from examples.   The development of the software system will require a Graphical User Interface       for data example selection, frequency-analytic preprocessing of EEG raw data,        feature extraction for microsleep characterization, design and training of           neural networks for single EEG channels, and a fuzzy system for contextual           combination of network response for multiple EEG channels to a single system         response.                                                                                                                       The training and testing of the neural networks will be based on a database of       visually scored examples of microsleep and non-microsleep events from                electrophysiological data, which will be randomly divided into training,             validation and test sets.                                                                                 The performnance of the software system will be evaluated based on the               false-positive and false-negative rate for the microsleep detection using data       examples unknown to the system. The agreement rate between the combined network      response and results from visual and conventional automatic scoring will be          used as additional evaluation parameter.        PROPOSED COMMERCIAL APPLICATION: The software system will be an attractive tool for researchers, medical and technical  personal, industrial engineers. It enables the user to quantify alertness/sleepiness  in studies on sleep disorders, shiftwork, drug effects and fatigue countermeasures.  It will help reduce time-consuming visual scoring by human experts. In addition, it  will widen our knowledge about the rapid transition events (microsleeps) between  wake and sleep and can contribute to the development of alertness monitor systems.                                                                                                                                                                                                                                                                                                      n/a",Neural Network System for Detection of EEG Microsleeps,6338195,R43NS039711,"['artificial intelligence', ' biomedical automation', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' electroencephalography', ' electrophysiology', ' human data', ' neural information processing', ' sleep']",NINDS,"CIRCADIAN TECHNOLOGIES, INC.",R43,2001,93457,-0.06297444778968903
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6188611,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2001,316991,0.004247082811031991
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6403447,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2001,403938,-0.04948458407837448
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6333620,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,297104,-0.01469325773114299
Computerized Radiographic Analysis of Bone Structure No abstract available n/a,Computerized Radiographic Analysis of Bone Structure,6487190,R01AR042739,"['artificial intelligence', ' bone density', ' bone fracture', ' clinical research', ' computer assisted diagnosis', ' densitometry', ' diagnosis design /evaluation', ' disease /disorder proneness /risk', ' hip', ' human subject', ' information systems', ' limbs', ' mathematical model', ' noninvasive diagnosis', ' osteoporosis', ' photon absorptiometry', ' radiography', ' spine', "" women's health""]",NIAMS,UNIVERSITY OF CHICAGO,R01,2001,10000,-0.01469325773114299
"SPATIAL-SYMBOLIC BRAIN INFORMATION MANAGEMENT SYSTEM In the past two decades, new imaging technology has given neurologists noninvasive tools that reveal the structure of the brain with a clarity that is little short of miraculous.  At the same time, neuroscientists, usually in animal studies, have developed ways to reveal hundreds of chemical and functional features of the brain that are relevant to human brain function. The problem of integrating new knowledge to the benefit of human patients is exploding in both magnitude and complexity. This project addresses that problem by creating software to test the feasibility and effectiveness of a Brain Information Management System for knowledge obtained from human and nonhuman primate research.  The system will allow the most precise possible indexation of written and pictorial information into a knowledge base that is accessible through the standard terminology of the National Library of Medicine's Unified Medical Language System.  Clinicians and neuroscientists any place in the country will be able to access the system via the World Wide Web to determine what is known about the involvement of any brain structure with any of the characteristics described in the neuroscientific knowledge base.  In addition, links directly into websites at other institutions will allow immediate access to relevant information about the clinical significance of specific brain structures. The computerized Brain Information Management System is intended to accelerate the application of basic neuroscientific knowledge in the clinical disciplines of neurosurgery, neurology and neuropsychiatry.  n/a",SPATIAL-SYMBOLIC BRAIN INFORMATION MANAGEMENT SYSTEM,6391268,R01LM006243,"['Internet', ' artificial intelligence', ' brain mapping', ' central neural pathway /tract', ' computational neuroscience', ' computer program /software', ' human data', ' image processing', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' neural information processing', ' physical model', ' vocabulary development for information system']",NLM,UNIVERSITY OF WASHINGTON,R01,2001,303182,-0.002115118939522048
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6363936,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,177776,0.0037024805172190126
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6351629,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2001,106893,-0.007909488079876273
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6384434,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2001,259731,-0.009308825828483438
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6392266,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2001,232139,0.002413503430365118
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6401728,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2001,237000,-0.020567714525324975
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6387141,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2001,163400,-0.0023448867369945197
"Educational Tools for Neuroscience   DESCRIPTION (provided by applicant): SHAI proposes to bring two instructional        technologies together to compliment neuroscience lectures and distance               learning. Specifically we want to embed Computer Simulations of experiments and      the chemical, genetic, and physiological systems that underlie them within an        Intelligent Tutoring System. Simulations are excellent tools for revealing the       structure and dynamics of systems to students. They can also serve as a basis        of interactive experiments where students can ""discover"" the answers to              questions. Intelligent Tutoring Systems (ITS) are an emerging educational            technology based on artificial intelligence research. They play the role of          tutor, in that they guide students with appropriate information or                   demonstrations when they are having difficulty with a lesson. They also              adaptively plan the presentation of new lessons based on evaluations of a            student's past performance and knowledge level. The objective of this phase I        proposal is to develop a prototype of NeuroTutor, a simulation-based ITS to          provide students with individualized instruction in a simulation centered            environment. Steps to reaching this objective include designing a curriculum,        developing instructional, presentations and support, developing appropriate          methods for Student Modeling and Diagnosis, and implementing a limited               prototype.                                                                           PROPOSED COMMERCIAL APPLICATION:  This project has a sizeable commercialization potential.  Medical schools and university  neuroscience courses from a significant market.  Moreover the technologies to be   developed are transferable to other domains in the natural and social sciences, business  and medicine.  The technologies used are appropriate for use in distance learning programs,  and can be used by individuals to educate themselves.                                                                                     n/a",Educational Tools for Neuroscience,6403961,R43MH065842,"['computer assisted instruction', ' computer simulation', ' educational resource design /development', ' interactive multimedia', ' neurobiology', ' science education']",NIMH,"STOTTLER HENKE ASSOCIATES, INC.",R43,2001,100000,0.005332884874116517
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6346620,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2001,527694,0.015320512609451052
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6384831,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2001,356485,0.0004325771581795029
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6385653,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2001,127154,0.0005904579312843596
"SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS In this Phase l proposal we plan to develop and test a new vision technology to locat and read general informational signs (street names, building directories, office door plates) and location and directional signs (EXIT, Information, aisle signs in supermarkets). To strengthen feasibility, we will target a restricted class of signs: those consisting primarily of one- color text on a different one-color background, and whose shape falls within a prescribed set. The intended market is for people who are blind or whose sight is impaired and hence cannot read these signs unaided. Our approach makes extensive use of recently developed computer vision recognition algorithms. We also make use of the Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for determining what the potential users will require from such a system. The ultimate goal, for Phase II, is to build and test a highly portable PC- based device implementing this vision technology using a CCD camera as input and a voice-generator as output. The user would scan/point the device at a scene and it would locate and read one or more signs. Given the pace of increase in power and decrease in size of computing devices, a hand-held Sign-Finder system may be plausible to build entirely with commercial, off-the-shelf hardware in two to three years. PROPOSED COMMERCIAL APPLICATION: The potential utility to blind and visually impaired individuals is great; a commercial product could have a market potential of 500,000.  n/a",SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS,2720318,R43EY011821,"['artificial intelligence', ' blind aid', ' charge coupled device camera', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' information display', ' portable biomedical equipment', ' symbolism', ' technology /technique development', ' vision aid']",NEI,BLINDSIGHT CORPORATION,R43,2000,100000,0.026238318708823576
ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION No abstract available n/a,ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION,6188557,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' chemical structure', ' computer system design /evaluation', ' crystallization', ' method development']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2000,228436,0.005069466162761423
"ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY   DESCRIPTION: (Verbatim from the Applicant's Abstract): This Phase I project          proposes to assess the feasibility of an advanced diagnostic logic system            (Diagnostica) to support the clinical assessment process for diagnosis in            psychiatry. A working prototype of the diagnostic rules in the American              Psychiatric Association Diagnostic and Statistical Manual (DSM-IV) uses and          artificial intelligence engine (""XSB"") to implement the logic of DSM-IV along        with and an interactive graphical user interface to allow a user to add              information and understand conclusions reached by the system. The Phase I            programming objectives are to make Diagnostica ready for commercial use by           improving its graphical user interface, and finalizing implementation of its         logical rules. The resulting system will be a practical tool in clinical             settings, and relies on computer science innovations that have preciously            neither been explored nor applied in the domain of medical reasoning. With the       emergence of decision support systems, the need for better quality diagnostic        information is becoming increasingly apparent. This has been due, in part, to        the complexity of diagnostic processes and the emphasis on support of financial      processes. Within mental health, the DSM-IV provides both a model and a              standard for making diagnoses. A software component that provides flexible,          complete, and efficient application of this standard is of great value. The          innovation of Diagnostica relies on the sophistication of its modeling of            DSM-IV rules, and it's flexibility in applying those rules. Diagnostica will         automatically track the status of the information entered and allow users to         tie up 'loose ends' in documenting the proof of diagnoses formally. AS example,      the user may indicate that a set of diagnoses in 'believed true' without             specifying the symptoms needed to make the diagnoses formally ( a procedure          used routinely in clinical practice). the application will track whatever            'residual' data this is necessary in order to complete formal diagnoses, while       leaving the option of when, or if, to complete the process up to the user.                                                                                                Phase II objectives include: (1) extending Diagnostica to provide other              software applications needing diagnostic decision support services, and              specifically to link Diagnostica to the World Health Organization Schedules for      Clinical Assessment in Neuropsychiatry (SCAN); (2) addressing logical modeling       of time and creating an effective user interface for repeated assessment; (3)        incorporating probabilistic information about sets of symptoms based on              empirical information initially obtained in Phase I; and (4) developing and          testing ""belief revision"" functions to changes in knowledge stemming from            repeated clinical assessment.                                                        PROPOSED COMMERCIAL APPLICATION:                                                                                     Computerization of diagnostic logic for clinical use can improve the quality of      mental health services by efficient standardization of assessment and through        motivating and making more practical the creation of data bases which can be         used for clinical quality improvement and knowledge discovery.                                                                                                            n/a",ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY,6210194,R43MH059420,"['artificial intelligence', ' computer assisted diagnosis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' interactive multimedia', ' mental disorder diagnosis', ' psychiatry']",NIMH,"MEDICINE RULES, INC.",R43,2000,98441,-0.005262087698862281
"IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS   DESCRIPTION: The investigators propose to test the feasibility of developing         improved collimators for use with higher performance pixelated detectors under       development for use in gamma cameras now under development, as further               described by their abstract:                                                                                                                                              ""In nuclear medicine, the collimator plays a critical role in the formation of       a projection image of the radiopharmaceutical distribution within a patient.         The current state-of-the-art of collimator design for Nuclear Medicine has           matured, under the assumption that gamma-ray detectors have an intrinsic             position dependant Gaussian response function. A fundamental rethinking of           collimator design is necessary to optimize collimation for solid state               detectors that have a fixed intrinsic rect function response. We will construct      design tools by first developing a mathematical model of collimation for             detectors with intrinsic pixels and then implement it by computer algorithms.        We will conduct experiments to measure performance and validate the simulation       tools. Using the validated simulator we will then explore novel collimator           designs and hole patterns. We will examine all proposed designs for                  sensitivity, resolution, cost and manufacture. To advance clinical                   applications, collimator design will need to keep pace with the anticipated          improvements in detector technology. Phase II brings a production prototype of       the new collimator design to laboratory and clinical testing.""  PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                          n/a",IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS,6071510,R41RR013519,"['artificial intelligence', ' biomedical equipment development', ' mathematical model', ' model design /development', ' nuclear medicine', ' radiation detector', ' scintillation cameras']",NCRR,MOSAIC IMAGING TECHNOLOGY,R41,2000,137074,-0.0019105184288515003
"CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY DESCRIPTION (Adapted from applicant's abstract): The ""closed-loop                artificial pancreas,"" a device that would measure glucose level and              deliver insulin automatically as needed, has been an elusive goal in the         treatment of diabetes. There are three essential components: the blood           glucose sensor, linking algorithms and the delivery system. For the first        time, a viable sensor and a proven delivery system are now available for         research. The broad goal of this clinical research proposal is to complete       the studies needed to link the sensor to the delivery system, paving the         way for a functional closed-loop artificial pancreas. First, we will make        a detailed analysis of sensor signal as it reflects glucose level in             normal and diabetic humans. Second, we will study the precise                    pharmacokinetics of insulin delivery by external and implantable insulin         pumps. Third, analysis of these two data sets will provide the basis for         algorithms that link the sensor signal to insulin delivery. A formal             safety analysis will evaluate the safety features needed in a closed loop        device. In the last year of the project, the entire system will be tested        and fine-tuned. This project takes advantage of our relatively extensive         investigational experience with mechanical insulin delivery pumps in             people with diabetes, and the recent availability, for research, of a            subcutaneously placed, glucose oxidase-based continuous glucose sensor.          The investigators have established experienced with clinical research in         diabetes, and the resources of an excellent General Clinical Research            Center. The co-investigators have extensive experience with mathematical         modeling of biologic systems. There is a close working relationship              between the research team and the manufacturer of the sensor and pumps, as       reflected by the Interactive Research Project Grant collaboration, and by        a long-standing history of collaboration. It is essential to emphasize           that we do not anticipate completion of a manufacturable, clinically             usable, commercially viable artificial pancreas within the time-frame of         this work. Rather, we aim to complete the basic studies and modeling             analyses that would form the basis of such a system, and demonstrate the         feasibility of linking the sensor to the delivery device. If these studies       and these trials were successful, they would be a major step towards             development of a clinically useful close-loop artificial pancreas.                n/a",CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY,6177804,R01DK055132,"['artificial endocrine pancreas', ' artificial intelligence', ' biosensor device', ' clinical research', ' drug delivery systems', ' glucose metabolism', ' human subject', ' insulin', ' insulin dependent diabetes mellitus', ' medical implant science', ' pharmacokinetics']",NIDDK,JOHNS HOPKINS UNIVERSITY,R01,2000,252566,-0.0015102678779363764
"PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY Computer algorithms based on pattern recognition are being used in many areas of science and technology to assist the scientist in solving complex, time-consuming, and often tedious real-world problems.  The basic premise is to train a computer to efficiently identify a known pattern in an unknown dataset.  This needle-in-a-haystack approach is being used in the area of genomics, where there are already several examples of very powerful computational pattern recognition approaches available for searching new sequences for structural motifs, similarities to other proteins and DNA, and predicting secondary structure, based solely on the DNA or amino acid sequence.  We believe that macromolecular crystallography can also benefit from the application of pattern recognition to the often daunting task of fitting atoms into an electron density map.  The fact that electron density maps are three-dimensional images provides an additional challenge to this technology in that the procedures we are developing in order to find matching patterns must be rotation invariant.  To test the validity of our hypothesis we will complete the following aims: 1) we will develop a set of rotation invariant features that can characterize the patterns in regions of an electron density map, 2) we will determine the optimal size of feature regions and the size and type of structural database required to find similar regions of electron density capable of accurately determining structures, and 3) we will develop a methodology to synthesize matched regions to produce coherent local and global models of protein structure. If these goals can be met, we will investigate the feasibility of incorporating knowledge-based methods, neural networks, and other AI techniques to augment the interpretation of structures from electron density maps.  In addition, we will attempt to extend this methodology to produce initial structures for electron density maps that are either of poor quality and/or low resolution.  n/a",PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY,6182183,R21GM059398,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer simulation', ' computer system design /evaluation', ' electron crystallography', ' electron density', ' molecular biology information system', ' physical model', ' protein structure', ' structural biology']",NIGMS,TEXAS ENGINEERING EXPERIMENT STATION,R21,2000,101500,-0.03592947633099463
"CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS The proposed work offers enhancements to the MagicMarker software developed in Phase I.  This software offers a new methodology for the display and analysis of long-term EEG records.  Epochs of similar activity are grouped into segments and then states via two-pass hierarchial clustering.  This results in clearly differentiated background, paroxysmal activity and patient state transitions.  The underlying EEG  is always available via hyper- links so that artifacts can be distinguished from ""real EEG."" The Phase II work adds classification abilities (intelligence) to the Phase I software.  Proposed are an expert-level seizure detector, an ICU abnormality detector and a user-defined activity detector.  The effort includes the development of a large library of carefully analyzed and annotated prolonged EEG studies. Newborns, older children and adults will be included ensuring robust algorithms for all age groups. The proposed software greatly reduces staff requirements for long-term monitoring through intelligent notification (visual, audible and dial-up pager) of interesting events.  This, in addition to the ability to monitor patients ""away from the lab,"" provides more frequent patient checks and improved clinical outcomes. PROPOSED COMMERCIAL APPLICATION The proposed software would be a valuable addition to any digital EEG because of the great timesavings it provides for both neurologists and EEG technicians.  The software will be marketed along with current Persyst products (Insight, SpikeDetector and Prism), which support and are sold by virtually every major DEEG manufacturer.  n/a",CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS,6186323,R44MH055895,"['Internet', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' generalized seizures', ' human data', ' image processing', ' intensive care']",NIMH,PERSYST DEVELOPMENT CORPORATION,R44,2000,352280,0.0066267337652489875
"PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of a randomized clinical trial are almost always analyzed using some form of statistical hypothesis test. Most hypothesis tests used for analyzing clinical trials assume a population model for statistical inference, when in fact a randomization model is more consistent with the way randomized clinical trials are actually conducted. Failure to consider the randomization model when analyzing clinical trials can lead to effective drugs being declared ineffective, and ineffective drugs being declared effective. In order to analyze clinical trials in accordance with the randomization model, sophisticated software for conducting permutation tests is needed. The overall goal of this research is to develop flexible and robust software, usable by statisticians or other medical data analysts, for conducting permutation tests for single- or multi-clinic randomized clinical trials. The ongoing advances in computing technology have created a favorable climate for development of software for conducting permutation tests. This project includes a collaboration with Dr. Rosenberger of the University of Maryland, Baltimore County who is a recognized expert on randomization based inference and adaptive designs. PROPOSED COMMERCIAL APPLICATIONS: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid.  n/a",PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS,6141347,R43CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R43,2000,98172,-0.010719914491536767
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6071498,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2000,364001,-0.019865056327630477
"TOOLS TO SUPPORT COMPUTER BASED CLINICAL GUIDELINES DESCRIPTION (Adapted from the applicant's abstract):                                                                                                              The proposed research will build, refine, and test in operational use, a set     of software tools designed to help support, maintain, and iteratively            revalidate computer-based clinical guidelines as they evolve over time.  The     project will focus on the domain of childhood immunization, and will build       upon IMM/Serve, a childhood immunization forecasting program that takes as       input a child's immunization history, and produces recommendations as to         which vaccinations are due and which vaccinations should be scheduled next.      The effort required to modify and validate such a program as the clinical        field evolves over time is a challenging task.  It will be extremely             important to have a robust set of tools to assist in this process.  Partial      prototype versions of certain of these tools already exist.                                                                                                       1.  The project will refine and extend computer-based tools for immunization     knowledge maintenance.  These tools will include:  a) IMM/Def, a program         which automatically generates the rule-based logic for the most complex          portion (""kernel"") of IMM/Serve's knowledge, and b) IMM/Test, a program          which automatically generates a set of test cases to help test the kernel        logic.  The project will also develop an organized set of strategies for         immunization test case generation, and implement those strategies in the         refined version of IMM/Test.                                                                                                                                      2.  The project will build a Web site to support immunization knowledge          maintenance.                                                                                                                                                      3.  The project will keep a detailed record of all modifications and             customization of the knowledge, and will represent all the variations of the     knowledge using a standardized format such as GLIF, the Guideline                Interchange Format being developed as a standard for exchanging guidelines       between sites.                                                                                                                                                    4.  The project will link IMM/Serve to a database designed to hold               IMM/Serve's analysis of a set of cases, so that the resulting package can be     used as a tool to perform compliance assessment.                                                                                                                  5.  A set of evaluation studies will be carried out to help assess the           efficacy of the tools and to help improve their functionality.                    n/a",TOOLS TO SUPPORT COMPUTER BASED CLINICAL GUIDELINES,6185229,R01LM006682,"['Internet', ' artificial intelligence', ' computer assisted medical decision making', ' computer assisted patient care', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' human data', ' immunization', ' information systems', ' medical records', ' pediatrics']",NLM,YALE UNIVERSITY,R01,2000,317318,-0.004734525562995031
INTELLIGENT CRITIQUING OF CLINICAL-GUIDELINE APPLICATION No abstract available n/a,INTELLIGENT CRITIQUING OF CLINICAL-GUIDELINE APPLICATION,6045000,R01LM006806,"['artificial intelligence', ' behavioral /social science research tag', ' clinical research', ' computer assisted medical decision making', ' computer system design /evaluation', ' experimental designs', ' health care quality', ' health services research tag', ' human data', ' medical records', ' vocabulary development for information system']",NLM,STANFORD UNIVERSITY,R01,2000,294258,0.006096983845458467
"SPATIAL-SYMBOLIC BRAIN INFORMATION MANAGEMENT SYSTEM In the past two decades, new imaging technology has given neurologists noninvasive tools that reveal the structure of the brain with a clarity that is little short of miraculous.  At the same time, neuroscientists, usually in animal studies, have developed ways to reveal hundreds of chemical and functional features of the brain that are relevant to human brain function. The problem of integrating new knowledge to the benefit of human patients is exploding in both magnitude and complexity. This project addresses that problem by creating software to test the feasibility and effectiveness of a Brain Information Management System for knowledge obtained from human and nonhuman primate research.  The system will allow the most precise possible indexation of written and pictorial information into a knowledge base that is accessible through the standard terminology of the National Library of Medicine's Unified Medical Language System.  Clinicians and neuroscientists any place in the country will be able to access the system via the World Wide Web to determine what is known about the involvement of any brain structure with any of the characteristics described in the neuroscientific knowledge base.  In addition, links directly into websites at other institutions will allow immediate access to relevant information about the clinical significance of specific brain structures. The computerized Brain Information Management System is intended to accelerate the application of basic neuroscientific knowledge in the clinical disciplines of neurosurgery, neurology and neuropsychiatry.  n/a",SPATIAL-SYMBOLIC BRAIN INFORMATION MANAGEMENT SYSTEM,6185215,R01LM006243,"['Internet', ' artificial intelligence', ' brain mapping', ' central neural pathway /tract', ' computational neuroscience', ' computer program /software', ' human data', ' image processing', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' neural information processing', ' physical model', ' vocabulary development for information system']",NLM,UNIVERSITY OF WASHINGTON,R01,2000,295722,-0.002115118939522048
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN DESCRIPTION (Taken from application abstract):  Reminder systems are expert       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6151393,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2000,103781,-0.005351987346242277
"STATISTICAL TOOLS--BIOELECTROMAGNETIC SOURCE ESTIMATION Functional imaging techniques are important to brain researchers and clinicians alike because many phenomena cannot be observed by anatomical techniques alone. Among functional imaging methods, only magneto- and electro-encephalography (MEG, EEG, or jointly M/EEG) can noninvasively resolve events with a millisecond time scale. Statistical tools for M/BEG functional brain imaging software will be developed to estimate and visualize the spatial extent and time course of brain activity. Algorithms will be developed for the incorporation of a priori information into source estimation, and for estimating the uncertainty of the estimates. These tools will permit the use of information derived from anatomy, physiology, and other functional imaging modalities (such as fMR1 and PET) to be combined with M/EEG data to improve the robustness, reliability, and objectivity of the M/EEG analysis. The algorithms will be incorporated into prototype software, and the software validated with both simulated and experimental data. The software will comprise a PC/Windows-based program suite for analysis and display. The algorithms and resulting software may be used to study both normal brain function, such as measurements in cognitive neuroscience which may be studied with evoked response/event related potentials or spontaneous EEG, and in diseases of the brain, such as the epilepsies, where precise spatial and temporal resolution may be of value for diagnosis and presurgical evaluation. PROPOSED COMMERCIAL APPLICATIONS: The techniques which we propose are a non-invasive, non-radiological and relatively low cost addition to existing EEG, MEG and MRI systems, and provides information which is not currently available from these systems independently. The resulting software will have direct application in clinical and cognitive neuroscience research. If clinical value is demonstrated, systems based on this methodology may find applications in the areas of psychiatry, neurology and psychology.  n/a",STATISTICAL TOOLS--BIOELECTROMAGNETIC SOURCE ESTIMATION,6187415,R44NS036133,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain electrical activity', ' brain imaging /visualization /scanning', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' electromagnetic radiation', ' encephalography', ' evoked potentials', ' functional magnetic resonance imaging', ' magnetic resonance imaging', ' magnetoencephalography', ' statistics /biometry', ' technology /technique development']",NINDS,"SOURCE SIGNAL IMAGING, INC.",R44,2000,361988,0.00502964985184983
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6186179,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2000,234591,0.002413503430365118
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,6185220,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,2000,117821,0.0005746901871555015
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6165278,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2000,172553,0.0037024805172190126
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6178669,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2000,254318,-0.009308825828483438
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,6168495,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,2000,180260,-0.021339668742120288
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6090912,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2000,214602,-0.0023448867369945197
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6179288,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2000,332626,0.0004325771581795029
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6180399,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2000,150497,0.0005904579312843596
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,9976348,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2020,529154,-0.015985258179490522
"Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study PROJECT SUMMARY Road traffic injuries are a major contributor to the burden of disease globally with nearly 1.3 million deaths globally and as many as 50 million injured annually with pedestrians and cyclists in low and middle-income countries (LMICs) among the most affected. Road infrastructure of the built environment (e.g., sidewalks), neighborhood design (e.g., street connectivity) and urban development (e.g., urban sprawl) are key determinants of the risk of pedestrian injuries. In LMICs, poor road infrastructure and neighborhood design are acknowledged as being important contributors to rising numbers of road traffic injuries and deaths, but there are few studies systematically identifying and quantifying what specific features of the built environment are contributing to motor vehicle collisions in these settings. Within LMIC cities, there are often large disparities where infrastructure is improved that reflect socioeconomic characteristics, leading to health inequities in road traffic injury. The paucity of georeferenced data on the built environment in LMICs has made research on road traffic injuries more difficult, though recent advances in computer vision and image analysis combined with Big Data of publicly available, georeferenced, images of roads worldwide (e.g., Google Street View, GSV) can help overcome the paucity of data and the cost and time limitations of collecting and analyzing data on the built environment in LMICs. Automated image analysis has largely been made possible via deep learning, a subfield of artificial intelligence and machine learning and relies on training neural networks to detect and label specific objects within images. These methods can drastically reduce the barriers to citywide built environment and traffic safety research in LMIC cities, thus substantially increasing research capacity and generalizability. My career goal is to become an independent investigator in global urban health with a focus on road safety and the built environment in LMICs. I propose undertaking research and training in deep learning methods applied to public health in the setting of Bogota, Colombia: 1) Develop neural networks to create a database of BE features of the road infrastructure from image data and to create neighborhood typologies from those features; 2) Assess the association between neighborhood-level BE features and typologies and pedestrian collisions and fatalities and road safety perceptions; 3) Assess the association of neighborhood social environment characteristics with pedestrian collision and fatalities, perceptions, and BE features and typologies. I am seeking additional training in 1) developing competency in deep learning methods applied to public health; 2) creating neighborhood indictors and typologies of health and the built environment; 3) applying Bayesian spatiotemporal models to understand how neighborhood characteristics and typologies influence health; 4) develop skills in multi-country collaboration, grant writing and overseeing research projects in LMICs. PROJECT NARRATIVE Roads and neighborhoods with a built environment that support safe and active transportation are a major priority in low- and middle-income countries (LMICs) due to 90% of road traffic deaths occurring in these locations, especially to pedestrians and other vulnerable road users, yet data on key built environment features at a large scale are not always readily available in these settings. My career goal is to improve population health by examining the effects of the built environment and transportation on health through the adoption and use of methods that can leverage Big Data sources and answer complex, multilevel research questions by overcoming the lack of built environment data in LMICs. The proposed research uses deep learning and advanced statistical methods to create a citywide dataset of built and social environment features in Bogota, Colombia that will provide crucial data to answer questions of their impact on pedestrian injuries and deaths, as well as assessing the presence of health inequities in their distribution and that will lay the groundwork to expand these efforts to more cities in Latin America and other LMICs.","Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study",10123391,K01TW011782,"['Adopted', 'Adoption', 'Affect', 'Artificial Intelligence', 'Big Data', 'Cessation of life', 'Characteristics', 'Cities', 'Classification', 'Collaborations', 'Colombia', 'Competence', 'Complex', 'Computer Vision Systems', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Discipline', 'Education', 'Future', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Injury', 'Label', 'Latin America', 'Lead', 'Location', 'Machine Learning', 'Mathematics', 'Mentors', 'Methods', 'Modeling', 'Neighborhoods', 'Perception', 'Persons', 'Public Health', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Risk', 'Safety', 'Social Environment', 'Statistical Methods', 'Time', 'Training', 'Transportation', 'Typology', 'Urban Developments', 'Urban Health', 'Vehicle crash', 'Writing', 'automated image analysis', 'built environment', 'burden of illness', 'career', 'career development', 'computer science', 'cost', 'data infrastructure', 'deep learning', 'design', 'digital imaging', 'experience', 'high risk', 'improved', 'injured', 'learning strategy', 'low and middle-income countries', 'neighborhood association', 'neural network', 'pedestrian injury', 'population health', 'skills', 'social', 'socioeconomics', 'spatiotemporal', 'virtual']",FIC,DREXEL UNIVERSITY,K01,2020,138024,-0.010158616104817846
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9941090,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2020,605875,-0.008929847667400853
"Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement PROJECT SUMMARY/ABSTRACT Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing. Project Narrative Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing",Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement,10149058,R24MH117179,"['Address', 'Administrative Supplement', 'Archives', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Benefits and Risks', 'Consent Forms', 'Country', 'Data', 'Data Analyses', 'Data Security', 'Data Set', 'Ensure', 'Ethics', 'Foundations', 'Funding', 'Future', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Subject Research', 'International', 'Investments', 'Laws', 'Legal', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Neurosciences', 'Parents', 'Policies', 'Privacy', 'Process', 'Regulation', 'Research', 'Research Subjects', 'Risk', 'Security Measures', 'Series', 'Software Tools', 'Solid', 'Surveys', 'Techniques', 'United States', 'United States National Institutes of Health', 'data archive', 'data privacy', 'data sharing', 'design', 'human subject', 'human subject protection', 'machine learning algorithm', 'neuroethics', 'neuroimaging', 'novel', 'prevent', 'privacy protection', 'research study', 'sharing platform', 'sound', 'stem']",NIMH,STANFORD UNIVERSITY,R24,2020,126592,-0.0387193659635004
"Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models Project Summary Amyotrophic lateral sclerosis (ALS) and Frontotemporal Dementia FTD are devastating neurodegenerative disorders that lie on a genetic and mechanistic continuum. ALS is a disease of motor neurons that that is almost uniformly lethal within only 3-5 years of diagnosis. FTD is a heterogeneous, rapidly progressing syndrome that is among the top three causes of presenile dementia. About 10% of ALS cases are caused by dominantly transmitted gene defects. SOD1 and FUS mutations cause aggressive motor neuron pathology while TDP43 mutations cause ALS-FTD. Further, wild type FUS and TDP43 are components of abnormal inclusions in many FTD cases, suggesting a mechanistic link between these disorders. Early phenotypes are of particular interest because these could lead to targeted interventions aimed at the root cause of the disorder that could stem the currently inexorable disease progression. Elucidating such early, potentially shared characteristics of these disorders should be greatly aided by: 1) knock-in animal models expressing familial ALS-FTD genes; 2) sensitive, rigorous and objective behavioral phenotyping methods to analyze and compare models generated in different laboratories. In published work the co-PIs applied their first-generation, machine vision-based automated phenotyping method, ACBM ‘1.0’ (automated continuous behavioral monitoring) to detect and quantify the earliest-observed phenotypes in Tdp43Q331K knock-in mice. This method entails continuous video recording for 5 days to generate >14 million frames/mouse. These videos are then scored by a trained computer vision system. In addition to its sensitivity, objectivity and reproducibility, a major advantage of this method is the ability to acquire and archive video recordings and to analyze the data at sites, including the Cloud, remote from those of acquisition. We will use Google Cloud TPUs supercomputers that have been designed from the ground up to accelerate cutting-edge machine learning workloads, with a special focus on deep learning. We will analyze this data using Bayesian hierarchical spline models that describe the different mouse behaviors along the circadian rhythm. The current proposal has two main goals: 1) Use deep learning to refine and apply a Next Generation ACBM - ‘2.0’ - that will allow for more sensitive, expansive and robust automated behavioral phenotyping of four novel knock-in models along with the well characterized SOD1G93A transgenic mouse. 2) To establish and validate procedures to enable remote acquisition of video recording data with cloud-based analysis. Our vision is to establish sensitive, robust, objective, and open-source machine vision-based behavioral analysis tools that will be widely available to researchers in the field. Since all the computer-annotated video data is standardized in ACBM 2.0 and will be archived, we envision a searchable ‘behavioral database’, that can be freely mined and analyzed. Such tools are critical to accelerate the development of novel and effective therapeutics for ALS-FTD. Narrative ALS and Frontotemporal Dementia (FTD) are devastating, rapidly progressing diseases and current treatments are of limited value. In this proposal a neuroscientist and a computer scientist have teamed up to develop a new machine vision-based method for behavioral analysis novel mouse models of ALS-FTD. The ultimate goal is to reveal early phenotypes in ALS-FTD models that can be used in understanding disease pathology and in the development of new therapeutic targets.",Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models,9979408,R21NS112743,"['Amyotrophic Lateral Sclerosis', 'Animal Model', 'Archives', 'Behavior', 'Behavior monitoring', 'Behavioral', 'Characteristics', 'Circadian Rhythms', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Expression Profiling', 'Familial Amyotrophic Lateral Sclerosis', 'Frontotemporal Dementia', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Hour', 'Human', 'Intervention', 'Knock-in', 'Knock-in Mouse', 'Laboratories', 'Lead', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Motor Neuron Disease', 'Motor Neurons', 'Mus', 'Mutation', 'Neurodegenerative Disorders', 'Paralysed', 'Pathology', 'Phenotype', 'Plant Roots', 'Presenile Dementia', 'Procedures', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Respiratory Paralysis', 'Scientist', 'Site', 'Standardization', 'Syndrome', 'TensorFlow', 'Time', 'Training', 'Transgenic Mice', 'Transgenic Organisms', 'Treatment Efficacy', 'Video Recording', 'Vision', 'Work', 'Workload', 'base', 'behavioral phenotyping', 'cloud based', 'data archive', 'deep learning', 'design', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'interest', 'knockin animal', 'machine vision', 'mouse model', 'new therapeutic target', 'next generation', 'novel', 'open source', 'programs', 'protein TDP-43', 'stem', 'supercomputer', 'superoxide dismutase 1', 'tool']",NINDS,BROWN UNIVERSITY,R21,2020,446875,-0.0043690246190730185
"Big Data Predictive Phylogenetics with Bayesian Learning Big Data Predictive Phylogenetics with Bayesian Learning Abstract Andrew Holbrook, Ph.D., is a Bayesian statistician with a broad background in applied, theoretical and compu- tational data science. His proposed research Big Data Predictive Phylogenetics with Bayesian Learning tackles viral outbreak forecasting by combining Bayesian phylogenetic modeling with ﬂexible, `self-exciting' stochastic process models. The development and publication of open-source, high-performance computing software for his models will facilitate fast epidemiological ﬁeld response in a big data setting. Dr. Holbrook will apply his method- ology to the reconstruction of the 2015-2016 Zika virus epidemic in the Americas, focusing on identifying key geographical routes of transmission and phylogenetic clades with enhanced infectiousness.  Candidate: Dr. Holbrook is Postdoctoral Scholar at the UCLA Department of Human Genetics. He earned his Ph.D. in Statistics from the Department of Statistics at UC Irvine, during which time he completed his dissertation Geometric Bayes, an investigation into Bayesian modeling and computing on abstract mathematical spaces, and simultaneously participated in scientiﬁc collaborations at the UC Irvine Alzheimer's Disease Research Center. The proposed career development plan will establish Dr. Holbrook as an independent leader in data intensive viral epidemiology by 1) facilitating coursework to build biological domain knowledge, 2) affording Dr. Holbrook the opportunity to lead his own project while remaining under the expert oversight of UCLA Prof. Marc Suchard, M.D., Ph.D., and 3) allowing Dr. Holbrook to continue his focus on quantitative viral epidemiology once he has moved to a faculty commitment.  Mentors: During the ﬁrst three years of the award period, Dr. Holbrook will work closely with Prof. Suchard, continuing their current schedule of weekly meetings. Prof. Suchard is a leading expert in both Bayesian phylo- genetics and high-performance statistical computing; and with his medical background, Prof. Suchard will advise Dr. Holbrook in his expansion of domain knowledge in viral epidemiology. As secondary mentor, Prof. Kristian Andersen, Ph.D., of the Scripps Institute will advise Dr. Holbrook in the impactful application of his statistical and computational methodologies to the 2015-2016 Zika virus epidemic. Dr. Holbrook and Profs. Suchard and Andersen will maintain their collaborations after the postdoctoral period.  Research: Bayesian phylogenetics successfully reconstructs evolutionary histories but fails to predict viral spread. Self-exciting point processes are devoid of biological insight and fail to account for geographic networks of diffusion. Aim 1 addresses deﬁciencies in these two complementary viral epidemiological modeling techniques by innovating a combined model where the phylogenetic and self-excitatory components support each other. Aim 2 makes widespread adoption a reality by publishing open-source, massively parallel computing software suitable for big data analysis. Aim 3 reconstructs the 2015-2016 Zika epidemic, learns key geographical routes of transmission and identiﬁes phylogenetic clades with enhanced infectiousness. Project Narrative Tracking and predicting viral outbreaks remains an open epidemiological problem with deadly consequences. Dr. Holbrook will attack the problem with his Bayesian phylogenetic Hawkes processes, a class of models tailored to simultaneously reconstruct evolutionary histories and predict viral diffusion dynamics. With the mentorship of Profs. Marc Suchard (primary) and Kristian Andersen (secondary), Dr. Holbrook will develop open-source, high-performance computing software and apply his statistical computing methodology to the analysis of the 2015-2016 Zika virus epidemic of the Americas, learning key routes of transmission and identifying phylogenetic clades with enhanced infectiousness.",Big Data Predictive Phylogenetics with Bayesian Learning,10039150,K25AI153816,"['Accounting', 'Address', 'Adoption', 'Air', 'Alzheimer&apos', 's Disease', 'Americas', 'Award', 'Bayesian Modeling', 'Bayesian learning', 'Behavior', 'Big Data', 'Biological', 'Biology', 'Collaborations', 'Complex', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Dangerousness', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Development Plans', 'Diffusion', 'Disease Outbreaks', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evolution', 'Faculty', 'Failure', 'Free Will', 'Generations', 'Geography', 'Goals', 'Health', 'Herd Immunity', 'High Performance Computing', 'Human Genetics', 'Individual', 'Influenza', 'Institutes', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Mathematics', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Process', 'Publications', 'Publishing', 'Recording of previous events', 'Research', 'Route', 'Schedule', 'Scientist', 'Ships', 'Speed', 'Statistical Computing', 'Stochastic Processes', 'Structure', 'Techniques', 'Testing', 'Time', 'Travel', 'Viral', 'Viral Epidemiology', 'Viral Physiology', 'Work', 'ZIKA', 'Zika Virus', 'blind', 'career development', 'epidemiological model', 'flexibility', 'innovation', 'insight', 'meetings', 'novel', 'open source', 'parallel computer', 'pathogen', 'reconstruction', 'response', 'statistics', 'transmission process']",NIAID,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2020,106467,0.0009039474929398237
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,10002209,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Models', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Facebook', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2020,100690,0.008280483434358322
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),9914387,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2020,36183,-0.007085146862068026
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,-0.004224634017694192
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,9970009,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,649026,-0.07554192242924462
"Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data Project Summary The broad objective of this research is to develop a powerful deep-learning based multiple testing approach for high-dimensional spatial data that arise commonly in biomedical imaging studies, in particular, brain imaging studies. The motivating problem is to detect the cerebral metabolic abnormalities in Alzheimer’s disease (AD) from Fluorine-18 fluorodeoxyglucose positron emission tomography (FDG-PET) data. Existing multiple testing approaches in solving this problem often ignore or inadequately capture the spatial dependence among the test statistics obtained from brain voxels and thus lose substantial power for the detection. We will develop a novel spatial multiple testing method that utilizes the deep convolutional neural network (DCNN), a key deep- learning technique, to well capture the spatial dependence among test statistics and thus to achieve the optimal power in the sense of minimizing the false nondiscovery rate (FNR) while correctly controlling the false discovery rate (FDR) at a given level. The proposed DCNN-based FDR controlling method has enhanced power to discover new AD-related brain regions that are missed by conventional methods, thereby leading to novel clinical and pathological studies. The specific aims of this proposal include: 1. To develop an optimal spatial FDR controlling approach by connecting the unsupervised local-significance-index based multiple testing with the supervised DCNN-based image segmentation; 2. To evaluate the proposed spatial FDR controlling approach via extensive simulations under various three-dimensional spatial dependence structures, in comparison with multiple classical and state-of-the-art methods; 3. To apply proposed spatial FDR controlling approach to detect AD-related brain regions using the FDG-PET datasets from the Alzheimer’s Disease Neuroimaging Initiative and the Weill Cornell Brain Health Imaging Institute; 4. To develop a user- friendly and publicly available software package with versions in both Python and R to implement the proposed spatial FDR controlling approach. The proposed DCNN-based approach will also be widely applicable to large- scale multiple testing problems in other fields of biomedical research that involve spatial dependence. Project Narrative This project will exploit recent advances in deep learning to efficiently solve the large-scale spatial multiple testing problems that arise commonly in biomedical imaging studies. The proposed powerful deep-learning based spatial multiple testing approach will be particularly useful in brain imaging studies on neurodegenerative disorders such as Alzheimer’s disease and age-related cognitive impairment.",Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data,10107565,R21AG070303,"['3-Dimensional', 'Affect', 'Age-associated memory impairment', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Architecture', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrum', 'Clinical', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Detection', 'Disease', 'Early Diagnosis', 'Family', 'Fluorine', 'Glucose', 'Goals', 'Health Sciences', 'Image', 'Institutes', 'Learning', 'Literature', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Monitor', 'Network-based', 'Neurodegenerative Disorders', 'Pathologic', 'Patients', 'Performance', 'Population Group', 'Positron-Emission Tomography', 'Problem Solving', 'Procedures', 'Pythons', 'Research', 'Research Personnel', 'Structural Models', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Training', 'base', 'bioimaging', 'brain health', 'convolutional neural network', 'deep learning', 'fluorodeoxyglucose positron emission tomography', 'high dimensionality', 'imaging Segmentation', 'imaging study', 'indexing', 'metabolic rate', 'mild cognitive impairment', 'neuroimaging', 'novel', 'repository', 'simulation', 'statistics', 'success', 'theories', 'user friendly software', 'user-friendly']",NIA,NEW YORK UNIVERSITY,R21,2020,435875,-0.06739129596492699
"ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD PROJECT SUMMARY/ABSTRACT  Millions of Americans are in need of evidence-based counseling, such as motivational interviewing (MI), for alcohol use disorders (AUDs) each year. To develop competence in an evidence-based practice like MI, trainees require ample opportunities for practice and immediate, performance-based feedback on the skills that they are learning. However, this is challenging if not impossible to offer at scale -- to the large number of providers in need of training. Opportunities for practice typically rely on roleplays with other trainees with limited experience, and feedback requires either direct supervision from an expert trainer or behavioral coding from a trained coding team; these are costly, limited, and time consuming. AI-based technology can meet this need, generating many opportunities for practice, and providing regular, actionable feedback. Many practice opportunities coupled with rapid, performance-based feedback can enhance and expand training in evidence-based counseling for AUDs in a scalable and cost-efficient manner.  Lyssn.io​, Inc., (“Lyssn”) is a start-up developing AI-based technologies to support training, supervision, and quality assurance of evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. ​Lyssn’s​ team includes expertise in natural language processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous research demonstrated the basic utility of a prototype conversational agent (ClientBot) for training counselors. Currently, ClientBot simulates a general mental health client who can engage in open-ended interaction with trainees and provides immediate, performance-based feedback to trainees using machine learning.  The current Fast-Track SBIR proposal partners ​Lyssn​ with Prevention Research Institute (PRI), who has a long track-record of training counselors in evidence-based approaches for AUD and currently trains approximately 1,250 counselors per year. Phase I will adapt ClientBot to an AUD training context, including understanding PRI training workflows, assessing usability, and accuracy of machine learning based MI feedback. Phase II will conduct a field-based usability trial and a randomized training trial (N = 200 PRI trainees) to evaluate the effectiveness of ClientBot on learning of MI skills compared to a wait-list and PRI training-as-usual. Analyses will also examine the hypothesized mechanisms of behavior change underlying ClientBot’s MI skills training. The successful execution of this project will break the reliance on role plays with peers and human judgment for training and performance-based feedback and support commercialization of a ClientBot product for training of AUD counselors in evidence-based practices. PROJECT NARRATIVE Training counselors in evidence-based treatments for alcohol use disorders (AUDs) requires repeated opportunities for skills practice with performance-based feedback, which is challenging to provide at scale. Building on an existing prototype, ​Lyssn.io​ – a technology start-up focused on scalable and cost-efficient human-centered technologies – will enhance and evaluate an AI-based, conversational agent (ClientBot) that simulates a realistic client with alcohol concerns and provides performance-based feedback to support counselor training.",ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD,10009084,R44AA028463,"['Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'American', 'Assessment tool', 'Behavioral', 'Behavioral Mechanisms', 'Client', 'Clinical', 'Code', 'Competence', 'Consumption', 'Control Groups', 'Counseling', 'Coupled', 'Development', 'Effectiveness', 'Environment', 'Evaluation', 'Evidence based practice', 'Evidence based treatment', 'Feedback', 'Goals', 'Health Personnel', 'Health Technology', 'Human', 'Individual', 'Interview', 'Judgment', 'Learning', 'Learning Skill', 'Machine Learning', 'Mental Health', 'Modeling', 'Music', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Nonprofit Organizations', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Play', 'Prevention Research', 'Professional counselor', 'Provider', 'Randomized', 'Recovery', 'Research', 'Research Institute', 'Role', 'Small Business Innovation Research Grant', 'Software Engineering', 'Sports', 'Strategic Planning', 'Structure', 'Substance abuse problem', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Thinking', 'Time', 'Training', 'Training Activity', 'Training Support', 'Vision', 'Waiting Lists', 'Work', 'alcohol testing', 'alcohol use disorder', 'base', 'behavior change', 'behavioral health', 'commercialization', 'cost', 'cost efficient', 'design', 'effectiveness evaluation', 'evidence base', 'experience', 'experimental study', 'improved', 'innovation', 'member', 'motivational enhancement therapy', 'peer', 'prototype', 'quality assurance', 'scale up', 'skill acquisition', 'skills', 'skills training', 'tool', 'treatment choice', 'usability', 'user centered design']",NIAAA,"LYSSN.IO, INC.",R44,2020,397456,-0.04186479200668176
"Closing the loop on markerless object tracking Abstract/Summary Tracking the movements of objects and parts of objects - referred to as pose estimation - is critical for understanding the mechanisms underlying complex behavior. Characterizing dynamic behaviors of animals (and other systems) is central to many disciplines, including computer science, physics, ethology, kinesiology, and sports medicine. Here we focus on neuroscience, where linking brain activity to associated dynamic behaviors is critical for both understanding normal function as well as effects of injury, disease, or degeneration. Invasive methods for measuring behavior are highly accurate, but require placement of sensors that may themselves interact with behavior and which may be susceptible to deterioration or infection. Video provides a non-invasive approach to characterizing behavior over time. Extracting behavior from video streams has, historically, been a slow and laborious process. Recent work in machine learning and artificial neural networks (ANNs), though, has revolutionized this process, making the analysis of complex video far easier and more accurate. While these systems are highly flexible, they were not designed for real time use, meaning that large video files must first be stored to disk for subsequent analysis. This poses two problems that this proposal will attempt to address. First, there is significant cost and management challenges associated with storage of large video stores, forming a practical barrier for adoption of this important technology for characterizing behavior. Second, estimates related to behavioral state are not available in real time so they cannot be used to control the experiment. We will develop a research methodology for “closing the loop”, by taking the networks trained by an existing and highly successful markerless object tracking system (DeepLabCut) and optimizing them for real time inference. After the system is functional, verified, and benchmarked, it will be shared with the community through open source repositories. Project Narrative Understanding the neural basis underlying complex behavior requires careful analysis of the dynamics of moving objects. Recent advances in computer vision has greatly facilitated our ability to track objects from video, but these tools are currently limited to offline analysis. Here we propose to build a system that addresses this problem by “closing the loop” using real time inference to be freely shared with the public to enhance ongoing research across the neuroscience spectrum.",Closing the loop on markerless object tracking,10047656,R03MH123990,"['Address', 'Adoption', 'Animal Behavior', 'Architecture', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Ensure', 'Ethology', 'Eye', 'Eye Movements', 'Freezing', 'Goals', 'Guidelines', 'Hand', 'Individual', 'Infection', 'Injury', 'Joints', 'Kinesiology', 'Label', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Movement', 'Neurosciences', 'Output', 'Performance', 'Physics', 'Process', 'Pupil', 'Research', 'Research Methodology', 'Research Personnel', 'Running', 'Sports Medicine', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Work', 'artificial neural network', 'base', 'computer science', 'cost', 'deep learning', 'design', 'experimental study', 'flexibility', 'gaze', 'haptics', 'open source', 'relating to nervous system', 'repository', 'sensor', 'time use', 'tool', 'virtual']",NIMH,BROWN UNIVERSITY,R03,2020,162500,-0.013895991179363286
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9969467,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Models', 'Computer software', 'Computers', 'Custom', 'Data', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'algorithm development', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'large datasets', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,614363,-0.0038029410182492244
"Abiotic-Biotic Interfaces for Ophthalmology Symposium ABSTRACT This proposal seeks funding to support a symposium, Abiotic-Biotic Interfaces for Ophthalmology (ABI), which will bring together recognized world experts in clinical, research, vision science, engineering, industrial and pharmaceutical communities as well as junior investigators (i.e., young faculty and those in training) to discuss the current state of ABI, ranging from bioelectronic implantable and wearable devices, to nanoscale scaffolds for stem cell and gene therapies. Given the multidisciplinary nature of this field, it is essential to bring together researchers and clinicians with varying levels of expertise across many domains related to ABI to advance the progress of this novel field, identify challenges of advancement, and develop a strategic action plan to overcome these challenges. The timing to have such a symposium to further the application of implantable and/or wearable bioengineered systems in ophthalmology is now as we focus on precision and personalized medicine and leverage the revolution in deep learning artificial intelligence algorithms. Through symposium talks, sessions, and discussions we will cover the fundamentals and also identify innovative and cutting-edge strategies and methodologies to accelerate the rate of major discoveries and development of novel therapeutics. The specific aims of this symposium are: Specific Aim 1. To bring together both established and junior investigators representing a broad range of disciplines to discuss cutting edge research in this novel field, catalyze the development of cross-disciplinary and translational approaches to advance abiotic-biotic interfaces for ophthalmology, and identify gaps in knowledge and barriers to advancement. We will identify research questions and develop an agenda to guide future research that is consistent with the objectives and interests of NEI. Specific Aim 2. Develop a junior investigator program to motivate a diverse group of students and junior investigators to pursue research careers in vision science and ophthalmologic therapeutic development, who will ultimately submit grant proposals to NEI solicitations and contribute to the scientific literature. Specific Aim 3. Develop a strategic action plan to set priorities for future studies that will encourage inter-agency collaborations (e.g., NEI, NSF, DARPA, etc.). This is critical because often certain engineering tasks are best suited to be supported by NSF or DARPA whereas the biological testing of the engineered systems lends itself to funding from NEI. Hence such inter-agency or cross-agency efforts can help leverage the funding to develop sophisticated abiotic-biotic systems NARRATIVE This meeting is the first on this topic dedicated to the broad use of implantable and/or wearable bioelectronics for ophthalmological applications. It is anticipated that the strategic action plan will significantly impact the field by greatly accelerating the translation of basic science and engineering research findings to stimulate the development of novel treatments and improve clinical practice. Key topics include visual restoration, drug and gene delivery, and sensing intraocular pressure. This meeting will foster training and development of future leaders in this emerging field and promote collaboration and exchange of knowledge and ideas among junior and established investigators.",Abiotic-Biotic Interfaces for Ophthalmology Symposium,10070800,R13EY031988,"['Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biological Testing', 'Biomedical Engineering', 'Cellular Phone', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Contact Lenses', 'Custom', 'Data', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Electronics', 'Engineering', 'Eye', 'Faculty', 'Fostering', 'Funding', 'Future', 'Gene Delivery', 'Glass', 'Industrialization', 'Intraocular lens implant device', 'Knowledge', 'Literature', 'Medicine', 'Methodology', 'Nature', 'Neural Retina', 'Ophthalmology', 'Optics', 'Pharmacologic Substance', 'Physiologic Intraocular Pressure', 'Physiological', 'Research', 'Research Personnel', 'Route', 'Scientific Inquiry', 'Scientist', 'Senior Scientist', 'Students', 'System', 'Time', 'Training', 'Translations', 'Virtual and Augmented reality', 'Visual', 'base', 'career', 'clinical practice', 'deep learning', 'gene therapy', 'implantable device', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'meetings', 'multidisciplinary', 'nanoscale', 'neural network', 'novel', 'novel therapeutics', 'personalized medicine', 'portability', 'precision medicine', 'programs', 'restoration', 'scaffold', 'stem cell therapy', 'symposium', 'therapeutic development', 'translational approach', 'vision science', 'wearable device']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R13,2020,42465,-0.0076903596985163965
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10058463,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data reuse', 'data sharing', 'data visualization', 'data warehouse', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2020,627034,0.0059382017180330095
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10022332,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,243885,0.0009238951450201448
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10228145,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,59206,0.0009238951450201448
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9899994,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,416374,0.027600979729868157
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9929599,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophagus', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'complex data ', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'immunoregulation', 'improved', 'in vivo', 'lymph nodes', 'machine learning method', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,347834,-0.005156844708701949
"Making antibody generation rapid, scalable, and democratic through machine learning and continuous evolution Project Summary/Abstract It is hard to overstate the importance of monoclonal antibodies in the life sciences. Antibodies are critical tools in biomedical research and diagnostics (e.g. western blotting, immunoprecipitation, cytometry, biomarker discovery, and histology), are one of the most rapidly growing class of therapeutics, and are the basis for myriad new strategies in cancer therapy, such as checkpoint inhibitors that are revolutionizing treatment. Unfortunately, current methods for the generation of custom antibodies, including animal immunization and phage display, are slow, costly, inaccessible to most researchers, and often unsuccessful. We propose Autonomously EvolvinG Yeast-displayed antibodieS (AEGYS), a system for the continuous and rapid evolution of high-quality antibodies against custom antigens that requires only the simple culturing of yeast cells. We believe this can be achieved by combining cutting-edge generative machine learning algorithms for antibody library design with a new technology for in vivo continuous evolution and a yeast antigen-presenting cell that we will engineer. If successful, AEGYS should have a transformative impact across the whole of biomedicine by turning monoclonal antibody generation into a rapid, scalable, and accessible process where any lab with standard molecular biology capabilities can generate custom antibodies on demand simply by “immunizing” a test tube of yeast cells with an antigen. We anticipate that this democratization of antibody generation will also result in an explosion of crowdsourced antibody sequence data that will train our machine learning algorithms to design better antibody libraries for AEGYS, starting a virtuous cycle. We ourselves will use AEGYS to generate a panel of subtype- and conformation-specific nanobodies against biogenic amine receptors including those that respond to acetylcholine, adrenaline, dopamine, and other neurotransmitters, so that we can understand their role in neurobiology and addiction.! Project Narrative This proposal will provide a system for the scalable continuous evolution and computational design of antibodies against user-selected antigens. Antibodies are critical tools in medical research and are the basis for numerous therapies, but the generation of custom antibodies against new targets is a difficult and specialized task. The system proposed will turn antibody generation into a routine and widely accessible process for researchers in almost any field.","Making antibody generation rapid, scalable, and democratic through machine learning and continuous evolution",10021311,R01CA260415,"['Acetylcholine', 'Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antibody Formation', 'Antigen Targeting', 'Antigen-Presenting Cells', 'Antigens', 'Architecture', 'Area', 'Back', 'Biogenic Amine Receptors', 'Biological Sciences', 'Biomedical Research', 'Cell Surface Receptors', 'Cells', 'Chemistry', 'Clinic', 'Collection', 'Communities', 'Cultured Cells', 'Custom', 'Cytometry', 'Data', 'Data Set', 'Detergents', 'Diagnostic', 'Directed Molecular Evolution', 'Docking', 'Dopamine', 'Elements', 'Engineering', 'Epidemic', 'Epinephrine', 'Evolution', 'Explosion', 'G-Protein-Coupled Receptors', 'Generations', 'Genes', 'Genetic', 'Histology', 'Human', 'Hybridomas', 'Image', 'Immune checkpoint inhibitor', 'Immune system', 'Immunization', 'Immunize', 'Immunoglobulin Fragments', 'Immunoprecipitation', 'Libraries', 'Machine Learning', 'Medical Research', 'Medicine', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Monoclonal Antibodies', 'Neuraxis', 'Neurobiology', 'Neurosciences', 'Neurotransmitters', 'Nobel Prize', 'Outcome', 'Pathogen detection', 'Phage Display', 'Pharmaceutical Preparations', 'Pheromone', 'Play', 'Problem Solving', 'Process', 'Production', 'Protein Engineering', 'Proteins', 'Proteome', 'Public Health', 'Reagent', 'Research', 'Research Personnel', 'Role', 'Signal Transduction', 'Specificity', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Studies', 'Training', 'Tube', 'Update', 'V(D)J Recombination', 'Western Blotting', 'Yeasts', 'addiction', 'antibody engineering', 'antibody libraries', 'antigen binding', 'base', 'biomarker discovery', 'cancer therapy', 'cost', 'crowdsourcing', 'decision research', 'design', 'empowered', 'experimental study', 'follow-up', 'improved', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'nanobodies', 'new technology', 'novel', 'receptor', 'response', 'scaffold', 'structural biology', 'tool']",NCI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2020,1690552,-0.02619252689898598
"Computational ontology of brain systems across the human neuroimaging literature Project Summary/Abstract Symptom-based diagnoses of mental illness are highly comorbid, biologically heterogeneous, and poorly predictive of treatment response. The National Institute of Mental Health has led efforts to redefine mental illness by its biological causes, establishing the Research Domain Criteria (RDoC) framework as a guide for investigating variation in basic brain systems. RDoC has been influential, named in hundreds of grants and publications, but it has yet to be systematically validated. It is unknown whether circuit-function links underlying the RDoC brain systems are reproducible across studies, and organizing principles remain largely untested. While the structure of RDoC as a modular hierarchy has evidence in resting state analyses, it has not been shown whether this applies to systems that support the diverse mental states affected in psychiatric disease. It is necessary to validate RDoC, and moreover, to establish fundamental principles of organization for systems defined jointly by human brain structure and function. The objective of this proposal is to apply large- scale computational neuroimaging meta-analyses to build a data-driven ontology that will not only serve as a benchmark in evaluating the validity of RDoC but also characterize the architecture of systems for human brain function. The long-term goal is to redefine mental illness by differences from healthy function within the brain systems of a data-driven ontology, facilitating rational targeting of neuromodulation treatments. The proposed meta-analyses will be the most comprehensive in the field with 18,155 MRI and PET studies already collected. The mental functions considered in these studies have been extracted from article texts using natural language processing, and brain circuits will be mapped from the brain coordinate data that were reported. The hypothesis is that brain systems are comprised of reproducible circuit-function links organized into a modular hierarchy, which for some systems will require updates to RDoC. This will be tested by comparing RDoC systems against those of a data-driven ontology. Aim 1: The reproducibility of circuit-function links will be evaluated by the performance of neural network classifiers predicting functions in article texts from circuits in brain scan data, and vice versa. Aim 2: The modularity of brain systems will be evaluated by a graph theoretic approach, and hierarchical structure will be assessed by representational similarity analysis. The impact of this project will be to validate the foremost psychiatry research framework and to characterize human brain systems through an innovative computational strategy. Together with targeted academic training in neurobiology, the fellowship is designed to offer preparation for a career as a physician-scientist leading advances in computational psychiatry. Training will be supported by an environment that combines world-class computing resources with esteemed and engaged mentors in psychiatry, neuroscience, and computer science. Project Narrative First-line treatments routinely fail for most of the 45 million US adults living with mental illness because psychiatric diagnoses lack a biological basis, making them unreliable predictors of treatment response. The proposed project will lay the foundation for a biologically based diagnostic system in psychiatry by characterizing the composition and structure of human brain systems through innovative computational meta-analyses of nearly 20,000 neuroimaging articles. When it is understood what makes up a brain system and how systems are organized, mental illness can be redefined by variation from healthy function, facilitating successful targeting of brain-based treatments.",Computational ontology of brain systems across the human neuroimaging literature,9991669,F30MH120956,"['Academic Training', 'Adult', 'Affect', 'Base of the Brain', 'Benchmarking', 'Biological', 'Biology', 'Brain', 'Brain region', 'Brain scan', 'Cognitive', 'Custom', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Emotional', 'Environment', 'Expert Opinion', 'Fellowship', 'Foundations', 'Goals', 'Grant', 'Graph', 'Higher Order Chromatin Structure', 'Human', 'Individual', 'Influentials', 'Link', 'Literature', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mental disorders', 'Mentors', 'Meta-Analysis', 'Modeling', 'Names', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Ontology', 'Pattern', 'Performance', 'Physicians', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Preparation', 'Psychiatric Diagnosis', 'Psychiatry', 'Publications', 'Reporting', 'Reproducibility', 'Research', 'Research Domain Criteria', 'Resources', 'Rest', 'Scheme', 'Scientist', 'Sensitivity and Specificity', 'Site', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Text', 'Training', 'Update', 'Variant', 'Work', 'base', 'brain circuitry', 'career', 'clinically relevant', 'comorbidity', 'computer science', 'computerized tools', 'computing resources', 'deep learning', 'design', 'improved', 'innovation', 'learning strategy', 'mental function', 'mental state', 'neural network classifier', 'neuroimaging', 'neuroinformatics', 'neuroregulation', 'predictive modeling', 'social', 'system architecture']",NIMH,STANFORD UNIVERSITY,F30,2020,37706,-0.01292252201473841
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10044301,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,929399,-0.02690512293845972
"Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery PROJECT SUMMARY / ABSTRACT Closed or open fracture reduction and internal fixation is the standard surgical approach in treating pelvic fractures, with current clinical practice using fluoroscopic guidance, guidewire insertion, and cannulated screw placement. The challenge in reckoning complex 3D morphology in 2D fluoroscopy presents a major source of uncertainty, trial-and- error, and poor outcomes, with 20-30% rate of suboptimal screw placement and long fluoroscopic runtime (mean fluoro time > 123 s) exposing operating personnel to high levels of radiation exposure. Despite these challenges, mainstream surgical approach has remained largely unchanged for 35 years, and surgical navigation systems (though increasingly common in neurosurgery) present cost and workflow barriers that limit their broad applicability in trauma surgery. We propose a computer vision-based navigation approach that is compatible with routine trauma surgery workflow, offers real-time guidance with accuracy comparable to stereotactic navigation, gives ten-fold reduction in radiation exposure, and works with tools already common in the trauma surgery arsenal. The proposed system uses a miniature stereoscopic camera mounted onboard the surgical drill in combination with 3D-2D registration of fluoroscopic views for direct, real-time registration of the instrument trajectory relative to patient anatomy. Real-time overlay of instrument trajectory in fluoroscopic views and/or CT permits accurate identification of guidewire entry point, orientation, and conformance within bone corridors and will reduce reliance on “fluoro hunting” and trial-and-error guidewire placement. The following aims develop and evaluate the system for application in pelvic trauma surgery, including quantitative assessment of accuracy, workflow, and radiation dose in pre-clinical studies. Aim 1. System for computer vision-based guidance in trauma surgery. The hardware and software components required for vision-based tracking onboard a standard surgical drill will be developed, providing real-time trajectory overlay in fluoroscopy and/or preoperative CT. A fast calibration method will be developed for automatic drill axis calibration. Automatic feature-based registration of the video and fluoroscopic frames enables real-time overlay of instrument trajectory in fluoroscopic views (Fluoro Navigation), and 3D-2D registration between CT and fluoroscopy will enable real-time overlay of the instrument trajectory in CT (CT Navigation). Aim 2: Evaluation in preclinical studies. The vision-based navigation system will be implemented in pre-clinical (cadaver) experiments to evaluate accuracy and workflow. These studies will evaluate the geometric accuracy and workflow factors relating to the number of repeated insertion attempts, procedure time, and radiation dose, evaluating vision-based Fluoro Navigation and CT Navigation in comparison to conventional freehand fluoroscopy guidance. Successful completion of the aims will establish a system suitable for computer vision-based navigation to be translated to clinical studies in future work. Such a system offers a potentially major advance in routine trauma surgery, bringing capabilities comparable to state-of-the-art stereotactic navigation without the cost, complexity, and additional workflow of conventional navigation. PROJECT NARRATIVE Even experienced trauma surgeons are challenged in resolving the complex 3D morphology of the pelvis in 2D x-ray fluoroscopy, presenting a major source of uncertainty, a high rate of malpositioned screws, and high levels of radiation exposure to the patient and operating staff. To facilitate high-precision pelvic trauma surgery and reduce intraoperative radiation dose, we propose a computer vision-based navigation approach providing real-time overlay of surgical instrument trajectories in fluoroscopic views and CT, facilitating accurate identification of guidewire entry point, orientation, and conformance within safe bone corridors. The approach offers a major advance compared to conventional navigation by not requiring intraoperative 3D imaging, avoiding time-consuming calibration, and eliminating externally-positioned hardware in the operating room, and the proposed research translates the system from basic development and quantitative testing to preclinical studies evaluating geometric accuracy, workflow, and radiation dose.",Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery,10005337,R21EB028330,"['3-Dimensional', '3D Print', 'Affect', 'Anatomy', 'Biopsy', 'Cadaver', 'Calibration', 'Clinical Research', 'Closed Fractures', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Ensure', 'Evaluation', 'Exposure to', 'Fluoroscopy', 'Fracture', 'Future', 'Healthcare', 'High Prevalence', 'Hour', 'Human Resources', 'Image', 'Incidence', 'Mainstreaming', 'Methods', 'Morphology', 'Navigation System', 'Needles', 'Open Fractures', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Outcome', 'Patients', 'Pelvis', 'Persons', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation exposure', 'Research', 'Roentgen Rays', 'Source', 'Structure', 'Surgeon', 'Surgical Instruments', 'System', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Translating', 'Translations', 'Trauma', 'Uncertainty', 'Visceral', 'Vision', 'Work', 'base', 'bone', 'clinical practice', 'comorbidity', 'cortical bone', 'cost', 'disability', 'experience', 'experimental study', 'improved', 'instrument', 'instrumentation', 'mortality', 'neurosurgery', 'neurovascular', 'pelvis fracture', 'pre-clinical', 'preclinical study', 'sample fixation', 'socioeconomics', 'stereoscopic', 'tool', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,204688,-0.020321118442170667
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,-0.03708207402861305
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Abstract COVID-19 has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. Accordingly, the goal of this COVID Supplement, which builds on and expands the work being conducted by the parent grant, is to develop a COVID map tool that provides fully accessible, non-visual access to maps. This tool will allow visually impaired persons to explore maps and preview routes from the comfort of their home, allowing them to plan their travel along safer, less congested routes using crowdedness data. In addition, the tool will present county-by-county COVID incidence data in a fully accessible form, which will inform their travel plans over greater distances. Thus, this project will give visually impaired persons the tools and confidence to undertake safer, more independent travel. Health Relevance The COVID-19 pandemic has an especially severe impact on people with significant vision impairments or blindness. The need for social distancing and reduced touching of one’s surroundings has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. These travel limitations may have adverse impacts on their physical and mental health. The proposed research would result in a new software tool that could greatly increase the confidence of the approximately 10 million Americans with significant vision impairments or blindness to undertake safe, independent travel.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10220178,R01EY029033,"['American', 'Blindness', 'COVID-19', 'COVID-19 pandemic', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'County', 'Crowding', 'Data', 'Destinations', 'Development', 'Ensure', 'Evaluation', 'Exercise', 'Goals', 'Health', 'Home environment', 'Incidence', 'Internet', 'Knowledge', 'Leisures', 'Maps', 'Mental Health', 'Pharmacy facility', 'Process', 'Publications', 'Research', 'Route', 'Running', 'Social Distance', 'Software Tools', 'System', 'Tablets', 'Tactile', 'Target Populations', 'Touch sensation', 'Travel', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'blind', 'braille', 'coronavirus disease', 'design', 'outreach', 'pandemic disease', 'parent grant', 'physical conditioning', 'software development', 'symposium', 'tool', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,406525,0.018550310238426793
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,9961522,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2020,15000,-0.004313735509508479
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9857605,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2020,145891,-0.01638146300395064
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,10078697,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Award', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Parents', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'intelligent algorithm', 'learning algorithm', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'smart watch', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2020,64079,0.005651265757652092
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,-0.009609193190788314
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9989186,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,749716,-0.011846697330784205
"Dynamics of long range network interactions  in focal epilepsy PROJECT SUMMARY Epilepsy is the world’s most prominent serious brain disorder, affecting nearly 50 million people worldwide. For about 30% of these patients, seizures remain poorly controlled despite optimal medical management, with attendant effects on health and quality of life. In order to enable advances in the therapeutic management of epilepsy, a thorough understanding of how cellular processes that drive seizures are linked to large-scale network effects is needed. While seizures impact large brain areas and often multiple lobes, the driving processes span regions on the scale of millimeters. These have been well characterized in animal models, but the relevance to human seizures, i.e. how seizures are driven by brain signals from small-scale processes remains unclear. Instead, the view that naturally-occurring seizures may be attributable instead to large-scale neural mass effects (i.e., the epileptic network) is a subject of ongoing debate. Previously, we defined a key role for surround inhibition in shaping EEG recordings of seizures at the onset site and on small spatial scales. We now propose that surround inhibition has a dual role. On a millimeter scale, its abrupt failure permits the advance of a seizure. At long distances from the seizure focus, strong local inhibition serves to mask the excitatory effects of seizures and may help to hasten seizure termination, while weakened inhibition may permit emergence of ictal activity at a distant, noncontiguous seizure site. Multiple seizure foci may go unrecognized with standard EEG interpretation methods, and are likely a critical factor in epilepsy surgery failures. We hypothesize that once established, multiple ictal generators behave as delay-coupled oscillators, demonstrating activity that is synchronized or even temporally reversed. This results in complex and at times counterintuitive network behavior that can be challenging to reverse engineer from EEG recordings. Typically, however, even intracranial EEG recordings provide only a limited view of neural activity. In this project, an interdisciplinary research group with combined expertise in epilepsy, clinical neurophysiology, computational modeling, and mathematics will conduct a comprehensive study of the neuronal contributors to epileptic networks utilizing a unique combined dataset of simultaneous microelectrode and macroelectrode recordings of human seizures. Using a machine learning approach, we will apply this information to develop a multivariate EEG biomarker based on the inferred source of EEG discharges, high frequency oscillations, and very low frequency (DC) shifts and assess its predictive value for post-resection surgical outcome. We anticipate that the project will lead to a theoretical framework for rational development of innovative strategies for developing interventions to control seizures. PROJECT NARRATIVE This project aims to identify the cellular mechanisms of epileptic networks, a critical barrier to developing treatments based on epileptic network analysis and manipulation. An interdisciplinary team of researchers will address this problem by analyzing and modeling multiscale voltage data from epilepsy patients, and utilizing the results to develop a new multivariate biomarker for seizure-generating brain areas.",Dynamics of long range network interactions  in focal epilepsy,9972766,R01NS084142,"['Address', 'Affect', 'Animal Model', 'Area', 'Automobile Driving', 'Award', 'Behavior', 'Biological Markers', 'Biophysics', 'Brain', 'Brain Diseases', 'Cell physiology', 'Clinical', 'Collection', 'Complement', 'Complex', 'Computer Models', 'Coupled', 'Data', 'Data Set', 'Decision Making', 'Development', 'Distant', 'Electroencephalography', 'Electrophysiology (science)', 'Engineering', 'Epilepsy', 'Event', 'Excision', 'Failure', 'Focal Seizure', 'Foundations', 'Frequencies', 'Generations', 'Goals', 'Health', 'High Frequency Oscillation', 'Human', 'Impact Seizures', 'In Vitro', 'Incidence', 'Interdisciplinary Study', 'Intervention', 'Link', 'Lobe', 'Location', 'Machine Learning', 'Masks', 'Mathematics', 'Medical', 'Methods', 'Microelectrodes', 'Monitor', 'Neurons', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Pathologic', 'Pathway Analysis', 'Patients', 'Predictive Value', 'Procedures', 'Process', 'Quality of life', 'Research Personnel', 'Role', 'Sampling', 'Seizures', 'Shapes', 'Signal Transduction', 'Site', 'Source', 'Specificity', 'Study models', 'Techniques', 'Terminology', 'Testing', 'Therapeutic', 'Time', 'Travel', 'Universities', 'Weight', 'base', 'improved', 'innovation', 'millimeter', 'minimally invasive', 'multi-scale modeling', 'neurophysiology', 'parallel computer', 'relating to nervous system', 'support vector machine', 'surgery outcome', 'voltage']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,615913,-0.013778479939248502
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,9887973,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2020,496911,-0.010752601675357553
"Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled Iifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. n/a",Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry,10023190,R01GM135927,"['Accelerometer', 'Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Behavior monitoring', 'Behavioral', 'Big Data', 'Cellular Phone', 'Classification', 'Coupled', 'Data', 'Data Analyses', 'Development', 'Devices', 'Diabetes Mellitus', 'Elements', 'Generations', 'Geometry', 'Goals', 'Growth', 'Harvest', 'Health', 'Home environment', 'Hour', 'Human Activities', 'Intervention', 'Life', 'Location', 'Machine Learning', 'Mathematics', 'Measurement', 'Modeling', 'Observational Study', 'Outcome', 'Pattern', 'Periodicity', 'Physical activity', 'Process', 'Regimen', 'Research', 'Research Activity', 'Sampling', 'Series', 'Stroke', 'Techniques', 'Technology', 'Time', 'Work', 'base', 'heart rate monitor', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'machine learning algorithm', 'mathematical algorithm', 'mathematical sciences', 'multimodality', 'sensor', 'signal processing', 'statistics', 'tool', 'wearable device']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,311680,-0.003341293866033119
"Nobrainer: A robust and validated neural network tool suite for imagers There is an increasing need for efficient and robust software to process, integrate, and offer insight across the diversity of population imaging efforts underway across the BRAIN Initiative and other projects. Advances in statistical learning offer a set of technologies that can address many research applications using the extensive and varied data being produced by the projects. This can transform how we analyze and integrate new data. We propose using Nobrainer, an open source Python library that leverages these new learning technologies, as a platform that greatly simplifies integrating deep learning into neuroimaging research. Using this library, we are building and distributing user-friendly and cloud enabled end-user applications for the neuroimaging community. In Aim 1, we provide neural network models. We will create robust, pre-trained neural networks for brain segmentation and time series processing using brain scans from over 65000 individuals. Once trained, these models can then be used as the basis for many other applications, especially in reducing time of processing. We will subsequently use these base networks to perform image processing, image correction, and quality control. In Aim 2, we address the ability to train on private datasets. We will use Bayesian neural network models, which support principled use of prior information. We will use these networks to help detect when the models are expected to fail on an input, and provide visualizations to better understand how the model is working. In Aim 3, we focus on the engineering needed to maintain the software infrastructure, improve efficiency, and increase the scalability of our training methods. Here, we will extend, maintain, and disseminate Nobrainer, our open source software framework, together with training materials and ready to use, cloud-friendly, applications. We will also create much faster, neural network equivalents of time consuming image processing tasks (e.g., registration, segmentation, and annotation). The Nobrainer tools developed through these aims will allow users to find and apply the most pertinent applications and developers to extend the framework to support new architectures and disseminate new models and applications. We expect these tools to be used by any neuroimaging researcher through integration with BRAIN archives and popular software packages. These tools will significantly reduce data processing and new model development time, thus allowing faster exploration of hypotheses using public data and increase reusability of data through greater trust in model outputs. 9/11/2019 ResearchPlan - Google Docs The proposal will create artificial intelligence software for scientists to analyze, integrate, and visualize data from large brain imaging projects, which inform our understanding of brain structure, function, and development. Open and reusable software helps to increase collaboration and benefits researchers, but can also be used by citizen scientists and students in high schools and colleges. An open collection of neural network tools will facilitate scientific communities and has the potential to accelerate scientific discoveries about the nervous system. https://docs.google.com/document/d/11s9ZRzy8tHs6NguzpnJdJUWRgLvdkXpEYjZchtJXSmY/edit# 2/23",Nobrainer: A robust and validated neural network tool suite for imagers,10021957,RF1MH121885,"['Address', 'Adolescent', 'Architecture', 'Archives', 'Artificial Intelligence', 'BRAIN initiative', 'Bayesian neural network', 'Brain', 'Brain imaging', 'Brain scan', 'Cognitive', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Disease', 'Educational workshop', 'Engineering', 'Ethics', 'Evaluation', 'Failure', 'Human', 'Image', 'Individual', 'Informatics', 'Institution', 'Label', 'Learning', 'Legal', 'Libraries', 'Longevity', 'Memory', 'Mental Health', 'Methods', 'Modeling', 'Nervous system structure', 'Network-based', 'Neural Network Simulation', 'Output', 'Pattern', 'Population', 'Population Heterogeneity', 'Privacy', 'Privatization', 'Process', 'Psychological Transfer', 'Pythons', 'Quality Control', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Series', 'Software Engineering', 'Software Framework', 'Structure', 'Students', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Training Support', 'Trust', 'Uncertainty', 'Visualization', 'Work', 'algorithm training', 'base', 'citizen science', 'cognitive development', 'college', 'computerized data processing', 'connectome', 'data reuse', 'deep learning', 'distributed data', 'diverse data', 'high school', 'image processing', 'imager', 'improved', 'insight', 'large datasets', 'learning strategy', 'model development', 'network models', 'neural network', 'neuroimaging', 'neurophysiology', 'open source', 'software infrastructure', 'statistical learning', 'tool', 'user-friendly']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,RF1,2020,419908,0.0005750425069124738
"Learning high-dimensional functional connectomes of heterogeneous populations PROJECT SUMMARY Network analysis of brain connectivity, or Connectomics, has emerged as an important interdisciplinary field, making strides in advancing both fundamental scientific knowledge on the structure of the brain, as well as providing insights into the pathology of neurological disorders. Advances in neuroimaging technologies have enabled acquisition of high-resolution datasets on brain activities in normal and diseased populations, while advanced machine learning methods hold promise to obtain data-driven insights into the functional architecture of the brain. Functional connectivity analysis is typically carried out in two steps. First, one estimates a network among different brain regions by studying strengths of associations among the time course of neurophysiological signals for different subjects (patients or healthy controls). Next, one compares the networks between different groups of subjects and seeks network features prevalent in specific groups of interest using statistical methods. Two emerging challenges in this field are the presence of heterogeneity amongst subjects in large study cohorts, and developing predictive models to construct robust and interpretable results. The central goal of this proposal is to address these challenges by developing machine learning methods equipped with uncertainty quantification measures, suitable for high-dimensional network data for heterogeneous populations. Upon completion, these methods are expected to provide automated, robust and more accurate discovery of connectivity patterns that is prevalent in heterogeneous populations of patients. We aim to accomplish this goal by pursuing two specific aims: (1) develop estimation and inference methods for frequency domain measures of high-dimensional functional connectivity networks, (2) develop a framework of mixed effects model of high-dimensional functional connectivity networks that accounts for heterogeneity among subjects and enables discoveries more likely to generalize in large cohorts. For each aim, novel machine learning methods for integrative analysis of structural and functional connectivity will be developed using a mathematical model of network diffusion. We will also calibrate and validate our proposed methods on data from Human Connectome Project, and on multiple sclerosis (MS) patients. The proposed approach is innovative since it integrates machinery across diverse disciplines, including statistics, machine learning and network analysis to address important challenges learning large functional connectivity graphs. The proposed research is significant in that it is expected to have both scientific and translational impact. PROJECT NARRATIVE The proposed research is relevant to public health because understanding brain connectivity patterns using rigorous machine learning methods can help seek common patterns in large databases in an automated fashion, and can potentially lead to development of neuroimaging based diagnostic tools and sensitive prognostic measures. The proposed research will thus use fundamental scientific knowledge about brain to assist translational research in neurological disease.",Learning high-dimensional functional connectomes of heterogeneous populations,10110789,R21NS120227,"['Address', 'Anatomy', 'Architecture', 'Atlases', 'Behavior', 'Benchmarking', 'Biological', 'Brain', 'Brain region', 'Cations', 'Cell Nucleus', 'Cerebral cortex', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Dependence', 'Development', 'Diagnostic', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Discipline', 'Disease', 'Estrogen receptor positive', 'Face', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Graph', 'Health', 'Heterogeneity', 'Human', 'Interest Group', 'Knowledge', 'Lasso', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Nature', 'Neurologic', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Population', 'Population Heterogeneity', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Statistical Methods', 'Structural Models', 'Structure', 'Technology', 'Testing', 'Time', 'Translational Research', 'Uncertainty', 'Visualization', 'Work', 'base', 'brain behavior', 'brain size', 'cognitive neuroscience', 'cognitive process', 'cohort', 'connectome', 'data integration', 'experience', 'help-seeking behavior', 'heterogenous data', 'high dimensionality', 'human data', 'individual patient', 'innovation', 'insight', 'interest', 'learning network', 'machine learning method', 'mathematical model', 'multidimensional data', 'multiple sclerosis patient', 'nervous system disorder', 'network models', 'neuroimaging', 'neurological pathology', 'neuropathology', 'neurophysiology', 'novel', 'open source', 'patient population', 'predictive modeling', 'prognostic', 'skills', 'statistics', 'tool', 'translational impact', 'white matter']",NINDS,CORNELL UNIVERSITY,R21,2020,428417,-0.01096323001765238
"Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry Project Summary The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled lifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. Project Number: 1R01GM135927-01 Title: Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry Project Narrative In this revision application, we seek to submit an equipment supplement to our existing R01 referenced above. As our project progressed, we found that it is important to consider the role of new emerging feature-learning approaches to extract downstream time-series features. To fully develop our approach and conduct additional experiments, we need significant GPU computational resources that will be dedicated to this project.",Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry,10135658,R01GM135927,"['Accelerometer', 'Address', 'Adopted', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Awareness', 'Behavior', 'Behavior Therapy', 'Behavior monitoring', 'Behavioral', 'Big Data', 'Cellular Phone', 'Classification', 'Coupled', 'Data', 'Data Analyses', 'Development', 'Devices', 'Diabetes Mellitus', 'Dimensions', 'Elements', 'Equipment', 'Generations', 'Geometry', 'Goals', 'Growth', 'Harvest', 'Health', 'Home environment', 'Hour', 'Human Activities', 'Intervention', 'Learning', 'Life', 'Location', 'Machine Learning', 'Mathematics', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Observational Study', 'Outcome', 'Pattern', 'Periodicity', 'Physical activity', 'Process', 'Regimen', 'Research', 'Research Activity', 'Role', 'Running', 'Sampling', 'Series', 'Statistical Methods', 'Stroke', 'Supervision', 'Techniques', 'Technology', 'Time', 'Time Series Analysis', 'Validation', 'Walking', 'Work', 'analysis pipeline', 'base', 'computing resources', 'density', 'experimental study', 'heart rate monitor', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'machine learning algorithm', 'mathematical algorithm', 'mathematical sciences', 'multimodality', 'preservation', 'sedentary lifestyle', 'sensor', 'signal processing', 'statistics', 'tool', 'wearable device', 'wearable sensor technology']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,69169,-0.0019454781930536224
"SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions  The project will investigate prosthetic support for people with visual impairment (PVI) that integrates computer vision-based prosthetics with video-mediated human-in-the-loop prosthetics. Computer vision- based (CV) prosthetics construe the fundamental technical challenge for visual prosthetics as one of parsing and identifying objects across scales, distances, and orientations. Visual prosthetic applications have been central drivers in the development of computer vision technology through the past 50 years. Video-mediated remote sighted assistance (RSA) prosthetics are more recent, enabled by different technologies, and construe the orienting technical challenge for visual prosthetics as one of effective helping interactions. RSA services are commercially available now, and have evoked much excitement in the PVI community. The two approaches, CV and RSA, will be successively integrated through a series of increasingly refined Wizard of Oz simulations, and investigate possible synergies between the two approaches. We will employ a human-centered design approach, identifying a set of key assistive interaction scenarios that represent authentic needs and concerns of PVIs, by leveraging our 6-year relationship working directly with our local chapter of the National Federation of the Blind. RELEVANCE (See Instructions): 23.7 million American adults have vision loss; 1.3 million people in US are legally blind. This project addresses a transformational opportunity to enhance human performance and experience, to diversify workplace participation, and to enhance economic and social well-being. n/a",SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions ,10020434,R01LM013330,"['Address', 'Adult', 'American', 'Articulation', 'Back', 'Blindness', 'Communities', 'Computer Vision Systems', 'Computers', 'Data Set', 'Development', 'Economics', 'Emotional', 'Female', 'Goals', 'Human', 'Information Sciences', 'Instruction', 'Mediating', 'Modeling', 'Ocular Prosthesis', 'Performance', 'Prosthesis', 'Route', 'Self-Help Devices', 'Series', 'Services', 'Social Well-Being', 'Technology', 'Time', 'Underrepresented Students', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'design', 'experience', 'graduate student', 'human-in-the-loop', 'learning materials', 'legally blind', 'outreach', 'prototype', 'simulation', 'synergism', 'undergraduate student']",NLM,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2020,229482,0.010332293012671544
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,10004013,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistical and machine learning', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2020,239423,0.012062994319409309
"Advancing Secondary Data Analysis: the ENIGMA Brain Injury Data Harmonization Initiative Project Summary/Abstract Traumatic brain injury (TBI) is a major public health issue globally, and while neuroimaging has been useful in understanding disruption in brain structure and function after injury, there are a number of factors that attenuate its prognostic ability. For example, there is tremendous heterogeneity in outcome after injury which is only partially explained by injury severity. Cost frequently limits sample size in neuroimaging studies, yet given the myriad factors that have been shown to influence patient outcome (age, injury severity, socioeconomic status), small samples and mass univariate testing often result in many studies being grossly under-powered. One solution is to combine data and create novel data sharing platforms, and the Enhancing Neuroimaging Genetics through Meta-Analysis (ENIGMA) consortium has supported this kind of collaboration for over a decade across a range of clinical disorders. The goal of this proposal is to develop tools and data processing procedures for use in the ENIGMA Brain Injury working group. In the R61 phase, we aim to develop and test a workflow for harmonized processing of behavioral data (Aim 1) as well as structural and functional (resting-state) MRI data (Aim 2). For Aim 1 of the R61, the goal is to offer a decision tree of procedures that is data-dependent, allowing investigators to establish common cognitive endpoints across cohorts that collect a range of neuropsychological and clinical measures. This proposal will create sharable procedures, flexible tools, and generalizable guidelines for best practices for extracting common cognitive endpoints from distinct behavioral test batteries (R61 Aim 1). In Aim 2 of the R61, we develop an image processing pipeline called Harmonization and Aggregation for Functional and structural imaging data PIPEline; HAF-PIPE) that allows for aggregation of non-equivalent imaging data. A primary goal is to decentralize ComBat, an open-source data harmonization tool, so that it can be used in a virtual sharing environment. Following satisfaction of the R61 Go/No-Go criteria, which is the curation of the dataset including 13 cohorts, extraction of common cognitive endpoints, and creation of HAF- PIPE, we will move to the R33 phase. In the R33 phase, we will leverage the large, harmonized dataset and apply a machine learning technique (CorEx - Correlation Explanation) to identify patient clusters within each patient population studied. HAF-PIPE and the procedures and guidelines from the R61 phase will then be extended to additional patient populations and made available to other ENIGMA working groups. The harmonized data, along with the tools and procedures for creating them, will be accessible to researchers following proposal submission and approval as a curated dataset. With success, this proposal holds the promise of significantly advancing data curation, harmonization, and sharing in the clinical neurosciences. We anticipate that our proposal will significantly advance our understanding of factors that impact outcome after injury and will yield a tool that will be useful across the neuroimaging community. Project Narrative Traumatic brain injury (TBI) can cause widespread alteration in brain structure and function, but sample size in imaging studies is often limited, and differences in data acquisition and variables can create obstacles to data sharing. We propose to develop an open-source workflow for utilizing behavioral and MRI data that addresses these concerns and allows for harmonization across sites, supporting “big data” analyses that can identify clinically-meaningful patient subgroups in TBI, a goal that is not feasible with small datasets. Achieving the proposed Aims will make a curated and harmonized dataset available to the TBI community as well as procedures and data processing pipelines adaptable to other disorders in the clinical neurosciences.",Advancing Secondary Data Analysis: the ENIGMA Brain Injury Data Harmonization Initiative,10129715,R61NS120249,"['Address', 'Age', 'Archives', 'Attenuated', 'Behavioral', 'Big Data', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Calibration', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Collection', 'Data Set', 'Decentralization', 'Decision Trees', 'Development', 'Disease', 'Environment', 'Epilepsy', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Guidelines', 'Heterogeneity', 'Image', 'Informatics', 'Injury', 'International', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Mental Depression', 'Meta-Analysis', 'Modeling', 'Neuronal Plasticity', 'Neuropsychology', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Population Study', 'Post-Traumatic Stress Disorders', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Quality Control', 'Research', 'Research Personnel', 'Rest', 'Sample Size', 'Sampling', 'Science', 'Severities', 'Site', 'Socioeconomic Status', 'Standardization', 'Stream', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'base', 'behavior test', 'behavioral construct', 'clinical heterogeneity', 'cohort', 'collaborative environment', 'combat', 'computerized data processing', 'cost', 'data acquisition', 'data analysis pipeline', 'data curation', 'data harmonization', 'data ingestion', 'data pipeline', 'data quality', 'data sharing', 'design', 'flexibility', 'heterogenous data', 'image processing', 'imaging study', 'insight', 'multimodal data', 'neuroimaging', 'novel', 'open data', 'open source', 'patient population', 'patient subsets', 'portability', 'prognostic value', 'response', 'satisfaction', 'sharing platform', 'stroke recovery', 'success', 'tool', 'virtual', 'virtual environment', 'working group']",NINDS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R61,2020,1015434,-0.008947643951249602
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,9914136,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Detection', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'disability', 'geometric structure', 'in vivo', 'lymphatic circulation', 'lymphatic vasculature', 'lymphatic vessel', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,540520,-0.07298530595871174
"Continued Development of Infant Brain Analysis Tools Continued Development of Infant Brain Analysis Tools Abstract: The increasing availability of infant brain MR images, such as those that will be collected through the Baby Connectome Project (BCP, on which Dr. Shen is a Co-PI, focusing on data acquisition), affords unprecedented opportunities for precise charting of dynamic early brain developmental trajectories in understanding normative and aberrant growth. However, to fully benefit from these datasets, a major barrier that needs to be overcome is the critical lacking of computational tools for accurate processing and analysis of infant MRI data, which typically exhibit poor tissue contrast, large within tissue intensity variation, and regionally-heterogeneous and dynamic changes. To fill this critical gap, in 2012 we pioneered in creating an infant-centric MRI processing software package, called infant Brain Extraction and Analysis Tool (iBEAT), and a set of infant-specific atlases, called UNC 0-1-2 Infant Atlases, and further made them freely and publicly available via NITRC. Over the last 4 years, iBEAT and UNC 0-1-2 Infant Atlases have been downloaded 2900+ and 5600+ times, respectively, and contributed to 160+ independent research papers. As indicated by 30+ support letters, iBEAT is now driving the research for MRI studies of early brain development in many labs throughout the world. Results produced by iBEAT are also highlighted in the National Institute of Mental Health (NIMH)'s 2015-2020 Strategic Plan. This project is dedicated to the continuous development, hardening, and dissemination of iBEAT, by developing innovative software modules with comprehensive user support. To achieve this goal, we propose four aims. In Aim 1, we will create an innovative learning-based multi-source information integration framework for joint skull stripping and tissue segmentation for accurate structural measurements. Our method employs random forest to adaptively learn the optimal image appearance features from multimodality images and also informative context features from tissue probability maps. In Aim 2, we will construct longitudinal infant brain atlases at multiple time points (i.e., 1, 3, 6, 9, and 12 months of age) for both T1-/T2-weighted and diffusion-weighted MR images. We propose a longitudinally-consistent sparse representation technique to construct representative atlases with significantly improved structural details by explicitly dealing with possible misalignments between images even after registration. In Aim 3, we will develop a novel learning-based approach for cortical topology correction and integrate it, along with our infant-centric analysis tools and atlases for cortical surfaces, into iBEAT for precise mapping of dynamic and complex cortical changes in infants. Unlike existing tools that perform poorly for infant brains, we will incorporate infant-dedicated tools for topology correction, surface reconstruction, registration, parcellation, and measurements. We will further integrate longitudinal infant cortical surface atlases equipped with parcellations based on growth trajectories. In Aim 4, we will significantly enhance iBEAT in terms of its software functionalities as well as user support via systematic outreach and training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC. Project Narrative This project is dedicated to the continuous development, hardening, and dissemination of iBEAT by developing innovative software modules with comprehensive user support. In particular, we propose four aims: 1) Learning-Based Brain Segmentation; 2) Infant Brain Atlases in the First Year of Life; 3) Cortical Surface-Based Analysis; and 4) Enhancing User Experience and Training. Finally, we will employ iBEAT to process all imaging data from BCP and will release both the iBEAT software package and the processed BCP data to the public via NITRC.",Continued Development of Infant Brain Analysis Tools,9919645,R01MH117943,"['2 year old', 'Address', 'Adult', 'Age', 'Age-Months', 'Appearance', 'Atlases', 'Automobile Driving', 'Base of the Brain', 'Brain', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Documentation', 'Education and Outreach', 'Environment', 'Exhibits', 'Goals', 'Growth', 'Human', 'Image', 'Infant', 'Infant Development', 'Joints', 'Label', 'Learning', 'Letters', 'Life', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Methods', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurodevelopmental Disorder', 'Online Systems', 'Paper', 'Play', 'Probability', 'Process', 'Publications', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Series', 'Shapes', 'Software Tools', 'Source', 'Speed', 'Strategic Planning', 'Structure', 'Surface', 'T2 weighted imaging', 'Techniques', 'Time', 'Tissues', 'Training', 'Variant', 'adaptive learning', 'base', 'computerized tools', 'connectome', 'cranium', 'critical period', 'data acquisition', 'diffusion weighted', 'experience', 'file format', 'gray matter', 'imaging modality', 'imaging study', 'improved', 'innovation', 'interoperability', 'large scale data', 'novel', 'postnatal', 'random forest', 'reconstruction', 'tool', 'white matter']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,465332,-0.013653895468994039
"Nathan Shock Center of Excellence in Basic Biology of Aging OVERALL PROJECT SUMMARY This application is for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington and affiliated institutions. This Center has over the past 25 years provided key resources in support of investigators who study the biology of aging. This application continues a theme that emphasizes outreach and service to the broadest community of investigators in the gerosciences. Of proximal relevance is the characterization of aging-related phenotypes of longevity and healthspan. As our Center services must be easily accessible to outside users, our Longevity and Healthspan Core (Core E) focuses on invertebrate assays, many of them novel. Two other Resources Cores focus on the high dimensional assessments that are closely related to aging phenotypes: Protein Phenotypes of Aging (Core C) and Metabolite Phenotypes of Aging (Core D). Sophisticated computational and bioinformatic tools for data analysis and optimal insight are provided by the Artificial Intelligence and Bioinformatics Core F. Each of these four Resource Cores is led by highly respected experts in that field, including Michael MacCoss and Judit Villen (Core C), Daniel Promislow (Core D), Matt Kaeberlein and Maitreya Dunham (Core E) and Su-In Lee (Core F). Each will push the envelope of appropriate technologies, developing new state-of-the art approaches for assessments that are the most applicable to gerontology and making them accessible to the national aging community. The Research Development Core (Core B) will continue to support pilot and junior faculty studies, with a firm focus on outreach of service to the national geroscience constituency. The Administrative and Program Enrichment Core (Core A) supports administrative management, an external advisory panel, courses, and data sharing and dissemination. Core A’s program of seminars and symposia will continue a focus on sponsorship and organization of national courses, meetings and pre-meetings, as well as workshops in the fields allied to our Resource Core Services. In coordination with other Nathan Shock Centers, we will support a new Geropathology Research initiative. UW NATHAN SHOCK CENTER OVERALL - PROJECT NARRATIVE We apply for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington, which has for 25 years provided key resources supporting investigators who study the biology of aging. The overarching goal of this Center is to have a positive impact on the field by accelerating research discovery and providing research support for investigators nationally and internationally, particularly junior investigators in the process of building their own research programs. We will accomplish this goal through six cores that function synergistically together: four Resource Cores with particular expertise in protein (Core C) and metabolite (Core D) phenotypes of aging, invertebrate longevity and healthspan phenotypes (Core E) and artificial intelligence and bioinformatics (Core F), along with a Research Development Core (Core B) that supports external pilot projects and junior faculty studies, and an Administrative and Program Enrichment Core (Core A) that supports administrative management, an external advisory panel, sponsorship and organization of national meetings and pre-meetings, courses, workshops and seminars, and, in coordination with other Nathan Shock Centers, a Geropathology Research initiative.",Nathan Shock Center of Excellence in Basic Biology of Aging,10042617,P30AG013280,"['Aging', 'Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'Biology of Aging', 'Collaborations', 'Communication', 'Communities', 'Consult', 'Data', 'Data Analyses', 'Development', 'Educational workshop', 'Environment', 'Experimental Designs', 'Faculty', 'Genes', 'Genetic study', 'Gerontology', 'Geroscience', 'Goals', 'Growth', 'Informatics', 'Institution', 'International', 'Invertebrates', 'Leadership', 'Longevity', 'Methodology', 'Methods', 'Microfluidics', 'Molecular Genetics', 'Office of Administrative Management', 'Pathway interactions', 'Phenotype', 'Philosophy', 'Pilot Projects', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteomics', 'Research', 'Research Activity', 'Research Personnel', 'Research Support', 'Resources', 'Robotics', 'Services', 'Shock', 'Statistical Data Interpretation', 'Technology', 'Transcript', 'Universities', 'Variant', 'Washington', 'bioinformatics tool', 'career development', 'cell age', 'computerized tools', 'data dissemination', 'data sharing', 'healthspan', 'high dimensionality', 'insight', 'meetings', 'metabolomics', 'multiple omics', 'novel', 'outreach', 'outreach services', 'programs', 'protein metabolite', 'research and development', 'symposium', 'tool', 'trait']",NIA,UNIVERSITY OF WASHINGTON,P30,2020,962037,-0.008613675528902506
"Multi-Study Integer Programming Methods for Human Voltammery Project Summary/Abstract  The development of treatments for addiction requires the characterization of neural mechanisms underlying reward. Studying reward in humans requires assays that can detect changes in neurotransmitter levels with high chemical specificity. Recently, fast-scan cyclic voltammetry (FSCV) has been implemented in humans to measure dopamine with high temporal and spatial resolution. This technological achievement was enabled in large part through the novel application of machine learning methods. FSCV relies on statistical tools since FSCV records an electrochemical response which must be converted into concentration estimates via a statistical model. The validity of the scientific conclusions from human FSCV studies therefore depends heavily on the reliability of these statistical models to generate accurate dopamine concentration estimates.  In human FSCV, models are fit on in vitro training sets as making in vivo training sets in humans is infeasible. Producing accurate estimates thus requires that models trained on in vitro training sets generalize to in vivo brain recordings. Combining data from multiple training sets is the standard approach human FSCV researchers have employed to improve model generalizability. This proposal extends work that shows that multi-study machine learning methods improve dopamine concentration estimates by combining training sets from different electrodes such that the resulting average signal (“cyclic voltammogram” or CV) is similar to the average CV of the electrode used in the brain. However, this approach relies on random resampling. This is problematic because the randomness limits the extent to which estimate accuracy can be improved and the slow speed of the resampling approach precludes the generation of estimates during data collection, which is critical to experiment success.  This proposal details the development of methods that leverage mixed integer programming to optimally generate training sets that combine data from multiple electrodes. By generating training sets that are specifically tailored to the electrode used for brain measurements, one can vastly improve dopamine concentration estimate accuracy. The speed of the integer programming methods will enable the use of this approach during data collection. This work will include validation of the methods on in vitro data as well as on data from published in vivo and slice experiments in rodents. By applying methods to published optogenetic experiments, one can compare estimates from the proposed methods and from standard methods. The asymptotic properties of the proposed methods will be characterized analytically assuming a linear mixed effects model and empirically through application of the methods to data simulated under this model.  This work will be conducted at the highly collaborative and innovative Harvard School of Public Health. The fellowship will support growth in statistical, computing and collaborative skills, and prepare the trainee for a productive career as a biostatistics professor who develops methods for neuroscience and addiction research. Project Narrative  Fast-scan cyclic voltammetry in humans offers an invaluable tool to study the neural mechanisms underlying reward by allowing for sub-second detection of dopamine during cognitive-behavioral tasks. However, conducting voltammetry in humans presents distinct statistical challenges that must be overcome to ensure optimal dopamine concentration estimates. We propose novel statistical methods that use mixed integer optimization and extend preliminary work that shows multi-study machine learning methods substantially improve dopamine concentration estimate accuracy.",Multi-Study Integer Programming Methods for Human Voltammery,10067624,F31DA052153,"['Achievement', 'Address', 'Algorithms', 'Behavioral', 'Biological Assay', 'Biometry', 'Brain', 'Cells', 'Chemicals', 'Cognitive', 'Complex Mixtures', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Dopamine', 'Electrodes', 'Ensure', 'Fellowship', 'Generations', 'Goals', 'Grant', 'Growth', 'Human', 'In Vitro', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Neurosciences', 'Neurotransmitters', 'Nucleus Accumbens', 'Performance', 'Periodicity', 'Property', 'Public Health Schools', 'Publications', 'Publishing', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Rewards', 'Rodent', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Specificity', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Statistical Models', 'Techniques', 'Training', 'Validation', 'Work', 'addiction', 'algorithm training', 'career', 'effective therapy', 'experimental study', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning method', 'method development', 'multiple data sources', 'neuromechanism', 'novel', 'optogenetics', 'predictive modeling', 'professor', 'relating to nervous system', 'response', 'skills', 'success', 'therapy development', 'tool']",NIDA,HARVARD SCHOOL OF PUBLIC HEALTH,F31,2020,37235,-0.006105944070713755
"Developing Molecular and Computational Tools to Enable Visualization of Synaptic Plasticity In Vivo Project Summary Developing new methodological and analytical tools to address currently insurmountable experimental questions is crucial to the future of neuroscience. While recent advances in two-photon microscopy and activity sensors have revolutionized our understanding of the cellular and circuit basis of behavior, many barriers still exist that preclude fully exploring the molecular basis of these processes in vivo. This is an important question, as modulating synaptic strength is thought to underlie higher brain functions such as learning and memory, whereas synaptic degradation is observed in many neurological pathologies. Despite the clear significance of synaptic communication, a large-scale analysis of how synapses across the brain are distributed and change during learning has not been performed, mainly due to technical difficulties arising from the immensely complex nature of synaptic networks. Here, we present a suite of novel methodologies that breaks through these barriers. Our novel approach leverages CRISPR-based labeling of endogenous synaptic proteins, in vivo two-photon microscopy to visualize fluorescently tagged synapses in behaving animals, and deep-learning-based automatic synapse detection. Using these minimally invasive methods, we will be able to longitudinally track how the strength of millions of individual synapses change during learning. By developing and enabling new strategies to automatically detect and track vast numbers of synapses across entire brain regions, this pioneering approach has the potential to provide us with an unprecedented view of synapses in behaving animals, enabling new discoveries regarding how dynamic regulation of synaptic strength encodes learning and memory. Project Narrative This multi-disciplinary proposal leverages molecular labeling, machine learning, and in vivo microscopy to develop a suite of first-in-class tools to automatically detect synaptic plasticity in intact animals. By employing these novel tools we seek to explain how dynamic modulation of synaptic networks encodes learning and memory. Disruption of synaptic plasticity has been shown to be tightly associated with several neuropsychiatric diseases and the proposed research may reveal novel therapeutic approaches for several disorders including schizophrenia, autism, intellectual disability and Alzheimer's disease.",Developing Molecular and Computational Tools to Enable Visualization of Synaptic Plasticity In Vivo,10009886,RF1MH123212,"['AMPA Receptors', 'Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Area', 'Behavior', 'Behavioral Paradigm', 'Brain', 'Brain region', 'CRISPR/Cas technology', 'Cells', 'Cephalic', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognition', 'Communication', 'Communities', 'Complex', 'Computer Analysis', 'Data Set', 'Detection', 'Disease', 'Ensure', 'Excitatory Synapse', 'Fright', 'Future', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Individual', 'Intellectual functioning disability', 'Investigation', 'Knock-in', 'Knock-in Mouse', 'Label', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Mediating', 'Memory', 'Methodology', 'Methods', 'Microscopy', 'Molecular', 'Molecular Computations', 'Mus', 'Nature', 'Neocortex', 'Neurons', 'Neurosciences', 'Optics', 'Process', 'Proteins', 'Reagent', 'Regulation', 'Research', 'Resolution', 'Role', 'Schizophrenia', 'Shapes', 'Silicon', 'Speed', 'Synapses', 'Synaptic Transmission', 'Synaptic plasticity', 'Techniques', 'Time', 'Training', 'Viral', 'Virus', 'Visualization', 'analytical tool', 'autism spectrum disorder', 'automated algorithm', 'base', 'brain volume', 'calcium indicator', 'cell type', 'computerized tools', 'deep learning', 'density', 'experimental study', 'in vivo', 'in vivo two-photon imaging', 'interest', 'minimally invasive', 'multidisciplinary', 'neurological pathology', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'novel therapeutic intervention', 'open source', 'postsynaptic', 'relating to nervous system', 'sensor', 'synaptic function', 'tool', 'two photon microscopy']",NIMH,JOHNS HOPKINS UNIVERSITY,RF1,2020,1757079,-0.011864067573448236
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning There is an enormous need for qualified people to pursue careers in STEM (Noonan, 2017). However, the lack of a strong foundation in mathematics means students are less likely to pursue STEM majors and careers (Chen, 2013; Griffith, 2010; Huang, Taddese, & Walter, E, 2000; Kokkelenberg & Sinha, 2010; Lowell et. al., 2009). Students from low-income families, women, and underrepresented minorities are also less likely to major in STEM (Bettinger, 2010; Griffith, 2010; Hill, Corbett & Rose, 2010; Kokkelenberg & Sinha, 2010). Improving math learning in the elementary grades is important to ensure children have the essential foundational skills and strong self-efficacy beliefs to be able to succeed with later mathematics and pursue careers in STEM. With this Fast-Track grant, Class Store ( CS ) , we propose to transform the way in which students learn Number and Operations in Base Ten. CS will be an engaging, commercially available, classroom-based economy game for tablets and Chromebooks that focuses on multi-digit operations. CS will encourage conceptual understanding and build math self-efficacy for students in grades K-5 within the context of a digital, classroom-based marketplace. Within the game, students will create stores, craft objects to sell, engage in selling/purchasing transactions, and work together to increase the value of the economy. In addition, the game will utilize artificial intelligence (AI) to detect strategies students use and help teachers facilitate rich mathematical discussions thereby enhancing students’ reasoning skills. Outcomes. The proposal will encourage three main outcomes, namely: 1) algorithms for detecting math strategies students use, 2) a discussion support dashboard, and 3) algorithms for predicting at-risk status. A key research aim is to determine whether the software can predict math strategies students use and detect which students are at-risk academically as compared to standardized assessment data, which will help teachers intervene appropriately. The discussion support dashboard will help to promote rich mathematical discussion, thereby improving students’ mathematical justification and conceptual understanding. The engaging game will bolster students’ motivation and self-efficacy in mathematics. Improving students’ academic outcomes and self-efficacy in base ten during elementary school will promote later success in high school mathematics. Since the number of advanced math classes students take is correlated with likelihood to complete a STEM degree, (Chen, 2013) a distal outcome of this proposal is increasing students pursuing careers in STEM. There is an enormous need for students majoring in the fields of Science, Technology, Engineering and Mathematics (STEM), yet lacking a strong foundation in mathematics makes students, especially women, minorities and those from low-income backgrounds, less likely to pursue careers in STEM. Class Store will bolster students’ mathematics abilities, including mathematical reasoning and self-efficacy, in the foundational area of Number and Operations in Base 10 in the short and long term. This will, in turn, lead to several positive distal outcomes, such as increased STEM majors and careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9889974,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'STEM field', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2020,575531,0.00712518162373308
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10024094,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2020,422740,-0.007998373683279537
"C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative ABSTRACT The BRAIN Initiative is designed to leverage sophisticated neuromodulation, electrophysiological recording, and macroscale neuroimaging techniques in human and non-human animal models in order to develop a multilevel understanding of human brain function. However, the necessary tools for organizing, processing and analyzing neuroimaging data generated through these efforts are not widely available as coherent and easy-to- use software packages. Gaps are particularly apparent for nonhuman data (i.e., monkey, rodent), as most of the existing processing and analytic software packages are specifically designed for human imaging. Methods have been proposed for addressing the challenges inherent to the processing of nonhuman data (e.g., brain extraction, tissue segmentation, spatial normalization, brain parcellation, temporal denoising); to date, these have not been readily integrated into an easy-to-use, robust, and reproducible analysis package. Similarly, many of the sophisticated machine learning and modeling methods developed for neuroimaging analyses are inaccessible to most researchers because they have not been integrated into easy-to-use pipeline software. As a result, translational and comparative neuroimaging researchers patch together neuroinformatics pipelines that use various combinations of disparate software packages and in-house code. We propose to extend the Configurable Pipeline for the Analysis of Connectomes (C-PAC) open-source software to provide robust and reproducible pipelines for functional and structural MRI data. We will integrate the various disparate image processing and analysis methods used to handle the challenges of nonhuman imaging data, into a single, open source, configurable, easy-to-use end-to-end analysis pipeline package that is accessible locally or via the cloud. The end product will not only improve the quality, transparency and reproducibility of nonhuman translational and comparative imaging, but also enable new avenues of scientific inquiry through our inclusion of methods that are yet to be applied to nonhuman imaging data (e.g., gradient- based cortical parcellation methods, hyperalignment). Specific aims of the proposed work include to: 1) Integrate neuroimaging processing and analysis methods optimized for BRAIN Initiative data, 2) Implement strategies for carrying out comparative studies of human and non-human populations, and 3) Extend C-PAC to include cutting-edge analytical strategies for identifying mechanisms of brain function. All development will occur “in the open” using GitHub and other collaborative tools to maximally involve participation in the C-PAC project. Annual hackathons will be held to collaborate with investigators from BRAIN Initiative awards and other neuroinformatics development projects to integrate their tools with C-PAC. Hands-on training will be held to train investigators on optimal use of the newly developed tools. NARRATIVE New neuroimaging analysis software is needed to process and analyze the various human and non-human neuroimaging data collected through the BRAIN Initiative. We will address this need by extending the already mature C-PAC human brain imaging data analysis pipeline to include support for animal data, with a particular focus on providing methods for conducting comparative studies between species. The proposed work will also include a toolbox for helping to align electrophysiological data that is commonly collected in non-human studies, with the brain imaging data.","C-PAC: A configurable, compute-optimized, cloud-enabled neuroimaging analysis software for reproducible translational and comparative",9954159,R24MH114806,"['Address', 'Adoption', 'Anatomy', 'Animal Model', 'Architecture', 'Award', 'BRAIN initiative', 'Brain', 'Brain imaging', 'Capital', 'Code', 'Communities', 'Comparative Study', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Development', 'Documentation', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Funding', 'High Performance Computing', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Outcome', 'Output', 'Pattern', 'Persons', 'Population', 'Process', 'Pythons', 'Readability', 'Reproducibility', 'Research Personnel', 'Rodent', 'Scientific Inquiry', 'Software Design', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validity of Results', 'Work', 'analysis pipeline', 'animal data', 'base', 'behavioral phenotyping', 'cloud based', 'comparative', 'computing resources', 'connectome', 'cost', 'data analysis pipeline', 'data sharing', 'data structure', 'denoising', 'design', 'flexibility', 'graphical user interface', 'hackathon', 'human imaging', 'image processing', 'improved', 'investigator training', 'learning strategy', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuroregulation', 'open source', 'software as a service', 'structured data', 'supervised learning', 'tool', 'unsupervised learning']",NIMH,"CHILD MIND INSTITUTE, INC.",R24,2020,545239,0.015067162291622202
"Intelligent connectomic analysis tool for dense neuronal circuits Intelligent Connectomic Analysis Tool for Dense Neuronal Circuits Project Summary: The lack of basic understanding of neuronal functions and disease processes is a big factor of failures in creating drugs for neurological diseases. High-resolution maps of the complex connectivity of neuronal circuits correlating with functional and/or molecular markers offer invaluable insights into the functional organization of the neuronal structures, which is a key to understanding the brain in health and disease. There is a strong interest in elucidating and quantifying the connectomics of brain networks with subcellular resolution using electron microscopy (EM) and correlate with functional fluorescence microscopy data. The ultimate goal is to elucidate human brain functions and the mechanisms of human brain disorders. This is critically important to enable new diagnostics and therapies for brain disorders.  The reconstruction and analyses of neuronal networks is challenging in part due to the joint requirement of large volume and high resolution and a large gap in connectomic analysis solutions. There is a strong need for next generation, well supported, integrated, easy to use and highly automated analysis tools to detect and classify neurons, trace arbor branches, identify synapses, spines and synaptic vesicles that increase the throughput of otherwise prohibitively time-consuming analyses in connectomic experiments. There is also a strong need for tools to perform downstream data-driven analysis such as functional inference from structure and phenotypic discovery.  Powered by machine learning and DRVision innovations and collaborating with Dr. Rachel Wong and 9 additional labs, this project proposes to create an intelligent connectomic analysis (ICA) tool optimized for dense neuronal circuits. The tool will be commercially supported and integrated with DRVision’s flagship product Aivia to (1) provide accurate and automated neuron tracing in 3D EM and 3D fluorescence data up to multi-terabytes, (2) identify pre- and post-synaptic dendrite segments, (3) correlate light and electron microscopy data, quantify and classify neurons and sub-cellular components, (4) extract and analyze neuron circuits, (5) provide tools for phenotype discoveries, (6) seamlessly integrate the pipeline of ground truth (GT) annotation, editing, and machine learning workflow, and (7) access the required computing infrastructure, database connection, and exchange of data with other tools. Project Narrative The lack of basic understanding of neuronal functions and disease processes is a big factor of failures in creating drugs for neurological diseases. There is a strong interest in elucidating and quantifying the connectomics of brain networks with subcellular resolution using electron microscopy (EM) and correlate with functional fluorescence microscopy data. This is critically important to enable new diagnostics and therapies for brain disorders.  Powered by machine learning and DRVision innovations and collaborating with Dr. Rachel Wong and 9 additional labs, this project proposes to create an intelligent connectomic analysis (ICA) tool optimized for dense neuronal circuits. The tool will be integrated with DRVision’s flagship product Aivia for commercialization.",Intelligent connectomic analysis tool for dense neuronal circuits,10019731,R44MH121167,"['3-Dimensional', 'Active Learning', 'Biological Models', 'Brain', 'Brain Diseases', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Set', 'Databases', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Evaluation', 'Failure', 'Feedback', 'Fluorescence', 'Fluorescence Microscopy', 'Generations', 'Goals', 'Health', 'Human', 'Image', 'Infrastructure', 'Intelligence', 'Intelligence Tests', 'Joints', 'Machine Learning', 'Maps', 'Modeling', 'Mus', 'Nervous system structure', 'Neurons', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Process', 'Resolution', 'Retina', 'Structure', 'Synapses', 'Synaptic Vesicles', 'Testing', 'Time', 'Tissues', 'Training', 'Update', 'Validation', 'Vertebral column', 'Zebrafish', 'annotation  system', 'automated analysis', 'brain disorder therapy', 'cell type', 'commercialization', 'data exchange', 'experimental study', 'fluorescence imaging', 'innovation', 'insight', 'interest', 'light microscopy', 'microscopic imaging', 'molecular marker', 'nervous system disorder', 'neuronal circuitry', 'next generation', 'novel diagnostics', 'novel therapeutics', 'prototype', 'reconstruction', 'terabyte', 'tool', 'usability']",NIMH,"DRVISION TECHNOLOGIES, LLC",R44,2020,330385,-0.015125364616283018
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,-0.00435882139985303
"ClearScope Combined in vivo and ex vivo three-dimensional (3D) whole-brain imaging of non-transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole-brain datasets, the best approach is brain clearing followed by whole-brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole-brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo-bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide-spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state-of-the-art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,10019728,R44MH116827,"['3-Dimensional', 'Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Confocal Microscopy', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Human', 'Image', 'Immersion', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,1313060,-0.015616509498316809
"Boston University CCCR OVERALL ABSTRACT The Boston University CCCR will serve as a central resource for clinical research focused mostly on the most common musculoskeletal disorders, osteoarthritis and gout and will also provide research resources for investigator based research in scleroderma, spondyloarthritis, musculoskeletal pain and osteoporosis. Center grant funding has supported 30-35 papers annually in peer reviewed journals, most in the leading arthritis journals and some in leading general medical journals. This center has trained many of the leading clinical researchers in rheumatology throughout the US and internationally, and many of these former trainees have active collaborations with the center. We will include a broad research community and a core group of faculty in this CCCR. The research community's ready access to core faculty and to the sophisticated research methods and assistance they provide will enhance the clinical and translational research of the community and will increase collaborative opportunities for the core faculty and the community. The CCCR updates BU's historical focus on epidemiologic methods to include new approaches to causal inference and adds new methods in machine learning and mobile health. The Research and Evaluation Support Core Unit (RESCU) is the focal point of this CCCR. A key feature is the weekly research (RESCU meetings in which ongoing and proposed research projects are critically evaluated. This feature ensures frequent interactions between clinician researchers, epidemiologists and biostatisticians who are the core members of the CCCR. The RESCU core unit has provided critical support for other Center grants related to rheumatic and arthritic disorders at Boston University, three current R01/U01's; five current NIH K awards (one K24, 3 K23's, one K01), an R03, an NIH trial planning grant (U34), and multiple ACR RRF awards. The overall goal of this center is to carry out and disseminate high-level clinical research informed both by state of the art clinical research methods and by clinical and biological scientific discoveries. Ultimately, we aim either to prevent the diseases we are studying or to improve the lives of those living with the diseases. NARRATIVE The Boston University Core Center for Clinical Research will provide broad clinical research methods expertise to a large multidisciplinary group of investigators whose research focuses on osteoarthritis and gout with a secondary emphasis on scleroderma, spondyloarthritis, osteoporosis and musculoskeletal pain. The group, which includes persons with backgrounds in rheumatology, physical therapy, epidemiology, biostatistics and  . behavioral science, meets weekly to critically review research projects and serves a broad research community with which it actively engages. It has been successful in publishing influential papers on the diseases of focus and in training many of the clinical research faculty in the US and internationally",Boston University CCCR,10017004,P30AR072571,"['Allied Health Profession', 'Area', 'Arthritis', 'Award', 'Behavioral Sciences', 'Biological', 'Biometry', 'Boston', 'Clinical', 'Clinical Research', 'Cohort Studies', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consultations', 'Databases', 'Degenerative polyarthritis', 'Disease', 'Ensure', 'Environment', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Europe', 'Evaluation', 'Excision', 'Faculty', 'Funding', 'Goals', 'Gout', 'Grant', 'Health', 'Influentials', 'Infusion procedures', 'Institutes', 'Institution', 'International', 'Journals', 'K-Series Research Career Programs', 'Machine Learning', 'Medical', 'Medical Research', 'Medical center', 'Methods', 'Musculoskeletal Diseases', 'Musculoskeletal Pain', 'New England', 'Osteoporosis', 'Outcome', 'Pain', 'Paper', 'Peer Review', 'Persons', 'Physical therapy', 'Privatization', 'Productivity', 'Public Health Schools', 'Publications', 'Publishing', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Risk Factors', 'Schools', 'Scleroderma', 'Spondylarthritis', 'Talents', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'clinical center', 'cohort', 'design', 'epidemiology study', 'faculty community', 'faculty research', 'improved', 'innovation', 'interdisciplinary collaboration', 'mHealth', 'machine learning method', 'medical schools', 'meetings', 'member', 'multidisciplinary', 'novel', 'novel strategies', 'patient oriented', 'prevent', 'programs', 'protocol development', 'statistical service', 'success']",NIAMS,BOSTON UNIVERSITY MEDICAL CAMPUS,P30,2020,725375,-0.03976403182792195
"Graphical Processing Units and a Large-Memory Compute Node for Applications in Genomics, Neuroscience, and Structural Biology Project Summary  Cold Spring Harbor Laboratory (CSHL) is a private, not-for-profit institution dedicated to research and education in biology, with leading research programs in genomics, neuroscience, quantitative biology, plant biology, and cancer. Many activities at CSHL depend critically on high-performance computing resources, but at present, investigators have limited access to Graphics Processing Units (GPUs) and large-memory compute nodes. This deficiency is beginning to hamper a wide variety of biomedical research activities, particularly in the key areas of genomics, neuroscience and structural biology, where such specialty hardware is becoming essential for many important computational analyses. Here, we propose to acquire four state-of-the-art GPU nodes, each equipped with eight Nvidia Tesla V100, SXM2, 32GB GPUs, two 20-core 2.5 GHz Intel Xeon-Gold 6248 (Cascade Lake) processors, and 768 GB of RAM. A second-generation Nvidia NVLink will provide for 300 GB/s inter-GPU communication. In addition, we propose to acquire one large-memory node with 3 TB of RAM and four 20-core 2.5 GHz Intel Xeon-Gold 6248 (Cascade Lake) processors, as well as a top-of-rack 10 Gb Ethernet switch to interconnect the servers with each other and with our existing computer cluster. These new resources will enable a wide variety of innovative research across fields, with direct implications for human health. In genomics, applications will include RNA-seq read mapping; alignment, base-calling, and genome assembly for long-read sequence data; clustering of single cell RNA-seq data; analysis of transposable elements; deep-learning methods for prediction of the fitness consequences of mutations; and deep-learning methods for interpreting high-throughput mutagenesis experiments. In neuroscience, they will include analysis of multi-neuron activity recordings; analysis of mouse brain images; and artificial neural network models of the human olfactory system, of audio features, and of behavior as a function of changing motivations. In structural biology, they will include image processing and 3D reconstruction from cryo-electron microscopy data. These new compute nodes will have a primary impact on the research programs of nine major users from the CSHL faculty with substantial NIH funding. They will also impact three minor users. The new GPU and large-memory nodes will be fully integrated with a soon-to-be-upgraded high-performance computer cluster and managed by the experienced Information Technology group at CSHL, with oversight from a committee of seven faculty members and two IT staff members. Altogether, these new computational resources will substantially enhance the overall computational infrastructure at CSHL. Project Narrative  Many areas of modern biomedical research depend critically on state-of-the-art computing resources. Here we propose to acquire two types of specialty computer hardware: four Graphics Processing Unit (GPU) nodes and a large-memory compute node, both of which will be fully integrated with an existing and soon-to-be-upgraded high-performance computer cluster. These resources will meet a wide variety of computing needs across research areas at Cold Spring Harbor Laboratory, particularly in the growing areas of genomics, neuroscience, and structural biology.","Graphical Processing Units and a Large-Memory Compute Node for Applications in Genomics, Neuroscience, and Structural Biology",9939826,S10OD028632,"['3-Dimensional', 'Area', 'Behavior', 'Biology', 'Biomedical Research', 'Brain imaging', 'Communication', 'Computer Analysis', 'Cryoelectron Microscopy', 'DNA Transposable Elements', 'Data', 'Data Analyses', 'Education', 'Faculty', 'Funding', 'Generations', 'Genome', 'Genomics', 'Gold', 'Health', 'High Performance Computing', 'Human', 'Information Technology', 'Institution', 'Laboratories', 'Malignant Neoplasms', 'Memory', 'Minor', 'Motivation', 'Mus', 'Mutagenesis', 'Mutation', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Olfactory Pathways', 'Plants', 'Privatization', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'United States National Institutes of Health', 'artificial neural network', 'base', 'computer cluster', 'computer infrastructure', 'computing resources', 'deep learning', 'experience', 'experimental study', 'fitness', 'high end computer', 'image processing', 'innovation', 'learning strategy', 'medical specialties', 'member', 'programs', 'reconstruction', 'single-cell RNA sequencing', 'structural biology', 'transcriptome sequencing']",OD,COLD SPRING HARBOR LABORATORY,S10,2020,436882,-0.01127661860827552
"Biomechanical Analysis in Strabismus Surgery We propose 3 interrelated aims to define the biomechanics of the eye rotating (extraocular) muscles (EOMs) & optic nerve (ON) in health & visual disease, understand novel EOM actions, & characterize mechanical effects that may contribute to severe myopia. We aim to improve treatment of strabismus, misalignment of visual directions of the eyes; glaucoma & non-arteritic anterior ischemic optic neuropathy (NA-AION), both common blinding ON diseases; & high axial myopia, an ocular elongation & distortion that has become a worldwide epidemic & major cause of blindness. We propose a novel & critical nexus linking the EOMs, ON, & structure of the eye's scleral wall that we will explore using modern imaging & artificial intelligence techniques. Aim I will clarify the kinematic (motion) properties of the human eye, testing by multipositional magnetic resonance imaging (MRI) of the eyeball & EOMs the hypothesis that translational (linear) movement contributes importantly to ocular alignment. MRI will be performed during horizontal convergence & vertical eye rotation in normal people, & in patients who have common forms of strabismus including convergence insufficiency, eye crossing (esotropia), & outward ocular deviation (exotropia), both before & after corrective EOM surgery. Clarification of ocular translation is necessary to understand normal ocular motility and treat its disorders. Aim II will characterize the mechanical loading on the ON caused by eye movements. We will characterize the mechanical effects of ON tractional loading on the eyeball during horizontal & vertical eye rotations at 2 scales in living people, to test the hypothesis that such ON loading deforms it & adjacent retina & blood vessels as loading translates the eye. We propose that the resulting deformation during eye movements may create repetitive strain injury contributing to glaucoma, NA-AION, & axial myopia. In groups of subjects with the foregoing diseases, & in an equal group of matched healthy subjects, we will study mechanical effects of eye movement within the living eye by imaging its internal micro structure & blood vessels with optical coherence tomography, & outside the eyeball in the eye socket using MRI. Effects of tethering during eye movement will be studied ex vivo by precision 3D optical imaging of fresh human eye bank specimens subjected to mechanical tension on the ON that mimic effects of the eye movements imaged in the living subjects. Aim III will model the biomechanics of ocular kinematics. The constitutive mechanical properties of the non-muscular ocular & eye socket tissues will be described by finite element models (FEMs) using modern engineering methods for computational simulation to predict ocular kinematics, as well as local mechanical strains in the ON & sclera that may cause glaucoma, NA-AION, & the ocular deformities underlying extreme nearsightedness. We will determine if FEMs employing normal tissue properties can simulate normal ocular translation during horizontal & vertical rotations & convergence. By FEM simulation, we will also test the hypothesis that ocular loading by eye movement might contribute to: normal vergence, strabismus, & the effects of strabismus surgery. Relevance. Strabismus is a common clinical disorder that can cause double vision in adults and vision loss in children. Strabismus is often treated by surgical manipulation of the eye muscles, although current knowledge of their structure and function is incomplete. Proposed functional imaging and biomechanical studies of the properties of the eye muscles, eyeball, and optic nerve will improve understanding of the causes and treatment of strabismus, optic nerve diseases, and nearsightedness.",Biomechanical Analysis in Strabismus Surgery,9972266,R01EY008313,"['3-Dimensional', 'Accounting', 'Adult', 'Agreement', 'Algorithms', 'Anatomy', 'Anterior Ischemic Optic Neuropathy', 'Artificial Intelligence', 'Behavior', 'Biological Specimen Banks', 'Biomechanics', 'Blindness', 'Blood Vessels', 'Child', 'Choroid', 'Clinical', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Connective Tissue', 'Convergence Insufficiency', 'Cumulative Trauma Disorders', 'Deformity', 'Degenerative Myopia', 'Diplopia', 'Disease', 'Duct (organ) structure', 'Elements', 'Engineering', 'Epidemic', 'Equilibrium', 'Esotropia', 'Etiology', 'Exotropia', 'Eye', 'Eye Banks', 'Eye Movements', 'Failure', 'Functional Imaging', 'Gap Junctions', 'Glaucoma', 'Health', 'Human', 'Image', 'Individual', 'Knowledge', 'Lasers', 'Link', 'Magnetic Resonance Imaging', 'Matched Group', 'Measurement', 'Measures', 'Mechanics', 'Modeling', 'Modernization', 'Motion', 'Movement', 'Muscle', 'Muscle Contraction', 'Myopia', 'Normal tissue morphology', 'Ocular orbit', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Physiologic Intraocular Pressure', 'Play', 'Primary Open Angle Glaucoma', 'Property', 'Retina', 'Role', 'Rotation', 'Scanning', 'Sclera', 'Strabismus', 'Stress', 'Structure', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Traction', 'Translating', 'Translations', 'Validation', 'Variant', 'Visual', 'anatomic imaging', 'biomechanical model', 'cell motility', 'crosslink', 'digital imaging', 'ex vivo imaging', 'human tissue', 'improved', 'in vivo imaging', 'in vivo optical imaging', 'kinematics', 'mechanical load', 'mechanical properties', 'model development', 'models and simulation', 'monocular', 'neglect', 'novel', 'ocular imaging', 'optic nerve disorder', 'optical imaging', 'orbit muscle', 'predictive modeling', 'quantitative imaging', 'retina blood vessel structure', 'simulation']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,622245,-0.01647211004565488
"Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT) Project Summary/Abstract  The idiosyncrasies of the human brain require that individualized mapping of functional regions be performed before surgical interventions for cancer or epilepsy. The success of this mapping procedure has direct effects on surgical outcomes and preserving cognitive and sensory function post-surgery. Current gold standard procedures for pre-surgical mapping are invasive, time-consuming, and technically demanding. Several non-invasive procedures have emerged in recent years; however, they have not yet displaced the gold standard procedures. Task-based functional magnetic resonance imaging (t-fMRI), the most widely used non-invasive pre-surgical mapping technique, requires that patients perform cognitive or motor tasks while in the scanner—a time-consuming and expensive procedure. Also, not all patients can perform fMRI tasks due to language barriers, sensory deficits, being unconscious, etc. Connectome Fingerprinting (CF) is a recently developed technique that uses machine learning to train a model capable of predicting functional brain activation from task-free resting-state fMRI (rs-fMRI). Once trained on a set of t-fMRI and rs- fMRI data, an unseen subject's unique pattern of brain activation can be predicted using only an rs-fMRI scan of their brain—therefore eliminating the need to perform tasks during the fMRI scan. Despite the promise of CF, the accuracy of the current best practice modeling techniques is not high enough yet to be clinically useful and studies applying CF have nearly always used healthy populations. Much research remains to be done to increase the accuracy of CF models before they can be deployed for pre-surgical mapping.  The long-term objective of the research proposed here is to develop a software application that combines applied machine learning with medical imaging to provide a non-invasive means for mapping the brains of neurosurgical patients before surgery. Importantly, we aim to increase the accuracy of CF modeling by expanding the modeling efforts to probabilistic Bayesian approaches that leverage prior information from the structure of the data. We will test a wide array of tunable data and model parameters to arrive at a current recommendation for best practices in CF research and applications. Finally, we will test our modeling procedures with a dataset of healthy control and pre-surgical patients diagnosed with brain tumors. We will test the software's ability to accurately predict functional brain organization in these patients and adaptively retrain the models to produce the most accurate results. This work has the potential to revolutionize pre-surgical brain mapping and expand its applicability to a greater number of patients. Project Narrative  In the United States, approximately 24,000 new cases of brain tumors are reported each year, with many patients requiring expensive pre-surgical planning and mapping of functional regions to minimize post-surgical impairments. In many neurosurgical practices [96% per 1], this involves performing a time-consuming and costly task-based fMRI acquisitions (nearly $1200/scan in 2014; [2]) before surgery to identify eloquent brain areas recruited for motor control, language, and cognition that must be spared during surgery. By combing task-based fMRI, resting-state fMRI and advanced machine learning to map the functional topology of the brain, the proposed technology will lower pre-surgical planning costs, reduce the burden on physicians and technicians, and expand pre-surgical mapping to previously excluded patients who cannot perform fMRI tasks.",Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT),10139299,R43NS117226,"['Activities of Daily Living', 'Anatomy', 'Area', 'Bayesian Method', 'Blindness', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Cancer Intervention', 'Clinical', 'Cognition', 'Cognitive', 'Comb animal structure', 'Computer software', 'Conscious', 'Consumption', 'Cost Savings', 'Data', 'Data Set', 'Diagnosis', 'Engineering', 'Ensure', 'Epilepsy', 'Evaluation', 'Fingerprint', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Generations', 'Gold', 'Government', 'Health Care Costs', 'Healthcare Systems', 'Hospitals', 'Human', 'Impairment', 'Individual', 'Language', 'Learning', 'Linear Models', 'Machine Learning', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Motor', 'Neurologic', 'Neurosurgeon', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physicians', 'Population', 'Preparation', 'Procedures', 'Recommendation', 'Reporting', 'Research', 'Rest', 'Scanning', 'Sensory', 'Software Engineering', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unconscious State', 'United States', 'Validation', 'Visual', 'Visual impairment', 'Woman', 'Work', 'anatomic imaging', 'base', 'cognitive task', 'compliance behavior', 'computerized data processing', 'connectome', 'cost', 'data acquisition', 'data quality', 'design', 'functional MRI scan', 'improved', 'individual variation', 'large scale data', 'motor control', 'multisensory', 'next generation', 'preservation', 'prototype', 'recruit', 'structured data', 'success', 'surgery outcome', 'usability']",NINDS,"CHARLES RIVER ANALYTICS, INC.",R43,2020,252569,-0.003805945604399173
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9923542,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data harmonization', 'data reuse', 'data sharing', 'data tools', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,619917,-0.029149031096961847
"Innovative biostatistical approaches to network level analyses of connectome-behavior relationships PROJECT SUMMARY/ABSTRACT Determining the mechanisms by which the human brain generates cognition, perception, and emotion hinges upon quantifying the relationships between coordinated brain activity and behavior. NIH-funded brain mapping initiatives such as the Human Connectome Project (HCP) and the Adolescent Cognitive and Behavioral Development (ABCD) study, have accelerated the production of large brain connectivity (i.e. connectome) and behavioral datasets. Contemporary connectome research views the brain as a large-scale, complex network composed of nonadjacent, yet connected brain regions. We propose to leverage the inherent network architecture of the connectome in order to probe fundamental biological mechanisms underlying the development of executive function and internalizing symptoms. In pursuit of this research question, this application proposes to formalize and validate in house analysis pipelines into a Network Level Analysis (NLA) toolbox as a comprehensive, versatile tool for use in connectome-wide association studies. The proposed NLA toolbox fulfills BRAIN Initiative goal #5 to “Produce conceptual foundations for understanding the biological basis of mental processes through development of new theoretical and data analysis tools”. While the research focus of this career transition award is on the application of NLA to developmental mechanisms of executive function and emotion regulation, this versatile analytic tool will be transformative to connectome data analysis across species, across the lifespan, and in health and disease. As part of tool development, the applicant will validate multiple NLA approaches using in silico connectome-behavior relationships and establish sensitivity and specificity of network level findings as compared to the connectome-wide control of familywise error rate (K99 Aim 1). The applicant will then establish test-retest reliability of NLA approaches using in vivo human connectome and behavioral data available from the HCP-Young Adult cohort (N=1105), and establish brain networks underlying healthy adult executive and emotional function (K99 Aim 2). During the independent R00 phase, she will then investigate changes in connectome architecture supporting the development of executive and emotional function using the ABCD longitudinal connectome and behavioral data (N=~11,000 age 9-14) (R00 Aim 3). During the K99 phase she will extend her training in behavioral neuroscience to include training in machine learning, longitudinal models, and computer science. Building on her strong foundation in human brain connectivity analysis, the applicant will gain advanced skills in biostatistics and best practices in software development to ensure her success as an independent researcher. The advisory committee, including Drs. Smyser (functional connectivity), Marcus (software engineering), Fair (developmental neuroscience), Todorov (biostatistics), Zhang (machine learning), Bassett (connectome analysis), Eggebrecht (toolbox development), and Barch (HCP/ABCD consultant) provide expertise in all core areas spanning experimental disciplines and possess an excellent record of obtaining independent funding and mentoring young scientists. PROJECT NARRATIVE While significant research efforts have been devoted to determining the biological pathways of cognition and emotion, there is concern over the lack of reproducibility of findings. This proposal seeks to develop and apply a Network Level Analysis (NLA) toolbox which will be used to identify and characterize the brain networks underlying healthy and disordered development of executive and emotional processes. The NLA toolbox is a versatile analysis pipeline which leverages the structural and functional architecture of the brain and rigorous statistical testing and validation procedures to define brain-behavior relationships across species, across the lifespan, and in health and disease.",Innovative biostatistical approaches to network level analyses of connectome-behavior relationships,10055480,K99EB029343,"['Adolescent', 'Adult', 'Advisory Committees', 'Age', 'Architecture', 'Area', 'Award', 'BRAIN initiative', 'Behavior', 'Behavior assessment', 'Behavioral', 'Biological', 'Biometry', 'Brain', 'Brain Mapping', 'Brain region', 'Career Transition Award', 'Cognition', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Discipline', 'Disease', 'Documentation', 'Emotional', 'Emotions', 'Endocrine', 'Ensure', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Human Development', 'Intervention', 'Investigation', 'Link', 'Longevity', 'Machine Learning', 'Manuals', 'Measures', 'Mental Processes', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurosciences', 'Pathway interactions', 'Perception', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Psychopathology', 'Publishing', 'ROC Curve', 'Reaction Time', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Software Engineering', 'Statistical Data Interpretation', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Training', 'United States National Institutes of Health', 'Update', 'Validation', 'Writing', 'analysis pipeline', 'analytical method', 'analytical tool', 'base', 'behavior measurement', 'brain behavior', 'cloud based', 'cognitive development', 'cognitive reappraisal', 'cohort', 'computer science', 'connectome', 'connectome data', 'dimensional analysis', 'emotion regulation', 'emotional functioning', 'executive function', 'graphical user interface', 'improved', 'in silico', 'in vivo', 'indexing', 'innovation', 'longitudinal dataset', 'longitudinal design', 'network architecture', 'neuroimaging', 'post intervention', 'programs', 'skills', 'skills training', 'software development', 'success', 'tool', 'tool development', 'young adult']",NIBIB,WASHINGTON UNIVERSITY,K99,2020,126289,-0.007837939929088376
"Bioethics of syndrome diagnosis using 3D image analysis Project Summary/Abstract This supplement will address the unintended consequences and collateral damage that arise when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. In Aim 1, we will determine whether the accuracy of this technology varies based on self-reported race, sex and age. In this aim, we examine our existing database for evidence of bias based on self-reported race, sex or age. We further determine the extent to which these variables influence classification performance. To the extent sample sizes allow, we will carry this analysis to the level of specific syndromes. Finally, we will use anonymized reference datasets of non-syndromic faces to compare false positive rates based on NIH race definitions, sex and age. The outcome of this aim is to objectively establish bias and estimate the effects of under-representation across race, age and sex categories within our data. In Aim 2, we will determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians. This aim will establish the extent to which the storing of large databases of facial images and the application of machine learning processes to them for diagnostic purposes may raise privacy concerns. The concerns investigated will include potential hacks into protected health information; fear relating to the bias in some facial recognition software (and, potentially, in the Facebase database); and fear of discrimination in the application of the technology, such as by insurers. The outcome will be a white paper that targets a high-profile journal, summarizing the findings and defining crucial issues that should guide the development of facial imaging for disease diagnosis and clinical usage. Project Narrative Our supplement application will address the important question of unintended consequences and collateral damage when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. The use of large facial recognition databases in medicine represents a frontier that arrives with tremendous potential but undeniable risks. Our central aims are: (1) determine whether the accuracy of this technology varies based on self-reported race, sex and age; and (2) determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians.",Bioethics of syndrome diagnosis using 3D image analysis,10132648,U01DE028729,"['3-Dimensional', 'Address', 'Age', 'Authoritarianism', 'Bioethical Issues', 'Bioethics', 'Biometry', 'Categories', 'Classification', 'Clinic', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Computational Biology', 'Country', 'Data', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Ethics', 'Face', 'FaceBase', 'Fright', 'Funding', 'General Hospitals', 'Generations', 'Genes', 'Genetic Diseases', 'Health', 'Hereditary Disease', 'Image', 'Image Analysis', 'Insurance Carriers', 'Journals', 'Libraries', 'Machine Learning', 'Medical', 'Medicine', 'Outcome', 'Paper', 'Pathology', 'Patient Self-Report', 'Patient imaging', 'Performance', 'Privacy', 'Private Sector', 'Process', 'Psychiatry', 'Public Sector', 'Race', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'San Francisco', 'Secure', 'Syndrome', 'Technology', 'Three-Dimensional Image', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'craniofacial', 'disease diagnosis', 'facial recognition software', 'frontier', 'human data', 'intervention cost', 'new technology', 'professor', 'repository', 'sex', 'tool']",NIDCR,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2020,152200,-0.010125735198442785
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9875480,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Science Core', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'biomedical data science', 'career', 'classification algorithm', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'large datasets', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2020,164298,0.013975257102518068
"Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space Project Summary  The natural environment is intrinsically spatiotemporally heterogenous at both macroscopic and microscopic levels. What shapes such a heterogeneity includes the concentration gradients of biologically relevant chemical species in the extracellular medium including dioxygen (O2), reactive oxygen species (ROS), as well as essential redox-active transition metals. While a significant amount of effort has been devoted to spectroscopically image these chemical moieties, our capability to spatiotemporally control their concentration distributions in the extracellular medium remains limited. This is especially the case for biofilms and microbiota, in which the microorganisms’ small length scales pose significant challenges for concentration modulation. The inadequate control of concentration heterogeneity limits our capability of mimicking the natural environments in vitro and investigating how local concentration gradients affect microbial functionality. Therefore, there is a need for an advanced method of controlling chemical concentrations at microscopic level.  Our proposed research aims to use electrochemical nano-/micro-electrodes to spatiotemporally control the concentration gradients in the extracellular medium. When an electrochemical reaction occurs on an electrode’s surface, a concentration gradient is established near the electrode. Taking advantages of this phenomena with the assistance of numerical simulation, we will employ an array of nano-/micro-electrodes with individually addressable electrochemical potentials to program any arbitrary spatiotemporal concentration profiles. We will fine-tune the surface chemistry and the electrochemical properties of these electrodes to ensure biocompatibility and reaction specificity. The developed system will be applied to biofilms and we aim to investigate how the microbial social behavior will be affected by a perturbation of local O2 concentration. Moreover, we will use this device to mimic the heterogenous environment in the gut and culture gut microbiota in vitro. An algorithm based on machine learning will be employed to actively adjust electrode potentials, maintaining a stable concentration profile despite the accumulation of gut microorganisms.  Ultimately, our work will expand our capability of controlling the concentration heterogeneity in nature. The developed electrochemical system will serve an in vitro platform to culture microorganisms in their native environment, or as a tool to perturb the concentration profiles. Combining electrochemistry, inorganic chemistry, and nanomaterials the research will enable a deeper understanding of the spatial distribution and temporal response of microbial systems. Project Narrative The natural environment is intrinsically heterogenous yet our control of concentrations for chemical species is limited at microscopic level. The proposed research is relevant to the mission of the NIH because it describes the development of technology that will expand our capability of controlling chemical concentration profiles in a variety of microbial systems relevant to the public health. The research described here will enable a deeper understanding of disease-related microbial systems and help to formulate strategies to combat diseases.",Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space,10029526,R35GM138241,"['Affect', 'Algorithms', 'Biological', 'Chemicals', 'Chemistry', 'Devices', 'Dioxygen', 'Disease', 'Electrochemistry', 'Electrodes', 'Ensure', 'Environment', 'Heterogeneity', 'In Vitro', 'Individual', 'Inorganic Chemistry', 'Length', 'Machine Learning', 'Methods', 'Microbial Biofilms', 'Microscopic', 'Mission', 'Nanoarray Analytical Device', 'Nature', 'Oxidation-Reduction', 'Property', 'Public Health', 'Reaction', 'Reactive Oxygen Species', 'Research', 'Shapes', 'Social Behavior', 'Spatial Distribution', 'Specificity', 'Surface', 'System', 'Transition Elements', 'United States National Institutes of Health', 'Work', 'base', 'biomaterial compatibility', 'combat', 'extracellular', 'gut microbiota', 'microbial', 'microbiota', 'microorganism', 'microorganism culture', 'nano', 'nanomaterials', 'programs', 'response', 'simulation', 'spatiotemporal', 'spectroscopic imaging', 'technology development', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,371084,-0.007486895146344701
"N3C & All of Us Research Program Collaborative Project Project Summary/Abstract The COVID-19 pandemic presents unprecedented clinical and public health challenges. Though institutions collect large amounts of clinical data about COVID-19 cases, these datasets individually might not be diverse enough to draw population level conclusions. Also, statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. To tackle this problem, NCATS introduced the National COVID Cohort Collaborative (N3C), an open science, community-based initiative to share patient level data for analysis. The initiative requires participating institutions to share information about their COVID-19 patients in a standard-driven way, including demographics, vital signs, diagnoses, laboratory results, medications, and other treatments. The data from multiple institutions will be merged and consolidated, and access will be provided to investigators through a centralized analytical platform. The COVID-19 data sharing collaboration with the N3C initiative offers a mechanism to initiate collaborations with other NIH sponsored data sharing programs, such as the All of Us Research Program (AoURP). This administrative supplement will support efforts to clean and standardize data at VCU, and to transfer it to the N3C data repository. The supplement will also assist in introducing new services at the Wright Center to support our investigators to use the N3C resources. It will also enable collaboration with the AoURP by establishing a pipeline to collect and transmit consented patients' EHR data and by building on existing community outreach pathways to recruit additional participants for the AoURP. The project will be overseen by the PI/Executive Committee and supervised by the Director of Research Informatics. Procedures and services developed at our local CTSA hub will be shared and disseminated to the CTSA network. Project Narrative NIH/NCATS has been working on the National COVID Cohort Collaborative (N3C), which aims to build a centralized national data resource to be used by the research community to study the COVID-19 pandemic and identify potential treatments as the pandemic continues to evolve. The COVID-19 data sharing collaboration with the N3C initiative also offers a mechanism to initiate collaborations with the All of Us Research Program (AoURP). This administrative supplement will support the creation and management of a data extraction and transfer pipeline to the N3C and AoURP data repositories from VCU.",N3C & All of Us Research Program Collaborative Project,10217339,UL1TR002649,"['Administrative Supplement', 'All of Us Research Program', 'COVID-19', 'COVID-19 pandemic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Outreach', 'Consent', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Effectiveness', 'Funding Opportunities', 'Goals', 'Health', 'Health Status', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Laboratories', 'Outcomes Research', 'Participant', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Procedures', 'Public Health', 'Research', 'Research Personnel', 'Resource Informatics', 'Resources', 'Services', 'Supervision', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'biomedical informatics', 'clinical center', 'cohort', 'coronavirus disease', 'data resource', 'data sharing', 'data standards', 'data warehouse', 'demographics', 'design', 'improved', 'informatics infrastructure', 'innovation', 'large scale data', 'multi-site trial', 'network informatics', 'open data', 'pandemic disease', 'parent grant', 'programs', 'recruit', 'response', 'statistical and machine learning', 'tool']",NCATS,VIRGINIA COMMONWEALTH UNIVERSITY,UL1,2020,346608,-0.01357714927597059
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,10018020,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2020,332870,-0.01269874224623139
"A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth This project provides a data science framework and a toolbox of best practices for systematic and reproducible data-driven methods for validating and deriving RDoC constructs with relevance to psychopathology. Despite recent advances in methods for data-driven constructs, results are often hard to reproduce using samples from other studies. There is a lack of systematic statistical methods and analytical design for enhancing reproducibility. To fill this gap, we will develop a data science framework, including novel scalable algorithms and software, to derive and validate RDoC constructs. Although the proposed methods will generally apply to all RDoC domains and constructs, we focus specifically on furthering understanding of the RDoC domains of cognitive control (CC) and attention (ATT) constructs implicated in attention deficit disorder (ADHD) and obsessive-compulsive disorder (OCD). Our application will use multi-modal neuroimaging, behavioral, and clinical/self-report data from large, nationally representative samples from the on Adolescent Brain Cognitive Development (ABCD) study and multiple local clinical samples with ADHD and OCD. Specifically, using the baseline ABCD samples, in aim 1, we will apply and develop methods to assess and validate the current configuration of RDoC for CC and ATT using confirmatory latent variable modeling. We will implement and develop new unsupervised learning methods to construct new computational-driven, brain-based domains from multi-modal image data. In Aim 2, We will introduce network analysis (via Gaussian graphical models) to characterize heterogeneity in the interrelationship of RDoC measurements due to observed characteristics (i.e., age and sex). We will further model the heterogeneity of the population due to unobserved characteristics by introducing the data-driven precision phenotypes, which are the subgroup of participants with similar RDoC dimensions. We propose a Hierarchical Bayesian Generative Model and scalable algorithm for simultaneous dimension reduction and identify precision phenotypes. The model also serves as a tool to transfer information from the community sample ABCD to local clinical enriched studies. In aim 3, we will utilize the follow-up samples from ABCD and local clinical enriched data sets to validate the results from Aims 1 and 2 and assess the clinical utility of the precision phenotypes in predicting psychological development in follow-up time. Our project will provide a suite of analytical tools to validate existing RDoC constructs and derive new, reproducible constructs by accounting for various sources of heterogeneity. To advance the understanding of psychopathology using dimensional constructs of measurements from multiple units of analysis, we propose reproducible statistical framework for validating and deriving RDoC constructs with relevance to psychopathology. We will use multi-modal neuroimaging, behavioral and clinical/self-report data from multiple samples to develop this framework. The design of our study consists of analyzing large, nationally representative samples, validating the results in local clinically enriched samples, and transfer information from the large community samples to local clinical samples.",A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth,10058921,R01MH124106,"['11 year old', 'Accounting', 'Adolescent', 'Age', 'Algorithmic Software', 'Algorithms', 'Attention', 'Attention Deficit Disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Characteristics', 'Child', 'Chronology', 'Clinical', 'Clinical Data', 'Communities', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Dimensions', 'Ensure', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Goals', 'Heterogeneity', 'Image', 'Knowledge', 'Learning', 'Link', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Obsessive-Compulsive Disorder', 'Participant', 'Pathway Analysis', 'Patient Self-Report', 'Phenotype', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Psychological Transfer', 'Psychopathology', 'Reproducibility', 'Reproducibility of Results', 'Research Domain Criteria', 'Sampling', 'Source', 'Statistical Methods', 'Structure', 'Subgroup', 'Symptoms', 'Time', 'Variant', 'Youth', 'age effect', 'analytical tool', 'autoencoder', 'base', 'biological sex', 'cognitive control', 'cognitive development', 'deep learning', 'design', 'follow up assessment', 'follow-up', 'high dimensionality', 'independent component analysis', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'multimodality', 'network models', 'neuroimaging', 'novel', 'psychologic', 'response', 'sex', 'tool', 'unsupervised learning']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2020,710101,-0.0013799865128118827
"EEGLAB: Software for Analysis of Human Brain Dynamics Electroencephalography (EEG), the first function brain activity imaging modality, has several natural advantages over metabolic brain imaging modalities. EEG is noninvasive, low cost, and lightweight enough to be highly mobile. Two major shifts in scientific perspective on the nature and use of human electrophysiological data are now ongoing. The first is a shift to using EEG data as a source-resolved, relatively high-resolution cortical source imaging modality. The EEGLAB signal processing environment, an open source software project of the Swartz Center for Computational Neuroscience (SCCN) of the University of California, San Diego (UCSD), began as a set of EEG data analysis running on Matlab (The Mathworks, Inc.) released by Makeig on the World Wide Web in 1997. EEGLAB was first released from SCCN in 2001. Now nearly twenty years later, the EEGLAB reference paper [4] has over 6,750 citations (now increasing by over 4 per day), the opt-in EEGLAB discussion email list links 6,000 researchers, the EEGLAB news list over 15,000 researchers, and an independent 2011 survey of 687 research respondents reported EEGLAB to be the software environment most widely used for electrophysiological data analysis in cognitive neuroscience. Our statistics show that after over the past four years, EEGLAB adoption is still growing steadily. Here, we will develop a framework for thorough comparison of preprocessing methods, and will apply machine learning methods on the large body of data collected by our laboratory to build optimized, automated data processing pipelines. We will greatly augment the power of the EEGLAB environment by providing a cross-study meta-analysis capability and will revise the software architecture to use a file and metadata organization compatible with the Brain Imaging Data Structure (BIDS) framework first developed for fMRI/MRI data archiving. These tools will integrate the HED annotating system allowing for meta-analysis across large corpus of studies. We will implement beamforming within EEGLAB. We will develop a hierarchical Bayesian framework for clustering effective sources on multiple measures across subjects and studies, and will develop tools to perform statistical testing on information flow measures at these scales. Although EEG and MEG recording have co- existed for four decades, little available software can combine both data types, recorded concurrently (`MEEG' data), to enhance source separation. We recently showed that ICA decomposition also allows joint MEEG effective source decomposition and will integrate MEG and joint MEEG data decomposition and imaging into the EEGLAB tool set. We will build tools to use MRI- and fMRI-derived anatomical atlases to inform the interpretation of EEG and MEG brain source dynamics. These radical improvements will further the use of non-invasive human electrophysiology for 3-D functional cortical brain imaging in the U.S. and worldwide, thereby accelerating progress in noninvasive basic and clinical human brain research using highly time- and space-resolved measures of brain electromagnetic dynamics. The EEGLAB signal processing environment is now used in many electrophysiological research and teaching laboratories worldwide. To accelerate progress in basic and clinical cognitive neuroscience, we will continue maintenance and development of the EEGLAB environment, introducing new tools for source separation and localization, source clustering, automatic artifact management, and across-studies meta-analysis, and will extend its scope to process magnetoencephalographic (MEG) and joint EEG/MEG data and to highlight parallels between EEG/MEG source dynamics and results of existing research using fMRI and other brain imaging.",EEGLAB: Software for Analysis of Human Brain Dynamics,9971588,R01NS047293,"['3-Dimensional', 'Adoption', 'Anatomy', 'Architecture', 'Atlases', 'Automatic Data Processing', 'Automation', 'Bayesian Modeling', 'Behavior', 'Brain', 'Brain imaging', 'California', 'Classification', 'Clinical', 'Code', 'Cognitive', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Documentation', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electronic Mail', 'Electrophysiology (science)', 'Environment', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Health', 'Human', 'Image', 'Institutes', 'Internet', 'Joints', 'Laboratories', 'Learning', 'Link', 'Links List', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Measures', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Nature', 'Neurosciences', 'Newsletter', 'Paper', 'Plug-in', 'Process', 'Psyche structure', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Respondent', 'Running', 'Source', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Work', 'automated analysis', 'base', 'brain research', 'central database', 'cognitive neuroscience', 'computational neuroscience', 'cost', 'data analysis pipeline', 'data archive', 'data cleaning', 'data infrastructure', 'data structure', 'data visualization', 'design', 'experience', 'graphical user interface', 'imaging modality', 'independent component analysis', 'interest', 'light weight', 'machine learning method', 'mathematical methods', 'news', 'novel strategies', 'online course', 'open source', 'research study', 'response', 'signal processing', 'statistics', 'structured data', 'support tools', 'teaching laboratory', 'tool', 'wiki']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,588823,0.018582680654902393
"Meta-analysis in human brain mapping This is the competing renewal of R01MH074457-13, which sustains the BrainMap Project (www.brainmap.org). The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data. To date, the BrainMap Project has designed and populated two coordinate-based databases: 1) a task-activation repository (TA DB); and, 2) a voxel-based morphometry repository (VBM DB). The TA DB contains >17,200 experiments, collectively representing > 78,000 subjects and > 110 task- activation paradigms. The VBM DB contains > 3,100 experiments, collectively representing > 81,000 subjects with > 80 psychiatric, neurologic and developmental disorders with ICD-10 coding. The BrainMap Project has created, optimized and validated an integrated pipeline of multi-platform (Javascript), open-access tools to curate (Scribe), filter and retrieve (Sleuth), analyze (GingerALE), visualize (Mango) and interpret analysis output (BrainMap meta-data plugins for Mango). Several network-modeling approaches have been applied to BrainMap data -- MACM, independent components analysis (ICA), graph theory modeling (GTM), author-topic modeling (ATM), structural equation modeling (SEM), and connectivity-based parcellation (CBP) – but none are yet pipeline components. Utilization of these CBMA resources is substantial: BrainMap software, data and meta-data have been used in > 825 peer-reviewed publications. Of these, > 350 were published within the current funding period (April 2015-March 2019; brainmap.org/pubs). In this competing renewal, four tool- development aims are proposed, each of which extends this high-impact research resource. Aim 1. Database Expansion. BrainMap data repositories will be expanded. Aim 2. Meta-analytic Network Modeling. Network modeling will be added to the BrainMap pipeline. Aim 3. Large-Scale Simulations, Comparisons and Validations. Data simulations, characterizations and validations will be performed. Aim 4. Meta-data Inferential tools. Tools for mining BrainMap’s location-linked meta-data will be expanded. Data Sharing Plan. BrainMap data, meta-data, pipeline tools, and templates created by whole-database modeling (e.g., ICA and ATM network masks) are shared at BrainMap.org. Of all new data entries, more than half are contributed by BrainMap users, i.e., community data sharing via BrainMap.org. For community-coded entries, the BrainMap team provides curation and quality control. Comprehensive database images (database dumps) are available to tool developers through Collaborative Use Agreements. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data  sets, metadata, computational tools, and related resources that enable coordinate-­based meta-­analyses  (CBMA), meta-­analytic connectivity modeling (MACM), meta-­data informed interpretation (“decoding”) of  imaging results, and meta-­analytic priors for mining (including machine learning) primary (per-­subject)  neuroimaging data.    ",Meta-analysis in human brain mapping,10056029,R56MH074457,"['Agreement', 'Area', 'Brain', 'Brain Mapping', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Data', 'Data Set', 'Databases', 'Disease', 'Educational workshop', 'Equation', 'Functional disorder', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Institution', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Internet', 'Java', 'Link', 'Location', 'Machine Learning', 'Mango - dietary', 'Masks', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Output', 'Peer Review', 'Plug-in', 'Publications', 'Publishing', 'Quality Control', 'Research Domain Criteria', 'Resources', 'Rest', 'Site', 'Software Framework', 'Specificity', 'Structure', 'Training', 'Universities', 'Validation', 'base', 'candidate marker', 'computerized tools', 'data pipeline', 'data sharing', 'data warehouse', 'design', 'developmental disease', 'experimental study', 'graph theory', 'independent component analysis', 'interest', 'large scale simulation', 'morphometry', 'nervous system disorder', 'network architecture', 'network models', 'neuroimaging', 'neuropsychiatric disorder', 'repository', 'simulation', 'tool', 'tool development']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R56,2020,543396,0.0074921840634903526
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,10002192,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'data standards', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2020,427122,0.01437705698681818
"Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain Great discoveries in neuroscience hold promise for reducing the burden of many of the most disabling conditions that threaten human health on a global scale, including mental illnesses and addictions. Increasingly, exceptionally innovative science inspires hope that these devastating brain-based disorders may be prevented, treated, and even cured but, as the BRAIN 2025 Scientific Vision notes, a suite of novel ethical challenges confronts those engaged in innovative neuroscience. These concerns include the deepest questions about what defines humanity and personhood, what forms of novel inquiry may exceed ethically acceptable limits in society, and how to perform ethically sound studies with volunteers who may be vulnerable to exploitation in the research situation. Such issues are particularly salient in mental illness and addiction research because these conditions affect cognition, emotion, motivation, behavior, and self-governance of potential participants. Importantly, some of these ethical issues are amenable to empirical study, which can yield valuable insights and evidence-informed practices that strengthen and enable ethically sound human brain investigation. The overarching goal of this proposal is thus to accelerate neuroscience toward lessening the burden of mental illness and addiction through hypothesis-driven empirical ethics inquiry in three parts. First, we determine the distinct ethical issues and problems encountered in innovative neuroscience related to mental illness and addiction through semi-structured interviews with neuroscientists, neuroethicists, and institutional review board members. Informed by our past work and grounded in a rigorous conceptual model, we examine factors both negative and positive that influence research decisionmaking by people with mental illness and addiction in the context of innovative neuroscience research, and compare their decisionmaking with that of individuals with diabetes and healthy controls. Finally, we develop a new, low-burden screening tool to tailor and enhance the safeguard of informed consent in brain research, providing investigators with a practical, actionable, and protocol-adaptable method for strengthening positive-valence factors and ameliorate negative-valence factors affecting participant decisionmaking. Maximizing our established record of expertise in empirical ethics investigations and neuroethics, this sequence of projects leverages access to the exceptional neuroscience research conducted at Stanford University, including work by BRAIN initiative investigators; provides extensive, systematically collected data on influences on decisionmaking about innovative neuroscience research participation by individuals with mental or physical illness and healthy controls; and develops a new evidence-informed tool for use as a best practice in safeguarding human volunteers in cutting-edge neuroscience. Innovative neuroscience holds extraordinary promise for improving understanding of brain disorders that threaten human health, but as the BRAIN 2025 Scientific Vision notes, new ethical questions are emerging as scientists begin to solve the mysteries of the brain. A rigorous, hypothesis-driven approach to ethical dimensions of neuroscience inquiry is needed to provide investigators, IRBs, policymakers, and the public with evidence to better enable ethical participation in brain research. We develop new knowledge and a novel tool for use as a best practice in safeguarding volunteers in innovative neuroscience research, to ensure ethical participation, enhance trust in science, and accelerate discovery.",Enabling ethical participation in innovative neuroscience on mental illness and addiction: towards a new screening tool enhancing informed consent for transformative research on the human brain,9993927,R01MH114856,"['Achievement', 'Affect', 'Artificial Intelligence', 'BRAIN initiative', 'Base of the Brain', 'Behavior', 'Behavioral', 'Big Data', 'Brain', 'Brain Diseases', 'Cell model', 'Clinical Research', 'Cognition', 'Collection', 'Data', 'Decision Making', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Ecology', 'Effectiveness', 'Emotions', 'Ensure', 'Ethical Issues', 'Ethics', 'Failure', 'Fostering', 'Fright', 'Genes', 'Goals', 'Gold', 'Health', 'Human', 'Human Genome Project', 'Human Volunteers', 'In Vitro', 'Individual', 'Informed Consent', 'Institutional Review Boards', 'Interview', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Motivation', 'Negative Valence', 'Neurosciences', 'Neurosciences Research', 'Participant', 'Personhood', 'Positive Valence', 'Process', 'Protocols documentation', 'Psyche structure', 'Public Health', 'Request for Applications', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Scientist', 'Screening procedure', 'Series', 'Societies', 'Structure', 'Surveys', 'Testing', 'Theoretical model', 'Translations', 'Trust', 'Universities', 'Vision', 'Work', 'addiction', 'base', 'brain machine interface', 'brain research', 'clinical care', 'decision research', 'design', 'evidence base', 'health disparity', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative neurotechnologies', 'insight', 'member', 'neuroethics', 'neuropsychiatry', 'neuroregulation', 'new technology', 'novel', 'optogenetics', 'patient engagement', 'prevent', 'programs', 'sound', 'standard measure', 'tool', 'vaccine development', 'volunteer']",NIMH,STANFORD UNIVERSITY,R01,2020,454017,0.008688715667479703
"Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design PROJECT SUMMARY/ABSTRACT Molecular simulation is a powerful tool to predict the properties of biomolecules, interpret biophysical experiments, and design small molecules or biomolecules with therapeutic utility. However, a number of obstacles have impeded the development of quantitative, cloud-scale research workﬂows involving biomolecular simulation. Two main ob- stacles are the insufﬁcient accuracy of current atomistic models for biomolecules and small molecule therapeutics and the lack of interoperability in simulation toolchains used in both academic and industrial biomolecular research. Our original R01, “Open Data-driven Infrastructure for Building Biomolecular Force Fields for Predictive Bio- physics and Drug Design,” seeks to solve the ﬁrst problem. It helps fund our effort, the Open Force Field Initiative (https://openforceﬁeld.org) to develop open, extensible, and shared software and data infrastructure, implementing statistically robust methods of parameterizing force ﬁelds and choosing new force ﬁelds in a statistically sound manner. This work is designed to create not just a new generation of force ﬁelds, but an open technology to continue advancing force ﬁeld science. However, even with improved molecular models, putting together complete workﬂows of biomolecular simulations involves interfacing substantial numbers of different tools. However the majority of the existing molecular simulation workﬂows are mutually incompatible, with differing representations of the molecular models. The Open Force Field Initiative effort already includes the development of molecular data structures that we can ex- port into existing molecular simulation tools. We propose to extend the existing scope of our R01 to create an extensible common molecular simulation representation and translators to and from this representation. Such a set of tools will immediately make it signiﬁcantly easier to combine the disparate workﬂows developed for different sets of molecular simulation tools. Researchers will be able to set up and build the biophysical simulations using their usual tools, but run and analyze them with currently incompatible tools, enabling better matching of computational resources and methods to problems. It will help avoid trapping in a single software framework, and enable combinations of functionalities previously impossible without substantial developer time and effort. We will (Aim 1) work with partners to generalize our modular, extensible object model for representing parameterized biomolecular systems in a manner that accommodates the force ﬁeld terms currently supported by most popular biomolecular simulation packages. We will engineer it to be extensible to advanced interaction forms, such as polarizability and other multibody terms, and machine learning models for intermolecular forces. We will (Aim 2): enable easy conversion between components of molecular simulation workﬂows by allowing other molecular simulation packages to easily store their representations in this data model, developing converters that can import/export this object model to multiple popular ﬁle formats, focusing initially on OpenMM, AMBER, CHARMM, and GROMACS. We will demonstrate the utility of this interface in cloud-ready workﬂows. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This supplement will make it much easier for molecular simulation workﬂows to interoperate with each other in large-scale workﬂows.",Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design,10166314,R01GM132386,"['Affinity', 'Binding', 'Biophysics', 'COVID-19', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA', 'Development', 'Drug Design', 'Ecosystem', 'Engineering', 'Funding', 'Generations', 'Human', 'Individual', 'Industrialization', 'Infrastructure', 'Language', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Problem Solving', 'Property', 'Proteins', 'Pythons', 'RNA', 'Readability', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Scientist', 'Software Framework', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Work', 'Writing', 'biomaterial interface', 'computing resources', 'data infrastructure', 'data modeling', 'design', 'experimental study', 'file format', 'improved', 'interoperability', 'molecular modeling', 'open data', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'sound', 'structured data', 'tool']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,225000,-0.014666512914550772
"A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping PROJECT SUMMARY/ABSTRACT The metabolite and neurotransmitter profiles of neural tissues provide a unique window into brain’s physiological state and can be used to extract potential biomarkers for detecting and characterizing neurodegenerative diseases. Magnetic resonance spectroscopic imaging (MRSI) allows simultaneous mapping and quantification of a number of metabolites and neurotransmitters without exogenous contrast agents thus promised tremendous opportunities for molecular imaging of the brain. However, due to several fundamental technical challenges, including low SNR, poor spatial resolution, long imaging time and inaccurate separation of spectrally overlapping molecular signals, most in vivo MRSI studies to date are still limited to very low-resolution experiments (~1cm3 voxel size) with small brain coverages. The primary goal of this proposed research is to develop, optimize and evaluate a new framework to model, acquire and process MRSI data to enable simultaneous, high-resolution, whole- brain mapping of metabolites and neurotransmitters in clinically feasible time. To achieve this goal, in Aim 1, we will design and implement a novel acquisition strategy that synergistically combines SNR- efficient, multi-slab and multi-TE excitation, sparse sampling in a (k,t,TE)-space and optimized TE selection with maximum echo sampling to generate J-resolved (multi-TE) MRSI data with an unprecedented combination of speed, resolution and organ coverage. In Aim 2, we will develop novel nonlinear low-dimensional models of general MR spectra using a learning-based strategy that integrates the biochemical priors of neural tissues, known physics-based MRSI signal modeling and deep neural networks. These learned models will effectively reduce the dimensionality of the imaging problem and allow for significantly improved speed, resolution and SNR tradeoffs as well as signal separation. Novel computational solutions that effectively exploit the learned models and other spatial-spectral-TE constraints will be developed for spatiospectral reconstruction of metabolites and neurotransmitters from the noisy, high-resolution J-resolved MRSI data. Finally, in Aim 3, we will systematically evaluate the proposed technology in terms of speed, resolution, SNR, and quantitative accuracy using computer simulations, phantom and in vivo experiments. The feasibility and robustness of the proposed technology for mapping metabolites and neurotransmitters in both healthy volunteers and temporal lobe epilepsy patients with mesial temporal sclerosis will be demonstrated. The success of the proposed research will lead to significant progress for in vivo MRSI and represent an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases. This tool, when fully developed, will add a transformative dimension to the existing neuroimaging technology profiles, with the potential to impact the diagnosis and management of neurological and neurodegenerative diseases. PROJECT NARRATIVE Magnetic resonance spectroscopic imaging (MRSI) is a potentially powerful modality that allows simultaneous mapping of a number of metabolites and neurotransmitters noninvasively, which provide a unique window into brain’s physiological states and can be used to extract biomarkers for detecting and characterizing neurodegenerative diseases. However, the current MRSI techniques do not provide the desired combination of resolution, imaging speed and organ coverage for many basic science and clinical applications. The proposed research will develop a new rapid, J-resolved MRSI technology to enable high-resolution, whole-brain mapping of metabolites and neurotransmitters in clinically feasible time, which, if successful, will lead to significant progress for the field of MRSI and an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases.",A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping,10057847,R21EB029076,"['Address', 'Algorithmic Software', 'Basic Science', 'Biochemical', 'Biological Markers', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical', 'Computer Simulation', 'Contrast Media', 'Coupling', 'Data', 'Diagnosis', 'Dimensions', 'Disease', 'Equation', 'Evaluation', 'Evolution', 'Experimental Designs', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Image', 'Imaging Techniques', 'Imaging problem', 'Imaging technology', 'Learning', 'Machine Learning', 'Maps', 'Mechanics', 'Metabolic', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Monitor', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurotransmitters', 'Noise', 'Organ', 'Pathologic', 'Patients', 'Physics', 'Physiologic pulse', 'Physiological', 'Physiological Processes', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Scientist', 'Sclerosis', 'Signal Transduction', 'Software Tools', 'Solid', 'Spectrum Analysis', 'Speed', 'Technology', 'Temporal Lobe Epilepsy', 'Time', 'Tissues', 'Training', 'Validation', 'Variant', 'Water', 'base', 'clinical application', 'clinical translation', 'computerized data processing', 'deep neural network', 'design', 'experimental study', 'healthy volunteer', 'high dimensionality', 'imaging study', 'improved', 'in vivo', 'innovation', 'interest', 'magnetic field', 'magnetic resonance spectroscopic imaging', 'molecular imaging', 'nervous system disorder', 'neuroimaging', 'novel', 'novel strategies', 'patient population', 'potential biomarker', 'quantum', 'reconstruction', 'relating to nervous system', 'simulation', 'spectroscopic imaging', 'success', 'tool']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565546,-0.022507145733440568
"The Neuroscience of Everyday World- A novel wearable system for continuous measurement of brain function Innovations in human neuroimaging tools have driven profound advances in our understanding of brain function under well-controlled and constrained conditions. While we are gaining greater understanding of how the brain functions in single-snapshot experiments under restricted lab settings, we do not know how it works in dynamic, complex and multisensory real-world environments. The goal of this project is to build a portable, miniaturized, lightweight, high-density wearable combined – functional Near Infrared-Spectroscopy (fNIRS) – Electro-Encepholography (EEG) - Eye-tracking system for enabling “Neuroscience of the Everyday World (NEW)” by permitting long duration continuous monitoring of normal / altered brain activity during movement, perception, and social interaction in real time and in the real world. In Aim 1, We will (A) develop a wearable and fully hybrid high-density EEG-fNIRS system that supports autonomous long-term recordings (>6 hours), (B) develop combined and miniaturized active EEG-Electrodes / fNIRS-Optodes; and (C) integrate the wearable system with Tobii Pro 2 eye-tracking/scene-camera glasses and state- of-the-art computer vision for adaptive acquisition and automated data annotation. In Aim 2, we will measure brain activity during walking, perceiving, and interacting, with experiments gradually increasing in complexity through three phases from lab to real world settings in young healthy adults and conduct a proof of principle in two sample clinical populations. In Aim 3, we will create an analysis workflow for data collected in Aim 2 that will accomplish the following: (1) removing nuisance signals from fNIRS/EEG signals, (2) analysis of multimodal fNIRS/EEG and behavioral data, (3) automatic annotation of and adaptation for real world measurements. This project brings together engineers, scientists and clinicians with the goal of building the next generation of imaging tools to capture brain function in real time. With our technological sophistication, interdisciplinary focus, and ready access to well-characterized clinical populations, we are uniquely positioned to successfully develop, apply, and disseminate our NEW technology, and lay down a foundation upon which groundbreaking advances in our understanding of the links between brain activity and behavior will build. There is a need to link brain activity to human movement, perception and cognition, and social communication in real time, and in the Everyday World. This project aims to develop a multi- modal wearable functional neuroimaging device to study brain function in freely behaving healthy subjects and to track the breakdown of normal brain function potentially revealing brain patterns that are signatures of these conditions.",The Neuroscience of Everyday World- A novel wearable system for continuous measurement of brain function,10007021,U01EB029856,"['Address', 'Adult', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Blood Vessels', 'Brain', 'Brain imaging', 'Clinical', 'Cognition', 'Communication', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Device or Instrument Development', 'Devices', 'Disease', 'Electrodes', 'Engineering', 'Environment', 'Failure', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hour', 'Human', 'Hybrids', 'Imaging Device', 'Individual', 'Investigation', 'Laboratories', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences', 'Noise', 'Parkinson Disease', 'Pattern', 'Perception', 'Phase', 'Physiological', 'Population', 'Positioning Attribute', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Speech', 'Stroke', 'Support System', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translations', 'Walking', 'Work', 'density', 'design', 'experimental study', 'frontier', 'hemodynamics', 'innovation', 'insight', 'light weight', 'millisecond', 'miniaturize', 'multimodality', 'multisensory', 'nervous system disorder', 'neurofeedback', 'neuroimaging', 'new technology', 'next generation', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'response', 'sensory stimulus', 'signal processing', 'social communication', 'tool', 'visual tracking', 'wearable sensor technology']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),U01,2020,1000000,-0.008351911666351962
"Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale Project Summary This project aims to leverage the best of both computational and human expertise in neuronal reconstruction towards the goal of accelerating global neuroscience discovery from internationally-sourced imaging data. We propose to create a cloud-based unified platform for converging 3-dimensional images of neurons onto a single analysis platform to (1) train and grow a new expert community of global reconstructors to work across the data from these groups, to (2) generate a community-sourced neuronal reconstruction database of open imaging data that can be incorporated into a 3-dimensional map of neuronal interconnectivity - onto which (3) novel annotations and more complex functional and molecular data can be overlaid. Our approach will evolve with the growing needs of the neuroscience community over time. To do this, in Aim One (Neuronal Reconstruction at Scale), we will test if the newly developed crowd-sourced game-based platform Mozak can develop a collective of new human experts at scale, capable of accelerating the rate of current reconstruction by at least an order of magnitude, at the same time as increasing the robustness, quality and unbiasedness of the final reconstructions. In Aim Two (Robust Multi-Purpose Annotation), we will enhance basic neuronal reconstruction by adding specific semantic annotation— including soma volume and morphological quantification, volumetric analysis, and ongoing features (e.g. dendritic spines, axonal varicosities) requested from the neuroscience community. Experienced and high-ranking members will be given the opportunity to advance through increasingly complex neurons into full arbor brain-wide neuronal projections and multiple clustered groups of neurons in localized circuits. Finally, in Aim 3 (Creation of a Research-Adaptive Data Repository), we aim to develop a database of neuronal images reconstructed using the Mozak interface that will directly serve the general and specific needs of different research groups. Our goal is to make this database dynamically adaptive — as new research questions will invariably bring new needs for additional annotations and cross-referencing with other data modalities. This highquality unbiased processing repository will also be perfectly suited for training sets for automated algorithms, and the generation of a 3-dimensional maps such as Allen Institute for Brain Science (AIBS) common coordinate framework. We expect that the computational reconstruction methods will further improve with the new large corpus of “gold standard” reconstructions. Collectively, the completion of these three aims will create an analysis suite as well as an online community of experts capable of performing in depth analysis of large-scale datasets that will significantly accelerate neuroscience research, enhance machine learning for reconstruction analysis, and create a common platform of baseline neuronal morphology data against which aberrantly functioning neurons can be analyzed. Project Narrative  This project will create a new central nexus point for neuronal reconstruction and semantic annotation (Mozak) that can be used by all research labs via an accessible online portal. We will develop a new cadre of neuronal reconstruction experts that will— in conjunction with automated tools that are enhanced by their work — drastically increase the volume, quality and robustness of neuron reconstructions and annotations. Mozak reconstructions will be shared with existing repositories and will be continually updated and re-annotated based on emerging needs of research - ensuring perpetual relevance, and allowing us to generate a platform to establish the range of “baseline” 3-dimensional readouts of neuronal morphology against which diseased or malfunctioning neurons can be analyzed and understood. 1",Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale,10005472,R01MH116247,"['3-Dimensional', 'Adopted', 'Algorithms', 'Area', 'Axon', 'Brain', 'Characteristics', 'Classification', 'Communities', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Dendritic Spines', 'Disease', 'Ensure', 'Future', 'Gap Junctions', 'Generations', 'Goals', 'Gold', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Molecular', 'Morphology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Output', 'Process', 'Research', 'Science', 'Semantics', 'Slice', 'Source', 'Standardization', 'Structure', 'Techniques', 'Testing', 'Three-dimensional analysis', 'Time', 'Training', 'Update', 'Variant', 'Varicosity', 'Work', 'automated algorithm', 'base', 'citizen science', 'cloud based', 'crowdsourcing', 'data warehouse', 'experience', 'improved', 'large scale data', 'member', 'neuronal cell body', 'novel', 'online community', 'petabyte', 'programs', 'reconstruction', 'repository', 'tool', 'two-dimensional', 'web portal']",NIMH,UNIVERSITY OF WASHINGTON,R01,2020,628430,-0.005063557271196805
"Reconstructions and Representations of Cerebral Cortex Project Summary This project will generate extensive new findings about cortical organization and connectivity in humans and nonhuman primates using high quality, multimodal datasets provided by our collaborators and by the young adult Human Connectome Project (YA-HCP). It will accelerate progress by freely sharing the resulting tools and experimental data with the scientific community. The first aim will provide a critically needed evaluation of non-invasive connectivity measures in relation to invasive anatomical tracers in macaque monkeys. Different methods for estimating fMRI-derived functional connectivity will be evaluated in order to determine which approach best correlates with `ground truth' tracer-based anatomical connectivity. This aim will also generate new insights about cortical evolution by comparing areal organization across humans, macaques, and marmosets using a novel approach in which areal features (myelin maps, resting-state networks, and identified homologous areas) constrain the registration between species. The second aim will focus on cortical organization in individual subjects using refined HCP-style analysis tools. It will optimize and evaluate intersubject alignment (using a recently developed Multimodal Surface Matching method) and individual-subject parcellation (using a machine learning based areal classifier). An important outcome will be recommendations of `best practice' for other projects that acquire less fMRI data than in the YA- HCP. These data will also be used to characterize individual variability of human cortical areas. For each of 180 areas, individual differences in size and topology (neighborhood relationships) will be examined for heritability and for symmetry across the two hemispheres. Additional analyses will reveal whether some areas are reproducibly absent in some individuals and whether `novel' areas are present in some subjects. The third aim is to enhance the capabilities of the Connectome Workbench visualization and analysis platform and the BALSA database that were introduced during previous grant periods. Enhancements to Connectome Workbench will: (i) enable non-invasive electrophysiological (MEG/EEG) and invasive neurophysiological data to be integrated with MRI data and atlas-based connectivity data (ii) facilitate interoperability across different atlases, (iii) improve interactive `HCP-style' analysis capabilities, and (iv) enable cortical layer-based analyses. Enhancements to the BALSA database include: (i) a WebGL-based web-viewer for interactive online visualization with special focus on the unique data generated by this project, (ii) an online spatial localization tool and (iii) support for uploading scene files to BALSA from 5 other software platforms besides Workbench. Relevance This project will evaluate the accuracy of noninvasive methods for estimating brain connectivity in humans and monkeys, compare areal organization across species, and characterize individual variability of cortical organization using a multimodal parcellation derived from the Human Connectome Project. Results will be shared via a state-of-the-art database that stores extensively analyzed data. These efforts will increase our understanding of normal human brain circuitry and organization and may ultimately contribute to better diagnosis and treatment of brain disorders.",Reconstructions and Representations of Cerebral Cortex,9995177,R01MH060974,"['3-Dimensional', 'Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Callithrix', 'Cerebral cortex', 'Classification', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Electroencephalography', 'Electrophysiology (science)', 'Evaluation', 'Evolution', 'Family', 'Functional Magnetic Resonance Imaging', 'Grant', 'Heritability', 'Hour', 'Human', 'Individual', 'Individual Differences', 'Injections', 'Link', 'Macaca', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Myelin', 'Neighborhoods', 'Online Systems', 'Outcome', 'Physiological', 'Publishing', 'Recommendation', 'Reference Values', 'Reproducibility', 'Research Design', 'Rest', 'Scanning', 'Site', 'Surface', 'Testing', 'Time', 'Tracer', 'Twin Multiple Birth', 'Visualization', 'Work', 'advanced analytics', 'analytical tool', 'anatomical tracing', 'base', 'brain circuitry', 'computerized', 'connectome', 'denoising', 'design', 'functional MRI scan', 'improved', 'individual variation', 'insight', 'interoperability', 'multimodal data', 'multimodality', 'neuroimaging', 'neurophysiology', 'nonhuman primate', 'novel', 'novel strategies', 'reconstruction', 'tool', 'user-friendly', 'young adult']",NIMH,WASHINGTON UNIVERSITY,R01,2020,650574,-0.0034338174642991885
"BRAIN INITIATIVE RESOURCE: DEVELOPMENT OF A HUMAN NEUROELECTROMAGNETIC DATA ARCHIVE AND TOOLS RESOURCE (NEMAR) To take advantage of recent and ongoing advances in intensive and large-scale computational methods, and to preserve the scientific data created by publicly funded research projects, data archives must be created as well as standards for specifying, identifying, and annotating deposited data. The value of and interest in such archives among researchers can be greatly increased by adding to them an active computational capability and framework of analysis and search tools that support further analysis as well as larger scale meta-analysis and large scale data mining. The OpenNeuro.org archive, begun as a repository for functional magnetic resonance imaging (fMRI) data, is such an archive. We propose to build a gateway to OpenNeuro for human electrophysiology data (EEG and MEG, as well as intracranial data recorded from clinical patients to plan brain surgeries or other therapies) – herein we refer to these modalities as neuroelectromagnetic (NEM) data. The Neuroelectromagnetic Data Archive and Tools Resource (NEMAR) at the San Diego Supercomputer Center will act as a gateway to OpenNeuro for NEM data research. Such data uploaded to NEMAR at SDSC will be deposited in the OpenNeuro archive. Still- private NEM data in OpenNeuro will, on user request, be copied to the NEMAR gateway for further user processing using the XSEDE high-performance resources at SDSC in conjunction with The Neuroscience Gateway (nsgportal.org), a freely available and easy to use portal to use of high-performance computing resources for neuroscience research. Publicly available OpenNeuro NEM data will be able to be analyzed by running verified analysis applications on the OpenNeuro system. In this project we will build an application to evaluate the quality of uploaded NEM data, and another to visualize the data, for EEG and MEG at both the scalp and brain source levels, including time-domain and frequency-domain dynamics time locked to sets of experimental events learned from the BIDS- and HED-formatted data annotations. The NEMAR gateway will take a major step toward applying machine learning methods to a large store of carefully collected and stored human electrophysiologic brain data to spur new developments in basic and clinical brain research. The NEMAR gateway to the OpenNeuro.org human neuroimaging data archive will build tools to add human electrical and magnetic brain activity records to the archive, to evaluate its quality for users and visualize its features. The resulting facility will allow applications of new machine learning methods to research on human brain dynamics that can be expected to lead to breakthroughs in understanding how the human brain supports our awareness and behavior in both health and disease.",BRAIN INITIATIVE RESOURCE: DEVELOPMENT OF A HUMAN NEUROELECTROMAGNETIC DATA ARCHIVE AND TOOLS RESOURCE (NEMAR),9985198,R24MH120037,"['Archives', 'Awareness', 'BRAIN initiative', 'Base of the Brain', 'Behavior', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Clinical', 'Cloud Computing', 'Communities', 'Computing Methodologies', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Deposition', 'Descriptor', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Educational workshop', 'Electrophysiology (science)', 'Engineering', 'Environment', 'Evaluation', 'Event', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Funding', 'Grant', 'Health', 'High Performance Computing', 'Human', 'Infrastructure', 'Internet', 'Laboratories', 'Lead', 'Libraries', 'Magnetic Resonance', 'Magnetism', 'Magnetoencephalography', 'Meta-Analysis', 'Methods', 'Mining', 'Modality', 'Neurosciences', 'Neurosciences Research', 'Patients', 'Performance', 'Privatization', 'Process', 'Quality Control', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Running', 'Scalp structure', 'Science', 'Source', 'Specific qualifier value', 'Spottings', 'Staging', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Visualization software', 'base', 'brain research', 'brain surgery', 'built environment', 'computational platform', 'computerized data processing', 'computing resources', 'cyber infrastructure', 'data analysis pipeline', 'data archive', 'data curation', 'data format', 'data mining', 'data quality', 'data structure', 'data submission', 'data tools', 'hackathon', 'interest', 'large scale data', 'machine learning method', 'neuroimaging', 'preservation', 'repository', 'response', 'sensor', 'structured data', 'supercomputer', 'support tools', 'tool', 'tool development', 'web interface', 'web services', 'web site']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R24,2020,900723,0.016432361108965444
"A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive Project Summary The Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative promotes the development and application of technologies to describe the temporal and spatial dynamics of cell types and neural circuits in the brain. The Principal Investigator, senior personnel and staff of this project have diverse expertise required to marshall data across the BRAIN Initiative consortium, including experience in data collection from multiple institutions, large-scale quality control and analysis processing capability, familiarity with NIH policy and public archive deposition strategies. To promote smooth interactions across a large research consortium, we will develop the Neuroscience Multi-Omic Archive (NeMO Archive), a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects. We will utilize a federated model for data storage such that the physical location of data can be distributed between the NeMO local file system, public repositories, and a cloud-based storage system (e.g. Amazon S3). We will leverage this capability and distribute BRAIN Initiative data between our local filesystem and the cloud. The Nemo Archive will be a data resource consistent with the principles advanced by research community members who are launching resources in next generation NIH data ecosystem. These practices include FAIR Principles, documentation of APIs, data-indexing systems, workflow sharing, use of shareable software pipelines and storage on cloud-based systems. The information incorporating into the NeMO archive will, in part, enable understanding of 1) genomic regions associated with brain abnormalities and disease; 2) transcription factor binding sites and other regulatory elements; 3) transcription activity; 4) levels of cytosine modification; and 5) histone modification profiles and chromatin accessibility. It will enable users to answer diverse questions of relevance to brain research, such as identifying diagnostic candidates, predicting prognosis, selecting treatments, and testing hypotheses. It will also provide the basic knowledge to guide the development and execution of predictive and machine learning algorithms in the future.   Project Narrative The Neuroscience Multi-Omic Archive (NeMO Archive) is a data repository that is specifically focused on the storage and dissemination of omic data from the BRAIN Initiative and related brain research projects.",A BRAIN Initiative Resource: The Neuroscience Multi-omic Data Archive,9989180,R24MH114788,"['Archives', 'Atlases', 'BRAIN initiative', 'Binding Sites', 'Bioconductor', 'Brain', 'Brain Diseases', 'Chromatin', 'Communities', 'Computer software', 'Cytosine', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Management Resources', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Diagnostic', 'Docking', 'Documentation', 'Elements', 'Ensure', 'Familiarity', 'Future', 'Generations', 'Genetic Transcription', 'Genomic Segment', 'Individual', 'Institution', 'Internet', 'Knowledge', 'Location', 'Metadata', 'Modeling', 'Modification', 'Multiomic Data', 'Neurosciences', 'Patients', 'Personnel Staffing', 'Phenotype', 'Policies', 'Principal Investigator', 'Procedures', 'Process', 'Quality Control', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Project Grants', 'Resources', 'Running', 'Services', 'Site', 'Standardization', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analysis pipeline', 'base', 'brain abnormalities', 'brain research', 'cell type', 'cloud based', 'cloud storage', 'complex R', 'computerized data processing', 'data archive', 'data centers', 'data ecosystem', 'data ingestion', 'data integration', 'data pipeline', 'data resource', 'data standards', 'data submission portal', 'data visualization', 'data warehouse', 'database structure', 'experience', 'experimental study', 'histone modification', 'indexing', 'machine learning algorithm', 'member', 'multiple data types', 'multiple omics', 'neural circuit', 'next generation', 'online resource', 'operation', 'outcome forecast', 'programs', 'public repository', 'query tools', 'repository', 'tool', 'transcription factor', 'web site', 'working group']",NIMH,UNIVERSITY OF MARYLAND BALTIMORE,R24,2020,1263611,-0.006974724267743304
"Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets Project Summary During the past three decades non-invasive functional brain imaging has developed immensely in terms of measurement technologies, analysis methods, and innovative paradigms to capture information about brain function both in healthy and diseased individuals. Although functional MRI (fMRI) has become very useful, it only provides indirect information about neuronal activity through the neurovascular coupling with a limited temporal resolution. Magnetoencephalography (MEG) and electroencephalography (EEG) remain the only available noninvasive techniques capable of directly measuring the electrophysiological activity with a millisecond resolution. During the past eight years we have developed, with NIH support, the MNE-Python software, which covers multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. To further extend our software to meet the needs of a growing user base and reflect recent developments in the MEG/EEG field we will pursue three specific Aims. In Aim 1 we will: (i) Create an all-embracing suite of noise cancellation tools incorporating and extending methods present in different MEG systems; (ii) Implement device independent methods for head-movement determination and compensation on the basis of head movement data recorded during a MEG session; (iii) Develop methods for automatic tagging of artifacts using machine learning approaches. In Aim 2 our focus is to extend the software to make modern distributed computing resources easily usable in processing and to allow for remote visualization without the need to move large amounts of data across the network. Finally, in Aim 3, we will continue to develop MNE-Python using best programming practices ensuring multiplatform compatibility, extensive web-based documentation, training and forums, and hands-on training workshops. As a result of these developments the MNE-Python will be able to effectively process large number of subjects and huge amounts data ensuing and from multi-site studies harmoniously across different MEG/EEG systems. Narrative MEG and EEG can be used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. However, widespread use of these methods especially in large populations has been problematic because of the lack of well-established analysis approaches, which map the sensor data into the brain space for detailed temporal, spatial, and connectivity analysis. This research will provide well-documented and tested novel analysis software to promote both basic neuroscience and clinical research applications using MEG and EEG.",Scalable Software for Distributed Processing and Visualization of Multi-Site MEG/EEG Datasets,9934294,R01NS104585,"['Adult', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Brain imaging', 'Brain region', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Collaborations', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Databases', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Documentation', 'Ecosystem', 'Educational workshop', 'Electroencephalography', 'Electrophysiology (science)', 'Ensure', 'Epilepsy', 'Experimental Designs', 'Financial compensation', 'Functional Magnetic Resonance Imaging', 'Guidelines', 'Head', 'Head Movements', 'Hour', 'Human', 'Individual', 'Laboratories', 'Language Development', 'Link', 'Machine Learning', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modernization', 'Morphologic artifacts', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Population', 'Process', 'Pythons', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Schizophrenia', 'Science', 'Scientist', 'Site', 'Statistical Data Interpretation', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Writing', 'analysis pipeline', 'autism spectrum disorder', 'base', 'cloud based', 'cluster computing', 'computing resources', 'data acquisition', 'data analysis pipeline', 'data exchange', 'falls', 'human data', 'innovation', 'large datasets', 'millisecond', 'multithreading', 'neurovascular coupling', 'novel', 'open source', 'pedagogy', 'sensor', 'sensor technology', 'software development', 'source localization', 'symposium', 'temporal measurement', 'tool', 'verification and validation']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,543993,0.017859509531928452
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10052188,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'combat', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2020,347094,0.0019492335988971167
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10023935,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2020,256578,-0.015009788696709067
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9922272,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratory of Neuro Imaging Resource', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data curation', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'image archival system', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2020,1217435,-0.01005928351298871
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we willl bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This supplement to the original RO1 is to purchase a small GPU cluster to enable rapid prototyping of many of the approaches that are proposed in this project outlined in the four aims. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This equipment supplement will provide computational resources for testing of new techniques throughout the duration of the grant.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,10157034,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Award', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Drug Design', 'Electrostatics', 'Ensure', 'Equipment', 'Error Sources', 'Generations', 'Goals', 'Grant', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'computing resources', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'prototype', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,96003,-0.03323851002938093
"Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases 7. Project Summary/Abstract There is an urgent need to support research that generates high-quality evidence to inform clinical decision making. Cluster randomized trials (CRTs) achieve the highest standard of evidence for the evaluation of community-level effectiveness of intervention strategies against infectious diseases. However, there is a need to develop new methods to improve the design and analysis of CRTs because unique and complicated analytical challenges arise in such settings. One such issue relates to the intraclass correlation coefficient (ICC), the degree to which individuals within a community are more similar to one another than to individuals in other communities. Design and analysis of CRTs must take into account the ICC. Lack of accurate information on the ICC jeopardizes the power of CRTs, leads to suboptimal choices of analysis methods and complicates the interpretation of study results. However, reliable information on the ICC is difficult to obtain. A robust and efficient approach for estimating ICCs is based on the second-order generalizing estimating equations. However, its use has been limited by considerable computational burden and poor convergence rates associated with the existing algorithms solving these equations. The first aim addresses these computational challenges. Missing data are ubiquitous and can lead to bias and loss of efficiency. The second aim proposes to develop novel robust and efficient methods for estimating ICCs in the presence of informative missing data. For infectious diseases, the underlying contact/transmission networks give rise to complicated correlation structure. The third aim is to develop network and epidemic models to project the ICC. User-friendly software will be developed to facilitate the implementation of new methods. An immediate application of the proposed methods is their application to the Botswana Combination Prevention Project to improve the estimation of intervention effect and to generate reliable ICC estimates for designing future CRTs in the same population. The proposed methods can be applied to other ongoing and future CRTs, and more broadly, to longitudinal studies and agreement studies where ICCs are also of great interest. The proposed research is significant, because success in addressing these issues will improve the ability to design efficient and well-powered CRTs and the precision in estimating the effects of intervention strategies. Innovation lies in the development of improved computing algorithms adapting approaches from deep learning, the use of semiparametric efficiency theory, and the integration of network modeling, epidemic modeling and statistical inference. The results of the proposed research will benefit both ongoing and future CRTs, permit more efficient use of the resources, and ultimately expedite the control of infectious diseases. 8. Project Narrative The proposed research is relevant to public health because improved methodologies for the design and analysis of cluster randomized trials will benefit both ongoing and future studies, permit more efficient use of the resources, and ultimately improve public health response intended to control the spread of infectious diseases. Thus, the proposed research is relevant to the part of NIAID’s mission that pertains to conducting and supporting research to prevent infectious diseases and to respond to emerging public health threats.",Network modeling and robust estimation of the intraclass correlation coefficient to inform the design and analysis of cluster randomized trials for infectious diseases,10011756,R01AI136947,"['AIDS prevention', 'Accounting', 'Address', 'Affect', 'Agreement', 'Algorithms', 'Americas', 'Area', 'Attention', 'Behavior Therapy', 'Botswana', 'Characteristics', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Data', 'Dependence', 'Development', 'Disease', 'Disease Outbreaks', 'Ebola', 'Effectiveness of Interventions', 'Epidemic', 'Equation', 'Evaluation', 'Future', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Institute of Medicine (U.S.)', 'Intervention', 'Intervention Studies', 'Knowledge', 'Lead', 'Longitudinal Studies', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nosocomial Infections', 'Population', 'Prevention', 'Prevention strategy', 'Probability', 'Public Health', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Support', 'Resources', 'Role', 'Running', 'Science', 'Societies', 'Structure', 'System', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'base', 'clinical decision-making', 'collaboratory', 'deep learning', 'design', 'effectiveness evaluation', 'experience', 'high standard', 'improved', 'innovation', 'insight', 'interest', 'intervention effect', 'mathematical model', 'network models', 'novel', 'prevent', 'response', 'semiparametric', 'success', 'systems research', 'theories', 'transmission process', 'user friendly software']",NIAID,"HARVARD PILGRIM HEALTH CARE, INC.",R01,2020,247413,-0.001220134158688555
"ShapeWorks in the Cloud Project Summary This application is submitted in response to NOT-OD-20-073 as an administrative supplement to the parent award R01AR076120 titled: ""Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches."" The form (or shape) of anatomies is the clinical language that describes abnormal mor- phologies tied to pathologic functions. Quantifying such subtle morphological shape changes requires parsing the anatomy into a quantitative description that is consistent across the population in question. For more than 100 years, morphometrics has been an indispensable quantitative tool in medical and biological sciences to study anatomical forms. But its representation capacity is limited to linear distances, angles, and areas. Sta- tistical shape modeling (SSM) is the computational extension of classical morphometric techniques to analyze more detailed representations of complex anatomy and their variability within populations The parent award ad- dresses existing roadblocks for the widespread adoption of SSM computational tools in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM) and its associated suite of open-source software tools, ShapeWorks. ShapeWorks enables learning population-level shape representation via automatic dense placement of homologous landmarks on image segmentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread applicability and impact to medicine and biology are hindered by computational barriers that most existing shape modeling packages face. The goal of this supplement award is to provide supplemental support for Aim 3 of the parent award to leverage best practices in software development and advances in cloud computing to enable researchers with limited computational resources and/or large-scale cohorts to build and execute custom SSM workﬂows us- ing remote scalable computational resources. To achieve this goal, we have developed a plan to enhance the design, implementation, and cloud-readiness of ShapeWorks and augmented our scientiﬁc team to add senior, experienced software engineers/developers who have extensive experience in professional programming, code refactoring, and scientiﬁc computing. This award will provide our team with the support necessary to (Aim 1) de- sign ShapeWorks as a collection of modular and reusable services, (Aim 2) decouple ShapeWorks services from explicitly encoded data sources, and (Aim 3) refactor ShapeWorks to scale efﬁciently on the cloud. All software development will be performed in adherence to software engineering practices and design principles, including coding style, documentation, and version control. The proposed efforts will be released as open-source software in a manner consistent with the principles of reproducible research and the practices of open science. Our long- term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein in addition to the parent award will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. The impact and scientiﬁc value of ShapeWorks have been recognized in a range of applications, including psychology, biological phenotyping, car- diology, and orthopedics. If funded, this supplement will provide support to revise, refactor, and redeploy Shape- Works to take advantage of new cloud computing paradigms, to be robust, sustainable, scalable, and accessible to a broader community, and to address the growing need for shape modeling tools to handle large collections of clinical data and to obtain sufﬁcient statistical power for large shape studies.",ShapeWorks in the Cloud,10166337,R01AR076120,"['Address', 'Adherence', 'Administrative Supplement', 'Adoption', 'Anatomy', 'Applied Research', 'Architecture', 'Area', 'Award', 'Biological', 'Biological Sciences', 'Biology', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Cloud Service', 'Code', 'Collection', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computer Models', 'Computer software', 'Computers', 'Coupled', 'Custom', 'Data', 'Data Sources', 'Databases', 'Disabled Persons', 'Documentation', 'Environment', 'Face', 'Funding', 'Goals', 'Image', 'Imagery', 'Language', 'Learning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Morphology', 'Occupations', 'Online Systems', 'Orthopedics', 'Parents', 'Pathologic', 'Phenotype', 'Population', 'Privatization', 'Psychology', 'Readiness', 'Reproducibility', 'Research', 'Research Personnel', 'Running', 'Scientist', 'Services', 'Shapes', 'Software Design', 'Software Engineering', 'Software Tools', 'Source Code', 'Speed', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'base', 'cohort', 'computational platform', 'computerized tools', 'computing resources', 'data management', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'large datasets', 'model development', 'open data', 'open source', 'particle', 'response', 'scientific computing', 'shape analysis', 'software development', 'statistics', 'tool', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,210000,0.00515736801882053
"Center for Mesoscale Mapping Overview of the Proposed Resource – Abstract The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings. While there is still no formal consensus on the definition of mesoscopic within the neuroscience community, we take as our guide the spatial and temporal scales at which local groups of neurons act in coherent fashion – in the cortex, this includes the spatial scale of columns and laminar structures (between ~0.1-1 mm), while in deeper structures includes the myriad of deep brain and brainstem nuclei. Preliminary data from our own center, and of course others throughout the world, now support the notion that we are on the threshold of being able to map, measure and perturb the human brain at these scales, and do so comprehensively across wide swaths of the human brain. Temporally too, recent advances suggest a convergence between temporal scales addressable with tools like fMRI, which can now investigate delta frequency coherent phenomena, and advanced electromagnetic tools to measure and perturb coherent electrophysiological activity at higher frequencies still. With this convergence in mind, the tools we proposed to develop within the TRDs of the CMM will provide our Collaborative and Service User community with the important “missing links” between the advances in human cognitive neuroscience at the “system level,” and the enormous strides in cellular level circuit functional characterization. Our Collaborators will bring their own unique challenges to help us define and further refine these tools, offering problems requiring distinct measures of human brain structural and functional properties in a variety of normal and disease settings. Our Service Users will utilize our tools to better understand human neural systems, and particularly human disease states from multiple sclerosis to Alzheimer’s, to depression and epilepsy. Finally, our Center will seek to disseminate these tools, through open-source software and hardware designs, industrial partnerships and “hands-on” teaching courses for hardware, and to train a new generation of human neuroscientists in the use of our advanced tools to explore the human brain at this next frontier. Overview of the Proposed Resource – Narrative The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings.",Center for Mesoscale Mapping,10038177,P41EB030006,"['3-Dimensional', 'Acceleration', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Basic Science', 'Biological', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cerebral Palsy', 'Communities', 'Computer Models', 'Computer software', 'Consensus', 'Data', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electrophysiology (science)', 'Epilepsy', 'Evaluation', 'Event', 'Fiber', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Histologic', 'Human', 'Image', 'Investigation', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Mental Depression', 'Mental disorders', 'Microscopic', 'Mind', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Motion', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Online Systems', 'Performance', 'Peripheral Nerve Stimulation', 'Property', 'Publications', 'Research Personnel', 'Resolution', 'Resources', 'Respiration', 'Scanning', 'Services', 'Signal Transduction', 'Sleep Disorders', 'Slice', 'Space Models', 'Spatial Distribution', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training Programs', 'Transcranial magnetic stimulation', 'Visualization', 'Work', 'base', 'cognitive neuroscience', 'data space', 'deep learning', 'design', 'electric field', 'frontier', 'human disease', 'human imaging', 'improved', 'in vivo', 'industry partner', 'instrumentation', 'machine learning algorithm', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'post-doctoral training', 'pre-doctoral', 'reconstruction', 'relating to nervous system', 'response', 'spatiotemporal', 'tool', 'tool development', 'translational neuroscience', 'usability', 'white matter']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,P41,2020,1731501,-0.001945890617501818
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we aim to bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This approach will bring statistical rigor to the ﬁeld of force ﬁeld construction and application by providing a means to make data-driven decisions, while enhancing reproducibility by enabling it to become a rigorous and reproducible science using a fully open infrastructure and datasets. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life do their jobs. They also use simulations to help design new medications – compounds that can bind and inﬂuence the behavior of these molecules of life, and thereby block diseases at the molecular level. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,9887804,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Design', 'Electrostatics', 'Ensure', 'Error Sources', 'Generations', 'Goals', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Occupations', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'behavior influence', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,675565,-0.030483649006667432
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10019388,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2020,381282,0.01904933802897463
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9982966,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'big-data science', 'brain dysfunction', 'career', 'clinical database', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistical learning', 'statistics', 'symposium', 'tool', 'usability', 'visual tracking']",NIEHS,VANDERBILT UNIVERSITY,K22,2020,202463,-0.00726623171065115
"Carolina Population Center PROJECT SUMMARY/ABSTRACT The Carolina Population Center requests infrastructure support that will advance population dynamics research at CPC by increasing research impact, innovation, and productivity, supporting the development of junior scientists, and reducing the administrative burden on scientists. Infrastructure support will advance science in three primary research areas: Sexuality, Reproduction, Fertility, and Families; Population, Health, and the Environment; and Inequality, Mobility, Disparities, and Well-Being. Much of the research at CPC draws on large publicly available longitudinal data sets that our faculty have designed and collected, including the National Longitudinal Study of Adolescent to Adult Health, the China Health and Nutrition Survey, newer surveys associated with the Transfer Project, and the Study of the Tsunami Aftermath and Recovery, all of which will continue to be important in work related to our primary research areas over the next five years. These projects embody several themes that have guided research at CPC since the Center's inception. These themes, which will continue to shape our work, are the importance of life course processes and longitudinal data, multi-level processes and measurement of context, interventions and natural experiments as means of learning about causal processes, and the relevance of sociodemographic variables such as age, gender, race- ethnicity, and socioeconomic status for disparities in health and well-being. By embedding these themes, our projects provide data that enable us to address barriers that otherwise impede progress in the population sciences generally, and in our primary research areas in particular. We request support for three cores which in combination will provide an institutional infrastructure that will push populations dynamics research forward by empowering CPC faculty to tackle challenging questions using state of the art measurement techniques and methods. The Administrative Core plans activities that maintain a stimulating intellectual community, streamlines administrative processes so that scientists can focus on research, coordinates activities of the Cores so that services are offered efficiently, and communicates information about research and data more broadly. The Development Core supports early stage investigators and other faculty with exciting new ideas through multiple mechanisms: workshops, access to technical expertise in measurement, and seed grants. The Research Services Core enables scientists to address complex and important population research issues by providing access to state-of-the-art research tools and professional support for programming, survey development, and analysis. NARRATIVE This project will provide infrastructure support for a cutting edge program of research on population dynamics at the Carolina Population Center. Research at the Center will analyze state-of-the art data to address fundamental questions regarding fertility, adolescent health, and links between the environment and health. Special attention will be paid to factors creating health disparities.",Carolina Population Center,10005569,P2CHD050924,"['Address', 'Adolescent', 'Adopted', 'Adult', 'Age', 'Applications Grants', 'Area', 'Attention', 'Biological Markers', 'China', 'Cognitive', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Vision Systems', 'Creativeness', 'Data', 'Data Collection', 'Development', 'Diffuse', 'Educational workshop', 'Environment', 'Ethnic Origin', 'Extramural Activities', 'Faculty', 'Family', 'Fertility', 'Fostering', 'Funding', 'Gender', 'Genetic', 'Grant', 'Hand', 'Health', 'Health Surveys', 'Home environment', 'Inequality', 'Infrastructure', 'Intervention', 'Journals', 'Learning', 'Life Cycle Stages', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Mentors', 'Methods', 'Natural experiment', 'Nutrition Surveys', 'Personal Satisfaction', 'Phase', 'Policy Making', 'Population', 'Population Dynamics', 'Population Research', 'Population Sciences', 'Postdoctoral Fellow', 'Process', 'Production', 'Productivity', 'Publishing', 'Race', 'Recovery', 'Reproduction', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Schools', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seeds', 'Services', 'Sexuality', 'Shapes', 'Socioeconomic Status', 'Structure', 'Students', 'Surveys', 'Talents', 'Teacher Professional Development', 'Technical Expertise', 'Techniques', 'Training Programs', 'Tsunami', 'Universities', 'Work', 'adolescent health', 'career', 'collaborative environment', 'cost', 'data access', 'design', 'empowered', 'experience', 'faculty support', 'health disparity', 'innovation', 'interdisciplinary collaboration', 'longitudinal dataset', 'novel strategies', 'population health', 'privacy protection', 'programs', 'research and development', 'response', 'sociodemographic variables', 'success', 'tool']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,P2C,2020,774402,-0.005511881204910757
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10139715,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2020,456359,-0.010041705398810767
"PsyNeuLink:  A Block Modeling Environment for Cognitive Neuroscience and Computational Psychiatry Project Summary Paralleling the growth of neuroscience research, there has been an explosion in the development of computationally explicit models of the functions of core brain subsystems. Unfortunately, however, there has not been a commensurate development of the tools needed to share, validate, and compare such models, or integrate them into models of system-level function. Such sharing, evaluation, and integration are necessary if computational modeling efforts are to be useful not only in generating reliable and accurate accounts of how brain subsystems operate, but also of how they interact to give rise to higher cognitive functions, and how disruptions of such interactions may give rise to disturbances of mental function observed in psychiatric and neurological disorders. This proposal seeks to meet this need by developing PsyNeuLink: an open source, Python-based software environment that makes it easy to create new models, import and/or re-implement existing ones, integrate these within a single software environment that will facilitate head-to-head comparison of comparable models, the assembly of complementary models into system-level models, and serve as a common repository for the documentation and dissemination of such models for both research and didactic purposes (i.e., publication, education, etc.). These goals will be pursued under two Specific Aims: 1) Extend the scope of modeling efforts that PsyNeuLink can accommodate by: i) enhancing its application programmer interface (API) used to add new components and interfaces to statistical analysis tools and other modeling environments (such as PyTorch, Emergent and ACT-R; ii) enriching its Library by adding PsyNeuLink implementations of influential models of neural subsystems; and iii) developing a publicly available workbook of simulation exercises as both an introduction to PsyNeuLink and for use in Cognitive Neuroscience and Computational Psychiatry curricula. 2) Accelerate PsyNeuLink by developing a custom compiler that preserves its simplicity and flexibility, while dramatically increasing its speed, to make it suitable for simulation of large and complex system-level models, and for parameter estimation, model fitting, and model comparison. This project will exploit the power and accelerating use of Python, and modern just-in-time compilation methods to develop a tool designed specifically for the needs of systems-level Cognitive Neuroscience and Computational Psychiatry. This promises to open up new opportunities for research at the systems-level — a level of analysis that is crucial both for understanding how human mental function emerges from the interplay among neural subsystems, and how disturbances of individual neural subsystems impact this interplay, disruptions of which are almost certainly a critical factor in neurologic and psychiatric disorders. Project Narrative Paralleling the growth of neuroscience research has been an explosion in the development of computationally explicit models of the functions of core brain subsystems. Unfortunately, however, there has not been a commensurate development of the tools needed to share, validate, and compare such models, or integrate them into models of system-level function. This proposed project seeks to address this need by developing a standard software platform for the construction, documentation, sharing, and integration of computational models of brain function, that promises to accelerate the study of how system-level interactions give rise to mental function and, critically, the kinds of disruptions of such system-level interactions produced by disturbances of individual subsystems — disruptions that are sure to be a complex but critical factor in neurological and psychiatric disorders.",PsyNeuLink:  A Block Modeling Environment for Cognitive Neuroscience and Computational Psychiatry,9976610,R21MH117548,"['Acceleration', 'Address', 'Architecture', 'Attention', 'Basal Ganglia', 'Biological', 'Biological Models', 'Brain', 'Complement', 'Complex', 'Computer Models', 'Computer software', 'Custom', 'Data', 'Development', 'Documentation', 'Education', 'Educational Curriculum', 'Environment', 'Episodic memory', 'Evaluation', 'Exercise', 'Explosion', 'Foundations', 'Goals', 'Grain', 'Growth', 'Hippocampus (Brain)', 'Human', 'Individual', 'Influentials', 'Libraries', 'Literature', 'Maintenance', 'Manuals', 'Mental disorders', 'Methods', 'Modeling', 'Modernization', 'Neurosciences Research', 'Perceptual learning', 'Play', 'Prefrontal Cortex', 'Procedures', 'Psychiatry', 'Publications', 'Publishing', 'Pythons', 'Research', 'Role', 'Seeds', 'Short-Term Memory', 'Speed', 'Statistical Data Interpretation', 'System', 'Time', 'Writing', 'application programming interface', 'base', 'cognitive function', 'cognitive neuroscience', 'cognitive process', 'deep learning', 'deep neural network', 'design', 'flexibility', 'head-to-head comparison', 'improved', 'learning network', 'memory encoding', 'memory retrieval', 'mental function', 'nervous system disorder', 'neural model', 'open source', 'parallelization', 'preservation', 'programs', 'relating to nervous system', 'repository', 'simulation', 'tool', 'tool development']",NIMH,PRINCETON UNIVERSITY,R21,2020,197545,-0.003983230744090369
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10115288,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'machine learning method', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2020,99860,-0.009926373698669406
"Reproducible imaging-based brain growth charts for psychiatry ABSTRACT Major psychiatric illnesses are increasingly understood as disorders of brain development, which has led to large-scale studies of youth that combine multi-modal neuroimaging with clinical phenotyping. Together, such data have emphasized the promise of objective ‘growth charts’ of brain development. However, synergies across major efforts remains unrealized due to use of different clinical instruments, different scanning protocols, challenges in informatics, and difficulties in data integration. In this proposal, we will overcome these obstacles by leveraging advances in multivariate harmonization and analysis techniques to build highly reproducible growth charts of human brain development. To do this, we will aggregate and harmonize eight existing large-scale developmental imaging studies, comprising over 10,000 participants between the age of 5- 24 (Aim 1). We will use this harmonized data to build generalizable indices of normal network brain development (Aim 2). Finally, developmental abnormalities within specific brain networks will be linked to dimensions of psychopathology (Aim 3). Critically, all code, data, and derived indices will be shared publicly, creating a massive new resource to accelerate research in the developmental neuroscience community (Aim 4). In sum, this proposal will have provide a new data resource, yield reproducible growth charts of brain development, and delineate novel mechanisms regarding the developmental basis of psychopathology in youth. RELEVANCE Psychiatric illnesses often begin in childhood, adolescence, or young adulthood, and are increasingly conceptualized as disorders of brain development. Reproducible growth charts of bran development are critical for understanding both normal brain development and abnormalities associated with diverse psychopathology. Early interventions crafted using these growth charts would benefit the public health by reducing the huge disability associated with psychiatric disorders and limiting the costs to society at large.",Reproducible imaging-based brain growth charts for psychiatry,10001025,R01MH120482,"['Address', 'Adolescence', 'Age', 'Base of the Brain', 'Bayesian Method', 'Brain', 'Brain Diseases', 'Categories', 'Childhood', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Pooling', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Docking', 'Early Intervention', 'Failure', 'Fright', 'Functional Imaging', 'Grain', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Informatics', 'International', 'Life', 'Link', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurosciences', 'Outcome', 'Participant', 'Phenotype', 'Process', 'Properdin', 'Protocols documentation', 'Psychiatry', 'Psychopathology', 'Public Health', 'Recording of previous events', 'Reproducibility', 'Research', 'Resources', 'Rest', 'Sampling', 'Scanning', 'Sex Differences', 'Site', 'Societies', 'Structure', 'Sum', 'Symptoms', 'Techniques', 'Training', 'Validation', 'Variant', 'Youth', 'aging brain', 'anxious', 'base', 'brain abnormalities', 'clinical phenotype', 'computing resources', 'cost', 'data archive', 'data harmonization', 'data integration', 'data resource', 'design', 'disability', 'externalizing behavior', 'image processing', 'imaging study', 'indexing', 'insight', 'instrument', 'machine learning method', 'multidimensional data', 'multimodality', 'neuroimaging', 'novel', 'portability', 'quality assurance', 'response', 'segregation', 'serial imaging', 'sex', 'somatosensory', 'synergism', 'theories', 'young adult']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,724789,-0.007926857714900645
"Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes PROJECT SUMMARY Overview: We will extend and develop implementations of foundational methods for analyzing populations of attributed connectomes. Our toolbox will enable brain scientists to (1) infer latent structure from individual connectomes, (2) identify meaningful clusters among populations of connectomes, and (3) detect relationships between connectomes and multivariate phenotypes. The methods we develop and extend will naturally overcome the challenges inherent in connectomics: high-dimensional non-Euclidean data with multi-level nonlinear interactions. Our implementations will comply with the highest open-source standards by: providing extensive online documentation and extended tutorials, hosting workshops to demonstrate our tools on an annual basis, and merging our implementations into commonly used packages such as scikit-learn [1], scipy [2], and networkx [3]. All of the code we develop is open source. We strive to ensure that our code is shared in accordance with the strictest guiding principles. We chose to implement these algorithms in Python due to its wide adoption in the neuroscience and data science fields. In particular, many other neuroscience tools applicable to connectomics, including NetworkX DiPy, mindboggle, nilearn, and nipy, are also implemented in Python. This will enable researchers to chain our analysis tools onto pre-existing pipelines for data preprocessing and visualization. Nonetheless, we feel that sharing our code in our own public repositories is insufficient for global reach. We have also begun reaching out to developers of the leading data science packages in python, including scipy, sklearn, networkx, scikit-image, and DiPy. For each of those packages, we have informal approval to begin integrating algorithms that we have developed. Those packages are collectively used by >220,000 other packages, so merging our algorithms into those packages will significantly extend our global reach. All researchers investigating connectomics, including all the authors of the 24,000 papers that mention the word “connectome”, will be able to apply state-of-the-art statistical theory and methods to their data. Currently, we have about 150 open source software projects on our NeuroData GitHub organization. Collectively, these projects get about 2,000 downloads and >11,000 views per month. As we incorporate additional functionality as described in this proposal, we expect far more researchers across disciplines and sectors will utilize our software. 20 ​ ​​ ​ ​​ Project Narrative Connectomes are an increasingly important modality for characterizing the structure of the brain, to complement behavior, genetics, and physiology. We and others have developed foundational statistical theory and methods over the last decade for the analysis of networks, networks with edge, vertex, and other attributes, and populations thereof, with preliminary implementations of those tools that we leverage in our laboratory for various application papers. In this project, we will extend our package, called graspy, to be of professional quality, implementing key functionality to include (1) estimating latent structure from attributed connectomes, (2) identifying meaningful clusters among populations of connectomes, and (3) detecting relationships between connectomes and multivariate phenotypes, such as behavior, genetics, and physiology. 18",Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes,10012519,RF1MH123233,"['Adoption', 'Algorithms', 'Behavioral Genetics', 'Brain', 'Code', 'Coin', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Development', 'Discipline', 'Documentation', 'Educational workshop', 'Ensure', 'Foundations', 'Funding', 'Genes', 'Human', 'Image', 'Individual', 'Journals', 'Laboratories', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modality', 'Modernization', 'Motivation', 'Neurosciences', 'Paper', 'Pathway Analysis', 'Phenotype', 'Physiology', 'Population', 'Population Analysis', 'Population Study', 'Property', 'PubMed', 'Publishing', 'Pythons', 'Research Personnel', 'Scientist', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Study', 'Structure', 'Telecommunications', 'Testing', 'Visualization', 'Work', 'brain research', 'connectome', 'data pipeline', 'design', 'high dimensionality', 'high standard', 'open source', 'public repository', 'software development', 'theories', 'tool', 'user-friendly']",NIMH,JOHNS HOPKINS UNIVERSITY,RF1,2020,1246005,0.013444761365078182
"Gaze-contingent computer screen magnification control for people with low vision ! Project Summary This application describes proposed research with the goal of facilitating use of a computer screen magnifier by people with low vision. Screen magnification is a well-established, popular technology for access of onscreen content. Its main shortcoming is that it requires the user to continuously control, with the mouse or trackpad, the location of the focus of magnification, in order to ensure that the magnified content of interest is within the screen viewport. This tedious process may be time-consuming and ineffective. For example, the simple task of reading the news on a web site requires continuous horizontal scrolling, which affects the experience of using this otherwise very beneficial technology, and may discourage its use, especially by those with poor manual coordination.  We propose to develop a software system that enables hands-free control of a screen magnifier. This system will rely on the user’s eye gaze (measured by a regular IR-based tracker, or from analysis of the images in a camera embedded in the screen) to update the location of the focus of magnification as desired. This research is inspired by preliminary work, which showed promising results with two simple gaze-based control algorithms, tested on three individuals with low vision.  This project will be a collaboration between the Department of Computer Science and Engineering at UC Santa Cruz (PI: Manduchi, Co-I: Prado) and the School of Optometry at UC Berkeley (PI: Chung). Dr. Legge from the Department of Psychology at U. Minnesota will participate as a consultant. Two human subjects studies are planned. In Study 1 with 80 low vision subjects from four different categories of visual impairment, we will investigate the failure rate of a commercial gaze tracker (Aim 1), and will record mouse tracks, gaze tracks, and images from the subjects while performing a number of tasks using two modalities of screen magnification (Aim 2). In Study 2, with the same number of subjects, we will repeat the Study 1 experiment, but using a gaze-based controller trained from the data collected in Study 1, and individually tunable for best performance (Aim 3). In addition, we will experiment with an appearance-based gaze tracker that uses images from the screen camera, thereby removing the need for specialized gaze tracking hardware, as well as with a computer tablet form factor (Aim 4). We expect that reading speed and error rate using our gaze-based controller will be no worse than using mouse-based control. If successful, this study will show that the convenience of hands-free control offered by the proposed system comes at no additional cost in terms of individual performance at the considered tasks. ! ! Project Narrative People with low vision often use screen magnification software to read on a computer screen. Since a magnifier expands the screen content beyond the physical size of the screen (the “viewport”), it is necessary to move the content using the mouse so that the portion of interest falls within the viewport. This project will facilitate use of a screen magnifier by means of a new software system that relies on the user’s own gaze to control scrolling when reading with magnification. !",Gaze-contingent computer screen magnification control for people with low vision,10053172,R01EY030952,"['Affect', 'Age', 'Algorithms', 'Appearance', 'Apple', 'Behavior Control', 'Benchmarking', 'Blindness', 'Categories', 'Collaborations', 'Communication', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Correlation Studies', 'Data', 'Data Set', 'Desktop Video', 'Engineering', 'Ensure', 'Eye', 'Face', 'Failure', 'Funding', 'Glass', 'Goals', 'Hand', 'Image', 'Individual', 'Learning', 'Location', 'Magic', 'Manuals', 'Measures', 'Minnesota', 'Modality', 'Mus', 'Operating System', 'Optometry', 'Performance', 'Peripheral', 'Process', 'Psychological reinforcement', 'Psychology', 'Reader', 'Reading', 'Research', 'Resort', 'Role', 'Schools', 'Science', 'Speech', 'Speed', 'Structure', 'Study Subject', 'System', 'Tablet Computer', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'algorithm development', 'algorithm training', 'base', 'computer science', 'control trial', 'cost', 'data acquisition', 'design', 'experience', 'experimental study', 'falls', 'gaze', 'human subject', 'interest', 'motor control', 'news', 'recurrent neural network', 'sample fixation', 'software systems', 'tool', 'web page', 'web site']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2020,350753,0.011867691213159707
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,10021018,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2020,255238,-0.0166237765800646
"CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience The field of network neuroscience has developed powerful analysis tools for studying brain networks and holds promise for deepening our understanding of the role played by brain networks in health, disease, development, and cognition. Despite widespread interest, barriers exist that prevent these tools from having broader impact. These include (1) unstandardized practices for sharing and documenting software, (2) long delays from when a method is first introduced to when it becomes publicly available, and (3) gaps in theoretic knowledge and understanding leading to incorrect, delays due to mistakes, and errors in reported results. These barriers ultimately slow the rate of neuroscientific discovery and stall progress in applied domains. To overcome these challenges, we will use open science methods and cloud-computing, to increase the availability of network neuroscience tools. We will use the platform ""brainlife.io"" for sharing these tools, which will be packaged into self-contained, standardized, reproducible Apps, shared with and modified by a community of users, and integrated into existing brainlife.io analysis pipelines. Apps will also be accompanied by links to primary sources, in-depth tutorials, and documentation, and worked-through examples, highlighting their correct usage and offering solutions for mitigating possible pitfalls. In standardizing and packaging network neuroscience tools as Apps, this proposed research will engage a new generation of neuroscientists, providing them powerful new and leading to new discoveries. Second, the proposed research will contribute growing suite of modeling analysis that can be modified to suit specialized purposes. Finally, the Brainlife.io platform will serve as part of the infrastructure supporting neuroscience research. Altogether, these advances will lead to new opportunities in network neuroscience research and further stimulate its growth while increasing synergies with other domains in neuroscience. Structural and functional networks support cognitive processes. Miswiring networks lead to maladaptive behavior and neuropsychicatric disorders. Network neuroscience is a young field that provides a quantitative framework for modeling brain networks. This project will make network neuroscientific tools available to new users via open science and cloud-computing. New applications of these tools this will lead deeper insight into the role of networks in health as well as in clinical disorders.",CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience,10019389,R01EB029272,"['Address', 'Aging', 'Behavior', 'Biophysics', 'Brain', 'Clinical', 'Cloud Computing', 'Cognition', 'Communities', 'Complex Analysis', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Elements', 'France', 'Funding', 'Generations', 'Graph', 'Growth', 'Health', 'Infrastructure', 'Instruction', 'Knowledge', 'Language', 'Lead', 'Libraries', 'Link', 'Literature', 'Mathematics', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Pathway Analysis', 'Play', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Science', 'Sociology', 'Source', 'Standardization', 'Structure', 'Study models', 'System', 'Techniques', 'Time', 'Training', 'Work', 'analysis pipeline', 'brain computer interface', 'cloud based', 'cognitive process', 'cyber infrastructure', 'data sharing', 'experience', 'innovation', 'insight', 'interest', 'machine learning method', 'network architecture', 'network models', 'neuroimaging', 'open data', 'prevent', 'relating to nervous system', 'statistics', 'support network', 'synergism', 'tool']",NIBIB,INDIANA UNIVERSITY BLOOMINGTON,R01,2020,218594,0.01614674485061854
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",10002220,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Structure', 'System', 'Techniques', 'Time', 'Work', 'base', 'complex data ', 'computer science', 'computerized tools', 'data modeling', 'data streams', 'data tools', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2020,20957,-0.00838290393977232
"Environmental Localization Mapping and Guidance for Visual Prosthesis Users Project Summary About 1.3 million Americans aged 40 and older are legally blind, a majority because of diseases with onset later in life, such as glaucoma and age-related macular degeneration. Second Sight has developed the world's first FDA approved retinal implant, Argus II, intended to restore some functional vision for people suffering from retinitis pigmentosa (RP). In this era of smart devices, generic navigation technology, such as GPS mapping apps for smartphones, can provide directions to help guide a blind user from point A to point B. However, these navigational aids do little to enable blind users to form an egocentric understanding of the surroundings, are not suited to navigation indoors, and do nothing to assist in avoiding obstacles to mobility. The Argus II, on the other hand, provides blind users with a limited visual representation of their surroundings that improves users' ability to orient themselves and traverse obstacles, yet lacks features for high-level navigation and semantic interpretation of the surroundings. The proposed research aims to address these limitations of the Argus II through a synergy of state-of-the-art stimultaneous localization and mapping (SLAM) and object recognition technologies. For the past three years, JHU/APL has collaborated with Second Sight to develop similar advanced vision-based capabilities for the Argus II, including capabilities for object recognition and obstacle detection by stereo vision. This proposal is driven by the hypothesis that navigation for users of retinal prosthetics can be greatly improved by incorporating SLAM and object recognition technology conveying environmental information via a retinal prosthesis and auditory feedback. SLAM enables the visual prosthesis system to construct a map of the user's environment and locate the user within that map. The system then provides object location and navigational cues via appropriate sensory modalities enabling the user to mentally form an egocentric map of the environment. We propose to develop and test a visual prosthesis system which 1) constructs a map of unfamiliar environments and localizes the user using SLAM technology 2) automatically identifies navigationally-relevant objects and landmarks using object recognition and 3) provides sensory feedback for navigation, obstacle avoidance, and object/landmark identification. Project Narrative The proposed system, when realized, will use advanced simultaneous localization and mapping, and object recognition techniques, to enable visual prosthesis users with unprecedented abilities to autonomously navigate and identify objects/landmarks in unfamiliar environments.",Environmental Localization Mapping and Guidance for Visual Prosthesis Users,10019559,R01EY029741,"['3-Dimensional', 'Address', 'Age related macular degeneration', 'Algorithms', 'American', 'Competence', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Detection', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Environment', 'Evaluation', 'FDA approved', 'Feedback', 'Glaucoma', 'Goals', 'Image', 'Implant', 'Late-Onset Disorder', 'Lead', 'Learning', 'Life', 'Location', 'Maps', 'Medical Device', 'Modality', 'Motion', 'Ocular Prosthesis', 'Patients', 'Performance', 'Psyche structure', 'Research', 'Retinitis Pigmentosa', 'Running', 'Semantics', 'Sensory', 'Societies', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vision', 'Visual', 'Volition', 'aged', 'auditory feedback', 'base', 'behavior test', 'blind', 'cognitive load', 'falls', 'human subject', 'improved', 'innovation', 'legally blind', 'navigation aid', 'object recognition', 'portability', 'prosthesis wearer', 'prototype', 'research and development', 'retina implantation', 'retinal prosthesis', 'sensory feedback', 'smartphone Application', 'synergism', 'visual feedback', 'visual information']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,662134,0.009300719521356669
"Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies Project Summary Traditionally, environmental epidemiologic studies have focused on assessing risks related to a single pollutant at a time. This, however, does not reflect reality, since we are constantly exposed to multiple pollutants at once. It is very important, therefore, to be able to assess exposure to pollutant mixtures when conducting environmental epidemiologic methods. Doing so, however, is especially challenging, mainly due to the high dimension of the multi-pollutant exposure matrix (if the exposure of interest includes more than e.g. 5 or 10 chemicals) and because these pollutants are usually very highly correlated with each other. Although some methods are available to address these issues, they usually require strong assumptions and have severe limitations. With this study we propose to bypass most of these limitations by adapting and extending a novel and robust method to assess exposure to multiple pollutants, called Principal Component Pursuit (PCP). We will assess the performance of PCP synthetic datasets representing multiple potential scenarios and study designs, and compare our results to those obtained by existing methods. Subsequently, we will apply PCP to three important Public Health issues, i.e. to evaluate the associations between (i) in utero exposure to a mixture of PCBs and neurodevelopment, (ii) exposure to a metals mixture and cardiovascular health, and (iii) exposure to an air pollution mixture and emergency cardiovascular admissions. Finally, we will develop and share software so other researchers can freely use this novel, robust and flexible tool across a plethora of study designs and research questions. Our proposed work will be significant as it will provide epidemiologists with a novel and robust tool to assess exposure to environmental pollutant mixtures. Project Narrative We are constantly exposed to a mixture of environmental pollutants at once, but current epidemiologic methods either assess each pollutant separately, not capturing reality, or have severe limitations. With this study we propose to adapt a wildly popular method used in computer vision applications, called Principal Component Pursuit (PCP), and develop flexible extensions for many epidemiologic settings. We propose to assess the performance of this method, compare with existing methods and employ in real-life applications, as well as develop and share software so other research can also use this novel, robust and flexible tool.",Principal Component Pursuit to Assess Exposure to Environmental Mixtures in Epidemiologic Studies,9843133,R01ES028805,"['Accounting', 'Address', 'Admission activity', 'Air Pollutants', 'Air Pollution', 'Biological', 'Bypass', 'Cardiovascular Diseases', 'Chemicals', 'Child', 'Child Development', 'Child Health', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Detection', 'Dimensions', 'Disadvantaged', 'Educational workshop', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Pollutants', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Exposure to', 'Family', 'Geography', 'Health', 'Heart', 'Joints', 'Life', 'Measurement', 'Metal exposure', 'Metals', 'Methods', 'National Institute of Environmental Health Sciences', 'New York', 'New York City', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Poison', 'Polychlorinated Biphenyls', 'Public Health', 'Publishing', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Sample Size', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'System', 'Techniques', 'Time', 'Toxic effect', 'Toxicology', 'Work', 'cardiovascular emergency', 'cardiovascular health', 'cohort', 'design', 'epidemiology study', 'flexibility', 'health data', 'high dimensionality', 'interest', 'neurodevelopment', 'novel', 'policy implication', 'pollutant', 'prenatal exposure', 'programs', 'tool', 'user-friendly']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,569866,-0.006363316624610925
"University of Buffalo Clinical and Translational Science Institute The Buffalo Translational Consortium (BTC), which includes the University at Buffalo (UB) health sciences schools, the major healthcare institutions in our region, four key research institutes and five influential community partners, have embarked on a comprehensive strategic plan to build a strong foundation for clinical and translational research in response to our community needs. Buffalo is the second most populous city in New York State and has a rich cultural history. The proportion of underrepresented minorities in Buffalo in 2018 (50%) parallels that projected for the US in 2050, making Buffalo a microcosm of what the US will look like in 30 years. A similar proportion of our population experiences health disparities. The vision for our CTSA hub is to perform innovative research across the translational spectrum to improve the health of our community and the nation. We will develop, test and share novel approaches to engage difficult-to-engage populations and reduce health disparities in our community, which represents a “population of the future”. Guided by our vision, the CTSA has catalyzed a transformation of our environment since our CTSA was first funded in August 2015 with remarkable growth in clinical and translational research. Further, in just the past year, the UB medical school has moved into a spectacular new building and our clinical partner, Kaleida Health, the largest healthcare system in the region, opened the new Oishei Children’s Hospital, both on the Buffalo Niagara Medical Campus and connected to the Clinical and Translational Research Center devoted entirely to clinical and translational research that opened in 2012. This rapid and continuing trajectory of growth in healthcare and research in the region has resulted in a new 21st century Academic Health Center with healthcare, medical education and clinical and translational research on one campus in the heart of Buffalo, creating a foundation to enhance the impact of our CTSA even further. While launching our CTSA, we have prioritized participation in the national consortium through hosting and testing Innovation Labs as a team science tool, working with multiple hubs on initiatives to solve translational research barriers and sharing tools that we have developed with the CTSA consortium, including novel health informatics tools. Our CTSA has five ambitious but achievable aims, including: 1) Accelerate innovative translational research with teams that engage communities, regional stakeholders and the national consortium; 2) Train an excellent, diverse workforce to advance translation of discoveries; 3) Enhance inclusion of special populations across the lifespan and difficult-to-engage populations; 4) Streamline clinical research processes focusing on quality and efficiency with emphasis on multisite studies; 5) Develop, test and share biomedical informatics tools to integrate data from multiple sources to speed translation. Guided by our vision to perform research to improve the health of our community and the nation, we will continue our momentum to expand translational research, train our diverse workforce, streamline processes, engage our community, and actively contribute to the national consortium. The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health.",University of Buffalo Clinical and Translational Science Institute,10053435,UL1TR001412,"['Achievement', 'Address', 'Adopted', 'African American', 'Buffaloes', 'Center for Translational Science Activities', 'Cities', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Health', 'County', 'Coupled', 'Cultural Backgrounds', 'Data', 'Diverse Workforce', 'Ensure', 'Environment', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Heart', 'Image', 'Imaging technology', 'Individual', 'Influentials', 'Informatics', 'Institutes', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Life Expectancy', 'Longevity', 'Medical', 'Medical Education', 'Medical center', 'Methods', 'Natural Language Processing', 'New York', 'Outcomes Research', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Population', 'Poverty', 'Process', 'Program Development', 'Prospective Studies', 'Public Health', 'Public Health Informatics', 'Recording of previous events', 'Recruitment Activity', 'Refugees', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Sensitivity and Specificity', 'Site', 'Speed', 'Strategic Planning', 'System', 'Testing', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'Universities', 'Vision', 'Work', 'Workforce Development', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'community partnership', 'data sharing', 'education research', 'experience', 'health care disparity', 'health disparity', 'imaging genetics', 'improved', 'informatics tool', 'innovation', 'interoperability', 'medical schools', 'multidisciplinary', 'multiple data sources', 'named group', 'novel', 'novel strategies', 'recruit', 'response', 'sharing platform', 'skills', 'social health determinants', 'structured data', 'tool', 'translational impact', 'translational pipeline', 'translational scientist', 'unstructured data']",NCATS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,UL1,2020,4118079,-0.008531136983341438
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9997967,R44GM130247,"['3-Dimensional', 'Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'graphical user interface', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'machine vision', 'mid-career faculty', 'mixed reality', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2020,698435,0.007822028943013058
"RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data Project Summary/Abstract  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allows the activity of small population of neurons in the human brain to be directly recorded. We use the term ECOG to refer to the entire range of invasive recording techniques (from subdural strips and grids to penetrating electrodes) that share the common attribute of recording neural activity from the human brain with high spatial and temporal resolution. While this ability has resulted in many high-impact advances in understanding fundamental mechanisms of brain function in health and disease, it generates staggering amounts of data as a single patient can be implanted with hundreds of electrodes, each sampled thousands of times a second for hours or even days. The difficulty of exploring these vast datasets is the rate-limiting step in using them to improve human health. We propose to overcome this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the unique properties of ECOG. We dub this software tool RAVE (“R Analysis and Visualization of Electrocorticography data”).  The first goal of Aim 1 is to release RAVE 1.0 to the entire ECOG community by month 6 of the first funding period. This will maximize transformative impact by putting the new tools in the hands of users as quickly as possible, facilitating rapid adoption. The design philosophy of RAVE is driven by three imperatives. The first is to keep users ""close to the data"" so that users may make discoveries about the brain without being misled by artifacts. The second imperative is rigorous statistical methodology. The final imperative is ""play well with others"". As described in Aim 2, our approach will make it easy to seamlessly incorporate new and existing analysis tools written in Matlab, C++, Python or R into RAVE, giving users the best of both worlds: advanced but easy-to-use visualization of results from ECOG experiments, whether they are analyzed with the off-the- shelf tools routines provided with RAVE or novel tools developed by others. Project Narrative  A fast-growing technique in human neuroscience is electrocorticography (ECOG), the only technique that allow the activity of small population of neurons in the human brain to be directly recorded with high spatial and temporal resolution. ECOG generates staggering amounts of data, and the rate-limiting step in generating new insights about the human brain is the difficulty in exploring this vast quantity of data. We propose to remove this obstacle by creating an easy-to-use, powerful platform designed from the ground up for the analysis and visualization of ECOG data, known as RAVE (“R Analysis and Visualization of Electrocorticography data”).",RAVE: A New Open Software Tool for Analysis and Visualization of Electrocorticography Data,9933092,R24MH117529,"['Adoption', 'Algorithms', 'Amalgam', 'Brain', 'Code', 'Communication', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrocorticogram', 'Electrodes', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Grant', 'Health', 'Hour', 'Human', 'Human Activities', 'Implant', 'Implanted Electrodes', 'Laboratories', 'Language', 'Least-Squares Analysis', 'Letters', 'Literature', 'Medicine', 'Methodology', 'Morphologic artifacts', 'Neurons', 'Neurosciences', 'Nightmare', 'Paper', 'Patients', 'Philosophy', 'Play', 'Plug-in', 'Population', 'Proliferating', 'Property', 'Pythons', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Rest', 'Sampling', 'Seeds', 'Software Design', 'Software Tools', 'Techniques', 'Time', 'United States National Institutes of Health', 'Variant', 'Visit', 'Visualization', 'application programming interface', 'base', 'college', 'computer science', 'design', 'experience', 'experimental study', 'graphical user interface', 'improved', 'insight', 'interoperability', 'novel', 'open source', 'programs', 'relating to nervous system', 'statistical and machine learning', 'statistics', 'temporal measurement', 'tool', 'wiki']",NIMH,BAYLOR COLLEGE OF MEDICINE,R24,2020,236620,0.0026797779997795963
"Eliminating the human factor from stereotaxic surgeries Project Summary: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. Advancing a tool such as an electrode, injection pipette or optical fiber through a small hole in the cranium, sometimes over long distances, and placing it precisely in a particular brain area, often much less than one millimeter in diameter, is a significant experimental challenge. Any time an investigator misses the target brain area and the experiment fails as a result, a significant amount of work is lost, additional animals get sacrificed, materials are wasted, and the pace of scientific discovery has been slowed. Even in cases when experiments succeed, they can be difficult to reproduce because many research groups rely on their most experienced lab members and their “special touch” to perform these procedures – thereby adding an element of non- quantitativeness to the procedures, effectively making the experiment less reproducible. We propose to develop a novel stereotaxic apparatus which will overcome many of these shortcomings. Our device features a radically different mechanical design which is natively compatible with both traditional and novel in-vivo techniques. We propose to combine computer 3D vision and robotics for automatic and software guided adjustments of the animal's skull. Landmarks are measured with 3D vision, based on structured illumination at a level of accuracy that has not been accomplished by any of the existing devices. This information will guide a robotic platform to position the animal for the experiment. Finally, we propose to develop an open software platform for neuronavigation that will allow investigators to use the platform with any small animal species they desire to use. Brain atlas systems for neuronavigation can either be downloaded from a cloud based site, or produced de-novo by the investigator by preparing a single set of MRI and CT scans from one sample animal. Our device will help make stereotaxic procedures more accurate and less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Narrative: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. These devices will help make stereotaxic procedures less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Most importantly, they will help reduce or eliminate failed experiments due to mistargeted interventions, thereby accelerating the pace of scientific discovery.",Eliminating the human factor from stereotaxic surgeries,10080673,R41NS119079,"['3-Dimensional', 'Animal Experimentation', 'Animal Experiments', 'Animals', 'Area', 'Atlases', 'Base of the Brain', 'Brain', 'Caliber', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Dorsal', 'Electrodes', 'Elements', 'Ensure', 'Frustration', 'Goals', 'Human', 'Image', 'Injections', 'Intervention', 'Laboratories', 'Lighting', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Mechanics', 'Monitor', 'Neuronavigation', 'Operative Surgical Procedures', 'Persons', 'Positioning Attribute', 'Procedures', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Robotics', 'Sampling', 'Savings', 'Scanning', 'Side', 'Site', 'Speed', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Translations', 'Vision', 'Work', 'X-Ray Computed Tomography', 'age group', 'base', 'bone', 'bone imaging', 'brain tissue', 'cloud based', 'cost effective', 'cranium', 'design', 'experimental study', 'genetic strain', 'hexapod', 'in vivo', 'laboratory experience', 'member', 'millimeter', 'novel', 'operation', 'optical fiber', 'programs', 'prototype', 'soft tissue', 'software development', 'tool', 'virtual', 'wasting']",NINDS,POPNEURON LTD.,R41,2020,251960,0.009004250878102754
"Development of a visual-to-tactile conversion system for automating tactile graphic generation process PROJECT SUMMARY/ABSTRACT There are an estimated 23.7 million people who are blind or visually-impaired (BVI) in the U.S. and 285 million globally. Of this population, 30% do not travel independently outside of their home, only ~11% have a bachelor’s degree, and more than 70% are unemployed. The goal of this SBIR effort is to develop a novel system, which performs principled down-sampling and translation of visual information from digital documents into tactile equivalents. Timely access to information is one of the biggest challenges for BVI people. While access to textual information has largely been solved via screen reading software (e.g., JAWS or VoiceOver), very little progress has been made in making graphical information accessible. Although few assistive technology (AT) devices aim provide non-visual graphical access, they suffer from several shortcomings including high cost, limited portability, lack of multi-purpose, and inability to present information in a real-time context. Importantly, a common underlying problem across all extant approaches is that they require intensive human effort for producing or authoring tactile (and/or multimodal) graphics, which leads to high production costs and significant delays in the time between when the accessible materials are needed, and when they are actually delivered, adversely impacting BVI individuals in K-12 schools, colleges, and workplace settings. To address this long-standing problem, UNAR Labs aims to develop a novel system, which will automatically down-sample and translate visual graphical information into an intuitive tactile equivalent that can be used in tactile embossers. Building upon eight years of empirical research, this Phase I SBIR effort will prove the technical feasibility and functional viability of a prototype system for automating visual-to-tactile graphic conversion process and using the output in embossers. Two specific aims will guide this Phase I project: (1) to develop a prototype of an automated system for performing visual-to-tactile conversion without human intervention, and (2) to assess the technical feasibility and functional utility of the system through a rigorous human study. Success in this effort will provide a robust automated system for tactile graphic generation and promote empowerment of millions of BVI individuals by supporting increased educational attainment, proliferation of vocational opportunities, and enhancing overall quality of life for BVI people. PROJECT NARRATIVE Lack of equitable and timely access to information among persons who are blind or visually impaired (BVI) is key to realizing an inclusive world for all as it alleviates a known impediment that is hugely detrimental to their success in activities affecting quality of life and socio-economic status. The proposed innovation presents a first- of-its kind on-demand visual-to-tactile translation system, which will fully automate the tactile graphic generation process using bio-inspired sensory substitution rules and will instantly deliver the translated information for use in tactile embossers. Successful completion of this project will significantly reduce tactile graphic production costs and preparation time, and will promote empowerment of millions of BVI individuals by supporting increased educational attainment, vocational opportunities, and overall better quality of life.",Development of a visual-to-tactile conversion system for automating tactile graphic generation process,10008494,R43EY031628,"['Access to Information', 'Address', 'Adoption', 'Affect', 'Bachelor&apos', 's Degree', 'Benchmarking', 'Braille Display', 'Characteristics', 'Cognitive', 'Computer software', 'Computers', 'Data', 'Development', 'Devices', 'Elements', 'Empirical Research', 'Evaluation', 'Floor', 'Generations', 'Goals', 'Graph', 'Home environment', 'Human', 'Individual', 'Information Retrieval', 'Intervention', 'Intuition', 'Maine', 'Maps', 'Nature', 'Output', 'Performance', 'Persons', 'Phase', 'Plant Roots', 'Population', 'Preparation', 'Process', 'Production', 'Productivity', 'Psychophysics', 'Quality of life', 'Readability', 'Reading', 'Research', 'Route', 'Sampling', 'Schools', 'Self-Help Devices', 'Sensory', 'Small Business Innovation Research Grant', 'Socioeconomic Status', 'Software Framework', 'Support System', 'System', 'Tactile', 'Text', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Unemployment', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'braille', 'college', 'cost', 'data modeling', 'deep learning', 'digital', 'empowerment', 'human study', 'innovation', 'multimodality', 'multisensory', 'novel', 'operation', 'portability', 'prototype', 'success', 'touchscreen', 'usability', 'visual information', 'visual learning']",NEI,"UNAR LABS, LLC",R43,2020,300000,-0.004011661072482311
"An interactive, digital platform to transform physical science learning Abstract: The next generation of science and health care professionals will need to understand the foundational concepts of physics. While textbooks play a critical role in science learning, these books are not designed to meet the diverse learning needs of students in today’s classrooms. Unfortunately, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current physical science textbooks and to revolutionize reading with interactive texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned force and motion (NGSS PS2A) content into Spanish (Aim 1); designing and developing science learning games (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content in both English and Spanish to address 9 additional NGSS standards (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive learning technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning disabilities. This Fast-Track project will produce a bilingual, digital platform to support students’ understanding of Physical Science, which will allow students to seamlessly move between different reading levels and languages, play science learning games, and receive personalized content. This project will also solicit feedback from teachers and students, develop teacher support materials, and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform physical science learning",10006915,R44GM137622,"['Address', 'Adoption', 'Books', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Drops', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Health Professional', 'Healthcare', 'Home environment', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Motion', 'Phase', 'Physics', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Rewards', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Students', 'Techniques', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'adaptive learning', 'base', 'bilingualism', 'design', 'digital', 'education resources', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'physical science', 'reading ability', 'response', 'science teacher', 'scientific literacy', 'skills', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,231500,0.00262707496447173
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,9918946,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'data tools', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'statistical and machine learning', 'tool']",NICHD,DUKE UNIVERSITY,R25,2020,153800,-0.00540384447336739
"Structural Development of Human Fetal Brain Abstract Despite its critical significance, little is known about the most dynamic phase of brain development in infancy: 0-2 years. To change the status quo, comprehensive and quantitative infant brain atlases as reference standards for precision health are needed. In addition, diffusion MRI (dMRI) has entered a new era in which dynamic cortical internal microstructural complexity, indexed by e.g. cortical mean kurtosis derived from diffusion kurtosis imaging (DKI), can be studied in the living infant brain noninvasively using more advanced multi-shell dMRI. Furthermore, multi-modality measures offer unparalleled insights into mechanistic structure- function and structure-behavior relationships. Work in the current cycle has focused on structural development of human fetal and preterm brains. Based on high resolution diffusion tensor imaging (DTI) of 150 brains, we have established the atlases and quantified cortical microstructure with cortical fractional anisotropy, validated by histological images and correlated with transcriptomic (RNA) expression. Building upon this work, in the next cycle, we will focus on brain development in infancy, immediately after the fetal period. Specifically, the goal is to establish next-generation dMRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural mean kurtosis measurement by delineating its 4D spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). 160 typically developing infants at 1, 3, 6, 12, 18, 24 months will be recruited. Advanced “connectome-quality” multi-band high-resolution multi-shell dMRI, resting state fMRI (rs-fMRI) and structural MRI will be acquired. High-quality whole-head magnetoencephalography (MEG) will also be acquired. Anatomical labels of all 122 major gray and white matter structures will be built up based on high contrasts from DTI-derived maps. The measurements of DTI-derived metrics will be used for the quantitative components of DTI atlases and age-dependent white matter tract trajectories (Aim 1). Mean kurtosis of the 4th order kurtosis tensor has been shown to be sensitive to cortical internal microstructural changes of infant brains. The spatiotemporal sensitivity of mean kurtosis measures to infant age and cortical region will be investigated (Aim 2). Furthermore, we will establish mechanistic structure-function relationships with multi- modality imaging, including not only multi-shell dMRI, but also rs-fMRI and MEG, all optimized for infant brains (Aim 3). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants (e.g. Z-score maps). Infant cortical microstructure will be delineated noninvasively with 4D spatiotemporal frameworks. With multi-modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general. Narrative Title: Structural development of human fetal brain The goal is to establish next-generation diffusion MRI atlases (quantitative UPenn-CHOP infant brain atlases) and to harness a more advanced cortical microstructural measurement by delineating its four-dimensional spatiotemporal frameworks as well as uncovering its relationship to brain function and behavior during infancy (0-2 years). The quantitative infant brain atlases and normal developmental trajectories will provide reference standards for “pre-“diagnostic risk assessment, filling a gap towards precision health for infants. With multi- modality strength, the fundamental structure-function and structure-behavior mechanistic relations will set the stage for understanding aberrant brain development in neurodevelopmental disorders such as autistic spectrum disorder and intellectual disabilities in general.",Structural Development of Human Fetal Brain,9984831,R01MH092535,"['2 year old', 'Age', 'Anatomy', 'Anisotropy', 'Architecture', 'Area', 'Atlases', 'Auditory', 'Behavior', 'Behavior assessment', 'Behavioral', 'Brain', 'Cerebral cortex', 'Characteristics', 'Clinical Research', 'Collaborations', 'Development', 'Developmental Process', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Fingerprint', 'Four-dimensional', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Human', 'Image', 'Infant', 'Infant Development', 'Infant Health', 'Intellectual functioning disability', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Measurement', 'Measures', 'Motor', 'Multimodal Imaging', 'Neurodevelopmental Disorder', 'Phase', 'Precision Health', 'RNA', 'Reference Standards', 'Research Personnel', 'Resolution', 'Rest', 'Risk Assessment', 'Sensorimotor functions', 'Sensory', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Time', 'Visual', 'Work', 'age related', 'artemis', 'autism spectrum disorder', 'base', 'connectome', 'fetal', 'gray matter', 'histological image', 'human fetal brain', 'indexing', 'infancy', 'insight', 'multimodality', 'neuroimaging', 'neuronal circuitry', 'next generation', 'novel', 'prisma', 'recruit', 'relating to nervous system', 'somatosensory', 'spatiotemporal', 'transcriptomics', 'white matter']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2020,378100,-0.01494053033534082
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9935968,U01MH117072,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'automated algorithm', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodal data', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'preservation', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2020,1563930,-0.04289567727301737
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9884770,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Models', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2020,388626,-0.0076114993366992855
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9970958,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,750000,0.001597964578658145
"Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs PROJECT ABSTRACT Above-knee amputees often struggle to perform the varying activities of daily life with conventional prostheses. Emerging powered knee-ankle prostheses have motors that can restore normative biomechanics, but these devices are limited to a small set of pre-defined activities that must be tuned to the user by technical experts over several hours. The overall goal of this project is to model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning. The universal use of different task-specific controllers in current powered legs is a direct consequence of the prevailing paradigm for viewing human locomotion as a discrete set of activities. There is a fundamental gap in knowledge about how to analyze, model, and control continuously varying locomotion, which greatly limits the adaptability and agility of powered prostheses. The central hypothesis of this project is that continuously varying activities can be represented by a single mathematical model based on measureable physical quantities called task variables. The proposed project will be scientifically significant to understanding how humans continuously adapt to varying activities and environments, technologically significant to the design of agile, user-synchronized powered prosthetic legs, and clinically significant to the adoption of powered knee-ankle prostheses for improved community ambulation. The proposed model of human locomotion will enable new prosthetic strategies for controlling and adapting to the environment, which aligns with the missions of the NICHD/NCMRR Devices and Technology Development program area and the NIBIB Mathematical Modeling, Simulation, and Analysis program. The innovation of this work is encompassed in 1) a continuous paradigm for variable locomotor activities that challenges the existing discrete paradigm, 2) a unified task control methodology that drastically improves the agility of powered prosthetic legs, and 3) a partially automated tuning process that significantly reduces the time and technical expertise required to configure powered knee- ankle prostheses. This continuous task paradigm will provide new methods and models for studying human locomotion across tasks and task transitions. This innovation will address a key roadblock in control technology that currently restricts powered legs to a small set of activities that do not generalize well across users. The adaptability of the proposed control paradigm across users and activities will transform the prosthetics field with a new generation of “plug-and-play” powered legs for community ambulation. PROJECT NARRATIVE The proposed research is relevant to public health because the clinical application of variable-activity powered prosthetic legs can significantly improve community mobility and therefore quality of life for nearly a million American amputees. Recently developed powered knee-ankle prostheses are limited to a small set of pre- defined activities that require several hours of expert tuning for each user. This project will model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning, which aligns with the missions of the Devices and Technology Development program area of the NICHD National Center for Medical Rehabilitation Research and the Mathematical Modeling, Simulation, and Analysis program of the NIBIB.",Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs,9925236,R01HD094772,"['Address', 'Adoption', 'American', 'Amputees', 'Ankle', 'Area', 'Artificial Leg', 'Biomechanics', 'Clinical', 'Communities', 'Data', 'Degree program', 'Device or Instrument Development', 'Devices', 'Doctor of Philosophy', 'Electrical Engineering', 'Environment', 'Gait', 'Gait speed', 'Generations', 'Goals', 'Hand', 'Home environment', 'Hour', 'Human', 'Human body', 'Joints', 'Knee', 'Knowledge', 'Lead', 'Leg', 'Life', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Mathematical Model Simulation', 'Measurable', 'Measures', 'Mechanics', 'Medical center', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motor', 'Motor Activity', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'Orthotic Devices', 'Outcome', 'Phase', 'Play', 'Process', 'Program Development', 'Prosthesis', 'Public Health', 'Quality of life', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Speed', 'Spinal cord injury', 'Stroke', 'Study models', 'System', 'Technical Expertise', 'Technology', 'Time', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'clinical application', 'clinically significant', 'design', 'exoskeleton', 'experience', 'human data', 'human model', 'improved', 'innovation', 'kinematics', 'mathematical model', 'multidisciplinary', 'powered prosthesis', 'programs', 'prosthesis control', 'rehabilitation research', 'robot control', 'sensor', 'success', 'technology development', 'temporal measurement', 'trend']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,446707,-0.0007219187448585005
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9969443,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data standards', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'large datasets', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'public repository', 'repository', 'research and development', 'software development', 'software infrastructure', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,158388,-0.01717218882066765
"Reconstruction of heterogeneous and small macromolecules by cyro-EM PROJECT SUMMARY Single-particle electron cryomicroscopy (cryo-EM) has recently joined X-ray crystallography and NMR spectroscopy as a high-resolution structural method for biological macromolecules. In addition, cryo-EM produces images of individual molecules, and therefore has the potential to resolve conformational changes. The proposal aims to develop new algorithms and software for extending the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing computational tools for cryo-EM. This extension requires solving two of the most challenging computational problems posed by cryo-EM. First, mapping the structural variability of macromolecules is widely recognized as the main computational challenge in cryo-EM. Structural variations are of great significance to biologists, as they provide insight into the functioning of molecular machines. Existing computational tools are limited to a small number of distinct conformations, and therefore are incapable of tackling highly mobile biomolecules with multiple, continuous spectra of conformational changes. The first area of investigation in this project is the development of a computational framework to analyze continuous variability. The proposed approach is based on a new mathematical representation of continuously changing structures and its efficient estimation using Markov chain Monte Carlo (MCMC) algorithms. MCMC algorithms have found great success in many other scientific disciplines, yet they have been mostly overlooked for cryo-EM single particle analysis. Second, a major limiting factor for present cryo-EM studies is the molecule size. Images of small molecules (below ~50kDa) have too little signal to allow existing methods to provide valid 3-D reconstructions. It is commonly believed that cryo-EM cannot be used for molecules that are too small to be reliably detected and picked from micrographs. Challenging that widespread belief, the second area of investigation focuses on developing a groundbreaking approach for reconstructing small molecules directly from micrographs without particle picking. The new approach is based on autocorrelation analysis and completely bypasses particle picking and orientation assignment and requires just one pass over the data. The single-pass approach opens new possibilities for real-time processing during data acquisition. PROJECT NARRATIVE Determining structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, and a first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to significantly increase the power of structure-determination using electron cryomicroscopy (cryo-EM). Importantly, our methods will broaden the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing techniques.",Reconstruction of heterogeneous and small macromolecules by cyro-EM,9943364,R01GM136780,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Area', 'Belief', 'Biological', 'Biological Process', 'Bypass', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Cryoelectron Microscopy', 'Crystallization', 'Data', 'Data Set', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Discipline', 'Drug Design', 'Fostering', 'G-Protein-Coupled Receptors', 'Heterogeneity', 'Human Genome', 'Image', 'Individual', 'Institution', 'Investigation', 'Ion Channel', 'Ion Pumps', 'Machine Learning', 'Maps', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mathematics', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Molecular Motors', 'Molecular Weight', 'Motion', 'NMR Spectroscopy', 'Names', 'Noise', 'Particle Size', 'Phase', 'Polymerase', 'Preparation', 'Proteins', 'Pythons', 'Research', 'Resolution', 'Ribosomes', 'Roentgen Rays', 'Sampling', 'Signal Transduction', 'Spliceosomes', 'Structural Protein', 'Structure', 'Techniques', 'Time', 'Uncertainty', 'Update', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'computer framework', 'computerized data processing', 'computerized tools', 'data acquisition', 'expectation', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'macromolecule', 'molecular mass', 'novel strategies', 'open source', 'particle', 'programs', 'protein complex', 'protein structure', 'receptor', 'reconstruction', 'small molecule', 'statistics', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2020,328440,-0.024192760955310182
"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, and involves a complicated interplay between functional infor- mation interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. functional and structural measures. However, the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities misses a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimen- sional problem, requiring appropriate data reduction strategies. In the previous phase of the project we devel- oped advanced approaches to capture high-dimensional relationships among 2 or more modalities. Our work continues to strongly support the benefits of multimodal data fusion to both provide a more complete picture of brain function and structure, but also to improve our ability to study and predict the impact of complex mental illness. In this new phase of the project, we will focus on methods that can fill some existing gaps, such as the ability to bridge spatial/temporal as well as structural/functional connectivity scales. We also propose a novel framework to integrate unimodal and multimodal features called chromatic fusion, which searches for combina- tions of multimodal `notes' which occupy a unique position in a latent (or dictionary) space. The proposed meth- ods will be validated using simulations, hybrid-data, and large N normative imaging data. Our proposed approach will be thoroughly tested using this large data set which includes multiple illnesses that have overlapping symp- toms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar depression). We will provide open source tools and release data throughout the duration of the project via GitHub and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 37 Project Narrative  The promise of multimodal imaging is clear, and our work has clearly shown the substantial benefits of ex- tracting multimodal features estimated jointly from the data. In this renewal, we focus on some key understudied areas including fusing across vast spatiotemporal and functional/structural connectivity scales as well as devel- oping powerful new frameworks for integrating the resulting information to enable decision making and enable identification of potential targets for further study or possible treatment. Completion of our aims will result in a powerful new toolkit for data fusion of multimodal brain imaging data. 36",Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,10058554,R01EB006841,"['Address', 'Algorithms', 'Area', 'Attention', 'Biological Markers', 'Biology', 'Bipolar Disorder', 'Blood flow', 'Brain', 'Brain Diseases', 'Brain imaging', 'Classification', 'Clinical', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Diagnosis', 'Dictionary', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Documentation', 'Electroencephalography', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Human', 'Hybrids', 'Image', 'Imaging technology', 'Intuition', 'Joints', 'Link', 'Measurable', 'Measures', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Moods', 'Multimodal Imaging', 'Neurobiology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Positioning Attribute', 'Process', 'Psychotic Disorders', 'Pythons', 'Reporting', 'Research', 'Research Personnel', 'Rest', 'Sample Size', 'Sampling', 'Schizophrenia', 'Source', 'Structure', 'Symptoms', 'Testing', 'Training', 'Unipolar Depression', 'Validation', 'Work', 'base', 'blind', 'clinical care', 'clinical phenotype', 'data fusion', 'data reduction', 'deep learning', 'design', 'feature extraction', 'gray matter', 'high dimensionality', 'imaging biomarker', 'imaging modality', 'improved', 'large datasets', 'multimodal data', 'multimodality', 'multiple datasets', 'multitask', 'neuropsychiatric disorder', 'next generation', 'novel', 'novel strategies', 'open source', 'patient subsets', 'potential biomarker', 'repository', 'simulation', 'spatiotemporal', 'tool', 'translational impact', 'user friendly software', 'user-friendly', 'white matter']",NIBIB,GEORGIA STATE UNIVERSITY,R01,2020,542808,0.001934860238822595
"Exploration of MRI measures of neurodegeneration within individuals over short intervals PROJECT ABSTRACT/SUMMARY  Alzheimer's disease and other forms of dementia affect over five million Americans. Alzheimer's disease begins with changes in the brain more than a decade before the disease can be diagnosed from memory and cognitive impairment in a clinic. The goal of this work is to provide a way to measure early signs of neurodegeneration in individual people. The historical barrier to measure change in individuals is that each person's brain is different with change accumulating too slowly to be picked over short intervals. As a result, most research focuses on tracking averaged subject groups or tracking change over multiple years. The present work optimizes new brain imaging techniques using MRI to make extremely fast, highly precise repeated measurements of brain regions all within the same individual. The work then seeks to use the novel imaging approach to measure neurodegeneration in individuals with early stages of Alzheimer's disease in six months or less and also differentiate changes in people with Alzheimer's disease from less common forms of dementia that have distinct anatomical changes in the brain. If successful, the present work will provide a new means to track the early stages of neurodegeneration as would be used in clinical trials and translational medical research. NARRATIVE  The proposed research explores the possibility of precisely estimating change in specific brain structures in individuals at early stages of neurodegeneration. Anchoring from recent developments in fast brain scanning techniques, we use a novel methodological approach that permits a tremendous increase in the precision of measuring change within a single person by repeatedly, safety, and efficiently scanning the brain over time. Demonstrating successful precision measurement within the individual will open opportunities to track therapeutic effects in small samples during early phases of development as well as allow for individualized estimates of neurodegeneration to be made dynamically within the same person. !",Exploration of MRI measures of neurodegeneration within individuals over short intervals,9971052,R01AG067420,"['Achievement', 'Affect', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'American', 'Amyloid beta-Protein', 'Anatomy', 'Atrophic', 'Base Sequence', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Brain scan', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Event', 'Focus Groups', 'Goals', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'Joints', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical Research', 'Memory impairment', 'Methodology', 'Modeling', 'Monitor', 'Nerve Degeneration', 'Neurosciences Research', 'Pathology', 'Pattern', 'Persons', 'Phase', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Procedures', 'Progressive Aphasias', 'Protocols documentation', 'Proxy', 'Research', 'Resolution', 'Safety', 'Sampling', 'Scanning', 'Semantics', 'Statistical Models', 'Stream', 'Structure', 'Techniques', 'Testing', 'Therapeutic Effect', 'Thick', 'Time', 'Unmarried person', 'Variant', 'Work', 'amnestic mild cognitive impairment', 'base', 'brain volume', 'cerebral atrophy', 'clinical translation', 'cognitive change', 'hippocampal atrophy', 'image reconstruction', 'imaging approach', 'morphometry', 'neuroimaging', 'normal aging', 'novel', 'pre-clinical', 'rate of change', 'safety testing', 'secondary analysis', 'tau Proteins', 'therapeutic development', 'time interval', 'tool', 'treatment response']",NIA,HARVARD UNIVERSITY,R01,2020,533173,-0.07264542034960178
"The chondrocranium in craniofacial development and disease Most investigations of craniosynostosis focus on the dermatocranium, the second cranial skeleton to form during embryogenesis that comprises the dermal bones of the cranial vault and facial skeleton. A completely separate cranial skeleton, the chondrocranium, develops before the dermatocranium to support the embryonic brain and other sense organs. Historically, the chondrocranium has been studied across the vertebrates and is recognized as fundamental to craniofacial development, but it is not well known to craniofacial biologists and has never been studied in the laboratory mouse until now. The chondrocranium is formed of cartilage and though parts of it ossify endochondrally, other portions begin to degenerate by about embryonic day 15-16 in the mouse. By careful analysis of whole mount and histological specimens, we have documented the synchronized deterioration of select chondrocranial elements with the appearance and superimposition of particular dermal bones of the growing dermatocranium. These observations signal the existence of a mechanism for the coordinated, localized expansion (dermal bones) and resorption (cartilage) of two developmentally and evolutionarily separate skeletal systems. Our project, supported by strong preliminary data of the mouse chondrocranium, is designed to test a central hypothesis: that the chondrocranium serves as a structural and functional scaffold for the later development of dermatocranial elements including the formation of cranial vault sutures. Based on the common finding that boundaries between different cell populations often serve as tissue organizers, we recognize the establishment and maintenance of stable boundaries that restrict the mixing of different cell populations as critical to proper development, and propose a research design that interrogates the chondrocranial/dermatocranial boundary as significant to the coordinated development of the skull. We will interrogate cells at specific sites to determine the processes that function to maintain the boundaries. Then using the Fgfr2c+/C342Y mouse model for craniosynostosis, we will investigate relevant chondrocranial/dermatocranial boundaries operative in the development of two craniosynostosis phenotypes: premature closure of the coronal suture and abnormal growth of the midface. That the chondrocranium is composed of irregularly shaped cartilages, many of which are short-lived, requires that we conceive new tools for analysis. We will complete development of an innovative system to dissect and reconstruct the chondrocranium in silico from micro computed tomography images with tight temporal control, precisely delineate chondrocranial anatomy in 3D over embryonic time, and establish the role of the chondrocranium in development of the dermatocranium. Achieving our goals will enrich textbook knowledge of craniofacial development by defining the role of the chondrocranium in the production of dermatocranial phenotypes, provide information relative to the pathophysiology of countless craniofacial anomalies, and reveal potential avenues for the development of novel therapeutics. Craniofacial anomalies are common birth defects that require comprehensive, sometimes repetitive corrective surgeries to manage individual cases. To ameliorate the financial and emotional burden on patients and their families, efforts are aimed at the development of preventative therapies but these require a thorough understanding of craniofacial development. We offer novel information about the chondrocranium, the first embryonic cranial skeleton to develop, and focus on mechanisms operating within boundaries between it and the dermatocranium that are critical to craniofacial development, in normal individuals and in craniofacial disease.",The chondrocranium in craniofacial development and disease,9847792,R01DE027677,"['3-Dimensional', 'Acids', 'Affect', 'Age', 'Anatomy', 'Apert-Crouzon syndrome', 'Apoptosis', 'Appearance', 'Awareness', 'Birth', 'Bone Resorption', 'Brain', 'Cartilage', 'Cell Lineage', 'Cell physiology', 'Cells', 'Cephalic', 'Chondrichthyes', 'Chondrocranium', 'Complex', 'Congenital Abnormality', 'Craniofacial Abnormalities', 'Craniosynostosis', 'Data', 'Dermal', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Elements', 'Embryo', 'Embryonic Development', 'Embryonic Structures', 'Emotional', 'Ethnic group', 'Event', 'Face', 'Family', 'Functional disorder', 'Gene Expression', 'Goals', 'Graph', 'Growth', 'Image', 'Incidence', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory mice', 'Live Birth', 'Maintenance', 'Modernization', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Operative Surgical Procedures', 'Osteoblasts', 'Pathway interactions', 'Patients', 'Phenotype', 'Play', 'Population', 'Preventive therapy', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Regulation', 'Reproducibility', 'Research', 'Research Design', 'Role', 'Sense Organs', 'Signal Transduction', 'Site', 'Skeletal system', 'Skeleton', 'Staging System', 'Stains', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Tissues', 'Transgenic Mice', 'Vertebrates', 'base', 'bone', 'cleft lip and palate', 'coronal suture', 'craniofacial', 'craniofacial development', 'cranium', 'deep learning', 'design', 'fibroblast growth factor receptor 2c', 'histological specimens', 'imaging Segmentation', 'in silico', 'innovation', 'microCT', 'molecular marker', 'mouse model', 'novel', 'novel therapeutics', 'osteogenic', 'premature', 'reconstruction', 'scaffold', 'sex', 'spatiotemporal', 'three-dimensional modeling', 'tool']",NIDCR,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2020,523782,-0.033277708778047047
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10050843,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk stratification', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,759918,-0.009785058631300102
"Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD) PROJECT SUMMARY Medical devices have been documented to contain toxic chemicals that can leach and cause acute contact dermatitis (ACD) after repeated exposure or prolonged contact of the skin to these toxins. ACD is credited for 10-15% of all occupational illnesses and is also the second highest reported occupational hazard. Given its prevalence, ACD is also a great public health burden with combined yearly costs of up to $1 billion, which spans including medical costs, worker’s compensation and lost working time due to workplace absence. To this end, the U.S. Food and Drug Administration has mandated that all medical devices must be evaluated for possible skin sensitization using in vivo animal assays, which includes the Guinea pig maximization test (GPMT). Although GPMT tests provide valuable data on the skin sensitization effects of potential toxins, these assays are time-consuming and expensive. Moreover, the Interagency Coordinating Committee on the Validation of Alternative Methods (ICCVAM) recently published a Strategic Roadmap, calling for the development of alternative approaches to reduce animal testing of chemical and medical agents. Thus, there is a stated need to modernize safety evaluation of medical devices to reduce animal testing and shorten the regulatory review time, which would ultimately bring safer devices to the market faster. To address this unmet need, the key objectives of our FDA Phase I SBIR project are to (i) produce rigorously validated computational models for the GPMT assay integrating data obtained in human, mouse, and in vitro assays; and (ii) integrate these models into a software product termed PreSS/MD (Predictor of Skin Sensitization for Medical Devices). Our specific aims for this study include: 1) collecting, curating, and integrating the largest publicly available dataset for GMPT; 2) creating and validating novel computational models for GMPT data; 3) developing the PreSS/MD web server to allow users to make predictions of skin sensitization potential in medical devices. We will also develop a model for mixtures, including compounds tested jointly in different concentrations, using an approach that we developed previously. Finally, we will implement novel approaches to help users of our PreSS/MD platform interpret the developed models in terms of key chemical features responsible for skin sensitization. In addition, we will employ biomedical knowledge graphs to elucidate Adverse Outcome Pathways (AOPs) for skin sensitizers. Successful execution of this Phase I project will yield in the development of PreSS/MD as a centralized resource to evaluate the skin sensitization potential for medical devices. We expect this software-as-a-service web server platform will be of great value for companies and sponsors seeking regulatory approval of medical devices. PROJECT NARRATIVE Given that medical devices have been documented to contain toxic chemicals that may lead to allergic contact dermatitis, the US Food and Drug Administration requires that all devices be evaluated for possible skin sensitization effects using in vivo assays such as the Guinea pig maximization test. In the effort to modernize skin sensitization safety evaluation methods to reduce in vivo animal testing, herein we propose to develop a software product, PreSS/-MD (Predictor of Skin Sensitization caused by Medical Devices), as an innovative and unique in silico alternative with the potential to better predict human response compared to the existing approaches for skin sensitization assessment. Successful execution of the objectives described in this project will result in a centralized web server platform to evaluate the skin sensitization potential for medical devices, which will be of significant value for companies and sponsors seeking regulatory approval of medical devices.",Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD),10079701,R43ES032371,"['Acute', 'Address', 'Advanced Development', 'Allergic Contact Dermatitis', 'Animal Testing', 'Animals', 'Bayesian Method', 'Bayesian Modeling', 'Biological Assay', 'Cavia', 'Chemical Structure', 'Chemicals', 'Computer Models', 'Computer software', 'Consumption', 'Contact Dermatitis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Economics', 'Evaluation', 'Feedback', 'Generations', 'Human', 'Immune response', 'Instruction', 'Interagency Coordinating Committee on the Validation of Alternative Methods', 'International', 'Knowledge', 'Lead', 'Medical', 'Medical Care Costs', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Occupational', 'Online Systems', 'Pathway interactions', 'Phase', 'Poison', 'Prevalence', 'Prostheses and Implants', 'Public Health', 'Publishing', 'Pythons', 'Quantitative Structure-Activity Relationship', 'Reaction', 'Reporting', 'Resources', 'Safety', 'Skin', 'Small Business Innovation Research Grant', 'Structure', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxin', 'United States Food and Drug Administration', 'Validation', 'Workers&apos', ' Compensation', 'Workplace', 'adverse outcome', 'chemical release', 'cost', 'experience', 'in silico', 'in vitro Assay', 'in vivo', 'innovation', 'knowledge graph', 'lymph nodes', 'machine learning algorithm', 'model development', 'novel', 'novel strategies', 'occupational hazard', 'operation', 'phase 1 study', 'response', 'skin patch', 'software as a service', 'success', 'systemic toxicity', 'tool', 'web portal', 'web server']",NIEHS,"PREDICTIVE, LLC",R43,2020,167910,-0.01543400863400733
"Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder ABSTRACT  This K24 Mid-Career Investigator Career Development Award seeks support for training and mentorship for Christopher Pittenger, MD, Ph.D., a well-established, tenured Associate Professor in Psychiatry at Yale University, Director of the Yale OCD Research Clinic, and Assistant Chair for Translational Research in the Department of Psychiatry. Dr. Pittenger leads a robust patient-oriented research (POR) research program, which is integrated with his basic/translational lab-based research and has produced important new insights into the neurobiological underpinnings and novel treatment avenues for obsessive-compulsive disorder (OCD) and Tourette syndrome (TS). Dr. Pittenger has a long-standing commitment to mentorship; most notably, he is Co-Director of the Neuroscience Research Training Program (NRTP), the research track within the Yale psychiatry residency.  The training plan supported by this grant will allow Dr. Pittenger to increase his skills in quantitative analysis, with a focus on advanced statistical methods and on the design and analysis of fMRI studies. These are areas in which he already has active research with expert collaborators; the aim of the proposed training plan is to enhance his own proficiency to make him a more effective collaborator and mentor in these important domains. Additional training is focused on his own abilities as a mentor and leader, with the goal of increasing his efficacy in the management of his own research groups and in effective and individualized mentorship. These training activities will take place in the context of two NIMH- funded research studies. The first, R01 MH116038, is a recently funded grant on which Dr. Pittenger is co-PI with his close collaborator Alan Anticevic and deploys cutting-edge imaging technology and data analysis approaches to examine brain network connectivity parallels and predictors of therapeutic response to pharmacotherapy in OCD. The second, R01 MH100068, is a grant with collaborator Michelle Hampson that is developing real-time fMRI neurofeedback as a probe and potential treatment for OCD, with promising early results. These two exciting projects provide a fruitful vehicle for the proposed training in statistics and neuroimaging.  Dr. Pittenger will devote substantial time to mentoring under this award. One major focus will be the NRTP; the plan is for him to take over as Director of this program over the next few years, and to take the lead in the next resubmission of our T32 grant in 2022. Support of this increased mentorship effort is a second major motivation for the current application. Dr. Pittenger will also provide mentorship to students, postdocs, and junior faculty in his own research program and throughout the Department of Psychiatry  Together, these integrated plans for training, research, and mentorship will support a well-established mid-career investigator whose robust research program is producing important insights into the neurobiology and treatment of OCD and TS, and whose dedicated mentorship efforts are helping to establish a new generation of translationally grounded patient-oriented researchers in psychiatric neuroscience. NARRATIVE This K24 Mid-Career Investigator Career Development Award in Patient-Oriented Research seeks support for Christopher Pittenger, a tenured Associate Professor of Psychiatry at Yale University and Director of the Yale OCD Research Clinic; training and mentorship activities supported by this award will take place in the context of two NIMH-funded projects, R01 MH100068 and R01 MH116038. The Award will support Dr. Pittenger in a robust training plan aimed at increasing his skills in statistics and in the design and analysis of fMRI experiments, with the goal of making him a more effective collaborator and mentor in these domains. The robust Mentorship Plan supports a range of trainees, from high school students through junior faculty, with a particular focus on the research track with the Yale Psychiatry Residency, of which Dr. Pittenger will become the Director in the coming years.",Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder,9871479,K24MH121571,"['Achievement', 'Adult', 'Area', 'Award', 'Brain', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Data', 'Data Analyses', 'Department chair', 'Disease', 'Dissociation', 'Doctor of Philosophy', 'Double-Blind Method', 'Drug Exposure', 'Faculty', 'Feedback', 'Fluoxetine', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Funding', 'Future', 'Generations', 'Gilles de la Tourette syndrome', 'Goals', 'Grant', 'Health Sciences', 'High School Student', 'Human', 'Image', 'Imaging technology', 'Individual', 'Infrastructure', 'K-Series Research Career Programs', 'Lead', 'Leadership', 'Linux', 'Machine Learning', 'Mentors', 'Mentorship', 'Motivation', 'National Institute of Mental Health', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Obsessive-Compulsive Disorder', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physicians', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preceptorship', 'Prediction of Response to Therapy', 'Protocols documentation', 'Psychiatry', 'Publishing', 'Pythons', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Residencies', 'Rest', 'Scanning', 'Scientist', 'Services', 'Statistical Methods', 'Structure', 'Students', 'Time', 'Training', 'Training Activity', 'Training Programs', 'Training Support', 'Translational Research', 'Universities', 'Work', 'base', 'career', 'career development', 'connectome', 'design', 'disorder control', 'experimental study', 'graph theory', 'innovation', 'insight', 'mid-career faculty', 'neurofeedback', 'neuroimaging', 'next generation', 'novel', 'patient oriented', 'patient oriented research', 'predicting response', 'programs', 'research study', 'simulation', 'skills', 'statistics', 'success', 'symptomatic improvement', 'symptomatology', 'teacher mentor']",NIMH,YALE UNIVERSITY,K24,2020,181291,0.0028979996049266444
"Mapping human brain perivascular space in lifespan using human connectome project data PROJECT SUMMARY Perivascular spaces are a critical component of the glia-lymphatic circuit, facilitating the clearance of soluble waste. The role of perivascular spaces and changes in the brain’s clearance system in normal development, aging, and cognition is not fully understood, mainly due to lack of neuroimaging capabilities. However, noninvasive in vivo mapping of the perivascular space fluid with high accuracy and reliability is now made possible with our recent analytical developments, using human connectome project (HCP) data. The objective of this project is to map structural and diffusion features of perivascular space fluid across lifespan. PVS features include PVS presence (e.g., count and volume fraction) and diffusion (e.g., diffusivity and anisotropy). These features will be extracted regionally and globally across the brain. Structural MRI will provide information regarding localization and extent of the PVS and diffusion MRI will be used to investigate biophysical properties of the PVS fluid and surrounding tissue. The central hypothesis is that the perivascular space fluid increases across lifespan. We also hypothesize that individual differences exist in perivascular spaces as a function of demographic, general health and lifestyle health choices, such as body mass index, blood pressure, tobacco use and sleep quality. The central hypothesis will be tested by characterizing the normative map of the perivascular space fluid across the lifespan and in relation to various demographic, cognitive measures, and health factors. We will also examine whether subjects neuro-behavioral performances can be predicted by perivascular space features. We will pursue these aims by applying innovative MRI-based computational techniques that we recently developed and optimized on HCP data. We will also use Adolescent Brain Cognitive Development (ABCD) Studies to build first normative template of PVS in neurodevelopment. Together, our findings will ultimately allow for a better understanding of the human brain clearance system, and our shared perivascular space mapping workflow can provide a resource for researchers to study a wide range of neurological conditions. PROJECT NARRATIVE The proposed research is relevant to public health because it is expected to fill our gap knowledge regarding the role of the clearance system in brain health and cognition and its neuroimaging signature. We will identify and provide access to quantitative morphological and diffusion features of brain glia-lymphatic network to the larger scientific community to help facilitate our understanding of what role the brain clearance system has across lifespan. The analytical workflow and the analyzed data can also be used to study a wide range of neurological conditions.",Mapping human brain perivascular space in lifespan using human connectome project data,10012731,RF1MH123223,"['3-Dimensional', 'Adolescent', 'Affect', 'Age', 'Aging', 'Anisotropy', 'BRAIN initiative', 'Biological', 'Blood Pressure', 'Body mass index', 'Brain', 'Brain region', 'Caliber', 'Cerebrospinal Fluid', 'Cognition', 'Cognitive', 'Communities', 'Computational Technique', 'Data', 'Data Analyses', 'Data Set', 'Deposition', 'Development', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Drug Delivery Systems', 'Early Diagnosis', 'Foundations', 'Future', 'Gatekeeping', 'Goals', 'Health', 'Heterogeneity', 'Human', 'Image', 'Immune system', 'Individual Differences', 'Intercellular Fluid', 'Knowledge', 'Life', 'Life Style', 'Light', 'Liquid substance', 'Longevity', 'Lymphatic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Modeling', 'Morphology', 'National Institute of Mental Health', 'Neuroglia', 'Neurologic', 'Outcome', 'Participant', 'Pathologic', 'Pathway interactions', 'Pediatric cohort', 'Performance', 'Physiology', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Robin bird', 'Role', 'Sample Size', 'Sampling', 'Short-Term Memory', 'Sleep', 'Smoking', 'Statistical Data Interpretation', 'Structure', 'System', 'T2 weighted imaging', 'Techniques', 'Testing', 'Tissues', 'Tobacco use', 'Variant', 'Visual', 'Walking', 'Work', 'age related', 'base', 'biophysical properties', 'brain health', 'cardiovascular health', 'cognitive development', 'cognitive function', 'cognitive performance', 'cohort', 'connectome', 'data archive', 'glymphatic system', 'human imaging', 'in vivo', 'innovation', 'insight', 'interest', 'lifestyle factors', 'neurobehavioral', 'neurodevelopment', 'neuroimaging', 'neurovascular unit', 'novel', 'sex', 'sleep quality', 'tool', 'wasting']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,RF1,2020,1336500,-0.01443658395830199
"Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION) PROJECT SUMMARY: Trauma to the spinal cord and brain (neurotrauma) together impact over 2.5 million people per year in the US, with economic costs of $80 billion in healthcare and loss-of-productivity. Yet precise pathophysiological processes impacting recovery remain poorly understood. This lack of knowledge limits the reliability of therapeutic development in animal models and limits translation across species and into humans. Part of the problem is that neurotrauma is intrinsically complex, involving heterogeneous damage to the central nervous system (CNS), the most complex organ system in the body. This results in a multifarious CNS syndrome spanning across heterogeneous data sources and multiple scales of analysis. Multi-scale heterogeneity makes spinal cord injury (SCI) and traumatic brain injury (TBI) difficult to understand using traditional analytical approaches that focus on a single endpoint for testing therapeutic efficacy. Single endpoint-testing provides a narrow window into the complex system of changes that describe the holistic syndromes of SCI and TBI. In this sense, complex neurotrauma is fundamentally a problem that requires big- data analytics to evaluate reproducibility in basic discovery and cross-species translation. For the proposed TOP-VISION cooperative agreement we will: 1) integrate preclinical neurotrauma data on a large-scale; 2) develop novel applications of cutting-edge multidimensional analytics to make sense of complex neurotrauma data; and 3) validate bio-functional patterns in targeted big-data-to-bench experiments in multi-PI single center (UG3 phase), and multicenter (UH3 phase) studies. The goal of the proposed project is to develop an integrated workflow for preclinical discovery, reproducibility testing, and translational discovery both within and across neurotrauma types. Our team is well-positioned to execute this project given that with prior NIH funding we built one of the largest multicenter, multispecies repositories of neurotrauma data to-date, housing detailed multidimensional outcome data on nearly N=5000 preclinical subjects and over 20,000 curated variables. We will leverage these existing data resources and apply recent innovations from data science to render complex multidimensional endpoint data into robust syndromic patterns that can be visualized and explored by researchers and clinicians for discovery, hypothesis-generation and ultimately translational outcome testing. PROJECT NARRATIVE: Multicenter, multispecies central nervous system (spinal cord and brain) injury data provides a unique and clinically-relevant opportunity to discover translational outcomes, if we can develop analytical workflows that fully harness these data. Our team has assembled one of largest repositories of such data spanning across spinal cord injury and traumatic brain injury models under prior NIH support. The proposed cooperative agreement will expand data-sharing and big-data analytical workflows to render raw neurotrauma data into novel insights to promote bench-to-bedside translation.",Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION),10092617,UH3NS106899,"['Address', 'Affect', 'Anatomy', 'Animal Model', 'Area', 'Behavioral', 'Big Data', 'Big Data Methods', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Collection', 'Data Commons', 'Data Element', 'Data Pooling', 'Data Science', 'Data Sources', 'Detection', 'Drug Targeting', 'FAIR principles', 'Functional disorder', 'Funding', 'Generations', 'Goals', 'Healthcare', 'Heterogeneity', 'Housing', 'Human', 'Individual', 'Injury', 'Knowledge', 'Machine Learning', 'Medical', 'Modeling', 'Modernization', 'Molecular', 'Multiple Trauma', 'Mus', 'Nervous System Trauma', 'Neuraxis', 'Outcome', 'Outcome Assessment', 'Pattern', 'Phase', 'Physiological', 'Positioning Attribute', 'Precision Health', 'Prevalence', 'Process', 'Rattus', 'Recovery', 'Recovery of Function', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sensitivity and Specificity', 'Severities', 'Site', 'Spinal Cord', 'Spinal Injuries', 'Spinal cord injury', 'Syndrome', 'System', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Trauma', 'Traumatic Brain Injury', 'Traumatic CNS injury', 'Treatment Efficacy', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Validation', 'Weight', 'Work', 'bench to bedside', 'biobehavior', 'biomarker discovery', 'body system', 'clinically relevant', 'cost', 'data curation', 'data integration', 'data resource', 'data warehouse', 'diverse data', 'economic cost', 'economic impact', 'experimental study', 'functional outcomes', 'heterogenous data', 'innovation', 'insight', 'large scale data', 'neuroinflammation', 'novel', 'pre-clinical', 'precision medicine', 'preclinical study', 'predictive modeling', 'productivity loss', 'repository', 'response to injury', 'spinal cord and brain injury', 'success', 'therapeutic development', 'therapeutic evaluation', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",UH3,2020,323000,0.006815857881675446
"BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging Project Summary Electrophysiological recordings in humans and animals play an essential role in developing an understanding of the human brain. Signal recording technology spans the entire scale from invasive microelectrode single-unit recordings, through mesoscale macroelectrode measures of local field potentials, to whole-brain monitoring through measurement of scalp potentials (EEG) and extracranial magnetic fields (MEG). Analysis of these data presents a host of challenges, from low level noise removal and artifact rejection to sophisticated spatio-temporal modeling and statistical inference. The multidisciplinary neuroscience research community has an ongoing need for validated and documented open-source software to perform this analysis and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets this need. Brainstorm is a Matlab/Java multi-platform (Linux, MacOS, Windows) software package for analysis and visualization of electrophysiological data. The software is extensively documented through a series of detailed tutorials and actively supported through a user forum and a mailing list. Over the past 8 years we have registered 16,000 distinct users, provided hands on instruction to 1,200 trainees, and the software has been used and cited in ~600 journal papers. Brainstorm includes tools for importing MEG/EEG, intracranial EEG, animal electrophysiology, and near-infrared spectroscopy (NIRS) data from multiple vendors, extensive interactive features for data preprocessing, selection and visualization, coregistration to volume and surface MRIs and atlases, forward and inverse mapping of cortical current density, time-series and connectivity analysis, and a range of statistical tools. Data can be analyzed through a graphical interface or through scripted pipelines. The current proposal represents a plan to extend Brainstorm in a manner that leverages the unique features of our software and addresses important needs for large-scale data analysis. In this project we will continue to extend and support our software through the following three specific aims: (i) we will harness recent developments in distributed and shared data and high performance computing resources, together with standardization of data organization, to facilitate large-scale, reproducible analysis of electrophysiological data. (ii) We will also address the need for improved modeling resulting from the increasing use of both invasive recordings and direct brain stimulation through development of new modeling software for accurate computation of the intracranial electromagnetic fields produced by brain stimulation and neuronal activation. (iii) Finally, we will continue to add new functionality and to support the software through in-person training, online forums, documentation and other resources. Project Narrative Magnetoencephalography (MEG) and Electroencephalography (EEG) are absolutely non-invasive brain imaging tools, which provide information on the spatial distribution and precise temporal orchestration of human brain activity. In addition to basic neuroscience research, MEG and EEG can be also used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses, including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. The neuroscience research community has an ongoing need for validated and documented open-source software to perform these analyses and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets these needs with well-documented and tested novel analyses using MEG and EEG in combination with anatomical MRI and intracranial EEG data.",BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging,9894648,R01EB026299,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Archives', 'Area', 'Atlases', 'Basic Science', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Development', 'Diagnosis', 'Documentation', 'Educational workshop', 'Electrodes', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Electrophysiology (science)', 'Ensure', 'Environment', 'Epilepsy', 'Excision', 'Frequencies', 'Goals', 'Grant', 'High Performance Computing', 'Human', 'Image', 'Imaging Device', 'Institution', 'Java', 'Joints', 'Journals', 'Language Development', 'Lead', 'Linux', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Paper', 'Pathway Analysis', 'Pattern', 'Persons', 'Play', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scalp structure', 'Schizophrenia', 'Series', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Surface', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Universities', 'Vendor', 'Visualization', 'Work', 'autism spectrum disorder', 'cloud storage', 'cognitive benefits', 'computerized tools', 'computing resources', 'cortex mapping', 'data archive', 'data curation', 'data resource', 'data sharing', 'data standards', 'data structure', 'data warehouse', 'density', 'design', 'electric field', 'graphical user interface', 'hands on instruction', 'improved', 'interoperability', 'large datasets', 'large scale data', 'magnetic field', 'multidisciplinary', 'neuroimaging', 'novel', 'open source', 'relating to nervous system', 'response', 'spatiotemporal', 'structured data', 'tool']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,633469,0.03137516017584278
