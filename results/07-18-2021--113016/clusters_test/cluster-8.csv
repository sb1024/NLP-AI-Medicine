text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,10236260,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'high body mass index', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'obese patients', 'obese person', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2021,585234
"Improved Surgical Navigation Using Video-CT Registration Abstract  In many surgical procedures, image guided surgery (IGS), also known as surgical navigation, facilitates precise surgical manipulations near critical structures such as the brain and eye. IGS suffers from critical limitations such as loss of precision and correspondence with preoperative imaging once surgery begins and the anatomy is altered. These limitations may be addressed through intra-operative imaging, which effectively “resets” the model and thus enables both improved precision of IGS as well as improved surgical decision- making. However, intraoperative radiologic imaging has many limitations, including disruption of the workflow, cost, and additional radiation exposure. This project aims to develop solutions to resolve limitations of IGS without the need for intra-operative radiologic imaging. Our solutions rely upon data from a device that is present in every procedure using IGS, namely, the endoscope. Our goal in this project is use endoscopic video images to reconstruct surgical anatomy as it changes. This enables sustained precision in registration with pre- operative imaging throughout the procedure by updating the anatomical model as surgery progresses. We will achieve this by 1) using advances in computer vision to develop improved methods for continuous direct registration between the endoscope and the CT; and 2) developing methods that continuously compute the geometry of observed surfaces and update the preoperative CT with changes in that geometry. The technology developed in this proposal thus enables the following: 1) precise surgical navigation using the endoscope throughout the procedure; 2) surgical decision-making without the need for additional intra-operative imaging; and 3) new tools to reconstruct surgical anatomy and quantitatively evaluate the extent of surgery. Narrative  Image guided surgery is widely used to safely navigate around complex structures like the ethmoid bone and critical structures such as the brain; its utility is greatly enhanced when coupled with intraoperative radiographic imaging because the anatomic changes caused by surgery are clearly elucidated and can be incorporated into the surgical plan. This project will develop computational methods that exploit readily available endoscopic video to improve the accuracy of navigation and to provide intraoperative updates to the anatomic model. This technology will enhance surgical decisions in the operating room and enable precise navigation throughout the surgery without the need for additional radiologic imaging in the operating room.",Improved Surgical Navigation Using Video-CT Registration,10099301,R01EB030511,"['3-Dimensional', 'Address', 'Anatomic Models', 'Anatomy', 'Brain', 'Brain imaging', 'Cadaver', 'Clinical', 'Complex', 'Computer Vision Systems', 'Computing Methodologies', 'Coupled', 'Data', 'Decision Making', 'Detection', 'Devices', 'Diagnostic radiologic examination', 'Documentation', 'Endoscopes', 'Ethmoid bone structure', 'Eye', 'Geometry', 'Goals', 'Image', 'Image-Guided Surgery', 'Investigation', 'Methods', 'Modeling', 'Monitor', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Performance', 'Postoperative Period', 'Problem Solving', 'Procedures', 'Psyche structure', 'Radiation exposure', 'Safety', 'Sinus', 'Slice', 'Speed', 'Structure', 'Surface', 'Surgeon', 'System', 'Technology', 'Touch sensation', 'United States National Institutes of Health', 'Update', 'Vision', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'base', 'cohort', 'cost', 'effectiveness evaluation', 'improved', 'interest', 'novel', 'operation', 'radiological imaging', 'reconstruction', 'tool', 'usability']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,628311
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10219212,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'lipidomics', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2021,620000
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10172909,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2021,741958
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,10061631,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2021,1261742
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399
"Functional Lung Imaging Using a Single kV CT Acquisition ABSTRACT Venous thromboembolism is a major global health and economic burden with about 10 million cases occurring every year, and a high lifetime risk of 8% after age 45 years. Pulmonary embolism (PE) is a venous thromboembolic event associated with high morbidity and mortality, with about 20% incidence of death before diagnosis or shortly thereafter. Most recently, the COVID-19 pandemic has contributed to a marked increase in patients presenting with acute pulmonary thromboembolic disease, most likely created when the infectious vasculitis involving the endothelium creates local arterial thrombosis and subsequent lung infarction, with a superimpose hypercoagulable state that promotes clot formation. In these patients, it is increasingly being recognized that pulmonary perfusion abnormalities associated with the lung consolidations and ground-glass opacities are important predictors of poor prognosis. Currently, pulmonary CT angiography (CTA) has become the preferred method for diagnosing PE and planar lung ventilation/perfusion (V/Q) scintigraphy is used in cases when pulmonary CTA is contraindicated. A compelling unmet clinical need is to develop a method for simultaneous pulmonary CTA and parenchymal perfusion assessment without the use of two modalities like CTA and SPECT perfusion in the same patient. In this project, an imaging physics-based deep learning method will be developed to extract the previously overlooked spectral information inherently encoded in the acquired contrast enhanced CT projection data. As a result of this breakthrough, this new spectral CT imaging method, referred to as Deep-En-Chroma, will be developed and validated for perfusion defect quantification in lung parenchyma from the currently available pulmonary CTA. This will be accomplished without the need for any expensive dual energy CT (DECT) hardware upgrades that have been commercialized by major CT manufacturers. In summary, upon the completion of this project, a new functional CT imaging method will have been developed, that in addition to providing the currently available pulmonary CTA images, will also detect perfusion defects in lung parenchyma without the requirement of high-end DECT hardware. PROJECT NARRATIVE Pulmonary embolism (PE) is a venous thromboembolic event associated with high morbidity and mortality, with about 20% incidence of death. Recently, the COVID-19 pandemic has contributed to a marked increase in patients presenting with acute pulmonary thromboembolic disease. It is increasingly being recognized that pulmonary perfusion abnormalities are important predictors of poor prognosis in PE patients. This project will develop a new spectral CT imaging method to provide simultaneous pulmonary CT angiography and parenchymal perfusion assessment without the requirement of high-end dual energy CT hardware or any non- CT imaging modalities.",Functional Lung Imaging Using a Single kV CT Acquisition,10212057,R01HL153594,"['Accident and Emergency department', 'Acute', 'Age', 'Angiography', 'Animals', 'Blood Volume', 'COVID-19 diagnosis', 'COVID-19 pandemic', 'COVID-19 pneumonia', 'Cessation of life', 'Chronic', 'Clinical', 'Coagulation Process', 'Data', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Economic Burden', 'Endothelium', 'Evaluation', 'Event', 'Fibrin fragment D', 'Functional Imaging', 'Glass', 'Health', 'Image', 'Incidence', 'Infarction', 'Iodine', 'Laboratories', 'Lung', 'Manufacturer Name', 'Maps', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motion', 'Patients', 'Perfusion', 'Physics', 'Pulmonary Embolism', 'Pulmonary vessels', 'Radiation Dose Unit', 'Radionuclide Imaging', 'Recurrence', 'Research', 'SARS-CoV-2 infection', 'Serology test', 'Structure of parenchyma of lung', 'Study Subject', 'Symptoms', 'Thrombophilia', 'Thrombosis', 'United States', 'Vasculitis', 'Venous', 'X-Ray Computed Tomography', 'base', 'chronic thromboembolic pulmonary hypertension', 'clinical risk', 'contrast enhanced', 'deep learning', 'diagnostic accuracy', 'global health', 'human subject', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'lifetime risk', 'lung imaging', 'mortality', 'network models', 'outcome forecast', 'perfusion imaging', 'risk prediction', 'single photon emission computed tomography', 'technological innovation', 'tool', 'venous thromboembolism', 'ventilation']",NHLBI,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,759616
"Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping PROJECT SUMMARY Osteoarthritis (OA), a leading cause of chronic disability in the elderly population, occurs with the degradation of the extracellular matrix of articular cartilage, mainly composed of proteoglycan, collagen fibers, and water. Early diagnosis of cartilage degeneration requires the detection of changes in proteoglycan concentration and collagen integrity, preferably non-invasively and before any morphological changes occur. Spin-spin relaxation time (T2) and spin-lattice relaxation time in the rotating frame (T1ρ) can provide quantitative information about the structure and biochemical composition of the cartilage before morphological changes occur. Mono-exponential (ME) models can characterize the T2 and T1ρ relaxation processes and map it for articular cartilage in the knee joint. A recent meta-analysis showed that T1ρ provides more discrimination than T2 for OA. However, the ME model alone cannot provide distinct information from different compartments of the cartilage. Recent studies have shown that T1ρ relaxation might have bi-exponential (BE) components, following the hypothesis of the multi- compartmental structure of the cartilage. BE T2 relaxation has shown better diagnostic performance than ME for OA and can show the dispersion of the relaxation times, reflecting the heterogeneity in the macromolecular environment of water in the cartilage. BE analysis of cartilage typically requires a larger number of acquisitions with different spin-lock times (TSLs) or echo times (TEs), resulting in long scan time. High spatial resolution is also needed to visualize the thin and curved cartilage and fine structures in the knee joint. As a result, in vivo application of BE three-dimensional (3D) T1ρ and T2 mapping techniques is still very limited. Compressed sensing (CS) combined with parallel imaging (PI) can accelerate acquisition and reduce the scan time required for ME 3D T1ρ and T2 mappings. T1ρ scans can be reduced from 30 min to ~3 min with an error smaller than 6.5%. However, the error is two to three times larger for BE mapping. This problem can be potentially solved by optimizing the sampling times (TSLs for T1ρ and TEs for T2) and the free parameters of the CS approach (k- space sampling pattern, regularization function, regularization parameter, and minimization algorithm parameters) using fully sampled 3D knee joint datasets, supported by machine learning tools. The overarching goal of this proposal is to develop, optimize, and translate a high-spatial-resolution, rapid 3D magnetic resonance imaging sequence using data-driven learning-based CS for assessment of the human knee joint and using ME and BE 3D T1ρ (T2) mapping for improved biochemical characterization of cartilage and menisci on a standard clinical 3T scanner. PROJECT NARRATIVE Osteoarthritis of the knee is a leading cause of disability in elderly people, and no curative treatments exist. Early detection of osteoarthritis might help delay or prevent the onset of disability later in life. We propose a rapid and robust approach for the quantitative multi-compartment assessment of knee cartilage without using either exogenous contrast agent or hardware modifications as an early screening tool for osteoarthritis.",Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping,10296235,R01AR078308,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Biochemical', 'Biological Models', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Protocols', 'Collagen', 'Collagen Fiber', 'Contrast Media', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Diagnostic', 'Discrimination', 'Early Diagnosis', 'Elderly', 'Evaluation', 'Extracellular Matrix', 'Extracellular Matrix Degradation', 'Future', 'Goals', 'Heterogeneity', 'Human', 'Hydration status', 'Image', 'Imaging Techniques', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Meniscus structure of joint', 'Meta-Analysis', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Musculoskeletal', 'Pathologic Processes', 'Patients', 'Pattern', 'Performance', 'Population', 'Process', 'Proteoglycan', 'Protocols documentation', 'Relaxation', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Screening procedure', 'Slice', 'Structure', 'T2 weighted imaging', 'Techniques', 'Therapeutic Agents', 'Thick', 'Thinness', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Validation', 'Water', 'articular cartilage', 'base', 'cartilage degradation', 'curative treatments', 'design', 'disability', 'early screening', 'efficacy evaluation', 'healing', 'human data', 'improved', 'in vivo', 'learning algorithm', 'macromolecule', 'prevent', 'reconstruction', 'repaired', 'tool', 'water environment']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,531779
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10220967,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2021,821583
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,10127641,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2021,589357
"Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy Abstract Socket augmentation after tooth extraction by placing either allograft or xenograft bone particulates in the socket is frequently applied to reduce jawbone volume shrinkage for subsequent implant placement. Socket healing after the augmentation varies largely, ranging from uneventful healing to infection, failure of bone graft integration and severe bone loss due to bacterial infection and/or local/systemic conditions. The healing duration, which dictates the timing of implant placement, is widely different as well. Currently, an arbitrary waiting time of 6 months after socket augmentation is adopted, when a 2-dimensional (2D) or 3D radiograph, along with a visual examination is performed to assess hard- and soft-tissue healing to determine the readiness and strategy for the subsequent implant surgery. However, 3D radiographs are not recommended for longitudinal use to monitor socket healing due to radiation concerns. They have lower image resolution (250-500 µm), which limits their ability to evaluate bone surface healing, and inferior soft tissue contrast. A non-radiation and point-of-care method that can evaluate both hard- and soft-tissue longitudinally is much needed for a definitive, accurate, and timely diagnosis of socket healing pathologies. A high-frequency and miniature-sized intraoral ultrasound probe that can operate on an off-the-shelf scanner has been manufactured in collaboration with industry (see support letter) by our research team. Research conducted by our group demonstrated accuracy of this probe in measuring various oral and dental structures. The central hypothesis is to develop ultrasound-based imaging to characterize and grade socket healing lesions in determining the extent and severity of disease. To test this hypothesis, two aims are proposed: Aim 1. Evaluate the diagnostic value of ultrasonic images for bone grafting procedures of dental extraction sockets in a longitudinal clinical study (from -2 months to +6 months of graft placement). We will compare other imaging and clinical diagnostic tools for assessing hard- and soft tissue, anatomical and physiological status throughout the longitudinal study time-course. Aim 2. Develop an extended-view scan-mode for acquiring large field- of-view jawbone images and determine buccal (facial) to lingual tissue morphology. We will engage the manufacturer (see support letter) to modify the existing scanner for this dental specific application. Design goals will include the creation of an extended, large angle, field-of-view to visualize the buccal to lingual jaw bone surface and to create machine learning based measurement tools, including soft- and hard-tissue thickness and surface analysis. Successful execution of the proposed aims will result in an imaging-based tool for longitudinal socket augmentation evaluation that is based on soft- and hard-tissue features and will allow the care provider to choose deviation from current clinical procedures where indicated. This would be investigated subsequently in a specifically designed clinical trial. Narrative The goals of this investigation are to follow dental patients that require bone grafts before their dental implant is placed and to demonstrate the diagnostic opportunities that ultrasound adds to the current standard of clinical dental care. 3",Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy,10427073,R56DE030872,"['3-Dimensional', 'Adopted', 'Allografting', 'Anatomy', 'Atrophic', 'Bacterial Infections', 'Blood', 'Blood flow', 'Bone Surface', 'Bone Transplantation', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials Design', 'Collaborations', 'Dental', 'Dental Care', 'Dental Implants', 'Dental caries', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Face', 'Failure', 'Frequencies', 'Goals', 'Gold', 'Image', 'Implant', 'Implantation procedure', 'Industry', 'Infection', 'Inferior', 'Inflammation', 'Investigation', 'Ionizing radiation', 'Jaw', 'Lateral', 'Lesion', 'Letters', 'Longitudinal Studies', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Miniaturization', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Oral', 'Oral cavity', 'Organ Transplantation', 'Outcome', 'Particulate', 'Pathology', 'Patients', 'Perfusion', 'Physiological', 'Procedures', 'Process', 'Quality of life', 'Radiation', 'Readiness', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Severities', 'Severity of illness', 'Site', 'Structure', 'Surface', 'Testing', 'Thick', 'Time', 'Time Study', 'Tissues', 'Tooth Extraction', 'Ultrasonography', 'United States', 'Visual', 'Wait Time', 'base', 'bone', 'bone healing', 'bone loss', 'bone xenograft', 'care providers', 'clinical diagnostics', 'cone-beam computed tomography', 'dental structure', 'design', 'experience', 'graft failure', 'graft healing', 'healing', 'improved', 'oral care', 'point of care', 'soft tissue', 'targeted treatment', 'tool', 'two-dimensional']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R56,2021,642438
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,10158473,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2021,227282
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
"Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) remains the main cause of morbidity and mortality in the United States. Cardiac CT provides fast non-invasive assessment of CAD with a high sensitivity and negative predictive value – provided that the lumen can be visualized. However, heavily calcified or stented coronary segments are non- assessable, precluding non-invasive diagnosis of flow-limiting coronary plaques in an estimated 2 million U.S. adults. In addition, the spatial resolution of state-of-the-art CT systems is insufficient for robust visualization of features associated with high risk plaques. Further, while CT can quantitatively evaluate the impact of obstructive CAD on myocardial function using dynamic perfusion imaging, this requires relatively high patient radiation doses, which has limited widespread adoption. Considering the high personal and societal cost of CAD, robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam is critically needed. Built by Siemens Healthcare, a first-of-its-kind, whole-body, photon-counting-detector (PCD) CT system was installed in 2014 at the Mayo Clinic. With support from NIH award EB016966, we showed that the increased iodine contrast-to-noise ratio, decreased electronic noise, spectral imaging capabilities, and improved spatial resolution of PCD-CT relative to commercial CT enabled us to accurately measure increased vasa vasorum density in injured swine carotid arterial walls, demonstrating the exceptional potential of PCD-CT in vascular imaging. Because this system lacks cardiac imaging capabilities, our objective is to develop and validate a PCD dual-source (DS) CT system and novel imaging algorithms to accurately assess CAD in humans, especially in patients with heavily calcified, stented, or high-risk plaques, and to identify patients with myocardial perfusion defects. Our premise is that the established benefits of PCD-CT, used with a DS geometry and advanced noise reduction and material decomposition algorithms, can meet these objectives. Our proposal is significant in many ways: the technology developments will benefit all of CT imaging; robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam will obviate the need for additional imaging, reducing the overall time and cost to comprehensively evaluate CAD and its clinical significance. To extend the demonstrated benefits of PCDs to cardiac CT will require numerous physics, engineering, and algorithm innovations, including novel noise reduction and material decomposition algorithms using energy, spatial and temporal domain redundancies, as well as deep learning. These advances will culminate in a large clinical study to demonstrate not merely that the images are “better,” as is so often done, but that PCD-DSCT provides clinically-significant improvements in the diagnosis and management of patients with suspected CAD. PROJECT NARRATIVE This project will develop a new type of cardiac computed tomography (CT) scanner that is able to comprehensively assess coronary artery disease in humans. This technology, known as photon-counting- detector dual-source CT, is capable of exceptional spatial and temporal resolution, multi-energy spectral imaging and reduced radiation doses, allowing it to image the coronary artery and myocardium with unparalleled quality. This will enable comprehensive assessment of coronary artery anatomy and myocardial function from a single imaging exam, reducing time to diagnosis and cost, while also improving patient diagnosis and management.",Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management,10150846,R01EB028590,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Award', 'Blood Vessels', 'Cardiac', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computed Tomography Scanners', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Defect', 'Diagnosis', 'Diagnostic', 'Dose', 'Engineering', 'Equipment', 'Family suidae', 'Geometry', 'Goals', 'Healthcare', 'Heart failure', 'Human', 'Image', 'Individual', 'Iodine', 'Lesion', 'Low Dose Radiation', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Noise', 'Patients', 'Perfusion', 'Physics', 'Physiological', 'Predictive Value', 'Radiation', 'Radiation Dose Unit', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Societies', 'Source', 'Specimen', 'Stents', 'Sudden Death', 'System', 'Techniques', 'Technology', 'Time', 'Translating', 'United States', 'United States National Institutes of Health', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'algorithm development', 'calcification', 'clinically significant', 'coronary plaque', 'cost', 'deep learning', 'density', 'design', 'detector', 'heart imaging', 'heart motion', 'high risk', 'human subject', 'imaging capabilities', 'improved', 'industry partner', 'injured', 'innovation', 'mortality', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'perfusion imaging', 'photon-counting detector', 'routine practice', 'single photon emission computed tomography', 'societal costs', 'spectral energy', 'spectrograph', 'technology development', 'temporal measurement', 'vasa vasorum']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,657862
"Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS) Project Abstract  Per- and polyfluoroalkyl substances (PFAS) are a family of over 5000 man-made chemicals that are ubiquitous in the environment, due to their chemical stability and bioaccumulative properties. Many of these “forever chemicals” have been linked with health concerns, including strong evidence of developmental health and harm to hormone-sensitive tissues. Manufacturers continue to substitute new PFAS for which exposure- based health risks are unknown. There is an urgent public health need to determine the effects of PFAS in use on both mammary gland development and increased breast cancer incidence. Current exposure studies use rodent models that require cumbersome end-point analyses as well as large monetary and time investments.  Our proposal is aimed at developing an in vitro to in vivo extrapolation (IVIVE) pipeline of mammary gland development and maintenance to identify and prioritize potentially toxic PFAS, to ultimately mitigate number of animals needed for environmental exposure studies. Our approach is to develop in vitro models of the mammary gland of increasing complexity but decreasing throughput, identifying links between high-throughput and high- complexity model endpoint readouts to best prioritize large chemical libraries. A key technology to establish links across multiple in vitro culture platforms is optical coherence tomography-based structural-functional imaging (OCT-SFI), developed by MPI Oldenburg, which non-invasively visualizes label-free cells, their intracellular motility, and morphology of formed spheroids, within optically turbid tissue models.  Our first specific aim advances a high-throughput paper-based culture system, developed by MPI Lockett, to study mammary epithelial cell invasion in physiologically relevant tissue microenvironments. The platform will evaluate 96 different exposure conditions in parallel. Our second specific aim employs 3D co-culture models that include fibroblasts to model stromal signaling known to affect mammary gland development. OCT-SFI will provide cellular motility and morphology of the organotypic spheroids that form in these cultures. Finally, our third aim will screen a library of 40 PFAS, with a particular focus on the perfluoroethercarboxylic acids (PFECAs) currently used in industrial coatings. In addition, 12 PFAS will be screened for which there is existing in vivo rodent model data available, and comparisons between in vitro assay outputs and in vivo gland remodeling will be used to refine the assay models and establish initial thresholds for screening.  The models developed as part of this proposal will thus be predictive of biology, enabling the high-throughput capability needed for future screening of all PFAS as well as other emerging endocrine disruptors. The project’s risk is balanced by the known imaging capabilities of OCT-SFI to probe responses in 3D spheroid and paper- based co-cultures. The high-throughput nature of this IVIVE pipeline makes it ideal for screening libraries of potential toxicants, providing information-rich datasets of spatially and temporally resolved morphological and molecular changes across the tissue-like structures. Project Narrative This proposal aims to develop a pipeline to screen and prioritize libraries of potentially toxic man-made chemicals found in the environment for further analyses, with particular emphasis on per- and poly-fluoroalkyl substances (PFAS) of which there are over 5000 currently known. Current environmental exposure testing methods evaluate mammary gland development in live mice because the mammary gland is highly susceptible to chemical exposure; yet, such methods are slow and expensive. Our proposal uses mammary cell culture models in increasingly complex, tissue-like environments, in combination with high-speed 3D optical imaging techniques, and ultimately compare the platform with a few candidate PFAS against existing data in live mice, setting the stage for future high-throughput screening of potential environmental toxicants.",Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS),10271405,R01ES032730,"['3-Dimensional', 'Acids', 'Affect', 'Animals', 'Architecture', 'Biological Assay', 'Biology', 'Biometry', 'Breast Cancer Epidemiology', 'Breast Epithelial Cells', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Cellular Morphology', 'Characteristics', 'Chemical Exposure', 'Chemicals', 'Clinical Trials', 'Coculture Techniques', 'Complex', 'Data', 'Data Set', 'Development', 'Endocrine Disruptors', 'Environment', 'Environmental Exposure', 'Epithelial', 'Estrogen receptor positive', 'Exposure to', 'Family', 'Fiber', 'Fibroblasts', 'Functional Imaging', 'Future', 'Gene Proteins', 'Gland', 'Growth', 'Health', 'Hormones', 'Imaging Techniques', 'In Vitro', 'Incidence', 'Industrialization', 'Investments', 'Label', 'Libraries', 'Link', 'Maintenance', 'Malignant Neoplasms', 'Mammary gland', 'Manufacturer Name', 'Mesenchymal', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Mus', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Odds Ratio', 'Optical Coherence Tomography', 'Optics', 'Output', 'Paper', 'Pathology', 'Physiological', 'Poly-fluoroalkyl substances', 'Property', 'Public Health', 'Rattus', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Rodent', 'Rodent Model', 'S-Phase Fraction', 'Scanning', 'Scoring Method', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Toxic Environmental Substances', 'Up-Regulation', 'Work', 'assay development', 'base', 'carcinogenesis', 'carcinogenicity', 'cell motility', 'chemical stability', 'data modeling', 'deep learning', 'deep learning algorithm', 'high throughput screening', 'imaging capabilities', 'in vitro Assay', 'in vitro Model', 'in vivo', 'intercellular communication', 'machine learning algorithm', 'malignant breast neoplasm', 'malignant phenotype', 'mammary epithelium', 'mammary gland development', 'man', 'model design', 'non-invasive imaging', 'novel', 'optical imaging', 'premalignant', 'protein biomarkers', 'response', 'screening', 'small molecule libraries', 'three dimensional cell culture', 'three-dimensional modeling', 'tool', 'toxicant']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,499609
"A novel method for volumetric oxygen mapping in living retina PROJECT SUMMARY It is widely accepted that oxygen deficiency is a culprit and a marker of several major retinal diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma etc. However, it remains to be extremely challenging to measure oxygen in vivo in the eye, and no tools currently exist that can provide 3D oxygen distributions in the retina with high spatial resolution at appropriate imaging speeds. The goal of this project is to overcome these limitations and develop a new optical imaging technique for volumetric oxygen mapping in retina. Our approach will leverage the recently developed potent oxygen probes (such as Oxyphor 2P), whose phosphorescence decay times serve as quantitative markers of local oxygen partial pressures (pO2) in living tissues. To enable volumetric imaging with high throughput, we propose to develop a novel imaging instrument, termed oblique scanning laser ophthalmoscope (oSLO). oSLO is based on the concept of single lens scanned light sheet microscopy and enables volumetric phosphorescence lifetime imaging without time- consuming plane-by-plane pixel-wise sectioning. Our new method should be able to achieve 10 kilohertz voxel rate that is three orders of magnitude higher than the current state-of-the-art two-photon phosphorescence lifetime microscopy (2PLM). In this project we will: (Aim 1) develop a phosphorescence lifetime-based oSLO for volumetric pO2 mapping in living retina in mouse. The new design will allow parallel detection of signals at depth from each scanned location, so that the need in conventional depth sectioning is eliminated and imaging throughput is greatly increased. We will (Aim 2) dynamically image responses of retina and choroid to systemic hypoxia challenge using Oxyphor 2P. We will (Aim 3) then bridge oSLO measurements and label-free applications by multimodal imaging with visible light optical coherence tomography (vis-OCT). Using vascular pO2 as the ground-truth, we will develop a deep spectral training (DSL) algorithm to supervise the inverse calculation of vis-OCT for robust and reliable label-free retinal oximetry. This study will enable the first direct quantitative imaging of interactions between the two circulatory systems in retina (i.e. retinal and choroidal circulation), providing unprecedented information about retinal oxygen supply. IMPACT ON PUBLIC HEALTH: Successful completion of this program will deliver a new ground-breaking methodology for mapping oxygen in the retina that will greatly improve our understanding of retinal diseases. NARRATIVE Oxygen is essential in the retina, and the deficiency of oxygen is a culprit in a broad spectrum of retinal diseases. However, it remains challenging to measure oxygen in vivo in the eye. This multidisciplinary proposal is to develop a disruptive imaging method to provide unprecedented volumetric oxygen mapping in living mouse retina, as well as a deep learning method, to translate our oxygen measurements into label-free retinal oximetry for future clinical applications.",A novel method for volumetric oxygen mapping in living retina,10098478,R01EY032163,"['3-Dimensional', 'Address', 'Affect', 'Age related macular degeneration', 'American', 'Biochemistry', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cardiovascular system', 'Cell Respiration', 'Choroid', 'Consumption', 'Data', 'Data Set', 'Detection', 'Diabetic Retinopathy', 'Dyes', 'Eye', 'Fluorescence Angiography', 'Fundus', 'Future', 'Glaucoma', 'Goals', 'Human', 'Hypoxia', 'Image', 'Imaging Device', 'Imaging Techniques', 'Inhalation', 'Label', 'Lasers', 'Life', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medicine', 'Metabolic', 'Methodology', 'Methods', 'Microscopy', 'Multimodal Imaging', 'Mus', 'Nobel Prize', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Oxygen', 'Oxygen saturation measurement', 'Partial Pressure', 'Pathologic', 'Pathology', 'Photons', 'Physiology', 'Public Health', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Scanning', 'Signal Pathway', 'Signal Transduction', 'Speed', 'Supervision', 'Time', 'Tissues', 'Training', 'Translating', 'Vascular System', 'Visible Radiation', 'adaptive optics', 'algorithm training', 'base', 'choroidal circulation', 'clinical application', 'clinical translation', 'deep learning', 'design', 'hemodynamics', 'human imaging', 'imaging modality', 'improved', 'in vivo', 'learning network', 'learning strategy', 'lens', 'multidisciplinary', 'novel', 'novel imaging technique', 'optical imaging', 'phosphorescence', 'porphyrin a', 'programs', 'quantitative imaging', 'response', 'retina circulation', 'retinal imaging', 'sensor', 'success', 'tool', 'two photon microscopy', 'two-photon']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,552744
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of differenttypes of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",10397321,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2021,1500000
"Imaging Goggles for Fluorescence-Guided Surgery Interest in the use of optical imaging instruments in medical interventions stems from their ease of use, rapid adaptation to clinical needs, portability, real-time feedback, and relatively low cost. Of particular interest is the role of optical imaging in oncology. Surgery is the primary curative method for solid tumors confined to the tissue of origin with the goal of completely removing both the tumor mass and microscopic lesions. Unfortunately, the irregular growth pattern and infiltrations into surrounding healthy tissue prevent complete removal in many cases, resulting in positive surgical margins (PSMs). PSMs are prevalent in oncologic surgery, increasing cancer recurrence rates and often necessitates a second surgery to improve disease-specific survival. While PSM occurrence is significant in advanced clinical centers, the situation is worse in many rural hospitals and resource- limited areas due to limited histology infrastructure and workforce needed for margin assessment. Thus there is an urgent need for an intraoperative imaging system to visualize cancer, guide tumor removal, and determine margin positivity in the operating room (OR) in low and high resource settings alike.  Handheld fluorescence imaging systems have been developed to aid cancer resection. Still, they suffer from several limitations, including a significant footprint in the OR and the inability of the operating surgeon to directly control the imaging device while performing surgery. To address these shortcomings, we developed a head- mounted display device (HMD) cancer imaging system for real-time intraoperative fluorescence-guided surgery (FGS). The system HMD captures near-infrared (NIR) fluorescence and color images from the surgical bed and displays accurately aligned color-NIR images in real-time, enabling FGS without disrupting surgical workflow. The HMD has a small footprint, is intuitive to use, and is amenable for widespread use, including non-cancer applications such as imaging of peripheral blood flow. Preliminary testing of the HMD system in human cancer patients identified some areas for improvement that will accelerate the eventual clinical adoption of the system worldwide. Addressing these needs requires expertise in packaging software development for medical devices with DICOM image format and user interface development using human factors engineering. We have teamed up with a company that has both expertise and experience in developing augmented reality/mixed reality (AR/VR) software combined with deep machine learning in wearable devices on this project. Together, we will optimize the system performance and ergonomics using human factors engineering. The collaborative project will (1) develop and validate an automated fluorescence thresholding algorithm for tumor delineation; (2) develop and validate automated registration of augmented reality in the system; and (3) develop and evaluate clinical software to improve user experience.  At the completion of this project, we expect to develop and validate a clinic-ready, user-friendly HMD system with a small hardware footprint, enabling seamless integration with surgical workflow to enhance clinical adoption. The system will increase the rates and decrease the time of successful tumor resection. Anticipated low cost and ease of use will expand adoption in low and high resource settings worldwide. This objective approach to cancer surgery will reduce the incidence of PSMs and improve treatment outcomes. Narrative  Optical imaging instruments have permeated medical practice because of their ease of use, rapid adaptation to clinical needs, portability, real-time feedback, and relatively low cost. We have developed a wearable head- mounted display device that is augmented by visible and near-infrared fluorescence imaging of tissues in real- time. In collaboration with an industry partner, we will optimize the device performance and ergonomics using human factors engineering. Successful completion of the research will accelerate its clinical translation and adoption in both high- and low-resource communities.",Imaging Goggles for Fluorescence-Guided Surgery,10233215,R01EB030987,"['3-Dimensional', 'Address', 'Adoption', 'Algorithms', 'Animal Cancer Model', 'Area', 'Augmented Reality', 'Beds', 'Biological', 'Blood flow', 'Breast-Conserving Surgery', 'Calibration', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Consumption', 'Data', 'Decision Making', 'Development', 'Devices', 'Diagnostic radiologic examination', 'Digital Imaging and Communications in Medicine', 'Disease', 'Dyes', 'Engineering', 'Ensure', 'Evaluation', 'Excision', 'Eye', 'Feedback', 'Fluorescence', 'Frozen Sections', 'Goals', 'Goggles', 'Growth', 'Head Cancer', 'Health Insurance Portability and Accountability Act', 'Histology', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Device', 'Incidence', 'Infiltration', 'Infrastructure', 'Intervention', 'Intuition', 'Left', 'Lesion', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medical Device', 'Medical center', 'Metadata', 'Methods', 'Microscopic', 'Molecular Probes', 'Molecular Target', 'Near-infrared optical imaging', 'Neck Cancer', 'Noninfiltrating Intraductal Carcinoma', 'Oncology', 'Operating Rooms', 'Operative Surgical Procedures', 'Optical Methods', 'Optics', 'Outcome', 'Pathology', 'Pathology Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Pilot Projects', 'Real-Time Systems', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Role', 'Rural', 'Rural Hospitals', 'Savings', 'Solid Neoplasm', 'Specimen', 'Stream', 'Surgeon', 'Surgical Oncology', 'Surgical margins', 'System', 'Tactile', 'Testing', 'Thick', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Treatment outcome', 'Vision', 'Visual', 'Visual Fields', 'Visualization', 'absorption', 'cancer cell', 'cancer imaging', 'cancer recurrence', 'cancer surgery', 'clinical center', 'clinical translation', 'cost', 'design', 'ergonomics', 'experience', 'fluorescence imaging', 'fluorescence-guided surgery', 'head mounted display', 'image processing', 'image registration', 'imaging system', 'improved', 'industry partner', 'infiltrating duct carcinoma', 'interest', 'lens', 'mixed reality', 'neoplastic cell', 'operation', 'optical imaging', 'peripheral blood', 'phantom model', 'portability', 'prevent', 'software development', 'standard of care', 'stem', 'tumor', 'user-friendly', 'virtual imaging', 'wearable device', 'workforce needs']",NIBIB,WASHINGTON UNIVERSITY,R01,2021,564129
"Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow Project Summary/Abstract Low oxygen (hypoxic) environments are known to be important for maintaining the small number of adult stem cells in the human body, such as in bone marrow. These conditions are also believed to enable dormant cancer cells to survive and metastasize years or decades after the original tumor has been destroyed and the reason why bone marrow is one of the most common sites of cancer metastasis. Understanding of these conditions can drive the development of 3D cellular scaffolds for growing stem cells ex vivo, thus reducing the burden on requiring bone marrow transplants, and for developing therapeutics that prevent cancer relapse. This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. The technique is based on developments in x-ray luminescence computed tomography, an emerging molecular imaging technique capable of achieving cellular level resolution and high sensitivities. The approach uses x-rays to excite oxygen-sensitive nanophosphors that emit near-infrared photons to finally enable 3D oxygen measurements in deep bone marrow. Because the technique requires a multidisciplinary team with x-ray expertise, nanophosphor expertise, near-infrared detection expertise, and algorithms for quantifying the concentrations and minimizing dose, this STTR fast-track proposal involves several institutions with deep expertise in their respective domains. The proposed Phase I 6-month project is a proof-of- principle demonstration of a breadboard system used on nanophosphors in low oxygen solutions and embedded in bone. The proposed Phase II 24-month project is to develop a complete prototype system and experimentally verify its performance. Project Narrative This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. Local oxygen microenvironments and changes to oxygen tensions over only tens of micrometers are known to be important for maintaining stem cell growth and are suspected to also enable cancer metastases, but are poorly understood because there are no methods with the resolution and sensitivity required. The proposed solution will finally enable 3D oxygen measurements in deep bone marrow based on a newly developed technique called x- ray luminescence computed tomography (XLCT) and oxygen-sensitive nanophosphors for 10 to 100 µm imaging of oxygen concentrations.",Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow,10255544,R42GM142394,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Area', 'Biomedical Research', 'Biopsy', 'Blood', 'Bone Marrow', 'Bone Marrow Transplantation', 'Cancer Patient', 'Cancer Relapse', 'Cells', 'Chemicals', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Disease', 'Dose', 'Environment', 'Fiber', 'Film', 'Heterogeneity', 'Human body', 'Hypoxia', 'Image', 'Imaging Techniques', 'Institution', 'Light', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Measures', 'Metastatic Neoplasm to the Bone', 'Methods', 'Microscopy', 'Modality', 'Molecular', 'Monitor', 'Morphology', 'Nature', 'Neoplasm Metastasis', 'Noise', 'Organ Transplantation', 'Oxygen', 'Penetration', 'Performance', 'Phase', 'Photons', 'Production', 'Radiation Dose Unit', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Small Business Technology Transfer Research', 'Spatial Design', 'Surface', 'System', 'Techniques', 'Therapeutic', 'Thick', 'Time', 'Tissues', 'Visible Radiation', 'X-Ray Computed Tomography', 'adult stem cell', 'base', 'bone', 'cancer cell', 'cancer site', 'deep learning', 'deep learning algorithm', 'denoising', 'design and construction', 'detector', 'high resolution imaging', 'image processing', 'image reconstruction', 'imaging system', 'improved', 'insight', 'luminescence', 'malignant breast neoplasm', 'molecular imaging', 'multidisciplinary', 'phosphorescence', 'pre-clinical', 'prevent', 'prototype', 'quantum', 'response', 'scaffold', 'stem cell growth', 'stem cells', 'therapeutic effectiveness', 'tissue oxygenation', 'tomography', 'transmission process', 'tumor', 'two-photon']",NIGMS,"SIGRAY, INC.",R42,2021,252113
"Simulation Tools for 3D and 4D CT and Dosimetry Abstract Photon-counting CT (PCCT) is a major technological advance in CT imaging. Using photon-counting instead of current energy-integrating detectors, PCCT can offer superior performance in terms of spatial resolution, artifact reduction, and most notably, material decomposition. PCCT’s energy differentiation utility offers an ability to more precisely distinguish different materials and optimize and expand the use of contrast agents in CT. With these abilities, PCCT can significantly facilitate quantitative imaging, reduce radiation exposure, and enable revolutionary new applications in functional and physiological imaging beyond existing CT techniques. To realize the full potential of PCCT in clinical practice, the technology needs comprehensive assessments and application-based optimizations. Effective design and deployment of PCCT depends on many design and use choices that should be made in view of the eventual clinical utility. Making these choices requires large scale trials on actual patients. However, such trials are challenging, considering the need to make many decisions prior to prototyping, the limited numbers of prototype PCCT scanners available today, and the often-unknown ground-truth in the patient images. Even for existing prototype systems, many decisions require repetitive trials with multiple acquisitions. This is both unethical and impractical considering radiation safety concerns and costs. These challenges can be overcome by utilizing virtual imaging trials (VITs) using computerized patients and imaging models. VITs provide an efficient means with which to determine the most effective and optimized design and use of imaging technologies with complete control over the study design. In our prior funded project, we developed a VIT framework to evaluate standard energy-integrating detector CT technologies. In this project, we expand the applicability of this framework to photon-counting detector CT. Specifically, we enhance our computational XCAT phantoms to model the necessary higher-resolution detail including normal and abnormal tissue heterogeneities and intra-organ contrast perfusion diversity across populations (Aim 1). To image the phantoms, we develop the first PCCT simulator capable of mimicking existing and emerging prototypes (Aim 2). The enhanced VIT framework will provide the essential foundation with which to comprehensively evaluate and optimize PCCT technologies and applications. In Aim 3, we assess and optimize the use of PCCT for morphological, textural, and compositional quantification in select oncologic and cardiac applications, two leading health detriments in the US where PCCT can offer a notable impact. The results will be the first of their kind in comprehensively evaluating the task-based merits and capabilities of PCCT, determining optimum dose per patient size for PCCT imaging of patients for cancerous lesions and cardiac plaque/stenoses, and helping to establish the effective utility of PCCT in clinical care. The purpose of this project is to develop and utilize a virtual framework to comprehensively evaluate and optimize emerging photon-counting devices and applications in CT imaging. The results will be the first of their kind evaluating the task-based merits and capabilities of photon-counting CT and will help establish its effectual utility in oncologic and cardiac care.",Simulation Tools for 3D and 4D CT and Dosimetry,10189580,R01EB001838,"['3-Dimensional', 'Abdomen', 'Anatomy', 'Cancerous', 'Cardiac', 'Caring', 'Clinic', 'Clinical', 'Computer software', 'Contrast Media', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Dose', 'Ensure', 'Ethics', 'Evaluation', 'Foundations', 'Functional Imaging', 'Funding', 'Health', 'Heterogeneity', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Industry', 'Lesion', 'Manufacturer Name', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Noise', 'Organ', 'Pathologic', 'Patient imaging', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Population', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Research Design', 'Resolution', 'Resources', 'Role', 'Safety', 'Scientist', 'Series', 'Specimen', 'Stenosis', 'System', 'Task Performances', 'Techniques', 'Technology', 'Texture', 'Tissue Model', 'Tissues', 'Work', 'X-Ray Computed Tomography', 'analytical method', 'base', 'cardiac plaque', 'clinical application', 'clinical care', 'clinical practice', 'computerized', 'computerized tools', 'cost', 'cost efficient', 'deep learning', 'design', 'detector', 'dosimetry', 'experimental study', 'human imaging', 'human subject', 'improved', 'insight', 'learning strategy', 'photon-counting detector', 'prototype', 'quantitative imaging', 'simulation', 'soft tissue', 'tool', 'unethical', 'virtual', 'virtual imaging']",NIBIB,DUKE UNIVERSITY,R01,2021,534495
"Shear stress and light-field to elucidate the initiation of cardiac outflow tract Shear Stress and Light-Field to Elucidate the Initiation of Cardiac Outflow Tract Biomechanical forces modulate cardiac morphogenesis, and mutations in mechano-sensitive signaling pathways result in congenital heart defects. During the previous funding cycle, our team custom-built a Light- Sheet Fluorescence Microscopy (LSFM) with sub-voxel resolution to enhance axial resolution needed to provide a large field-of-view. This laser optical system allowed for imaging pulsatile vs. oscillatory shear stress- mediated Notch signaling to initiate endocardial trabeculation. We demonstrated that spatial (/x) and temporal (/t) variations in shear stress modulates Notch-EphrinB2-Neureguilin-1 signaling in the endocardium to activate erb-B2 receptor tyrosine kinase (ErbB2) that promotes proliferation of trabeculation. By integrating LSFM, computation, and transgenic models, we further established that trabeculation dissipates intracardiac shear stress-generated kinetic energy; thus, mitigating ventricular remodeling. However, it remains unclear what would be the consequences of reduced myocardial contractility or altered intracardiac flow dynamics on valve morphogenesis. Thus, we seek to integrate light-sheet (Bessel-Gaussian beam arrays) with a new 2) light-field (microlens array). The former provides non-diffracting illumination, and the latter provides volumetric detection as a paradigm shift to image both myocardial contractility and intracardiac flow dynamics in the outflow tract (OFT). Our preliminary study reveals that shear-mediated Notch1b expression in the endocardium of OFT regulates endothelial-to-mesenchymal transition (EndoMT); however, the mechanotransduction causation whereby myocardial contractility and intracardiac shear stress reciprocally interact to form bicuspid valves and subsequent remodeling to multi-cuspid valves remains elusive. Thus, our hypothesis is that integration of the new light-field system with imaging computation enhances spatiotemporal resolution needed to decouple myocardial contraction from intracardiac flow dynamics that modulates Notch1b-EndoMT to mediate valve morphogenesis in the OFT. In Aim 1, we plan to integrate light-sheet with the new light-field system for 4-D volumetric imaging of valve formation in the OFT. Our goal is to capture myocardial contractility and intracardiac shear stress at one snapshot. In Aim 2, we will demonstrate the interaction between intracardiac shear stress and myocardial contractility underlying valve morphogenesis. Our goal is to decouple hemodynamic shear from contractile forces that mediate Notch1b-mediated EndoMT. In Aim 3, we will determine the relative role of shear stress and contractility underlying Notch1b-mediated EndoMT. Our goal is to elucidate the relative role of contractility and intracardiac stress to transmit Notch1b- EndoMT signaling underlying bicuspid-valve formation. Overall, our team aims to establish the micro- environment in which intracardiac flow dynamics and myocardial contractility interact to modulate OFT valve formation, with clinical significance to aortic valvular disease. Project Narrative Cardiac outflow tract (OFT) defects, including aortic valves and the greater arteries, are estimated to cause approximately 30% of these congenital heart diseases, and they are treated with surgical correction and/or replacement. It remains unclear what would be the consequences of reduced cardiac contractility or altered intracardiac flow dynamics on valve morphogenesis, including aortic stenosis, bicuspid or tricuspid aortic valves. To understand the mechanotransduction causation downstream of blood flow and shear stress sensing, we have assembled a multi-disciplinary team to integrate advanced laser optics, imaging computation, and genetic models to decouple intracardiac flow dynamics from myocardial contractility that modulates Notch1b-mediated endothelial-to-mesenchymal transition (EndoMT) with translational implication to aortic valve disease.",Shear stress and light-field to elucidate the initiation of cardiac outflow tract,10146767,R01HL129727,"['4D Imaging', 'Aortic Valve Stenosis', 'Arteries', 'Bicuspid', 'Biomechanics', 'Blood flow', 'Cardiac', 'Computer Models', 'Congenital Heart Defects', 'Coupled', 'Cuspid', 'Custom', 'Data Reporting', 'Defect', 'Detection', 'ERBB2 gene', 'Endocardium', 'Endothelium', 'Etiology', 'Fluorescence Microscopy', 'Funding', 'Gaussian model', 'Genes', 'Genetic Models', 'Genetic Recombination', 'Goals', 'Heart', 'Image', 'Kinetics', 'Lasers', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Mediating', 'Mesenchymal', 'Microscopy', 'Mitral Valve', 'Morphogenesis', 'Mutation', 'Myocardial', 'Myocardial Contraction', 'Neuregulin 1', 'Operative Surgical Procedures', 'Optics', 'Receptor Protein-Tyrosine Kinases', 'Reporter', 'Resolution', 'Role', 'Signal Pathway', 'Signal Transduction', 'Stress', 'Structure', 'System', 'Testing', 'Time', 'Transgenic Model', 'Transgenic Organisms', 'Variant', 'Ventricular', 'Ventricular Remodeling', 'aortic valve', 'aortic valve disorder', 'automated segmentation', 'base', 'clinically significant', 'congenital heart disorder', 'erbB-2 Receptor', 'hemodynamics', 'imaging Segmentation', 'mechanotransduction', 'multidisciplinary', 'notch protein', 'optical imaging', 'response', 'shear stress', 'simulation', 'single-cell RNA sequencing', 'spatiotemporal', 'transcriptomics']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,459651
"Automated Digital Imaging for Cervical Cancer Screening Project Abstract/Summary: Cervical cancer screening programs remain essential to reduce cervical cancer in women despite the availability of human papilloma virus (HPV) vaccines. Screening is important for all women but is particularly important for women living with HIV given the high prevalence of HPV in this group and risks associated with progression notwithstanding antiretroviral therapy. Here we propose to investigate the clinical utility of a new method of automated digital imaging of the cervix on the MobileODT platform as a screen-and-treat approach. We build on a long-term collaboration between the University of Cape Town and Columbia University investigating how to strengthen cervical cancer screening and treatment in South Africa. Currently, screen-and-treat programs utilizing HPV DNA testing are recommended by the World Health Organization. We have demonstrated the safety, efficacy and cost-effectiveness of this approach for the South African setting with its high HIV prevalence in women. In this setting, we are currently completing an NCI- supported study demonstrating the feasibility and outstanding performance of an HPV DNA assay that can be used at the point-of-care for a single-visit, screen-and-treat program. Here we propose to extend this work to investigate in Specific Aim 1: the performance characteristics of automated digital imaging as a standalone, primary screening test to replace HPV DNA testing for use in the single-visit, screen-and-treat approach; Specific Aim 2: the performance characteristics of automated digital imaging as a triage test for women who test HPV DNA positive in the screen- and-treat approach; and Specific Aim 3: facility-level operational challenges and facilitators to integrating this new imaging technology into single-visit screen-and-treat programs. We propose to undertake the studies to address these aims among women living with and without HIV at clinical sites in Cape Town, South Africa. Our overall goal is to strengthen cervical cancer screening approaches to reduce cost and improve the effectiveness of screening. Project Narrative We propose to investigate the accuracy and implementation potential of a new technology that provides an automated and almost instant classification of cervical cancer precursor lesions based on a cloud-based, machine-learning algorithm of an image of the cervix. We will investigate the clinical utility of this new technology for integrating into screen-and-treat programs for women living with and without HIV in South Africa.",Automated Digital Imaging for Cervical Cancer Screening,10210372,R01CA254576,"['Acetic Acids', 'Address', 'Algorithms', 'Automobile Driving', 'Biological Assay', 'Biopsy', 'Cervical', 'Cervical Cancer Screening', 'Cervical Intraepithelial Neoplasia', 'Cervix Uteri', 'Characteristics', 'Classification', 'Clinical', 'Collaborations', 'Colposcopes', 'Colposcopy', 'Cytology', 'Data Analyses', 'Development', 'Diagnosis', 'Effectiveness', 'FDA approved', 'General Population', 'Generations', 'Goals', 'Gold', 'HIV', 'Health Services', 'High Prevalence', 'Histologic', 'Human Papilloma Virus Vaccine', 'Human Papillomavirus', 'Human papilloma virus infection', 'Image', 'Imaging technology', 'Incidence', 'India', 'Infrastructure', 'Investigation', 'Lesion', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Output', 'Performance', 'Predictive Value', 'Prevalence', 'Price', 'Primary Prevention', 'Procedures', 'Provider', 'Randomized Clinical Trials', 'Reporting', 'Resources', 'Risk', 'Safety', 'Secondary Prevention', 'Sensitivity and Specificity', 'Services', 'South Africa', 'South African', 'Specificity', 'Testing', 'Time', 'Triage', 'Universities', 'Visit', 'Visual', 'Woman', 'Women&apos', 's Group', 'Work', 'World Health Organization', 'antiretroviral therapy', 'automated visual evaluation', 'base', 'clinical research site', 'cloud based', 'cost', 'cost effective', 'cost effectiveness', 'digital', 'digital imaging', 'effectiveness study', 'high risk population', 'histological specimens', 'improved', 'low and middle-income countries', 'machine learning algorithm', 'mortality', 'new technology', 'point of care', 'programs', 'recruit', 'screening', 'screening program', 'success', 'viral DNA']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,519004
"Dynamic µOCT for cellular tissue phenotyping Phenotyping cells and tissue is a critical function that spans basic science to clinical diagnosis. Yet, established methods for phenotyping cells in tissue are static, are evaluated when the tissue is dead, and typically involve destruction of the sample. This paradigm misses an entire dimension represented by cellular function and activity, information that is potentially of great significance in understanding cell/tissue state. Recently, a new field has emerged that uses coherence-gated imaging to quantify living tissue motion as a proxy of cellular function and activity. Coherence-based motility imaging is relatively new - much remains to be learned about the nature of its dynamic signal. In addition, many of the coherence-gated technologies described to date lack the resolution to investigate individual cells. The ones that are capable of seeing cells do not provide cross-sectional images and thus miss important architectural patterns associated with tissue maturation. We have developed a form of coherence-gated imaging called 1-µm optical coherence tomography (µOCT). µOCT has a resolution of 1 µm axial by 2 µm lateral, enabling cross-sectional visualization of tissue at the cellular level. Recently, we have discovered that by sequentially acquiring multiple µOCT images and computing the pixel-per-pixel power spectrum, we observe a dramatic increase in image contrast and new information emerging from the µOCT datasets. Preliminary studies with this new technology, termed dynamic µOCT (DµOCT), suggest that it can be used to visualize epithelial maturation, cell death/apoptosis, and cellular activity. In this grant, we will mature this technology by conducting key validation studies in a variety of clinically relevant human tissues, animal models, and spheroids to understand the dynamic signal and determine its accuracy for diagnosing pathology, activity, and response to therapy (apoptosis/necrosis) (Aim 1). We also will advance DµOCT further by increasing spatial and temporal resolution, creating new data mining analysis pipelines, and developing and validating technology and probes that enable DµOCT to be implemented in vivo (Aim 2). By expanding our understanding and implementation of this exciting technology, we hope to provide a powerful new tool that will have significant and wide-reaching impact in the biological and clinical sciences. In this proposal we will develop a cross-sectional imaging technology termed dynamic µOCT (DµOCT) that identifies distinct cells and tissues using intracellular motility signatures, a proxy of cell activity and state. Research will involve conducting a series of experiments in spheroids, animals, and human tissue to understand the nature of the dynamic signal and determine the diagnostic capacity of this technology for distinguishing disease, cell/tissue activity, and response to therapy. We additionally will develop next generation DµOCT technology that will increase resolution, provide more powerful diagnostic algorithms, and enable the use of DµOCT in living patients.",Dynamic µOCT for cellular tissue phenotyping,10221328,R01CA265742,"['3-Dimensional', 'ANXA5 gene', 'Algorithms', 'Animal Model', 'Antineoplastic Agents', 'Apoptosis', 'Apoptotic', 'Architecture', 'Area', 'Basic Science', 'Biological', 'Biological Sciences', 'Cancerous', 'Cell Death', 'Cell Line', 'Cell Maturation', 'Cell Proliferation', 'Cell physiology', 'Cells', 'Clinical', 'Clinical Sciences', 'Data', 'Data Set', 'Devices', 'Diagnostic', 'Dimensions', 'Disease', 'Epithelial', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Frequencies', 'Gold', 'Grant', 'Growth', 'Human', 'Image', 'Imaging technology', 'Immunohistochemistry', 'Individual', 'Label', 'Lateral', 'Light', 'Measures', 'Melanoma Cell', 'Metabolic', 'Metabolism', 'Methods', 'Microscopic', 'Modification', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'Movement', 'Mus', 'Nature', 'Necrosis', 'Optical Coherence Tomography', 'Optics', 'Organism', 'Organoids', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phase-Contrast Microscopy', 'Phenotype', 'Pilot Projects', 'Process', 'Propidium Diiodide', 'Proxy', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Signal Transduction', 'Skin', 'Source', 'Speed', 'Stains', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Upper digestive tract structure', 'Visualization', 'analysis pipeline', 'animal tissue', 'base', 'cell motility', 'clinical Diagnosis', 'clinically relevant', 'contrast imaging', 'data mining', 'diagnostic accuracy', 'disease diagnosis', 'drug efficacy', 'experimental study', 'histological slides', 'human tissue', 'imaging system', 'improved', 'in vivo', 'inhibitor/antagonist', 'machine learning algorithm', 'microdevice', 'mouse model', 'new technology', 'next generation', 'response', 'spatiotemporal', 'temporal measurement', 'three dimensional cell culture', 'tool', 'tumor', 'validation studies']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,619861
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10202460,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2021,749956
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10256621,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,447500
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027
"Machine learning algorithms to analyze large medical image datasets Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. Our overall objective for this research is to dramatically reduce the burden of creating high quality reference labels by requiring only a small set of such labels from experts. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. This will enable us to apply ML techniques to generate high quality labels of the large amounts of unlabeled data that are already available, which in turn will facilitate the assessment of potential quantitative imaging biomarkers. We will develop, extend and evaluate novel algorithms that represent three distinct strategies for reducing labelling cost. These three strategies are learning from unlabelled data incorporating a novel strategy for characterizing uncertainty, optimizing sample selection for expert quality labelling with a novel form of Active Learning especially suited for deep learning, and reducing the cost of achieving quality labeling by replacing or augmenting an expert with a crowd of inexperts. We will then implement and distribute these novel algorithms, facilitating the replication of our experiments. Finally, we will demonstrate the practical efficacy of these three strategies by applying them to the important challenge of identifying quantitative imaging biomarkers that best capture alterations in brain structure that are associated with characteristics of ASD. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes. Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes.",Machine learning algorithms to analyze large medical image datasets,10182522,R01LM013608,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'Benchmarking', 'Brain', 'Characteristics', 'Child', 'Clinical', 'Collection', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Fatigue', 'Image', 'Image Analysis', 'Informatics', 'Interruption', 'Label', 'Learning', 'Life', 'Machine Learning', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Noise', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Reference Standards', 'Research', 'Sampling', 'Speed', 'Structure', 'Techniques', 'Training', 'Uncertainty', 'Update', 'autism spectrum disorder', 'base', 'clinical decision-making', 'cost', 'crowdsourcing', 'deep learning', 'design', 'experimental study', 'imaging Segmentation', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'novel', 'novel strategies', 'prevent', 'quantitative imaging', 'radiologist', 'success', 'supervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,369580
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis ABSTRACT Heart failure imposes a tremendous burden of morbidity and mortality, costing the United States in excess of $31 billion annually. An increasingly recognized major determinant of outcomes in heart failure is right ventricular (RV) dysfunction. However, the nature and character of RV contribution to cardiovascular outcomes remains poorly understood, largely due to the imprecision of imaging and interpretation of RV morphology and function. Echocardiography, with its high temporal resolution and low cost of acquisition, serves as frontline cardiovascular imaging and a mainstay in approaches to assessing RV morphology and function. However, echocardiographic imaging of the RV is limited by factors that include technical variation in image acquisition and heterogeneity in image assessment as well as overall interpretation. We postulate that deep learning based phenotyping can offer the ability to not only more precisely characterize RV function but also classify RV imaging phenotypes according to etiologic disease states and, even further, refine prognostic evaluations of future cardiovascular risk. Therefore, in Aim 1, we will use video-based deep learning segmentation models to assess RV function, evaluate its cross-sectional relation with a range of expert-measured parameters, and examine its variation in the context of patient characteristics derived from large hospital-based cohorts. In Aim 2, we will use video-based deep learning models to produce imaging-based classification of RV disease and assess the ability of unsupervised approaches to classify RV dysfunction into various categories of disease etiology. In Aim 3, we will use models developed in part from training in Aims 1 and 2 to predict major cardiovascular outcomes including heart failure in addition to coronary artery disease, stroke, and cardiovascular death in both hospital- based and community-based cohorts. The overarching goal of this proposal is to improve the precision and standardization of RV phenotyping and determine the extent to which deep learning models can augment human assessment of the RV. This research will be accomplished in the setting of a comprehensive career development program designed to provide the candidate with the skills needed to become an independent physician-scientist in cardiovascular medicine and translational imaging science. An advisory committee of established scientists/mentors in the fields of cardiac imaging, deep learning, data science, and translational science will guide the candidate in his transition to scientific independence over the course of the award period. PUBLIC HEALTH RELEVANCE STATEMENT Heart failure imposes a tremendous morbidity and mortality burden, costing the U.S. healthcare system over $31 billion per year. An under-recognized and yet important contributor to heart failure outcomes is right ventricular dysfunction, which remains understudied due to technical issues that have historically challenged conventional approaches to cardiovascular imaging. We will examine how deep learning models can precisely evaluate right ventricular function – and enable earlier, more accurate assessments of its contributions to cardiovascular risk.","Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis",10185865,K99HL157421,"['Address', 'Advisory Committees', 'Architecture', 'Arrhythmogenic Right Ventricular Dysplasia', 'Award', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Cohort Studies', 'Communities', 'Computer Vision Systems', 'Coronary Arteriosclerosis', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Outcome', 'Dissection', 'Early Diagnosis', 'Echocardiography', 'Engineering', 'Epidemiology', 'Etiology', 'Evaluation', 'Framingham Heart Study', 'Future', 'Goals', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart failure', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Motion', 'Multi-Ethnic Study of Atherosclerosis', 'Nature', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Program Development', 'Prospective cohort', 'Pulmonary Embolism', 'Research', 'Research Personnel', 'Right Ventricular Dysfunction', 'Right Ventricular Function', 'Right ventricular structure', 'Risk', 'Risk Factors', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Standardization', 'Stroke', 'Techniques', 'Training', 'Translational Research', 'United States', 'Validation', 'Variant', 'Ventricular', 'base', 'cardiovascular imaging', 'cardiovascular risk factor', 'career', 'career development', 'cohort', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'hands on research', 'healthcare community', 'heart imaging', 'improved', 'mortality', 'neural network', 'neural network architecture', 'novel', 'outcome forecast', 'outcome prediction', 'performance tests', 'population based', 'predictive modeling', 'prognostic', 'programs', 'public health relevance', 'pulmonary arterial hypertension', 'skills', 'spatiotemporal', 'statistics', 'study population', 'success', 'temporal measurement']",NHLBI,CEDARS-SINAI MEDICAL CENTER,K99,2021,154780
"Radiomics signatures and patient outcomes in intracerebral hemorrhage PROJECT SUMMARY / ABSTRACT The following K23 proposal is for Dr. Sam Payabvash, a Neuroradiologist and Assistant Professor of Radiology at Yale University. Dr. Payabvash is a physician-scientist with specialized expertise at the intersection of neuroscience, neuroimaging, and computer vision. His career goal is to find new treatment targets and to provide personalized care for patients with cerebrovascular disease. Intracerebral hemorrhage (ICH) is one of the most devastating cerebrovascular diseases with no effective treatment. To date, imaging markers of ICH risk- stratification and outcome prediction have been subjective and descriptive in nature, leaving a large gap for automated assessment of imaging feautres embedded in medical images. Preliminary results by Dr. Payabvash have demonstrated the feasibility of a research plan to apply automated feature extraction pipelines and machine learning algorithms to harness the information in medical images for early risk-stratification and identification of potential treatment targets in ICH. In this proposal, Dr. Payabvash will use detailed clinical and imaging data of 3,991 patients from NIH-funded clinical trials, online archives, and institutional registries at Yale, Tufts, and University College of London. He will apply machine-learning algorithms to identify those imaging features of brain hemorrhage on baseline head CT scan that are related to symptom severity at presentation (aim 1). Then, he will use imaging features of hemorrhage to identify those patients who are at risk for early expansion of hematoma (aim 2a), or surrounding edema (aim 2b). These two “modifiable” indicators of poor outcome are considered potential treatment targets in ICH patients. Finally, he will combine admission clinical information and imaging features to build a risk-stratification tool for long-term outcome prediction (aim 3). Under the expert mentorship of Dr. Kevin Sheth (Chief of Neurocritical Care), Dr. Todd Constable (Director of MRI Research), and Dr. Ronald Coifman (Professor of Mathematics), this K23 award will allow Dr. Payabvash to (1) identify and address the most pressing issues in cerebrovascular disease with innovative neurogaming tools; (2) gain expertise in advanced statistical analysis of brain scans; and (3) expand his knowledge in machine learning and computer vision for assessment of medical images. Dr. Payabvash will receive didactic training in neuroimaging statistical analysis, machine learning, deep neural networks, and computer vision. The proposed research and career development plans draw on the wealth of resources available at Yale, including a Regional Coordinating Center for the NIH StrokeNet, the Center for Research Computing; High Performance Computing services, and cutting-edge image processing and analysis infrastructure. At the conclusion of this award period, Dr. Payabvash will be well-positioned to become an independently-funded investigator conducting high-quality research in advanced neuroimaging techniques and analysis aimed at improving the care of patients with cerebrovascular disease. PROJECT NARRATIVE Intracerebral hemorrhage (ICH) is a severely debilitating cerebrovascular disease, which affects over 70,000 patients per year in the U.S., and is responsible for over half of stroke-related disability worldwide. So far, the diagnosis, surveillance, and prediction of outcome in intracerebral hemorrhage have mainly relied on visual and subjective assessment of head CT scans. Computerized assessment of medical images and machine learning algorithms can extract hidden features from CT scans and provide innovative tools for accurate outcome prediction and personalized treatment decisions in patients with hemorrhagic stroke.",Radiomics signatures and patient outcomes in intracerebral hemorrhage,10301527,K23NS118056,"['Address', 'Admission activity', 'Affect', 'Age', 'Atlases', 'Award', 'Biologic Characteristic', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Brain scan', 'Caring', 'Cellularity', 'Cerebral hemisphere hemorrhage', 'Cerebrovascular Disorders', 'Cerebrum', 'Characteristics', 'Clinical', 'Clinical Trials', 'Computer Vision Systems', 'Data', 'Deterioration', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Edema', 'Funding', 'Future', 'Genomics', 'Goals', 'Grant', 'Growth', 'Head', 'Healthcare', 'Hematoma', 'Hemoglobin', 'Hemorrhage', 'Heterogeneity', 'High Performance Computing', 'Hour', 'Human', 'Image', 'Image Analysis', 'Inflammatory', 'Infrastructure', 'Knowledge', 'Lead', 'Lesion', 'Linear Models', 'Location', 'London', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Mentored Patient-Oriented Research Career Development Award', 'Mentorship', 'Modeling', 'Nature', 'Necrosis', 'Neurologic', 'Neurologic Deficit', 'Neurologic Symptoms', 'Neurosciences', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Prognostic Factor', 'Proteomics', 'Radiology Specialty', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rogaine', 'Scientist', 'Services', 'Severities', 'Shapes', 'Signal Transduction', 'Statistical Data Interpretation', 'Stroke', 'Symptoms', 'Techniques', 'Texture', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Writing', 'X-Ray Computed Tomography', 'automated analysis', 'base', 'bioimaging', 'blood-brain barrier disruption', 'career', 'career development', 'clinical risk', 'college', 'computerized', 'cytotoxic', 'data archive', 'deep neural network', 'density', 'disability', 'effective therapy', 'evidence base', 'feature extraction', 'feature selection', 'follow-up', 'functional independence', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'machine learning algorithm', 'metabolomics', 'modifiable risk', 'neuroimaging', 'neuroimaging marker', 'new therapeutic target', 'novel', 'online repository', 'outcome prediction', 'personalized care', 'personalized medicine', 'precision medicine', 'professor', 'prognostic', 'quantitative imaging', 'radiomics', 'research and development', 'risk stratification', 'skills', 'statistics', 'tool', 'treatment optimization']",NINDS,YALE UNIVERSITY,K23,2021,194939
"Sustaining the Integrative Imaging Informatics for Cancer Research (I3CR) Center Abstract Artificial intelligence (AI) and other computationally intensive methods have the potential to revolutionize cancer imaging research and patient care. The broad adoption of these technologies depends on the availability development of imaging informatics tools to assist users in managing massive data sets, generating well-curated annotations, and accessing scalable computing resources. The Integrative Imaging Informatics for Cancer Research (I3CR) Center has played a lead role in implementing cancer imaging informatics technology, with a focus on expanding the widely used open source XNAT informatics platform to better support computational workflows in cancer imaging. I3CR has also developed knowledge management tools to better track data processing and analysis, including tools for orchestrating and tracking container-based computing pipelines. As result of this work, XNAT has emerged as the most widely used imaging informatics platform in cancer research. It is deployed in over 200 organizations across academia and industry and has been adopted across a wide range of research contexts, including preclinical imaging, multi-site clinical trials, and clinical translation. As the I3CR informatics platform has matured and been widely adopted, the Center is now evolving to the next phase of development to more broadly sustain the platform. In the work proposed here, we will sustain the I3CR’s ongoing engineering initiatives and expand its outreach efforts. The Center’s sustainment activities will build on and extend the I3CR platform’s expansive set of data and knowledge management capabilities, with a focus on addressing key emergent needs within our user base. In Aim 1, we will continue to develop the XNAT-based data management platform, including adding standards-based clinical interfaces, developing a cohort discovery service with natural language processing support, implementing a task automation service, and extending its container-based computing service to support high performance computing and cloud computing environments. In Aim 2, we will implement a suite of integrations with complementary image analysis and data sharing platforms, including The Cancer Image Archive and the NCI Imaging Data Commons. In Aim 3, we will expand the I3CR’s outreach initiatives to ensure broad and effective adoption of the I3CR informatics platforms. The Center’s training program will utilize the XNAT Academy education platform to host a series of online training programs directed at specific audiences including developers, data scientists, integrators, and system administrators. A suite of supporting cloud services will be implemented assist the community in adopting and developing on the I3CR platform. Relevance Medical imaging is one of the key methods used by cancer researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable cancer researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cancer cures and treatments.",Sustaining the Integrative Imaging Informatics for Cancer Research (I3CR) Center,10187782,U24CA258483,"['Academia', 'Academy', 'Address', 'Administrator', 'Adopted', 'Adoption', 'Advanced Development', 'Area', 'Artificial Intelligence', 'Automation', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Cloud Service', 'Communities', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Commons', 'Data Scientist', 'Data Set', 'Database Management Systems', 'Development', 'Digital Imaging and Communications in Medicine', 'Disease', 'Ecosystem', 'Education', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Event', 'FAIR principles', 'Funding', 'Grant', 'Health', 'High Performance Computing', 'Human Biology', 'Image', 'Image Analysis', 'Industry', 'Informatics', 'Information Resources Management', 'Information Systems', 'International', 'Knowledge', 'Lead', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Multi-Institutional Clinical Trial', 'NCI Center for Cancer Research', 'National Cancer Institute', 'Natural Language Processing', 'Online Systems', 'Outreach Research', 'Pathway interactions', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Play', 'Radiology Information Systems', 'Request for Applications', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Services', 'Structure', 'System', 'Technology', 'The Cancer Imaging Archive', 'Training Programs', 'Visualization', 'Work', 'anticancer research', 'application programming interface', 'base', 'cancer imaging', 'clinical translation', 'cohort', 'computerized data processing', 'computing resources', 'data dissemination', 'data management', 'data sharing', 'deep learning', 'education resources', 'feature extraction', 'imaging informatics', 'improved', 'indexing', 'informatics tool', 'large datasets', 'open source', 'outreach', 'preclinical imaging', 'reconstruction', 'response', 'sharing platform', 'success', 'symposium', 'tool', 'trend', 'web services']",NCI,WASHINGTON UNIVERSITY,U24,2021,770038
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,10162650,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual clinical trial', 'virtual patient']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2021,384396
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10224190,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2021,119250
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,10150027,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2021,695400
"Content-based MR-TRUS Fusion without Tracking There are about 3 million American men living with prostate cancer, the second leading cause of cancer death for men in the United States. If the prostate cancer is caught early before it spreads to other parts of the body, by active monitoring or treatment, most men will not die from it. Nevertheless, 22% to 47% of the patients with negative biopsies but elevated prostate-specific antigen levels may still harbor malignant tumors, which can be life threatening and could have been missed by the commonly used ultrasound guided random biopsy. By contrast, fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted biopsies has shown to significantly improve the cancer detection rate. However, MR-TRUS fusion itself is very challenging due to the difficulties in directly registering images of these two very different modalities in different dimensions. To bypass the difficult registration problems, the existing fusion techniques require the use of specialized expensive and cumbersome hardware tracking devices, which increases cost and elongates procedures. More importantly, due to a number of factors such as patient movement, respiratory motion and ultrasound transducer pressure change, prostate motion can happen during a procedure and cause the images to be misaligned. Timely noticing and correcting such motion require great skill and knowledge of radiological imaging, where studies show a steep learning curve for mastering fusion systems. Failing in image registration and motion compensation renders the fusion guided biopsy performing no differently than random biopsy. To address the fundamental cause of the problems, the goal of this project is to create enabling technology of MR- TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs. Recent advancement in machine learning, especially deep learning, has provided us new tools and new angles to tackle this challenging problem. This project aims for directly fusing 2D TRUS frames with 3D MR volume by developing novel deep learning methods for image reconstruction and registration. The proposed methods are designed to exploit both population and patient specific imaging information to accurately align images. As all learning-based image registration methods try to better use population knowledge to improve the registration performance, few of them have been able to efficiently use patient specific information, which can be essential to obtain robust and accurate performance. Upon successful completion, the innovation created from the project will disrupt the common perception that hardware tracking has to be used for multimodal image fusion-guided interventions and alleviate the demand on physicians’ experience and skill in image analysis and fusion to help obtain consistent results. This project will lead to the development of novel prostate biopsy systems and will also impact a range of other image fusion based interventional guidance technologies. Fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted prostate biopsies can significantly improve the detection of aggressive cancer. The goal of this project is to create enabling technology of MR-TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs.",Content-based MR-TRUS Fusion without Tracking,10140348,R21EB028001,"['3-Dimensional', 'Address', 'American', 'Area', 'Biopsy', 'Body part', 'Bypass', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Cyst', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Electromagnetics', 'Financial compensation', 'Foundations', 'Future', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Intelligence', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Life', 'Liver', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manuals', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Multimodal Imaging', 'PSA level', 'Patients', 'Perception', 'Performance', 'Physicians', 'Population', 'Pressure Transducers', 'Procedures', 'Prostate', 'Psychological Transfer', 'Research', 'Retrospective Studies', 'Risk Assessment', 'Slice', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Thinness', 'Time', 'Training', 'Transrectal Ultrasound', 'Ultrasonic Transducer', 'Ultrasonography', 'United States', 'base', 'calcification', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'experience', 'image reconstruction', 'image registration', 'imaging modality', 'imaging study', 'improved', 'innovation', 'learning strategy', 'men', 'next generation', 'novel', 'patient population', 'population based', 'prostate biopsy', 'radiological imaging', 'reconstruction', 'research clinical testing', 'respiratory', 'skills', 'tool']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R21,2021,192513
"Optical design and the development of high accuracy automated tick classification using computer vision Abstract. The incidence of US tick-borne diseases has more than doubled in the last two decades. Due to lack of effective vaccines for tick-borne diseases, prevention of tick bites remains the primary focus of disease mitigation. Tick vector surveillance—monitoring an area to understand tick species composition, abundance, and spatial distribution—is key to providing the public with accurate and up-to-date information when they are in areas of high risk, and enabling precision vector control when necessary. Despite the importance of vector surveillance, current practices are highly resource intensive and require significant labor and time to collect and identify vector specimens. Acarologist or field taxonomist expertise is a limited resource required for tick identification, creating a significant capability barrier for national tick surveillance practice. While mobile applications to facilitate passive surveillance and reporting of human-tick encounters have grown in popularity, variable image quality, limited engagement, and scientist misidentification of rare, invasive, or morphologically similar tick species hinder the scalability of this approach. No automated solutions exist to build tick identification capacity. We seek to develop the first imaging and automated identification system capable of instantaneously and accurately identifying the top nine tick vectors in the US. This proposal will first characterize the optical requirements necessary to image diagnostic morphological features associated with adult ticks and develop a standardized imaging platform for tick identification. This will enable the development of a high-quality tick image dataset in partnership with the Walter Reed Biosystems Unit (WRBU) which will be used to train high-accuracy computer vision models for tick species and sex identification. Ultimately the approaches developed here will enable new tick identification tools for both the lab and citizen scientists; allowing vector surveillance managers to leverage image recognition in a practical system that will increase capacity and capability for biosurveillance, and equipping citizen scientists with improved tools to identify tick species during a human-tick encounter. Project Narrative. Despite the importance of tick vector surveillance for disease prevention, current practices to collect and identify specimens are resource intensive, limiting the quality and quantity of the data informing control efforts. Here we propose the determination of optical requirements for visualization of diagnostic features of the top nine US tick vectors, and the development of high-accuracy computer vision algorithms for the identification of tick species and sex for use in a standardized optical configuration. The high-accuracy tick classification system developed through this proposal promises to expand capacity and capability for tick vector surveillance.",Optical design and the development of high accuracy automated tick classification using computer vision,10325667,R43AI162425,"['Adult', 'Agreement', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Car Phone', 'Cellular Phone', 'Classification', 'Collaborations', 'Computer Vision Systems', 'Culicidae', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Disease Surveillance', 'Disease Vectors', 'Future', 'Goals', 'Grain', 'Human', 'Image', 'Incidence', 'Insecta', 'Larva', 'Learning', 'Leg', 'Life', 'Lighting', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Nymph', 'Optics', 'Phase', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Resolution', 'Resources', 'Scientist', 'Spatial Distribution', 'Specimen', 'Standardization', 'Surveillance Methods', 'System', 'Telephone', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Time', 'Training', 'Vaccines', 'Validation', 'Visual', 'Visualization', 'Work', 'base', 'citizen science', 'convolutional neural network', 'design', 'detection method', 'disorder prevention', 'field study', 'flexibility', 'high resolution imaging', 'high risk', 'human disease', 'imaging platform', 'imaging system', 'improved', 'insight', 'intelligent algorithm', 'interest', 'mobile application', 'novel', 'sample collection', 'sex', 'tick bite', 'tool', 'validation studies', 'vector', 'vector control', 'vector tick']",NIAID,"VECTECH, LLC",R43,2021,295705
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,10137892,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'risk prediction', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,482108
"A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging PROJECT SUMMARY  Obesity is a significant and growing problem in the United States. Currently, 68.5% of the U.S. population is overweight, with approximately 37.7% of the overweight population being obese. The significant health problems associated with overweightedness and obesity, the “body habitus” of this population combined with the significant challenges in medical imaging of these individuals reduces the effectiveness of healthcare for this population. In ultrasound imaging, the quality of abdominal ultrasound exams are significantly affected by obesity.  Fundamentally, an ultrasound image relies on acoustic propagation to a target, reflection, and then propagation back to the surface. The process of beamforming, which converts the surface measurement to an image, is sensitive to the low amplitude reflections from different tissue layers and tissue properties. Typically, the additional fat and connective tissue layers in obese patients can significantly degrade ultrasound image quality by introducing multi-path reverberation and phase aberration that obscure or distort these low amplitude reflections.  However, due to the computational complexity of describing ultrasound propagation and reflection in heterogeneous media, beamformers currently rely on simplified models that do not describe the propagation physics directly. We propose a generational leap in how we approach ultrasound beamforming by using physically and anatomically realistic wave propagation models and measurements that can effectively harness the power of data-driven and rapidly evolving machine learning beamformers. A custom highly realistic simulation tool that we have developed will use acoustical maps of the fine structures in the human body based on photographic cryosections. This physics-based approach will allow us to develop high quality training data and to understand the physical mechanisms for image quality improvement. These simulations will be calibrated to ex vivo and in vivo human data to subsequently generate a large data set that can be used to train a machine- learning-based real-time beamformer. We will focus on two sources of image degradation which we have identified to be particularly deleterious: multipath reverberation and aberration of the focusing profile. The proposed neural network beamformer filters incoherent noise, such as multi-path reverberation, and corrects aberration in the radiofrequency channel signals.  After training the beamformer and implementing it in real-time, a pilot human study in liver ultrasound imaging will be conducted to determine the improvement in image quality in high-body-mass index individuals, where diagnostic imaging is problematic due to image degradation. This technique is highly translatable to other clinical scenarios, varying from cardiac to transcranial to obstetric imaging, by changing the anatomical model. Furthermore, the physical concepts that will be extracted from the learned representation, can be used to improve the design process for ultrasound equipment, including transmit sequences, and transducers. RELEVANCE TO PUBLIC HEALTH Ultrasound beamforming, the process of transforming ultrasound into an image, is based on the principles of wave propagation which are complex due to the soft tissue structure in the human anatomy. Currently, ultrasound imaging uses simplified models of wave propagation. Here we address these limitations with physically and anatomically realistic propagation models based on the human anatomy that can effectively train and harness the power of machine learning beamformers. This technique directly addresses the principal challenge and objective of ultrasound beamforming, which is to limit unwanted acoustical effects from superficial tissue while maximizing signal from deep targets. The advancement of the proposed technology addresses the clear clinical need to provide diagnostic imaging to the growing population of body-limited imaging cases.",A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging,10130064,R01EB029419,"['3-Dimensional', 'Abdomen', 'Acoustics', 'Address', 'Affect', 'Anatomic Models', 'Anatomy', 'Back', 'Cardiac', 'Carotid Arteries', 'Characteristics', 'Clinical', 'Complex', 'Connective Tissue', 'Custom', 'Data', 'Data Set', 'Databases', 'Dependence', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of obstetrics', 'Effectiveness', 'Equipment', 'Fatty acid glycerol esters', 'Generations', 'Health', 'Healthcare', 'Human', 'Human body', 'Image', 'Individual', 'Left', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Measurement', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Noise', 'Obesity', 'Overweight', 'Patients', 'Phase', 'Physics', 'Population', 'Process', 'Property', 'Public Health', 'Resolution', 'Signal Transduction', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Transducers', 'Ultrasonic wave', 'Ultrasonography', 'United States', 'Weight', 'base', 'deep learning', 'design', 'health care quality', 'high body mass index', 'human data', 'human study', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo imaging', 'large datasets', 'learning strategy', 'liver imaging', 'neural network', 'obese patients', 'prototype', 'radio frequency', 'relating to nervous system', 'simulation', 'soft tissue', 'sound', 'tissue phantom', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,521287
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567
"Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans Project Summary The long-term goal of this research is to establish a pipeline for automated image processing that enhances cadaveric non-contrast enhanced (NCE) CT data and extracts meaningful models and metrics to improve anatomy research and education. The objective is to develop the necessary toolset for this image processing, and feature extraction. The central hypothesis is that it is possible to enrich the information content of biomedical imaging data, particularly that of cadaveric NCE CT imaging, for use in gross anatomy education and research. The rationale behind this project is that cadaveric dissection, while an important part of anatomy education, is limited due to sample size, infrastructure, cost, and time. Biomedical imaging can preserve specimens for posterity and be used to supplement this material by providing statistical and quantitative information from anatomical structures. This research will attempt to establish a working pipeline for efficient information extraction through the following specific aims: (1) Improving inter-observer anatomical agreement in cadaveric CT scans; (2) Develop an approach to automatically segment anatomical structures from non-contrast enhanced CT images; and (3) Establish normal variation of anatomical structures and its relationship to pathologies. This project is innovative because it applies artificial intelligence to efficiently extract anatomical information from cadaveric NCE CT imaging, which has only been performed with traditional registration- dependent methods that often fail and are domain specific, acting on a single organ at a time. In addition, this project works with multi-species data to enhance human image data.  This project is significant because it will allow students to understand anatomical variation better by both expanding student exposure to more samples, while also extracting useful representations and analytics from these samples for education and research. The expected outcome of this project is a toolset that is capable of enhancing anatomy education and research by increasing soft-tissue contrast, automatically segmenting the kidneys, liver, mandible, and intraosseus sites of the cranial nerves, and performing statistical analysis on these organs, including but not limited to statistical shape modelling and shape analysis. This will have a positive impact on anatomical education and student retention because it will provide students with a broader range of sample variability information which will decrease pervading biases in medical training that result from small, limited sample sizes, and improve medical training. Project Narrative Dissection is a critical component of anatomy education but is limited due to the infrastructure required by the institution, the amount of variability in the available specimens, and the limited number of specimens available within the course. Biomedical imaging and analysis can be used to supplement dissection, allowing for an expansion in the number of anatomical specimens that students can observe and the amount of clinically relevant material that is available to students to improve their understanding of pathology and variation. This will expand student exposure to anatomical variation, produce more proficient medical professionals, and improve anatomy research.",Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans,10141430,F31EB030904,"['3-Dimensional', 'Address', 'Agreement', 'Anatomic Models', 'Anatomy', 'Artificial Intelligence', 'Blood coagulation', 'Buffaloes', 'Cadaver', 'Characteristics', 'Clinical', 'Computer Models', 'Contrast Media', 'Coupled', 'Cranial Nerves', 'Data', 'Development', 'Diagnostic', 'Disease', 'Dissection', 'Education', 'Exposure to', 'Gifts', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Individual', 'Information Retrieval', 'Infrastructure', 'Institution', 'Kidney', 'Lead', 'Libraries', 'Liver', 'Machine Learning', 'Mandible', 'Manuals', 'Medical', 'Medical Students', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Nature', 'Noise', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Population', 'Preservation Technique', 'Process', 'Reading', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Scanning', 'Shapes', 'Signal Transduction', 'Site', 'Specimen', 'Statistical Data Interpretation', 'Structure', 'Students', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Variant', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'bioimaging', 'clinically relevant', 'cohort', 'contrast enhanced', 'cost', 'deep learning', 'demographics', 'education research', 'feature extraction', 'human imaging', 'image processing', 'image registration', 'improved', 'innovation', 'interest', 'non-invasive imaging', 'posters', 'preservation', 'programs', 'quantitative imaging', 'retention rate', 'segmentation algorithm', 'shape analysis', 'soft tissue', 'success', 'virtual']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,F31,2021,30805
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,10143238,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool', 'trauma surgery']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,197201
"Quantitative MR Imaging of Vascular Factors in Parkinsons Disease Abstract Vascular health has been shown to be an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases. Hence, the ability to measure reliably and quantitatively early hemodynamic changes in the aging brain can be a powerful tool for diagnosing, studying, and developing treatments. Arterial Spin Labeling (ASL) magnetic resonance imaging can yield quantitative perfusion images without the use of contrast agents. We propose that combining new ASL techniques, such as Velocity Selective Inversion (VSI) labeling pulses and magnetic resonance fingerprinting (MRF) with deep learning regression methods will allow quantification of multiple hemodynamic parameters beyond perfusion, thus providing a much more nuanced picture of the state of the vasculature. We also expect that the new technique will offer dramatic improvements in SNR, specificity and sensitivity of ASL, and that the proposed techniques will have many other applications in research and in the clinic. We propose to use these techniques to fill the knowledge gap regarding the relationship between vascular changes and Parkinson’s disease and its symptoms, particularly fatigue, whose pathogenesis is not well understood. If we are successful in this application, future work will use the hemodynamic parameters of interest as biomarkers to assess risk of neurodegeneration, determine therapeutic targets, and guide in the development of new therapies. Public Health Statement Vascular health is an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases We propose to develop a method that can produce quantifiable images of multiple blood flow related parameters with a single scan and without the use of contrast injections. We will use this method to gain a better understanding of the relationship between Parkinson’s disease and cerebral blood flow, and expect that our method will have multiple applications beside Parkinson’s disease.",Quantitative MR Imaging of Vascular Factors in Parkinsons Disease,10266020,R01NS112233,"['Address', 'Agreement', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteries', 'Biological', 'Biological Markers', 'Blood Vessels', 'Blood Volume', 'Blood flow', 'Bolus Infusion', 'Brain', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Contrast Media', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Etiology', 'Fatigue', 'Fingerprint', 'Future', 'Health', 'Human Volunteers', 'Hybrids', 'Image', 'Injections', 'Knowledge', 'Label', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Movement', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Noise', 'Parkinson Disease', 'Pathogenesis', 'Pathologic', 'Patients', 'Perfusion', 'Physiologic pulse', 'Public Health', 'Reproducibility', 'Research', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Spatial Distribution', 'Spin Labels', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Validation', 'Weight', 'Work', 'aging brain', 'deep learning', 'feeding', 'hemodynamics', 'imaging biomarker', 'insight', 'interest', 'machine learning algorithm', 'neural network', 'non-invasive imaging', 'novel therapeutics', 'patient stratification', 'perfusion imaging', 'relating to nervous system', 'success', 'support vector machine', 'therapeutic target', 'tool', 'vascular factor', 'vector', 'white matter']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,281031
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,10110023,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'risk prediction', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2021,777637
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction', 'risk prediction model', 'risk stratification', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",10129958,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury to Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'statistical learning', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,350335
"Real time colon histopathology by infrared spectroscopic imaging Abstract Colorectal cancer (CRC) is one of the leading causes of death in the US. Active screening and early intervention in risky cancers can lead to good outcomes; however, a bottleneck in rapidly delivering appropriate patient care is the long time period for histologic assessment and lack of precision in predicting disease severity. Morphological assessments prevalent in histology are useful but resource intensive and not predictive enough. Molecular techniques to complement traditional pathology are emerging but often require much more effort and time, without being especially compatible with histologic assessments. Here, we seek to develop a technology that measures the chemical content of tissues, does not require reagents, is entirely compatible with clinical workflows and leverages modern artificial intelligence (AI) techniques to provide real-time histologic assessment. The foundation of our approach is a new design for an infrared spectroscopic imaging system that is faster than any reported, offers a higher spatial and spectral quality and uses a solid immersion lens with a fixed focus at the sealed surface of the lens to enable use by a minimally trained person. In conjunction with the instrument, we develop AI algorithms that measure the chemical content of tissue and use it to provide (a) conventional pathology images without the use of dyes (“stainless staining”), and (b) histologic assessment based on molecular data, which can provide complementary composition, disease and risk of lethal cancer images akin to conventional pathology. The instrument will be usable by laboratory technicians, without the need to prepare thin sections from excised tissue and will provide information in minutes. Using preliminary data from human patients on over 850 tissue microarray (TMA) samples from 8 TMAs and 30 surgical resections, we validate the use of technology in providing complete histologic and disease grade assessment. Statistical methods will be used to assess the results rigorously and quantitative milestones guide the entire approach. We then translate the results to fresh tissue chunks, providing histology minutes after tissue is extracted from the body. Finally, we use the detailed tumor and microenvironment information available from the tissue to segment patients into a “high risk” and “low risk” group. The availability of rapid histologic assessment can help prevent delays in providing care, provide intraoperative assessment, and add more information to morphologic assessments following screening, enabling a wide use in CRC and other cancer pathologies. Project Narrative Colorectal cancers (CRC) are among the leading causes of death from cancers in the US. Morphologically assessing excised tissue is the gold standard but requires fixation, staining, microscopy and pathology review, taking days and the information not being especially prognostic. This project develops an alternate technology based on chemical imaging evaluation that can provide an assessment within minutes, resulting in a new instrument, artificial intelligence methods for histology and microenvironment-powered prediction of disease course.",Real time colon histopathology by infrared spectroscopic imaging,10318008,R01CA260830,"['Analysis of Variance', 'Archives', 'Artificial Intelligence', 'Benchmarking', 'Cancerous', 'Caring', 'Cause of Death', 'Chemicals', 'Clinical', 'Code', 'Collaborations', 'Colon', 'Color', 'Colorectal Cancer', 'Complement', 'Computer software', 'Confusion', 'Custom', 'Data', 'Detection', 'Disease', 'Dyes', 'Early Intervention', 'Electronics', 'Epithelial Cells', 'Excision', 'Foundations', 'Fourier Transform', 'Fresh Tissue', 'Future', 'Goals', 'Gold', 'Histocompatibility Testing', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immersion', 'Laboratories', 'Laboratory Chemicals', 'Laboratory Technicians', 'Lead', 'Logistic Regressions', 'Lymph Node Involvement', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microtomy', 'Modeling', 'Modernization', 'Molecular', 'Molecular Analysis', 'Morphology', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Polyps', 'Process', 'Protocols documentation', 'ROC Curve', 'Reagent', 'Regression Analysis', 'Reporting', 'Research', 'Resources', 'Risk', 'Route', 'Sampling', 'Severity of illness', 'Solid', 'Spectroscopy, Fourier Transform Infrared', 'Staging', 'Stains', 'Statistical Methods', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Microarray', 'Tissues', 'Training', 'Translating', 'Validation', 'Work', 'analytical method', 'base', 'cancer diagnosis', 'cancer imaging', 'cell type', 'clinical translation', 'colorectal cancer treatment', 'coronavirus disease', 'deep learning', 'design', 'design and construction', 'disorder risk', 'experience', 'follow-up', 'high risk', 'human data', 'imaging system', 'improved outcome', 'instrument', 'intelligent algorithm', 'learning strategy', 'lens', 'novel', 'pathology imaging', 'pre-clinical', 'prevent', 'prognostic', 'real-time images', 'rural setting', 'sample fixation', 'screening', 'seal', 'spectroscopic imaging', 'success', 'technology validation', 'tissue archive', 'tool', 'tumor microenvironment']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,466088
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,R01CA238191,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,576268
"Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers Superficially spreading types of skin cancers such as lentigo maligna melanomas (LMMs) and non-melanoma skin cancers (NMSCs) occur mostly on older patients, with diffuse sub-clinical sub-surface spread over large areas and with poorly defined margins that are difficult to detect. To treat these cancers, dermatologists rou- tinely perform a large number of mapping biopsies to determine the spread and margins, followed by surgical excision with wide ""safety"" margins. Not surprisingly, such a ""blind"" approach results in under-sampling of the margins, over-sampling of normal skin, too many false positives and false negatives, and too much loss of normal skin tissue. What may help address this problem is reflectance confocal microscopy (RCM) imaging to noninvasively delineate margins, directly on patients. RCM imaging detects skin cancers in vivo with sensitivity of 85-95% and specificity 80-70%. In 2016, the Centers for Medicare and Medicaid Services granted reim- bursement codes for RCM imaging of skin. RCM imaging is now being increasingly used to noninvasively guide diagnosis, sparing patients from unnecessary biopsies of benign lesions. While the two-decade effort leading to the granting of these codes was focused on imaging-guided diagnosis, emerging applications are in imaging to guide therapy. We propose to create an approach called RCM video-mosaicking, to noninvasively map skin cancer margins over large areas on patients, with increased sampling, accuracy and sparing of nor- mal tissue. The innovation will be in designing a highly robust (against tissue warping and motion artifacts) and high speed (real-time, seconds) approach for RCM video-mosaicking: we will develop an optical flow ap- proach with a novel hybrid 3-stage deep learning network comprising of 8 parameters that will model global and local rigid and non-rigid tissue motion dynamics, learn and adapt to variable tissue and speckle noise con- ditions in patients, and predict and automatically detect motion blur artifacts. As required by PAR-18-009, our academic-industrial partnership will deliver RCM video-mosaicking to clinicians for real-time implementation at the bedside (translational novelty). Our proposed application is for guiding surgical excision, but the approach will have wider impact, for guiding new and emerging less invasive non-surgical treatments for superficial skin cancers. In a preliminary study, we demonstrated RCM video-mosaicking with real-time speed (125 millisec- onds per frame, 8 frames per second), and registration errors of 1.02 ± 1.3 pixels relative to field-of-view of 1000 x 1000 pixels. Our specific aims are (1) to develop a real-time and robust RCM video-mosaicking ap- proach and incorporate into a handheld confocal microscope for use at the bedside, (2) to test the approach for image quality and clinical acceptability, and (3) to prospectively test on 100 patients, with pre-surgical video- mosaicking of LMM margins and superficial NMSC margins, followed by validation against post-surgical pa- thology. We are a highly synergistic team from Memorial Sloan Kettering Cancer Center, Northeastern Uni- versity, and Caliber Imaging and Diagnostics (formerly, Lucid Inc.), with a 13-year record of collaboration. RELEVANCE TO PUBLIC HEALTH Reflectance confocal microscopy (RCM) imaging can noninvasively diagnose skin cancers, and spare patients from biopsies of benign skin conditions. We propose to develop an approach to noninvasively delineate skin cancer margins, to help guide less invasive surgery, and help more accurately and completely remove cancer while preserving more of the surrounding normal skin.",Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers,10203886,R01CA240771,"['Ablation', 'Address', 'Area', 'Benign', 'Biopsy', 'Caliber', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Confocal Microscopy', 'Dermatologist', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Excision', 'Funding Opportunities', 'Grant', 'Hutchinson&apos', 's Melanotic Freckle', 'Hybrids', 'Image', 'Lasers', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopy', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Mosaicism', 'Motion', 'Noise', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pharmacotherapy', 'Procedures', 'Process', 'Public Health', 'Radiation therapy', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Skin Tissue', 'Specificity', 'Speed', 'Standardization', 'Surface', 'Surgeon', 'Surgical Pathology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Validation', 'Video Microscopy', 'Visit', 'Visual', 'blind', 'cellular imaging', 'clinical practice', 'deep learning', 'design', 'expectation', 'human imaging', 'image guided', 'image guided therapy', 'imaging approach', 'in vivo', 'industry partner', 'innovation', 'interest', 'learning network', 'microscopic imaging', 'noninvasive diagnosis', 'novel', 'older patient', 'preservation', 'prospective test', 'reflectance confocal microscopy', 'response', 'vector']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2021,641977
"Deformable motion compensation for 3D image-guided interventional radiology PROJECT SUMMARY / ABSTRACT C-arm cone-beam CT (CBCT) plays an increasing role in guidance of interventional radiology (IR) procedures in the abdo- men, with special emphasis in embolization procedures, such as transarterial chemoembolization (TACE) for treatment of hepatocellular carcinoma (HCC) or transarterial embolization (TAE) for control of internal hemorrhage. However, relatively long scan time of CBCT results in artifacts arising from organ motion (respiratory and cardiac motion and peristalsis). This poses a significant challenge to guidance in interventional radiology: for example, motion artifacts were found to render up to 25% of CBCT images un-interpretable in image-guided TACE, and 18% in CBCT-guided emergency TAE. The impact of motion is most significant in cases of single or isolated lesions treated with selective embolization that requires visual- ization of very small vascular structures. Existing motion correction methods often invoke assumption of periodicity, lim- iting their applicability outside of cardiac and respiratory motions, or rely on fiducial tracking or gated acquisition that disrupt IR workflow and/or increase radiation dose. Therefore, the application of CBCT in image-guided interventional procedures in the abdomen would significantly benefit from new methods that estimate complex deformable motion directly from image data. “Autofocus” techniques based on maximization of a regularized image sharpness criterion were shown to yield effective patient motion compensation in extremity, head and cardiac CBCT. However, current applications of such methods are limited to rigid motions. We hypothesize that deformable organ motion compensation in interven- tional soft-tissue CBCT can be achieved with advanced autofocus techniques using multiple locally rigid regions of in- terest, preconditioned with basic motion characteristics obtained through a machine learning decision framework. The following aims will be pursued: 1) Develop a joint multi-region autofocus optimization method to compensate deforma- ble organ motion. This includes incorporation into a comprehensive artifacts correction and image reconstruction pipe- line, design of multi-stage optimization schedules for convergence acceleration, and performance evaluation in deforma- ble phantoms, and cadaver and animal experiments. 2) Develop a decision framework for preconditioning of the motion compensation method through a combination of projection-based approaches for physiological signal estimations (res- piratory cycle) and a multi-input, multi-branch, deep learning architecture trained on extremely realistic simulated data that will estimate basic properties of motion (spatial distribution of amplitude, direction, and frequency) from an initial motion-contaminated image and its associated raw projection data. 3) Evaluate deformable motion compensation in animal experiments and in a clinical study in 50 cases of CBCT-guided TACE and assess image quality via expert observer evaluation of satisfaction and utility. The proposed work will yield a robust, practical method for compensation of deform- able soft-tissue motion in CBCT, removing a critical impediment to 3D guidance in IR. The deformable autofocus frame- work will be applicable to other interventions in which soft-tissue motion diminishes CBCT guidance, such as image-guided radiation therapy. PROJECT NARRATIVE Interventional Cone Beam CT (CBCT) provides critical 3D information to guide minimally-invasive procedures in the abdomen, but CBCT image quality is often compromised by organ deformation due to breathing, cardiac, and peristaltic motions. We propose a novel framework to mitigate the effects of this complex deformable motion using only the CBCT image data, without a need for gating, external trackers, or fiducial markers. This algorithm will remove a major impediment to 3D guidance in procedures such as transcatheter embolization procedures in the abdomen.",Deformable motion compensation for 3D image-guided interventional radiology,10100337,R01EB030547,"['3-Dimensional', 'Abdomen', 'Acceleration', 'Affect', 'Algorithms', 'Angiography', 'Animal Experiments', 'Animals', 'Architecture', 'Arterial Embolization', 'Arteries', 'Blood Vessels', 'Breathing', 'Cadaver', 'Cardiac', 'Characteristics', 'Chemoembolization', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Emergency Situation', 'Evaluation', 'Exhibits', 'Family suidae', 'Financial compensation', 'Fluoroscopy', 'Frequencies', 'Head', 'Hemorrhage', 'Image', 'Intervention', 'Interventional radiology', 'Joints', 'Learning', 'Lesion', 'Limb structure', 'Liver', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Motion', 'Organ', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Periodicity', 'Peristalsis', 'Physiological', 'Play', 'Primary carcinoma of the liver cells', 'Procedures', 'Property', 'Prostate Ablation', 'Radiation Dose Unit', 'Recurrence', 'Reporting', 'Residual state', 'Role', 'Scanning', 'Schedule', 'Signal Transduction', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Therapeutic Embolization', 'Three-Dimensional Image', 'Time', 'Training', 'Validation', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'arm', 'base', 'clinical application', 'cone-beam computed tomography', 'convolutional neural network', 'deep learning', 'design', 'experimental study', 'feeding', 'heart motion', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging modality', 'improved', 'internal control', 'minimally invasive', 'novel', 'preconditioning', 'radiologist', 'respiratory', 'satisfaction', 'simulation', 'soft tissue', 'standard care', 'tumor']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,368438
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,P41EB028741,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2021,1527478
"A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals PROJECT SUMMARY The aim of this proposal is to deliver an innovative and easy-to-use experimental platform for measuring and quantifying naturalistic behaviors of mammalian animal models used for biomedical research, including rodents and monkeys, across a range of spatial and temporal scales. This will require developing a method for tracking movements freely behaving animals with far higher spatiotemporal resolution and more kinematic detail than currently possible. To overcome the limitations of current technologies, a new solution is proposed that synergistically combines two methods - marker based motion capture and a video- based machine learning approach. First, using marker-based motion capture, the gold standard for 3D tracking in humans, the position of experimental subjects' head, trunk, and limbs will be tracked in 3D with submillimeter precision. An innovative marker design, placement strategy, and post-processing pipeline will ensure an unprecedentedly detailed description of rodent behavior over a large range of timescales. To make the system more efficient, robust, affordable and better suited for high-throughput longitudinal studies, the unprecedentedly rich and large 3D datasets generated by the motion capture experiments will be leveraged to train a deep neural network to predict pose and appendage positions from a set of 1-6 normal video cameras. To best capitalize on the large training datasets, the latest advances in convolutional neural networks for image analysis will be incorporated. Together, these advances will promote generalization of the high-resolution 3D tracking system to a variety of animals and environments, thus establishing a cheap, flexible, and easy-to use kinematic tracking method that can easily be scaled up and adopted by other labs. The large ground-truth datasets will allow the system to be benchmarked and compared against state-of-the art technologies in quantitative and rigorous ways. Preliminary studies have been very positive and suggest large improvements over current methods both when it comes to the range of behaviors that can be tracked and the precision with which they can be measured. Importantly, all new technology will be readily shared with the scientific community, thereby leveraging from this single grant the potential for numerous investigators to dramatically improve the efficiency of their research programs requiring rigorous quantitative descriptions of animal behavior. Narrative We will develop and disseminate innovative new technology for measuring precise 3D kinematics in freely moving animals over long time-periods. Our proposed experimental platform will illuminate how natural behaviors are organized and help us understand how they are controlled by the nervous system, and how this control goes awry in disease. The technological leap made possible by this grant will catalyze a host of studies on the neural mechanisms underlying motor control, learning, and mental disorders, and thus help in the discovery of new diagnostic and therapeutic approaches for afflicted patients.",A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals,10120068,R01GM136972,"['3-Dimensional', 'Address', 'Adopted', 'Anatomy', 'Animal Behavior', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Benchmarking', 'Biological Models', 'Biomedical Research', 'Brain', 'Callithrix', 'Cephalometry', 'Communities', 'Complex', 'Data', 'Data Set', 'Deer Mouse', 'Disease', 'Ensure', 'Environment', 'Gold', 'Grant', 'Hand', 'Head', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Learning Disorders', 'Lighting', 'Limb structure', 'Logic', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Movement', 'Mus', 'Nervous System Physiology', 'Nervous System control', 'Neurologic Deficit', 'Output', 'Patients', 'Performance', 'Positioning Attribute', 'Posture', 'Process', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'appendage', 'base', 'computer science', 'convolutional neural network', 'cost', 'deep neural network', 'design', 'expectation', 'experimental study', 'flexibility', 'improved', 'innovation', 'kinematics', 'motor control', 'neural network', 'neuromechanism', 'new technology', 'novel diagnostics', 'novel therapeutic intervention', 'programs', 'relating to nervous system', 'scale up', 'skeletal', 'spatiotemporal']",NIGMS,HARVARD UNIVERSITY,R01,2021,411071
"Developing computational algorithms for histopathological image analysis Project Summary  Histopathology is the cornerstone of disease diagnosis and prognosis. With the advance of imaging technology, whole-slide image (WSI) scanning of tissue slides is becoming a routine clinical procedure and producing a massive amount of data that captures histopathological details in high resolution. Most current pathological image analysis methods, similar to general image analysis approaches, mainly focus on morphology features, such as tissue texture and granularity, but ignore the complex hierarchical structures of tissues. Cells are the fundamental building blocks to tissues. Different types of cells are first organized into cellular components, which together with the extracellular matrix, form different types of tissue architectures. Understanding the interactions among these different types of cells can provide critical insights into biology and disease status. However, there are some major computational challenges: (1) How to identify and classify different types of cells in tissue, (2) how to characterize the highly complex and heterogeneous spatial organization of tissue, and (3) how to integrate histopathology data with other types of data to study disease status and progression. The goal of this proposal is to develop novel computational methods to analyze histopathology image data to study disease status and progression. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, statistical modeling, and clinical pathology. Specifically, we will develop novel algorithms to: (1) classify different types of cells from histopathology tissue WSI scans, (2) characterize and quantify cell spatial distribution and cell-cell interactions, and (3) integrate histopathology data with other types data to study disease progression. All proposed methods were motivated by real-world biological and clinical applications across different types of diseases, such as liver diseases, infectious diseases, and cancer. If implemented successfully, the proposed study will facilitate the analysis and modeling of data generated from histopathology tissue slides to improve disease risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in histopathology imaging and computing have enabled the in-depth characterization of pathology tissues. The overarching goal of this proposal is to develop computational algorithms to analyze histopathology image data to study disease status and progression.",Developing computational algorithms for histopathological image analysis,10097119,R01GM140012,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Bayesian Method', 'Biological', 'Biology', 'Biomedical Research', 'Cell Communication', 'Cells', 'Classification', 'Clinical', 'Clinical Pathology', 'Communicable Diseases', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Diagnosis', 'Disease', 'Disease Progression', 'Evaluation', 'Extracellular Matrix', 'Genomics', 'Goals', 'Graph', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Intuition', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Physics', 'Procedures', 'Research', 'Resolution', 'Risk Assessment', 'Scanning', 'Slide', 'Spatial Distribution', 'Stains', 'Statistical Models', 'Structure', 'Texture', 'Tissue imaging', 'Tissues', 'base', 'cancer type', 'cell type', 'clinical application', 'clinical care', 'convolutional neural network', 'data integration', 'data modeling', 'deep learning algorithm', 'digital', 'digital pathology', 'disease diagnosis', 'disorder risk', 'drug discovery', 'experience', 'improved', 'insight', 'machine learning method', 'molecular pathology', 'multiple datasets', 'novel', 'outcome forecast', 'outcome prediction', 'particle', 'pathology imaging', 'predictive modeling', 'software development', 'user friendly software', 'whole slide imaging']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,409167
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",10075930,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'diagnostic technologies', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'risk stratification', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,448421
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,10188407,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'automated algorithm', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'point-of-care diagnosis', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,1079736
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,10165820,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Comparative Effectiveness Research', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data repository', 'clinical decision support', 'clinical imaging', 'cohort', 'cost', 'deep learning', 'diagnosis standard', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2021,345325
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",10139080,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2021,790095
"A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images Abstract  The ability of accurate localize and characterize cells in light sheet fluorescence microscopy (LSFM) image is indispensable for shedding new light on the understanding of three dimensional structures of the whole brain. In our previous work, we have successfully developed a 2D nuclear segmentation method for the nuclear cleared microscopy images using deep learning techniques. Although the convolutional neural networks show promise in segmenting cells in LSFM images, our previous work is confined in 2D segmentation scenario and suffers from the limited number of annotated data. In this project, we aim to develop a high throughput 3D cell segmentation engine, with the focus on improving the segmentation accuracy and generality. First, we will develop a cloud based semi-automatic annotation platform using the strength of virtual reality (VR) and crowd sourcing. The user-friendly annotation environment and stereoscopic view in VR can significantly improve the efficiency of manual annotation. We design a semi-automatic annotation workflow to largely reduce human intervention, and thus improve both the accuracy and the replicability of annotation across different users. Enlightened by the spirit of citizen science, we will extend the annotation software into a crowd sourcing platform which allows us to obtain a massive number of manual annotations in short time. Second, we will develop a fully 3D cell segmentation engine using 3D convolutional neural networks trained with the 3D annotated samples. Since it is often difficult to acquire isotropic LSFM images, we will further develop a super resolution method to impute a high resolution image to facilitate the 3D cell segmentation. Third, we will develop a transfer learning framework to make our 3D cell segmentation engine general enough to the application of novel LSFM data which might have significant gap of image appearance due to different imaging setup or clearing/staining protocol. This general framework will allow us to rapidly develop a specific cell segmentation solution for new LSFM data with very few or even no manual annotations, by transferring the existing 3D segmentation engine that has been trained with a sufficient number of annotated samples. Fourth, we will apply our computational tools to several pilot neuroscience studies: (1) Investigating how topoisomerase I (one of the autism linked transcriptional regulators) regulates brain structure, and (2) Investigating genetic influence on cell types in the developing human brain by quantifying the number of progenitor cells in fetal cortical tissue. Successful carrying out our project will have wide-reaching impact in neuroscience community in visualizing and analyzing complete cellular resolution maps of individual cell types within healthy and disease brain. The improved cell segmentation engine in 3D allows scientists from all over the world to share and process each other’s data accurately and efficiently, thus increasing reproducibility and power. Project Narrative This proposal aims to develop a next generation cell segmentation engine for the whole brain tissue cleared images. Our proposed work is built upon our previous 2D nuclear segmentation project using deep learning techniques. However, we found that our current computational tool is limited in 2D segmentation scenario and insufficient of annotated training samples. To address these limitations, we will first develop a cloud-based semi-automatic annotation tool with the capacity of virtual reality. Our annotation tool is designed to be cross- platform, which allows us to partner with “SciStarter” (the largest citizen science projects in the world) and acquire large amount of cell annotations from the science enthusiastic volunteers. Meanwhile, we will develop next generation 3D cell segmentation engine using an end-to-end fully connected convolution neural network. To facilitate 3D cell segmentation, we will also develop a super resolution method to impute an isotropic high- resolution image from a low-resolution microscopy image. After the development of 3D cell segmentation engine, we will continue to improve its generality by developing a transfer learning framework which enables us to rapidly deploy our 3D cell segmentation engine to the novel microscopy images without the time-consuming manual annotation step. Finally, we will apply our segmentation tool to visualize and quantify brain structure differences within genetically characterized mouse and human brain tissue at UNC neuroscience center. In the end of this project, we will release the software (both binary program and source code) and the 3D cell annotations, in order to facilitate the similar neuroscience studies in other institutes. Considering the importance of high throughput computational tools in quantifying three dimensional brain structure, this cutting- edge technique will be very useful in neuroscience research community.",A Scalable Platform for Exploring and Analyzing Whole Brain Tissue Cleared Images,10244882,R01NS110791,"['3-Dimensional', 'Address', 'Affect', 'Anecdotes', 'Appearance', 'Area', 'Biological', 'Brain', 'Brain Diseases', 'Brain region', 'Cell Nucleus', 'Cells', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Development', 'Environment', 'Evaluation', 'Fluorescence Microscopy', 'Genetic', 'Genetic Transcription', 'Genotype', 'Gold', 'Human', 'Image', 'Individual', 'Institutes', 'Intervention', 'Knock-out', 'Label', 'Lead', 'Learning', 'Light', 'Link', 'Manuals', 'Maps', 'Methods', 'Microscopy', 'Modeling', 'Mus', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Nuclear', 'Performance', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Reproducibility', 'Resolution', 'Sampling', 'Science', 'Scientist', 'Shapes', 'Slice', 'Source Code', 'Stains', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Type I DNA Topoisomerases', 'Visual', 'Visualization', 'Work', 'annotation  system', 'autism spectrum disorder', 'base', 'bioimaging', 'brain tissue', 'cell type', 'citizen science', 'cloud based', 'computerized tools', 'contrast imaging', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'design', 'fetal', 'flexibility', 'high resolution imaging', 'improved', 'microscopic imaging', 'next generation', 'novel', 'programs', 'stem cells', 'stereoscopic', 'success', 'three dimensional structure', 'tissue processing', 'tool', 'two-dimensional', 'user-friendly', 'virtual reality', 'volunteer']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,335104
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10188526,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2021,388359
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10183329,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2021,797476
"Development of A High Throughput Image-Guided IMRT System for Preclinical Research Project Summary/Abstract Preclinical radiobiology experiments on small animals are crucial to test the safety and efficacy before human clinical trials. However, limited by currently available technologies, preclinical animal studies substantially differ from state-of-the-art human treatments in dose conformity. Consequently, the animal studies poorly mimic the radiobiological, radioimmunological, and toxicity environment of human therapies. The disparity adversely affects our ability to meaningfully test hypotheses that are intended for human translation. With decades of advancement, human radiotherapy has achieved high targeting accuracy and dose conformality based on technological breakthroughs, including intensity-modulated radiotherapy (IMRT), which is unavailable for mouse experiments. A practical device and algorithm to modulate the x-ray intensity for the scale of small animals is the first step to bridge the gap. With the support of an NIH R21 grant, we engineered a novel small animal IMRT dose modulator termed sparse orthogonal collimator (SOC). Equally important as the hardware, we created the enabling mathematical tools to deliver SOC IMRT plans with higher achievable resolution than a theoretically miniaturized MLC-based IMRT. We commissioned and tested prototypical SOCs to deliver highly modulated doses in silico and on phantoms. Nonetheless, there are still large gaps between an intensity modulation device and a small animal IMRT system suitable for broad adoption and impact. The required time, resources, and training to create sophisticated SOC-IMRT plans are incompatible with preclinical settings. Furthermore, without automation, the existing image-guided small animal IMRT treatment is prohibitively slow for treating live animals under anesthesia. Lastly, the current manual method to switch between imaging and therapy modes results in intractable uncertainties in dose delivery. We propose to fill these gaps using automation, robotics, and system optimization. We propose the following specific aims. Specific Aim 1 (SA1). Automated organ segmentation for mice using deep learning neural networks. Specific Aim 2 (SA2). Development of a fully functional, automated, and efficient IMRT system. Specific Aim 3 (SA3). Development and validation of a robotic Multi Mouse Automated Treatment Environment (Multi-MATE) for automated imaging and treatment. Besides dosimetry, we will quantify the time performance, which is critical to small animal IMRT system. As a result, in addition to improving the hardware accuracy and reliability, the proposed project will provide a fully automated planning and delivery system, thus removing the last barriers towards the broad adoption of small animal IMRT. The success of the proposed project will help existing research to achieve the full potential for human translation and enable future hypotheses testing where accurate complex dose distribution is critical. Project Narrative A major impediment in translating animal radiation studies to human patients is the disparity in radiation techniques. Existing methods cannot create human like conformal radiation dose on mice with necessary accuracy and efficiency. To better mimic human treatment without prohibitively complicated and slow procedures, we propose to develop a high throughput image guided small animal conformal irradiation platform.",Development of A High Throughput Image-Guided IMRT System for Preclinical Research,10317441,R01CA259008,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Anesthesia procedures', 'Animals', 'Automation', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collimator', 'Complex', 'Computer software', 'Conformal Radiotherapy', 'Development', 'Devices', 'Dose', 'Engineering', 'Environment', 'Future', 'Grant', 'Human', 'Image', 'Individual', 'Intensity-Modulated Radiotherapy', 'Intervention', 'Knowledge', 'Manuals', 'Mathematics', 'Methods', 'Mus', 'Organ', 'Patients', 'Performance', 'Procedures', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Radiobiology', 'Research', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Roentgen Rays', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Toxic effect', 'Training', 'Translating', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'base', 'biological research', 'deep learning', 'deep neural network', 'design', 'dosimetry', 'experimental study', 'image guided', 'improved', 'in silico', 'innovation', 'irradiation', 'miniaturize', 'novel', 'pre-clinical', 'pre-clinical research', 'process optimization', 'robotic system', 'safety testing', 'success', 'tool', 'treatment planning', 'trend', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,441662
"Accuracy and Precision in CT Quantification of COPD Through Virtual Imaging Trials Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of death. Increasing in prevalence, COPD is a major burden to patients and providers. Computed tomography (CT) can provide valuable information about the structural and functional abnormalities of the disease as demonstrated in numerous studies where quantitative CT is deployed to characterize and evaluate the treatment. For instance, the COPDGene study has recently shown the substantial role of quantitative CT in the redefinition of COPD diagnosis, and in evaluating the progression of emphysema over time. However, these biomarkers vary across different scanners, settings, and patient attributes. There is a crucial need to manage this variability by optimizing and harmonizing CT images for reliable biomarker quantifications across both current and emerging scanners. This goal is not possible through conventional methods of using physical phantoms or patient images. Physical phantoms are often oversimplified and not representative of the complex anatomy and physiology of COPD patients. Patient images are ground-truth-limited, i.e., the exact anatomy and physiology of the patient is not fully known. Further, patient-based comparisons require multiple acquisitions of the same subjects across different scanners and settings. This is not ethically possible since repeated imaging increases the absorbed radiation dose. These challenges can be overcome through the use of virtual imaging trials (VITs) where studies are performed in silico using computational models of patients and scanners. VITs can provide reliable and practical solution to the challenge of COPD imaging provided realistic models of patients and scanners. Such models are currently lacking in the context of COPD. We develop and then utilize realistic virtual imaging toolsets to systematically evaluate and optimize CT biomarkers in COPD patients across scanners, imaging parameters, and patient attributes. We develop the first library of realistic COPD patient models with diverse attributes and severities. Coupled with accurate models of different scanners, the phantoms will be used to generate sets of ground-truth-known virtual CT cases, to be disseminated to the research community and to be used to systematically evaluate the effects of current and emerging scanners, various patient attributes, and the effects of image processing algorithms (through a national challenge), on the accuracy and precision of COPD biomarkers. Further, we develop and optimize a truth-based artificial intelligence-based algorithm for COPD quantifications. We optimize the algorithm for accuracy and reproducibility, taking advantage of the ground-truth known simulated images . We then harmonize CT settings across different scanners to accurately and precisely assess COPD imaging biomarkers for both single time-point and longitudinal studies. The studies will be done for the top two image processing algorithms, identified in the challenge, as well as our developed algorithm. Through these efforts, the project will position CT as a more reliable method for improved characterization and monitoring of COPD. Narrative The project aims to systematically evaluate and optimize quantitative CT imaging biomarkers in Chronic Obstructive Pulmonary Disease (COPD) patients, across scanner makes and models, imaging parameters, and patient attributes. This will be performed by developing and using in silico models of COPD patients and CT scanners. The project will position CT alongside other diagnostic methods to accurately and precisely characterize COPD.",Accuracy and Precision in CT Quantification of COPD Through Virtual Imaging Trials,10298963,R01HL155293,"['Algorithms', 'Anatomy', 'Artificial Intelligence', 'Biological Markers', 'Cause of Death', 'Chronic Obstructive Airway Disease', 'Communities', 'Comparative Study', 'Complement', 'Complex', 'Computed Tomography Scanners', 'Computer Models', 'Coupled', 'Data', 'Data Set', 'Densitometry', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease model', 'Effectiveness', 'Environmental Risk Factor', 'Evaluation', 'Exposure to', 'Goals', 'Image', 'Interstitial Lung Diseases', 'Libraries', 'Longitudinal Studies', 'Lung', 'Lung diseases', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Patient imaging', 'Patients', 'Photons', 'Physiology', 'Positioning Attribute', 'Prevalence', 'Protocols documentation', 'Provider', 'Pulmonary Emphysema', 'Radiation exposure', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Role', 'Severities', 'Severity of illness', 'Smoking', 'Spirometry', 'Structure', 'Symptoms', 'System', 'Technology', 'Time', 'Tube', 'Variant', 'X-Ray Computed Tomography', 'base', 'cohort', 'disease diagnosis', 'human model', 'image processing', 'imaging biomarker', 'improved', 'in silico', 'in vivo', 'insight', 'intelligent algorithm', 'quantitative imaging', 'radiation absorbed dose', 'reconstruction', 'tool', 'virtual', 'virtual imaging', 'virtual patient', 'voltage']",NHLBI,DUKE UNIVERSITY,R01,2021,447232
"AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution Abstract. Whole-organ 3D immunohistochemistry is revolutionizing the field of neuroscience, enabling unprecedented insight into the distribution of neural cells and neurological markers throughout the brain in health and disease. LifeCanvas Technologies is at the forefront of the new field of spatial proteomics, providing a complete workflow for whole-organ preservation, tissue clearing, immunohistochemical labeling, and imaging. Nevertheless, an ongoing challenge for such studies is the need to rapidly, reproducibly and rigorously quantify terabyte-sized datasets from whole-organ imaging efforts. While progress has been made in applying Artificial Intelligence (AI) tools to enable detection of cellular and sub-cellular markers in neural tissue, one-size-fits-all algorithms are inadequate for analyzing complex, information-rich brain datasets due to varying biomolecular expression patterns (e.g. nuclear, cytoplasmic, membrane-bound) and region-specific heterogeneities in cell density and neural cell types. However, AI-driven algorithms targeting a subset of labeling patterns can be effective provided the availability of adequate training data. LifeCanvas Technologies LCT is optimally positioned to develop highly accurate algorithms serving a wide range of detection tasks through its access to high volumes of whole-organ image data containing a variety of label expression patterns via its Contract Research Organization and user base. LCT proposes to develop a data analysis program, SmartAnalytics, which will embed a suite of AI algorithms within a user-friendly software package to identify labeled cell locations and characterize morphological features across the whole brain at cellular and sub-cellular resolution. Specifically, LCT will use intact, 3D immunolabeled mouse brains to design AI algorithms to detect labeled cells imaged at cellular resolution and generate further algorithms for the segmentation of labeled features imaged at sub-micron resolution. Data from LCT’s Contract Research Organization and academic collaborations will be continually fed back to improve and expand the library of detection algorithms available within SmartAnalytics, and these developments will drive further customer adoption and enhancement of future versions of the software. SmartAnalytics will guide users through model application, quality-control testing, and the generation of output products such as figures and summary statistics. In summary, SmartAnalytics will be an evolving and user- friendly workflow execution program that enables neuroscientists to take full advantage of their 3D image data, driving new discoveries in brain function, development and disease. Narrative. The ability to readily and accurately quantify proteomic expression patterns that define neural cell- type specific distributions and morphologies across intact brains will enable unprecedented and unbiased insights into studies of brain function. LifeCanvas Technologies’ state-of-the-art tissue processing pipeline provides uniform clearing, labeling, and imaging of whole brains at cellular and sub-cellular resolution. By developing Artificial Intelligence algorithms to detect labeled cells and determine morphologies and by packaging these algorithms in a user-friendly software ‘SmartAnalytics’, LifeCanvas will enable neuroscientists to quantify image data and derive critical results towards a more complete understanding of brain function in development, health and disease.",AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution,10139966,R43MH125512,"['3-Dimensional', 'Adoption', 'Algorithms', 'Amyloid beta-Protein', 'Antibodies', 'Artificial Intelligence', 'Astrocytes', 'Automobile Driving', 'Back', 'Binding Proteins', 'Biological Markers', 'Brain', 'Brain imaging', 'Cell Density', 'Cell membrane', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cytoplasm', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Feedback', 'Future', 'Generations', 'Glial Fibrillary Acidic Protein', 'Health', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunohistochemistry', 'Individual', 'Institutes', 'Label', 'Libraries', 'Location', 'Maps', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neurologic', 'Neurons', 'Neurosciences', 'Nuclear', 'Organ', 'Organ Preservation', 'Output', 'Pattern', 'Positioning Attribute', 'Process', 'Proteins', 'Proteomics', 'Quality Control', 'Research Contracts', 'Resolution', 'Rosaniline Dyes', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissue imaging', 'Tissues', 'Training', 'algorithm development', 'base', 'biomarker-driven', 'cell type', 'cellular imaging', 'computerized data processing', 'cost', 'design', 'extracellular', 'improved', 'insight', 'intelligent algorithm', 'neuronal cell body', 'new technology', 'programs', 'relating to nervous system', 'segmentation algorithm', 'software development', 'statistics', 'submicron', 'terabyte', 'tissue processing', 'tool', 'user friendly software', 'user-friendly']",NIMH,"LIFECANVAS TECHNOLOGIES, INC.",R43,2021,226754
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10143312,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2021,499966
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,10066353,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2021,373738
"Development of advanced cardiac SPECT imaging technologies Project Abstract Single Photon Emission Computed Tomography (SPECT) continues to play a critical role in the diagnosis and management of coronary artery disease (CAD). While conventional SPECT scanners using parallel-hole collimators are still the foundation of cardiac SPECT, recently our field observed an exciting growth of new developments of dedicated cardiac scanners. Such dedicated scanners, such as the GE Alcyone 530/570c systems and the D-SPECT systems both with CZT detectors, typically have multiple detectors collecting photons emitted from the heart simultaneously, leading to dramatically improved sensitivity (2-5 X). In addition, the GE systems use pinhole collimators and can achieve much higher resolution. These dedicated scanners opened doors to new applications with significant clinical impact, including ultra-low-dose imaging, absolute quantification of myocardial blood flow (MBF) and coronary flow reserve (CFR), high resolution molecular imaging, multi-isotope imaging, motion correction, and many more. Most of these new applications are uniquely achievable only using dedicated scanners. While the dedicated cardiac SPECT systems can improve clinical practice and lead to numerous new clinical applications, such systems are far from being optimized to fully realize their great potentials. In this grant, we propose to systematically develop and optimize innovative imaging technologies for the GE 530/570c systems to further improve its clinical efficacy in a variety of significant ways. In Aim 1, we will develop and optimize methods for static cardiac SPECT imaging. We will develop various deep learning methods and investigate approaches to increase angular sampling to reduce noise, and improve resolution and quantitative accuracy. In Aim 2, we will develop and validate methods for dynamic SPECT imaging, particularly involving direct parametric image reconstruction. In Aim 3, we will develop and validate methods for dual-isotope SPECT. Monte Carso simulation and deep learning based methods will be developed for tracers with different spatial distributions and fast kinetics. In all three aims, large animal studies and human subject data will be used for optimization and validation. Narrative The success of imaging technology developments proposed in this grant will substantially improve the image quality, reduce patient dose, expand the applications of cardiac SPECT from mainly static imaging to dynamic imaging, and establish multi-isotope clinical imaging.",Development of advanced cardiac SPECT imaging technologies,10221049,R01HL154345,"['Address', 'Advanced Development', 'Algorithms', 'Amyloidosis', 'Anatomy', 'Animals', 'Blood flow', 'Cardiac', 'Charge', 'Clinical', 'Collimator', 'Computed Tomography Scanners', 'Coronary', 'Coronary Arteriosclerosis', 'DCNU', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dose', 'Event', 'Foundations', 'Gold', 'Grant', 'Heart', 'Human', 'Hybrids', 'Image', 'Imaging technology', 'Infarction', 'Isotopes', 'Kidney', 'Kinetics', 'Lead', 'Maps', 'Methods', 'Microspheres', 'Molecular Target', 'Monte Carlo Method', 'Motion', 'Myocardial', 'Myopathy', 'Noise', 'Patients', 'Perfusion', 'Photons', 'Play', 'Positioning Attribute', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Resolution', 'Role', 'Sampling', 'Spatial Distribution', 'Study Subject', 'System', 'Tail', 'Toxic effect', 'Tracer', 'Training', 'Validation', 'animal data', 'attenuation', 'base', 'cardiac single photon emission computed tomography', 'clinical application', 'clinical efficacy', 'clinical imaging', 'clinical practice', 'contrast enhanced', 'convolutional neural network', 'deep learning', 'detector', 'efficacy evaluation', 'human subject', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'new growth', 'parametric imaging', 'prospective', 'reconstruction', 'respiratory', 'simulation', 'single photon emission computed tomography', 'success', 'technology development']",NHLBI,YALE UNIVERSITY,R01,2021,805251
"A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC) Project Summary/Abstract: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will include datasets produced locally at Washington University: The Connectome Coordination Facility (CCF) (which itself includes the Human Connectome Project (HCP) Young Adult study, The Lifespan related projects, the Disease related projects, and assorted HCP-related projects), The Knight Alzheimer Disease Research Center (ADRC), the Adolescent Brain Cognitive Development (ABCD) Study, The Comprehensive Neuro-Oncology Data Repository (CONDR), and the clinically-based PACS image repository. In addition, copies of external data collections such as the UK Biobank, The Alzheimer's Disease Neuroimaging Initiative (ADNI), and The Cancer Image Archive (TCIA) will be maintained. The RIR includes a data management software solution that will introduce many novel features (such as `data tagging' to enrich datasets, and advanced search features) and will allow us to leverage existing storage including the Center for High Performance Computing's (CHPC) 1.4PB of BeeGFS `scratch' storage, solid-state NVMe drives integrated into the compute nodes, and 10PB of ZFS-based storage. All storage will be presented to the user as a single file-system, while data will be migrated to different performance tiers based on the storage requirements of the datasets or processing algorithms. The RIR will be integrated into the CHPC for data processing. The proposal also includes two NVIDIA DGX A100 GPU servers providing state-of-the-art GPU- based processing power. The combination of high-quality, diverse sets of biomedical imaging data with next- generation computing power will have a transformative effect on biomedical imaging processing pipelines and nowhere will the effects be more profound than in the emerging field of Deep Learning for image processing. Project Narrative: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will be integrated into Washington University in St. Louis's Center for High Performance Computing (CHPC) to process the data and will leverage over 11PB of existing storage.",A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC),10177147,S10OD030477,"['Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Clinical', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Disease', 'High Performance Computing', 'Human', 'Longevity', 'Performance', 'Research', 'System', 'The Cancer Imaging Archive', 'Universities', 'Washington', 'base', 'biobank', 'bioimaging', 'cognitive development', 'computerized data processing', 'connectome', 'data management', 'data repository', 'deep field survey', 'deep learning', 'image archival system', 'image processing', 'neuro-oncology', 'neuroimaging', 'next generation', 'novel', 'solid state', 'young adult']",OD,WASHINGTON UNIVERSITY,S10,2021,1927344
"Imaging and Analysis Techniques to Construct a Cell Census Atlas of the Human Brain Admin Supplement Abstract The ~86 billion neurons that form the human brain are organized at multiple scales, ranging from the fine details of an individual neuron’s dendritic arborization, to local circuits that are embedded within large-scale systems spanning the brain. In this project, we will image across this vast range of scales to create a multiscale atlas akin to Google Earth for the human brain that can visualize hemisphere-wide networks and then zoom in to see individual, labeled cells at micron resolution in the frontal temporal lobe. This dramatic advance will be made possible through the use of an array of imaging technologies, including light-sheet microscopy (LSM), tissue clearing, immunohistochemistry (IMH), magnetic resonance imaging (MRI) and newly developed techniques in Optical Coherence Tomography (OCT). OCT in particular is a potentially transformative technology as it provides micron resolution over large volumes of tissue, images all of the tissue (as opposed to fluorescence), does not require mounting and staining and hence can be automated, and is essentially distortion free as it images the tissue prior to cutting. LSM-based IMH will provide molecular, morphological and spatial properties of cells that will enable us to develop cellular classification systems, while OCT images of the same tissue will enable us to remove the distortions induced by cutting and clearing, and transfer information to whole-hemisphere MRI for atlasing and in vivo inference. This transfer of information depends critically on the ability to register images across a huge range of resolutions and contrast types. For this we propose to use the endogenous fiducial landmarks provided by the cerebral vasculature. To take full advantage of the vasculature using deep learning requires a training set of labeled vessels in each of our imaging modalities across an array of examples. The goal of this supplement is to provide these labelings including the assessment of intra- and inter-rater reliability. Relevance Automated segmentation of neurons, glia, cortical areas and laminar boundaries will enable new and more specific types of analyses of neuroimaging data. In particular, the ability to probe cellular and laminar properties of specific cortical areas may provide significant advances in developmental disorders such as Alzheimer’s, autism, schizophrenia and dyslexia. To facilitate these advances we propose to label cerebral vessels, then use the manual labeling to develop a deep learning-based technique to register images from microscopy to whole-hemisphere MRI.",Imaging and Analysis Techniques to Construct a Cell Census Atlas of the Human Brain Admin Supplement,10307352,U01MH117023,"['Alzheimer&apos', 's Disease', 'Area', 'Atlases', 'Brain', 'Cells', 'Censuses', 'Cerebrovascular system', 'Cerebrum', 'Classification', 'Data', 'Dyslexia', 'Fluorescence', 'Goals', 'Human', 'Image', 'Imaging technology', 'Immunohistochemistry', 'Individual', 'Label', 'Light', 'Magnetic Resonance Imaging', 'Manuals', 'Microscopy', 'Molecular', 'Morphology', 'Neuroglia', 'Neurons', 'Optical Coherence Tomography', 'Planet Earth', 'Property', 'Resolution', 'Schizophrenia', 'Stains', 'System', 'Techniques', 'Technology', 'Temporal Lobe', 'Tissue imaging', 'Tissues', 'Training', 'autism spectrum disorder', 'automated segmentation', 'base', 'deep learning', 'developmental disease', 'imaging modality', 'in vivo', 'microscopic imaging', 'neuroimaging']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,U01,2021,99916
