text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,10160864,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,335661
"A holistic approach to identifying functional units of tongue motion during speech PROJECT SUMMARY  Oral cancers have the seventh highest incidence, with roughly 51,540 new cases and 10,030 cancer- related deaths expected to occur in 2018. Although a variety of treatment methods are available, the death rate is higher than that for most cancers with five-year rates of about 50 percent. The most frequently used treatment method, glossectomy surgery, involves the surgical removal of tumors and surrounding tissues, and the addition of grafted tissues, often followed by radiotherapy. Although tongue cancer and its treatment have debilitating effects on speech, the impact of varying degrees of resection and reconstruction on the formation of functional units in speech has remained poorly understood. In order to produce intelligible speech, a variety of local muscle groupings of the tongue—i.e., functional units—emerge and recede rapidly and nimbly in a highly coordinated fashion. Therefore, understanding the formation of functional units that are critical for speech production can provide substantial insights into normal, pathological, and adapted motor control strategies in controls and patients with tongue cancer for novel therapeutic, surgical, and rehabilitative strategies. One of the critical challenges in pre-operative surgical and treatment planning, as well as in post- operative evaluation for tongue cancer is the difficulty in developing objective and quantitative measures and in evaluating their functional outcome predictability. To address this, in this proposal, three integrated approaches will be used in in vivo tongue motion during speech to seamlessly identify the functional units and associated quantitative measures: multimodal MRI methods, multimodal deep learning, and biomechanical simulations. This will provide a convergent approach, thereby allowing us to (1) test hypotheses about the spatiotemporal basis of muscle coordination in a consilient way, and (2) develop objective quantitative measures that are required for understanding the complex biomechanical system as well as for predicting the functional outcomes after various reconstruction methods. The first proof of concept study published by the PI and the team identified the functional units of speech tasks using the sparse non-negative matrix factorization framework, in which the magnitude and angle of displacements from tagged MRI were used as our input quantities. With these advances in place, we will further incorporate muscle fiber anatomy from diffusion MRI and motion tracking from tagged MRI into our framework to yield physiologically and anatomically meaningful functional units. In addition, we will create a completely novel and integrated way of directly relating the functional units to tongue muscle anatomy, learning joint representation via a multimodal deep learning technique, and linking them to biomechanical simulations. Furthermore, 3D and 4D atlases will be utilized to identify objective and quantitative measures based on our functional units analysis. Taken together, the successful implementation of our integrated framework will identify functional units that can be used for research on tongue motion, for surgical planning, and for diagnosis, prognosis, and rehabilitation in a range of speech-related disorders. PROJECT NARRATIVE  Tongue cancer and its treatment affect tongue structure and function, yet little is known about how the changes in tongue structure due to varying degrees of resection and reconstruction affect the formation of functional units of tongue motion during speech. We propose to use novel integrated platform tools to identify functional units seamlessly with unprecedented resolution and precision. Upon success of this proposal, our integrated framework has the potential to aid in an increased understanding of speech motor control strategies in healthy controls and the patient group, thereby benefiting patients through improved diagnosis, treatment, and rehabilitative strategies.",A holistic approach to identifying functional units of tongue motion during speech,10147030,R01DC018511,"['3-Dimensional', 'Acoustics', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Atlases', 'Behavior', 'Biomechanics', 'Cessation of life', 'Clinical', 'Complex', 'Computing Methodologies', 'Data', 'Death Rate', 'Deglutition', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Evaluation', 'Excision', 'Exhibits', 'Fiber', 'Geometry', 'Glossectomy', 'Goals', 'Grouping', 'Impairment', 'Incidence', 'Joints', 'Knowledge', 'Learning', 'Link', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Muscle', 'Muscle Fibers', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Physiological', 'Postoperative Period', 'Predictive Value', 'Procedures', 'Production', 'Proxy', 'Publishing', 'Radiation therapy', 'Rehabilitation therapy', 'Research', 'Resolution', 'Speech', 'Speech Intelligibility', 'Standardization', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Tissue Grafts', 'Tissues', 'Tongue', 'Weight', 'Work', 'base', 'biomechanical model', 'clinical practice', 'deep learning', 'functional outcomes', 'holistic approach', 'improved', 'in vivo', 'insight', 'malignant mouth neoplasm', 'malignant tongue neoplasm', 'motor control', 'multimodality', 'muscular structure', 'novel', 'novel therapeutics', 'outcome forecast', 'outcome prediction', 'reconstruction', 'rehabilitation strategy', 'signal processing', 'spatiotemporal', 'success', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,565453
"Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders Abstract: Early and accurate diagnosis of neurocognitive disorders (NCDs) is critical for planning, treatment, and research referral, but demands time and expertise often unavailable to primary care providers. Speech and language are often impaired early in the disease course of several NCDs. Previous research has demonstrated the diagnostic potential of computer speech analysis (CSA), with differences between healthy controls and disorders such as mild cognitive impairment (MCI) and Alzheimer's disease. However, there are several additional steps that must be taken to make CSA a diagnostically viable screening tool. This proposal includes a career development plan providing the applicant with training, mentorship, and experience in the following areas in order to bring CSA techniques into clinical practice: 1) computational linguistics and paralinguistics, 2) longitudinal markers of disease, and 3) design of novel technology for dissemination. As part of this training, academic and professional skills, including ethics in research, will also be expanded. Uniquely qualified mentorship and advisory teams have been selected to ensure the success of the proposed training and research. The proposed study is a prospective, longitudinal, observational, cohort investigation of two distinct research groups. The first group is a highly selected and well-characterized research cohort of healthy control, Alzheimer's disease, and MCI subjects (Group A). In Group A, the performance and reproducibility of a machine learning algorithm will be improved to distinguish Alzheimer's disease and MCI from healthy controls using CSA. Multiple regression and voxel-based morphometry will be used to better understand what may drive group differences in CSA measures in Group A as well. Clinical applications of this algorithm will then be assessed in a clinic-based cohort of patients with different NCDs (Group B) in order reduce spectrum bias likely present in prior studies. As sub-aims in both groups, possible further improvement of the algorithmic outcomes with longitudinal CSA measures will also be examined. The overall objective is to develop intuitive, reliable and reproducible CSA-based clinical measures by correlating them with established neuropsychiatric and imaging markers, determining their efficacy in clinical populations, and determining how they change over time. As a result, this research will validate specific speech traits as useful diagnostic markers of neurocognitive disease and explain why those markers differ between patient groups, both of which are major steps towards the design of novel and easily implemented tools in the screening of NCDs such as Alzheimer's disease. PROJECT NARRATIVE Computational speech analysis (CSA) has shown promise as a cost-effective, rapid screening for patients with neurocognitive disorders (NCDs) by objectively and automatically quantifying speech and language use; however, critical steps must be taken before these measures can become clinically useful. I have training and experience in the neurology of speech and language, but require additional training in computational linguistics and paralinguistics, longitudinal markers of disease including neuroimaging and neuropsychological measures, and design of novel technology for dissemination in order to bring CSA into clinical practice. In this project, we propose to investigate the utility of using CSA measures in two distinct patient groups, including a highly characterized group of research participants that includes healthy controls, Alzheimer's disease patients, and mild cognitive impairment patients (Group A), and a group of consented clinic patients with different NCDs (Group B) and to follow these two groups in prospective, longitudinal studies to correlate spontaneous speech measures with standardized linguistic, neuropsychological, and biological measures.",Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders,10145566,K23AG063900,"['Accent', 'Address', 'Adult', 'Advisory Committees', 'Algorithms', 'Alzheimer disease screening', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Alzheimer&apos', 's disease pathology', 'Alzheimer&apos', 's disease patient', 'Area', 'Biological', 'Brain', 'Caregivers', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Communities', 'Computational Linguistics', 'Computers', 'Consent', 'Cross-Sectional Studies', 'Dementia', 'Dementia with Lewy Bodies', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Disease', 'Disease Marker', 'Early Diagnosis', 'Effectiveness', 'Enrollment', 'Ensure', 'Ethics', 'Evaluation', 'Fostering', 'Frontotemporal Dementia', 'Goals', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Intuition', 'Investigation', 'Knowledge', 'Language', 'Language Tests', 'Lead', 'Linguistics', 'Liquid substance', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Mentorship', 'Neurocognitive', 'Neurology', 'Neuropsychological Tests', 'Neuropsychology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Population', 'Positioning Attribute', 'Preparation', 'Prevalence', 'Primary Health Care', 'Quality of life', 'Rapid screening', 'Reproducibility', 'Research', 'Screening procedure', 'Speech', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'accurate diagnosis', 'aging population', 'base', 'care providers', 'career development', 'clinical application', 'clinical practice', 'cohort', 'cost effective', 'design', 'diagnostic biomarker', 'experience', 'healthy aging', 'imaging biomarker', 'improved', 'machine learning algorithm', 'mild cognitive impairment', 'morphometry', 'neurocognitive disorder', 'neuroimaging', 'neuropsychiatry', 'new technology', 'novel', 'novel diagnostics', 'novel therapeutics', 'patient screening', 'primary outcome', 'prospective', 'recruit', 'screening', 'skills', 'success', 'technology development', 'tool', 'trait']",NIA,UNIVERSITY OF COLORADO DENVER,K23,2021,188298
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,10134315,K01DC017751,"['Acoustics', 'Address', 'Age', 'Area', 'Auditory', 'Behavior', 'Biomechanics', 'Categories', 'Characteristics', 'Clinical', 'Communication', 'Coupling', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dysphonia', 'Endoscopes', 'Evaluation', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Knowledge', 'Larynx', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mining', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paralysed', 'Patients', 'Physics', 'Physiological', 'Prevention', 'Production', 'Protocols documentation', 'Research', 'Series', 'Severities', 'Source', 'Spastic Dysphonias', 'Speech', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tremor', 'Visual', 'Voice', 'Voice Disorders', 'Voice Disturbances', 'Voice Quality', 'base', 'clinical application', 'clinical development', 'clinical practice', 'clinically relevant', 'cohort', 'flexibility', 'image processing', 'imaging approach', 'improved', 'innovation', 'kinematics', 'sex', 'temporal measurement', 'time use', 'tool', 'treatment strategy', 'vibration', 'vocal cord', 'vocalization']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2021,137795
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,10194459,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2021,39939
"The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment PROJECT SUMMARY  Primary language impairment (PLI) begins early in life and affects 6-8% of children. Language intervention is maximally effective the earlier it is delivered. However, normative variation in language acquisition across toddlerhood (here, 24-36 months) contributes to a high rate of false positives, impeding accurate identification of PLI prior to late preschool age. The proposed study introduces a novel, theoretically- grounded, neurodevelopmental framework designed to generate a sensitive and specific model of toddler PLI risk. Innovations introduced in this developmentally-sensitive, translational approach include: (1) a developmental precursor model using state-of-the-art methods to characterize multiple features and growth patterns of toddler emergent language patterns, within a large community sample; (2) incorporating EEG/ERP neural biomarkers of language and transactional synchrony into PLI predictive models; and (3) considering emergent mental health risk. Mental health risk is captured via multi-method measures of irritability, a developmentally meaningful marker of risk for internalizing and externalizing problems that are common correlates of PLI. The proposed When to Worry about Language Study (W2W-L) will capitalize on the team's existed funded study of 350 infants (50% irritable and 50% non irritable) (R01MH107652, Wakschlag, PI) and enrich it via recruitment of a new sub-sample of 200 late talking toddlers. This will yield a large and diverse sample of 550 24 month olds, followed to age 54 months (when PLI can be reliably evaluated). The key predictor will be toddler emergent language patterns measured via language skill, language processing, and corollary neural biomarkers. The central outcome is primary language impairment (PLI) status at preschool age, assessed via clinical gold standard measures. Key risk modifiers are distal and proximal features of the transactional language environment, and longitudinal patterns of irritability.  SPECIFIC AIMS: Aim 1. Specify the contribution of language skills, processing, neural biomarkers, and their growth to early PLI prediction. Hypotheses: 1a. Language skills, processing, and neural biomarkers will each contribute incrementally to PLI prediction. 1b. Considering longitudinal patterns will enhance prediction. Aim 2. Identify the distal risk- and proximal protective- features of the transactional language environment that provide greatest explanatory power for individual differences in PLI. Hypothesis 2: Family history and poor parental language ability will increase PLI risk, and features of parental input, and behavioral and neural synchrony will decrease PLI risk. Aim 3. Examine the mutual influences of toddler irritability, proximal language environment, and emergent language patterns on PLI pathways. Hypothesis 3: A model specifying these reciprocal influences over time will sharpen PLI prediction beyond variance explained by their individual influences. Aim 4. Evaluate feasibility of a clinical algorithm for earlier PLI risk identification. We will use machine learning approaches to generate a sensitive/specific, feasible clinical model building on Aims 1-3. PROJECT NARRATIVE Primary language impairment (PLI) emerges early and is responsive to intervention; however, identification in toddlers is not currently possible because of the high rate of false positives reflecting transient language delays. We use a novel, theoretically-grounded, neurodevelopmental approach to generate earlier, more accurate identification of toddler risk for persistent PLI via: (a) multi-faceted, longitudinal assessment of toddler emergent language patterns; (b) detailed consideration of the transactional language environment; and (c) accounting for emergent health risk in predictive models. Earlier, reliable identification of toddlers at highest risk for PLI will optimize early intervention to prevent developmentally- cascading effects.",The When to Worry about Language Study (W2W-L): Joint consideration of developmental patterning and neural substrates for enhancing earlyidentification of language impairment,10105196,R01DC016273,"['Accounting', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Behavioral', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Child Behavior', 'Classification', 'Clinical', 'Communities', 'Development', 'Distal', 'Early Intervention', 'Education', 'Electroencephalography', 'Environment', 'Family', 'Family history of', 'Funding', 'Goals', 'Gold', 'Growth', 'Health', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Infant', 'Infrastructure', 'Intervention', 'Joints', 'Language', 'Language Delays', 'Language Development', 'Language Disorders', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methods', 'Modeling', 'Neuronal Plasticity', 'Nursery Schools', 'Outcome', 'Parents', 'Pathway interactions', 'Pattern', 'Productivity', 'Public Health', 'Recording of previous events', 'Resources', 'Risk', 'Risk Marker', 'Role', 'Sampling', 'Shapes', 'Specific qualifier value', 'Standardization', 'Syndrome', 'Time', 'Toddler', 'Variant', 'Vocabulary', 'Work', 'base', 'brain behavior', 'cohort', 'design', 'experience', 'high risk', 'improved', 'individual variation', 'innovation', 'language impairment', 'language processing', 'model building', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'recruit', 'relating to nervous system', 'skills', 'social', 'standard measure', 'translational approach', 'visual tracking']",NIDCD,NORTHWESTERN UNIVERSITY,R01,2021,653332
Computational neuroscience of language processing in the human brain  ,Computational neuroscience of language processing in the human brain,10199330,U01NS121471,"['Address', 'Architecture', 'Area', 'Brain', 'Charge', 'Code', 'Cognition', 'Complement', 'Complex', 'Computer Models', 'Data', 'Data Set', 'Disease', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Hand', 'Human', 'Influentials', 'Investigation', 'Language', 'Language Development', 'Left', 'Lesion', 'Linguistics', 'Machine Learning', 'Modeling', 'Neural Network Simulation', 'Noise', 'Patients', 'Performance', 'Population', 'Psycholinguistics', 'Research', 'Sampling', 'Science', 'Semantics', 'Stimulus', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Variant', 'Word Processing', 'Work', 'artificial neural network', 'computational neuroscience', 'design', 'human data', 'human model', 'language impairment', 'language processing', 'lens', 'lexical', 'network models', 'neural network', 'neuroimaging', 'phrases', 'relating to nervous system', 'response', 'semantic processing', 'syntax']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2021,662552
"Speech markers of cognitive impairment in Parkinson's disease ABSTRACT Dr. Kara Smith is a Movement Disorders neurologist at the University of Massachusetts Medical School (UMMS) whose goal is to become an independent investigator focused on early cognitive impairment in Parkinson disease (PD). Her long-term goal is to develop speech markers of cognitive impairment in PD. Cognitive impairment occurs in the majority of PD patients, leading to increased mortality and decreased quality of life. The current diagnostic tools are resource-intensive and have limited sensitivity. Treatments are often offered late in the course of cognitive decline and do not provide optimal benefit. Speech markers could improve detection, monitoring and treatment of cognitive impairment in PD. Speech markers could be monitored frequently and remotely via mobile technology, capturing sensitive, quantitative data about cognitive function in the context of patients’ daily life and in response to therapeutics. Dr. Smith’s role as a clinical movement disorders specialist ideally positions her to lead the application of advanced speech and language research to feasible, patient-oriented tools for real-life clinical practice and clinical trials. Dr. Smith has assembled an expert interdisciplinary mentorship team ideally suited for the goals of this innovative proposal. Dr. Smith and her team have previously shown that a) speech acoustic markers are associated with cognitive function in non-demented PD patients, and b) PD patients with mild cognitive impairment had linguistic deficits including pauses within utterances and grammaticality. Building on these results, Dr. Smith proposes to study speech and language more comprehensively in PD patients with and without mild cognitive impairment and controls to confirm these preliminary results and identify additional biomarkers. The aims of this study will be 1) to develop algorithms using speech acoustic markers to categorize by cognitive status, 2) to identify linguistic markers associated with mild cognitive impairment in PD, and 3) to assess on-line syntactic processing in PD subjects with mild cognitive impairment. The overall goal of the proposal is to identify speech and language markers of early cognitive dysfunction that can be further refined, validated and implemented using mobile technology into a larger scale, longitudinal R01 proposal. Further work will also address the underlying neurobiological mechanisms of these speech markers. Dr. Smith’s rigorous training plan includes a Master’s degree, linguistics and speech motor physiology courses, and experience in signal processing and speech acoustic analysis. Through her training goals, she will advance her knowledge and skills in patient-centered outcomes measures and instrument validation. She will gain experience in research leadership, presentation and dissemination of scientific work, and in grant writing, culminating in an R01 proposal. This K23 award will be critical for Dr. Smith to establish an independent career as a PD clinician-scientist at the unique intersection of speech and language science and cognitive impairment. PUBLIC HEALTH RELEVANCE: Speech markers have the potential to improve diagnosis, monitoring and treatment of cognitive impairment in Parkinson’s disease (PD). Although the majority of PD patients will develop cognitive impairment, the tools available to assess and treat this disabling complication are fraught with limitations. As a detailed and quantitative assessment tool, speech markers may increase sensitivity to early cognitive dysfunction and to changes over time compared with current measures. They may be automated and then implemented through mobile technology to increase patients’ access to cognitive symptom monitoring outside of the clinic setting. Dr. Smith’s proposed career development plan has potential to fill a major gap in PD research by making inexpensive and easy-to-use cognitive assessment tools accessible to patients in rural and international settings, and by fueling clinical trials to discover new therapeutics capable of slowing cognitive decline in PD.",Speech markers of cognitive impairment in Parkinson's disease,10115019,K23DC016656,"['Acoustics', 'Address', 'Algorithms', 'American', 'Area', 'Articulation', 'Assessment tool', 'Award', 'Biological Markers', 'Biomedical Engineering', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Cognitive Therapy', 'Cognitive deficits', 'Complication', 'Comprehension', 'Data', 'Data Analyses', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Foundations', 'Future', 'Goals', 'Grant', 'Health Services Accessibility', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Knowledge', 'Language', 'Language Disorders', 'Lead', 'Leadership', 'Life', 'Linguistics', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Massachusetts', 'Master&apos', 's Degree', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurobiology', 'Neurologist', 'Neuropsychological Tests', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Participant', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiology', 'Population', 'Positioning Attribute', 'Production', 'Proxy', 'Quality of Care', 'Quality of life', 'Research', 'Research Personnel', 'Resources', 'Role', 'Rural', 'Science', 'Scientist', 'Severities', 'Specialist', 'Speech', 'Speech Acoustics', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'Writing', 'career', 'career development', 'clinical movement disorder', 'clinical practice', 'cognitive change', 'cognitive control', 'cognitive function', 'cognitive impairment in Parkinson&apos', 's', 'cognitive performance', 'cognitive testing', 'common symptom', 'experience', 'handheld mobile device', 'improved', 'innovation', 'instrument', 'language processing', 'large scale data', 'lexical retrieval', 'machine learning method', 'medical schools', 'mild cognitive impairment', 'mobile computing', 'mortality', 'motor deficit', 'neurobiological mechanism', 'non-demented', 'novel', 'novel therapeutics', 'patient oriented', 'public health relevance', 'recruit', 'response', 'screening', 'signal processing', 'skills', 'syntax', 'tool']",NIDCD,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K23,2021,189216
"International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL) Project Abstract This proposal requests support to convene the next three International Conferences on Advances in Quantitative Laryngology, Voice and Speech Research (AQL). During the 5 years of requested support, the 14th, 15th, and 16th AQL (2021, 2023, and 2025 respectively) will be assembled. The 14th AQL will be held in Bogota, Colombia, South America, June 9 and 10, 2021 (pre-conference workshops June 7 and 8), the 15th will be in Phoenix, AZ, USA, in April 2023, while location of the 16th AQL conference will be determined during the 2021 conference (potential locations in South Korea or Germany). AQL is a valuable scientific meeting in the field of voice research and is regarded by voice and speech science specialists as a high quality international scientific meeting. AQL fosters the exchange of theoretical, experimental, and methodological advances, thereby progressing the translational and clinical aspects of voice and speech science. This multidisciplinary conference brings together scientists, clinicians, and students from around the world in various disciplines including Engineering, Biology, Physics, Otolaryngology and Speech Pathology. This proposal will allow for conference development and continuity to ensure an equitable conference that maintains its cutting-edge focus and provide support for students and early career investigators. The continuity of support will also ensure metrics and evaluations from previous conferences to be used to guide future AQL planning. The goals of this proposal are: to promote and support the education and development of young and underrepresented investigators in the voice and speech research community, organize special sessions on emerging research areas specific to quantitative laryngology, voice and speech research, to develop and foster digital networking strategies to provide a more inclusive and equitable conference, and to establish a Steering Committee. NIH funds are requested to provide support for child/family care, conference support for students and keynote speakers, students to assist Chair/Co-Chairs with various logistic needs, before, during and after the AQL conferences, website design and management, and streaming support during the meeting. In the off- conference years, necessary activities will include: student research trainee support, maintaining AQL website, Steering Committee meetings for conference evaluation and planning. Project Narrative This proposal seeks funding for the upcoming 14th, 15th, and 16th International Conference on Advances in Quantitative Laryngology, Voice and Speech Research (AQL) and the associated workshops and pre- conference, taking place in 2021, 2023, and 2025. AQL is an important international scientific meeting specialized in translational research and methods for measurement and modeling of voice and speech. Special emphasis will be given to promoting young investigators and underrepresented populations, digital networks to support a more inclusive and equitable conference, and to develop a permanent AQL website to help disseminate AQL information.","International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL)",10237766,R13DC019564,"['Area', 'Award', 'Biology', 'COVID-19 pandemic', 'Carbon', 'Caring', 'Child', 'Child Support', 'Clinical', 'Collection', 'Colombia', 'Communities', 'Development', 'Disabled Persons', 'Discipline', 'Education', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Family', 'Fees', 'Fostering', 'Funding', 'Future', 'Germany', 'Goals', 'Health', 'International', 'Leadership', 'Location', 'Logistics', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Occupations', 'Online Systems', 'Otolaryngology', 'Persons', 'Physics', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Science', 'Scientist', 'South America', 'South Korea', 'Specialist', 'Speech', 'Speech Pathology', 'Stream', 'Students', 'Translational Research', 'Travel', 'Underrepresented Populations', 'United States National Institutes of Health', 'Update', 'Voice', 'Woman', 'career', 'cost', 'design', 'digital', 'ethnic minority population', 'expectation', 'improved', 'interest', 'meeting abstracts', 'meetings', 'member', 'minority student', 'multidisciplinary', 'outreach', 'posters', 'preservation', 'programs', 'racial and ethnic', 'recruit', 'social', 'symposium', 'virtual', 'web site']",NIDCD,MAYO CLINIC ARIZONA,R13,2021,40000
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,10087511,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Models', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'machine learning algorithm', 'nervous system disorder', 'novel', 'optimal treatments', 'outcome prediction', 'phrases', 'predictive modeling', 'recruit', 'signal processing', 'speech in noise', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,305399
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,10132296,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'individuals with autism spectrum disorder', 'language impairment', 'longitudinal design', 'machine learning method', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2021,588497
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,10064139,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,301954
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['3-Dimensional', 'Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
"Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App PROJECT SUMMARY Background: Depression during pregnancy and the postpartum period affects up to 15% of US mothers, imposing costs on mother, child, and society. Early detection can significantly reduce the incidence of depression, yet depressive symptoms are often missed during prenatal visits, which tend to focus on maternal and fetal physical health, leaving less time for maternal mental health. Even if mental health is addressed during prenatal care, women may not feel comfortable answering questions that are perceived to be embarrassing or invasive. Failing to detect depression is even more likely during the postpartum period due to infrequent physician visits once the baby has been born. Measurement in the form of daily journals, which can be analyzed using natural language processing, can promote early and more frequent detection of depression during pregnancy and the postpartum period. Study Aims: 1) Model which dynamic features of language used over time best predict changes in depression status in the pregnancy and postpartum periods, creating phenotypes of depression risk; 2) examine how the language patterns that predict depression differ for African-American and Caucasian women; and 3) identify the relationship between the characteristics of what depressed peripartum women say and their treatment-seeking behavior. Innovation: The proposed research is innovative in its use of high frequency natural language measurements, captured in daily journals using a smartphone app, combined with advances in natural language processing models, to assess the onset and trajectory of depression during pregnancy and the postpartum period. This is the first prospective longitudinal study using natural language collection for risk prediction in a clinical population and the first to: 1) characterize the critical topics women discuss during the peripartum period over time using open-ended journals; 2) evaluate multiple facets of language to gain a more comprehensive understanding of the relationship between language and depression; 3) use a longitudinal design approach allowing for optimal modeling of language changes associated with depression onset. Methodology and Expected Results: Monthly depression risk identified from the Edinburgh Postnatal Depression Scale. will be collected through the MyHealthyPregnancy smartphone app, a mobile health application developed through close collaboration between decision scientists, clinicians, statisticians, and local peripartum women. A daily journal embedded in the MyHealthyPregnancy app will collect natural language text from the participants for 10 months (from their first prenatal visit through two months postpartum). Using three distinct natural language processing algorithmic approaches, this study will characterize how the natural language used by peripartum women in their daily journal entries is connected to the onset and experience of peripartum depression, as measured through monthly-administered depression scales. Group- based trajectory modeling will then classify women according to the patterns in their depression scores over time. Potential Impact: This work lays the foundation for developing and evaluating real-time interventions that could be deployed at scale to women who are using language that signals high depression risk. PROJECT NARRATIVE This research will examine how the topics (the people and events mentioned), sentiment (the positive, negative, and neutral affect), and other aspects of language expressed in daily journal entries correspond to diagnostic measures of depression and treatment-seeking in a peripartum clinical population. Psychometric and daily journal entry data will be gathered through an existing smartphone app, MyHealthyPregnancy, which monitors risk and delivers actionable information as part of routine prenatal care provided to the pregnant members of a large regional healthcare system.",Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App,10111569,R21MH119450,"['Address', 'Affect', 'African American', 'Algorithms', 'Appointment', 'Behavior', 'Behavioral Sciences', 'Birth', 'Caring', 'Caucasians', 'Characteristics', 'Child', 'Childbirth', 'Clinical', 'Collaborations', 'Collection', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Developmental Delay Disorders', 'Diagnostic', 'Disclosure', 'Early Diagnosis', 'Early treatment', 'Emotions', 'Environment', 'Event', 'Failure to Thrive', 'Feeling', 'Foundations', 'Frequencies', 'Healthcare Systems', 'Incidence', 'Infant', 'Intervention', 'Journals', 'Language', 'Longitudinal observational study', 'Longitudinal prospective study', 'Measurable', 'Measurement', 'Measures', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Moods', 'Mothers', 'National Institute of Mental Health', 'Natural Language Processing', 'Participant', 'Patients', 'Pattern', 'Perinatal', 'Phenotype', 'Physicians', 'Population', 'Postpartum Depression', 'Postpartum Period', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Prenatal care', 'Psychometrics', 'Race', 'Reporting', 'Research', 'Risk', 'Risk Assessment', 'Scientist', 'Signal Transduction', 'Societies', 'Source', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Visit', 'Voice', 'Well in self', 'Woman', 'Work', 'antepartum depression', 'base', 'cohort', 'cost', 'depression model', 'depressive symptoms', 'experience', 'fetal', 'health assessment', 'improved', 'innovation', 'longitudinal design', 'machine learning algorithm', 'member', 'motherhood', 'natural language', 'patient subsets', 'peripartum depression', 'physical conditioning', 'pregnant', 'racial disparity', 'response', 'risk prediction', 'routine screening', 'smartphone Application', 'social culture', 'sociodemographics', 'statistical and machine learning', 'time use', 'vector']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,194684
"Research Symposium in Communication Sciences and Disorders The Research Symposium in Communication Sciences and Disorders supports a full day of presentations by leading scientists in areas that are having transformational effects in the communication sciences and disorders (CSD) discipline. The Research Symposium is held at the annual Convention of the American Speech-Language-Hearing Association (ASHA) and is open to all of the approximately 15,000 Convention attendees, which includes students, practitioners, and researchers. Following Convention, the Symposium content is widely disseminated through audio recordings of the presentations, which are synced with the slides and transcribed, and by making them freely accessible on the ASHA website. Additionally, each presenter submits an article based on their presentation to the Journal of Speech, Language, and Hearing Research to be published in the annual Research Symposium Forum. An innovation that will be implemented in this current funding cycle is that ASHA will make these articles freely accessible upon publication on the ASHA Journals website and will deposit them in PubMed Central without embargo. The first aim of the Research Symposium grant is to advance scientific discourse and dissemination of scientific discovery and innovation on five topics that are having transformational effects across several subareas in CSD. This will be accomplished, in part, by making the Research Symposium Forum open access and by widely promoting both the recorded and the written content across ASHA’s many communication channels. Over the next 5-year funding cycle, the Symposium will address five topics that cut across the areas of hearing, speech, language, and other aspects of cognition, including (1) Health and Healthcare Equity of People With Communication Disabilities, (2) Bilingualism, (3) Artificial Intelligence in CSD, (4) Genetics in CSD, and (5) Intervention and Implementation Clinical Trials in CSD. The second aim of the Research Symposium grant is to advance the research career development of early- career scientists focused on research in CSD. Between 2021 and 2025, the Research Mentoring- Pair Travel Award and ASHA’s in-kind contribution will provide funding to attend the Symposium and mentoring support to 130 early-career scientists in CSD. The Travel Award recipients will attend the Symposium along with a mentor and engage in mentored research activities before, during, and after each Symposium. These activities are designed to help integrate the protégés into their scientific community and encourage them to pursue a research career and become productive scholars. The scientific base of the CSD discipline will be strengthened by these scientific dissemination, research education, and mentoring activities. The Research Symposium in Communication Sciences and Disorders aims to strengthen the scientific base and increase the research capacity of the discipline, which will lead to improvements in the communication health of millions people with communication or related disorders. The Symposium presentations will advance the scientific dialogue and be broadly disseminated through freely available peer-reviewed publications and transcribed recordings. The associated Travel Award will provide funds to support 130 promising early-career scientists in attending the Research Symposium and engaging in mentored research activities before, during, after the Symposium to increase their recruitment and retention in a research career.",Research Symposium in Communication Sciences and Disorders,10070224,R13DC003383,"['Address', 'American Speech-Language-Hearing Association', 'Area', 'Artificial Intelligence', 'Award', 'Awareness', 'Clinical', 'Clinical Trials', 'Cognition', 'Communication', 'Communication Disability', 'Communities', 'Data', 'Degree program', 'Deposition', 'Dimensions', 'Discipline', 'Disease', 'Doctor&apos', 's Degree', 'Enrollment', 'Ensure', 'Event', 'Funding', 'Generations', 'Genetic', 'Grant', 'Health', 'Health Communication', 'Healthcare', 'Hearing', 'Hour', 'Intervention', 'Journals', 'Knowledge', 'Language', 'Manuscripts', 'Mentors', 'Methodology', 'Monitor', 'Outcome Measure', 'Peer Review', 'Postdoctoral Fellow', 'Preparation', 'PubMed', 'Publications', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seminal', 'Slide', 'Speech', 'Students', 'Surveys', 'Time', 'Travel', 'Work', 'base', 'bilingualism', 'career', 'career development', 'clinical trial implementation', 'design', 'dissemination research', 'doctoral student', 'education research', 'experience', 'innovation', 'knowledge base', 'meetings', 'next generation', 'online community', 'recruit', 'social media', 'stem', 'symposium', 'web site']",NIDCD,AMERICAN SPEECH-LANGUAGE-HEARING ASSN,R13,2021,39900
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,10146334,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,427761
"Automated measurement of language outcomes for neurodevelopmental disorders Improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders. However, progress in testing these treatments is limited by the lack of informative outcome measures to indicate whether or not an intervention or treatment is having the desired effect on a child's conversational use of language (i.e., discourse skills). The long-term goal of the proposed renewal project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The goal of the parent R01 (R01DC012033) is to develop and validate new Natural Language Processing (NLP) based methods that automatically measure discourse-related skills, including language productivity (talkativeness), grammar and vocabulary, and discourse, based on raw (i.e., not coded or annotated) transcripts of natural language samples. Our objective in this proposal is to take the next step to evaluate the suitability of these NLP-based measures as outcomes for children with a range of intellectual abilities, language levels, and diagnoses. NLP algorithms require choices of pivotal parameter settings, such as word frequency dependent weights. While our previous results, involving between-group contrasts, were insensitive to these settings, our proposed project, involving psychometric quantities such as validity, may be sensitive to them. Building on our progress from the parent R01, we propose to pursue three specific aims: (1) Identify pivotal parameter settings that optimize stability of NLP discourse measures, and examine responsiveness to real change; (2) Evaluate consistency of NLP discourse measures, and identify key measurement factors that impact consistency; and (3) Evaluate validity of NLP discourse measures, and differences in validity as a function of diagnostic group, age, IQ, and language ability. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and different sample lengths, and validity of each measure. The contribution of the proposed project will be to systematically assess the psychometric properties of NLP discourse measures. The proposed research is innovative because it represents a substantial departure from the status quo by taking the crucial next step: the development of scalable, psychometrically sound measures of discourse skills that can be used to assess between-group differences as well as within-individual change over time. The proposed research is significant because it is expected to result in viable spoken language outcome measures for children with a range of neurodevelopmental disorders, making it possible to target and meaningfully measure improvements in clinical trials and behavioral interventions. Ultimately, the successful completion of this study will provide the immediate ability to scale up treatment evaluations involving measurement of spoken language use, allowing flexible data collection across sites and studies, and in the future provide new targets for to-be-developed behavioral and pharmacological interventions. The proposed research is relevant to public health because improving conversational use of spoken language is an important goal for many new interventions and treatments for children with neurodevelopmental disorders, and outcome measures that are automated, quantitative, scalable, and objective are needed to evaluate these treatments. The proposed research is relevant to the mission of NIH because it contributes to the development of fundamental knowledge about the spoken language use among children with a range of neurodevelopment disorders and conversational language difficulties, and will make it possible to target spoken language and meaningfully measure improvements in clinical trials and behavioral interventions.",Automated measurement of language outcomes for neurodevelopmental disorders,10132284,R01DC012033,"['Address', 'Age', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Child', 'Clinical', 'Clinical Trials', 'Code', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Individual', 'Influentials', 'Intervention', 'Knowledge', 'Language', 'Length', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neurodevelopmental Disorder', 'Outcome', 'Outcome Measure', 'Parents', 'Productivity', 'Property', 'Psychometrics', 'Public Health', 'Research', 'Research Personnel', 'Sampling', 'Site', 'Social Functioning', 'Speech', 'Stereotyping', 'Testing', 'Time', 'Transcript', 'Translating', 'United States National Institutes of Health', 'Vocabulary', 'Weight', 'Work', 'autism spectrum disorder', 'autistic children', 'base', 'behavioral pharmacology', 'common treatment', 'design', 'flexibility', 'improved', 'indexing', 'informant', 'innovation', 'language outcome', 'natural language', 'neurodevelopment', 'parent project', 'scale up', 'skills', 'sound', 'symptomatic improvement', 'translational impact']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,576876
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,10118008,F32DC018205,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Aphasia', 'Auditory', 'Auditory Perception', 'Auditory area', 'Behavioral', 'Brain', 'Brain region', 'Cognition', 'Communication', 'Data', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Judgment', 'Linguistics', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mind', 'Music', 'Noise', 'Participant', 'Pathway interactions', 'Perception', 'Performance', 'Periodicity', 'Process', 'Psychophysics', 'Records', 'Research', 'Research Personnel', 'Role', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speech Perception', 'Stimulus', 'Structure', 'System', 'Testing', 'Work', 'auditory processing', 'career', 'cognitive neuroscience', 'experimental study', 'individuals with autism spectrum disorder', 'insight', 'neuroimaging', 'neuromechanism', 'non-invasive imaging', 'operation', 'programs', 'relating to nervous system', 'sound', 'spectral energy', 'speech processing']",NIDCD,NEW YORK UNIVERSITY,F32,2021,65994
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,10201558,K24DC016312,"['3-Dimensional', 'Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'effectiveness testing', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'machine learning algorithm', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual', 'virtual vocal tract']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2021,189937
