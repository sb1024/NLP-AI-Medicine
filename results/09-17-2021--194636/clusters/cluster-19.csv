text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9777388,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2019,24447,-0.024965941274776516
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9691995,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2019,378183,0.07020884634453241
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9747977,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,115051,0.10397914365504311
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9727582,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Radiation', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'cancer care', 'cancer recurrence', 'cancer therapy', 'chemotherapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2019,77450,0.04856948100739731
"Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning RESEARCH SUMMARY The goal of this award is to provide Andrew Beam, PhD with research support and comprehensive mentoring designed to transition him to an independent investigator in perinatal and neonatal informatics. Preterm labor (PTL) is labor which occurs before 37 weeks of gestation and carries with it enormous health and financial consequences. Preterm infants have some of the highest levels of pulmonary and cardiac morbidity, yet machine-learning techniques for these important outcomes remains under developed. The research strategy is focused developing predictive models for two very important clinical scenarios using large sources of existing healthcare data. The focus of Specific Aim 1 develops a new form of machine learning known as deep learning for predicting PTL in pregnant women, while the focus of Specific Aim 2 investigates the use of deep learning for predicting clinical trajectories of preterm infants in the NICU. Currently, management and anticipation of both clinical scenarios is challenging and advancement in our predictive capacity could dramatically improve the quality and efficiency of the healthcare system. These models will be built using an existing database of 50 million patient-lives obtained through a partnership with a major US health insurer. Specific Aim 3 seeks to understand how the models constructed using this unique data resource translate and generalize to data from the electronic health records of Boston-area hospitals, which is a key concern for all healthcare data scientists. The education plan focuses on augmenting Dr. Beam’s graduate degrees in statistics and bioinformatics with additional training in clinical medicine and human pathology. This additional education will grant Dr. Beam a deeper understanding of the clinical problems faced by these populations and will allow for more fluid collaborations with clinicians in the future. The composition of Dr. Beam’s mentorship committee, which includes expertise in neonatology, biostatistics, and translational informatics, reflects his long-term desire to be quantitative scientist who works side-by-side practicing physicians so that quantitative research is translated into impactful clinical practice. PROJECT NARRATIVE Infants born prematurely experience some of the highest levels of pulmonary and cardiac morbidity and are among the most expensive patients in all of pediatrics. Now, with the availability of large sources of healthcare data from insurance claims databases and electronic health records, there is an opportunity to better understand prematurity and its predictors using computational techniques. We propose leveraging state of the art deep learning models built using data from hospitals and insurers to both predict which pregnancies will result in preterm birth and to predict which preterm infants will experience severe cardiac and pulmonary morbidity.",Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning,9928552,K01HL141771,"['37 weeks gestation', 'Accounting', 'Acute Disease', 'Address', 'Adverse event', 'Affect', 'Area', 'Award', 'Big Data', 'Bioinformatics', 'Biometry', 'Birth', 'Birth Weight', 'Boston', 'Bronchopulmonary Dysplasia', 'Cardiac', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Collaborations', 'Computational Technique', 'Conceptions', 'Data', 'Data Analyses', 'Data Scientist', 'Data Sources', 'Databases', 'Diagnosis', 'Doctor of Philosophy', 'Education', 'Electronic Health Record', 'Environment', 'Event', 'Future', 'Gestational Age', 'Goals', 'Graduate Degree', 'Grant', 'Health', 'Healthcare', 'Healthcare Systems', 'Heart', 'Heart Diseases', 'Hospitals', 'Human Pathology', 'Incidence', 'Infant', 'Informatics', 'Institutional Review Boards', 'Insurance Carriers', 'Life', 'Liquid substance', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Necrotizing Enterocolitis', 'Neonatal', 'Neonatal Intensive Care Units', 'Neonatology', 'Outcome', 'Patent Ductus Arteriosus', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Perinatal', 'Physicians', 'Physiological', 'Population', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Premature Infant', 'Premature Labor', 'Reproducibility', 'Research', 'Research Personnel', 'Research Support', 'Rest', 'Retinopathy of Prematurity', 'Risk', 'Risk Estimate', 'Scientist', 'Sepsis', 'Side', 'Signal Transduction', 'Source', 'Structure', 'Teaching Hospitals', 'Techniques', 'Time', 'Training', 'Translating', 'Update', 'Vulnerable Populations', 'Work', 'clinical practice', 'clinical predictors', 'data resource', 'deep learning', 'deep learning algorithm', 'design', 'education planning', 'electronic data', 'experience', 'improved', 'insurance claims', 'mortality', 'peer', 'portability', 'prediction algorithm', 'predictive modeling', 'premature', 'prognostic', 'respiratory distress syndrome', 'social', 'statistics']",NHLBI,HARVARD SCHOOL OF PUBLIC HEALTH,K01,2019,166320,0.03281413554058134
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,9800752,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'learning strategy', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,632498,0.036345882432819145
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9742525,R44MH115523,"['Address', 'Applications Grants', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'autism spectrum disorder', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2019,491792,-0.01545637154102428
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9840810,R44MH115523,"['Address', 'Applications Grants', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'autism spectrum disorder', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2019,107870,-0.01545637154102428
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9669002,R61AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2019,447173,0.07362143337429201
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9764151,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,461656,0.02564965500847732
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,0.16693169601944682
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9818000,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,489349,0.09065178778279293
"Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. Cancers in the thoracic region, which include lung, esophageal, thymus, mesothelioma and breast cancers, are among the most pervasive and deadly cancers. The protection of normal thoracic organs including lungs, heart, esophagus and spinal cord is critical in reducing long term toxicity in such cancers. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dosage distribution. Despite tremendous effort into the development of semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria and thus leads to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. The associated human efforts would significantly increase if adaptive radiation therapy (ART) is used as OARs from two or more simulation CT scans need to be segmented to adjust treatment plans. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, a thoracic OAR auto-segmentation product will be developed in this project with the two aims: 1) improve and validate the deep-learning-based automatic thoracic organ segmentation algorithm on a larger clinical data set, and 2) incorporate this algorithm into a preliminary product that fits into the clinical workflow. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. Furthermore, the time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based thoracic OAR auto-segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region,9776272,R43EB027523,"['3-Dimensional', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Area', 'Atlases', 'Attention', 'Cancer Center', 'Cancer Patient', 'Chest', 'Client', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Early Diagnosis', 'Environment', 'Esophageal', 'Esophagus', 'Goals', 'Healthcare', 'Heart', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Kentucky', 'Label', 'Lung', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medicine', 'Mesothelioma', 'Methods', 'Modeling', 'Organ', 'Outcome', 'Pathologic', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Privatization', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Spinal Cord', 'Structure', 'Survival Rate', 'Testing', 'Thymus Gland', 'Time', 'Toxic effect', 'Training', 'Treatment Cost', 'Universities', 'Validation', 'X-Ray Computed Tomography', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinically relevant', 'convolutional neural network', 'cost', 'deep learning', 'dosage', 'dosimetry', 'improved', 'learning strategy', 'malignant breast neoplasm', 'millimeter', 'novel', 'prototype', 'satisfaction', 'simulation', 'success', 'tool', 'treatment planning']",NIBIB,"CARINA MEDICAL, LLC",R43,2019,299288,0.02756033332724546
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9824066,R21ES029722,"['Adult', 'Algorithms', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2019,221376,0.10937326582234992
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9769180,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,559137,0.050309757980044854
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0.063233531204764
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9607075,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Imagery', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,373880,0.04032735245537588
"An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers Abstract  Stereotactic MRI-guided online adaptive radiotherapy (SMART) is an effective treatment for the pancreas and other upper abdominal cancers. SMART allows precise delivery of escalated prescription dose to the abdominal tumor targets while avoiding the complications of radiation toxicity to the mobile gastrointestinal (GI) organs surrounding the tumor target. In the clinical workflow of SMART, manual segmentation of the GI orangs at risk (OARs) is one of the most important but also the most labor-intensive steps. Manual segmentation takes 10 minutes on average but ranges from 5 to 22 minutes. The slow and costly manual segmentation step directly decreases the accessibility and affordability of online SMART and indirectly reduces the effectiveness of SMART due to intra-fractional body and organ movement of the patients. In this study, we will develop a deep-learning based interactive and semi-automatic procedure to accurately and quickly segment the GI OARs to make SMART more efficient and affordable. Stereotactic MRI-guided online adaptive radiotherapy (SMART) has been demonstrated as an effective treatment for the pancreas and other upper abdominal cancers. For nonresectable pancreatic cancer, SMART increased the overall survival at 36 months from 18% to 55% compared to conventional radiation therapy (RT) treatment. In this study, we will develop a deep-learning based interactive and semi-automatic method to accurately and quickly segment the organs-at- risk (OAR) in the abdomen to support SMART. The method to be developed will significantly expedite the OAR segmentation step and make SMART more efficient and affordable.",An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers,9807610,R03EB028427,"['3-Dimensional', 'Abdomen', 'Affect', 'Agreement', 'Anatomy', 'Biological', 'Clinical', 'Disadvantaged', 'Dose', 'Dose-Rate', 'Duodenum', 'Effectiveness', 'Ensure', 'Exhibits', 'Goals', 'Image', 'Kidney', 'Large Intestine', 'Liver', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Minor', 'Morphologic artifacts', 'Motion', 'Movement', 'Noise', 'Organ', 'Pancreas', 'Patients', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation Toxicity', 'Radiation therapy', 'Resolution', 'Risk', 'Small Intestines', 'Stomach', 'Time', 'Toxic effect', 'Universities', 'Washington', 'base', 'computerized', 'cost', 'deep learning', 'design', 'effective therapy', 'gastrointestinal', 'imaging capabilities', 'improved', 'irradiation', 'learning strategy', 'novel', 'preservation', 'time use', 'tool', 'treatment duration', 'tumor']",NIBIB,WASHINGTON UNIVERSITY,R03,2019,89216,0.03556813081644029
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.1022795779455762
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9666310,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Epithelial', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Natural regeneration', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2019,194052,0.08760142149956548
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine No abstract available PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,10063300,U01LM012675,[' '],NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2019,375751,0.09266988420283642
"Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement ABSTRACT for Administrative Supplement: Current methods identified at late to identify pancreatic cancer are suboptimal stage resulting in a substantially unmet clinical with the majority of cases need. The current imaging approaches are often limited in spatiotemporal resolution and specificity with high inter- and intra-reader variability in radiological exams that often result in flawed evaluation in identifying pancreatic cancer. Our original grant R01EB020125 aimed to utilize UPRT nanoparticles containing IR780 dye to detect pancreatic cancer using Multispectral optoacoustic tomography (MSOT) imaging. The objective of our administrative supplement is to develop machine learning algorithms to accurately, objectively and consistently assess and distinguish pancreatic cancer versus normal pancreas as utilizing MSOT images. Building upon our experience in theranostic nanoparticles, MSOT imaging, and machine and deep learning, the focus of this supplement is to identify molecular features of pancreatic cancer using MSOT. As MSOT is a new imaging modality, interpreting its images will be challenging for medical professionals. Therefore, we will develop a computer-assisted image analysis (CAIA) system which will help physicians to interpret these images accurately and consistently, minimizing inter-reader variability. Similarly, we will develop and evaluate a machine-learning classifier to quantitatively identify pancreatic cancer. Together, these studies aim to optimize and validate our novel MSOT imaging combined with machine learning to identify pancreatic cancer. This project extends our existing grant which develops a pancreatic tumor targeted nanoparticle detectable using multispectral optoacoustic tomography to include evaluation of the images using deep learning. The deep learning algorithms will segment possible pancreatic cancer regions and identify features to characterize possible pancreatic cancer regions.",Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement,9750320,R01EB020125,"['Administrative Supplement', 'Algorithms', 'Clinical', 'Computer-Assisted Image Analysis', 'Dyes', 'Evaluation', 'Grant', 'Image', 'Image Analysis', 'Machine Learning', 'Malignant neoplasm of pancreas', 'Medical', 'Methods', 'Molecular', 'Pancreas', 'Physicians', 'Radiology Specialty', 'Reader', 'Resolution', 'Specificity', 'Systems Analysis', 'deep learning', 'experience', 'imaging approach', 'imaging modality', 'nanoparticle', 'novel', 'optoacoustic tomography', 'pancreatic neoplasm', 'spatiotemporal', 'theranostics']",NIBIB,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2018,133300,0.0060216581084149125
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.07164466657018578
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9485584,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'Supervision', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2018,378183,0.07020884634453241
"A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies PROJECT SUMMARY/ABSTRACT More people die every year from kidney disease than breast or prostate cancer. Kidney transplantation is life-saving but is limited by a shortage of organ donors and an unacceptably high donor organ discard rate. The decision to use or discard a donor kidney relies heavily on manual quantitation of key microscopic findings by pathologists. A major limitation of this microscopic examination is human variability and inefficiency in interpreting the findings, resulting in potentially healthy organs being deemed unsuitable for transplantation or potentially damaged organs being transplanted inappropriately. Our team developed the first Deep Learning model capable of automatically quantifying percent global glomerulosclerosis in whole slide images of donor kidney frozen section wedge biopsies. This innovative approach has the potential to transform donor kidney biopsy evaluation by improving pathologist efficiency, accuracy, and precision ultimately resulting in optimized donor organ utilization, diminished health care costs, and improved patient outcomes. The goal of this project is to establish our Deep Learning automated quantitative evaluation as the standard practice of donor kidney evaluation prior to transplantation. This will be achieved by assembling a team of expert kidney pathologists and computer scientists specializing in machine learning. The proposal will evaluate the accuracy and precision of the computerized approach to quantifying percent global glomerulosclerosis and compare these results with current standard of care pathologist evaluation. The feasibility of deploying the Deep Learning model to analyze whole slide images on the cloud will also be examined. The end product of this STTR will be a web-based platform to securely deploy Deep Learning image analysis as a tool to assist pathologists with donor kidney biopsy evaluation. PUBLIC HEALTH RELEVANCE STATEMENT Before a kidney can be transplanted, the tissue must be assessed under a microscope to ensure the organ is healthy enough for transplant. A major limitation of microscopic examination is human variability in interpreting the findings, resulting in healthy organs being deemed unsuitable for transplantation. This funding will support developing computer algorithms to assist pathologists in microscopic examination of donor kidney tissues, resulting in more consistent and objective biopsy interpretations, minimizing discard of potentially usable kidneys and optimizing organ placement for transplant.",A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies,9678574,R41DK120253,"['Address', 'Biopsy', 'Blinded', 'Caring', 'Cessation of life', 'Charge', 'Chronic', 'Chronic Kidney Failure', 'Clinical', 'Computational algorithm', 'Computer Assisted', 'Computer software', 'Computers', 'Cost of Illness', 'Data Set', 'Ensure', 'Evaluation', 'Freezing', 'Frozen Sections', 'Funding', 'Goals', 'Health Care Costs', 'Healthcare Systems', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Transplantation', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Measures', 'Medicare', 'Microscope', 'Microscopic', 'Modeling', 'Online Systems', 'Organ', 'Organ Donor', 'Outcome', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Personal Satisfaction', 'Phase', 'Process', 'Quantitative Evaluations', 'Reproducibility', 'Research Personnel', 'Savings', 'Scientist', 'Secure', 'Slide', 'Small Business Technology Transfer Research', 'Speed', 'Testing', 'Time', 'Tissues', 'Translating', 'Transplantation', 'Transplanted tissue', 'Universities', 'Washington', 'Work', 'base', 'clinical practice', 'cloud based', 'commercial application', 'computerized', 'deep learning', 'digital', 'glomerulosclerosis', 'improved', 'innovation', 'learning network', 'malignant breast neoplasm', 'meetings', 'power analysis', 'predictive modeling', 'public health relevance', 'software development', 'standard of care', 'technological innovation', 'tool', 'whole slide imaging']",NIDDK,"NEWVENTUREIQ, LLC",R41,2018,214009,0.06651588997687059
"Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data NARRATIVE SUMMARY The landscape of data formats is rapidly expanding, with image, text and other complex formats becoming available for health related outcomes. By considering such data within the context of observational causal inference, they can be leveraged to improve clinical decisions, help evaluate treatment efficacy by estimating individualized treatment effects and help develop intelligent therapeutic systems where individualized treatments can be deployed. In R01EB025021, we concentrate on understanding how nearly exact matching can be achieved in the presence of a large number of categorical covariates. The proposed approach (called FLAME - Fast Large Almost Matching Exactly) is able to quickly learn which categorical covariates are important and to produce high quality matches \citep{wang2017flame,dieng2018collapsing}. The main shortfall in the proposed work for R01EB025021 is that it does not naturally extend to more complex data types, it only works for categorical data in which each feature is meaningful. {\bf This proposal will develop new statistical and computational tools for causal analysis of complex data structures.} Our new approach is called {\emph Matching After Learning to Stretch (MALTS)}. For each unit (e.g. patient), we propose learn a latent representation of their covariate information and a distance metric on the latent space such that units that are matched tend to provide accurate estimates of treatment effect. MALTS can use deep learning to encode the latent representations for the units, or it can learn basis transformations in linear space (stretching and rotation matrices) for simpler continuous data types. We will develop the MALTS algorithm, and apply it in a medical context. Our goal is to construct high quality matches for the following types of data: (i) medical images, such as x-rays and CT scans, (ii) medical record data, (iii) time series data (continuous EEG data), (iv) a combination of any of the first three types of data. We aim to leverage the newly developed tools to continue our evaluation of the efficacy of isolation for flu-like ailments as well as to apply them more broadly to publicly available modern datasets such as the MIMIC III database. Reliable and consistent causal analysis of public health interventions requires the use of massive previously unavailable datastreams. For example, evaluation of the efficacy of isolation interventions on flu-like-illness spread must include information on friendships and interactions between individuals, biometric information, imaging, longitudinal health record data as well as standard demographic data. The proposed research provides machine learning and deep learning tools for properly employing this data for the identification and quantification of causal effects of such treatments that can lead to the development of better public health interventions.",Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data,9750434,R01EB025021,"['Algorithms', 'Biometry', 'Categories', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Electroencephalography', 'Friendships', 'Goals', 'Health', 'Image', 'Individual', 'Intervention', 'Lead', 'Learning', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Modernization', 'Outcome', 'Patients', 'Research', 'Roentgen Rays', 'Rotation', 'Series', 'Stretching', 'Structure', 'System', 'Text', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'X-Ray Computed Tomography', 'computerized tools', 'data format', 'deep learning', 'efficacy evaluation', 'flu', 'health record', 'improved', 'individualized medicine', 'novel strategies', 'public health intervention', 'tool', 'treatment effect']",NIBIB,DUKE UNIVERSITY,R01,2018,98714,0.047259411350359846
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9527181,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,545116,0.10397914365504311
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9465737,R44MH115523,"['Address', 'Applications Grants', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2018,149124,-0.01545637154102428
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,0.01957593066057402
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,-0.0006748583054401126
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9475340,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'deep learning', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2018,27175,0.02925055350982962
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Project​ ​Summary/Abstract This​ ​SBIR​ ​Phase​ ​I​ ​project​ ​will​ ​develop​ ​a​ ​deep​ ​learning-based​ ​clinical​ ​decision​ ​support​ ​algorithm for​ ​identifying​ ​aortic​ ​stenosis​ ​from​ ​heart​ ​sounds​ ​recorded​ ​using​ ​the​ ​Eko​ ​Core​ ​Digital Stethoscope.​ ​This​ ​screening​ ​tool​ ​will​ ​help​ ​to​ ​decrease​ ​the​ ​number​ ​of​ ​patients​ ​with​ ​severe asymptomatic​ ​aortic​ ​stenosis​ ​that​ ​remain​ ​undertreated​ ​simply​ ​because​ ​the​ ​condition​ ​is​ ​not diagnosed.​ ​Auscultation​ ​is​ ​commonly​ ​the​ ​method​ ​by​ ​which​ ​valvular​ ​heart​ ​disease​ ​is​ ​first detected,​ ​but​ ​cases​ ​often​ ​fail​ ​to​ ​be​ ​referred​ ​to​ ​echocardiography​ ​for​ ​diagnosis​ ​because clinicians​ ​fail​ ​to​ ​detect​ ​heart​ ​murmurs,​ ​particularly​ ​in​ ​noisy​ ​or​ ​rushed​ ​environments.​ ​To​ ​address this​ ​challenge,​ ​Eko​ ​had​ ​developed​ ​the​ ​Core,​ ​a​ ​digital​ ​stethoscope​ ​attachment​ ​that​ ​can​ ​be​ ​added in-line​ ​to​ ​a​ ​clinician’s​ ​existing​ ​stethoscope​ ​that​ ​amplifies​ ​heart​ ​sounds​ ​and​ ​streams​ ​digitized phonocardiograms​ ​to​ ​a​ ​smartphone,​ ​tablet​ ​or​ ​personal​ ​computer.​ ​There,​ ​the​ ​signal​ ​can​ ​be analyzed​ ​with​ ​the​ ​decision​ ​support​ ​algorithm​ ​we​ ​will​ ​develop​ ​as​ ​part​ ​of​ ​this​ ​project.​ ​The​ ​specific aims​ ​of​ ​this​ ​study​ ​are​ ​(1)​ ​to​ ​​collect​ ​a​ ​database​ ​with​ ​condition-specific​ ​recording​ ​labels​ ​to enable​ ​deep​ ​learning​ ​for​ ​heart​ ​sounds​ ​though​ ​clinical​ ​data​ ​collection​ ​at​ ​UCSF​ ​and​ ​(2)​ ​to develop​ ​and​ ​evaluate​ ​a​ ​deep​ ​convolutional​ ​neural​ ​network-based​ ​algorithm​ ​trained​ ​on​ ​the database.​ ​By​ ​integrating​ ​this​ ​deep​ ​learning​ ​algorithm​ ​into​ ​Eko’s​ ​mobile​ ​and​ ​cloud​ ​software platform,​ ​currently​ ​used​ ​by​ ​clinicians​ ​at​ ​over​ ​700​ ​institutions​ ​worldwide,​ ​we​ ​anticipate​ ​this algorithm​ ​will​ ​enable​ ​more​ ​accurate​ ​screening​ ​for​ ​aortic​ ​stenosis,​ ​leading​ ​to​ ​earlier​ ​diagnosis and​ ​better​ ​patient​ ​outcomes. SBIR​ ​Project​ ​Narrative Valvular​ ​heart​ ​disease,​ ​and​ ​aortic​ ​stenosis​ ​in​ ​particular,​ ​are​ ​becoming​ ​increasingly​ ​prevalent manifestations​ ​of​ ​poor​ ​cardiovascular​ ​health​ ​in​ ​both​ ​the​ ​developed​ ​and​ ​developing​ ​world.​ ​A highly-accurate​ ​clinical​ ​decision​ ​support​ ​algorithm​ ​that​ ​is​ ​able​ ​to​ ​detect​ ​aortic​ ​stenosis​ ​will impact​ ​public​ ​health​ ​by​ ​reducing​ ​unnecessary​ ​referrals​ ​for​ ​echocardiography​ ​and​ ​promoting early​ ​and​ ​accurate​ ​diagnosis​ ​in​ ​underserved​ ​areas​ ​with​ ​limited​ ​access​ ​to​ ​subspecialty​ ​care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,9621223,R43HL144297,"['Address', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Benign', 'Biological Neural Networks', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Data Collection', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Environment', 'Evaluation', 'FDA approved', 'Future', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Heart Abnormalities', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Hospitals', 'Human', 'Image', 'Imaging Techniques', 'Institution', 'Label', 'Learning', 'Medical Device', 'Medicare', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Monitor', 'Network-based', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physicians', 'Positioning Attribute', 'Public Health', 'Resources', 'Screening procedure', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Tablet Computer', 'Testing', 'Training', 'Weight', 'accurate diagnosis', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinically significant', 'cloud software', 'commercialization', 'cost', 'deep learning', 'deep neural network', 'diagnosis standard', 'digital', 'innovation', 'screening', 'speech recognition']",NHLBI,"EKO DEVICES, INC.",R43,2018,295881,0.02349204297935475
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9724174,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,24598,0.07362143337429201
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9526090,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,399482,0.07362143337429201
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9566185,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,436007,0.02564965500847732
"Deep learning enhanced seizure monitoring from wearable sensors Deep learning enhanced seizure monitoring from wearable sensors Over 1 million patients in the United States have uncontrolled epilepsy despite ongoing medical therapy. When seizures are prolonged or violent, there is significant risk of injury or even Sudden Unexpected Death of Epilepsy (SUDEP) which occurs in approximately 1 in 500 patients per year. Novel seizure monitoring could help alleviate this burden. Our research team has created a software application, EpiWatch, to capture different sensor measurements related to seizure activity such as convulsions (accelerometers), heart rate increases (photo- plethysmography-PPG), and unresponsiveness to behavioral prompting (interactive user interface). Our hope is to offer accurate seizure detection with improved false positive performance to encourage usage. Our team proposes to develop multi-modal sensor analysis driven by deep learning technology to enhance seizure monitoring. We are uniquely positioned to accelerate development by leveraging our team’s prior EpiWatch IRB approved study which generated over 6,000 hours of sensor data. In Phase I, we will teach EpiWatch how to read time series sensor data and how to discriminate seizure activity. EpiWatch will employ a convolutional neural network, a technique rooted in deep learning, to self-characterize seizure features from labeled sensor data. In order to infer additional information from vast amounts of unlabeled sensor data from US epilepsy patients, EpiWatch will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of EpiWatch will test its ability to identify the presence of seizures in a prospective new cohort of epilepsy patients. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact. Our goal is to combine recent advances in deep learning and scalable parallel computing to create EpiWatch. In the long term, we hope this monitoring technology will aid epilepsy patient management and improve outcomes. PROJECT NARRATIVE Recurring seizures are disabling, dangerous, and often limit independence. We are developing novel seizure detection using a consumer friendly device with wearable sensors (EpiWatch) to enable monitoring and emergency alerting for seizures that occur without warning (~50% of all seizures) and without witnesses, especially when they are prolonged (> 5 min) or accompanied by cardiac arrhythmias responsible for SUDEP (Sudden Unexpected Death with Epilepsy), a 1 in 500 annual risk for patients with uncontrolled seizures. If emergency care can be summoned under these circumstances, patients can live more safely and independently, in turn encouraging app usage. When integrated with current disease monitoring activities, EpiWatch will have the long range impact of providing a unique platform for individualized epilepsy care.",Deep learning enhanced seizure monitoring from wearable sensors,9622338,R43NS108905,"['Accelerometer', 'Apple', 'Arrhythmia', 'Behavioral', 'Biological Neural Networks', 'Biosensor', 'Caregivers', 'Caring', 'Cessation of life', 'Computer software', 'Consent', 'Convulsions', 'Dangerousness', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Emergency Care', 'Emergency Situation', 'Epilepsy', 'Event', 'Goals', 'Gold', 'Heart Rate', 'Hospitals', 'Hour', 'Injury', 'Institutional Review Boards', 'Label', 'Learning', 'Measurement', 'Medical', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Network-based', 'Neural Network Simulation', 'Neurologist', 'Outcome', 'Outpatients', 'Patient Monitoring', 'Patient Self-Report', 'Patient risk', 'Patients', 'Performance', 'Phase', 'Photoplethysmography', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Refractory', 'Research', 'Risk', 'Seizures', 'Series', 'Signal Transduction', 'Supervision', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Translating', 'United States', 'Violence', 'Work', 'clinical translation', 'cohort', 'computing resources', 'deep learning', 'improved', 'improved outcome', 'insight', 'novel', 'parallel computer', 'prospective', 'response', 'sensor', 'wearable device']",NINDS,"VIGILANT MEDICAL, INC.",R43,2018,238872,0.07303415735891727
"Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy Project Summary We propose to introduce and optimize a new method of radiomics extraction via transfer learning with deep convolutional neural networks (CNNs) and to compare it to the conventional segmentation-based radiomics approach on breast dynamic contrast-enhanced magnetic resonance images (DCE-MRIs). The field of breast radiomics has been expanding fast, with many clinical conclusions being successfully derived from medical images using qualitative analysis. In the past couple of years, deep learning has experienced explosive growth in image recognition, easily solving complex problems. Deep CNNs achieve remarkable classification results on everyday image datasets. We propose to investigate the utility of deep neural networks with regards to the medical image datasets, specifically on the breast DCE-MRI dataset. Given the relatively small sizes of these datasets, CNNs previously trained on non-medical images will be utilized for clinical classifications as feature extractors. We will investigate multiple parameters involved in the CNN feature extraction methodology and their effect on classification performance. Two clinical tasks will be studied under the proposed research: 1) malignancy assessment and 2) response to therapy prediction. The optimized CNN method will be compared to and combined with the conventional segmentation- based radiomics method. Furthermore, we aim to investigate the robustness of the segmentation-based features across MR scanners of different manufacturers. The first aim of the proposed research will study the robustness of the segmentation- based features extracted from images acquired on MR scanners of two different manufacturers. The robustness will be investigated under four clinical tasks, such as lymph node involvement and receptor statuses. The second aim will be focused on optimization of CNN feature extraction and subsequent classifier design. Lastly, under the third aim we will compare and combine the CNN and segmentation-based radiomics in the classification tasks of malignancy assessment and response to therapy prediction. Project Narrative The goal of the proposed research is to improve breast cancer diagnosis and prognosis based on dynamic contrast-enhanced magnetic resonance images by introducing novel deep learning methods to medical image classification and combining it with the conventional radiomics systems. The incredible power of deep learning methods to classify everyday images shows great promise to make predictions based on medical image datasets. Our thorough investigation of deep learning methods and their combination with conventional radiomics methods has potential to improve breast cancer management.",Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy,9469826,F31CA221193,"['Benign', 'Biological Neural Networks', 'Breast', 'Cancer Prognosis', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Complex', 'Computers', 'Data', 'Data Set', 'Effectiveness', 'Evaluation', 'Goals', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intuition', 'Investigation', 'Lesion', 'Lymph Node Involvement', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical Imaging', 'Methodology', 'Methods', 'Nature', 'Neoadjuvant Therapy', 'Performance', 'Prediction of Response to Therapy', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Research', 'Standardization', 'System', 'Techniques', 'Training', 'Variant', 'base', 'breast cancer diagnosis', 'chemotherapy', 'computerized', 'contrast enhanced', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'learning strategy', 'malignant breast neoplasm', 'novel', 'radiomics', 'receptor', 'response']",NCI,UNIVERSITY OF CHICAGO,F31,2018,26048,-0.015170721344917214
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9447403,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Imagery', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,385444,0.04032735245537588
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9574149,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,579883,0.050309757980044854
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More No abstract available The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9608820,R44MH115523,"['Address', 'Applications Grants', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2018,441001,0.03864307742575611
"Structure-based prediction of the interactome Supplement Summary “Structure-based prediction of the interactome” NIH R01GM081871-10 PI: Bonnie Berger We have designed and implemented a system for privacy-preserving and scalable sharing of drug-target interaction data (Aim 1, under review at Science), where we required GPUs to run our protocol, discover and experimentally validate novel drug-target interactions and will make our software publicly-available for academic and non-profit use (Aim 3). At the same time, we have presented a novel loss function for training classifiers from positive and unlabeled data and developed a software pipeline, Topaz, which uses convolutional neural networks trained with few positive examples for protein detection (Aim 2, RECOMB 2018). We are now developing new deep learning models for protein structure embedding and extending the Topaz framework to learn a general deep learning model of protein images from multiple cryo-EM micrograph datasets. Our continued progress on these projects is significantly jeopardized by our lack of GPU compute power. While in the last year we have purchased a compute node with four GPUs, we are continually frustrated by wait-times and inability to try different models and hyperparameters. Thus, we are requesting an additional node with eight GPUs to enable us to reach the broader goals of our grant. Narrative The interactions of small molecules with proteins are omnipresent throughout cellular processes and of fundamental importance to drug design and disease treatment, yet the task of predicting these interactions brings major challenges because of the heterogeneity and proprietary nature of the data. Here, we develop new mathematical methods and software that can address not only interpreting the data itself, but also the collaborative and generative process through which researchers work: new cryptographic tools can enable unprecedented forms of secure sharing and collaboration between industry and the public, and deep learning can accelerate the drug discovery process.",Structure-based prediction of the interactome,9703262,R01GM081871,"['Address', 'Biological Neural Networks', 'Cell physiology', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Detection', 'Disease', 'Drug Design', 'Drug Targeting', 'Goals', 'Grant', 'Heterogeneity', 'Image', 'Industry', 'Learning', 'Modeling', 'Nature', 'Privacy', 'Process', 'Proteins', 'Protocols documentation', 'Research Personnel', 'Running', 'Science', 'Secure', 'Structure', 'System', 'Time', 'Topaz', 'Training', 'United States National Institutes of Health', 'Wait Time', 'Work', 'base', 'cryptography', 'deep learning', 'design', 'drug discovery', 'loss of function', 'mathematical methods', 'new therapeutic target', 'novel', 'protein structure', 'small molecule', 'tool']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2018,83700,-0.024581130403232565
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9523172,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'deep learning', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2018,213750,0.0650073502823076
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9403171,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Learning', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,548068,0.10397914365504311
"Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction   PROJECT  SUMMARY  Heart failure (HF) is a highly disabling and costly disease with a high mortality rate. In the pre­diagnostic phase  (i.e.,  12­36  months  before  diagnosis),  HF  is  difficult  to  detect  given  the  insidious  signs  and  symptoms.  After  diagnosis,  where  it  is not possible to reverse disease progression, efforts are made to avoid hospital admission  and  re­admission,  but  with  limited  capabilities  to  stratify  patients  by  risk.  We  propose  to  develop  interpretable  deep learning models applied to large­scale electronic health record (EHR) data to detect HF related events on  two  different  time  scales.  One  set  of  models will be developed to detect HF diagnosis one to two years before  actual  documented  diagnosis.  Separately,  we  propose  to  identify  HF  patients  who  are  at  risk  of  hospital  admission  and  readmission . The project focuses on developing deep learning models that offer the potential for  greater  accuracy,  clinical  interpretability,  and  utility  than  alternatives.  The  expected  deliverables  include  comprehensive  software  for  creating  deep  learning  algorithms  that  predict  HF  outcomes  and  related  software  tools  for  model  visualization.           PROJECT NARRATIVE Deep learning has shown tremendous success in many domains but is yet to have similar impact in health care. The key challenges in healthcare applications are the lack of interpretation for deep learning models and limited transferability of the models across institutions. We develop interpretable deep learning algorithms for heart failure prediction that can handle large longitudinal patient records and are able to adapt across institutions.",Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction,9544376,R56HL138415,"['Accounting', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Biological Neural Networks', 'Caring', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer software', 'Cost of Illness', 'Data', 'Decision Trees', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease Progression', 'E-learning', 'Early Diagnosis', 'Electronic Health Record', 'Event', 'Future', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'Hospitals', 'Image', 'Imagery', 'Individual', 'Influentials', 'Inpatients', 'Institution', 'Intuition', 'Learning', 'Logistic Regressions', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Outcome', 'Output', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Procedures', 'Records', 'Recurrence', 'Research', 'Risk', 'Risk Factors', 'Signs and Symptoms', 'Software Tools', 'Structure', 'System', 'Time', 'Translating', 'Work', 'base', 'clinical care', 'clinical risk', 'health application', 'high dimensionality', 'improved', 'individual patient', 'interest', 'interoperability', 'learning strategy', 'mortality', 'parallel computer', 'patient stratification', 'prediction algorithm', 'predictive modeling', 'relating to nervous system', 'success']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R56,2017,756093,0.10885991425147641
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9371358,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Learning', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2017,222279,0.02925055350982962
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9288493,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Learning', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'computer aided detection', 'cost', 'improved', 'innovation', 'minimally invasive', 'mortality', 'prevent', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,436007,0.02564965500847732
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9297792,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Ingestion', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2017,256500,0.0650073502823076
"Deep-radiomics-learning for mass detection in CT colonography Project Summary/Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States. However, it would be prevented by early detection and removal of its precursor lesions. The use of CT colonography (CTC) would substantially increase the access, capacity, safety, cost-effectiveness, and patient compliance of colorectal examinations. The interpretation of CTC examinations would be most effective by use of a first-reader computer- aided detection (FR-CADe) paradigm, where a radiologist reviews only the lesion candidates detected automatically by a computer-aided detection (CADe) system. However, because CADe systems can miss large masses, radiologists still need to perform an additional two-dimensional (2D) review of the CT images of the colon, which increases reading time over 40% on average. Furthermore, also radiologists can occasionally miss some types of masses on CTC images. The goal of this project is to develop a DEep RAdiomics LEarning (DERALE) scheme for the detection of large masses on CTC images. The scheme will be used to integrate deep learning methods and radiomic biomarkers to perform a complete automated review of CTC images for reliable detection of colorectal masses. We hypothesize that the DERALE scheme will be able to detect colorectal masses at a sensitivity comparable to that of unaided expert radiologists and that it can be used to reduce the interpretation time of FR- CADe without degrading diagnostic accuracy in CTC. We will evaluate and compare the classification performance of DERALE with that of unaided expert radiologists and conduct an observer performance study to compare the detection accuracy of the use of DERALE in the FR-CADe paradigm with that of unaided expert radiologists in the detection of masses from CTC images. Successful development and broad adoption of DERALE in the FR-CADe paradigm will facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce the mortality rate from colon cancer, one of the largest threats of cancer deaths in the United States. Project Narrative Successful development and validation of DERALE will substantially advance the clinical implementation of CTC and the FR-CADe paradigm in large populations to facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce mortality from colon cancer, the second leading cause of cancer deaths in both men and women in the United States. The research is innovative in that robust mass detection has not been developed for CTC and FR- CADe, and that there have been no attempts to use deep learning for mass detection in CTC.",Deep-radiomics-learning for mass detection in CT colonography,9316607,R21EB022747,"['Abdomen', 'Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Anatomy', 'Biological Markers', 'Biological Neural Networks', 'Cancer Etiology', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Collection', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Excision', 'Fatigue', 'Goals', 'Guidelines', 'Image', 'Image Analysis', 'Learning', 'Lesion', 'Location', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Methods', 'Performance', 'Phenotype', 'Polyps', 'Population', 'Prevention', 'Reader', 'Reading', 'Reporting', 'Research', 'Safety', 'Scheme', 'Societies', 'System', 'Testing', 'Time', 'United States', 'Validation', 'Woman', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'compliance behavior', 'computer aided detection', 'cost effective', 'cost effectiveness', 'design', 'diagnostic accuracy', 'innovation', 'learning strategy', 'men', 'mortality', 'novel', 'prevent', 'radiologist', 'radiomics', 'screening', 'two-dimensional']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2017,213750,0.004869703354266043
"Deep-radiomics-learning for mass detection in CT colonography Project Summary/Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States. However, it would be prevented by early detection and removal of its precursor lesions. The use of CT colonography (CTC) would substantially increase the access, capacity, safety, cost-effectiveness, and patient compliance of colorectal examinations. The interpretation of CTC examinations would be most effective by use of a first-reader computer- aided detection (FR-CADe) paradigm, where a radiologist reviews only the lesion candidates detected automatically by a computer-aided detection (CADe) system. However, because CADe systems can miss large masses, radiologists still need to perform an additional two-dimensional (2D) review of the CT images of the colon, which increases reading time over 40% on average. Furthermore, also radiologists can occasionally miss some types of masses on CTC images. The goal of this project is to develop a DEep RAdiomics LEarning (DERALE) scheme for the detection of large masses on CTC images. The scheme will be used to integrate deep learning methods and radiomic biomarkers to perform a complete automated review of CTC images for reliable detection of colorectal masses. We hypothesize that the DERALE scheme will be able to detect colorectal masses at a sensitivity comparable to that of unaided expert radiologists and that it can be used to reduce the interpretation time of FR- CADe without degrading diagnostic accuracy in CTC. We will evaluate and compare the classification performance of DERALE with that of unaided expert radiologists and conduct an observer performance study to compare the detection accuracy of the use of DERALE in the FR-CADe paradigm with that of unaided expert radiologists in the detection of masses from CTC images. Successful development and broad adoption of DERALE in the FR-CADe paradigm will facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce the mortality rate from colon cancer, one of the largest threats of cancer deaths in the United States. Project Narrative Successful development and validation of DERALE will substantially advance the clinical implementation of CTC and the FR-CADe paradigm in large populations to facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce mortality from colon cancer, the second leading cause of cancer deaths in both men and women in the United States. The research is innovative in that robust mass detection has not been developed for CTC and FR- CADe, and that there have been no attempts to use deep learning for mass detection in CTC.",Deep-radiomics-learning for mass detection in CT colonography,9167836,R21EB022747,"['Abdomen', 'Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Anatomy', 'Biological Markers', 'Biological Neural Networks', 'Cancer Etiology', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Collection', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Excision', 'Fatigue', 'Goals', 'Guidelines', 'Heating', 'Image', 'Image Analysis', 'Learning', 'Lesion', 'Location', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Methods', 'Performance', 'Polyps', 'Population', 'Prevention', 'Reader', 'Reading', 'Reporting', 'Research', 'Safety', 'Scheme', 'Societies', 'System', 'Testing', 'Time', 'United States', 'Validation', 'Woman', 'X-Ray Computed Tomography', 'abstracting', 'accurate diagnosis', 'base', 'compliance behavior', 'computer aided detection', 'cost effective', 'cost effectiveness', 'design', 'diagnostic accuracy', 'innovation', 'learning strategy', 'men', 'mortality', 'novel', 'prevent', 'radiologist', 'radiomics', 'screening', 'two-dimensional']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2016,256500,0.004869703354266043
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8689173,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2014,202714,0.07330634353337567
"Scalable Biomedical Pattern Recognition Via Deep Learning DESCRIPTION (provided by applicant): Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.  The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is  being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.  Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.  In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes. Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,9302040,R21LM011664,[' '],NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2014,7696,0.07330634353337567
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8566062,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2013,175500,0.07330634353337567
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,9976348,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2020,529154,0.08595537723199495
"Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study PROJECT SUMMARY Road traffic injuries are a major contributor to the burden of disease globally with nearly 1.3 million deaths globally and as many as 50 million injured annually with pedestrians and cyclists in low and middle-income countries (LMICs) among the most affected. Road infrastructure of the built environment (e.g., sidewalks), neighborhood design (e.g., street connectivity) and urban development (e.g., urban sprawl) are key determinants of the risk of pedestrian injuries. In LMICs, poor road infrastructure and neighborhood design are acknowledged as being important contributors to rising numbers of road traffic injuries and deaths, but there are few studies systematically identifying and quantifying what specific features of the built environment are contributing to motor vehicle collisions in these settings. Within LMIC cities, there are often large disparities where infrastructure is improved that reflect socioeconomic characteristics, leading to health inequities in road traffic injury. The paucity of georeferenced data on the built environment in LMICs has made research on road traffic injuries more difficult, though recent advances in computer vision and image analysis combined with Big Data of publicly available, georeferenced, images of roads worldwide (e.g., Google Street View, GSV) can help overcome the paucity of data and the cost and time limitations of collecting and analyzing data on the built environment in LMICs. Automated image analysis has largely been made possible via deep learning, a subfield of artificial intelligence and machine learning and relies on training neural networks to detect and label specific objects within images. These methods can drastically reduce the barriers to citywide built environment and traffic safety research in LMIC cities, thus substantially increasing research capacity and generalizability. My career goal is to become an independent investigator in global urban health with a focus on road safety and the built environment in LMICs. I propose undertaking research and training in deep learning methods applied to public health in the setting of Bogota, Colombia: 1) Develop neural networks to create a database of BE features of the road infrastructure from image data and to create neighborhood typologies from those features; 2) Assess the association between neighborhood-level BE features and typologies and pedestrian collisions and fatalities and road safety perceptions; 3) Assess the association of neighborhood social environment characteristics with pedestrian collision and fatalities, perceptions, and BE features and typologies. I am seeking additional training in 1) developing competency in deep learning methods applied to public health; 2) creating neighborhood indictors and typologies of health and the built environment; 3) applying Bayesian spatiotemporal models to understand how neighborhood characteristics and typologies influence health; 4) develop skills in multi-country collaboration, grant writing and overseeing research projects in LMICs. PROJECT NARRATIVE Roads and neighborhoods with a built environment that support safe and active transportation are a major priority in low- and middle-income countries (LMICs) due to 90% of road traffic deaths occurring in these locations, especially to pedestrians and other vulnerable road users, yet data on key built environment features at a large scale are not always readily available in these settings. My career goal is to improve population health by examining the effects of the built environment and transportation on health through the adoption and use of methods that can leverage Big Data sources and answer complex, multilevel research questions by overcoming the lack of built environment data in LMICs. The proposed research uses deep learning and advanced statistical methods to create a citywide dataset of built and social environment features in Bogota, Colombia that will provide crucial data to answer questions of their impact on pedestrian injuries and deaths, as well as assessing the presence of health inequities in their distribution and that will lay the groundwork to expand these efforts to more cities in Latin America and other LMICs.","Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study",10123391,K01TW011782,"['Adopted', 'Adoption', 'Affect', 'Artificial Intelligence', 'Big Data', 'Cessation of life', 'Characteristics', 'Cities', 'Classification', 'Collaborations', 'Colombia', 'Competence', 'Complex', 'Computer Vision Systems', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Discipline', 'Education', 'Future', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Injury', 'Label', 'Latin America', 'Lead', 'Location', 'Machine Learning', 'Mathematics', 'Mentors', 'Methods', 'Modeling', 'Neighborhoods', 'Perception', 'Persons', 'Public Health', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Risk', 'Safety', 'Social Environment', 'Statistical Methods', 'Time', 'Training', 'Transportation', 'Typology', 'Urban Developments', 'Urban Health', 'Vehicle crash', 'Writing', 'automated image analysis', 'built environment', 'burden of illness', 'career', 'career development', 'computer science', 'cost', 'data infrastructure', 'deep learning', 'design', 'digital imaging', 'experience', 'high risk', 'improved', 'injured', 'learning strategy', 'low and middle-income countries', 'neighborhood association', 'neural network', 'pedestrian injury', 'population health', 'skills', 'social', 'socioeconomics', 'spatiotemporal', 'virtual']",FIC,DREXEL UNIVERSITY,K01,2020,138024,0.06227979647285898
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,9968604,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2020,80500,0.04975924627251172
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,10000961,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2020,702450,-0.024965941274776516
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.0736565643124445
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9979659,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'MeSH Thesaurus', 'Measures', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'large scale data', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'public repository', 'specific biomarkers']",NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2020,467177,0.10397914365504311
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,0.1634241492895335
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9925232,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2020,378183,0.07020884634453241
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,9868507,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'tool']",NEI,DUKE UNIVERSITY,K23,2020,195131,0.06761002323657063
"A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies ABSTRACT More people die every year from kidney disease than breast or prostate cancer. Kidney transplantation is life-saving, yet the donor organ shortage and high organ discard rate contributes to 13 deaths daily among patients awaiting transplant. The decision to use or discard a donor kidney relies heavily on microscopic quantitation of chronic damage by pathologists. The current standard of care relies on a manual process that is subject to significant human variability and inefficiency, resulting in potentially healthy kidneys being discarded and potentially damaged kidneys being transplanted inappropriately. Our team developed the first Deep Learning model to quantify percent global glomerulosclerosis in donor kidney frozen section biopsy whole slide images. We developed a cloud-based platform to apply the Deep Learning model to analyze kidney biopsy whole slide images in under 6 minutes with accuracy and precision equal to or greater than current standard of care pathologists. We have also developed a Deep Learning model to quantify interstitial fibrosis on donor kidney biopsy whole slide images. This innovative approach has the potential to transform donor kidney biopsy evaluation by improving pathologist efficiency, accuracy, and precision ultimately resulting in optimized donor organ utilization, improved patient outcomes, and diminished health care costs. The goal of this project is to establish our Deep Learning automated techniques as the standard for evaluating donor kidneys prior to transplantation. This will be achieved by assembling a team of expert pathologists and computer scientists specializing in machine learning. The proposal will evaluate the accuracy and precision of the interstitial fibrosis Deep Learning model, use the automated quantitation of key microscopic findings to develop an outcome-based chronic damage score that predicts graft outcome, and test the ability of the Deep Learning models to withstand variations encountered using different scanners and processing in different laboratories. The functionality of the Trusted Kidney software platform will be improved beyond the current usable product into a commercially viable solution for multiple laboratories. PUBLIC HEALTH RELEVANCE STATEMENT Before kidneys can be transplanted, they must be examined using a microscope to ensure the kidney is healthy enough for transplant. A limitation of microscopic examination by pathologists is the inherent human variability in quantifying the amount of scar tissue, or chronic damage, present. The result is potentially healthy organs being discarded or damaged kidneys being used inappropriately. This funding will support developing artificial intelligence tools to assist pathologists with quantifying scar tissue in donor kidneys prior to transplantation, resulting in more consistent and objective biopsy evaluations, minimizing discard of potentially healthy kidneys, and optimizing placement of kidneys for transplant.",A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies,10138826,R42DK120253,"['Adoption', 'Americas', 'Artificial Intelligence', 'Biopsy', 'Canada', 'Cessation of life', 'Chronic', 'Cicatrix', 'Clinical', 'Computer software', 'Computers', 'Contracts', 'Data', 'Databases', 'Development', 'Ensure', 'Evaluation', 'Fast Healthcare Interoperability Resources', 'Fibrosis', 'Frozen Sections', 'Funding', 'Goals', 'Gold', 'Graft Survival', 'Health Care Costs', 'Human', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Transplantation', 'Knowledge', 'Laboratories', 'Letters', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Measurement', 'Microscope', 'Microscopic', 'Midwestern United States', 'Modeling', 'Multivariate Analysis', 'Online Systems', 'Organ', 'Organ Donor', 'Organ Procurements', 'Outcome', 'Pathologist', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Satisfaction', 'Phase', 'Process', 'Reproducibility of Results', 'Research Personnel', 'Savings', 'Scanning', 'Scientist', 'Secure', 'Services', 'Slide', 'Small Business Technology Transfer Research', 'Specialist', 'Speed', 'System', 'Techniques', 'Testing', 'Tissues', 'Transplantation', 'Trichrome stain', 'Trichrome stain method', 'Trust', 'United Network for Organ Sharing', 'Universities', 'Variant', 'Washington', 'Work', 'analytical tool', 'base', 'clinical biomarkers', 'cloud based', 'cloud platform', 'commercial application', 'cost', 'deep learning', 'functional improvement', 'glomerulosclerosis', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'interstitial', 'kidney biopsy', 'learning strategy', 'malignant breast neoplasm', 'pathology imaging', 'phase 1 study', 'predictive modeling', 'public health relevance', 'renal damage', 'shared database', 'standard of care', 'technological innovation', 'tool', 'whole slide imaging']",NIDDK,"NEWVENTUREIQ, LLC",R42,2020,811695,0.09362300833660303
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.03671877604721916
"Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning RESEARCH SUMMARY The goal of this award is to provide Andrew Beam, PhD with research support and comprehensive mentoring designed to transition him to an independent investigator in perinatal and neonatal informatics. Preterm labor (PTL) is labor which occurs before 37 weeks of gestation and carries with it enormous health and financial consequences. Preterm infants have some of the highest levels of pulmonary and cardiac morbidity, yet machine-learning techniques for these important outcomes remains under developed. The research strategy is focused developing predictive models for two very important clinical scenarios using large sources of existing healthcare data. The focus of Specific Aim 1 develops a new form of machine learning known as deep learning for predicting PTL in pregnant women, while the focus of Specific Aim 2 investigates the use of deep learning for predicting clinical trajectories of preterm infants in the NICU. Currently, management and anticipation of both clinical scenarios is challenging and advancement in our predictive capacity could dramatically improve the quality and efficiency of the healthcare system. These models will be built using an existing database of 50 million patient-lives obtained through a partnership with a major US health insurer. Specific Aim 3 seeks to understand how the models constructed using this unique data resource translate and generalize to data from the electronic health records of Boston-area hospitals, which is a key concern for all healthcare data scientists. The education plan focuses on augmenting Dr. Beam’s graduate degrees in statistics and bioinformatics with additional training in clinical medicine and human pathology. This additional education will grant Dr. Beam a deeper understanding of the clinical problems faced by these populations and will allow for more fluid collaborations with clinicians in the future. The composition of Dr. Beam’s mentorship committee, which includes expertise in neonatology, biostatistics, and translational informatics, reflects his long-term desire to be quantitative scientist who works side-by-side practicing physicians so that quantitative research is translated into impactful clinical practice. PROJECT NARRATIVE Infants born prematurely experience some of the highest levels of pulmonary and cardiac morbidity and are among the most expensive patients in all of pediatrics. Now, with the availability of large sources of healthcare data from insurance claims databases and electronic health records, there is an opportunity to better understand prematurity and its predictors using computational techniques. We propose leveraging state of the art deep learning models built using data from hospitals and insurers to both predict which pregnancies will result in preterm birth and to predict which preterm infants will experience severe cardiac and pulmonary morbidity.",Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning,9850130,K01HL141771,"['37 weeks gestation', 'Accounting', 'Acute Disease', 'Address', 'Adverse event', 'Affect', 'Area', 'Award', 'Big Data', 'Bioinformatics', 'Biometry', 'Birth', 'Birth Weight', 'Boston', 'Bronchopulmonary Dysplasia', 'Cardiac', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Collaborations', 'Computational Technique', 'Conceptions', 'Data', 'Data Analyses', 'Data Scientist', 'Data Sources', 'Databases', 'Diagnosis', 'Doctor of Philosophy', 'Education', 'Electronic Health Record', 'Environment', 'Event', 'Future', 'Gestational Age', 'Goals', 'Graduate Degree', 'Grant', 'Health', 'Healthcare', 'Healthcare Systems', 'Heart', 'Heart Diseases', 'Hospitals', 'Human Pathology', 'Incidence', 'Infant', 'Informatics', 'Institutional Review Boards', 'Insurance Carriers', 'Life', 'Liquid substance', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Necrotizing Enterocolitis', 'Neonatal', 'Neonatal Intensive Care Units', 'Neonatology', 'Outcome', 'Patent Ductus Arteriosus', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Perinatal', 'Physicians', 'Physiological', 'Population', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Premature Infant', 'Premature Labor', 'Reproducibility', 'Research', 'Research Personnel', 'Research Support', 'Rest', 'Retinopathy of Prematurity', 'Risk', 'Risk Estimate', 'Scientist', 'Sepsis', 'Side', 'Signal Transduction', 'Source', 'Teaching Hospitals', 'Techniques', 'Time', 'Training', 'Translating', 'Update', 'Vulnerable Populations', 'Work', 'clinical practice', 'clinical predictors', 'data resource', 'deep learning', 'deep learning algorithm', 'design', 'education planning', 'electronic data', 'experience', 'improved', 'insurance claims', 'mortality', 'peer', 'portability', 'prediction algorithm', 'predictive modeling', 'premature', 'prognostic', 'respiratory distress syndrome', 'social', 'statistical and machine learning', 'statistics', 'structured data']",NHLBI,HARVARD SCHOOL OF PUBLIC HEALTH,K01,2020,166320,0.03281413554058134
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,9864905,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,400056,0.10381232716327893
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,9938424,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'algorithm training', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'complex data ', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'large datasets', 'machine learning method', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,710049,0.036345882432819145
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9984379,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Chemotherapy and/or radiation', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'automated segmentation', 'cancer care', 'cancer recurrence', 'cancer therapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2020,77450,0.04856948100739731
"Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography Project Abstract / Summary Primary open angle glaucoma (POAG) is a leading cause of blindness in the United States and worldwide. It is estimated that over 2.2 million Americans suffer from POAG and that over 130,000 are legally blind from the disease. As the population ages, the number of people with POAG in the United States will increase to over 3.3 million in 2020 and worldwide to an estimated 111.8 million by 2040. POAG is a progressive disease associated with characteristic functional and structural changes that clinicians use to diagnose and monitor the disease. Over the past several years, spectral domain optical coherent tomography (SDOCT) has become the standard tool for measuring structure in POAG. This 3D imaging modality provides a wealth of information about retinal structure and POAG-related retinal layers. This large amount of data is hard for clinicians to interpret and use effectively to help guide treatment decisions. Instead, summary metrics such as average layer thicknesses are used to reduce SDOCT images to a handful of values. While these metrics are useful, they can be difficult to interpret and they throwaway important information regarding voxel intensity and texture, relationships across retinal layers, and the overall 3D structure of the retina. Relying too heavily on these metrics limits our ability to gain a deeper understanding structural contributions to POAG, the relationship between structure and visual function, and how structural (and functional) changes progress in POAG. Recent advances in artificial intelligence and deep learning, however, offer new data-driven tools and techniques to interpret 3D SDOCT images and learn from the large SDOCT datasets being collected in clinics around the world. This proposal will apply state-of-the-art deep learning techniques to 3D SDOCT data in order to (1) develop more accurate POAG detection tools, (2) reveal structure-function relationships, and (3) predict structural and functional progression in POAG. This proposal also details a training plan to help the PI transition from a postdoctoral scholar to an independent researcher. The mentored phase of this award will be supervised by the primary mentor, Dr. Linda Zangwill, and a multidisciplinary mentoring team including Dr. Robert Weinreb (Ophthalmology), Dr. David Kriegman (Computer Science and Engineering), and Dr. Armin Schwartzman (Biostatistics). Performing the proposed research, formal coursework, and mentored career development will the provide the PI with highly sought- after skills and experience to help ensure a successful transition into independence. Project Narrative Three-dimensional imaging techniques such as optical coherence tomography have become an essential tool in the clinical care of glaucoma and other eye diseases. These imaging techniques provide clinicians with huge amounts of structural information, but interpreting the data and using it effectively to improve outcomes remains challenging in clinical glaucoma management. This project will improve patient care by applying powerful deep learning techniques to provide clinicians with critical decision support information to more accurately detect glaucoma, reveal associations between structure and visual function, and predict glaucoma progression.",Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography,10055661,K99EY030942,"['3-Dimensional', 'Affect', 'Age', 'American', 'Artificial Intelligence', 'Award', 'Biometry', 'Blindness', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Computational Technique', 'Cornea', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Ensure', 'Evaluation', 'Eye', 'Eye diseases', 'Frequencies', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Learning', 'Length', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Modeling', 'Monitor', 'Ophthalmology', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Population', 'Primary Open Angle Glaucoma', 'Probability', 'Progressive Disease', 'Race', 'Research', 'Research Personnel', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'South Korea', 'Standardization', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Texture', 'Thick', 'Thinness', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Training', 'Translating', 'United States', 'Universities', 'Vision', 'Visual Fields', 'Visualization', 'Width', 'Work', 'base', 'career development', 'clinical care', 'college', 'computer science', 'deep learning', 'experience', 'field study', 'imaging modality', 'improved', 'improved outcome', 'individual patient', 'large datasets', 'legally blind', 'macula', 'multidisciplinary', 'predictive modeling', 'preservation', 'research clinical testing', 'retinal nerve fiber layer', 'sex', 'skills', 'standard measure', 'three dimensional structure', 'tomography', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2020,117347,0.0556540372920406
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,0.041170592214781615
"Interpretable deep learning models for translational medicine Understanding the state of cellular signaling systems provides insights to how cells behave under physiological and pathological conditions. Cellular signaling systems are organized as hierarchy (cascade) and signals of a molecular is often compositionally encoded to control cellular processes, such as gene expression. This project aims to develop advanced deep learning models (DLMs) to simulate cellular signaling systems based on gene expression data. In last 3 years, the project has made significant progresses, but the challenges remain. Importantly, contemporary DLMs behave as “black boxes”, in that it is difficult to interpret how signals are encoded and how to interpret which signal a hidden node represent in a DLM. This black-box nature prevents researchers from gaining biological insights using DLMs, even though these models can be much superior in modeling data than other types of models in many tasks, e.g., predicting drug sensitivity of cancer cells. In this competitive renewal, we propose to develop novel DLMs and innovative inference algorithms to train “interpretable” DLMs and apply them in translational research. The proposed research is innovative and of high significance in several perspectives: 1) Our novel DLMs and algorithms take advantage of big data resulting from systematic chemical/genetic perturbations of cellular signaling machinery, so that we can use the perturbation condition as side information to reveal how signals are encoded in a DLM. 2) We integrate principles of causal inference and information theory with deep learning method to make DLMs interpretable. As results, that researchers can gain mechanistic insights from such models. 3) Innovative application of interpretable DLMs will advance translational research. For example, we will train interpretable DLMs to model cellular signaling at the level of single cells and use this information investigate inter-cellular interactions among cells in tumor microenvironment to shed light on immune evasion mechanisms of cancers. We will also use information derived from interpretable DLMs to predict cancer cell drug sensitivity. We anticipate that our study will bring forth significant advances not only in deep learning methodology but also in precision medicine. This project aims to develop advance machine learning methods, referred to as deep learning models, to simulate cellular signaling systems, at both multiple cell and single cell levels. Success of these models will enable researchers to investigate cellular behaviors under physiological and pathological condition, and such information can be used to guide therapy of cancer patients.",Interpretable deep learning models for translational medicine,9972153,R01LM012011,"['Affect', 'Algorithms', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Cancer Patient', 'Cancer cell line', 'Cell model', 'Cell physiology', 'Cells', 'Data', 'Disease', 'Event', 'Gene Expression', 'Genetic', 'Genetic Transcription', 'Grain', 'Human', 'Immune Evasion', 'Immunotherapy', 'Individual', 'Information Theory', 'Intervention', 'Knowledge', 'Learning', 'Libraries', 'Light', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'MicroRNAs', 'Mining', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Network-based', 'Organoids', 'Outcome', 'Paper', 'Pathologic', 'Pathway interactions', 'Patients', 'Pharmacology', 'Phenotype', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Cancer Genome Atlas', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Yeasts', 'base', 'biological systems', 'cancer cell', 'cancer therapy', 'cell behavior', 'chemical genetics', 'data modeling', 'deep field survey', 'deep learning', 'deep learning algorithm', 'design', 'drug sensitivity', 'experience', 'genome-wide', 'innovation', 'inquiry-based learning', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'novel', 'patient response', 'pre-clinical', 'precision medicine', 'precision oncology', 'predicting response', 'prevent', 'response', 'single-cell RNA sequencing', 'success', 'theories', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'translational impact', 'translational medicine', 'translational model', 'tumor', 'tumor microenvironment']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,309622,0.005592529134996099
"SBIR Phase I - Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring Retinoblastoma is a rare pediatric cancer affecting the retina, optic nerve, and brain. Accounting for 6% of all cancers in children under the age of five, it is the world's most common primary intraocular childhood malignancy. While survival rates in the U.S. are high, early detection is pivotal to preserving vision: by the time symptoms present, enucleation is often the only option. This proposal seeks to develop IRIS-R, an Intelligent Retinal Imaging Solution to enable earlier detection of Retinoblastoma. This inexpensive, noninvasive screening tool will leverage recent advances in deep learning to detect the tell-tale signs of retinal tumors in near real-time. The models will be integrated with a handheld non-mydriatic fundus imager, providing a reliable, inexpensive, hardware backbone for the screening tool. IRIS-R will be developed with help from retinal specialists, practicing ophthalmologists, and pediatricians to guarantee maximum diagnostic accuracy and clinical usefulness. n/a","SBIR Phase I - Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269835,5N91020C00047,"['Accounting', 'Affect', 'Age', 'Artificial Intelligence', 'Brain', 'Clinical', 'Country', 'Databases', 'Diagnosis', 'Early Diagnosis', 'Fundus', 'Image', 'Intelligence', 'Malignant Childhood Neoplasm', 'Modeling', 'Monitor', 'Ophthalmologist', 'Optic Nerve', 'Phase', 'Retina', 'Retinal Neoplasms', 'Retinoblastoma', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Specialist', 'Survival Rate', 'Symptoms', 'Time', 'Training', 'Vertebral column', 'Vision', 'cancer imaging', 'cancer prevention', 'deep learning', 'diagnostic accuracy', 'fundus imaging', 'imager', 'pediatrician', 'preservation', 'retinal imaging']",NCI,BABEL ANALYTICS LLC,N43,2020,398149,0.009773456012735453
"Lupus Nephritis Neural Network, LuNN Up to 60% of adults and 80% of children with systemic lupus erythematosus (SLE) develop nephritis (LN), with 10–30% progressing to end-stage renal disease (ESRD). The gold standard for diagnosis of LN is a renal biopsy. Histological parameters remain the best predictors of ESRD. Despite being the gold standard, histological diagnosis of LN has several shortcomings. In multiple inter-observer renal pathology assessment studies reported thus far, the inter- pathologist correlation coefficients, or concordance, in assessing most histological parameters have been sub-optimal. This has provided the impetus for the current proposal. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of LN using current diagnostic criteria. We propose to train a deep convolutional neural network to distinguish the different LN classes, and to identify a full spectrum of histological attributes useful for diagnosis. We will compare the performance of the newly generated neural network in scoring glomerular/tubulo-interstitial features and LN classes, against a panel of human renal pathologists. Finally, we propose to build a neural network that can predict clinical outcome based on baseline renal pathology. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival. Despite being the gold standard, histological diagnosis of lupus nephritis is imprecise, and marked by significant inter-pathologist discordance in readings. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of lupus nephritis. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival.","Lupus Nephritis Neural Network, LuNN",10246669,R56DK122036,"['Adult', 'Algorithms', 'Automobile Driving', 'Cellular Structures', 'Child', 'Chronic', 'Classification', 'Computer Vision Systems', 'Diagnosis', 'Diagnostic', 'End stage renal failure', 'Feedback', 'Gold', 'Histologic', 'Human', 'Image', 'Kidney', 'Lupus', 'Lupus Nephritis', 'Machine Learning', 'Mus', 'Nephritis', 'Outcome', 'Outcome Study', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Phenotype', 'Prediction of Response to Therapy', 'Reading', 'Reporting', 'Reproducibility', 'Retrieval', 'Supervision', 'Systemic Lupus Erythematosus', 'Testing', 'Tissues', 'Training', 'Uncertainty', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnosis standard', 'falls', 'improved', 'indexing', 'innovation', 'kidney biopsy', 'neural network', 'novel', 'predict clinical outcome', 'time interval', 'tool', 'treatment response', 'user-friendly', 'web portal']",NIDDK,UNIVERSITY OF HOUSTON,R56,2020,100750,0.035956763169578694
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.1311125408399614
"Cardiac CT Deblooming PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the most common type of heart disease, killing over 370,000 Americans annu- ally2. Cardiac CT is a safe, accurate, non-invasive method widely employed for diagnosis of CAD and planning therapeutic interventions. With the current CT technology, calcium blooming artifacts severely limit the accuracy of coronary stenosis assessment. Similarly, stent blooming artifacts lead to overestimation of in-stent restenosis. As a result, many coronary CT angiography (CCTA) scans are non-diagnostic and result in patients receiving costly and invasive coronary angiography (ICA) procedures.  Based on extensive feasibility results, the goal of this project is to use deep learning innovations to fundamen- tally eliminate blooming artifacts without costly redesign of the CT hardware. A consortium between GE Re- search, Rensselaer Polytechnic Institute and Weill Cornell Medicine will develop dedicated imaging protocols and machine learning methods to avoid or minimize blooming artifacts and evaluate the clinical impact of the proposed solutions. In Aim 1, the CT scan protocol will be optimized and paired with deep learning reconstruc- tion and post-processing algorithms to generate high-resolution CT images and prevent blooming artifacts. In Aim 2, image-domain and raw-data-domain deep learning processing algorithms will be developed to correct for residual blooming. After successful demonstration of the proposed methods on phantom scans and emulated clinical datasets, in Aim 3 the proposed CT methods will be clinically demonstrated and optimized based on 100 patients with coronary artery disease, using intravascular ultrasound as the ground-truth reference.  At the end of the project, we will have demonstrated and publicly disseminated a systematic methodology to essentially remove blooming artifacts in cardiac CT without a costly hardware upgrade. This will be another suc- cess of deep learning, enabling accurate coronary stenosis assessment and eliminating many unnecessary diag- nostic catheterizations. PROJECT NARRATIVE Blooming artifacts severely limit the accuracy of coronary stenosis assessment with cardiac CT, leading to un- necessary invasive coronary angiography procedures. The goal of this project is to eliminate blooming artifacts without costly redesign of the CT hardware, but based on optimized scan protocols and deep-learning-based image reconstruction and post-processing techniques. The proposed CT methods will be clinically demonstrated and optimized based on CT scans of 100 patients with coronary artery disease and using intravascular ultrasound as the ground-truth reference.",Cardiac CT Deblooming,9943684,R01HL151561,"['Address', 'Algorithms', 'American', 'Angiography', 'Area', 'Attenuated', 'Calcium', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Collaborations', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Data Set', 'Diagnosis', 'Goals', 'Heart', 'Heart Diseases', 'High Resolution Computed Tomography', 'Hospitals', 'Image', 'In Vitro', 'Institutes', 'Lead', 'Measurement', 'Medicine', 'Metals', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'New York', 'Noise', 'Outcome', 'Patients', 'Physics', 'Plant Roots', 'Presbyterian Church', 'Prevention', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Scanning', 'Speed', 'Stenosis', 'Stents', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Training', 'Ultrasonography', 'Validation', 'X-Ray Computed Tomography', 'base', 'calcification', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'diagnostic catheterization', 'image reconstruction', 'improved', 'in silico', 'in vivo', 'innovation', 'learning network', 'machine learning method', 'man', 'microCT', 'mortality', 'prevent', 'reconstruction', 'recruit', 'restenosis', 'simulation', 'success', 'temporal measurement', 'virtual', 'virtual reality simulation']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2020,900092,0.005330453775950492
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,10193990,R33AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Models', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'automated segmentation', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'feature extraction', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'large datasets', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R33,2020,403748,0.07362143337429201
"Quantifying the individual contributions of comorbid tau neuropathologies using deep learning PROJECT SUMMARY/ABSTRACT Co-occurrence of different neurodegenerative diseases is increasingly common with age and acts as a confounding factor in the development of disease-specific biomarkers. Yet, even by the gold standard of evaluating immunostaining for aggregated proteins in autopsy brains, pathologic complexity makes it impossible to reliably quantify the mixture of diseases by visual inspection, especially when coexistent disorders both feature the same aggregated protein, albeit in different disease-specific patterns. Here, we hypothesize that recent advances in deep learning can identify the distinctive patterns of Alzheimer disease (AD) and progressive supranuclear palsy (PSP) neuropathology, thereby allowing us to de-convolve their individual contributions from phospho-tau immunostaining of mixed pathologies. We will tackle this problem in three steps. First, in order to incorporate biological knowledge and enable interpretability of our disease predictions, we will develop a set of deep learning classifiers to identify disease relevant “features” in virtual whole slide images. These features will include different types of cells (e.g. neurons, astrocytes), aggregates (e.g. tufted astrocytes and senile plaques that are enriched in PSP and AD, respectively) and tissue regions (gray vs. white matter, which differ in pattern of involvement in these diseases). Second, based on the assumption that comorbid pathologies exhibit a mixture of pure disease features, we will build disease classifiers from pure AD and pure PSP cases. Given a local patch of tau-stained tissue, these classifiers will return their confidence that tissue exhibited either of these diseases. We will evaluate two approaches, one building on the “features” identified above and the other a more traditional black- box deep learning approach working purely off of image patches. Finally, we will evaluate our pure disease classifiers on cases with mixed pathologies based on pathologist review and concordance with antibodies to tau isoforms whose individual histomorphologies help to distinguish between AD and PSP. As they will identify established neuropathology features demonstrated by the widely-used AT8 phospho-tau and 3R and 4R tau isoform immunostaining, our classifiers will be a valuable resource for future digital imaging based studies in neuropathology. Our framework for de-convolving comorbidities from autopsy samples can be extended to other diseases, thus enabling better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy. PROJECT NARRATIVE Co-occurrence of different neurodegenerative pathologies is increasingly common with age. Here, we aim to use deep learning to distinguish the relative contributions of individual comorbid diseases from tau-stained images of autopsy brains affected by two comorbid conditions, Alzheimer disease and progressive supranuclear palsy. Technologies developed during this proposal will provide powerful machine learning tools for neuropathology, while its successful completion will facilitate better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy.",Quantifying the individual contributions of comorbid tau neuropathologies using deep learning,10058010,R21AG066012,"['Adoption', 'Affect', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Astrocytes', 'Atlases', 'Autopsy', 'Biological', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Data', 'Dementia', 'Deposition', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Exhibits', 'Future', 'Genetic', 'Gold', 'Heterogeneity', 'Histopathology', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Lesion', 'Libraries', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Monoclonal Antibodies', 'Morphology', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurons', 'Pathologic', 'Pathologist', 'Pathology', 'Pattern', 'Phenotype', 'Progressive Supranuclear Palsy', 'Protein Isoforms', 'Research', 'Resources', 'Sampling', 'Senile Plaques', 'Spatial Distribution', 'Stains', 'Tauopathies', 'Technology', 'Testing', 'Tissue Stains', 'Tissues', 'Visual', 'Visualization', 'base', 'case-based', 'cell type', 'clinical biomarkers', 'comorbidity', 'deep learning', 'digital imaging', 'gray matter', 'hands-on learning', 'improved', 'learning classifier', 'learning strategy', 'method development', 'neocortical', 'neuropathology', 'protein aggregation', 'specific biomarkers', 'tau Proteins', 'tau-1', 'tool', 'tumor', 'virtual', 'virtual imaging', 'white matter', 'whole slide imaging']",NIA,UT SOUTHWESTERN MEDICAL CENTER,R21,2020,450250,-0.021390642075424147
"Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data Project Summary The broad objective of this research is to develop a powerful deep-learning based multiple testing approach for high-dimensional spatial data that arise commonly in biomedical imaging studies, in particular, brain imaging studies. The motivating problem is to detect the cerebral metabolic abnormalities in Alzheimer’s disease (AD) from Fluorine-18 fluorodeoxyglucose positron emission tomography (FDG-PET) data. Existing multiple testing approaches in solving this problem often ignore or inadequately capture the spatial dependence among the test statistics obtained from brain voxels and thus lose substantial power for the detection. We will develop a novel spatial multiple testing method that utilizes the deep convolutional neural network (DCNN), a key deep- learning technique, to well capture the spatial dependence among test statistics and thus to achieve the optimal power in the sense of minimizing the false nondiscovery rate (FNR) while correctly controlling the false discovery rate (FDR) at a given level. The proposed DCNN-based FDR controlling method has enhanced power to discover new AD-related brain regions that are missed by conventional methods, thereby leading to novel clinical and pathological studies. The specific aims of this proposal include: 1. To develop an optimal spatial FDR controlling approach by connecting the unsupervised local-significance-index based multiple testing with the supervised DCNN-based image segmentation; 2. To evaluate the proposed spatial FDR controlling approach via extensive simulations under various three-dimensional spatial dependence structures, in comparison with multiple classical and state-of-the-art methods; 3. To apply proposed spatial FDR controlling approach to detect AD-related brain regions using the FDG-PET datasets from the Alzheimer’s Disease Neuroimaging Initiative and the Weill Cornell Brain Health Imaging Institute; 4. To develop a user- friendly and publicly available software package with versions in both Python and R to implement the proposed spatial FDR controlling approach. The proposed DCNN-based approach will also be widely applicable to large- scale multiple testing problems in other fields of biomedical research that involve spatial dependence. Project Narrative This project will exploit recent advances in deep learning to efficiently solve the large-scale spatial multiple testing problems that arise commonly in biomedical imaging studies. The proposed powerful deep-learning based spatial multiple testing approach will be particularly useful in brain imaging studies on neurodegenerative disorders such as Alzheimer’s disease and age-related cognitive impairment.",Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data,10107565,R21AG070303,"['3-Dimensional', 'Affect', 'Age-associated memory impairment', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Architecture', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrum', 'Clinical', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Detection', 'Disease', 'Early Diagnosis', 'Family', 'Fluorine', 'Glucose', 'Goals', 'Health Sciences', 'Image', 'Institutes', 'Learning', 'Literature', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Monitor', 'Network-based', 'Neurodegenerative Disorders', 'Pathologic', 'Patients', 'Performance', 'Population Group', 'Positron-Emission Tomography', 'Problem Solving', 'Procedures', 'Pythons', 'Research', 'Research Personnel', 'Structural Models', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Training', 'base', 'bioimaging', 'brain health', 'convolutional neural network', 'deep learning', 'fluorodeoxyglucose positron emission tomography', 'high dimensionality', 'imaging Segmentation', 'imaging study', 'indexing', 'metabolic rate', 'mild cognitive impairment', 'neuroimaging', 'novel', 'repository', 'simulation', 'statistics', 'success', 'theories', 'user friendly software', 'user-friendly']",NIA,NEW YORK UNIVERSITY,R21,2020,435875,-0.009929662991654825
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,0.16693169601944682
"Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease Summary  Alzheimer's disease (AD) affects over 44 million individuals worldwide, and the number is projected to triple by 2050. However, currently there is no cure for AD. This project aims to develop and apply novel statistical methods, especially deep learning, to advance neuroimaging genetics for AD. It involves novel methodological developments in Aims 1-4, cost-effective applications to the large-scale UK Biobank neuroimaging genetic data for AD (Aim 5), and software development (Aim 6). All four Aims for the methods development tackle emerging impor- tant topics in deep learning with their applications to neuroimaging genetics for AD; although the other three Aims deal with independent topics with their own other broad applications, they in turn serve for Aim 1: 1) Aim 1 applies manually searched deep learning models for automatic feature extraction/phenotyping from neuroimages, by which both the statistical power and biological interpretation of subsequent genome-wide association studies (GWAS) are expected to be enhanced; 2) Aim 2 employs (automatic) neural architecture search (NAS) to more efﬁciently identify better deep learning models, which are then applied to Aim 1 for enhancing feature extraction/phenotyping and thus boosting the power of GWAS; 3) Aim 3 focuses on explainable deep learning, offering biological insights by localizing and highlighting the most important features extracted by deep learning models that can be used for Aim 1; 4) Aim 4 develops a novel inferential theory for deep learning, which is then applied to rigorously test for the statistical signiﬁcance of any selected/highlighted features used in Aim 1. In Aim 5, these new methods will be applied to the UK Biobank neuroimaging and GWAS data to identify novel genetic loci and neuroimaging features for AD. As a byproduct, we will develop and distribute software implementing the proposed methods in Aim 6. Project Narrative  This proposed research is to develop new statistical estimation and inference methods for deep learning with their applications to neuroimaging genetics for Alzheimer's disease (AD), which is expected to contribute to the elucidation of genetic components and etiology of AD with potential applications to other common diseases, thus facilitating their prevention, early diagnosis and therapeutic development.",Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease,10088703,R01AG069895,"['Advocate', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Architecture', 'Atlases', 'Biological', 'Brain', 'Classification', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Disease', 'Documentation', 'Early Diagnosis', 'Entropy', 'Environment', 'Etiology', 'Genetic', 'Genotype', 'Hand', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Nature', 'Noise', 'Outcome', 'Performance', 'Phenotype', 'Prevention', 'Process', 'Proxy', 'Psychological reinforcement', 'Public Domains', 'Publishing', 'Pythons', 'Research', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'base', 'biobank', 'combinatorial', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'endophenotype', 'feature extraction', 'feature selection', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic locus', 'high dimensionality', 'improved', 'insight', 'interest', 'method development', 'model building', 'neural network architecture', 'neuroimaging', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'relating to nervous system', 'software development', 'success', 'theories', 'therapeutic development', 'tool', 'trait', 'web site']",NIA,UNIVERSITY OF MINNESOTA,R01,2020,685871,-0.039360323224204644
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9970413,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,497020,0.09065178778279293
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9942528,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'aggressive therapy', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'large datasets', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,559900,0.050309757980044854
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9998736,R21ES029722,"['Adult', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'segmentation algorithm', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2020,185625,0.10937326582234992
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9828620,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,385444,0.04032735245537588
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,0.15333763045042575
"An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers Abstract  Stereotactic MRI-guided online adaptive radiotherapy (SMART) is an effective treatment for the pancreas and other upper abdominal cancers. SMART allows precise delivery of escalated prescription dose to the abdominal tumor targets while avoiding the complications of radiation toxicity to the mobile gastrointestinal (GI) organs surrounding the tumor target. In the clinical workflow of SMART, manual segmentation of the GI orangs at risk (OARs) is one of the most important but also the most labor-intensive steps. Manual segmentation takes 10 minutes on average but ranges from 5 to 22 minutes. The slow and costly manual segmentation step directly decreases the accessibility and affordability of online SMART and indirectly reduces the effectiveness of SMART due to intra-fractional body and organ movement of the patients. In this study, we will develop a deep-learning based interactive and semi-automatic procedure to accurately and quickly segment the GI OARs to make SMART more efficient and affordable. Stereotactic MRI-guided online adaptive radiotherapy (SMART) has been demonstrated as an effective treatment for the pancreas and other upper abdominal cancers. For nonresectable pancreatic cancer, SMART increased the overall survival at 36 months from 18% to 55% compared to conventional radiation therapy (RT) treatment. In this study, we will develop a deep-learning based interactive and semi-automatic method to accurately and quickly segment the organs-at- risk (OAR) in the abdomen to support SMART. The method to be developed will significantly expedite the OAR segmentation step and make SMART more efficient and affordable.",An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers,10017990,R03EB028427,"['3-Dimensional', 'Abdomen', 'Affect', 'Agreement', 'Anatomy', 'Biological', 'Clinical', 'Disadvantaged', 'Dose', 'Dose-Rate', 'Duodenum', 'Effectiveness', 'Ensure', 'Exhibits', 'Goals', 'Image', 'Kidney', 'Large Intestine', 'Liver', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Minor', 'Morphologic artifacts', 'Motion', 'Movement', 'Noise', 'Organ', 'Pancreas', 'Patients', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation Toxicity', 'Radiation therapy', 'Resolution', 'Risk', 'Small Intestines', 'Stomach', 'Time', 'Toxic effect', 'Universities', 'Washington', 'automated segmentation', 'base', 'computerized', 'cost', 'deep learning', 'design', 'effective therapy', 'gastrointestinal', 'imaging capabilities', 'improved', 'irradiation', 'learning strategy', 'novel', 'preservation', 'time use', 'tool', 'treatment duration', 'tumor']",NIBIB,WASHINGTON UNIVERSITY,R03,2020,74942,0.03556813081644029
"Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks PROJECT SUMMARY The long-term goal of this project is to improve the care of patients with laryngeal disorders through development of automated diagnostic support for in-office flexible laryngoscopy. To accomplish this goal, we propose developing neural network-based algorithms to detect and classify structural laryngeal lesions in laryngoscopy images. An automated diagnostic tool for in-office laryngoscopy such as we propose will have several benefits: (1) It will improve access to care for patients with symptoms of laryngeal dysfunction living in communities with limited otolaryngology resources, (2) It will improve early detection of laryngeal cancers potentially reducing the morbidity of treatment, and (3) It will prove a valuable teaching tool for students and residents first learning to interpret laryngoscopic exams. Flexible laryngoscopy is a common in-office procedure performed by otolaryngologists to evaluate the upper aerodigestive tract in patients with symptoms of laryngeal dysfunction. Subtle differences in the appearance of laryngeal lesions enable otolaryngologists to differentiate benign lesions from suspected malignant ones. The expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training and therefore laryngoscopy is largely only performed in subspecialty otolaryngology clinics. The primary objective of this project is to develop neural network-based algorithms to detect and classify structural laryngeal lesions. Our hypothesis is that these algorithms can be trained using a large dataset of laryngeal images to accurately detect and classify structural laryngeal lesions on flexible laryngoscopic exam. To test this hypothesis, we propose the following aims: (1) Generate a dataset of high-quality, labeled endoscopic laryngeal images corresponding to normal and structural lesions of the larynx, (2) Develop a location-aware anchor-based reasoning neural network for accurate detection of laryngeal lesions, and (3) Develop an adaptive network model for classification of structural laryngeal pathologies including papilloma, polyp, leukoplakia and suspected malignancy. With expertise in the diagnosis and treatment of laryngeal disorders and computer vision, including object detection and classification, our multidisciplinary team is uniquely qualified to complete this project. PROJECT NARRATIVE We propose to revolutionize in-office laryngoscopy through development of a deep neural network-based automated detection and classification system for diagnosis of structural diseases of the larynx. Currently, flexible laryngoscopy is only performed by expert subspecialists with years of experience because developing the expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training. Through development of deep neural network-based algorithms to detect and classify laryngeal lesions on in- office laryngoscopy, we will improve access to care for patients living in communities without subspecialty otolaryngology care and will develop an important teaching tool for clinicians learning to interpret laryngoscopic exams.",Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks,10043172,R03CA253212,"['Aerodigestive Tract', 'Algorithms', 'Anesthesia procedures', 'Appearance', 'Architecture', 'Awareness', 'Benign', 'Caring', 'Categories', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Colonic Polyps', 'Colonoscopy', 'Communities', 'Computer Vision Systems', 'Custom', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Distal', 'Drops', 'Early Diagnosis', 'Educational process of instructing', 'Ensure', 'Fellowship', 'Functional disorder', 'Gastroesophageal reflux disease', 'Goals', 'Health Services Accessibility', 'Hoarseness', 'Image', 'Improve Access', 'Infection', 'Label', 'Laryngeal Diseases', 'Laryngoscopes', 'Laryngoscopy', 'Larynx', 'Learning', 'Lesion', 'Leukoplakia', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of larynx', 'Manuals', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Network-based', 'Normal Range', 'Otolaryngologist', 'Otolaryngology', 'Papilloma', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Pilot Projects', 'Plug-in', 'Polyps', 'Positioning Attribute', 'Procedures', 'Recurrence', 'Resources', 'Sampling', 'Semantics', 'Structure', 'Students', 'Symptoms', 'System', 'Technical Expertise', 'Testing', 'Training', 'Vision research', 'Work', 'base', 'classification algorithm', 'cost', 'deep neural network', 'detector', 'digital', 'experience', 'feature extraction', 'flexibility', 'improved', 'large datasets', 'learning algorithm', 'multidisciplinary', 'network models', 'neural network', 'tool']",NCI,UNIVERSITY OF KANSAS MEDICAL CENTER,R03,2020,154375,0.007400193683639377
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.1022795779455762
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9928452,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2020,192552,0.08760142149956548
