text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9777388,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2019,24447,-0.031120397127118584
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9691995,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2019,378183,0.07612980516015186
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9752639,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'neural network', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,196250,0.016038004976802456
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9747977,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,115051,0.0950815576173261
"Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning RESEARCH SUMMARY The goal of this award is to provide Andrew Beam, PhD with research support and comprehensive mentoring designed to transition him to an independent investigator in perinatal and neonatal informatics. Preterm labor (PTL) is labor which occurs before 37 weeks of gestation and carries with it enormous health and financial consequences. Preterm infants have some of the highest levels of pulmonary and cardiac morbidity, yet machine-learning techniques for these important outcomes remains under developed. The research strategy is focused developing predictive models for two very important clinical scenarios using large sources of existing healthcare data. The focus of Specific Aim 1 develops a new form of machine learning known as deep learning for predicting PTL in pregnant women, while the focus of Specific Aim 2 investigates the use of deep learning for predicting clinical trajectories of preterm infants in the NICU. Currently, management and anticipation of both clinical scenarios is challenging and advancement in our predictive capacity could dramatically improve the quality and efficiency of the healthcare system. These models will be built using an existing database of 50 million patient-lives obtained through a partnership with a major US health insurer. Specific Aim 3 seeks to understand how the models constructed using this unique data resource translate and generalize to data from the electronic health records of Boston-area hospitals, which is a key concern for all healthcare data scientists. The education plan focuses on augmenting Dr. Beam’s graduate degrees in statistics and bioinformatics with additional training in clinical medicine and human pathology. This additional education will grant Dr. Beam a deeper understanding of the clinical problems faced by these populations and will allow for more fluid collaborations with clinicians in the future. The composition of Dr. Beam’s mentorship committee, which includes expertise in neonatology, biostatistics, and translational informatics, reflects his long-term desire to be quantitative scientist who works side-by-side practicing physicians so that quantitative research is translated into impactful clinical practice. PROJECT NARRATIVE Infants born prematurely experience some of the highest levels of pulmonary and cardiac morbidity and are among the most expensive patients in all of pediatrics. Now, with the availability of large sources of healthcare data from insurance claims databases and electronic health records, there is an opportunity to better understand prematurity and its predictors using computational techniques. We propose leveraging state of the art deep learning models built using data from hospitals and insurers to both predict which pregnancies will result in preterm birth and to predict which preterm infants will experience severe cardiac and pulmonary morbidity.",Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning,9928552,K01HL141771,"['37 weeks gestation', 'Accounting', 'Acute Disease', 'Address', 'Adverse event', 'Affect', 'Area', 'Award', 'Big Data', 'Bioinformatics', 'Biometry', 'Birth', 'Birth Weight', 'Boston', 'Bronchopulmonary Dysplasia', 'Cardiac', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Collaborations', 'Computational Technique', 'Conceptions', 'Data', 'Data Analyses', 'Data Scientist', 'Data Sources', 'Databases', 'Diagnosis', 'Doctor of Philosophy', 'Education', 'Electronic Health Record', 'Environment', 'Event', 'Future', 'Gestational Age', 'Goals', 'Graduate Degree', 'Grant', 'Health', 'Healthcare', 'Healthcare Systems', 'Heart', 'Heart Diseases', 'Hospitals', 'Human Pathology', 'Incidence', 'Infant', 'Informatics', 'Institutional Review Boards', 'Insurance Carriers', 'Life', 'Liquid substance', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Necrotizing Enterocolitis', 'Neonatal', 'Neonatal Intensive Care Units', 'Neonatology', 'Outcome', 'Patent Ductus Arteriosus', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Perinatal', 'Physicians', 'Physiological', 'Population', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Premature Infant', 'Premature Labor', 'Reproducibility', 'Research', 'Research Personnel', 'Research Support', 'Rest', 'Retinopathy of Prematurity', 'Risk', 'Risk Estimate', 'Scientist', 'Sepsis', 'Side', 'Signal Transduction', 'Source', 'Structure', 'Teaching Hospitals', 'Techniques', 'Time', 'Training', 'Translating', 'Update', 'Vulnerable Populations', 'Work', 'clinical practice', 'clinical predictors', 'data resource', 'deep learning', 'deep learning algorithm', 'design', 'education planning', 'electronic data', 'experience', 'improved', 'insurance claims', 'mortality', 'peer', 'portability', 'prediction algorithm', 'predictive modeling', 'premature', 'prognostic', 'respiratory distress syndrome', 'social', 'statistics']",NHLBI,HARVARD SCHOOL OF PUBLIC HEALTH,K01,2019,166320,0.03780416712285834
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9746373,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Computer software', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,234000,0.01072845777600613
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,9885663,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Traction', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'success', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2019,206139,-0.018253864575616972
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9669002,R61AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2019,447173,0.07516579468084478
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures. In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s and Parkinson’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 35,000 researchers that use FreeSurfer through our existing open source mechanism. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner. These new capabilities well enable other studies to significantly increase their ability to detect disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately.",Deep Learning Algorithms for FreeSurfer,9971629,R56AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Architecture', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Parkinson Disease', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'autoencoder', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'morphometry', 'nervous system disorder', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R56,2019,609504,0.010522179375620293
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,0.17049955265442696
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9818000,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,489349,0.09119148860218805
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9824066,R21ES029722,"['Adult', 'Algorithms', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2019,221376,0.09838621006727359
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9769180,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,559137,0.02739855093661146
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0.05693430984617655
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,9721392,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Imagery', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2019,226659,0.0386100152842474
"An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers Abstract  Stereotactic MRI-guided online adaptive radiotherapy (SMART) is an effective treatment for the pancreas and other upper abdominal cancers. SMART allows precise delivery of escalated prescription dose to the abdominal tumor targets while avoiding the complications of radiation toxicity to the mobile gastrointestinal (GI) organs surrounding the tumor target. In the clinical workflow of SMART, manual segmentation of the GI orangs at risk (OARs) is one of the most important but also the most labor-intensive steps. Manual segmentation takes 10 minutes on average but ranges from 5 to 22 minutes. The slow and costly manual segmentation step directly decreases the accessibility and affordability of online SMART and indirectly reduces the effectiveness of SMART due to intra-fractional body and organ movement of the patients. In this study, we will develop a deep-learning based interactive and semi-automatic procedure to accurately and quickly segment the GI OARs to make SMART more efficient and affordable. Stereotactic MRI-guided online adaptive radiotherapy (SMART) has been demonstrated as an effective treatment for the pancreas and other upper abdominal cancers. For nonresectable pancreatic cancer, SMART increased the overall survival at 36 months from 18% to 55% compared to conventional radiation therapy (RT) treatment. In this study, we will develop a deep-learning based interactive and semi-automatic method to accurately and quickly segment the organs-at- risk (OAR) in the abdomen to support SMART. The method to be developed will significantly expedite the OAR segmentation step and make SMART more efficient and affordable.",An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers,9807610,R03EB028427,"['3-Dimensional', 'Abdomen', 'Affect', 'Agreement', 'Anatomy', 'Biological', 'Clinical', 'Disadvantaged', 'Dose', 'Dose-Rate', 'Duodenum', 'Effectiveness', 'Ensure', 'Exhibits', 'Goals', 'Image', 'Kidney', 'Large Intestine', 'Liver', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Minor', 'Morphologic artifacts', 'Motion', 'Movement', 'Noise', 'Organ', 'Pancreas', 'Patients', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation Toxicity', 'Radiation therapy', 'Resolution', 'Risk', 'Small Intestines', 'Stomach', 'Time', 'Toxic effect', 'Universities', 'Washington', 'base', 'computerized', 'cost', 'deep learning', 'design', 'effective therapy', 'gastrointestinal', 'imaging capabilities', 'improved', 'irradiation', 'learning strategy', 'novel', 'preservation', 'time use', 'tool', 'treatment duration', 'tumor']",NIBIB,WASHINGTON UNIVERSITY,R03,2019,89216,0.03901255160710241
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.10603590027546914
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9666310,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Epithelial', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Natural regeneration', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2019,194052,0.06155711098509985
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine No abstract available PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,10063300,U01LM012675,[' '],NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2019,375751,0.08379590455822696
"Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement ABSTRACT for Administrative Supplement: Current methods identified at late to identify pancreatic cancer are suboptimal stage resulting in a substantially unmet clinical with the majority of cases need. The current imaging approaches are often limited in spatiotemporal resolution and specificity with high inter- and intra-reader variability in radiological exams that often result in flawed evaluation in identifying pancreatic cancer. Our original grant R01EB020125 aimed to utilize UPRT nanoparticles containing IR780 dye to detect pancreatic cancer using Multispectral optoacoustic tomography (MSOT) imaging. The objective of our administrative supplement is to develop machine learning algorithms to accurately, objectively and consistently assess and distinguish pancreatic cancer versus normal pancreas as utilizing MSOT images. Building upon our experience in theranostic nanoparticles, MSOT imaging, and machine and deep learning, the focus of this supplement is to identify molecular features of pancreatic cancer using MSOT. As MSOT is a new imaging modality, interpreting its images will be challenging for medical professionals. Therefore, we will develop a computer-assisted image analysis (CAIA) system which will help physicians to interpret these images accurately and consistently, minimizing inter-reader variability. Similarly, we will develop and evaluate a machine-learning classifier to quantitatively identify pancreatic cancer. Together, these studies aim to optimize and validate our novel MSOT imaging combined with machine learning to identify pancreatic cancer. This project extends our existing grant which develops a pancreatic tumor targeted nanoparticle detectable using multispectral optoacoustic tomography to include evaluation of the images using deep learning. The deep learning algorithms will segment possible pancreatic cancer regions and identify features to characterize possible pancreatic cancer regions.",Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement,9750320,R01EB020125,"['Administrative Supplement', 'Algorithms', 'Clinical', 'Computer-Assisted Image Analysis', 'Dyes', 'Evaluation', 'Grant', 'Image', 'Image Analysis', 'Machine Learning', 'Malignant neoplasm of pancreas', 'Medical', 'Methods', 'Molecular', 'Pancreas', 'Physicians', 'Radiology Specialty', 'Reader', 'Resolution', 'Specificity', 'Systems Analysis', 'deep learning', 'experience', 'imaging approach', 'imaging modality', 'nanoparticle', 'novel', 'optoacoustic tomography', 'pancreatic neoplasm', 'spatiotemporal', 'theranostics']",NIBIB,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2018,133300,0.005376711062306669
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.0688512677836416
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9485584,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'Supervision', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2018,378183,0.07612980516015186
"A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies PROJECT SUMMARY/ABSTRACT More people die every year from kidney disease than breast or prostate cancer. Kidney transplantation is life-saving but is limited by a shortage of organ donors and an unacceptably high donor organ discard rate. The decision to use or discard a donor kidney relies heavily on manual quantitation of key microscopic findings by pathologists. A major limitation of this microscopic examination is human variability and inefficiency in interpreting the findings, resulting in potentially healthy organs being deemed unsuitable for transplantation or potentially damaged organs being transplanted inappropriately. Our team developed the first Deep Learning model capable of automatically quantifying percent global glomerulosclerosis in whole slide images of donor kidney frozen section wedge biopsies. This innovative approach has the potential to transform donor kidney biopsy evaluation by improving pathologist efficiency, accuracy, and precision ultimately resulting in optimized donor organ utilization, diminished health care costs, and improved patient outcomes. The goal of this project is to establish our Deep Learning automated quantitative evaluation as the standard practice of donor kidney evaluation prior to transplantation. This will be achieved by assembling a team of expert kidney pathologists and computer scientists specializing in machine learning. The proposal will evaluate the accuracy and precision of the computerized approach to quantifying percent global glomerulosclerosis and compare these results with current standard of care pathologist evaluation. The feasibility of deploying the Deep Learning model to analyze whole slide images on the cloud will also be examined. The end product of this STTR will be a web-based platform to securely deploy Deep Learning image analysis as a tool to assist pathologists with donor kidney biopsy evaluation. PUBLIC HEALTH RELEVANCE STATEMENT Before a kidney can be transplanted, the tissue must be assessed under a microscope to ensure the organ is healthy enough for transplant. A major limitation of microscopic examination is human variability in interpreting the findings, resulting in healthy organs being deemed unsuitable for transplantation. This funding will support developing computer algorithms to assist pathologists in microscopic examination of donor kidney tissues, resulting in more consistent and objective biopsy interpretations, minimizing discard of potentially usable kidneys and optimizing organ placement for transplant.",A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies,9678574,R41DK120253,"['Address', 'Biopsy', 'Blinded', 'Caring', 'Cessation of life', 'Charge', 'Chronic', 'Chronic Kidney Failure', 'Clinical', 'Computational algorithm', 'Computer Assisted', 'Computer software', 'Computers', 'Cost of Illness', 'Data Set', 'Ensure', 'Evaluation', 'Freezing', 'Frozen Sections', 'Funding', 'Goals', 'Health Care Costs', 'Healthcare Systems', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Transplantation', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Measures', 'Medicare', 'Microscope', 'Microscopic', 'Modeling', 'Online Systems', 'Organ', 'Organ Donor', 'Outcome', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Personal Satisfaction', 'Phase', 'Process', 'Quantitative Evaluations', 'Reproducibility', 'Research Personnel', 'Savings', 'Scientist', 'Secure', 'Slide', 'Small Business Technology Transfer Research', 'Speed', 'Testing', 'Time', 'Tissues', 'Translating', 'Transplantation', 'Transplanted tissue', 'Universities', 'Washington', 'Work', 'base', 'clinical practice', 'cloud based', 'commercial application', 'computerized', 'deep learning', 'digital', 'glomerulosclerosis', 'improved', 'innovation', 'learning network', 'malignant breast neoplasm', 'meetings', 'power analysis', 'predictive modeling', 'public health relevance', 'software development', 'standard of care', 'technological innovation', 'tool', 'whole slide imaging']",NIDDK,"NEWVENTUREIQ, LLC",R41,2018,214009,0.0690054736377305
"Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data NARRATIVE SUMMARY The landscape of data formats is rapidly expanding, with image, text and other complex formats becoming available for health related outcomes. By considering such data within the context of observational causal inference, they can be leveraged to improve clinical decisions, help evaluate treatment efficacy by estimating individualized treatment effects and help develop intelligent therapeutic systems where individualized treatments can be deployed. In R01EB025021, we concentrate on understanding how nearly exact matching can be achieved in the presence of a large number of categorical covariates. The proposed approach (called FLAME - Fast Large Almost Matching Exactly) is able to quickly learn which categorical covariates are important and to produce high quality matches \citep{wang2017flame,dieng2018collapsing}. The main shortfall in the proposed work for R01EB025021 is that it does not naturally extend to more complex data types, it only works for categorical data in which each feature is meaningful. {\bf This proposal will develop new statistical and computational tools for causal analysis of complex data structures.} Our new approach is called {\emph Matching After Learning to Stretch (MALTS)}. For each unit (e.g. patient), we propose learn a latent representation of their covariate information and a distance metric on the latent space such that units that are matched tend to provide accurate estimates of treatment effect. MALTS can use deep learning to encode the latent representations for the units, or it can learn basis transformations in linear space (stretching and rotation matrices) for simpler continuous data types. We will develop the MALTS algorithm, and apply it in a medical context. Our goal is to construct high quality matches for the following types of data: (i) medical images, such as x-rays and CT scans, (ii) medical record data, (iii) time series data (continuous EEG data), (iv) a combination of any of the first three types of data. We aim to leverage the newly developed tools to continue our evaluation of the efficacy of isolation for flu-like ailments as well as to apply them more broadly to publicly available modern datasets such as the MIMIC III database. Reliable and consistent causal analysis of public health interventions requires the use of massive previously unavailable datastreams. For example, evaluation of the efficacy of isolation interventions on flu-like-illness spread must include information on friendships and interactions between individuals, biometric information, imaging, longitudinal health record data as well as standard demographic data. The proposed research provides machine learning and deep learning tools for properly employing this data for the identification and quantification of causal effects of such treatments that can lead to the development of better public health interventions.",Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data,9750434,R01EB025021,"['Algorithms', 'Biometry', 'Categories', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Electroencephalography', 'Friendships', 'Goals', 'Health', 'Image', 'Individual', 'Intervention', 'Lead', 'Learning', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Modernization', 'Outcome', 'Patients', 'Research', 'Roentgen Rays', 'Rotation', 'Series', 'Stretching', 'Structure', 'System', 'Text', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'X-Ray Computed Tomography', 'computerized tools', 'data format', 'deep learning', 'efficacy evaluation', 'flu', 'health record', 'improved', 'individualized medicine', 'novel strategies', 'public health intervention', 'tool', 'treatment effect']",NIBIB,DUKE UNIVERSITY,R01,2018,98714,0.05133420359710688
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9527181,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,545116,0.0950815576173261
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9586688,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Biological Neural Networks', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Dose', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2018,221250,0.016038004976802456
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,0.012625630760196502
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,-0.008839630478157555
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9475340,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'deep learning', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2018,27175,0.04595159723463659
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Project​ ​Summary/Abstract This​ ​SBIR​ ​Phase​ ​I​ ​project​ ​will​ ​develop​ ​a​ ​deep​ ​learning-based​ ​clinical​ ​decision​ ​support​ ​algorithm for​ ​identifying​ ​aortic​ ​stenosis​ ​from​ ​heart​ ​sounds​ ​recorded​ ​using​ ​the​ ​Eko​ ​Core​ ​Digital Stethoscope.​ ​This​ ​screening​ ​tool​ ​will​ ​help​ ​to​ ​decrease​ ​the​ ​number​ ​of​ ​patients​ ​with​ ​severe asymptomatic​ ​aortic​ ​stenosis​ ​that​ ​remain​ ​undertreated​ ​simply​ ​because​ ​the​ ​condition​ ​is​ ​not diagnosed.​ ​Auscultation​ ​is​ ​commonly​ ​the​ ​method​ ​by​ ​which​ ​valvular​ ​heart​ ​disease​ ​is​ ​first detected,​ ​but​ ​cases​ ​often​ ​fail​ ​to​ ​be​ ​referred​ ​to​ ​echocardiography​ ​for​ ​diagnosis​ ​because clinicians​ ​fail​ ​to​ ​detect​ ​heart​ ​murmurs,​ ​particularly​ ​in​ ​noisy​ ​or​ ​rushed​ ​environments.​ ​To​ ​address this​ ​challenge,​ ​Eko​ ​had​ ​developed​ ​the​ ​Core,​ ​a​ ​digital​ ​stethoscope​ ​attachment​ ​that​ ​can​ ​be​ ​added in-line​ ​to​ ​a​ ​clinician’s​ ​existing​ ​stethoscope​ ​that​ ​amplifies​ ​heart​ ​sounds​ ​and​ ​streams​ ​digitized phonocardiograms​ ​to​ ​a​ ​smartphone,​ ​tablet​ ​or​ ​personal​ ​computer.​ ​There,​ ​the​ ​signal​ ​can​ ​be analyzed​ ​with​ ​the​ ​decision​ ​support​ ​algorithm​ ​we​ ​will​ ​develop​ ​as​ ​part​ ​of​ ​this​ ​project.​ ​The​ ​specific aims​ ​of​ ​this​ ​study​ ​are​ ​(1)​ ​to​ ​​collect​ ​a​ ​database​ ​with​ ​condition-specific​ ​recording​ ​labels​ ​to enable​ ​deep​ ​learning​ ​for​ ​heart​ ​sounds​ ​though​ ​clinical​ ​data​ ​collection​ ​at​ ​UCSF​ ​and​ ​(2)​ ​to develop​ ​and​ ​evaluate​ ​a​ ​deep​ ​convolutional​ ​neural​ ​network-based​ ​algorithm​ ​trained​ ​on​ ​the database.​ ​By​ ​integrating​ ​this​ ​deep​ ​learning​ ​algorithm​ ​into​ ​Eko’s​ ​mobile​ ​and​ ​cloud​ ​software platform,​ ​currently​ ​used​ ​by​ ​clinicians​ ​at​ ​over​ ​700​ ​institutions​ ​worldwide,​ ​we​ ​anticipate​ ​this algorithm​ ​will​ ​enable​ ​more​ ​accurate​ ​screening​ ​for​ ​aortic​ ​stenosis,​ ​leading​ ​to​ ​earlier​ ​diagnosis and​ ​better​ ​patient​ ​outcomes. SBIR​ ​Project​ ​Narrative Valvular​ ​heart​ ​disease,​ ​and​ ​aortic​ ​stenosis​ ​in​ ​particular,​ ​are​ ​becoming​ ​increasingly​ ​prevalent manifestations​ ​of​ ​poor​ ​cardiovascular​ ​health​ ​in​ ​both​ ​the​ ​developed​ ​and​ ​developing​ ​world.​ ​A highly-accurate​ ​clinical​ ​decision​ ​support​ ​algorithm​ ​that​ ​is​ ​able​ ​to​ ​detect​ ​aortic​ ​stenosis​ ​will impact​ ​public​ ​health​ ​by​ ​reducing​ ​unnecessary​ ​referrals​ ​for​ ​echocardiography​ ​and​ ​promoting early​ ​and​ ​accurate​ ​diagnosis​ ​in​ ​underserved​ ​areas​ ​with​ ​limited​ ​access​ ​to​ ​subspecialty​ ​care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,9621223,R43HL144297,"['Address', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Benign', 'Biological Neural Networks', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Data Collection', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Environment', 'Evaluation', 'FDA approved', 'Future', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Heart Abnormalities', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Hospitals', 'Human', 'Image', 'Imaging Techniques', 'Institution', 'Label', 'Learning', 'Medical Device', 'Medicare', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Monitor', 'Network-based', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physicians', 'Positioning Attribute', 'Public Health', 'Resources', 'Screening procedure', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Tablet Computer', 'Testing', 'Training', 'Weight', 'accurate diagnosis', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinically significant', 'cloud software', 'commercialization', 'cost', 'deep learning', 'deep neural network', 'diagnosis standard', 'digital', 'innovation', 'screening', 'speech recognition']",NHLBI,"EKO DEVICES, INC.",R43,2018,295881,0.06904228909452303
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9724174,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,24598,0.07516579468084478
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9526090,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,399482,0.07516579468084478
"Deep learning enhanced seizure monitoring from wearable sensors Deep learning enhanced seizure monitoring from wearable sensors Over 1 million patients in the United States have uncontrolled epilepsy despite ongoing medical therapy. When seizures are prolonged or violent, there is significant risk of injury or even Sudden Unexpected Death of Epilepsy (SUDEP) which occurs in approximately 1 in 500 patients per year. Novel seizure monitoring could help alleviate this burden. Our research team has created a software application, EpiWatch, to capture different sensor measurements related to seizure activity such as convulsions (accelerometers), heart rate increases (photo- plethysmography-PPG), and unresponsiveness to behavioral prompting (interactive user interface). Our hope is to offer accurate seizure detection with improved false positive performance to encourage usage. Our team proposes to develop multi-modal sensor analysis driven by deep learning technology to enhance seizure monitoring. We are uniquely positioned to accelerate development by leveraging our team’s prior EpiWatch IRB approved study which generated over 6,000 hours of sensor data. In Phase I, we will teach EpiWatch how to read time series sensor data and how to discriminate seizure activity. EpiWatch will employ a convolutional neural network, a technique rooted in deep learning, to self-characterize seizure features from labeled sensor data. In order to infer additional information from vast amounts of unlabeled sensor data from US epilepsy patients, EpiWatch will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of EpiWatch will test its ability to identify the presence of seizures in a prospective new cohort of epilepsy patients. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact. Our goal is to combine recent advances in deep learning and scalable parallel computing to create EpiWatch. In the long term, we hope this monitoring technology will aid epilepsy patient management and improve outcomes. PROJECT NARRATIVE Recurring seizures are disabling, dangerous, and often limit independence. We are developing novel seizure detection using a consumer friendly device with wearable sensors (EpiWatch) to enable monitoring and emergency alerting for seizures that occur without warning (~50% of all seizures) and without witnesses, especially when they are prolonged (> 5 min) or accompanied by cardiac arrhythmias responsible for SUDEP (Sudden Unexpected Death with Epilepsy), a 1 in 500 annual risk for patients with uncontrolled seizures. If emergency care can be summoned under these circumstances, patients can live more safely and independently, in turn encouraging app usage. When integrated with current disease monitoring activities, EpiWatch will have the long range impact of providing a unique platform for individualized epilepsy care.",Deep learning enhanced seizure monitoring from wearable sensors,9622338,R43NS108905,"['Accelerometer', 'Apple', 'Arrhythmia', 'Behavioral', 'Biological Neural Networks', 'Biosensor', 'Caregivers', 'Caring', 'Cessation of life', 'Computer software', 'Consent', 'Convulsions', 'Dangerousness', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Emergency Care', 'Emergency Situation', 'Epilepsy', 'Event', 'Goals', 'Gold', 'Heart Rate', 'Hospitals', 'Hour', 'Injury', 'Institutional Review Boards', 'Label', 'Learning', 'Measurement', 'Medical', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Network-based', 'Neural Network Simulation', 'Neurologist', 'Outcome', 'Outpatients', 'Patient Monitoring', 'Patient Self-Report', 'Patient risk', 'Patients', 'Performance', 'Phase', 'Photoplethysmography', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Refractory', 'Research', 'Risk', 'Seizures', 'Series', 'Signal Transduction', 'Supervision', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Translating', 'United States', 'Violence', 'Work', 'clinical translation', 'cohort', 'computing resources', 'deep learning', 'improved', 'improved outcome', 'insight', 'novel', 'parallel computer', 'prospective', 'response', 'sensor', 'wearable device']",NINDS,"VIGILANT MEDICAL, INC.",R43,2018,238872,0.07627272463079836
"Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy Project Summary We propose to introduce and optimize a new method of radiomics extraction via transfer learning with deep convolutional neural networks (CNNs) and to compare it to the conventional segmentation-based radiomics approach on breast dynamic contrast-enhanced magnetic resonance images (DCE-MRIs). The field of breast radiomics has been expanding fast, with many clinical conclusions being successfully derived from medical images using qualitative analysis. In the past couple of years, deep learning has experienced explosive growth in image recognition, easily solving complex problems. Deep CNNs achieve remarkable classification results on everyday image datasets. We propose to investigate the utility of deep neural networks with regards to the medical image datasets, specifically on the breast DCE-MRI dataset. Given the relatively small sizes of these datasets, CNNs previously trained on non-medical images will be utilized for clinical classifications as feature extractors. We will investigate multiple parameters involved in the CNN feature extraction methodology and their effect on classification performance. Two clinical tasks will be studied under the proposed research: 1) malignancy assessment and 2) response to therapy prediction. The optimized CNN method will be compared to and combined with the conventional segmentation- based radiomics method. Furthermore, we aim to investigate the robustness of the segmentation-based features across MR scanners of different manufacturers. The first aim of the proposed research will study the robustness of the segmentation- based features extracted from images acquired on MR scanners of two different manufacturers. The robustness will be investigated under four clinical tasks, such as lymph node involvement and receptor statuses. The second aim will be focused on optimization of CNN feature extraction and subsequent classifier design. Lastly, under the third aim we will compare and combine the CNN and segmentation-based radiomics in the classification tasks of malignancy assessment and response to therapy prediction. Project Narrative The goal of the proposed research is to improve breast cancer diagnosis and prognosis based on dynamic contrast-enhanced magnetic resonance images by introducing novel deep learning methods to medical image classification and combining it with the conventional radiomics systems. The incredible power of deep learning methods to classify everyday images shows great promise to make predictions based on medical image datasets. Our thorough investigation of deep learning methods and their combination with conventional radiomics methods has potential to improve breast cancer management.",Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy,9469826,F31CA221193,"['Benign', 'Biological Neural Networks', 'Breast', 'Cancer Prognosis', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Complex', 'Computers', 'Data', 'Data Set', 'Effectiveness', 'Evaluation', 'Goals', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intuition', 'Investigation', 'Lesion', 'Lymph Node Involvement', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical Imaging', 'Methodology', 'Methods', 'Nature', 'Neoadjuvant Therapy', 'Performance', 'Prediction of Response to Therapy', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Research', 'Standardization', 'System', 'Techniques', 'Training', 'Variant', 'base', 'breast cancer diagnosis', 'chemotherapy', 'computerized', 'contrast enhanced', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'learning strategy', 'malignant breast neoplasm', 'novel', 'radiomics', 'receptor', 'response']",NCI,UNIVERSITY OF CHICAGO,F31,2018,26048,-0.012830359559684128
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9574149,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,579883,0.02739855093661146
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More No abstract available The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9608820,R44MH115523,"['Address', 'Applications Grants', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2018,441001,0.031991086786946246
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Supplement Title: Deep learning-based methods for PET image reconstruction and segmentation to enhance radionuclide therapy dosimetry Abstract There is much recent interest in quantitative imaging of yttrium-90 (Y-90) for dosimetry because of the promise of novel Y-90 labelled radionuclide therapies. Deep learning methods are well suited for addressing the challenges of Y-90 positron emission tomography (PET) imaging, where compared with diagnostic FDG PET, true coincidence count-rates are very low while random coincidences are high. The potential of deep learning-based algorithms to outperform conventional algorithms in medical imaging is well recognized, however research in applying these methods to nuclear medicine imaging modalities such as PET is very limited. The few studies applying deep learning to PET imaging have been mostly limited to post-reconstruction image processing/analysis for denoising and feature extraction, and not in the image formation/reconstruction process. Additionally, deep learning research in PET thus far have focused on improving diagnostic imaging, not quantitative imaging, which together with accurate lesion/organ segmentation are pre-requisite for accurate dosimetry. In this supplement, we propose to develop and evaluate deep learning-based image reconstruction and lesion/organ segmentation for low count PET applications such as Y-90 PET. Our approach starts with the raw projection data and utilizes a deep recurrent network in the image formation process. Because the two tasks are mutually dependent, our formalism takes the novel approach of joint reconstruction-segmentation with multi-modality (PET/CT) data. Specifically, we will 1) develop and evaluate Y-90 PET image reconstruction with a deep recurrent network for the regularizer, 2) develop and evaluate deep-learning based joint PET segmentation-reconstruction using multi- modal 90Y PET/CT data. To train/validate/test the proposed methods, we will use clinically realistic phantom measurements and simulations as well as leverage on existing patient data from the parent grant where thus far, PET data and radiologist defined morphologic liver/lesion contours for over 50 cases and 150 lesions are available. We will compare the new Y-90 PET reconstruction with the formulation we recently developed under the parent grant (using conventional untrained regularizers) that showed promising results but suffered from resolution- noise tradeoff. The expected outcome of this work is a well validated deep learning reconstruction- segmentation framework for challenging PET imaging applications where conventional methods are suboptimal. The proposed research is expected to result in new and accurate tools for quantitative image reconstruction and lesion/organ segmentation that have the potential to contribute significantly toward improving dosimetry in internal radionuclide therapy such as Yttrium- 90 radioembolization in liver malignancies. This study is relevant to public health because a dosimetry-guided personalized approach to radionuclide therapy is highly likely to substantially improve patient outcomes compared to current standard practice. !",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,9750430,R01EB022075,"['90Y', 'Address', 'Algorithms', 'Clinical', 'Data', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Formulation', 'Image', 'Joint repair', 'Joints', 'Label', 'Lesion', 'Liver', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Morphology', 'Noise', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Positron-Emission Tomography', 'Process', 'Public Health', 'Radioembolization', 'Radionuclide therapy', 'Recurrence', 'Research', 'Resolution', 'Testing', 'Training', 'Work', 'base', 'deep learning', 'dosimetry', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'interest', 'learning strategy', 'novel', 'novel strategies', 'parent grant', 'personalized approach', 'personalized cancer therapy', 'quantitative imaging', 'radiologist', 'reconstruction', 'simulation', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,102093,0.032861277573304905
"Structure-based prediction of the interactome Supplement Summary “Structure-based prediction of the interactome” NIH R01GM081871-10 PI: Bonnie Berger We have designed and implemented a system for privacy-preserving and scalable sharing of drug-target interaction data (Aim 1, under review at Science), where we required GPUs to run our protocol, discover and experimentally validate novel drug-target interactions and will make our software publicly-available for academic and non-profit use (Aim 3). At the same time, we have presented a novel loss function for training classifiers from positive and unlabeled data and developed a software pipeline, Topaz, which uses convolutional neural networks trained with few positive examples for protein detection (Aim 2, RECOMB 2018). We are now developing new deep learning models for protein structure embedding and extending the Topaz framework to learn a general deep learning model of protein images from multiple cryo-EM micrograph datasets. Our continued progress on these projects is significantly jeopardized by our lack of GPU compute power. While in the last year we have purchased a compute node with four GPUs, we are continually frustrated by wait-times and inability to try different models and hyperparameters. Thus, we are requesting an additional node with eight GPUs to enable us to reach the broader goals of our grant. Narrative The interactions of small molecules with proteins are omnipresent throughout cellular processes and of fundamental importance to drug design and disease treatment, yet the task of predicting these interactions brings major challenges because of the heterogeneity and proprietary nature of the data. Here, we develop new mathematical methods and software that can address not only interpreting the data itself, but also the collaborative and generative process through which researchers work: new cryptographic tools can enable unprecedented forms of secure sharing and collaboration between industry and the public, and deep learning can accelerate the drug discovery process.",Structure-based prediction of the interactome,9703262,R01GM081871,"['Address', 'Biological Neural Networks', 'Cell physiology', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Detection', 'Disease', 'Drug Design', 'Drug Targeting', 'Goals', 'Grant', 'Heterogeneity', 'Image', 'Industry', 'Learning', 'Modeling', 'Nature', 'Privacy', 'Process', 'Proteins', 'Protocols documentation', 'Research Personnel', 'Running', 'Science', 'Secure', 'Structure', 'System', 'Time', 'Topaz', 'Training', 'United States National Institutes of Health', 'Wait Time', 'Work', 'base', 'cryptography', 'deep learning', 'design', 'drug discovery', 'loss of function', 'mathematical methods', 'new therapeutic target', 'novel', 'protein structure', 'small molecule', 'tool']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2018,83700,-0.021421836189378346
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9403171,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Learning', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,548068,0.0950815576173261
"Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction   PROJECT  SUMMARY  Heart failure (HF) is a highly disabling and costly disease with a high mortality rate. In the pre­diagnostic phase  (i.e.,  12­36  months  before  diagnosis),  HF  is  difficult  to  detect  given  the  insidious  signs  and  symptoms.  After  diagnosis,  where  it  is not possible to reverse disease progression, efforts are made to avoid hospital admission  and  re­admission,  but  with  limited  capabilities  to  stratify  patients  by  risk.  We  propose  to  develop  interpretable  deep learning models applied to large­scale electronic health record (EHR) data to detect HF related events on  two  different  time  scales.  One  set  of  models will be developed to detect HF diagnosis one to two years before  actual  documented  diagnosis.  Separately,  we  propose  to  identify  HF  patients  who  are  at  risk  of  hospital  admission  and  readmission . The project focuses on developing deep learning models that offer the potential for  greater  accuracy,  clinical  interpretability,  and  utility  than  alternatives.  The  expected  deliverables  include  comprehensive  software  for  creating  deep  learning  algorithms  that  predict  HF  outcomes  and  related  software  tools  for  model  visualization.           PROJECT NARRATIVE Deep learning has shown tremendous success in many domains but is yet to have similar impact in health care. The key challenges in healthcare applications are the lack of interpretation for deep learning models and limited transferability of the models across institutions. We develop interpretable deep learning algorithms for heart failure prediction that can handle large longitudinal patient records and are able to adapt across institutions.",Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction,9544376,R56HL138415,"['Accounting', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Biological Neural Networks', 'Caring', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer software', 'Cost of Illness', 'Data', 'Decision Trees', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease Progression', 'E-learning', 'Early Diagnosis', 'Electronic Health Record', 'Event', 'Future', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'Hospitals', 'Image', 'Imagery', 'Individual', 'Influentials', 'Inpatients', 'Institution', 'Intuition', 'Learning', 'Logistic Regressions', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Outcome', 'Output', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Procedures', 'Records', 'Recurrence', 'Research', 'Risk', 'Risk Factors', 'Signs and Symptoms', 'Software Tools', 'Structure', 'System', 'Time', 'Translating', 'Work', 'base', 'clinical care', 'clinical risk', 'health application', 'high dimensionality', 'improved', 'individual patient', 'interest', 'interoperability', 'learning strategy', 'mortality', 'parallel computer', 'patient stratification', 'prediction algorithm', 'predictive modeling', 'relating to nervous system', 'success']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R56,2017,756093,0.1328184759893603
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9371358,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Learning', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2017,222279,0.04595159723463659
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8689173,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2014,202714,0.07466659207995395
"Scalable Biomedical Pattern Recognition Via Deep Learning DESCRIPTION (provided by applicant): Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.  The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is  being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.  Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.  In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes. Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,9302040,R21LM011664,[' '],NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2014,7696,0.07466659207995395
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8566062,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2013,175500,0.07466659207995395
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,9976348,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2020,529154,0.09893833683527671
"Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study PROJECT SUMMARY Road traffic injuries are a major contributor to the burden of disease globally with nearly 1.3 million deaths globally and as many as 50 million injured annually with pedestrians and cyclists in low and middle-income countries (LMICs) among the most affected. Road infrastructure of the built environment (e.g., sidewalks), neighborhood design (e.g., street connectivity) and urban development (e.g., urban sprawl) are key determinants of the risk of pedestrian injuries. In LMICs, poor road infrastructure and neighborhood design are acknowledged as being important contributors to rising numbers of road traffic injuries and deaths, but there are few studies systematically identifying and quantifying what specific features of the built environment are contributing to motor vehicle collisions in these settings. Within LMIC cities, there are often large disparities where infrastructure is improved that reflect socioeconomic characteristics, leading to health inequities in road traffic injury. The paucity of georeferenced data on the built environment in LMICs has made research on road traffic injuries more difficult, though recent advances in computer vision and image analysis combined with Big Data of publicly available, georeferenced, images of roads worldwide (e.g., Google Street View, GSV) can help overcome the paucity of data and the cost and time limitations of collecting and analyzing data on the built environment in LMICs. Automated image analysis has largely been made possible via deep learning, a subfield of artificial intelligence and machine learning and relies on training neural networks to detect and label specific objects within images. These methods can drastically reduce the barriers to citywide built environment and traffic safety research in LMIC cities, thus substantially increasing research capacity and generalizability. My career goal is to become an independent investigator in global urban health with a focus on road safety and the built environment in LMICs. I propose undertaking research and training in deep learning methods applied to public health in the setting of Bogota, Colombia: 1) Develop neural networks to create a database of BE features of the road infrastructure from image data and to create neighborhood typologies from those features; 2) Assess the association between neighborhood-level BE features and typologies and pedestrian collisions and fatalities and road safety perceptions; 3) Assess the association of neighborhood social environment characteristics with pedestrian collision and fatalities, perceptions, and BE features and typologies. I am seeking additional training in 1) developing competency in deep learning methods applied to public health; 2) creating neighborhood indictors and typologies of health and the built environment; 3) applying Bayesian spatiotemporal models to understand how neighborhood characteristics and typologies influence health; 4) develop skills in multi-country collaboration, grant writing and overseeing research projects in LMICs. PROJECT NARRATIVE Roads and neighborhoods with a built environment that support safe and active transportation are a major priority in low- and middle-income countries (LMICs) due to 90% of road traffic deaths occurring in these locations, especially to pedestrians and other vulnerable road users, yet data on key built environment features at a large scale are not always readily available in these settings. My career goal is to improve population health by examining the effects of the built environment and transportation on health through the adoption and use of methods that can leverage Big Data sources and answer complex, multilevel research questions by overcoming the lack of built environment data in LMICs. The proposed research uses deep learning and advanced statistical methods to create a citywide dataset of built and social environment features in Bogota, Colombia that will provide crucial data to answer questions of their impact on pedestrian injuries and deaths, as well as assessing the presence of health inequities in their distribution and that will lay the groundwork to expand these efforts to more cities in Latin America and other LMICs.","Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study",10123391,K01TW011782,"['Adopted', 'Adoption', 'Affect', 'Artificial Intelligence', 'Big Data', 'Cessation of life', 'Characteristics', 'Cities', 'Classification', 'Collaborations', 'Colombia', 'Competence', 'Complex', 'Computer Vision Systems', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Discipline', 'Education', 'Future', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Injury', 'Label', 'Latin America', 'Lead', 'Location', 'Machine Learning', 'Mathematics', 'Mentors', 'Methods', 'Modeling', 'Neighborhoods', 'Perception', 'Persons', 'Public Health', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Risk', 'Safety', 'Social Environment', 'Statistical Methods', 'Time', 'Training', 'Transportation', 'Typology', 'Urban Developments', 'Urban Health', 'Vehicle crash', 'Writing', 'automated image analysis', 'built environment', 'burden of illness', 'career', 'career development', 'computer science', 'cost', 'data infrastructure', 'deep learning', 'design', 'digital imaging', 'experience', 'high risk', 'improved', 'injured', 'learning strategy', 'low and middle-income countries', 'neighborhood association', 'neural network', 'pedestrian injury', 'population health', 'skills', 'social', 'socioeconomics', 'spatiotemporal', 'virtual']",FIC,DREXEL UNIVERSITY,K01,2020,138024,0.0534433370612691
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,9968604,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2020,80500,0.05568216194445616
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,10000961,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2020,702450,-0.031120397127118584
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.07469011405053794
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9979659,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'MeSH Thesaurus', 'Measures', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'large scale data', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'public repository', 'specific biomarkers']",NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2020,467177,0.0950815576173261
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,0.18090003713752667
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9925232,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2020,378183,0.07612980516015186
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,9868507,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'tool']",NEI,DUKE UNIVERSITY,K23,2020,195131,0.05171484353826268
"A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies ABSTRACT More people die every year from kidney disease than breast or prostate cancer. Kidney transplantation is life-saving, yet the donor organ shortage and high organ discard rate contributes to 13 deaths daily among patients awaiting transplant. The decision to use or discard a donor kidney relies heavily on microscopic quantitation of chronic damage by pathologists. The current standard of care relies on a manual process that is subject to significant human variability and inefficiency, resulting in potentially healthy kidneys being discarded and potentially damaged kidneys being transplanted inappropriately. Our team developed the first Deep Learning model to quantify percent global glomerulosclerosis in donor kidney frozen section biopsy whole slide images. We developed a cloud-based platform to apply the Deep Learning model to analyze kidney biopsy whole slide images in under 6 minutes with accuracy and precision equal to or greater than current standard of care pathologists. We have also developed a Deep Learning model to quantify interstitial fibrosis on donor kidney biopsy whole slide images. This innovative approach has the potential to transform donor kidney biopsy evaluation by improving pathologist efficiency, accuracy, and precision ultimately resulting in optimized donor organ utilization, improved patient outcomes, and diminished health care costs. The goal of this project is to establish our Deep Learning automated techniques as the standard for evaluating donor kidneys prior to transplantation. This will be achieved by assembling a team of expert pathologists and computer scientists specializing in machine learning. The proposal will evaluate the accuracy and precision of the interstitial fibrosis Deep Learning model, use the automated quantitation of key microscopic findings to develop an outcome-based chronic damage score that predicts graft outcome, and test the ability of the Deep Learning models to withstand variations encountered using different scanners and processing in different laboratories. The functionality of the Trusted Kidney software platform will be improved beyond the current usable product into a commercially viable solution for multiple laboratories. PUBLIC HEALTH RELEVANCE STATEMENT Before kidneys can be transplanted, they must be examined using a microscope to ensure the kidney is healthy enough for transplant. A limitation of microscopic examination by pathologists is the inherent human variability in quantifying the amount of scar tissue, or chronic damage, present. The result is potentially healthy organs being discarded or damaged kidneys being used inappropriately. This funding will support developing artificial intelligence tools to assist pathologists with quantifying scar tissue in donor kidneys prior to transplantation, resulting in more consistent and objective biopsy evaluations, minimizing discard of potentially healthy kidneys, and optimizing placement of kidneys for transplant.",A Deep Learning Model to Improve Pathologist Interpretation of Donor Kidney Biopsies,10138826,R42DK120253,"['Adoption', 'Americas', 'Artificial Intelligence', 'Biopsy', 'Canada', 'Cessation of life', 'Chronic', 'Cicatrix', 'Clinical', 'Computer software', 'Computers', 'Contracts', 'Data', 'Databases', 'Development', 'Ensure', 'Evaluation', 'Fast Healthcare Interoperability Resources', 'Fibrosis', 'Frozen Sections', 'Funding', 'Goals', 'Gold', 'Graft Survival', 'Health Care Costs', 'Human', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Transplantation', 'Knowledge', 'Laboratories', 'Letters', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Measurement', 'Microscope', 'Microscopic', 'Midwestern United States', 'Modeling', 'Multivariate Analysis', 'Online Systems', 'Organ', 'Organ Donor', 'Organ Procurements', 'Outcome', 'Pathologist', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Satisfaction', 'Phase', 'Process', 'Reproducibility of Results', 'Research Personnel', 'Savings', 'Scanning', 'Scientist', 'Secure', 'Services', 'Slide', 'Small Business Technology Transfer Research', 'Specialist', 'Speed', 'System', 'Techniques', 'Testing', 'Tissues', 'Transplantation', 'Trichrome stain', 'Trichrome stain method', 'Trust', 'United Network for Organ Sharing', 'Universities', 'Variant', 'Washington', 'Work', 'analytical tool', 'base', 'clinical biomarkers', 'cloud based', 'cloud platform', 'commercial application', 'cost', 'deep learning', 'functional improvement', 'glomerulosclerosis', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'interstitial', 'kidney biopsy', 'learning strategy', 'malignant breast neoplasm', 'pathology imaging', 'phase 1 study', 'predictive modeling', 'public health relevance', 'renal damage', 'shared database', 'standard of care', 'technological innovation', 'tool', 'whole slide imaging']",NIDDK,"NEWVENTUREIQ, LLC",R42,2020,811695,0.0945855198643607
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.04006030619557697
"Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning RESEARCH SUMMARY The goal of this award is to provide Andrew Beam, PhD with research support and comprehensive mentoring designed to transition him to an independent investigator in perinatal and neonatal informatics. Preterm labor (PTL) is labor which occurs before 37 weeks of gestation and carries with it enormous health and financial consequences. Preterm infants have some of the highest levels of pulmonary and cardiac morbidity, yet machine-learning techniques for these important outcomes remains under developed. The research strategy is focused developing predictive models for two very important clinical scenarios using large sources of existing healthcare data. The focus of Specific Aim 1 develops a new form of machine learning known as deep learning for predicting PTL in pregnant women, while the focus of Specific Aim 2 investigates the use of deep learning for predicting clinical trajectories of preterm infants in the NICU. Currently, management and anticipation of both clinical scenarios is challenging and advancement in our predictive capacity could dramatically improve the quality and efficiency of the healthcare system. These models will be built using an existing database of 50 million patient-lives obtained through a partnership with a major US health insurer. Specific Aim 3 seeks to understand how the models constructed using this unique data resource translate and generalize to data from the electronic health records of Boston-area hospitals, which is a key concern for all healthcare data scientists. The education plan focuses on augmenting Dr. Beam’s graduate degrees in statistics and bioinformatics with additional training in clinical medicine and human pathology. This additional education will grant Dr. Beam a deeper understanding of the clinical problems faced by these populations and will allow for more fluid collaborations with clinicians in the future. The composition of Dr. Beam’s mentorship committee, which includes expertise in neonatology, biostatistics, and translational informatics, reflects his long-term desire to be quantitative scientist who works side-by-side practicing physicians so that quantitative research is translated into impactful clinical practice. PROJECT NARRATIVE Infants born prematurely experience some of the highest levels of pulmonary and cardiac morbidity and are among the most expensive patients in all of pediatrics. Now, with the availability of large sources of healthcare data from insurance claims databases and electronic health records, there is an opportunity to better understand prematurity and its predictors using computational techniques. We propose leveraging state of the art deep learning models built using data from hospitals and insurers to both predict which pregnancies will result in preterm birth and to predict which preterm infants will experience severe cardiac and pulmonary morbidity.",Predicting Pulmonary and Cardiac Morbidity in Preterm Infants with Deep Learning,9850130,K01HL141771,"['37 weeks gestation', 'Accounting', 'Acute Disease', 'Address', 'Adverse event', 'Affect', 'Area', 'Award', 'Big Data', 'Bioinformatics', 'Biometry', 'Birth', 'Birth Weight', 'Boston', 'Bronchopulmonary Dysplasia', 'Cardiac', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Collaborations', 'Computational Technique', 'Conceptions', 'Data', 'Data Analyses', 'Data Scientist', 'Data Sources', 'Databases', 'Diagnosis', 'Doctor of Philosophy', 'Education', 'Electronic Health Record', 'Environment', 'Event', 'Future', 'Gestational Age', 'Goals', 'Graduate Degree', 'Grant', 'Health', 'Healthcare', 'Healthcare Systems', 'Heart', 'Heart Diseases', 'Hospitals', 'Human Pathology', 'Incidence', 'Infant', 'Informatics', 'Institutional Review Boards', 'Insurance Carriers', 'Life', 'Liquid substance', 'Lung', 'Lung diseases', 'Machine Learning', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Necrotizing Enterocolitis', 'Neonatal', 'Neonatal Intensive Care Units', 'Neonatology', 'Outcome', 'Patent Ductus Arteriosus', 'Patients', 'Pattern', 'Pediatrics', 'Performance', 'Perinatal', 'Physicians', 'Physiological', 'Population', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Premature Infant', 'Premature Labor', 'Reproducibility', 'Research', 'Research Personnel', 'Research Support', 'Rest', 'Retinopathy of Prematurity', 'Risk', 'Risk Estimate', 'Scientist', 'Sepsis', 'Side', 'Signal Transduction', 'Source', 'Teaching Hospitals', 'Techniques', 'Time', 'Training', 'Translating', 'Update', 'Vulnerable Populations', 'Work', 'clinical practice', 'clinical predictors', 'data resource', 'deep learning', 'deep learning algorithm', 'design', 'education planning', 'electronic data', 'experience', 'improved', 'insurance claims', 'mortality', 'peer', 'portability', 'prediction algorithm', 'predictive modeling', 'premature', 'prognostic', 'respiratory distress syndrome', 'social', 'statistical and machine learning', 'statistics', 'structured data']",NHLBI,HARVARD SCHOOL OF PUBLIC HEALTH,K01,2020,166320,0.03780416712285834
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,9864905,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,400056,0.09681027108024788
"Personalized Deep Learning Models of Rapid Changes in Major Depressive Disorder Symptoms using Passive Sensor Data from Smartphones and Wearable Devices ABSTRACT Major depressive disorder (MDD) is highly prevalent and the leading cause of global disease burden. Associated with over 1,000 different symptom profiles, MDD is highly heterogeneous. The majority of MDD symptom change occurs across hours. Consequently, there is a need to increasingly focus MDD research on personalized assessment of these rapid symptom fluctuations. To date, personalized models of MDD have shown promise, but relied solely on self-report measures. There is thus a critical need to develop personalized models of MDD that incorporate objective signals. Passively collected information from smartphones and wearable sensors can continuously and unobtrusively track behavioral and physiological signals related to core disturbances associated with MDD, including psychomotor retardation, sleep disturbances, social contact, behavioral activation, heart rate variability, and screen time. Preliminary data suggest that personalized artificial intelligence (i.e., personally weighted deep learning models) are well suited for creating novel personalized digital biomarkers of these passive indicators, and that these biomarkers can predict rapid changes in MDD symptoms. This proposal will investigate the ability to develop personalized deep learning models of rapid changes in MDD symptoms among a nationally representative sample of 120 treatment seeking adults with MDD across 90 days using passively collected data from smartphones and wearable sensors. This proposal aims to test the accuracy of personalized, subtyped, and cohort-based modeling techniques and uncover personalized digital biomarkers of moment-to-moment changes in MDD symptoms. The project proposes the following innovations: it will (1) conduct the first passive-sensing study of MDD in a nationally-representative cohort; (2) utilize deep learning models to aid in the discovery of novel maintenance factors of MDD symptom changes; and (3) use personalized multimodal assessments of MDD to address the heterogeneity in MDD. In line with the aims of the NIMH Research Domain Criteria (RDoC), this project will study MDD symptom changes across multiple units of analysis and integrate multiple systems. This study will provide a critical step towards uncovering novel personalized maintenance patterns of MDD symptom changes in daily life. Further, it will allow for scalable personalized treatments to be developed using technology to deliver behavioral interventions in the moments immediately preceding rapid MDD symptom changes. PROJECT NARRATIVE This project aims to utilize personalized artificial intelligence techniques and objective data (collected from smartphones and wearable devices) to create individualized digital biomarkers of rapid changes in major depressive disorder symptoms. This is important because, if we were to uncover personalized patterns between objectively measured physiology and behavioral changes and understand their resulting impact on rapid fluctuations in major depressive disorder symptoms, we would be able to define new, person-specific maintenance patterns that underlie the wide-ranging heterogeneity that is currently seen in patients suffering from major depressive disorder. Moreover, these advancements will provide a crucial step forward towards developing personalized, scalable, technology-based interventions that will be able to be delivered immediately (and, ideally, before rapid symptom changes) among those persons with major depressive disorder.",Personalized Deep Learning Models of Rapid Changes in Major Depressive Disorder Symptoms using Passive Sensor Data from Smartphones and Wearable Devices,10029386,R01MH123482,"['Address', 'Adult', 'Affect', 'Arousal', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological Markers', 'Cellular Phone', 'Cessation of life', 'Collection', 'Data', 'Depressed mood', 'Deterioration', 'Devices', 'Ecological momentary assessment', 'Enrollment', 'Exposure to', 'Fostering', 'Heterogeneity', 'Hour', 'Individual', 'Intervention', 'Life', 'Light', 'Location', 'Maintenance', 'Major Depressive Disorder', 'Measures', 'Modeling', 'Moods', 'Motor', 'National Institute of Mental Health', 'Negative Valence', 'Participant', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Persons', 'Photoplethysmography', 'Physiological', 'Physiology', 'Population', 'Positive Valence', 'Process', 'Research', 'Research Domain Criteria', 'Sampling', 'Signal Transduction', 'Sleep', 'Sleep disturbances', 'Subgroup', 'Surveys', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'Wrist', 'actigraphy', 'analog', 'base', 'biomarker-driven', 'burden of illness', 'cohort', 'deep learning', 'depressive symptoms', 'digital', 'disability', 'heart rate variability', 'innovation', 'learning strategy', 'meetings', 'microphone', 'multimodality', 'novel', 'personalized medicine', 'phenomenological models', 'premature', 'prevent', 'sensor', 'social', 'treatment planning', 'treatment response', 'tv watching', 'wearable device', 'wearable sensor technology']",NIMH,DARTMOUTH COLLEGE,R01,2020,250435,0.025089334458720365
"Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography Project Abstract / Summary Primary open angle glaucoma (POAG) is a leading cause of blindness in the United States and worldwide. It is estimated that over 2.2 million Americans suffer from POAG and that over 130,000 are legally blind from the disease. As the population ages, the number of people with POAG in the United States will increase to over 3.3 million in 2020 and worldwide to an estimated 111.8 million by 2040. POAG is a progressive disease associated with characteristic functional and structural changes that clinicians use to diagnose and monitor the disease. Over the past several years, spectral domain optical coherent tomography (SDOCT) has become the standard tool for measuring structure in POAG. This 3D imaging modality provides a wealth of information about retinal structure and POAG-related retinal layers. This large amount of data is hard for clinicians to interpret and use effectively to help guide treatment decisions. Instead, summary metrics such as average layer thicknesses are used to reduce SDOCT images to a handful of values. While these metrics are useful, they can be difficult to interpret and they throwaway important information regarding voxel intensity and texture, relationships across retinal layers, and the overall 3D structure of the retina. Relying too heavily on these metrics limits our ability to gain a deeper understanding structural contributions to POAG, the relationship between structure and visual function, and how structural (and functional) changes progress in POAG. Recent advances in artificial intelligence and deep learning, however, offer new data-driven tools and techniques to interpret 3D SDOCT images and learn from the large SDOCT datasets being collected in clinics around the world. This proposal will apply state-of-the-art deep learning techniques to 3D SDOCT data in order to (1) develop more accurate POAG detection tools, (2) reveal structure-function relationships, and (3) predict structural and functional progression in POAG. This proposal also details a training plan to help the PI transition from a postdoctoral scholar to an independent researcher. The mentored phase of this award will be supervised by the primary mentor, Dr. Linda Zangwill, and a multidisciplinary mentoring team including Dr. Robert Weinreb (Ophthalmology), Dr. David Kriegman (Computer Science and Engineering), and Dr. Armin Schwartzman (Biostatistics). Performing the proposed research, formal coursework, and mentored career development will the provide the PI with highly sought- after skills and experience to help ensure a successful transition into independence. Project Narrative Three-dimensional imaging techniques such as optical coherence tomography have become an essential tool in the clinical care of glaucoma and other eye diseases. These imaging techniques provide clinicians with huge amounts of structural information, but interpreting the data and using it effectively to improve outcomes remains challenging in clinical glaucoma management. This project will improve patient care by applying powerful deep learning techniques to provide clinicians with critical decision support information to more accurately detect glaucoma, reveal associations between structure and visual function, and predict glaucoma progression.",Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography,10055661,K99EY030942,"['3-Dimensional', 'Affect', 'Age', 'American', 'Artificial Intelligence', 'Award', 'Biometry', 'Blindness', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Computational Technique', 'Cornea', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Ensure', 'Evaluation', 'Eye', 'Eye diseases', 'Frequencies', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Learning', 'Length', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Modeling', 'Monitor', 'Ophthalmology', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Population', 'Primary Open Angle Glaucoma', 'Probability', 'Progressive Disease', 'Race', 'Research', 'Research Personnel', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'South Korea', 'Standardization', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Texture', 'Thick', 'Thinness', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Training', 'Translating', 'United States', 'Universities', 'Vision', 'Visual Fields', 'Visualization', 'Width', 'Work', 'base', 'career development', 'clinical care', 'college', 'computer science', 'deep learning', 'experience', 'field study', 'imaging modality', 'improved', 'improved outcome', 'individual patient', 'large datasets', 'legally blind', 'macula', 'multidisciplinary', 'predictive modeling', 'preservation', 'research clinical testing', 'retinal nerve fiber layer', 'sex', 'skills', 'standard measure', 'three dimensional structure', 'tomography', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2020,117347,0.02786366727705635
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,0.042648169316255674
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,0.02070538877696357
"Interpretable deep learning models for translational medicine Understanding the state of cellular signaling systems provides insights to how cells behave under physiological and pathological conditions. Cellular signaling systems are organized as hierarchy (cascade) and signals of a molecular is often compositionally encoded to control cellular processes, such as gene expression. This project aims to develop advanced deep learning models (DLMs) to simulate cellular signaling systems based on gene expression data. In last 3 years, the project has made significant progresses, but the challenges remain. Importantly, contemporary DLMs behave as “black boxes”, in that it is difficult to interpret how signals are encoded and how to interpret which signal a hidden node represent in a DLM. This black-box nature prevents researchers from gaining biological insights using DLMs, even though these models can be much superior in modeling data than other types of models in many tasks, e.g., predicting drug sensitivity of cancer cells. In this competitive renewal, we propose to develop novel DLMs and innovative inference algorithms to train “interpretable” DLMs and apply them in translational research. The proposed research is innovative and of high significance in several perspectives: 1) Our novel DLMs and algorithms take advantage of big data resulting from systematic chemical/genetic perturbations of cellular signaling machinery, so that we can use the perturbation condition as side information to reveal how signals are encoded in a DLM. 2) We integrate principles of causal inference and information theory with deep learning method to make DLMs interpretable. As results, that researchers can gain mechanistic insights from such models. 3) Innovative application of interpretable DLMs will advance translational research. For example, we will train interpretable DLMs to model cellular signaling at the level of single cells and use this information investigate inter-cellular interactions among cells in tumor microenvironment to shed light on immune evasion mechanisms of cancers. We will also use information derived from interpretable DLMs to predict cancer cell drug sensitivity. We anticipate that our study will bring forth significant advances not only in deep learning methodology but also in precision medicine. This project aims to develop advance machine learning methods, referred to as deep learning models, to simulate cellular signaling systems, at both multiple cell and single cell levels. Success of these models will enable researchers to investigate cellular behaviors under physiological and pathological condition, and such information can be used to guide therapy of cancer patients.",Interpretable deep learning models for translational medicine,9972153,R01LM012011,"['Affect', 'Algorithms', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Cancer Patient', 'Cancer cell line', 'Cell model', 'Cell physiology', 'Cells', 'Data', 'Disease', 'Event', 'Gene Expression', 'Genetic', 'Genetic Transcription', 'Grain', 'Human', 'Immune Evasion', 'Immunotherapy', 'Individual', 'Information Theory', 'Intervention', 'Knowledge', 'Learning', 'Libraries', 'Light', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'MicroRNAs', 'Mining', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Network-based', 'Organoids', 'Outcome', 'Paper', 'Pathologic', 'Pathway interactions', 'Patients', 'Pharmacology', 'Phenotype', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Cancer Genome Atlas', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Yeasts', 'base', 'biological systems', 'cancer cell', 'cancer therapy', 'cell behavior', 'chemical genetics', 'data modeling', 'deep field survey', 'deep learning', 'deep learning algorithm', 'design', 'drug sensitivity', 'experience', 'genome-wide', 'innovation', 'inquiry-based learning', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'novel', 'patient response', 'pre-clinical', 'precision medicine', 'precision oncology', 'predicting response', 'prevent', 'response', 'single-cell RNA sequencing', 'success', 'theories', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'translational impact', 'translational medicine', 'translational model', 'tumor', 'tumor microenvironment']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,309622,0.0037677341870753093
"Lupus Nephritis Neural Network, LuNN Up to 60% of adults and 80% of children with systemic lupus erythematosus (SLE) develop nephritis (LN), with 10–30% progressing to end-stage renal disease (ESRD). The gold standard for diagnosis of LN is a renal biopsy. Histological parameters remain the best predictors of ESRD. Despite being the gold standard, histological diagnosis of LN has several shortcomings. In multiple inter-observer renal pathology assessment studies reported thus far, the inter- pathologist correlation coefficients, or concordance, in assessing most histological parameters have been sub-optimal. This has provided the impetus for the current proposal. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of LN using current diagnostic criteria. We propose to train a deep convolutional neural network to distinguish the different LN classes, and to identify a full spectrum of histological attributes useful for diagnosis. We will compare the performance of the newly generated neural network in scoring glomerular/tubulo-interstitial features and LN classes, against a panel of human renal pathologists. Finally, we propose to build a neural network that can predict clinical outcome based on baseline renal pathology. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival. Despite being the gold standard, histological diagnosis of lupus nephritis is imprecise, and marked by significant inter-pathologist discordance in readings. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of lupus nephritis. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival.","Lupus Nephritis Neural Network, LuNN",10246669,R56DK122036,"['Adult', 'Algorithms', 'Automobile Driving', 'Cellular Structures', 'Child', 'Chronic', 'Classification', 'Computer Vision Systems', 'Diagnosis', 'Diagnostic', 'End stage renal failure', 'Feedback', 'Gold', 'Histologic', 'Human', 'Image', 'Kidney', 'Lupus', 'Lupus Nephritis', 'Machine Learning', 'Mus', 'Nephritis', 'Outcome', 'Outcome Study', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Phenotype', 'Prediction of Response to Therapy', 'Reading', 'Reporting', 'Reproducibility', 'Retrieval', 'Supervision', 'Systemic Lupus Erythematosus', 'Testing', 'Tissues', 'Training', 'Uncertainty', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnosis standard', 'falls', 'improved', 'indexing', 'innovation', 'kidney biopsy', 'neural network', 'novel', 'predict clinical outcome', 'time interval', 'tool', 'treatment response', 'user-friendly', 'web portal']",NIDDK,UNIVERSITY OF HOUSTON,R56,2020,100750,0.027878279671135278
"Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response SUMMARY Drug-induced cardiac toxicity, in the form of QT prolongation and torsade de pointes, is an uncommon but devastating side effect of over one hundred currently marketed drugs. The ubiquity of drug-induced QT prolongation (diLQTS) across medical specialties and conditions creates a challenge for providers seeking to prescribe known QT-prolonging medications, particularly for non-cardiac conditions. Work by our group to develop automated clinical decision support (CDS) tools that alert providers of patient risk has shown promise towards reducing the number of prescriptions to at-risk individuals. However, these tools rely on a history of an electrocardiogram (ECG) with QT prolongation to identify at-risk patients, and thus exclude a large number of potentially at-risk individuals who have not had an ECG within our system. Through a unique institutional partnership with Google, in which a copy of our entire electronic health record (EHR) is stored on the Google Cloud Platform (GCP), we have developed preliminary deep-learning models to predict risk of diLQTS. We have also validated the genetic association with the QT interval and diLQTS across several real-world populations using an aggregate polygenic risk score. Through creation of an institutional biobank with certification for clinical application of results, as well as cloud-based integration of EHR data with genetic data, we have the capability to leverage our existing infrastructure to study the role of deep learning and genetics to reduce the risk of diLQTS. This investigation will combine our unique research and clinical infrastructure on the University of Colorado Anschutz Medical Campus with our investigative team composed of experts in the study of pharmacogenomics and medical informatics to develop and study an end-to-end CDS tool incorporating genetics and deep learning to predict risk of diLQTS. The specific aims of this application include the following: (1) develop and test a cloud-based, deep-learning model using EHR data on in- and outpatients to predict risk of diLQTS; (2) validate genetic predictors of diLQTS using institutional biobank samples, and a multi-ethnic external population; and (3) develop and test CDS tools using these advanced methods to reduce the risk of diLQTS. We will use a common data model (Observational Medical Outcomes Partnership) mapped from EHR data, as well as a custom DNA array (Multi-Ethnic Genotyping Array) designed for imputation across a variety of non-European ancestries, to ensure that the our prediction model and findings from this study can be replicated in other institutions and populations in the future. In such a way, this investigation will not only provide insight into the use of machine learning and genetics for risk prediction of diLQTS, but it will also create a blueprint for future advanced CDS development for other conditions. PROJECT NARRATIVE The goal of this project is the development of a clinical decision support tool that can be used to predict the risk of drug-induced QT prolongation based on deep learning and genetics. This tool could be used to prevent potentially fatal side effects of medications when alternatives are available, or increase vigilance when safer alternatives are not available. This study is specifically designed so that the models created can be directly applied across other institutional medical record systems beyond the study population.",Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response,9887500,R01HL146824,"['Adherence', 'Adverse drug effect', 'Arrhythmia', 'Artificial Intelligence', 'Automated Clinical Decision Support', 'Benefits and Risks', 'Biometry', 'Cardiotoxicity', 'Certification', 'Clinical', 'Cluster randomized trial', 'Colorado', 'Custom', 'DNA', 'Data', 'Data Science', 'Decision Analysis', 'Development', 'Electrocardiogram', 'Electronic Health Record', 'Ensure', 'Excision', 'Future', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Health Technology', 'Health system', 'Heritability', 'Hospitals', 'Individual', 'Information Technology', 'Infrastructure', 'Inpatients', 'Institution', 'Investigation', 'Long QT Syndrome', 'Machine Learning', 'Maps', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Modeling', 'Outcome', 'Outpatients', 'Participant', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Population', 'Protocols documentation', 'Provider', 'Recording of previous events', 'Relative Risks', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Risk stratification', 'Role', 'Sample Size', 'Sampling', 'Science', 'System', 'Technology', 'Testing', 'Time', 'Torsades de Pointes', 'Toxic effect', 'Universities', 'Validation', 'Variant', 'Work', 'analytical tool', 'base', 'biobank', 'classification algorithm', 'clinical application', 'clinical decision support', 'clinical implementation', 'clinical infrastructure', 'cloud based', 'cloud platform', 'cloud storage', 'data modeling', 'data warehouse', 'deep learning', 'design', 'disorder risk', 'drug market', 'electronic data', 'experience', 'genetic association', 'genetic epidemiology', 'genetic information', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health data', 'improved', 'innovation', 'insight', 'machine learning method', 'medical schools', 'medical specialties', 'patient safety', 'personalized medicine', 'polygenic risk score', 'practical application', 'predictive modeling', 'prevent', 'primary outcome', 'response', 'secondary outcome', 'side effect', 'study population', 'support tools', 'tool', 'trend', 'vigilance']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2020,777314,0.03320072703747568
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.14957260050965895
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,10193990,R33AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Models', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'automated segmentation', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'feature extraction', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'large datasets', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R33,2020,403748,0.07516579468084478
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9928429,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'algorithm training', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'segmentation algorithm', 'software infrastructure', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2020,195000,0.01072845777600613
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,9970009,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,649026,-0.020687719394208916
"Quantifying the individual contributions of comorbid tau neuropathologies using deep learning PROJECT SUMMARY/ABSTRACT Co-occurrence of different neurodegenerative diseases is increasingly common with age and acts as a confounding factor in the development of disease-specific biomarkers. Yet, even by the gold standard of evaluating immunostaining for aggregated proteins in autopsy brains, pathologic complexity makes it impossible to reliably quantify the mixture of diseases by visual inspection, especially when coexistent disorders both feature the same aggregated protein, albeit in different disease-specific patterns. Here, we hypothesize that recent advances in deep learning can identify the distinctive patterns of Alzheimer disease (AD) and progressive supranuclear palsy (PSP) neuropathology, thereby allowing us to de-convolve their individual contributions from phospho-tau immunostaining of mixed pathologies. We will tackle this problem in three steps. First, in order to incorporate biological knowledge and enable interpretability of our disease predictions, we will develop a set of deep learning classifiers to identify disease relevant “features” in virtual whole slide images. These features will include different types of cells (e.g. neurons, astrocytes), aggregates (e.g. tufted astrocytes and senile plaques that are enriched in PSP and AD, respectively) and tissue regions (gray vs. white matter, which differ in pattern of involvement in these diseases). Second, based on the assumption that comorbid pathologies exhibit a mixture of pure disease features, we will build disease classifiers from pure AD and pure PSP cases. Given a local patch of tau-stained tissue, these classifiers will return their confidence that tissue exhibited either of these diseases. We will evaluate two approaches, one building on the “features” identified above and the other a more traditional black- box deep learning approach working purely off of image patches. Finally, we will evaluate our pure disease classifiers on cases with mixed pathologies based on pathologist review and concordance with antibodies to tau isoforms whose individual histomorphologies help to distinguish between AD and PSP. As they will identify established neuropathology features demonstrated by the widely-used AT8 phospho-tau and 3R and 4R tau isoform immunostaining, our classifiers will be a valuable resource for future digital imaging based studies in neuropathology. Our framework for de-convolving comorbidities from autopsy samples can be extended to other diseases, thus enabling better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy. PROJECT NARRATIVE Co-occurrence of different neurodegenerative pathologies is increasingly common with age. Here, we aim to use deep learning to distinguish the relative contributions of individual comorbid diseases from tau-stained images of autopsy brains affected by two comorbid conditions, Alzheimer disease and progressive supranuclear palsy. Technologies developed during this proposal will provide powerful machine learning tools for neuropathology, while its successful completion will facilitate better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy.",Quantifying the individual contributions of comorbid tau neuropathologies using deep learning,10058010,R21AG066012,"['Adoption', 'Affect', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Astrocytes', 'Atlases', 'Autopsy', 'Biological', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Data', 'Dementia', 'Deposition', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Exhibits', 'Future', 'Genetic', 'Gold', 'Heterogeneity', 'Histopathology', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Lesion', 'Libraries', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Monoclonal Antibodies', 'Morphology', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurons', 'Pathologic', 'Pathologist', 'Pathology', 'Pattern', 'Phenotype', 'Progressive Supranuclear Palsy', 'Protein Isoforms', 'Research', 'Resources', 'Sampling', 'Senile Plaques', 'Spatial Distribution', 'Stains', 'Tauopathies', 'Technology', 'Testing', 'Tissue Stains', 'Tissues', 'Visual', 'Visualization', 'base', 'case-based', 'cell type', 'clinical biomarkers', 'comorbidity', 'deep learning', 'digital imaging', 'gray matter', 'hands-on learning', 'improved', 'learning classifier', 'learning strategy', 'method development', 'neocortical', 'neuropathology', 'protein aggregation', 'specific biomarkers', 'tau Proteins', 'tau-1', 'tool', 'tumor', 'virtual', 'virtual imaging', 'white matter', 'whole slide imaging']",NIA,UT SOUTHWESTERN MEDICAL CENTER,R21,2020,450250,-0.01480007444387056
"Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data Project Summary The broad objective of this research is to develop a powerful deep-learning based multiple testing approach for high-dimensional spatial data that arise commonly in biomedical imaging studies, in particular, brain imaging studies. The motivating problem is to detect the cerebral metabolic abnormalities in Alzheimer’s disease (AD) from Fluorine-18 fluorodeoxyglucose positron emission tomography (FDG-PET) data. Existing multiple testing approaches in solving this problem often ignore or inadequately capture the spatial dependence among the test statistics obtained from brain voxels and thus lose substantial power for the detection. We will develop a novel spatial multiple testing method that utilizes the deep convolutional neural network (DCNN), a key deep- learning technique, to well capture the spatial dependence among test statistics and thus to achieve the optimal power in the sense of minimizing the false nondiscovery rate (FNR) while correctly controlling the false discovery rate (FDR) at a given level. The proposed DCNN-based FDR controlling method has enhanced power to discover new AD-related brain regions that are missed by conventional methods, thereby leading to novel clinical and pathological studies. The specific aims of this proposal include: 1. To develop an optimal spatial FDR controlling approach by connecting the unsupervised local-significance-index based multiple testing with the supervised DCNN-based image segmentation; 2. To evaluate the proposed spatial FDR controlling approach via extensive simulations under various three-dimensional spatial dependence structures, in comparison with multiple classical and state-of-the-art methods; 3. To apply proposed spatial FDR controlling approach to detect AD-related brain regions using the FDG-PET datasets from the Alzheimer’s Disease Neuroimaging Initiative and the Weill Cornell Brain Health Imaging Institute; 4. To develop a user- friendly and publicly available software package with versions in both Python and R to implement the proposed spatial FDR controlling approach. The proposed DCNN-based approach will also be widely applicable to large- scale multiple testing problems in other fields of biomedical research that involve spatial dependence. Project Narrative This project will exploit recent advances in deep learning to efficiently solve the large-scale spatial multiple testing problems that arise commonly in biomedical imaging studies. The proposed powerful deep-learning based spatial multiple testing approach will be particularly useful in brain imaging studies on neurodegenerative disorders such as Alzheimer’s disease and age-related cognitive impairment.",Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data,10107565,R21AG070303,"['3-Dimensional', 'Affect', 'Age-associated memory impairment', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Architecture', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrum', 'Clinical', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Detection', 'Disease', 'Early Diagnosis', 'Family', 'Fluorine', 'Glucose', 'Goals', 'Health Sciences', 'Image', 'Institutes', 'Learning', 'Literature', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Monitor', 'Network-based', 'Neurodegenerative Disorders', 'Pathologic', 'Patients', 'Performance', 'Population Group', 'Positron-Emission Tomography', 'Problem Solving', 'Procedures', 'Pythons', 'Research', 'Research Personnel', 'Structural Models', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Training', 'base', 'bioimaging', 'brain health', 'convolutional neural network', 'deep learning', 'fluorodeoxyglucose positron emission tomography', 'high dimensionality', 'imaging Segmentation', 'imaging study', 'indexing', 'metabolic rate', 'mild cognitive impairment', 'neuroimaging', 'novel', 'repository', 'simulation', 'statistics', 'success', 'theories', 'user friendly software', 'user-friendly']",NIA,NEW YORK UNIVERSITY,R21,2020,435875,-0.004762814031696508
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,0.17049955265442696
"Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease Summary  Alzheimer's disease (AD) affects over 44 million individuals worldwide, and the number is projected to triple by 2050. However, currently there is no cure for AD. This project aims to develop and apply novel statistical methods, especially deep learning, to advance neuroimaging genetics for AD. It involves novel methodological developments in Aims 1-4, cost-effective applications to the large-scale UK Biobank neuroimaging genetic data for AD (Aim 5), and software development (Aim 6). All four Aims for the methods development tackle emerging impor- tant topics in deep learning with their applications to neuroimaging genetics for AD; although the other three Aims deal with independent topics with their own other broad applications, they in turn serve for Aim 1: 1) Aim 1 applies manually searched deep learning models for automatic feature extraction/phenotyping from neuroimages, by which both the statistical power and biological interpretation of subsequent genome-wide association studies (GWAS) are expected to be enhanced; 2) Aim 2 employs (automatic) neural architecture search (NAS) to more efﬁciently identify better deep learning models, which are then applied to Aim 1 for enhancing feature extraction/phenotyping and thus boosting the power of GWAS; 3) Aim 3 focuses on explainable deep learning, offering biological insights by localizing and highlighting the most important features extracted by deep learning models that can be used for Aim 1; 4) Aim 4 develops a novel inferential theory for deep learning, which is then applied to rigorously test for the statistical signiﬁcance of any selected/highlighted features used in Aim 1. In Aim 5, these new methods will be applied to the UK Biobank neuroimaging and GWAS data to identify novel genetic loci and neuroimaging features for AD. As a byproduct, we will develop and distribute software implementing the proposed methods in Aim 6. Project Narrative  This proposed research is to develop new statistical estimation and inference methods for deep learning with their applications to neuroimaging genetics for Alzheimer's disease (AD), which is expected to contribute to the elucidation of genetic components and etiology of AD with potential applications to other common diseases, thus facilitating their prevention, early diagnosis and therapeutic development.",Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease,10088703,R01AG069895,"['Advocate', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Architecture', 'Atlases', 'Biological', 'Brain', 'Classification', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Disease', 'Documentation', 'Early Diagnosis', 'Entropy', 'Environment', 'Etiology', 'Genetic', 'Genotype', 'Hand', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Nature', 'Noise', 'Outcome', 'Performance', 'Phenotype', 'Prevention', 'Process', 'Proxy', 'Psychological reinforcement', 'Public Domains', 'Publishing', 'Pythons', 'Research', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'base', 'biobank', 'combinatorial', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'endophenotype', 'feature extraction', 'feature selection', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic locus', 'high dimensionality', 'improved', 'insight', 'interest', 'method development', 'model building', 'neural network architecture', 'neuroimaging', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'relating to nervous system', 'software development', 'success', 'theories', 'therapeutic development', 'tool', 'trait', 'web site']",NIA,UNIVERSITY OF MINNESOTA,R01,2020,685871,-0.030050458270705124
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Abstract This SBIR Phase II project will develop a deep learning-based clinical decision support algorithm for detecting and diagnosing valvular heart disease based on heart sounds recorded using the Eko Core and Eko Duo Digital Stethoscopes. This screening tool will help to decrease the number of patients with valvular heart disease that remain undertreated simply because their condition is not diagnosed. Auscultation is commonly the method by which valvular heart disease is first detected, but cases often fail to be referred to echocardiography for diagnosis because clinicians fail to detect heart murmurs, particularly in noisy or rushed environments. To address this challenge, Eko had developed the Core, a digital stethoscope attachment that can be added in-line to a clinician’s existing stethoscope that amplifies heart sounds and Duo, a digital stethoscope in a handheld form factor with built-in single lead electrocardiogram. Both devices are designed to stream digitized phonocardiograms to a smartphone, tablet or personal computer. There, the signal can be analyzed with the decision support algorithm we will develop as part of this project. The specific aims of this study are: (1) to collect a database with condition- specific recording labels to enable deep learning for heart sounds though clinical data collection at six clinical sites, and (2) to develop and evaluate a collection of deep convolutional neural network-based algorithms trained on the database. These algorithms will (2a) distinguish between systolic, diastolic and continuous murmurs, (2b) classify aortic stenosis (AS), mitral regurgitation (MR), tricuspid regurgitation (TR), and innocent murmurs (2c) assess the severity of AS, MR and TR. By integrating these deep learning algorithms into Eko's mobile and cloud software platform, currently used by clinicians at over 1000 institutions worldwide, we anticipate this algorithm will enable more accurate screening for valvular heart disease in adult patients, leading to earlier diagnosis and better patient outcomes. Public Health Relevance Valvular heart disease is becoming an increasingly prevalent manifestation of poor cardiovascular health in both the developed and developing world. A highly-accurate clinical decision support algorithm that is able to detect and classify valvular heart disease will impact public health by reducing unnecessary referrals for echocardiography and promoting early and accurate diagnosis in underserved areas with limited access to specialty care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,10079904,R44HL144297,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinic', 'Clinical', 'Clinical Data', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Detection', 'Device Designs', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Electrocardiogram', 'Enrollment', 'Environment', 'Goals', 'Gold', 'Health Personnel', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Institution', 'Label', 'Lead', 'Medical Device', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Network-based', 'Outcome Study', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Prevalence', 'Primary Health Care', 'Public Health', 'Reporting', 'Resources', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Supervision', 'System', 'Tablet Computer', 'Testing', 'Training', 'Tricuspid Valve Insufficiency', 'accurate diagnosis', 'algorithm training', 'automated algorithm', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinical research site', 'clinically significant', 'cloud software', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'diagnosis standard', 'digital', 'experience', 'innovation', 'learning strategy', 'medical specialties', 'point of care', 'public health relevance', 'screening', 'sound']",NHLBI,"EKO DEVICES, INC.",R44,2020,938347,0.054129419343989335
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9970413,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,497020,0.09119148860218805
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9942528,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'aggressive therapy', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'large datasets', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,559900,0.02739855093661146
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9998736,R21ES029722,"['Adult', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'segmentation algorithm', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2020,185625,0.09838621006727359
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,0.1583432459692878
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10136941,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2020,746725,-0.018253864575616972
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,10013198,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air Movements', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'Visualization', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'respiratory morbidity', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2020,187049,0.0386100152842474
"Neurodegenerative diseases and the role of green space: A deep learning assessment PROJECT SUMMARY Alzheimer’s disease and related dementias (ADRD) have well-established risk factors such as physical activity (PA), depression, and hypertension (HTN). These risk factors disproportionately affect racial minority populations, but the mechanisms underlying racial health disparities are not well understood. In this, geographic factors could be key, as PA, depression and HTN are strongly affected by geographic exposures, including green space. However, green space is typically measured with questionnaires, which have substantial error, or satellite-based indexes that are nonspecific and provide no information on the type of vegetation (e.g., tree vs. grass), nor whether the vegetation is within view at the street level. As a result, no study has quantified the contribution of green space to racial disparities in ADRD. And while novel technologies such as Google Street Views (GSV) imaging are promising data sources for capturing unique measures of green space, managing, processing, and analyzing high-dimensional data present significant logistical and analytical challenges, especially when linking these data to existing data from large prospective cohorts. Finally, we need to understand green space in the context of other potentially correlated geographic exposures, or the urban exposome—the totality of life- course geographic exposures (the set of green space, air pollutants, noise, built environment, and social environment)—to estimate which factors drive health. This proposal will address these challenges by using GSV imaging to assess the effect of green space on PA, depression, and HTN, as well as subsequent ADRD risk within the Multi-Ethnic Study of Atherosclerosis (MESA)—a 10-year longitudinal study of 6,814 men and women without clinical cardiovascular disease at baseline from 4 racial/ethnic groups (Non-Hispanic White, African-American, Chinese, and Hispanic). Aim 1 will quantify the effect of specific aspects of green space (e.g. trees, grass, shrubs, plants) on ADRD and cognitive decline and evaluate whether these associations differ according to race/ethnicity. Aim 2 will determine the indirect effect of green space on ADRD that is mediated through PA, depression, and HTN. Aim 3 will quantify exposome associations with ADRD and cognitive decline using untargeted data-driven approaches in conjunction with dimension reduction techniques and evaluate whether they differ according to race/ethnicity. This research plan is complemented by a training plan that builds on the applicant’s background in epidemiology and biostatistics and includes new training in (1) implementing deep learning algorithms to analyze high-resolution geographic data, (2) cognitive function epidemiology, and (3) developing and refining data-driven approaches to perform exposome-informed epidemiological studies. These combined plans will successfully prepare the applicant for an independent research career focused on identifying modifiable geographic determinants of ADRD in diverse populations using innovative measures of geographic context. Project Narrative Green space or trees and natural vegetation can provide mental health benefits and possibly lower risk of neurodegenerative diseases such as Alzheimer’s disease and related dementias (ADRD); however, green space is often measured poorly in epidemiologic research. I propose to integrate high-resolution images from Google Street Views to derive ground-level objective measurements of green space into a diverse prospective cohort study using deep learning algorithms, mediation analysis and geographic mixtures. This research will enable unprecedented perspectives on exposures that drive ADRD and related cognitive decline risk, and will provide translational insights into potential interventions to optimize opportunities for ADRD prevention and reduce racial disparities in ADRD.",Neurodegenerative diseases and the role of green space: A deep learning assessment,9952648,K99AG066949,"['Accounting', 'Address', 'Adult', 'Affect', 'African American', 'Age', 'Air Pollutants', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'Baltimore', 'Biological', 'Biometry', 'Cardiovascular Diseases', 'Chicago', 'Chinese People', 'Cities', 'Clinical', 'Complement', 'Complex', 'County', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Diagnosis', 'Dimensions', 'Elderly', 'Environment', 'Environmental Hazards', 'Epidemiology', 'Ethnic Origin', 'Ethnic group', 'Exposure to', 'Family', 'Funding', 'Geographic Factor', 'Geography', 'Goals', 'Green space', 'Health', 'Health Benefit', 'Healthcare', 'Hispanics', 'Hypertension', 'Image', 'Imagery', 'Impaired cognition', 'Incidence', 'Individual', 'Intervention', 'Lead', 'Life Cycle Stages', 'Link', 'Literature', 'Logistics', 'Longitudinal Studies', 'Los Angeles', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Minority', 'Multi-Ethnic Study of Atherosclerosis', 'Neurodegenerative Disorders', 'New York', 'Noise', 'Not Hispanic or Latino', 'Pathway interactions', 'Patients', 'Physical activity', 'Plants', 'Poaceae', 'Population', 'Population Heterogeneity', 'Prevalence', 'Prevention', 'Prevention strategy', 'Prospective cohort', 'Prospective cohort study', 'Questionnaires', 'Race', 'Research', 'Resolution', 'Risk', 'Risk Factors', 'Role', 'Social Environment', 'Social Impacts', 'Techniques', 'Time', 'Training', 'Trees', 'United States National Institutes of Health', 'Woman', 'aged', 'base', 'built environment', 'career', 'cognitive function', 'cohort', 'comorbidity', 'deep learning', 'deep learning algorithm', 'dementia risk', 'design', 'economic impact', 'epidemiology study', 'ethnic minority population', 'healthy aging', 'high resolution imaging', 'indexing', 'innovation', 'insight', 'longitudinal analysis', 'men', 'multidimensional data', 'neurocognitive disorder', 'new technology', 'novel', 'physical inactivity', 'public health intervention', 'racial and ethnic', 'racial disparity', 'racial health disparity', 'racial minority', 'segmentation algorithm', 'skills', 'urban public health']",NIA,HARVARD SCHOOL OF PUBLIC HEALTH,K99,2020,129600,0.01970912863044202
"An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers Abstract  Stereotactic MRI-guided online adaptive radiotherapy (SMART) is an effective treatment for the pancreas and other upper abdominal cancers. SMART allows precise delivery of escalated prescription dose to the abdominal tumor targets while avoiding the complications of radiation toxicity to the mobile gastrointestinal (GI) organs surrounding the tumor target. In the clinical workflow of SMART, manual segmentation of the GI orangs at risk (OARs) is one of the most important but also the most labor-intensive steps. Manual segmentation takes 10 minutes on average but ranges from 5 to 22 minutes. The slow and costly manual segmentation step directly decreases the accessibility and affordability of online SMART and indirectly reduces the effectiveness of SMART due to intra-fractional body and organ movement of the patients. In this study, we will develop a deep-learning based interactive and semi-automatic procedure to accurately and quickly segment the GI OARs to make SMART more efficient and affordable. Stereotactic MRI-guided online adaptive radiotherapy (SMART) has been demonstrated as an effective treatment for the pancreas and other upper abdominal cancers. For nonresectable pancreatic cancer, SMART increased the overall survival at 36 months from 18% to 55% compared to conventional radiation therapy (RT) treatment. In this study, we will develop a deep-learning based interactive and semi-automatic method to accurately and quickly segment the organs-at- risk (OAR) in the abdomen to support SMART. The method to be developed will significantly expedite the OAR segmentation step and make SMART more efficient and affordable.",An interactive deep-learning method to semi-automatically segment abdominal organs to support stereotactic MR guided online adaptive radiotherapy (SMART) for abdominal cancers,10017990,R03EB028427,"['3-Dimensional', 'Abdomen', 'Affect', 'Agreement', 'Anatomy', 'Biological', 'Clinical', 'Disadvantaged', 'Dose', 'Dose-Rate', 'Duodenum', 'Effectiveness', 'Ensure', 'Exhibits', 'Goals', 'Image', 'Kidney', 'Large Intestine', 'Liver', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Minor', 'Morphologic artifacts', 'Motion', 'Movement', 'Noise', 'Organ', 'Pancreas', 'Patients', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation Toxicity', 'Radiation therapy', 'Resolution', 'Risk', 'Small Intestines', 'Stomach', 'Time', 'Toxic effect', 'Universities', 'Washington', 'automated segmentation', 'base', 'computerized', 'cost', 'deep learning', 'design', 'effective therapy', 'gastrointestinal', 'imaging capabilities', 'improved', 'irradiation', 'learning strategy', 'novel', 'preservation', 'time use', 'tool', 'treatment duration', 'tumor']",NIBIB,WASHINGTON UNIVERSITY,R03,2020,74942,0.03901255160710241
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.10603590027546914
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9928452,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2020,192552,0.06155711098509985
