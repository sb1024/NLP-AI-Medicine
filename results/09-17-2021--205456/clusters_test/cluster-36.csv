text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,10236260,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'high body mass index', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'obese patients', 'obese person', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2021,585234
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10219212,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'lipidomics', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2021,620000
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,10061631,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2021,1261742
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10173765,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'efficacy evaluation', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2021,256578
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10186744,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,377473
"A novel method for volumetric oxygen mapping in living retina PROJECT SUMMARY It is widely accepted that oxygen deficiency is a culprit and a marker of several major retinal diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma etc. However, it remains to be extremely challenging to measure oxygen in vivo in the eye, and no tools currently exist that can provide 3D oxygen distributions in the retina with high spatial resolution at appropriate imaging speeds. The goal of this project is to overcome these limitations and develop a new optical imaging technique for volumetric oxygen mapping in retina. Our approach will leverage the recently developed potent oxygen probes (such as Oxyphor 2P), whose phosphorescence decay times serve as quantitative markers of local oxygen partial pressures (pO2) in living tissues. To enable volumetric imaging with high throughput, we propose to develop a novel imaging instrument, termed oblique scanning laser ophthalmoscope (oSLO). oSLO is based on the concept of single lens scanned light sheet microscopy and enables volumetric phosphorescence lifetime imaging without time- consuming plane-by-plane pixel-wise sectioning. Our new method should be able to achieve 10 kilohertz voxel rate that is three orders of magnitude higher than the current state-of-the-art two-photon phosphorescence lifetime microscopy (2PLM). In this project we will: (Aim 1) develop a phosphorescence lifetime-based oSLO for volumetric pO2 mapping in living retina in mouse. The new design will allow parallel detection of signals at depth from each scanned location, so that the need in conventional depth sectioning is eliminated and imaging throughput is greatly increased. We will (Aim 2) dynamically image responses of retina and choroid to systemic hypoxia challenge using Oxyphor 2P. We will (Aim 3) then bridge oSLO measurements and label-free applications by multimodal imaging with visible light optical coherence tomography (vis-OCT). Using vascular pO2 as the ground-truth, we will develop a deep spectral training (DSL) algorithm to supervise the inverse calculation of vis-OCT for robust and reliable label-free retinal oximetry. This study will enable the first direct quantitative imaging of interactions between the two circulatory systems in retina (i.e. retinal and choroidal circulation), providing unprecedented information about retinal oxygen supply. IMPACT ON PUBLIC HEALTH: Successful completion of this program will deliver a new ground-breaking methodology for mapping oxygen in the retina that will greatly improve our understanding of retinal diseases. NARRATIVE Oxygen is essential in the retina, and the deficiency of oxygen is a culprit in a broad spectrum of retinal diseases. However, it remains challenging to measure oxygen in vivo in the eye. This multidisciplinary proposal is to develop a disruptive imaging method to provide unprecedented volumetric oxygen mapping in living mouse retina, as well as a deep learning method, to translate our oxygen measurements into label-free retinal oximetry for future clinical applications.",A novel method for volumetric oxygen mapping in living retina,10098478,R01EY032163,"['3-Dimensional', 'Address', 'Affect', 'Age related macular degeneration', 'American', 'Biochemistry', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cardiovascular system', 'Cell Respiration', 'Choroid', 'Consumption', 'Data', 'Data Set', 'Detection', 'Diabetic Retinopathy', 'Dyes', 'Eye', 'Fluorescence Angiography', 'Fundus', 'Future', 'Glaucoma', 'Goals', 'Human', 'Hypoxia', 'Image', 'Imaging Device', 'Imaging Techniques', 'Inhalation', 'Label', 'Lasers', 'Life', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medicine', 'Metabolic', 'Methodology', 'Methods', 'Microscopy', 'Multimodal Imaging', 'Mus', 'Nobel Prize', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Oxygen', 'Oxygen saturation measurement', 'Partial Pressure', 'Pathologic', 'Pathology', 'Photons', 'Physiology', 'Public Health', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Scanning', 'Signal Pathway', 'Signal Transduction', 'Speed', 'Supervision', 'Time', 'Tissues', 'Training', 'Translating', 'Vascular System', 'Visible Radiation', 'adaptive optics', 'algorithm training', 'base', 'choroidal circulation', 'clinical application', 'clinical translation', 'deep learning', 'design', 'hemodynamics', 'human imaging', 'imaging modality', 'improved', 'in vivo', 'learning network', 'learning strategy', 'lens', 'multidisciplinary', 'novel', 'novel imaging technique', 'optical imaging', 'phosphorescence', 'porphyrin a', 'programs', 'quantitative imaging', 'response', 'retina circulation', 'retinal imaging', 'sensor', 'success', 'tool', 'two photon microscopy', 'two-photon']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,552744
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of differenttypes of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",10397321,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2021,1500000
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10202460,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2021,749956
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027
"Machine learning algorithms to analyze large medical image datasets Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. Our overall objective for this research is to dramatically reduce the burden of creating high quality reference labels by requiring only a small set of such labels from experts. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. This will enable us to apply ML techniques to generate high quality labels of the large amounts of unlabeled data that are already available, which in turn will facilitate the assessment of potential quantitative imaging biomarkers. We will develop, extend and evaluate novel algorithms that represent three distinct strategies for reducing labelling cost. These three strategies are learning from unlabelled data incorporating a novel strategy for characterizing uncertainty, optimizing sample selection for expert quality labelling with a novel form of Active Learning especially suited for deep learning, and reducing the cost of achieving quality labeling by replacing or augmenting an expert with a crowd of inexperts. We will then implement and distribute these novel algorithms, facilitating the replication of our experiments. Finally, we will demonstrate the practical efficacy of these three strategies by applying them to the important challenge of identifying quantitative imaging biomarkers that best capture alterations in brain structure that are associated with characteristics of ASD. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes. Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes.",Machine learning algorithms to analyze large medical image datasets,10182522,R01LM013608,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'Benchmarking', 'Brain', 'Characteristics', 'Child', 'Clinical', 'Collection', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Fatigue', 'Image', 'Image Analysis', 'Informatics', 'Interruption', 'Label', 'Learning', 'Life', 'Machine Learning', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Noise', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Reference Standards', 'Research', 'Sampling', 'Speed', 'Structure', 'Techniques', 'Training', 'Uncertainty', 'Update', 'autism spectrum disorder', 'base', 'clinical decision-making', 'cost', 'crowdsourcing', 'deep learning', 'design', 'experimental study', 'imaging Segmentation', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'novel', 'novel strategies', 'prevent', 'quantitative imaging', 'radiologist', 'success', 'supervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,369580
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,10162650,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual clinical trial', 'virtual patient']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2021,384396
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10224190,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2021,119250
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,10150027,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2021,695400
"Optical design and the development of high accuracy automated tick classification using computer vision Abstract. The incidence of US tick-borne diseases has more than doubled in the last two decades. Due to lack of effective vaccines for tick-borne diseases, prevention of tick bites remains the primary focus of disease mitigation. Tick vector surveillance—monitoring an area to understand tick species composition, abundance, and spatial distribution—is key to providing the public with accurate and up-to-date information when they are in areas of high risk, and enabling precision vector control when necessary. Despite the importance of vector surveillance, current practices are highly resource intensive and require significant labor and time to collect and identify vector specimens. Acarologist or field taxonomist expertise is a limited resource required for tick identification, creating a significant capability barrier for national tick surveillance practice. While mobile applications to facilitate passive surveillance and reporting of human-tick encounters have grown in popularity, variable image quality, limited engagement, and scientist misidentification of rare, invasive, or morphologically similar tick species hinder the scalability of this approach. No automated solutions exist to build tick identification capacity. We seek to develop the first imaging and automated identification system capable of instantaneously and accurately identifying the top nine tick vectors in the US. This proposal will first characterize the optical requirements necessary to image diagnostic morphological features associated with adult ticks and develop a standardized imaging platform for tick identification. This will enable the development of a high-quality tick image dataset in partnership with the Walter Reed Biosystems Unit (WRBU) which will be used to train high-accuracy computer vision models for tick species and sex identification. Ultimately the approaches developed here will enable new tick identification tools for both the lab and citizen scientists; allowing vector surveillance managers to leverage image recognition in a practical system that will increase capacity and capability for biosurveillance, and equipping citizen scientists with improved tools to identify tick species during a human-tick encounter. Project Narrative. Despite the importance of tick vector surveillance for disease prevention, current practices to collect and identify specimens are resource intensive, limiting the quality and quantity of the data informing control efforts. Here we propose the determination of optical requirements for visualization of diagnostic features of the top nine US tick vectors, and the development of high-accuracy computer vision algorithms for the identification of tick species and sex for use in a standardized optical configuration. The high-accuracy tick classification system developed through this proposal promises to expand capacity and capability for tick vector surveillance.",Optical design and the development of high accuracy automated tick classification using computer vision,10325667,R43AI162425,"['Adult', 'Agreement', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Car Phone', 'Cellular Phone', 'Classification', 'Collaborations', 'Computer Vision Systems', 'Culicidae', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Disease Surveillance', 'Disease Vectors', 'Future', 'Goals', 'Grain', 'Human', 'Image', 'Incidence', 'Insecta', 'Larva', 'Learning', 'Leg', 'Life', 'Lighting', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Nymph', 'Optics', 'Phase', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Resolution', 'Resources', 'Scientist', 'Spatial Distribution', 'Specimen', 'Standardization', 'Surveillance Methods', 'System', 'Telephone', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Time', 'Training', 'Vaccines', 'Validation', 'Visual', 'Visualization', 'Work', 'base', 'citizen science', 'convolutional neural network', 'design', 'detection method', 'disorder prevention', 'field study', 'flexibility', 'high resolution imaging', 'high risk', 'human disease', 'imaging platform', 'imaging system', 'improved', 'insight', 'intelligent algorithm', 'interest', 'mobile application', 'novel', 'sample collection', 'sex', 'tick bite', 'tool', 'validation studies', 'vector', 'vector control', 'vector tick']",NIAID,"VECTECH, LLC",R43,2021,295705
"A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging PROJECT SUMMARY  Obesity is a significant and growing problem in the United States. Currently, 68.5% of the U.S. population is overweight, with approximately 37.7% of the overweight population being obese. The significant health problems associated with overweightedness and obesity, the “body habitus” of this population combined with the significant challenges in medical imaging of these individuals reduces the effectiveness of healthcare for this population. In ultrasound imaging, the quality of abdominal ultrasound exams are significantly affected by obesity.  Fundamentally, an ultrasound image relies on acoustic propagation to a target, reflection, and then propagation back to the surface. The process of beamforming, which converts the surface measurement to an image, is sensitive to the low amplitude reflections from different tissue layers and tissue properties. Typically, the additional fat and connective tissue layers in obese patients can significantly degrade ultrasound image quality by introducing multi-path reverberation and phase aberration that obscure or distort these low amplitude reflections.  However, due to the computational complexity of describing ultrasound propagation and reflection in heterogeneous media, beamformers currently rely on simplified models that do not describe the propagation physics directly. We propose a generational leap in how we approach ultrasound beamforming by using physically and anatomically realistic wave propagation models and measurements that can effectively harness the power of data-driven and rapidly evolving machine learning beamformers. A custom highly realistic simulation tool that we have developed will use acoustical maps of the fine structures in the human body based on photographic cryosections. This physics-based approach will allow us to develop high quality training data and to understand the physical mechanisms for image quality improvement. These simulations will be calibrated to ex vivo and in vivo human data to subsequently generate a large data set that can be used to train a machine- learning-based real-time beamformer. We will focus on two sources of image degradation which we have identified to be particularly deleterious: multipath reverberation and aberration of the focusing profile. The proposed neural network beamformer filters incoherent noise, such as multi-path reverberation, and corrects aberration in the radiofrequency channel signals.  After training the beamformer and implementing it in real-time, a pilot human study in liver ultrasound imaging will be conducted to determine the improvement in image quality in high-body-mass index individuals, where diagnostic imaging is problematic due to image degradation. This technique is highly translatable to other clinical scenarios, varying from cardiac to transcranial to obstetric imaging, by changing the anatomical model. Furthermore, the physical concepts that will be extracted from the learned representation, can be used to improve the design process for ultrasound equipment, including transmit sequences, and transducers. RELEVANCE TO PUBLIC HEALTH Ultrasound beamforming, the process of transforming ultrasound into an image, is based on the principles of wave propagation which are complex due to the soft tissue structure in the human anatomy. Currently, ultrasound imaging uses simplified models of wave propagation. Here we address these limitations with physically and anatomically realistic propagation models based on the human anatomy that can effectively train and harness the power of machine learning beamformers. This technique directly addresses the principal challenge and objective of ultrasound beamforming, which is to limit unwanted acoustical effects from superficial tissue while maximizing signal from deep targets. The advancement of the proposed technology addresses the clear clinical need to provide diagnostic imaging to the growing population of body-limited imaging cases.",A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging,10130064,R01EB029419,"['3-Dimensional', 'Abdomen', 'Acoustics', 'Address', 'Affect', 'Anatomic Models', 'Anatomy', 'Back', 'Cardiac', 'Carotid Arteries', 'Characteristics', 'Clinical', 'Complex', 'Connective Tissue', 'Custom', 'Data', 'Data Set', 'Databases', 'Dependence', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of obstetrics', 'Effectiveness', 'Equipment', 'Fatty acid glycerol esters', 'Generations', 'Health', 'Healthcare', 'Human', 'Human body', 'Image', 'Individual', 'Left', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Measurement', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Noise', 'Obesity', 'Overweight', 'Patients', 'Phase', 'Physics', 'Population', 'Process', 'Property', 'Public Health', 'Resolution', 'Signal Transduction', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Transducers', 'Ultrasonic wave', 'Ultrasonography', 'United States', 'Weight', 'base', 'deep learning', 'design', 'health care quality', 'high body mass index', 'human data', 'human study', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo imaging', 'large datasets', 'learning strategy', 'liver imaging', 'neural network', 'obese patients', 'prototype', 'radio frequency', 'relating to nervous system', 'simulation', 'soft tissue', 'sound', 'tissue phantom', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,521287
"Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans Project Summary The long-term goal of this research is to establish a pipeline for automated image processing that enhances cadaveric non-contrast enhanced (NCE) CT data and extracts meaningful models and metrics to improve anatomy research and education. The objective is to develop the necessary toolset for this image processing, and feature extraction. The central hypothesis is that it is possible to enrich the information content of biomedical imaging data, particularly that of cadaveric NCE CT imaging, for use in gross anatomy education and research. The rationale behind this project is that cadaveric dissection, while an important part of anatomy education, is limited due to sample size, infrastructure, cost, and time. Biomedical imaging can preserve specimens for posterity and be used to supplement this material by providing statistical and quantitative information from anatomical structures. This research will attempt to establish a working pipeline for efficient information extraction through the following specific aims: (1) Improving inter-observer anatomical agreement in cadaveric CT scans; (2) Develop an approach to automatically segment anatomical structures from non-contrast enhanced CT images; and (3) Establish normal variation of anatomical structures and its relationship to pathologies. This project is innovative because it applies artificial intelligence to efficiently extract anatomical information from cadaveric NCE CT imaging, which has only been performed with traditional registration- dependent methods that often fail and are domain specific, acting on a single organ at a time. In addition, this project works with multi-species data to enhance human image data.  This project is significant because it will allow students to understand anatomical variation better by both expanding student exposure to more samples, while also extracting useful representations and analytics from these samples for education and research. The expected outcome of this project is a toolset that is capable of enhancing anatomy education and research by increasing soft-tissue contrast, automatically segmenting the kidneys, liver, mandible, and intraosseus sites of the cranial nerves, and performing statistical analysis on these organs, including but not limited to statistical shape modelling and shape analysis. This will have a positive impact on anatomical education and student retention because it will provide students with a broader range of sample variability information which will decrease pervading biases in medical training that result from small, limited sample sizes, and improve medical training. Project Narrative Dissection is a critical component of anatomy education but is limited due to the infrastructure required by the institution, the amount of variability in the available specimens, and the limited number of specimens available within the course. Biomedical imaging and analysis can be used to supplement dissection, allowing for an expansion in the number of anatomical specimens that students can observe and the amount of clinically relevant material that is available to students to improve their understanding of pathology and variation. This will expand student exposure to anatomical variation, produce more proficient medical professionals, and improve anatomy research.",Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans,10141430,F31EB030904,"['3-Dimensional', 'Address', 'Agreement', 'Anatomic Models', 'Anatomy', 'Artificial Intelligence', 'Blood coagulation', 'Buffaloes', 'Cadaver', 'Characteristics', 'Clinical', 'Computer Models', 'Contrast Media', 'Coupled', 'Cranial Nerves', 'Data', 'Development', 'Diagnostic', 'Disease', 'Dissection', 'Education', 'Exposure to', 'Gifts', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Individual', 'Information Retrieval', 'Infrastructure', 'Institution', 'Kidney', 'Lead', 'Libraries', 'Liver', 'Machine Learning', 'Mandible', 'Manuals', 'Medical', 'Medical Students', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Nature', 'Noise', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Population', 'Preservation Technique', 'Process', 'Reading', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Scanning', 'Shapes', 'Signal Transduction', 'Site', 'Specimen', 'Statistical Data Interpretation', 'Structure', 'Students', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Variant', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'bioimaging', 'clinically relevant', 'cohort', 'contrast enhanced', 'cost', 'deep learning', 'demographics', 'education research', 'feature extraction', 'human imaging', 'image processing', 'image registration', 'improved', 'innovation', 'interest', 'non-invasive imaging', 'posters', 'preservation', 'programs', 'quantitative imaging', 'retention rate', 'segmentation algorithm', 'shape analysis', 'soft tissue', 'success', 'virtual']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,F31,2021,30805
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction', 'risk prediction model', 'risk stratification', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,P41EB028741,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2021,1527478
"Developing computational algorithms for histopathological image analysis Project Summary  Histopathology is the cornerstone of disease diagnosis and prognosis. With the advance of imaging technology, whole-slide image (WSI) scanning of tissue slides is becoming a routine clinical procedure and producing a massive amount of data that captures histopathological details in high resolution. Most current pathological image analysis methods, similar to general image analysis approaches, mainly focus on morphology features, such as tissue texture and granularity, but ignore the complex hierarchical structures of tissues. Cells are the fundamental building blocks to tissues. Different types of cells are first organized into cellular components, which together with the extracellular matrix, form different types of tissue architectures. Understanding the interactions among these different types of cells can provide critical insights into biology and disease status. However, there are some major computational challenges: (1) How to identify and classify different types of cells in tissue, (2) how to characterize the highly complex and heterogeneous spatial organization of tissue, and (3) how to integrate histopathology data with other types of data to study disease status and progression. The goal of this proposal is to develop novel computational methods to analyze histopathology image data to study disease status and progression. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, statistical modeling, and clinical pathology. Specifically, we will develop novel algorithms to: (1) classify different types of cells from histopathology tissue WSI scans, (2) characterize and quantify cell spatial distribution and cell-cell interactions, and (3) integrate histopathology data with other types data to study disease progression. All proposed methods were motivated by real-world biological and clinical applications across different types of diseases, such as liver diseases, infectious diseases, and cancer. If implemented successfully, the proposed study will facilitate the analysis and modeling of data generated from histopathology tissue slides to improve disease risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in histopathology imaging and computing have enabled the in-depth characterization of pathology tissues. The overarching goal of this proposal is to develop computational algorithms to analyze histopathology image data to study disease status and progression.",Developing computational algorithms for histopathological image analysis,10097119,R01GM140012,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Bayesian Method', 'Biological', 'Biology', 'Biomedical Research', 'Cell Communication', 'Cells', 'Classification', 'Clinical', 'Clinical Pathology', 'Communicable Diseases', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Diagnosis', 'Disease', 'Disease Progression', 'Evaluation', 'Extracellular Matrix', 'Genomics', 'Goals', 'Graph', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Intuition', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Physics', 'Procedures', 'Research', 'Resolution', 'Risk Assessment', 'Scanning', 'Slide', 'Spatial Distribution', 'Stains', 'Statistical Models', 'Structure', 'Texture', 'Tissue imaging', 'Tissues', 'base', 'cancer type', 'cell type', 'clinical application', 'clinical care', 'convolutional neural network', 'data integration', 'data modeling', 'deep learning algorithm', 'digital', 'digital pathology', 'disease diagnosis', 'disorder risk', 'drug discovery', 'experience', 'improved', 'insight', 'machine learning method', 'molecular pathology', 'multiple datasets', 'novel', 'outcome forecast', 'outcome prediction', 'particle', 'pathology imaging', 'predictive modeling', 'software development', 'user friendly software', 'whole slide imaging']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,409167
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,10188407,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'automated algorithm', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'point-of-care diagnosis', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,1079736
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10183329,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2021,797476
"AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution Abstract. Whole-organ 3D immunohistochemistry is revolutionizing the field of neuroscience, enabling unprecedented insight into the distribution of neural cells and neurological markers throughout the brain in health and disease. LifeCanvas Technologies is at the forefront of the new field of spatial proteomics, providing a complete workflow for whole-organ preservation, tissue clearing, immunohistochemical labeling, and imaging. Nevertheless, an ongoing challenge for such studies is the need to rapidly, reproducibly and rigorously quantify terabyte-sized datasets from whole-organ imaging efforts. While progress has been made in applying Artificial Intelligence (AI) tools to enable detection of cellular and sub-cellular markers in neural tissue, one-size-fits-all algorithms are inadequate for analyzing complex, information-rich brain datasets due to varying biomolecular expression patterns (e.g. nuclear, cytoplasmic, membrane-bound) and region-specific heterogeneities in cell density and neural cell types. However, AI-driven algorithms targeting a subset of labeling patterns can be effective provided the availability of adequate training data. LifeCanvas Technologies LCT is optimally positioned to develop highly accurate algorithms serving a wide range of detection tasks through its access to high volumes of whole-organ image data containing a variety of label expression patterns via its Contract Research Organization and user base. LCT proposes to develop a data analysis program, SmartAnalytics, which will embed a suite of AI algorithms within a user-friendly software package to identify labeled cell locations and characterize morphological features across the whole brain at cellular and sub-cellular resolution. Specifically, LCT will use intact, 3D immunolabeled mouse brains to design AI algorithms to detect labeled cells imaged at cellular resolution and generate further algorithms for the segmentation of labeled features imaged at sub-micron resolution. Data from LCT’s Contract Research Organization and academic collaborations will be continually fed back to improve and expand the library of detection algorithms available within SmartAnalytics, and these developments will drive further customer adoption and enhancement of future versions of the software. SmartAnalytics will guide users through model application, quality-control testing, and the generation of output products such as figures and summary statistics. In summary, SmartAnalytics will be an evolving and user- friendly workflow execution program that enables neuroscientists to take full advantage of their 3D image data, driving new discoveries in brain function, development and disease. Narrative. The ability to readily and accurately quantify proteomic expression patterns that define neural cell- type specific distributions and morphologies across intact brains will enable unprecedented and unbiased insights into studies of brain function. LifeCanvas Technologies’ state-of-the-art tissue processing pipeline provides uniform clearing, labeling, and imaging of whole brains at cellular and sub-cellular resolution. By developing Artificial Intelligence algorithms to detect labeled cells and determine morphologies and by packaging these algorithms in a user-friendly software ‘SmartAnalytics’, LifeCanvas will enable neuroscientists to quantify image data and derive critical results towards a more complete understanding of brain function in development, health and disease.",AI-driven biomarker analysis of intact whole brains imaged at micron and sub-micron resolution,10139966,R43MH125512,"['3-Dimensional', 'Adoption', 'Algorithms', 'Amyloid beta-Protein', 'Antibodies', 'Artificial Intelligence', 'Astrocytes', 'Automobile Driving', 'Back', 'Binding Proteins', 'Biological Markers', 'Brain', 'Brain imaging', 'Cell Density', 'Cell membrane', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cytoplasm', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Feedback', 'Future', 'Generations', 'Glial Fibrillary Acidic Protein', 'Health', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunohistochemistry', 'Individual', 'Institutes', 'Label', 'Libraries', 'Location', 'Maps', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neurologic', 'Neurons', 'Neurosciences', 'Nuclear', 'Organ', 'Organ Preservation', 'Output', 'Pattern', 'Positioning Attribute', 'Process', 'Proteins', 'Proteomics', 'Quality Control', 'Research Contracts', 'Resolution', 'Rosaniline Dyes', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissue imaging', 'Tissues', 'Training', 'algorithm development', 'base', 'biomarker-driven', 'cell type', 'cellular imaging', 'computerized data processing', 'cost', 'design', 'extracellular', 'improved', 'insight', 'intelligent algorithm', 'neuronal cell body', 'new technology', 'programs', 'relating to nervous system', 'segmentation algorithm', 'software development', 'statistics', 'submicron', 'terabyte', 'tissue processing', 'tool', 'user friendly software', 'user-friendly']",NIMH,"LIFECANVAS TECHNOLOGIES, INC.",R43,2021,226754
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10143312,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2021,499966
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,10066353,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2021,373738
"A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC) Project Summary/Abstract: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will include datasets produced locally at Washington University: The Connectome Coordination Facility (CCF) (which itself includes the Human Connectome Project (HCP) Young Adult study, The Lifespan related projects, the Disease related projects, and assorted HCP-related projects), The Knight Alzheimer Disease Research Center (ADRC), the Adolescent Brain Cognitive Development (ABCD) Study, The Comprehensive Neuro-Oncology Data Repository (CONDR), and the clinically-based PACS image repository. In addition, copies of external data collections such as the UK Biobank, The Alzheimer's Disease Neuroimaging Initiative (ADNI), and The Cancer Image Archive (TCIA) will be maintained. The RIR includes a data management software solution that will introduce many novel features (such as `data tagging' to enrich datasets, and advanced search features) and will allow us to leverage existing storage including the Center for High Performance Computing's (CHPC) 1.4PB of BeeGFS `scratch' storage, solid-state NVMe drives integrated into the compute nodes, and 10PB of ZFS-based storage. All storage will be presented to the user as a single file-system, while data will be migrated to different performance tiers based on the storage requirements of the datasets or processing algorithms. The RIR will be integrated into the CHPC for data processing. The proposal also includes two NVIDIA DGX A100 GPU servers providing state-of-the-art GPU- based processing power. The combination of high-quality, diverse sets of biomedical imaging data with next- generation computing power will have a transformative effect on biomedical imaging processing pipelines and nowhere will the effects be more profound than in the emerging field of Deep Learning for image processing. Project Narrative: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will be integrated into Washington University in St. Louis's Center for High Performance Computing (CHPC) to process the data and will leverage over 11PB of existing storage.",A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC),10177147,S10OD030477,"['Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Clinical', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Disease', 'High Performance Computing', 'Human', 'Longevity', 'Performance', 'Research', 'System', 'The Cancer Imaging Archive', 'Universities', 'Washington', 'base', 'biobank', 'bioimaging', 'cognitive development', 'computerized data processing', 'connectome', 'data management', 'data repository', 'deep field survey', 'deep learning', 'image archival system', 'image processing', 'neuro-oncology', 'neuroimaging', 'next generation', 'novel', 'solid state', 'young adult']",OD,WASHINGTON UNIVERSITY,S10,2021,1927344
"Super-Resolution Tau PET Imaging for Alzheimer's Disease PROJECT SUMMARY Preclinical Alzheimer’s disease (the presymptomatic phase of Alzheimer’s disease) is characterized by pathophysiological changes without measurable cognitive decline and begins decades before the onset of cognitive symptoms. Preclinical Alzheimer’s disease research is in pressing need of new biomarker endpoints to enable disease monitoring before traditional cognitive endpoints are measurable. The overarching research objectives of this R03 Small Project Grant are to develop a super-resolution (SR) positron emission tomography (PET) imaging framework for tau (a pathophysiological hallmark of Alzheimer’s disease) and to assess the clinical utility of localized outcome measures obtained from SR PET images. Studies show that tau pathology in the medial temporal lobe is an important marker of cognitive decline in Alzheimer’s disease. Cohorts focused on preclinical Alzheimer’s now incorporate serialized 18F-flortaucipir PET scans for longitudinal tracking of tau accumulation in key anatomical regions-of-interest (ROIs). The quantitative accuracy of tau PET, however, is degraded by the limited spatial resolution capabilities of PET, which lead to inter-ROI spillover and partial volume effects. The problem is further compounded in studies spanning several decades, many of which were commenced on legacy scanners with even lower resolution capabilities than the current state of the art. Additionally, many longitudinal studies began on older scanners and later transitioned to newer models posing a multi-scanner data harmonization challenge. The proposed SR framework will perform a mapping from a low- resolution scanner’s image domain to a high-resolution scanner’s image domain and enable PET resolution recovery and data harmonization. Underlying the proposed framework is a neural network model that can be adversarially trained in self-supervised mode without requiring paired input/output image samples for training. This critical feature ensures practical clinical utility of the method as the need for paired low-resolution and high- resolution datasets from the same subject with similar tracer dose and scan settings is a major barrier for the clinical translatability of simpler supervised alternatives for SR. The proposed network, although trained using unpaired clinical data, receives guidance from an ancillary neural network separately pretrained using paired simulation datasets. For this purpose, we will synthesize paired low- and high-resolution images from a series of digital tau phantoms that will be created for this project. Training and validation of the self-supervised SR framework will be performed via secondary use of de-identified 18F-flortaucipir PET scans from the Harvard Aging Brain Study, a longitudinal cohort focused on preclinical Alzheimer’s disease. We will evaluate SR performance using a variety of image quality metrics. To assess the clinical utility of localized super-resolution measures, we will perform cross-sectional statistical power analyses that estimate sample sizes per arm needed to power clinical trials. Accurate localized measures of tau generated by this project could enable early diagnosis of Alzheimer’s disease and facilitate ongoing clinical trials by reducing sample sizes required for a given effect size. PROJECT NARRATIVE The objective of this R03 Small Project Grant is to develop methods for generating high-resolution images of abnormal tau protein tangles, which are a hallmark of Alzheimer’s disease. This will be achieved by building a self-supervised super-resolution framework based on a deep neural network for positron emission tomography (PET) imaging of tau. The proposed imaging technique can facilitate early diagnosis and accurate monitoring of Alzheimer’s disease.",Super-Resolution Tau PET Imaging for Alzheimer's Disease,10118776,R03AG070750,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Anatomy', 'Artificial Intelligence', 'Binding', 'Biological Markers', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cognitive', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Disease Progression', 'Dose', 'Early Diagnosis', 'Early Intervention', 'Ensure', 'Evaluation', 'Funding Opportunities', 'Future', 'Goals', 'Grant', 'Image', 'Imaging Techniques', 'Impaired cognition', 'Lead', 'Longitudinal Studies', 'Longitudinal cohort', 'Longitudinal cohort study', 'Measurable', 'Measures', 'Medial', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Names', 'Neural Network Simulation', 'Neurobehavioral Manifestations', 'Neurofibrillary Tangles', 'Outcome Measure', 'Output', 'Pathology', 'Performance', 'Phase', 'Positron-Emission Tomography', 'Recovery', 'Research', 'Resolution', 'Sample Size', 'Sampling', 'Scanning', 'Series', 'Statistical Data Interpretation', 'Supervision', 'Surrogate Markers', 'Techniques', 'Technology', 'Temporal Lobe', 'Tracer', 'Training', 'Treatment Efficacy', 'Validation', 'aging brain', 'arm', 'base', 'clinically translatable', 'cohort', 'data harmonization', 'deep learning', 'deep neural network', 'digital', 'drug development', 'high resolution imaging', 'high risk', 'human subject', 'improved', 'in vivo', 'innovation', 'interest', 'neural network', 'neural network architecture', 'neuroimaging', 'neuroimaging marker', 'novel', 'power analysis', 'pre-clinical', 'radioligand', 'radiotracer', 'rate of change', 'response', 'simulation', 'tau Proteins', 'tau aggregation', 'tau mutation']",NIA,UNIVERSITY OF MASSACHUSETTS LOWELL,R03,2021,151980
