text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342,570146095
"Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning Project Summary/Abstract A plethora of neuroscience studies shows mounting evidence that neurodegenerative diseases manifest distinct network dysfunction patterns much earlier prior to the onset of clinical symptoms. Since the subject-specific longitudinal network changes are more relevant to the neuropathological process than topological patterns derived from cross-sectional data, recognizing the subtle and dynamic longitudinal network biomarkers from noisy network data is of great demand to enhance the sensitivity and specificity of computer-assisted diagnosis in neurodegenerative diseases. However, current popular statistical inference or machine learning approaches used for neuroimages (in a regular data structure such as grid and lattice) are not fully optimized for the learning task on brain network data which is often encoded in a high dimensional graph (an irregular and non-linear data structure). Such gross adaption is partially responsible for the lack of reliable biomarkers that can be used to predict cognitive decline in routine clinical practice. To address this challenge, we aim to (1) develop a novel GNN (graph neural network) based learning framework to hierarchically discover the multi-scale network biomarkers that can recognize the disease-relevant network alterations over time, and (2) examine the diagnostic power of the new network biomarkers derived from our GNN-based machine learning engine across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia. The success of this project will allow us to integrate the novel GNN-based learning component into our current longitudinal network analysis toolbox and release the AI (artificial intelligence) based network analysis software to the neuroscience and neuroimaging community. Project Narrative The goal of this project is to continue the tool development of longitudinal network analysis for neurodegenerative diseases with the focus on the machine learning component. To do so, we will first develop the GNN (graph neural network) based learning framework to discover the multi-scale network biomarkers from the population of brain network data. After examining the diagnostic value of the network biomarkers discovered by our learning- based method across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia, we will integrate the machine learning component into our current longitudinal network analysis software and release to the neuroscience and neuroimaging community.",Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning,10109509,R03AG070701,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Artificial Intelligence', 'Biological Markers', 'Brain', 'Clinical', 'Cognitive', 'Communities', 'Computer software', 'Computer-Assisted Diagnosis', 'Data', 'Databases', 'Diagnostic', 'Dimensions', 'Disease', 'Early Diagnosis', 'Event', 'Evolution', 'Frontotemporal Dementia', 'Goals', 'Graph', 'Image', 'Impaired cognition', 'Individual', 'Industry', 'Investigation', 'Label', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Nerve Degeneration', 'Network-based', 'Neural Network Simulation', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Neurosciences', 'Outcome', 'Parkinson Disease', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Research', 'Resolution', 'Resources', 'Sample Size', 'Senile Plaques', 'Sensitivity and Specificity', 'Source Code', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Text', 'Time', 'United States National Institutes of Health', 'base', 'clinical practice', 'cohort', 'collaboratory', 'comparison group', 'computerized tools', 'data mining', 'data structure', 'deep learning', 'design', 'high dimensionality', 'machine learning method', 'method development', 'network dysfunction', 'neural network', 'neuroimaging', 'novel', 'outcome forecast', 'software development', 'success', 'tool', 'tool development']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R03,2021,158733,511185245
"Data Science Applications in Communication andSwallowing Disorders PROJECT SUMMARY/ABSTRACT The emergence of electronic medical records, large data registries and readily accessible, protected servers have resulted in an explosion of digital information with potentially high clinical impact for improving patient management and outcomes. Big data warehouses that capture standardized information within the scope of clinical practices allow trained scientists to not only engage in traditional hypothesis testing, but to also uncover new hypotheses, refine existing theories and apply new discoveries to health assessments and interventions. Despite the accessibility and potential impact of these data platforms, clinician scientists have traditionally directed experiments that incorporate relatively small sample sizes and data from individual laboratories, and have not been trained in big data analytics or in engaging appropriate team scientists who work in this space, such as computer scientists, biostatisticians and engineers. The overarching goal of this proposal is to mentor early patient oriented communication and swallowing scientists in big data analytics and to mentor and involve early data science scholars in communication and swallowing research. The PI proposes four primary mentorship and research goals in this K24 renewal proposal: 1. Train a cadre of early stage communication and swallowing scientists in data science methods, including machine learning, by an expert, interdisciplinary, collaborative data science team, 2. Engage and introduce early career data scientists from fields of biostatistics, computer science and engineering to communication and swallowing sciences, and respective data sets, toward facilitating interdisciplinary data science teams and research productivity, 3. Apply novel data science methods to identify phenotypes of swallowing impairment and severity classifications in patient groups known to be at high risk for nutritional and health complications related to dysphagia, and 4. Develop a new area of research in machine learning applications toward improving reliability of physiologic swallowing assessment. The data science theme of the career development and research plan directly align with NIDCD's Strategic Plan for Data Science which lists as its mission: Storing, managing, standardizing and publishing the vast amounts of data produced by biomedical research. NIDCD recognizes that accessible, well-organized, secure and efficiently operated data resources are critical to modern scientific inquiry…and by maximizing the value of data generated through NIH-funded efforts, the pace of biomedical discoveries and medical breakthroughs for better health outcomes can be accelerated. PROJECT NARRATIVE The emergence of electronic health records exposes clinicians to massive amounts of information about the millions of patients who suffer from communication and swallowing disorders, yet most clinical scientists do not have the training or skill to apply meaning to the data toward improving patient care. The overarching mentorship goal of this proposal is to train early, patient-oriented communication and swallowing scientists in big data analyses, including computer machine learning approaches. The research project will uncover distinct patterns and severity of swallowing impairments in large groups of patients with high risk medical diagnoses, which will have high impact on patient care planning and identification of treatments that directly target these impairments for improved outcomes.",Data Science Applications in Communication andSwallowing Disorders,10073493,K24DC012801,"['Algorithms', 'Area', 'Award', 'Barium swallow', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Communication', 'Communication impairment', 'Computer Vision Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Data Scientist', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Economics', 'Electronic Health Record', 'Engineering', 'Explosion', 'Funding', 'Geography', 'Goals', 'Grant', 'Head and Neck Cancer', 'Health', 'Hearing', 'Impairment', 'Individual', 'Instruction', 'Intervention', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Records', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Mission', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Nutritional', 'Outcome', 'Parkinson Disease', 'Patient Care', 'Patient Care Planning', 'Patients', 'Pattern', 'Phenotype', 'Physiological', 'Productivity', 'Publishing', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Science', 'Scientific Inquiry', 'Scientist', 'Secure', 'Severities', 'Speech', 'Standardization', 'Statistical Models', 'Strategic Planning', 'Stroke', 'Supervision', 'Techniques', 'Testing', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computer science', 'computerized', 'data registry', 'data resource', 'data warehouse', 'digital', 'experimental study', 'health assessment', 'high risk', 'human error', 'impression', 'improved', 'improved outcome', 'learning algorithm', 'novel', 'patient oriented', 'programs', 'research and development', 'skills', 'statistical learning', 'theories', 'uptake']",NIDCD,NORTHWESTERN UNIVERSITY,K24,2021,183209,66720547
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,10164762,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Villous Atrophy', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'dietary', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'systemic inflammatory response', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2021,192552,169622494
"Leveraging computational models of neurocognition to improve predictions about individual youths' risk for substance use disorders PROJECT SUMMARY/ABSTRACT This K23 proposal seeks to provide an early-career clinical psychologist and neuroscientist (Dr. Alexander Weigard) with the mentorship, training, and resources necessary to launch a career as an independent patient- oriented investigator focused on using advanced computational methods to elucidate etiological mechanisms of substance use disorders (SUDs) and generate meaningful predictions for patients. The candidate will work towards this long-term goal through the completion of a research project focused on assessing whether two advanced computational methods can facilitate the selection of features from neuroscientific data that are relevant for the individualized prediction of SUD risk in youth. Although extant research in developmental neuroscience has identified multiple early risk factors that are associated with development of SUD at the group level, there is currently a dearth of large scale, replicable research in which neurocognitive data are used to make reliable and generalizable predictions of SUD outcomes for individual youth. In the proposed project, the candidate will combine his existing expertise in computational models of cognition with new training in predictive informatics methods to assess whether two advanced computational approaches, a) sequential sampling models (SSMs) of cognition and b) network neuroscience, can be used to extract features from longitudinal neurocognitive data that enhance the prediction of youths’ SUD outcomes. The candidate will conduct extensive analyses with two large data sets (Michigan Longitudinal Study, Adolescent Brain Cognitive Development Study) and collect pilot data with 60 young adults to accomplish the following research aims: 1) Quantify the added benefit of SSM parameters for improving the performance of multivariate SUD prediction models, and 2) Identify the multivariate neural signature of v, an SSM parameter with promising links to substance use, and determine the potential of this signature for predicting a precursor to SUD (substance use initiation in mid-adolescence) in ABCD and differentiating young adults with SUDs in the newly-collected pilot sample. Completion of the following training objectives will ensure that the candidate can both carry out the proposed project and establish himself as an independent investigator who is well-equipped to conduct future projects following from this work: 1) Mastering principles of machine learning model development and testing in longitudinal data sets, 2) building expertise in using multivariate network neuroscience methods for feature selection and prediction, 3) increasing clinical and epidemiological knowledge of SUD risk factors beyond neurocognition, and 4) improving professional skills necessary to become an independent patient-oriented investigator. The proposed K23 aims to take a crucial step towards the development of advanced computational neuroscience methods that may ultimately inform SUD prevention efforts by identifying reliable predictors of individuals’ SUD risk, and to set the candidate up to independently conduct leading edge research in the interest of this larger goal. PROJECT NARRATIVE Decades of developmental neuroscience research have illuminated multiple factors that convey risk for the development of substance use disorders (SUDs) at the group level, but the field currently lacks methods for using neurocognitive data to make accurate and generalizable predictions about SUD risk for individual youth. The proposed project seeks to address this critical gap in the field by providing an early-career scientist with the tools and training necessary to test whether the combination of two advanced computational approaches, sequential sampling models of cognitive functioning and network neuroscience methods, improve the accuracy of multivariate predictive models of individuals’ SUD risk. Knowledge from this project could lead to the development of novel computational approaches that optimize the identification of predictive features in youths’ neurocognitive data, which may ultimately inform SUD prevention efforts.",Leveraging computational models of neurocognition to improve predictions about individual youths' risk for substance use disorders,10213907,K23DA051561,"['Address', 'Adolescence', 'Adolescent', 'Adult', 'Advanced Development', 'Age', 'Alcohol or Other Drugs use', 'Behavioral', 'Brain', 'Brain region', 'Clinical', 'Clinical Investigator', 'Cognition', 'Cognitive', 'Collection', 'Computer Models', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Early Intervention', 'Ensure', 'Epidemiology', 'Etiology', 'Future', 'Goals', 'Image Analysis', 'Individual', 'Individual Differences', 'Informatics', 'Knowledge', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Neurocognition', 'Neurocognitive', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Patients', 'Performance', 'Personality', 'Preventive Intervention', 'Psychologist', 'Psychopathology', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Rest', 'Risk', 'Risk Factors', 'Sampling', 'Sampling Studies', 'Scientist', 'Substance Use Disorder', 'Testing', 'Training', 'Validation', 'Work', 'Youth', 'addiction', 'adolescent substance use', 'base', 'career', 'cognitive development', 'cognitive function', 'computational neuroscience', 'connectome', 'design', 'disorder prevention', 'disorder risk', 'early onset substance use', 'emerging adulthood', 'feature selection', 'improved', 'indexing', 'interest', 'large datasets', 'learning network', 'longitudinal dataset', 'meetings', 'model development', 'neural patterning', 'neurocognitive test', 'neuroimaging', 'novel', 'patient oriented', 'personalized predictions', 'predictive modeling', 'predictive signature', 'psychosocial', 'relating to nervous system', 'skills', 'statistics', 'theories', 'tool', 'trait', 'young adult']",NIDA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2021,196560,641965656
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250,685608202
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591,61050884
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876,338121506
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,10145719,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2021,378183,63611576
"The neural computations supporting hierarchical reinforcement learning The neural computations supporting hierarchical reinforcement learning - Project Summary. This project explores how humans learn at multiple hierarchical levels in parallel, and how this supports human intelligence. Human decisions are typically hierarchically structured: we make high-level decisions (making a cup of coffee), which constrain lower level decisions (grinding coffee beans, boiling water, etc.), which themselves constrain simpler and simpler decisions and motor actions. This hierarchy in decisions is paralleled by a hierarchy in our representation of our environment: some sensory signals trigger simple decisions (a red light signals a stop), while other signal a broader, more abstract behavioral change (rain signals a set of adaptations when driving). Thus, complex hierarchical structure underlies the way we respond to our environment in seemingly simple, everyday tasks. This ability is supported by the prefrontal cortex, which represents states and decisions at multiple degrees of hierarchical abstraction. My previous work shows that hierarchical representations support transfer and generalization while learning, an ability that artificial agents still struggle to match human performance in. However, how we learn to form these hierarchical representations is poorly understood, despite how crucial it is for human intelligence. The proposed work will examine how multiple, parallel hierarchical loops between prefrontal cortex and the basal ganglia support reinforcement learning at multiple hierarchical levels in parallel, and how this promotes flexible behavior. To this end, we will address three aims: 1. We will show that the same reinforcement learning computations happen in parallel at multiple levels of abstraction, as hypothesized by our computational model of prefrontal- subcortical networks. 2. We will demonstrate that humans partition learning problems into multiple sequential subgoals so they can learn multiple simple strategies instead of one complex strategy, and that reusing these simple strategies promotes fast exploration and learning. 3. We will show that hierarchical learning does not rely exclusively on rewards, but that novelty signals are crucial for identifying subgoals and learning through curiosity. Across all three aims, we will use behavioral experiments in conjunction with computational modeling to characterize how humans learn hierarchically. In addition, we will use EEG and fMRI to identify the neural computations underlying the cognitive systems inferred from behavior and modeling. This project will provide new insights into the computational mechanisms that give rise to learning, and thus provide a better handle on the sources of learning dysfunction observed in many psychiatric diseases, including schizophrenia, depression, anxiety, ADHD, and OCD. Additionally, it will provide new tools, in the form of experimental protocols and precise computational models, for studying learning across populations and species. Project Narrative This proposal will explore how learning hierarchically structured representations of our environments helps humans adapt flexibly and efficiently to new situations. We will record how people learn to make simple decisions, observe changes in brain activity, and use mathematical models to study how hierarchical learning happens in the brain. This will help explain how human learning can be so efficient and flexible, how mental conditions such as schizophrenia, depression, and anxiety cause learning and decision-making impairments, and will help develop better treatments.",The neural computations supporting hierarchical reinforcement learning,10113371,R01MH119383,"['Address', 'Anterior', 'Anxiety', 'Area', 'Artificial Intelligence', 'Attention deficit hyperactivity disorder', 'Automobile Driving', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Brain', 'Clinical', 'Coffee', 'Complex', 'Computer Models', 'Corpus striatum structure', 'Curiosities', 'Data', 'Decision Making', 'Diagnosis', 'Disease', 'Dopamine', 'Educational process of instructing', 'Electroencephalography', 'Environment', 'Experimental Models', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Goals', 'Human', 'Impairment', 'Individual', 'Intelligence', 'Lead', 'Learning', 'Life', 'Light', 'Mental Depression', 'Mental disorders', 'Modeling', 'Motor', 'Outcome', 'Outcomes Research', 'Performance', 'Play', 'Population', 'Prefrontal Cortex', 'Process', 'Protocols documentation', 'Psyche structure', 'Psychiatry', 'Psychological reinforcement', 'Rain', 'Research Domain Criteria', 'Rewards', 'Role', 'Schizophrenia', 'Sensory', 'Signal Transduction', 'Source', 'Structure', 'System', 'Testing', 'Thinking', 'Variant', 'Water', 'Work', 'autism spectrum disorder', 'base', 'bean', 'cognitive system', 'executive function', 'experimental study', 'flexibility', 'insight', 'learning algorithm', 'mathematical model', 'neuromechanism', 'novel', 'prevent', 'relating to nervous system', 'skills', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2021,380647,148186688
"Bioinformatics for post-traumatic stress Project Summary/Abstract Maladaptive complications following trauma, including post-traumatic stress (PTS), are highly prevalent in both veterans and civilians, and have been difficult to accurately diagnose, manage and treat. Debate regarding diagnostic criteria and the need to represent the full spectrum of inter-connected features contributing to psychopathology has spawned the development of the Research Domain Criteria (RDoC) by the National Institute of Mental Health (NIMH). RDoC is a developing framework to help guide the discovery and validation of new dimensions of mental health disorders and their relationships to underlying biological mechanisms. NIMH now has a rich federated database that currently houses raw data from RDoC-sponsored clinical research, and clinical trial data from the National Database of Clinical Trials (NDCT) with information that may help to unlock the complex and overlapping relationships between symptoms of PTS and the underlying biomarkers to fuel improvements on diagnostic and therapeutic frameworks for trauma recovery. The proposed project will apply bioinformatics and machine learning analytical tools to these large, heterogeneous datasets to identify and validate new research dimensions of trauma-related psychopathology and treatment response trajectories and their predictors. Aim 1 will develop an in silico trauma patient population by integrating data from diverse sources, including cross-sectional and observational longitudinal clinical studies housed within available data repositories for trauma and other related mental health research. Data will include medical history, demographics, diagnostic tests, clinical outcomes, psychological assessments, genomics, imaging, and other relevant study and meta-data. Aim 2 will identify multiple dimensions of PTS diagnostic criteria, using a combination of unsupervised dimension-reduction statistical methods, internal and external cross-validation, and supervised hypothesis testing of predictive models to understand the heterogeneous subtypes of PTS. Aim 3 will deploy unsupervised machine learning methods, such as topological data analysis and hierarchical clustering, to identify unique clusters of patients based on symptomatology to develop clustering methods for precision mapping of PTS patients based on disease severity. Aim 4 will use supervised machine learning techniques for targeted predictive analytics focused on identifying treatment responders from the NDCT, and identification of latent variables that predict treatment response. The results of the proposed research project will greatly enrich the field of computational psychiatry research to identify conserved dimensions associated with the complex relationships of psychopathology and precision treatment planning following exposure to traumatic events. Project Narrative A recent restructuring of diagnostic and research criteria for psychiatric disorders has been implemented to promote greater understanding of the biological mechanisms involved in the development of complex mental health disorders. The proposed project aims to apply bioinformatics and machine learning analytics to large datasets from trauma-exposed patients to identify and validate dimensions of post-traumatic stress (PTS), relevant biological predictors, and precision treatment response trajectories.",Bioinformatics for post-traumatic stress,10205954,R01MH116156,"['Bioinformatics', 'Biological', 'Biological Markers', 'Categories', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Database', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Dimensions', 'Disease', 'Exposure to', 'Genomics', 'Growth', 'Image', 'Laboratories', 'Linear Models', 'Linear Regressions', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Medical History', 'Mental Health', 'Mental disorders', 'Metadata', 'Methods', 'Modeling', 'National Institute of Mental Health', 'Nervous System Trauma', 'Neurocognitive', 'Observational Study', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Principal Component Analysis', 'Psychiatry', 'Psychopathology', 'Recovery', 'Reproducibility', 'Research', 'Research Domain Criteria', 'Research Project Grants', 'Severity of illness', 'Source', 'Statistical Methods', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Therapeutic', 'Trauma', 'Trauma Research', 'Trauma patient', 'Trauma recovery', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Work', 'accurate diagnosis', 'analytical tool', 'base', 'biobehavior', 'combat veteran', 'computational platform', 'data archive', 'data mining', 'data repository', 'data sharing', 'demographics', 'diverse data', 'feature selection', 'federated computing', 'guided inquiry', 'hands-on learning', 'heterogenous data', 'in silico', 'indexing', 'innovation', 'insight', 'interest', 'large datasets', 'machine learning method', 'multidimensional data', 'multimodality', 'patient population', 'patient subsets', 'post-traumatic stress', 'post-traumatic symptoms', 'precision medicine', 'predictive modeling', 'predictive test', 'psychologic', 'research and development', 'research study', 'response', 'statistics', 'stress related disorder', 'supervised learning', 'symptomatology', 'tool', 'trauma exposure', 'traumatic event', 'treatment planning', 'treatment responders', 'treatment response', 'unsupervised learning', 'vector']",NIMH,UNIVERSITY OF MINNESOTA,R01,2021,501996,340417756
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125,340417756
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506,560644462
"BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging Project Summary Electrophysiological recordings in humans and animals play an essential role in developing an understanding of the human brain. Signal recording technology spans the entire scale from invasive microelectrode single-unit recordings, through mesoscale macroelectrode measures of local field potentials, to whole-brain monitoring through measurement of scalp potentials (EEG) and extracranial magnetic fields (MEG). Analysis of these data presents a host of challenges, from low level noise removal and artifact rejection to sophisticated spatio-temporal modeling and statistical inference. The multidisciplinary neuroscience research community has an ongoing need for validated and documented open-source software to perform this analysis and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets this need. Brainstorm is a Matlab/Java multi-platform (Linux, MacOS, Windows) software package for analysis and visualization of electrophysiological data. The software is extensively documented through a series of detailed tutorials and actively supported through a user forum and a mailing list. Over the past 8 years we have registered 16,000 distinct users, provided hands on instruction to 1,200 trainees, and the software has been used and cited in ~600 journal papers. Brainstorm includes tools for importing MEG/EEG, intracranial EEG, animal electrophysiology, and near-infrared spectroscopy (NIRS) data from multiple vendors, extensive interactive features for data preprocessing, selection and visualization, coregistration to volume and surface MRIs and atlases, forward and inverse mapping of cortical current density, time-series and connectivity analysis, and a range of statistical tools. Data can be analyzed through a graphical interface or through scripted pipelines. The current proposal represents a plan to extend Brainstorm in a manner that leverages the unique features of our software and addresses important needs for large-scale data analysis. In this project we will continue to extend and support our software through the following three specific aims: (i) we will harness recent developments in distributed and shared data and high performance computing resources, together with standardization of data organization, to facilitate large-scale, reproducible analysis of electrophysiological data. (ii) We will also address the need for improved modeling resulting from the increasing use of both invasive recordings and direct brain stimulation through development of new modeling software for accurate computation of the intracranial electromagnetic fields produced by brain stimulation and neuronal activation. (iii) Finally, we will continue to add new functionality and to support the software through in-person training, online forums, documentation and other resources. Project Narrative Magnetoencephalography (MEG) and Electroencephalography (EEG) are absolutely non-invasive brain imaging tools, which provide information on the spatial distribution and precise temporal orchestration of human brain activity. In addition to basic neuroscience research, MEG and EEG can be also used to understand and diagnose abnormalities underlying a wide range neurological and psychiatric illnesses, including epilepsy, schizophrenia, obsessive-compulsive disorder, autism spectrum disorders, and Alzheimer's disease, as well as cognitive deficits such as delayed acquisition of language. The neuroscience research community has an ongoing need for validated and documented open-source software to perform these analyses and to facilitate reproducible and large-scale research involving electrophysiological data. This proposal describes our plans to continue to develop and support Brainstorm, open-source software that meets these needs with well-documented and tested novel analyses using MEG and EEG in combination with anatomical MRI and intracranial EEG data.",BrainStorm: Highly Extensible Software for Advanced Electrophysiology and MEG/EEG Imaging,10113609,R01EB026299,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Archives', 'Area', 'Atlases', 'Basic Science', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical Research', 'Cloud Computing', 'Code', 'Cognitive deficits', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Development', 'Diagnosis', 'Documentation', 'Educational workshop', 'Electrodes', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Electrophysiology (science)', 'Ensure', 'Environment', 'Epilepsy', 'Excision', 'Frequencies', 'Goals', 'Grant', 'High Performance Computing', 'Human', 'Image', 'Imaging Device', 'Institution', 'Java', 'Joints', 'Journals', 'Language Development', 'Lead', 'Linux', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maintenance', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences Research', 'Noise', 'Obsessive-Compulsive Disorder', 'Online Systems', 'Paper', 'Pathway Analysis', 'Pattern', 'Persons', 'Play', 'Pythons', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scalp structure', 'Schizophrenia', 'Series', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Surface', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Universities', 'Vendor', 'Visualization', 'Work', 'autism spectrum disorder', 'cloud storage', 'cognitive benefits', 'computerized tools', 'computing resources', 'cortex mapping', 'data archive', 'data curation', 'data repository', 'data resource', 'data sharing', 'data standards', 'data structure', 'density', 'design', 'electric field', 'graphical user interface', 'hands on instruction', 'improved', 'interoperability', 'large datasets', 'large scale data', 'magnetic field', 'multidisciplinary', 'neuroimaging', 'novel', 'open source', 'relating to nervous system', 'response', 'spatiotemporal', 'tool']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,616433,324592664
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746,551214295
"A computer vision toolbox for computational analysis of nonverbal social communication PROJECT SUMMARY We will develop novel computer vision tools to reliably and precisely measure nonverbal social communication through quantifying communicative facial and bodily expressions. Our tools will be designed and developed in order to maximize their usability by non-engineer behavioral scientists, filling the enormous gap between engineering advances and their clinical accessibility. Significance: Social interaction inherently relies on perception and production of coordinated face and body expressions. Indeed, atypical face and body movements are observed in many disorders, impacting social interaction and communication. Traditional systems for quantifying nonverbal communication (e.g., FACS, BAP) require extensive training and coding time. Their tedious coding requirements drastically limits their scalability and reproducibility. While an extensive literature exists on advanced computer vision and machine learning techniques for face and body analysis, there is no well-established method commonly used in mental health community to quantify production of facial and bodily expressions or efficiently capture individual differences in nonverbal communication in general. As a part of this proposal, we will develop a computer vision toolbox including tools that are both highly granular and highly scalable, to allow for measurement of complex social behavior in large and heterogeneous populations. Approach: Our team will develop tools that provide granular metrics of nonverbal social behavior, including localized face and body kinematics, characteristics of elicited expressions, and imitation performance. Our tools will facilitate measurement of social communication both within a person and between people, to allow for assessment of individual social communication cues as well as those that occur within bidirectional social contexts. Preliminary Data: We have developed and applied novel computer vision tools to assess: (1) diversity of mouth motion during conversational speech (effect size d=1.0 in differentiating young adults with and without autism during a brief natural conversation), (2) interpersonal facial coordination (91% accuracy in classifying autism diagnosis in young adults during a brief natural conversation, replicated in an independent child sample), and (3) body action imitation (85% accuracy in classifying autism diagnosis based on body imitation performance). As apart of current proposal, we will develop more generic methods that can be used in normative and clinical samples. Aims. In Aim 1, we will develop tools to automatically quantify fine-grained face movements and their coordination during facial expression production; in Aim 2, we will develop tools to quantify body joint kinematics and their coordination during bodily expression production; in Aim 3, we will demonstrate the tools’ ability to yield dimensional metrics using machine learning. Impact: Our approach is designed for fast and rigorous assessment of nonverbal social communication, providing a scalable solution to measure individual variability, within a dimensional and transdiagnostic framework. PROJECT NARRATIVE This project develops novel tools for measuring nonverbal social communication as manifested through facial and bodily expressions. Using advanced computer vision and machine learning methodologies, we will quantify humans’ communicative social behavior. The results of this project will impact public health by facilitating a rich characterization of normative development of social functioning, providing access to precise phenotypic information for neuroscience and genetics studies, and by measuring subtle individual differences to determine whether some interventions or treatments work better than others.",A computer vision toolbox for computational analysis of nonverbal social communication,10150095,R01MH122599,"['Adolescent', 'Age', 'Area', 'Behavior', 'Behavioral', 'Behavioral Research', 'Behavioral Sciences', 'Characteristics', 'Child', 'Clinical', 'Code', 'Communication', 'Community Health', 'Complex', 'Computational Technique', 'Computer Analysis', 'Computer Vision Systems', 'Cues', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Educational Materials', 'Engineering', 'Face', 'Facial Expression', 'Genetic study', 'Goals', 'Gold', 'Grain', 'Grant', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Joints', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Motion', 'Movement', 'Nature', 'Neurologic', 'Neurosciences', 'Nonverbal Communication', 'Oral cavity', 'Participant', 'Perception', 'Performance', 'Persons', 'Phenotype', 'Population Heterogeneity', 'Production', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Scientist', 'Sex Differences', 'Social Behavior', 'Social Development', 'Social Environment', 'Social Functioning', 'Social Interaction', 'Speech', 'System', 'Techniques', 'Teenagers', 'Time', 'Training', 'Translations', 'Validation', 'Work', 'analysis pipeline', 'autism spectrum disorder', 'automated algorithm', 'base', 'behavior measurement', 'behavioral health', 'clinical application', 'computerized tools', 'design', 'individual variation', 'interest', 'kinematics', 'novel', 'open source', 'sex', 'social', 'social communication', 'tool', 'usability', 'young adult']",NIMH,CHILDREN'S HOSP OF PHILADELPHIA,R01,2021,660945,178185562
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835,593605914
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",10083748,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2021,750000,981500
"An interactive, digital platform to transform physical science learning Abstract: The next generation of science and health care professionals will need to understand the foundational concepts of physics. While textbooks play a critical role in science learning, these books are not designed to meet the diverse learning needs of students in today’s classrooms. Unfortunately, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current physical science textbooks and to revolutionize reading with interactive texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned force and motion (NGSS PS2A) content into Spanish (Aim 1); designing and developing science learning games (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content in both English and Spanish to address 9 additional NGSS standards (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive learning technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning disabilities. This Fast-Track project will produce a bilingual, digital platform to support students’ understanding of Physical Science, which will allow students to seamlessly move between different reading levels and languages, play science learning games, and receive personalized content. This project will also solicit feedback from teachers and students, develop teacher support materials, and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform physical science learning",10303076,R44GM137622,"['Address', 'Adoption', 'Books', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Drops', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Health Professional', 'Healthcare', 'Home environment', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Motion', 'Phase', 'Physics', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Rewards', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Students', 'Techniques', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'adaptive learning', 'base', 'bilingualism', 'design', 'digital', 'education resources', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'physical science', 'reading ability', 'response', 'science teacher', 'scientific literacy', 'skills', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2021,774997,981500
"Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt Founded in 1965 as one of the original Intellectual and Developmental Disorders Research Centers (IDDRC), the Vanderbilt Kennedy Center (VKC) IDDRC serves as the central nexus across Vanderbilt for interdisciplinary research, communication, and training in intellectual and developmental disabilities (IDD). The VKC IDDRC serves as a trans-institutional institute that brings together over 200 faculty from 38 departments in 10 schools at Vanderbilt. The VKC’s mission to facilitate discoveries that inform best practices to improve the lives of people with IDD and their families. This mission is met by leveraging our outstanding institutional resources and support, partnering with disability communities, and capitalizing on synergistic interactions across the VKC’s federally-designated centers: the VKC IDDRC, a University Center of Excellence in Developmental Disabilities and a Leadership Education in Neurodevelopmental Disabilities program. The IDDRC as the centerpiece of the VKC is the foundational organizing structure that creates a “Center culture” wherein research and discovery permeates the VKC’s broader training and service activities, thus enhancing the translational research goals of the IDDRC. Demonstrable IDDRC success includes 976 investigator- authored publications and robust NIH funding to Vanderbilt to support IDD-related research ($52.6M in FY20). Harnessing and leveraging this trans-institutional strength to focus on unique challenges in IDD, the overarching goal of the next phase of the IDDRC is to develop precision care for IDD by providing infrastructure and scientific leadership to enable rapid translation of basic discoveries into high- impact IDD interventions and treatments. Three global Aims guide the IDDRC’s work. Aim 1 provides core services to enable and disseminate impactful research on individualizing treatments based upon the causes, mechanisms, and contributing co-morbid sequelae of IDD; Aim 2 focuses on incorporating innovative methods and approaches to enhance multidisciplinary IDD research; and Aim 3 proposes to conduct a signature research project to improve the precision use of antipsychotic medication in people with autism. Across these Aims and five Cores supported by the IDDRC (Administrative, Clinical Translational, Translational Neuroscience, Behavioral Phenotyping, and Data Sciences), three themes permeate our work: (1) recruitment of highly-skilled researchers not currently conducting IDD research (non-traditional researchers); (2) inclusion of IDD participants into research studies that currently do not include IDD (non-traditional subjects); and (3) incorporation of novel scientific approaches and methods (non-traditional approaches). Our IDDRC is ideally posed to enable rapid discovery of precision care approaches by supporting 50 investigators leading 70 research projects (15 from NICHD) and, as highlighted by the Signature Research Project, to promote and implement generative, novel, and impactful research directions, thus meeting the NICHD’s vision of applying newly evolved technologies and approaches to rapidly accelerate the prevention and/or amelioration of IDDs. PUBLIC HEALTH RELEVANCE: As a group, intellectual and developmental disabilities, including Down syndrome and autism spectrum disorder, have dramatic effects on affected people’s and their caregiver’s lives. Unfortunately, there remains a lack of understanding about what causes these disabilities and, critically, how to treat them with targeted therapies. The Vanderbilt Kennedy Center’s Intellectual and Developmental Disabilities Research Center serves as the hub for Vanderbilt’s research efforts focusing on improving the lives of people with intellectual and developmental disabilities by understanding the causes of these disorders and developing and testing therapies tailored to each individual’s precise needs.",Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt,10229591,P50HD103537,"['Academic Medical Centers', 'Affect', 'Antipsychotic Agents', 'Basic Science', 'Behavioral', 'Biomedical Research', 'Caregivers', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Communities', 'Computerized Medical Record', 'Data', 'Data Science', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Disease', 'Disease model', 'Down Syndrome', 'Education', 'Evaluation', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Gap Junctions', 'Genotype', 'Goals', 'Image', 'Individual', 'Infrastructure', 'Institutes', 'Intellectual and Developmental Disabilities Research Centers', 'Intellectual functioning disability', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Longevity', 'Machine Learning', 'Medical Records', 'Methods', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurodevelopmental Disability', 'Obesity', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Pilot Projects', 'Policy Research', 'Prevention', 'Problem behavior', 'Publications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Schools', 'Series', 'Services', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Universities', 'Vision', 'Weight Gain', 'Work', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'clinical translation', 'comorbidity', 'cost effective', 'developmental disease', 'disability', 'drug-induced weight gain', 'experience', 'image processing', 'implementation science', 'improved', 'individualized medicine', 'individuals with autism spectrum disorder', 'innovation', 'large datasets', 'lectures', 'meetings', 'multidisciplinary', 'novel', 'personalized approach', 'personalized care', 'personalized medicine', 'population based', 'pragmatic trial', 'predictive modeling', 'programs', 'public health relevance', 'recruit', 'research study', 'success', 'targeted treatment', 'translational neuroscience', 'trial comparing']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,P50,2021,1364066,377931988
