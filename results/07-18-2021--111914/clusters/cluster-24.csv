text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9748523,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,195128,-0.002304033587648173
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9777388,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2019,24447,0.023818029343018247
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9784818,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation Dose Unit', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'neural network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2019,78500,0.03464201871917173
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9783816,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,438449,0.040199242665563954
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9752639,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'neural network', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,196250,0.05635309561367292
"Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization Project Summary Prostate cancer (PCa) is the most diagnosed form of non-cutaneous cancer in US men. The selection of patients who require immediate treatment from those suitable for active surveillance currently relies on non- specific and inaccurate measurements. A method that allows clinicians to more confidently discriminate clinically relevant from non-life-threatening tumors is needed to improve patient management. Multiparametric magnetic resonance imaging (mpMRI) is the preferred non-invasive imaging modality for characterizing primary PCa. However, its accuracy for detecting clinically significant PCa is variable. We propose to address this limitation by combining mpMRI with positron emission tomography (PET) with a PCa-specific radiotracer and using advanced multimodal machine learning models (i.e. radiomics and deep learning) to characterize tumor aggressiveness based on the imaging data. Recently, scanners capable of simultaneous PET and MR data acquisition in human subjects have become commercially available. An integrated MR-PET scanner is the ideal tool for comparing MR and PET derived image features to identify those that provide complementary information and build a hybrid PET-mpMRI model that most accurately identifies clinically significant tumors. While this novel technology allows the acquisition of perfectly coregistered complementary anatomical, functional and metabolic data in a single imaging session, a new challenge needs to first be addressed to obtain quantitatively accurate PET data. In an integrated MR-PET scanner, the information needed for PET attenuation correction (AC) has to be derived from the MR data and the methods currently available for this task are inadequate for advanced quantitative studies. We have formed an academic-industrial partnership to accelerate the translation of multimodal MR-PET machine learning approaches into PCa research and clinical applications by addressing the AC challenge and validating machine learning models for detecting clinically significant disease against gold standard histopathology in patients undergoing radical prostatectomy. Specifically, we will: (1) Develop and validate an MR-based approach for obtaining quantitatively accurate PET data. We hypothesize that attenuation maps as accurate as those obtained using a 511 keV transmission source – the true gold standard for PET AC – will be obtained; (2) Identify the multimodal radiomics model that most accurately predicts PCa aggressiveness. We hypothesize that the diagnostic accuracy of this approach will be superior to that offered by the stand-alone modalities; (3) Evaluate radiomics and deep learning approaches for predicting pPCa aggressiveness. We hypothesize that machine learning approaches will achieve a higher predictive accuracy when applied to data acquired simultaneously than sequentially. Project narrative A better method to non-invasively characterize primary prostate cancer is needed to improve patient management. Extracting additional information from multimodality quantitative MR-PET data using machine learning approaches is expected to result in better diagnostic performance. In this work, we propose to accelerate the translation of quantitative MR-PET to prostate cancer research and clinical applications. In particular, we will develop and validate an MR-based attenuation correction approach to guarantee that quantitatively accurate PET data are obtained in an integrated MR-PET scanner and then use machine learning approaches to characterize the aggressiveness of the tumors in patients undergoing radical prostatectomy.",Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization,9653979,R01CA218187,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Biopsy', 'Cancer Death Rates', 'Cancer Patient', 'Classification', 'Computer software', 'Data', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Early treatment', 'FOLH1 gene', 'Gold', 'Guidelines', 'Hand', 'Histopathology', 'Hybrids', 'Image', 'Individual', 'Interobserver Variability', 'Kinetics', 'Lesion', 'Life Expectancy', 'Ligands', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Meta-Analysis', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Morphology', 'Patient Selection', 'Patients', 'Pelvis', 'Performance', 'Phenotype', 'Physiological', 'Positron-Emission Tomography', 'Prostate', 'Prostate-Specific Antigen', 'Quality of life', 'Radical Prostatectomy', 'Reproducibility', 'Risk', 'Scanning', 'Source', 'Testing', 'Time', 'Translations', 'Work', 'anticancer research', 'attenuation', 'base', 'bone imaging', 'cancer classification', 'cancer imaging', 'clinical application', 'clinically relevant', 'clinically significant', 'data acquisition', 'deep learning', 'diagnostic accuracy', 'human subject', 'imaging modality', 'improved', 'industry partner', 'men', 'multimodality', 'new technology', 'non-invasive imaging', 'radiologist', 'radiomics', 'radiotracer', 'tool', 'transmission process', 'tumor']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,663746,-0.039777567456558506
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9727582,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Radiation', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'cancer care', 'cancer recurrence', 'cancer therapy', 'chemotherapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2019,77450,-0.00797514888349274
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9751222,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,373460,0.04475972274061687
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,-0.014013400051342812
"Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI Project Summary/Abstract The goal of this project is to increase the precision and resolution of quantitative magnetic resonance imaging (MRI). Quantitative information such as tissue relaxation parameters (e.g., T1 and T2) measure tissue function and indicate disease-related changes in the heart, liver, brain, and other organs. For instance, T1 changes can provide evidence of diffuse fibrosis in the myocardium that can signal heart disease. Quantitative maps also are reproducible, directly comparable longitudinally and across subjects, and less affected by the properties of the scanner used, when compared versus common weighted (non-quantitative) clinical imaging. But, quantitative imaging involves more complicated and time-consuming pulse sequences. To accomplish this goal, this project will develop new machine learning algorithms for high-quality parameter mapping from free-breathing data. The first aim of this project will increase parameter map resolution achievable from highly accelerated, noisy data. The proposed method will integrate existing deep cascade network-based image reconstructions with convolutional network-based blocks for super-resolution and parameter map estimation. Preliminary studies suggest these new blocks improve sharpness and mitigate artifacts in the reconstructed parameter maps. The next aim will improve the training precision of such artificial neural networks to account for the significant per-voxel nonlinear fit variability in quantitative MRI. The proposed method will reweight the loss function used for calibrating these networks by the goodness-of-fit (coefficient of determination) of the reference maps obtained from fully sampled training data. Preliminary results demonstrate that quality-aware reweighting significantly improves reconstructed image quality when working with noisy training data. Experiments will evaluate the precision of both of these innovations against existing deep-learning-based reconstructions on T1 maps obtained from pre- and post-contrast cardiac images of volunteer patients. The final aim will address motion during the acquisition by estimating and tracking nonrigid motion in the data consistency stages of the deep cascade artificial neural network architecture. Two methods are proposed: deformable motion estimation already demonstrated on compressive model-based image reconstructions, and a new “re-blurring” convolutional neural network that automatically introduces artifacts into a “clean” image to match the motion-corrupted data. Both of these methods enforce consistency between motion-affected data and a motion-free image during the reconstruction. Both methods will be validated on both cardiac and abdominal images for motion artifacts and reconstruction quality against breath-held parameter mapping acquisitions. Project Narrative Quantitative magnetic resonance imaging noninvasively measures physical properties of tissue connected to cardiovascular disease and many other conditions. Novel machine learning methods for processing data to produce higher quality maps will facilitate earlier and more accurate treatment of these diseases. This project will facilitate rapid quantitative imaging with freely breathing subjects.",Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI,10007241,R56EB028254,"['Abdomen', 'Address', 'Adoption', 'Affect', 'Algorithms', 'Awareness', 'Balance training', 'Brain', 'Breathing', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Consumption', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Disease', 'Fibrosis', 'Financial compensation', 'Goals', 'Heart', 'Heart Diseases', 'Heart failure', 'Image', 'Infiltration', 'Literature', 'Liver', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myocardium', 'Network-based', 'Noise', 'Non-linear Models', 'Organ', 'Patients', 'Physiologic pulse', 'Process', 'Property', 'Protocols documentation', 'Relaxation', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Signal Transduction', 'Techniques', 'Time', 'Tissues', 'Training', 'Weight', 'artificial neural network', 'base', 'clinical imaging', 'clinically relevant', 'computerized data processing', 'contrast imaging', 'convolutional neural network', 'coronary fibrosis', 'data space', 'deep learning', 'design', 'experimental study', 'heart imaging', 'image reconstruction', 'improved', 'innovation', 'learning strategy', 'loss of function', 'machine learning algorithm', 'motion sensitivity', 'multitask', 'neural network architecture', 'non-invasive imaging', 'novel', 'physical property', 'quantitative imaging', 'reconstruction', 'volunteer']",NIBIB,UNIVERSITY OF VIRGINIA,R56,2019,347527,-0.0066254482441579846
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,0.021454972694181933
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning. !",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,9776655,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis\xa0', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2019,185379,-0.019980157256598657
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9762102,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2019,460690,0.017058058629856283
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9746373,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Computer software', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,234000,0.01750158404912466
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.03149062215255328
"Development and Evaluation of a Machine Learning Approach to Interpret Optical Coherence Tomography Images of the Middle Ear to Improve Antibiotic Management PROJECT SUMMARY Introduction: PhotoniCare, Inc. is a medical device company developing the TOMi Scope, a handheld, optical imaging device for improved diagnosis of middle ear health. The purpose of this proposal is to establish and evaluate a machine learning approach to interpret TOMi Scope depth-resolved images using a set of ear models with human middle ear effusion (MEE; fluid) to enable improved diagnostic accuracy and, ultimately, antibiotic stewardship for ear health. Significance: Ear infections affect 95% of all children, yet they are one of the most poorly diagnosed and managed diseases in all of medicine, resulting in high antibiotic over-prescription and antibiotic resistance development. Correctly identifying the absence or presence/type of MEE through the non-transparent eardrum is critical to accurate diagnosis, and the limited current diagnostic tools suffer poor diagnostic accuracy (50- 70%) due to inherent subjectivity and dependence on user experience. Therefore, objective image classification metrics to enable improved diagnostic accuracy is sorely needed to finally provide children afflicted by this disease with the correct treatment the first time. Hypothesis: Applying a machine learning approach to TOMi Scope image classification of a set of ear models with human MEE will facilitate detection of the presence or absence of effusion (≥90% accuracy), as well as classification by the type of effusion samples (≥80% accuracy), regardless of user experience. Specific Aims: (1) Collect robust datasets of ex vivo human MEE, sufficient for machine learning image analysis. (2) Develop a neural network model based on the MEE dataset and apply the model to a representative test clinical dataset to determine classification feasibility. Commercial Opportunity: The TOMi Scope will provide physicians with new, objective information, enabling better decision-making for antibiotic prescription and surgical intervention. This has the potential to impact the standard of care for ~1B children worldwide that experience ear infections, representing a multi-billion-dollar commercial opportunity. PROJECT NARRATIVE Ear infections (otitis media) are highly prevalent in the pediatric population and represent a significant clinical challenge due to the limitations of the gold-standard diagnostic tools, resulting in high antibiotic prescription but also antibiotic resistance development. Accurate detection and classification of effusion (fluid) in the middle ear is a critical element for this diagnosis, and for making informed medical treatment decisions, particularly regarding antibiotic stewardship. The long-term goal of this work is to reduce antibiotic resistance and healthcare costs through improving patient outcomes by addressing the low diagnostic accuracy and user experience dependence of current subjective methods, with a novel, non-invasive imaging tool capable of quantitative depth-resolved measurements to not only visualize the underlying infection behind the eardrum, but also, with automated machine learning image analysis algorithms, minimize user experience dependence and variability.",Development and Evaluation of a Machine Learning Approach to Interpret Optical Coherence Tomography Images of the Middle Ear to Improve Antibiotic Management,9847606,R43DC017422,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Biological', 'Biomechanics', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Classification', 'Clinical', 'Collaborations', 'Controlled Environment', 'Data', 'Data Quality', 'Data Set', 'Decision Making', 'Dependence', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Elements', 'Evaluation', 'Family suidae', 'Goals', 'Gold', 'Health', 'Health Care Costs', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Infection', 'Intestines', 'Liquid substance', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medicine', 'Methods', 'Modeling', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopy', 'Outcome', 'Pathologic', 'Patient observation', 'Patient-Focused Outcomes', 'Performance', 'Physicians', 'Population', 'Pythons', 'Resistance development', 'Safety', 'Sampling', 'Serous', 'Sterility', 'Surface', 'Technology', 'TensorFlow', 'Testing', 'Time', 'Tissues', 'Training', 'Tympanic membrane', 'Work', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnostic accuracy', 'digital', 'ear infection', 'effusion', 'ex vivo imaging', 'experience', 'hearing impairment', 'improved', 'in vivo', 'middle ear', 'neural network', 'non-invasive imaging', 'novel', 'optical imaging', 'pediatric patients', 'standard of care', 'tool']",NIDCD,"PHOTONICARE, INC.",R43,2019,223899,0.03131585893973664
"IEEE International Symposium on Biomedical Imaging Project Summary This proposal requests funds to provide travel support for graduates to attend and participate in the IEEE Inter- national Symposium on Biomedical Imaging (ISBI) 2019 conference, Venice, Italy on April 08-11, 2019. The main objective of the IEEE ISBI is to bring together researchers with interests in mathematical and computa- tional aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. ISBI partici- pants – on the order of 600-700 from across the world are involved in biomedical imaging research and development in academic institutions, government laboratories, or R&D departments of private companies. ISBI is co-sponsored by two IEEE societies: Signal Processing Society (SPS) and Engineering in Medicine and Biology Society (EMBS), representing academia, industry, and healthcare, and considered the world's foremost societies in biomedical engineering and imaging. SPS and EMBS publish IEEE Transactions on Medical Imag- ing, Transactions on Image Processing, Transactions on Biomedical Engineering, Transactions on Computational Imaging, and IEEE Journal of Biomedical and Health Informatics, among others. Since incep- tion in 2002, ISBI has become the leading international conference bringing together researchers from diverse algorithmic fields, applications, modalities, and size scales, to facilitate cross-fertilization of ideas across imag- ing modalities and scales. Conference topics include physical, biological and statistical modeling, image formation and reconstruction, computational and statistical image analysis, visualization and image quality as- sessment, and artificial intelligence and machine learning for big image data. ISBI, like other IEEE SPS and EMBS conferences, requires submission and review of a 4-page paper. Peer reviews are handled by a 50-mem- ber editorial board (area editors) of leading experts in the community, who in turn assign papers to well- qualified reviewers. All oral and poster papers are published in IEEExplore as Proceedings of ISBI. If awarded, IEEE anticipates the primary impact of this R13 grant will be increased attendance of U.S.-based students, postdoctoral fellows, and early career faculty. By offering to cover a significant portion of attendee's travel expenses, the cost-benefit ratio for attending ISBI 2019 will be extremely favorable. Furthermore, IEEE will award travel grants based on need and scientific excellence, creating opportunities for those early career researchers who have accepted papers (of which less than 50% are accepted to ISBI) and who have limited means to travel. IEEE will be particularly supportive in providing travel awards to women, under-represented groups, and persons with disabilities. Benefits can largely be summarized as “exposure” and education. ISBI provides opportunity for student exposure to many more areas of computational imaging research than generally available in her/his home institution, and concurrently provides opportunity for students to interact with leaders in the field through tutorials, plenary, oral, and poster presentations, and individual discussions. This proposal requests funds to provide travel support for graduate to attend and participate in the IEEE International Symposium on Biomedical Imaging (ISBI) 2019 conference, to be held in Venice, Italy on April 08-11, 2019. The main objective of the IEEE international Symposium on Biomedical Imaging is to bring together researchers with interests in the mathematical and computational aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. The conference covers biomedical imaging problems of high relevance to human health, and hence is of high relevance to the interests of the National Institute of Health.",IEEE International Symposium on Biomedical Imaging,9685477,R13EB027566,"['Academia', 'Address', 'Algorithms', 'Appointment', 'Area', 'Artificial Intelligence', 'Award', 'Biological Models', 'Biology', 'Biomedical Computing', 'Biomedical Engineering', 'Breeding', 'Budgets', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Costs and Benefits', 'Data', 'Development', 'Disabled Persons', 'Education', 'Engineering', 'Exposure to', 'Fertilization', 'Funding', 'Future', 'Generations', 'Goals', 'Government', 'Grant', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging problem', 'Individual', 'Industry', 'Institution', 'International', 'Italy', 'Journals', 'Laboratories', 'Location', 'Machine Learning', 'Mathematics', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Microscopic', 'Microscopy', 'Modality', 'Modeling', 'Oral', 'Paper', 'Participant', 'Peer Review', 'Postdoctoral Fellow', 'Privatization', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Request for Proposals', 'Research', 'Research Personnel', 'Series', 'Societies', 'Statistical Models', 'Students', 'System', 'Training', 'Transact', 'Travel', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'authority', 'base', 'biocomputing', 'bioimaging', 'biomedical informatics', 'body system', 'career', 'computerized tools', 'cost', 'early-career faculty', 'editorial', 'graduate student', 'image processing', 'imaging modality', 'imaging system', 'innovation', 'interest', 'meetings', 'member', 'physical model', 'posters', 'programs', 'reconstruction', 'research and development', 'signal processing', 'student participation', 'success', 'supportive environment', 'symposium', 'whole body imaging']",NIBIB,UNIVERSITY OF IOWA,R13,2019,10000,0.02397145657455194
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9669002,R61AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2019,447173,0.02084212756475931
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",9798875,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2019,357486,0.006096882754608996
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9765316,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Endothelium', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Tissue Transplantation', 'Topical Corticosteroids', 'Translating', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2019,200104,0.011589032418918526
"Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers Superficially spreading types of skin cancers such as lentigo maligna melanomas (LMMs) and non-melanoma skin cancers (NMSCs) occur mostly on older patients, with diffuse sub-clinical sub-surface spread over large areas and with poorly defined margins that are difficult to detect. To treat these cancers, dermatologists rou- tinely perform a large number of mapping biopsies to determine the spread and margins, followed by surgical excision with wide ""safety"" margins. Not surprisingly, such a ""blind"" approach results in under-sampling of the margins, over-sampling of normal skin, too many false positives and false negatives, and too much loss of normal skin tissue. What may help address this problem is reflectance confocal microscopy (RCM) imaging to noninvasively delineate margins, directly on patients. RCM imaging detects skin cancers in vivo with sensitivity of 85-95% and specificity 80-70%. In 2016, the Centers for Medicare and Medicaid Services granted reim- bursement codes for RCM imaging of skin. RCM imaging is now being increasingly used to noninvasively guide diagnosis, sparing patients from unnecessary biopsies of benign lesions. While the two-decade effort leading to the granting of these codes was focused on imaging-guided diagnosis, emerging applications are in imaging to guide therapy. We propose to create an approach called RCM video-mosaicking, to noninvasively map skin cancer margins over large areas on patients, with increased sampling, accuracy and sparing of nor- mal tissue. The innovation will be in designing a highly robust (against tissue warping and motion artifacts) and high speed (real-time, seconds) approach for RCM video-mosaicking: we will develop an optical flow ap- proach with a novel hybrid 3-stage deep learning network comprising of 8 parameters that will model global and local rigid and non-rigid tissue motion dynamics, learn and adapt to variable tissue and speckle noise con- ditions in patients, and predict and automatically detect motion blur artifacts. As required by PAR-18-009, our academic-industrial partnership will deliver RCM video-mosaicking to clinicians for real-time implementation at the bedside (translational novelty). Our proposed application is for guiding surgical excision, but the approach will have wider impact, for guiding new and emerging less invasive non-surgical treatments for superficial skin cancers. In a preliminary study, we demonstrated RCM video-mosaicking with real-time speed (125 millisec- onds per frame, 8 frames per second), and registration errors of 1.02 ± 1.3 pixels relative to field-of-view of 1000 x 1000 pixels. Our specific aims are (1) to develop a real-time and robust RCM video-mosaicking ap- proach and incorporate into a handheld confocal microscope for use at the bedside, (2) to test the approach for image quality and clinical acceptability, and (3) to prospectively test on 100 patients, with pre-surgical video- mosaicking of LMM margins and superficial NMSC margins, followed by validation against post-surgical pa- thology. We are a highly synergistic team from Memorial Sloan Kettering Cancer Center, Northeastern Uni- versity, and Caliber Imaging and Diagnostics (formerly, Lucid Inc.), with a 13-year record of collaboration. RELEVANCE TO PUBLIC HEALTH Reflectance confocal microscopy (RCM) imaging can noninvasively diagnose skin cancers, and spare patients from biopsies of benign skin conditions. We propose to develop an approach to noninvasively delineate skin cancer margins, to help guide less invasive surgery, and help more accurately and completely remove cancer while preserving more of the surrounding normal skin.",Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers,9801564,R01CA240771,"['Ablation', 'Address', 'Area', 'Benign', 'Biopsy', 'Caliber', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Confocal Microscopy', 'Dermatologist', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Excision', 'Funding Opportunities', 'Grant', 'Hutchinson&apos', 's Melanotic Freckle', 'Hybrids', 'Image', 'Lasers', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopy', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Mosaicism', 'Motion', 'Noise', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pharmacotherapy', 'Procedures', 'Process', 'Public Health', 'Radiation therapy', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Skin Tissue', 'Specificity', 'Speed', 'Standardization', 'Surface', 'Surgeon', 'Surgical Pathology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Validation', 'Video Microscopy', 'Visit', 'Visual', 'blind', 'cellular imaging', 'clinical practice', 'deep learning', 'design', 'expectation', 'human imaging', 'image guided', 'image guided therapy', 'imaging approach', 'in vivo', 'industry partner', 'innovation', 'interest', 'learning network', 'microscopic imaging', 'noninvasive diagnosis', 'novel', 'older patient', 'preservation', 'prospective test', 'reflectance confocal microscopy', 'response', 'vector']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2019,667106,-0.011602623048767089
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9764151,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,461656,0.0019452028517490177
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,-0.008831960365919385
"Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. Cancers in the thoracic region, which include lung, esophageal, thymus, mesothelioma and breast cancers, are among the most pervasive and deadly cancers. The protection of normal thoracic organs including lungs, heart, esophagus and spinal cord is critical in reducing long term toxicity in such cancers. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dosage distribution. Despite tremendous effort into the development of semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria and thus leads to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. The associated human efforts would significantly increase if adaptive radiation therapy (ART) is used as OARs from two or more simulation CT scans need to be segmented to adjust treatment plans. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, a thoracic OAR auto-segmentation product will be developed in this project with the two aims: 1) improve and validate the deep-learning-based automatic thoracic organ segmentation algorithm on a larger clinical data set, and 2) incorporate this algorithm into a preliminary product that fits into the clinical workflow. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. Furthermore, the time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based thoracic OAR auto-segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region,9776272,R43EB027523,"['3-Dimensional', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Area', 'Atlases', 'Attention', 'Cancer Center', 'Cancer Patient', 'Chest', 'Client', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Early Diagnosis', 'Environment', 'Esophageal', 'Esophagus', 'Goals', 'Healthcare', 'Heart', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Kentucky', 'Label', 'Lung', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medicine', 'Mesothelioma', 'Methods', 'Modeling', 'Organ', 'Outcome', 'Pathologic', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Privatization', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Spinal Cord', 'Structure', 'Survival Rate', 'Testing', 'Thymus Gland', 'Time', 'Toxic effect', 'Training', 'Treatment Cost', 'Universities', 'Validation', 'X-Ray Computed Tomography', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinically relevant', 'convolutional neural network', 'cost', 'deep learning', 'dosage', 'dosimetry', 'improved', 'learning strategy', 'malignant breast neoplasm', 'millimeter', 'novel', 'prototype', 'satisfaction', 'simulation', 'success', 'tool', 'treatment planning']",NIBIB,"CARINA MEDICAL, LLC",R43,2019,299288,-0.011587182066968857
"NIDDK Extramural Digital Pathology Repository System In recent years, new technology and data processing capabilities have removed barriers to integration of molecular and histopathological data sets. Several clinical research networks across the National Institute of Diabetes, Digestive and Kidney Diseases extramural programs have put Digital Pathology Repositories (DPRs) into place with digital whole slide images (WSI) available to support standardization of classical diagnostic criteria across clinical sites. A developing line of investigation is the “mining” of these digital sets to identify features which correlate with disease. Computer assisted-image analysis for feature detection and feature recognition are key components of such investigation. The Centralized NIDDK Digital Pathology Repository will serve as an online repository to facilitate standardized archiving of WSI with the goal of providing controlled access for standardization, discovery and validation research efforts. n/a",NIDDK Extramural Digital Pathology Repository System,10032690,5N94019F00322,"['Archives', 'Artificial Intelligence', 'Clinical', 'Clinical Research', 'Computer-Assisted Image Analysis', 'Data Set', 'Diabetes Mellitus', 'Diagnostic', 'Digestive System Disorders', 'Disease', 'Extramural Activities', 'Future', 'Goals', 'Institutes', 'Investigation', 'Kidney Diseases', 'Machine Learning', 'Metadata', 'Mining', 'Molecular', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Research', 'Standardization', 'System', 'Validation', 'clinical research site', 'computerized data processing', 'digital', 'digital pathology', 'feature detection', 'new technology', 'online repository', 'programs', 'repository', 'whole slide imaging']",NICHD, ,N02,2019,95738,-0.004483413040879964
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0.023329923977233883
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9607075,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Imagery', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,373880,0.007902707125735443
"Ultraportable Stroke CT Based on Stationary Carbon Nanotube X-ray Source and Deep Learning Image Formation PROJECT SUMMARY The goal of this 12-month SBIR phase 1 project is developing an imaging device that will enable highly efficient and cost-effective stroke imaging for patients suffered trauma events. The expected technical outcome will be a proof-of-concept head CT imaging system with sub- second imaging speed, sub-mSv radiation dose, and high-quality images. Imaging systems with such capabilities will address the current deficiency in timely diagnosis of stroke patients, and benefit society with higher efficiency and lower cost. Such imaging device will make a strong economic impact on the global head CT imaging market, which is estimated to be about $36 billion in the U.S. In a longer term, the novel imaging technology could be translated into markets for security screening, industry inspection, and dental imaging. This project is based on the recent research results by Dr. Cao's team under the support of an NSF CAREER award (PI Dr. Cao, 08/01/2014-07/31/2019, $400,000) and a Dr. Cao's Commonwealth Research Commercialization Fund (CRCF) award (Title: “Computed Tomography Without Moving Parts for Fast and Portable Biomedical Imaging”, 07/01/2017- 06/30/2019, $100,000). The project has a strong footing in intellectual property. The technology is protected by a few patent applications at the Virginia Tech, including US. 62/316649, “Ultrafast Micro-CT for Imaging Free-Moving Animals” (Inventor: Guohua Cao), and PCT/US2013/061049 and US14/429835, “System and Method of Stationary Source Computed Tomography” (Inventor: Guohua Cao, et. al.). In this project, the team will design and build a proof-of-concept head CT platform to test the feasibility of ultraportable and compact head CT based on the stationary carbon nanotube x-ray source design and deep learning image reconstruction algorithm. The expected outcomes from this project include demonstration of the feasibility for ultrafast, low dose, and diagnostic imaging capabilities for intracerebral hemorrhage in head phantoms (ICH), with potential automatic ICH identification through deep learning algorithm. A ready-to- prototype head CT device will be optimized and designed, and a corresponding business plan will be developed. PROJECT NARRATIVE Stroke is a common of death in the world at tremendous social and healthcare costs. Currently head CT is typically used for initial evaluation of stroke patients for signs of intracerebral hemorrhage. An ultraportable stroke CT that can be mounted in a small minivan would significantly shorten the time it takes for the diagnosis of intracerebral hemorrhage, particularly from trauma incidents. This technology will save life and overall healthcare costs.",Ultraportable Stroke CT Based on Stationary Carbon Nanotube X-ray Source and Deep Learning Image Formation,9909721,R43NS115277,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Architecture', 'Award', 'Beds', 'Businesses', 'Carbon Nanotubes', 'Cerebral hemisphere hemorrhage', 'Cessation of life', 'Data', 'Dental', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Dose', 'Employment', 'Evaluation', 'Event', 'Funding', 'Future', 'Goals', 'Head', 'Health Care Costs', 'Human', 'Image', 'Imaging Device', 'Industry', 'Intellectual Property', 'Legal patent', 'Life', 'Low Dose Radiation', 'Measurement', 'Methods', 'Noise', 'Outcome', 'Patient imaging', 'Performance', 'Phase', 'Radiation Dose Unit', 'Research', 'Roentgen Rays', 'Security', 'Site', 'Small Business Innovation Research Grant', 'Societies', 'Source', 'Speed', 'Spottings', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Translating', 'Trauma', 'Tube', 'Validation', 'Virginia', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'clinical imaging', 'commercialization', 'cost', 'cost effective', 'data acquisition', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'detector', 'economic impact', 'experimental study', 'foot', 'image reconstruction', 'imaging capabilities', 'imaging system', 'innovation', 'microCT', 'neural network algorithm', 'novel imaging technology', 'off-patent', 'portability', 'prototype', 'reconstruction', 'screening', 'social', 'stroke patient', 'tomography']",NINDS,"IMAGINGX, INC.",R43,2019,225052,-0.06491235800935347
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,9893208,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed\xa0imaging', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2019,587413,0.013172382952431096
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9752019,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2019,991516,0.012744833478338834
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9804438,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'off-patent', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2019,1715698,0.023935330639796595
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,9764897,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'Tomography, Computed, Scanners', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2019,1350820,0.026216067615325574
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9790958,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Financial Hardship', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'central database', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2019,199142,0.014374430609423521
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9782980,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2019,375000,0.0049937669005903846
"Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB) Project Summary Each major human disease is associated with a specific range of morphological changes to cells and tissues in the micron scale. Normal and abnormal structure was discovered and is still characterized using histology - a microscopic technique that depends on physical tissue slices. Presently, histology’s use in systems biology is limited by its largely descriptive and two-dimensional nature. Making histology quantitative and three-dimensional would be potentially transformational for research and diagnostics, but has been impractical. Accordingly, we have now created a 3D form of histology by customizing X-ray microtomography (micro-CT) of fixed and stained, millimeter-scale, whole organisms and tissue samples. We used fixed and metal-stained, whole zebrafish because they contain a full range of tissues within the size range currently studied histologically. The result is the first practical way to create virtual histology-like “sections” in any plane. Three-dimensional, complete histological phenotyping has potential use in genetic and chemical screens, and in clinical and toxicological tissue diagnostics. Here, we propose the next steps needed to enable high-throughput, quantitative, 3D histological phenotyping of whole, millimeter-scale animals. The proposed work applies the principles of chemistry, physics, and computer science to improve image resolution, throughput, and analytics, organized into three specific aims. Specific Aim 1 will build on our developments in this project and further improve imaging volume and resolution by upgrading imaging array, optics, and sub-pixel shifting, and to throughput by changes in sample embedding, loading geometry and mechanics, helical CT scanning, scintillator material, and to data sharing by improvements to the ViewTool infrastructure and user interface. Specific Aim 2 will yield reference images to define the range of normal phenotypic variation and to obtain samples related to a range of potential applications. Specific Aim 3 will apply the power of machine learning to segmentation, annotation, and analytics. Together, this work will establish a practical foundation for large-scale genetic and chemical screens involving mm-scale, whole organisms based on 3-dimensional, quantitative, histological phenotyping. The instrumentation and analytics will be state-of-the-art in its combination of resolution, field-of-view, pancellularity, image quality, analytical potential, throughput, sample stability, and reproducibility and largely usable with both tube and synchrotron X-ray sources. The voxel resolution will be at least 0.5 μm across fields-of-view of up to 1 cm. Representation of every cell type make the images suitable for cross-referencing across imaging modalities. Potential applications will be explored, “wild-type” will begin to be defined, and training sets for automated segmentation generated. The potential impact will encompass the missions of most NIH Institutes and Centers. The whole-animal genetic and chemical screens enabled are expected to impact drug development, diagnostics, and our basic understanding of how genes and environment define phenotype. Project Narrative Our group has established the only three-dimensional form of histology that is suitable for histopathology and quantitative tissue phenotyping, tissue X-ray microtomography (micro-CT). We outline here a plan to establish mechanisms for increasing resolution and field-of-view, to add sample multiplexing, to simply sample preparation, and to explore machine learning mechanisms for defining normal and abnormal structure towards whole-organism complete tissue phenotyping. The resulting tools will allow the community to comprehensively and computationally determine the roles of genes and environment in defining phenotype, which has implications in drug development, biomedical research, and medicine.",Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB),9792960,R24OD018559,"['3-Dimensional', 'Adolescent', 'Age', 'Animal Genetics', 'Animals', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Body measure procedure', 'Caenorhabditis elegans', 'Cells', 'Cellular Structures', 'Cesium', 'Chemicals', 'Chemistry', 'Communities', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Drosophila genus', 'Embryo', 'Environment', 'Fishes', 'Foundations', 'Genes', 'Genetic', 'Geometry', 'Goals', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Infrastructure', 'Institutes', 'Iodides', 'Machine Learning', 'Measures', 'Mechanics', 'Medicine', 'Metals', 'Microscopic', 'Mission', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Nerve', 'Normal Range', 'Online Systems', 'Optics', 'Organ', 'Output', 'Pharmaceutical Preparations', 'Phenotype', 'Physics', 'Preparation', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Robotics', 'Roentgen Rays', 'Role', 'Sampling', 'Scanning', 'Series', 'Siblings', 'Signal Transduction', 'Slice', 'Source', 'Spiral Computed Tomography', 'Stains', 'Structural defect', 'Structure', 'Synchrotrons', 'Systems Biology', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Training', 'Travel', 'Tube', 'United States National Institutes of Health', 'Variant', 'Whole Organism', 'Work', 'Writing', 'X-Ray Computed Tomography', 'Zebrafish', 'base', 'bone', 'cell type', 'clinical toxicology', 'computer science', 'computerized tools', 'crowdsourcing', 'data sharing', 'detector', 'disease phenotype', 'drug development', 'feature detection', 'histological studies', 'human disease', 'imaging modality', 'improved', 'instrumentation', 'microCT', 'millimeter', 'mutant', 'programs', 'supervised learning', 'tool', 'two-dimensional', 'unsupervised learning', 'virtual']",OD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R24,2019,667280,0.009679540716732821
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9791188,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2019,22992,0.001015834317882965
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9624738,R01CA193730,"['3-Dimensional', 'Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation Dose Unit', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'radiation delivery', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2019,343572,-0.02811879369772713
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,0.033519053927806707
"Automatic SUV Extraction and Biodistribution Analysis of Preclinical PET Preclinical positron emission tomography (PET) plays a significant role in monitoring radiotracer biodistributions for the development of new therapies. The standardized uptake value (SUV) has become one of the most important quantitation measures in PET analysis. However, SUV extraction from PET data hinges on the ability to clearly delineate the organ region-of-interest (ROI) from an anatomical reference. Cross-comparison of different organ SUVs and biodistributions is also cumbersome due to complex registration strategies of each animal with an unknown pose and size. Operator bias and lack of efficient co-registration strategies results in poor data reproducibility, high data variability, low data throughput and prohibits the use of fully-automated data parsing and data analysis for predicting early therapy outcomes with high sensitivity. In Vivo Analytics will directly address these shortcomings by developing InVivoPET. It will be a cloud-based PET data analysis tool, which will enable automatic organ SUV extraction followed by an instantaneous biodistribution analysis. InVivoPET will automatically coregister PET images to the animal’s anatomy and will calculate biodistributions in almost real-time. InVivoPET consists of several parts. First, a Body Conforming Animal Mold (BCAM) enables consistent spatial and longitudinal registration of the animal’s pose and location to the PET data. Second, a statistical mouse atlas based on an Organ Probability Map (OPM) provides a digital and operator-independent organ ROI template. Third, a cloud-based software with a browser-based user interface enables an automatic organ SUV extraction with following biodistribution analysis. Last, machine learning and data mining algorithms can be applied in the future that will further enhance study outcomes. InVivoPET does not rely on manual delineation of organs. A machine-driven data analysis fully eliminates operator-dependent variability and increases data reproducibility. It will enable the drug development team to quantitate the impact of candidate therapeutics with the highest accuracy, reduces the time to enter clinical trials, reduces costs, and ensures the quantification and consistency of PET data. Therefore, the hypothesis is that the organ SUV can automatically be extracted from PET data using the BCAM and OPM. In Aim 1, we will modify the BCAM for housing mice with surface-protruding tumors and confirm the ability for spatially aligning mice with tumor xenografts to the OPM. In Aim 2, we will perform PET imaging of tumor bearing mice using 18F-FDG and confirm the ability for automatically extracting the organ SUV based on the OPM. The successful completion of the proposed project will help to commercialize InVivoPET, which will be sold as a plug-in to existing PET systems and as a PET- manufacturer independent Software-as-a-Service (SaaS). Project Narrative: InVivo Analytics seeks funding for demonstrating the feasibility of automatically analyzing radiotracer biodistributions of small animal positron emission tomography (PET). Biodistribution analysis is currently operator-dependent, time-consuming, and prone to error while reducing the reproducibility of study results. The proposed technology will be fully automated, operator- independent, and will facilitate the development of new therapies in small animal models of infection, inflammation, and cancer.",Automatic SUV Extraction and Biodistribution Analysis of Preclinical PET,9680585,R43CA224841,"['Address', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Atlases', 'Automation', 'Biodistribution', 'Biotechnology', 'Clinical Trials', 'Complex', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease', 'Drug Kinetics', 'Early treatment', 'Ensure', 'Funding', 'Future', 'Geometry', 'Goals', 'Housing', 'Image', 'Infection', 'Inflammation', 'Knowledge', 'Location', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Manufacturer Name', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molds', 'Molecular Target', 'Monitor', 'Mus', 'Optics', 'Organ', 'Outcome Study', 'Persons', 'Phase', 'Play', 'Plug-in', 'Positron-Emission Tomography', 'Posture', 'Probability', 'Radiation therapy', 'Radioisotopes', 'Reproducibility', 'Roentgen Rays', 'Role', 'Shoulder', 'Skeleton', 'Standardization', 'Surface', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translations', 'X-Ray Computed Tomography', 'animal imaging', 'base', 'cancer imaging', 'cloud based', 'commercial application', 'contrast enhanced', 'cost', 'data mining', 'digital', 'dosimetry', 'drug development', 'fluorodeoxyglucose', 'imaging Segmentation', 'imaging platform', 'imaging study', 'improved', 'in vivo', 'interest', 'novel therapeutics', 'platform-independent', 'pre-clinical', 'radiotracer', 'sex', 'software as a service', 'subcutaneous', 'therapeutic candidate', 'therapy development', 'therapy outcome', 'tool', 'tumor', 'tumor xenograft', 'uptake']",NCI,"IN VIVO ANALYTICS, INC.",R43,2019,222931,0.004222092672482163
"New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens Project Summary Over 600,000 bone marrow biopsies are performed every year in the United States, while hundreds of thousands more lymph node biospies are performed. Histological evaluation of these biopsies is a critical component of care for hematologic diseases including leukemia, lymphoma, myelodysplastic syndrome, myeloproliferative disease and non-neoplastic conditions such as viral infections and autoimmune conditions.  We have developed a platform that we consider a paradigm shift in the histologic examination of tissues. It is based on a new chemical process, imaging, and image processing approach that we have dubbed Clearing Histology with MultiPhoton microscopy (CHiMP).The CHiMP technology enables visual analysis of entire intact, un-embedded and uncut specimens within a short time-frame and with a resolution that is amenable to primary diagnosis. The significant clinical benefits include: 1) potential for same-day diagnosis, 2) labor and cost savings, 3) access to 3D perspective, 4) increased visual data from same specimen, 5) complete tissue preservation for ancillary studies such as DNA analysis and 6) inherent benefits of digital data such as reduced risk of loss, ready remote review by experts, and amenability to machine learning tools. Hematopoietic tissue evaluation would similarly benefit from these advantages, but unfortunately the systems developed thus far lack the resolution typically needed for visual examination of hematopoietic tissues.  For this Phase I SBIR proposal, an objective is to develop customized optics to improve the resolution of our current microscopes and thereby enable use in the specialized field of hematology. Commercially available objective lenses that are compatible with our immersion medium are either limited to numerical apertures (NA) that are less than one, affecting resolution and image quality, or have insufficient working distances for imaging past the coverslip and surface roughness to obtain complete sections. We will design and test a custom objective lens with high NA and long working distance, suited for our proprietary reagents. Integrating such a lens into our microscope will also require the design of a custom scan lens, custom beam conditioning optics, and a custom polygon scanner.  An associated goal is to develop a novel approach to preparing bone marrow aspiration specimens that will make them amenable to imaging with CHiMP, potentially reducing the need for core biopsies by permitting unambiguous morphologic categorization of cell subtypes in their architectural context, without the routine need for immunohistochemistry, and while preserving nucleic acids for molecular/genetic evaluation. Project Narrative Applikate Technologies has developed a powerful platform for histological evaluation of tissue called Clearing Histology with MultiPhoton Microscopy, or CHiMP. This platform has many advantages over traditional approaches, including same-day turn-around, reduced labor costs, preservation of tissue for DNA analysis, and direct-to-digital imaging for ease of consultation with remote experts. This proposal seeks to develop custom optics to enable very-high-resolution imaging of bone marrow and lymph node samples that are critical for diagnosing diseases such as leukemia and lymphoma.","New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens",9677952,R43CA235890,"['3-Dimensional', 'Address', 'Adoption', 'Affect', 'Ancillary Study', 'Antigens', 'Architecture', 'Aspirate substance', 'Autoimmune Diseases', 'Autoimmune Process', 'Biopsy', 'Blinded', 'Bone Marrow', 'Bone Marrow Aspiration', 'Bone marrow biopsy', 'Caring', 'Cells', 'Chemicals', 'Chronic', 'Clinical', 'Clinical Data', 'Communicable Diseases', 'Consultations', 'Consumption', 'Core Biopsy', 'Cost Savings', 'Custom', 'DNA', 'DNA analysis', 'Data', 'Decalcification', 'Diagnosis', 'Diagnostic', 'Disease', 'Dysmyelopoietic Syndromes', 'Evaluation', 'Fibrosis', 'Goals', 'Hematological Disease', 'Hematology', 'Hematopathology', 'Histologic', 'Histology', 'Image', 'Imagery', 'Immersion Investigative Technique', 'Immunohistochemistry', 'Iron', 'Lateral', 'Lymph', 'Machine Learning', 'Marrow', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Molecular Genetics', 'Morphologic artifacts', 'Morphology', 'Myeloproliferative disease', 'Nucleic Acids', 'Optics', 'Pan Genus', 'Pathologist', 'Pathology', 'Phase', 'Preparation', 'Process', 'Protocols documentation', 'RNA', 'Reagent', 'Recovery', 'Resolution', 'Risk', 'Sampling', 'Scanning', 'Slice', 'Slide', 'Small Business Innovation Research Grant', 'Specimen', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Preservation', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'United States', 'Virus Diseases', 'Visual', 'Waxes', 'Work', 'base', 'bone imaging', 'conditioning', 'cost', 'design', 'digital', 'digital imaging', 'disease diagnosis', 'hematopoietic tissue', 'high resolution imaging', 'image processing', 'improved', 'instrument', 'lens', 'leukemia/lymphoma', 'lymph nodes', 'medical specialties', 'multiphoton microscopy', 'nanoparticle', 'novel', 'novel strategies', 'particle', 'pre-clinical', 'preservation', 'second harmonic', 'tool', 'whole slide imaging']",NCI,"APPLIKATE TECHNOLOGIES, LLC",R43,2019,224713,0.0050070770372592
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.04797123976040416
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,0.059191095622042354
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9741471,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,367570,-0.00263349913418846
"Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging PROJECT SUMMARY Optical imaging methods are well-established in neuroscience, but high-speed, high- resolution volumetric imaging of neural activity in deep tissue remains a challenge. A number of techniques address limited aspects of this goal, and most are applicable primarily to acute preparations. We propose to develop and test a novel approach to achieve three-dimensional “deep-tissue” imaging for high spatial and temporal resolution neural recording by combining aspects of embedded optical probes with computational imaging techniques. Rather than use a single micro-endoscopic probe, we propose to utilize an array of narrower probes, or optrodes, to reduce the volume of tissue displacement. Computational imaging through each probe can be performed to achieve a field of view (FOV) at a desired distance from the probe tip. Combining the fields of view from multiple probes arranged in an array then provides a composite image field that is much larger than achievable from a single micro-endoscope. In our approach, each ∼0.1 mm diameter probe of the array acts as an independent micro- endoscope. In order to achieve full-field imaging across the array, the individual fields must intersect, and the computational method must be scaled to accommodate, and stitch, multiple fields. In pursuit of these goals, we propose three Aims: Optimizing the FOV of a single micro-endoscope - The purpose of this Aim is to characterize the FOV for an individual probe at multiple depths, and optimize the FOV to about 0.3mm through control over the shape of the probe tip and light collection numerical aperture. Accelerating calibration and reconstruction - In this Aim, we will pursue efficient computational approaches for calibration based upon ray-tracing simulations and image reconstruction based on deep learning. Scaling the FOV with an endoscope array - The computational image reconstruction method will be scaled to accommodate small micro-endoscope arrays (e.g. 4 element) arranged in a hexagonal lattice with FOV of 0.6mm at a 1.5mm depth. NARRATIVE Imaging deep inside tissue, including the brain, is critical to understanding various biological processes. Doing so through a small probe is also of primary importance for minimizing tissue damage. In this proposal, we apply computational techniques to create fluorescent images using an array of microscopic glass needles to guide light in and out of a mouse brain. The simplicity and small footprint of our system have the potential for deep-brain imaging (depths > 1.5 mm) across a large (mm) field of view, which should enable a wide variety of biological and neuroscience studies in the future.",Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging,9829467,R21EY030717,"['3-Dimensional', 'Acute', 'Address', 'Biological', 'Biological Process', 'Brain', 'Brain imaging', 'Caliber', 'Calibration', 'Collection', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Confocal Microscopy', 'Coupled', 'Devices', 'Dimensions', 'Elements', 'Endoscopes', 'Fluorescence Microscopy', 'Fluorescent Probes', 'Future', 'Glass', 'Goals', 'Head', 'Holography', 'Image', 'Imaging Techniques', 'Individual', 'Light', 'Methods', 'Microscope', 'Microscopic', 'Microscopy', 'Miniaturization', 'Mus', 'Needles', 'Neurosciences', 'Optics', 'Penetration', 'Preparation', 'Resolution', 'Risk', 'Running', 'Scanning', 'Shapes', 'Source', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Work', 'absorption', 'adaptive optics', 'attenuation', 'base', 'cost', 'deep learning', 'fluorescence imaging', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'interest', 'lens', 'microendoscope', 'multi-photon', 'neural circuit', 'novel strategies', 'optical fiber', 'optical imaging', 'reconstruction', 'relating to nervous system', 'retinal rods', 'simulation', 'temporal measurement']",NEI,UNIVERSITY OF UTAH,R21,2019,456800,0.00891610986583036
"Rapid Robust Pediatric MRI Project Abstract Motivation: This is a competing renewal of our successful project, Rapid Robust Pediatric MRI, R01 EB009690. MRI offers superb soft tissue contrast for children, without the ionizing radiation and cancer risk of CT. However, MRI use has been limited due to long exams, low spatial resolution, and motion-artifacts. Thus, MRI often requires prolonged anesthesia with breath-holds and attendant risk; hence, children often lack the beneﬁts of cross-sectional imaging altogether or are exposed to ionizing radiation. The previous project addressed these concerns by creating a dedicated pediatric imaging system. Highly par- allel, high-SNR 3T receive coil arrays were designed and constructed speciﬁcally for pediatric body imaging. The high SNR was used to accelerate scans reconstructed with a combination of parallel imaging, new mo- tion correction algorithms, compressed sensing (CS), and higher dimensional imaging. The resulting system is now being used extensively in clinical practice, signiﬁcantly reducing anesthesia depth and duration, and has markedly increased our MRI utilization. Key technologies have been or are now being commercialized with GE Healthcare, including the pediatric receive array, CS, 4D ﬂow, full-Fourier single-shot T2-weighted scanning, and coil compression. Siemens has licensed ﬁve of our patents, implemented them in work-in-progress packages, and productized our coil compression and our ESPIRiT coil sensitivity estimation. Philips has licensed three of our patents. This ensures broad impact. Approach: Despite signiﬁcant progress and reduced anesthesia depth and duration, patient cooperation re- mains the main limitation to eliminate anesthesia in all pediatric body MRI exams. Many children will cooperate for several minutes, but then ﬁdget and get out of the scanner. Others are content until acoustic noise agi- tates them. Therefore the major emphasis now is greater exam execution speed, comprehensive elimination of acoustic noise, and increased robustness, particularly to contrast agent injection. The project has three interrelated development aims, validated by clinical studies. Aim 1 will enable fast 2D imag- ing for quiet T2 and quiet low-distortion diffusion weighted imaging. A second aim is to develop free-breathing 3D contrast-enhanced and diffusion-weighted imaging that is silent and motion-robust. The third aim will enable au- tomated, smart scanning to speed the exam execution and adaptive protocols to increase the exam robustness. The impact of all of these developments in the clinic will then be assessed to assess the resulting reduction of anesthesia. Signiﬁcance: This work will lead to fast, robust, broadly-applicable pediatric MRI protocols with less anes- thesia, making MRI safer, cheaper, and more available to children. MRI will be transformed into a workhorse modality, reducing CT radiation burden. The techniques will facilitate wide application in the community setting and permit new MRI applications, for both pediatric and adult diseases. Project Narrative Pediatric MRI often requires anesthesia. After considerable progress reducing the depth and duration of anes- thesia, this work aims to reduce the frequency of anesthesia through a synergistic combination of fast, quiet, motion-robust, automated, and adaptive scanning. This will make MRI safer, cheaper, and more widely available to children, reducing the population risk of radiation from CT.",Rapid Robust Pediatric MRI,9754130,R01EB009690,"['3-Dimensional', 'Acoustics', 'Address', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Body part', 'Bolus Infusion', 'Breathing', 'Child', 'Child Health', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Computational Technique', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Data Quality', 'Development', 'Diagnostic Imaging', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Ensure', 'Exposure to', 'Frequencies', 'Funding', 'Goals', 'Healthcare', 'Image', 'Image Compression', 'Image Enhancement', 'Injections', 'Ionizing radiation', 'Legal patent', 'Letters', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modality', 'Morphologic artifacts', 'Motion', 'Motivation', 'Noise', 'Patients', 'Pediatric Oncology', 'Pediatrics', 'Population', 'Protocols documentation', 'Radiation', 'Resolution', 'Risk', 'Role', 'Running', 'Scanning', 'Speed', 'System', 'T2 weighted imaging', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transplantation', 'Validation', 'Work', 'base', 'cancer risk', 'clinical practice', 'clinical translation', 'community setting', 'compliance behavior', 'contrast enhanced', 'design and construction', 'experience', 'high dimensionality', 'image reconstruction', 'imaging system', 'innovation', 'multidisciplinary', 'novel', 'off-patent', 'patient tolerability', 'pediatric patients', 'programs', 'radiation risk', 'reconstruction', 'skills', 'soft tissue', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2019,683589,-0.002371628007305345
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9769725,R21EB024700,"['3-Dimensional', 'Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'mortality risk', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,327488,0.013908118460458014
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,9881453,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2019,397500,0.017616536713597968
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9817807,R01AR074492,"['Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dimensions', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Kinetics', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'extracellular', 'flexibility', 'gait examination', 'gait retraining', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2019,561592,0.0032422561550509684
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9827910,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Tomography, Computed, Scanners', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2019,213271,-0.05460105646023631
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,9877321,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2019,195110,-0.014416597010063342
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,9886087,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Quality', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Drug effect disorder', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'deep learning', 'denoising', 'detector', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,344862,-0.0016572128775645112
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9750285,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2019,679852,0.0279000518841175
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9879968,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2019,167376,0.0279000518841175
"Medical Image Perception Society XVIII Conference MIPS XVIII brings together an international community of experts including radiologists, pathologists, other image-based clinicians, psychologists, statisticians, physicists, engineers, and computer scientists investigating the extraction of diagnostic information from medical images. The meeting forges research and learning opportunities for new students and young researchers in a dedicated forum unmatched by other meetings. MIPS XVIII is being organized by the Medical Image Perception Society (a US-based society; Elizabeth Krupinski, PhD President) in conjunction with local hosts Trafton Drew, PhD (University of Utah Psychology) and William Auffermann, MD, PhD (University of Utah Radiology); and committee Lauren Williams (University of Utah) trainee member, David Alonso trainee member (University of Utah). It will run July 14-17, 2019 at the University of Utah Guest House & Conference Center located near the University of Utah campus. Nine topic areas have been selected for MIPS XVIII, reflecting important dimensions of medical image interpretation. This year’s special focus theme is addressing other image-based specialties outside radiology. Studying how clinicians extract diagnostic information from images identifies the causes of missed diagnoses and ways to eliminate these errors. Careful design and evaluation of imaging systems are critical in view of their enormous costs. With the current emphasis in the practice of medicine on “meaningful use” and “accountable care” to improve the quality, safety, and efficiency of care, the role the clinician as decision-maker cannot be ignored. Medical image perception research develops and applies modern methods to the evaluation of observer performance in diagnostic imaging tasks. Understanding basic aspects of the perception of medical images can reduce diagnostic error and improve medical decision-making quality. This grant will support 10 students to attend and present their research at MIPS XVIII. To date, 115 students have been awarded scholarships. The primary goal in supporting these students is to create opportunities and offer supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success. The meeting brings together researchers investigating the process of extracting diagnostic information from medical images to render accurate and efficient diagnostic decisions. Opportunities for advanced, interdisciplinary training of young scientists interested in medical image perception research and its relevance to disease prevention and treatment are often quite limited at the university level. Since 1997, 115 students have been awarded MIPS scholarships, having a significant impact on the field by creating opportunities and offering supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success as independent basic science and clinician-scientist researchers.",Medical Image Perception Society XVIII Conference,9833051,R13EB028683,"['3-Dimensional', 'Acquired Immunodeficiency Syndrome', 'Address', 'American', 'Area', 'Attention', 'Award', 'Basic Science', 'Behavior', 'Caring', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Color', 'Communities', 'Computers', 'Data Set', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Dimensions', 'Discrimination', 'Doctor of Philosophy', 'Engineering', 'Evaluation', 'Failure', 'Fatigue', 'Frequencies', 'Goals', 'Grant', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institute of Medicine (U.S.)', 'International', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Malpractice', 'Medical', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Modern Medicine', 'Modernization', 'Ophthalmology', 'Pathologist', 'Patients', 'Pattern', 'Perception', 'Performance', 'Physician&apos', 's Role', 'Physicians', 'Population', 'Prevention', 'Process', 'Psychologist', 'Psychology', 'Psychophysics', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Running', 'Safety', 'Scholarship', 'Scientist', 'Societies', 'Students', 'Technology', 'Telemedicine', 'Training', 'United States National Institutes of Health', 'Universities', 'Utah', 'Work', 'automobile accident', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'design', 'disorder prevention', 'health care quality', 'image processing', 'imaging system', 'improved', 'interest', 'malignant breast neoplasm', 'medical specialties', 'meetings', 'member', 'outcome forecast', 'prognostic', 'radiologist', 'statistics', 'success', 'symposium', 'whole slide imaging']",NIBIB,EMORY UNIVERSITY,R13,2019,10000,0.031205302220984894
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,0.014348848443787428
"Computer-Aided Diagnosis of Pulmonary Embolism Project Summary/Abstract: The US Surgeon General has declared pulmonary embolism (PE) a major national health problem, causing more deaths than breast, colon, and lung cancers. The current diagnostic standard for suspected PE is CT pulmonary angiography (CTPA). However, the number of CTPA examinations is increasing dramatically, and incorrect CTPA interpretations are frequent in general practice (10-14% over/under-diagnosis). There is a clinical need to improve the efficiency and accuracy of PE diagnosis at CTPA. Our central hypothesis is that this clinical need can be addressed by exploiting computer-radiologist synergy. However, existing computer-aided diagnosis (CAD) methods for PE have serious deficiencies: they are limited in sensitivity and specificity, incapable of handling PE over-diagnosis, and operating only at the embolus level―localizing individual emboli, but PE diagnosis is rendered at the patient-level―excluding non-PE patients and dispatching PE-patients to treatment. Therefore, our objective is to overcome these deficiencies with a new methodology. We have built a strong interdisciplinary team, developed an innovative prototype, and evaluated it through our pilot clinical studies, demonstrating outstanding performance. This proposed research has three specific aims: 1) boost our current system’s embolus-level performance with our newly proposed strategies, assisting radiologists in accurately localizing emboli and facilitating precision medicine through risk stratification; 2) achieve patient-level diagnosis through our newly developed algorithms, assisting radiologists in quickly excluding negative patients and improving diagnostic efficiency; and 3) demonstrate clinical benefits of our system by testing specific clinical hypotheses. This research is innovative because (1) our approach to embolus-level detection fundamentally differs from prior approaches in that it requires no vessel segmentation, overcoming their limitations; (2) we are pioneering two uncharted areas: PE patient-level diagnosis and over-diagnosis prevention; we do not perceive any similar objectives in existing NIH grants or publications in the literature; and (3) this project utilizes our original algorithms and will yield multiple novel algorithms. Our project is significant because it (1) addresses a major national health problem; (2) develops a new methodology that transcends the current paradigm from mere detection of emboli to simultaneous patient-level diagnosis, embolus-level detection, and over-diagnosis prevention, overcoming the deficiencies of the current PE CAD systems; and (3) delivers a next- generation, high-performance PE CAD system that quickly excludes non-PE patients, accurately localizes emboli, and actively prevent PE over-diagnosis, thereby enhancing radiologists’ diagnostic capabilities and supporting precision medicine through risk stratification. Successful completion of the project is expected because (1) we have already made good progress in algorithm development and clinical evaluation; (2) our approach is carefully crafted on solid algorithmic and mathematical foundations; (3) our clinical evaluation is rigorously designed; and (4) our team is uniquely capable and well prepared to conduct this project, which builds upon our innovative research in CAD, pioneering research in deformable models, and world-renowned PIOPED trials. This research is expected to have important impact on PE- related clinical practice, development of decision support systems for many diseases, and medical education. Project Narrative Behind the great success of biomedical imaging, a crisis is looming: the number of imaging studies is growing exponentially; the workload of radiologists is increasing dramatically; the health-care cost related to imaging is rising rapidly—We are facing a grant new challenge: “image data explosion” (a manifestation of big data in biomedical imaging): Modern imaging systems generate enormous data, far exceeding human abilities for interpretation, but what is paramount are not the images themselves, rather the clinically relevant information contained within the images; therefore, our long-term goal is to develop and validate comprehensive, high-performance computational tools that automatically and quantitatively extract clinically relevant information from images to support clinical decision making and facilitate precision medicine. To demonstrate the immediate, measurable impact of our research, we have chosen pulmonary embolism as our initial research platform because the Surgeon General has declared pulmonary embolism a major national health problem, causing more deaths than breast cancer, AIDS, and motor vehicle accidents combined; with laudable efforts to diagnose pulmonary embolism, the number of CT studies for suspected pulmonary embolism has been increasing dramatically, while incorrect CT interpretations are frequent in general practice (10-14% over/under-diagnosis); therefore, there is a clinical need to (1) mitigate radiologists’ workloads and (2) improve the efficiency and accuracy for pulmonary embolism diagnosis using CT. Our objective is to address this clinical need by exploiting radiologist-computer synergy, delivering two important outcomes: (a) a new methodology that transcends the current paradigm from mere detection of emboli to simultaneous patient-level diagnosis, embolus-level detection, and over-diagnosis prevention; and (b) a next-generation, high- performance system that will be able to assist radiologists in quickly excluding negative patients without overlooking positive patients, accurately localizing individual emboli to support personalized treatments through risk stratification, and actively preventing PE over-diagnosis, exerting an important positive impact on clinical practice associated with pulmonary embolism—a life-threatening condition.",Computer-Aided Diagnosis of Pulmonary Embolism,9741795,R01HL128785,"['Acquired Immunodeficiency Syndrome', 'Address', 'Algorithms', 'Anatomy', 'Angiography', 'Area', 'Arteries', 'Big Data', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Embolism', 'Ensure', 'Equilibrium', 'Explosion', 'Foundations', 'General Practices', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Learning', 'Legal patent', 'Life', 'Literature', 'Lung', 'Malignant neoplasm of lung', 'Mathematics', 'Measurable', 'Medical', 'Medical Education', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Organism', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Peer Review', 'Performance', 'Pilot Projects', 'Prevention', 'Publications', 'Pulmonary Embolism', 'Research', 'Research Personnel', 'Risk stratification', 'Sensitivity and Specificity', 'Social Impacts', 'Solid', 'Surgeon', 'System', 'Technology', 'Testing', 'Traffic accidents', 'Training', 'Transcend', 'United States National Institutes of Health', 'Validation', 'Veins', 'Visualization software', 'Workload', 'base', 'bioimaging', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized tools', 'design', 'experience', 'imaging study', 'imaging system', 'improved', 'innovation', 'malignant breast neoplasm', 'next generation', 'novel', 'off-patent', 'personalized medicine', 'precision medicine', 'prevent', 'prototype', 'radiologist', 'research clinical testing', 'success', 'supervised learning', 'synergism', 'vehicular accident']",NHLBI,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,586687,0.009542859685400886
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9782929,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2019,154915,-0.04750062985058943
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9600285,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biological Neural Networks', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,194115,-0.002304033587648173
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9651713,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Biological Neural Networks', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Dose', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2018,78500,0.03464201871917173
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.03559719364515135
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9521289,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,471965,0.040199242665563954
"Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization Project Summary Prostate cancer (PCa) is the most diagnosed form of non-cutaneous cancer in US men. The selection of patients who require immediate treatment from those suitable for active surveillance currently relies on non- specific and inaccurate measurements. A method that allows clinicians to more confidently discriminate clinically relevant from non-life-threatening tumors is needed to improve patient management. Multiparametric magnetic resonance imaging (mpMRI) is the preferred non-invasive imaging modality for characterizing primary PCa. However, its accuracy for detecting clinically significant PCa is variable. We propose to address this limitation by combining mpMRI with positron emission tomography (PET) with a PCa-specific radiotracer and using advanced multimodal machine learning models (i.e. radiomics and deep learning) to characterize tumor aggressiveness based on the imaging data. Recently, scanners capable of simultaneous PET and MR data acquisition in human subjects have become commercially available. An integrated MR-PET scanner is the ideal tool for comparing MR and PET derived image features to identify those that provide complementary information and build a hybrid PET-mpMRI model that most accurately identifies clinically significant tumors. While this novel technology allows the acquisition of perfectly coregistered complementary anatomical, functional and metabolic data in a single imaging session, a new challenge needs to first be addressed to obtain quantitatively accurate PET data. In an integrated MR-PET scanner, the information needed for PET attenuation correction (AC) has to be derived from the MR data and the methods currently available for this task are inadequate for advanced quantitative studies. We have formed an academic-industrial partnership to accelerate the translation of multimodal MR-PET machine learning approaches into PCa research and clinical applications by addressing the AC challenge and validating machine learning models for detecting clinically significant disease against gold standard histopathology in patients undergoing radical prostatectomy. Specifically, we will: (1) Develop and validate an MR-based approach for obtaining quantitatively accurate PET data. We hypothesize that attenuation maps as accurate as those obtained using a 511 keV transmission source – the true gold standard for PET AC – will be obtained; (2) Identify the multimodal radiomics model that most accurately predicts PCa aggressiveness. We hypothesize that the diagnostic accuracy of this approach will be superior to that offered by the stand-alone modalities; (3) Evaluate radiomics and deep learning approaches for predicting pPCa aggressiveness. We hypothesize that machine learning approaches will achieve a higher predictive accuracy when applied to data acquired simultaneously than sequentially. Project narrative A better method to non-invasively characterize primary prostate cancer is needed to improve patient management. Extracting additional information from multimodality quantitative MR-PET data using machine learning approaches is expected to result in better diagnostic performance. In this work, we propose to accelerate the translation of quantitative MR-PET to prostate cancer research and clinical applications. In particular, we will develop and validate an MR-based attenuation correction approach to guarantee that quantitatively accurate PET data are obtained in an integrated MR-PET scanner and then use machine learning approaches to characterize the aggressiveness of the tumors in patients undergoing radical prostatectomy.",Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization,9524253,R01CA218187,"['Address', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Biopsy', 'Cancer Death Rates', 'Cancer Patient', 'Classification', 'Computer software', 'Data', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Early treatment', 'FOLH1 gene', 'Gold', 'Guidelines', 'Hand', 'Histopathology', 'Hybrids', 'Image', 'Individual', 'Interobserver Variability', 'Kinetics', 'Lesion', 'Life Expectancy', 'Ligands', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Meta-Analysis', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Morphology', 'Patient Selection', 'Patient risk', 'Patients', 'Pelvis', 'Performance', 'Phenotype', 'Physiological', 'Positron-Emission Tomography', 'Prostate', 'Prostate-Specific Antigen', 'Quality of life', 'Radical Prostatectomy', 'Reproducibility', 'Scanning', 'Source', 'Testing', 'Time', 'Translations', 'Work', 'anticancer research', 'attenuation', 'base', 'bone imaging', 'cancer classification', 'cancer imaging', 'clinical application', 'clinically relevant', 'clinically significant', 'data acquisition', 'deep learning', 'diagnostic accuracy', 'human subject', 'imaging modality', 'improved', 'industry partner', 'men', 'multimodality', 'new technology', 'non-invasive imaging', 'radiologist', 'radiomics', 'radiotracer', 'tool', 'transmission process', 'tumor']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,684119,-0.039777567456558506
"MRI near Total Joint replacements Project Abstract Overview: The parent project for this supplement aims to provide routine MRI of subjects with total joint replacements by reducing the severe image artifacts near metal, while offering highly efficient patient-specific scans that can detect bone loss, infection, and temperature changes near the implant in clinically feasible scan times. The supplement aims to incorporate deep learning techniques to better meet the parent grant goals. Relevance: Total joint replacements are one of the most successful orthopedic procedures, used annually to reduce pain from joint diseases in about one million patients in the United States (a number projected to double by 2030). However, about 10% of joint replacements fail in 5-10 years due to bone loss (osteolysis), infection, or other complications, often leading to revision surgery. Accurate, early, non-invasive assessment of complications remains limited, but would offer earlier and less invasive treatments, reduce unnecessary surgery, or allow better surgical planning. Approach: Prior to, and during the parent grant period, we have developed novel “multi-spectral imaging” (MSI) MRI techniques that allow visualization of pathology adjacent to metallic implants, and together with other groups have successfully applied them to imaging of patients with devices including joint replacements and spinal fixation hardware. However these methods remain slow, have limited spatial resolution, and are challenging to use routinely. The recent growth of the machine learning field including convolutional neural networks (CNNs), and its application to medical imaging offers unique opportunities to substantially improve MRI near metal, and specifically the goals of the parent grant. We propose 3 small, independent aims in the supplement: (1) to bring fast, isotropic imaging near metal to clinical practice by using CNN-based methods to reduce reconstruction times to under 30 seconds, (2) to improve image quality away from metal by using a new reconstruction and CNN to avoid needing standard imaging in addition to MSI methods and (3) to reduce background-gradient induced artifacts near to metal using a CNN-based approach to enable better diagnosis of abnormalities adjacent to metal. Summary: We aim to supplement our parent grant with CNN-based approaches to speed up scanning and image reconstruction, and to improve image quality near to and way from metal. These techniques will allow routine, non-invasive evaluation for earlier and more accurate detection and treatment of complications in these patients, as well as numerous other applications of MRI near metal implants. Project Narrative There is a growing need for accurate diagnosis of complications surrounding joint arthroplasty, where MRI would provide excellent contrast if not for the fact that the presence of metal severely degrades images. Building on recent ideas in MRI and deep learning, we propose to develop practical methods for routine clinical imaging of patients with metal implants by increasing speed as well as offering image contrast that shows infection and other complications near the metal devices. Ultimately these methods will be tested and offered for widespread use to enable earlier and better treatment of complications resulting from arthroplasty, as well as for better understanding of the implications of different devices.",MRI near Total Joint replacements,9750463,R01EB017739,"['Address', 'Biological Neural Networks', 'Clinical', 'Code', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Evaluation', 'Frequencies', 'Goals', 'Grant', 'Gray unit of radiation dose', 'Growth', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Infection', 'Joint repair', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metals', 'Methods', 'Morphologic artifacts', 'Network-based', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Osteolysis', 'Pathology', 'Patients', 'Phase', 'Principal Component Analysis', 'Protocols documentation', 'Replacement Arthroplasty', 'Residual state', 'Resolution', 'Scanning', 'Signal Transduction', 'Slice', 'Speed', 'Spinal', 'Stretching', 'Techniques', 'Temperature', 'Testing', 'Time', 'United States', 'Unnecessary Surgery', 'Variant', 'Vendor', 'Work', 'accurate diagnosis', 'arthropathies', 'bone loss', 'clinical imaging', 'clinical practice', 'cluster computing', 'contrast imaging', 'cost', 'deep learning', 'field study', 'image reconstruction', 'imaging approach', 'imaging modality', 'improved', 'learning strategy', 'metallicity', 'novel', 'pain reduction', 'parent grant', 'parent project', 'reconstruction', 'response', 'sample fixation', 'spectrograph']",NIBIB,STANFORD UNIVERSITY,R01,2018,156870,0.015113368636437826
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9586688,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Biological Neural Networks', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Dose', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2018,221250,0.05635309561367292
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9580704,R01EB026708,"['Abdomen', 'Air', 'Algorithms', 'Area', 'Biological Neural Networks', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,460690,0.017058058629856283
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,0.02657702425668024
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,0.025685781821330852
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9523267,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2018,385011,0.04475972274061687
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.02999571360265674
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.03149062215255328
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9592472,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Topical Corticosteroids', 'Translating', 'Transplantation', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2018,240000,0.011589032418918526
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9724174,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,24598,0.02084212756475931
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9526090,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,399482,0.02084212756475931
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9566185,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,436007,0.0019452028517490177
"Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy Project Summary We propose to introduce and optimize a new method of radiomics extraction via transfer learning with deep convolutional neural networks (CNNs) and to compare it to the conventional segmentation-based radiomics approach on breast dynamic contrast-enhanced magnetic resonance images (DCE-MRIs). The field of breast radiomics has been expanding fast, with many clinical conclusions being successfully derived from medical images using qualitative analysis. In the past couple of years, deep learning has experienced explosive growth in image recognition, easily solving complex problems. Deep CNNs achieve remarkable classification results on everyday image datasets. We propose to investigate the utility of deep neural networks with regards to the medical image datasets, specifically on the breast DCE-MRI dataset. Given the relatively small sizes of these datasets, CNNs previously trained on non-medical images will be utilized for clinical classifications as feature extractors. We will investigate multiple parameters involved in the CNN feature extraction methodology and their effect on classification performance. Two clinical tasks will be studied under the proposed research: 1) malignancy assessment and 2) response to therapy prediction. The optimized CNN method will be compared to and combined with the conventional segmentation- based radiomics method. Furthermore, we aim to investigate the robustness of the segmentation-based features across MR scanners of different manufacturers. The first aim of the proposed research will study the robustness of the segmentation- based features extracted from images acquired on MR scanners of two different manufacturers. The robustness will be investigated under four clinical tasks, such as lymph node involvement and receptor statuses. The second aim will be focused on optimization of CNN feature extraction and subsequent classifier design. Lastly, under the third aim we will compare and combine the CNN and segmentation-based radiomics in the classification tasks of malignancy assessment and response to therapy prediction. Project Narrative The goal of the proposed research is to improve breast cancer diagnosis and prognosis based on dynamic contrast-enhanced magnetic resonance images by introducing novel deep learning methods to medical image classification and combining it with the conventional radiomics systems. The incredible power of deep learning methods to classify everyday images shows great promise to make predictions based on medical image datasets. Our thorough investigation of deep learning methods and their combination with conventional radiomics methods has potential to improve breast cancer management.",Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy,9469826,F31CA221193,"['Benign', 'Biological Neural Networks', 'Breast', 'Cancer Prognosis', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Complex', 'Computers', 'Data', 'Data Set', 'Effectiveness', 'Evaluation', 'Goals', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intuition', 'Investigation', 'Lesion', 'Lymph Node Involvement', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical Imaging', 'Methodology', 'Methods', 'Nature', 'Neoadjuvant Therapy', 'Performance', 'Prediction of Response to Therapy', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Research', 'Standardization', 'System', 'Techniques', 'Training', 'Variant', 'base', 'breast cancer diagnosis', 'chemotherapy', 'computerized', 'contrast enhanced', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'learning strategy', 'malignant breast neoplasm', 'novel', 'radiomics', 'receptor', 'response']",NCI,UNIVERSITY OF CHICAGO,F31,2018,26048,-0.07325034177943628
"A Computer Aided Diagnosis(CAD) Algorithm for Identification of Dysplasia in Patients with Barrett Esophagus ABSTRACT The goal of this project is to develop a based computer aided diagnosis (CAD) algorithm for identification of regions at risk for developing esophageal adenocarcinoma (EAC) in optical coherence tomography (OCT) scans of the esophagus. EAC is one of the deadliest cancers with a 5-year survival rate of less than 20%; yet the standard of care for detecting precursors to EAC is widely recognized to be inadequate. Just recently, a study found that 25% of patients who underwent a standard endoscopic surveillance exam which was found to be ‘clear’ then went on and progressed to EAC within one year. Clearly today’s approach is not working and a significant percentage of disease is being missed. While comprehensive esophageal OCT imaging has shown great potential in addressing this unmet clinical need, one of the main limiters to wider adoption and impact of this technology is the challenge of interpreting the large volume of high-resolution images in real-time. A CAD algorithm would allow OCT to realize its promise in this field and significantly improve the standard of care. Here we propose the development of a deep learning CAD algorithm which will operate on a full patient level volumetric dataset with awareness of the anatomy, robust against image quality and motion artifacts, and trained and validated against a large dataset (>1000 patients). We will aim to reach a sensitivity and specificity of 90/80% based on a threshold set by the American Society for Gastroenterology (ASGE) for the performance of advanced imaging in the detection of high grade dysplasia in BE. PROJECT NARRATIVE The goal of this project is to develop a computer aided diagnosis (CAD) algorithm for use with the NinePoint Medical OCT imaging system and provide early detection of pre-cancerous lesions. Earlier detection leads to earlier treatment, more positive health outcomes for patients and lower healthcare system costs.",A Computer Aided Diagnosis(CAD) Algorithm for Identification of Dysplasia in Patients with Barrett Esophagus,9622504,R43CA232860,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Architecture', 'Awareness', 'Barrett Esophagus', 'Biopsy', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Dysplasia', 'Early Diagnosis', 'Early treatment', 'Epithelium', 'Esophageal', 'Esophageal Adenocarcinoma', 'Esophageal Diseases', 'Esophageal Intraepithelial Neoplasia', 'Esophagus', 'Gastroenterology', 'Gland', 'Goals', 'Health', 'Health Care Costs', 'Healthcare Systems', 'Image', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Morphologic artifacts', 'Motion', 'Optical Coherence Tomography', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Premalignant', 'Risk', 'Sample Size', 'Scanning', 'Sensitivity and Specificity', 'Societies', 'Software Tools', 'Squamous Epithelium', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'base', 'case-based', 'cost', 'deep learning', 'diagnosis quality', 'effective therapy', 'gastric foveola', 'gastric rugae', 'high resolution imaging', 'imaging system', 'improved', 'in vivo', 'interest', 'software development', 'standard of care', 'stomach cardia']",NCI,"NINEPOINT MEDICAL, INC.",R43,2018,217888,0.04598354049518446
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9447403,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Imagery', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,385444,0.007902707125735443
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9669491,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2018,252169,0.014374430609423521
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9659552,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2018,375000,0.0049937669005903846
"New Approach to US Elasticity Imaging Project Summary To more fully exploit the basic science of mechanobiology as it pertains to breast cancer progression, the medical imaging field continues to search for fast, safe, and effective elasticity imaging methods. In this project we propose a fundamentally new approach to ultrasonic elasticity imaging in which the weak forces applied to patient tissues and the measured displacements that result are used to train a numerical model specifically for that patient. This constitutive model is developed using finite-element methods and neural networks assembled in a unique configuration called the AutoProgressive (AutoP) Method. AutoP “learns” complete stress and strain properties directly from sparse force and displacement measurements and without a mathematical model. Using quasi-static stimuli, AutoP exploits the fact that each force-displacement estimate contains information about mechanical properties at all locations in the contiguous tissue. From measurement information and conservation laws, AutoP generates an informational model without the need to make assumptions about tissue linearity, isotropy, or other material properties normally required when constructing images that display tissue mechanical properties. Once an accurate material-property model is formed by AutoP, we adopt a separate rheological model (e.g., Kelvin Voigt) to form viscoelastic parameters for image display. The AutoP method employs beamformed RF-echo acquisitions from which point displacements are estimated, applied compressional force sensed at the transducer surface, and tissue shape.  No other imaging method is capable of estimating all relevant stress fields, which gives AutoP unique capabilities. AutoP estimates the mechanical properties that one strives to obtain from an inverse problem approach, but AutoP is not a mathematical inverse technique and hence does not suffer from nonunique solutions. Without the need to assume material properties, AutoP can (in principle) model tissue properties in three dimensions and in time following large deformations in highly-nonlinear, anisotropic media. This R21 proposal focuses on establishing the feasibility of the AutoP methodology for subsequent clinical trials under future funding. At the completion of this two-year project, we will demonstrate a new tool for medical imaging capable of exploring the mechanical properties of tissues over a very broad range of deformations. We specifically target ultrasonic methods and quasi-static force stimuli in this project. However AutoP could eventually be coupled to other imaging modalities (e.g., MRE, OCE) or dynamic force-stimulus methods.  The scientific premise underlying AutoP is that we already record all of the information needed to generate a very broad range of elasticity images. The key to unlocking this information is to set aside mathematical models in favor of data-driven informational models built using the unique machine learning abilities of the AutoP method. If successful, AutoP will have a major influence on medical elasticity imaging methods. Project Narrative: A new type of machine-learning method is proposed for elasticity imaging of patient tissues that offers the potential to minimize many current limitations. If we are successful in this development, ultrasonic elasticity imaging would significantly improve in its ability to accurately represent mechanical properties of breast tissues, without any changes in current instrumentation and without increasing cost to the healthcare system or adding risk to patients.",New Approach to US Elasticity Imaging,9560761,R21EB023402,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Basic Science', 'Behavior', 'Biological Neural Networks', 'Breast', 'Clinical', 'Clinical Trials', 'Code', 'Coupled', 'Data', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Elasticity', 'Elements', 'Engineering', 'Environment', 'Feedback', 'Funding', 'Future', 'Goals', 'Healthcare Systems', 'Image', 'Inflammatory', 'Isotropy', 'Laws', 'Learning', 'Legal patent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammary Gland Parenchyma', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modulus', 'Patients', 'Procedures', 'Process', 'Property', 'Recording of previous events', 'Risk', 'Role', 'Scanning', 'Shapes', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Study Subject', 'Surface', 'Techniques', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transducers', 'Ultrasonic Transducer', 'Ultrasonics', 'Writing', 'aged', 'base', 'breast cancer progression', 'breast imaging', 'cost', 'experience', 'healthy volunteer', 'human subject', 'imaging modality', 'imaging properties', 'improved', 'in vivo', 'information model', 'insight', 'instrumentation', 'learning strategy', 'mathematical model', 'mechanical properties', 'model building', 'model development', 'novel strategies', 'object shape', 'processing speed', 'sensor technology', 'tool', 'viscoelasticity']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2018,179876,-0.014436657974882774
"2018 Image Science Gordon Research Conference & Gordon Research Seminar Project Summary: The proposal requests support for early-career investigators to attend the 2018 Gordon Research Conference on Image Science. The unique feature of this conference in its third offering compared with others in medical imaging is the bringing together of renown speakers from disparate application areas, including astronomy, biology, medicine, remote sensing, and security and defense industries, in a forum that encourages each to describe their greatest challenges and most promising solutions. All speakers are invited based on their leadership in their field and their willingness to debate fundamental issues shared by everyone developing, evaluating, and applying imaging in medicine and biology. We believe the GRC format placed in the context of a small-college venue promotes the type of innovative interdisciplinary thinking that leads to breakthroughs. An environment where leading senior scientists debate core issues is valuable to young investigators trying to build successful independent careers in medical imaging in industry and academia. All attendees are invited to present a poster describing their research in poster sessions that are a key element of the Gordon Conference format. The June 17-22, 2018 GRC conference theme is “Image Science: Creating Knowledge from Information,” which is focused on appropriate acquisition and efficient uses of the massive volume of imaging information now collected from patients. Speakers give 40 minutes presentations in a single-track format with 20 minute discussions following each presentation that are led by experts in the field. Topic range from “Imaging in Brain Science Discovery” to “Advanced Machine Learning” and “Computational Imaging.” At the center of each presentation is a discussion of the core challenges shared by image scientists and novel techniques for acquiring and displaying information in a manner that maximizes decision performance. Given the success of the previous meeting, we will hold the first-ever, student-run Gordon Research Seminars (GRS) on Image Science June 16, 17, 2018. Our aim is to build Image Science as an independent field of study through detailed interdisciplinary discussions and by fostering the success of a new generation of image scientists. Project Narrative: Solutions to very difficult problems often emerge from discussions among experts in different fields of study being challenged by the same core problems. The 2018 GRC on Imaging Science strives to build a community of problem solvers by creating an environment for detailed discussions among senior investigators that involves young investigators at a time when they are building careers. This is a proposal to fund young investigators to attend the conference.",2018 Image Science Gordon Research Conference & Gordon Research Seminar,9461211,R13EB025662,"['Academia', 'Area', 'Astronomy', 'Big Data', 'Biology', 'Brain', 'Collaborations', 'Communities', 'Computational Science', 'Data', 'Data Analytics', 'Development', 'Disabled Persons', 'Discipline', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Fees', 'Female', 'Financial Support', 'Fostering', 'Funding', 'Housing', 'Human', 'Image', 'Industry', 'Information Sciences', 'Interdisciplinary Study', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Minority', 'Modeling', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Recruitment Activity', 'Request for Proposals', 'Research', 'Research Personnel', 'Resource Development', 'Risk-Taking', 'Role', 'Running', 'Science', 'Scientist', 'Security', 'Senior Scientist', 'Series', 'Societies', 'Source', 'Statistical Models', 'Students', 'Systems Development', 'Techniques', 'Thinking', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'career', 'college', 'cost', 'design', 'disabled students', 'educational atmosphere', 'field study', 'frontier', 'graduate student', 'image reconstruction', 'imaging scientist', 'imaging system', 'information display', 'innovation', 'instrument', 'meetings', 'minority student', 'multidisciplinary', 'next generation', 'novel', 'posters', 'preference', 'remote sensing', 'skills', 'success', 'symposium', 'training opportunity', 'virtual', 'willingness']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,0.023366164382957837
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9616697,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2018,29442,0.001015834317882965
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Supplement Title: Deep learning-based methods for PET image reconstruction and segmentation to enhance radionuclide therapy dosimetry Abstract There is much recent interest in quantitative imaging of yttrium-90 (Y-90) for dosimetry because of the promise of novel Y-90 labelled radionuclide therapies. Deep learning methods are well suited for addressing the challenges of Y-90 positron emission tomography (PET) imaging, where compared with diagnostic FDG PET, true coincidence count-rates are very low while random coincidences are high. The potential of deep learning-based algorithms to outperform conventional algorithms in medical imaging is well recognized, however research in applying these methods to nuclear medicine imaging modalities such as PET is very limited. The few studies applying deep learning to PET imaging have been mostly limited to post-reconstruction image processing/analysis for denoising and feature extraction, and not in the image formation/reconstruction process. Additionally, deep learning research in PET thus far have focused on improving diagnostic imaging, not quantitative imaging, which together with accurate lesion/organ segmentation are pre-requisite for accurate dosimetry. In this supplement, we propose to develop and evaluate deep learning-based image reconstruction and lesion/organ segmentation for low count PET applications such as Y-90 PET. Our approach starts with the raw projection data and utilizes a deep recurrent network in the image formation process. Because the two tasks are mutually dependent, our formalism takes the novel approach of joint reconstruction-segmentation with multi-modality (PET/CT) data. Specifically, we will 1) develop and evaluate Y-90 PET image reconstruction with a deep recurrent network for the regularizer, 2) develop and evaluate deep-learning based joint PET segmentation-reconstruction using multi- modal 90Y PET/CT data. To train/validate/test the proposed methods, we will use clinically realistic phantom measurements and simulations as well as leverage on existing patient data from the parent grant where thus far, PET data and radiologist defined morphologic liver/lesion contours for over 50 cases and 150 lesions are available. We will compare the new Y-90 PET reconstruction with the formulation we recently developed under the parent grant (using conventional untrained regularizers) that showed promising results but suffered from resolution- noise tradeoff. The expected outcome of this work is a well validated deep learning reconstruction- segmentation framework for challenging PET imaging applications where conventional methods are suboptimal. The proposed research is expected to result in new and accurate tools for quantitative image reconstruction and lesion/organ segmentation that have the potential to contribute significantly toward improving dosimetry in internal radionuclide therapy such as Yttrium- 90 radioembolization in liver malignancies. This study is relevant to public health because a dosimetry-guided personalized approach to radionuclide therapy is highly likely to substantially improve patient outcomes compared to current standard practice. !",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,9750430,R01EB022075,"['90Y', 'Address', 'Algorithms', 'Clinical', 'Data', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Formulation', 'Image', 'Joint repair', 'Joints', 'Label', 'Lesion', 'Liver', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Morphology', 'Noise', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Positron-Emission Tomography', 'Process', 'Public Health', 'Radioembolization', 'Radionuclide therapy', 'Recurrence', 'Research', 'Resolution', 'Testing', 'Training', 'Work', 'base', 'deep learning', 'dosimetry', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'interest', 'learning strategy', 'novel', 'novel strategies', 'parent grant', 'personalized approach', 'personalized cancer therapy', 'quantitative imaging', 'radiologist', 'reconstruction', 'simulation', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,102093,0.04189364319585888
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9414991,R01CA193730,"['Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2018,354198,-0.02811879369772713
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9536759,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,619539,0.04759382526157225
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,0.033519053927806707
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9476341,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2018,770494,-0.0011612519034232525
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9523172,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'deep learning', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2018,213750,0.012289507613652615
"Toward Diagnostics and Therapies of Molecular Subcategories of CAD ﻿    DESCRIPTION (provided by applicant): Coronary artery disease (CAD) is a leading cause of death worldwide and in the US. While the genetics of this disease are intrinsically complex, thanks to huge research investments during the last 5-10 years, particularly in genome-wide association studies (GWAS), a more unbiased, data-driven and realistic view of CAD has been achieved. As part of this achievement, ~160 common risk loci for CAD/myocardial infarction (MI) have been identified. An important task is now to understand the molecular mechanisms/pathways by which these loci exert risk for CAD/MI allowing to translating the initial findings into new therapies and diagnostics. However, since the loci identified thus far explain only ~10% of variation in CAD/MI risk, it is also essential to define additional CAD pathways operating in parallel with GWA loci. In recent years, clinical studies that consider intermediate phenotypes (between DNA and disease) have greatly enhanced interpretations of risk loci identified in GWA datasets. In addition, disease networks that can be identified from intermediate molecular phenotypes provide an essential framework to identify novel CAD pathways and targets for new CAD therapies. Over the last 6 years, we have performed a clinical study considering many intermediate phenotypes in CAD patients (the STARNET study). In this proposal we intend to use newly generated DNA genotype and RNA sequence data from the STARNET study to identify atherosclerosis and metabolic networks underlying CAD. We then propose a new prospective study of CAD (the NGS-PREDICT study) with the main purpose of validating findings from the STARNET study. We hypothesize that the extent and stability of coronary lesions, thus clinical outcomes can be accurately assessed by defining the status of key atherosclerosis gene networks. In turn, metabolic networks active in liver, abdominal fat, and skeletal muscle influence the status of the atherosclerosis gene networks. In addition, molecular data isolated from easily obtainable tissues (e.g., blood, subcutaneous fat and plasma) can be used to identify biomarkers that can predict risk for clinical events caused by CAD. To test these hypotheses, we propose the following specific aims. Aim 1: To identify regulatory Bayesian gene networks causally linked to CAD and/or CAD sub-phenotypes using the STARNET datasets and the CARDIoGRAM meta-analysis GWA datasets. Aim 2: Identify biomarkers predicting clinical events of CAD (reflected in SYNTAX score) by applying machine learning on DNA genotype, RNA sequence and CAD plasma protein data from easily obtainable tissues of the STARNET cases. Aim 3: To validate the identified causal CAD eQTLs/networks and the biomarkers using the NGS-PREDICT study performed at the Mt. Sinai Hospital, the Swedish Twin study and CAD cell and animal models. We believe the proposed studies can lead to a significantly better molecular understanding of CAD and thus, serve the more long-term goal of preventive and personalized therapies of CAD patients diagnosed in well-defined molecular subcategories. PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the world's leading cause of death. We will perform systems genetic analysis of DNA and RNAseq data from 9 CAD-relevant tissues in 700 well-characterized patients (STARNET) integrated with genome-wide association data to reveal CAD-causing metabolic and atherosclerosis gene networks, and within these, new inherited risk variants, CAD-mechanisms, therapeutic targets and biomarkers will be identified and validated in a new prospective clinical study of CAD (NGS-PREDICT). Our studies promise to significantly advance understanding of CAD towards achieving preventive and personalized care.",Toward Diagnostics and Therapies of Molecular Subcategories of CAD,9497813,R01HL125863,"['Abdomen', 'Achievement', 'Address', 'Alleles', 'Angiography', 'Animal Model', 'Area', 'Atherosclerosis', 'Benchmarking', 'Biochemical Pathway', 'Biological Markers', 'Biological Models', 'Biology', 'Biopsy', 'Blood', 'Blood Vessels', 'Cardiology', 'Cardiovascular system', 'Cause of Death', 'Cell Differentiation process', 'Cell model', 'Chest', 'Clinical', 'Clinical Research', 'Complex', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'DNA', 'DNA analysis', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Pathway', 'Engineering', 'Event', 'Family', 'Fatty acid glycerol esters', 'Foam Cells', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Models', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Hospitals', 'In Vitro', 'Individual', 'Inherited', 'Institutes', 'Investments', 'Lead', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Meta-Analysis', 'Metabolic', 'Molecular', 'Molecular Disease', 'Myocardial Infarction', 'New York', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Plasma Proteins', 'Preventive', 'Preventive care', 'Preventive therapy', 'Prospective Studies', 'Quantitative Trait Loci', 'RNA', 'RNA Sequences', 'Regulator Genes', 'Research', 'Research Proposals', 'Risk', 'Sampling', 'Single Nucleotide Polymorphism', 'Skeletal Muscle', 'Subcategory', 'System', 'Techniques', 'Testing', 'Tissues', 'Translating', 'Twin Multiple Birth', 'Twin Studies', 'Variant', 'Whole Blood', 'abdominal fat', 'biological systems', 'clinical predictors', 'clinical risk', 'computer based statistical methods', 'coronary event', 'coronary lesion', 'disorder risk', 'follow-up', 'genetic analysis', 'genome wide association study', 'in vivo Model', 'macrophage', 'medical schools', 'molecular phenotype', 'monocyte', 'multidisciplinary', 'novel', 'novel diagnostics', 'novel therapeutics', 'percutaneous coronary intervention', 'personalized care', 'personalized diagnostics', 'personalized medicine', 'predictive marker', 'predictive modeling', 'prospective', 'protein biomarkers', 'public health relevance', 'recruit', 'risk variant', 'subcutaneous', 'targeted biomarker', 'therapeutic target', 'trait', 'transcriptome sequencing']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2018,798847,0.027448810508243257
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9547376,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,362947,-0.00263349913418846
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,0.06405792476765242
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,-0.00803321500551169
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9517057,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Radiology Specialty', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Screening procedure', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'single photon emission computed tomography', 'skills', 'success', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2018,169609,0.0034700432868635884
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9456285,R21EB024700,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,295916,0.013908118460458014
"Rapid Robust Pediatric MRI Project Abstract Motivation: This is a competing renewal of our successful project, Rapid Robust Pediatric MRI, R01 EB009690. MRI offers superb soft tissue contrast for children, without the ionizing radiation and cancer risk of CT. However, MRI use has been limited due to long exams, low spatial resolution, and motion-artifacts. Thus, MRI often requires prolonged anesthesia with breath-holds and attendant risk; hence, children often lack the beneﬁts of cross-sectional imaging altogether or are exposed to ionizing radiation. The previous project addressed these concerns by creating a dedicated pediatric imaging system. Highly par- allel, high-SNR 3T receive coil arrays were designed and constructed speciﬁcally for pediatric body imaging. The high SNR was used to accelerate scans reconstructed with a combination of parallel imaging, new mo- tion correction algorithms, compressed sensing (CS), and higher dimensional imaging. The resulting system is now being used extensively in clinical practice, signiﬁcantly reducing anesthesia depth and duration, and has markedly increased our MRI utilization. Key technologies have been or are now being commercialized with GE Healthcare, including the pediatric receive array, CS, 4D ﬂow, full-Fourier single-shot T2-weighted scanning, and coil compression. Siemens has licensed ﬁve of our patents, implemented them in work-in-progress packages, and productized our coil compression and our ESPIRiT coil sensitivity estimation. Philips has licensed three of our patents. This ensures broad impact. Approach: Despite signiﬁcant progress and reduced anesthesia depth and duration, patient cooperation re- mains the main limitation to eliminate anesthesia in all pediatric body MRI exams. Many children will cooperate for several minutes, but then ﬁdget and get out of the scanner. Others are content until acoustic noise agi- tates them. Therefore the major emphasis now is greater exam execution speed, comprehensive elimination of acoustic noise, and increased robustness, particularly to contrast agent injection. The project has three interrelated development aims, validated by clinical studies. Aim 1 will enable fast 2D imag- ing for quiet T2 and quiet low-distortion diffusion weighted imaging. A second aim is to develop free-breathing 3D contrast-enhanced and diffusion-weighted imaging that is silent and motion-robust. The third aim will enable au- tomated, smart scanning to speed the exam execution and adaptive protocols to increase the exam robustness. The impact of all of these developments in the clinic will then be assessed to assess the resulting reduction of anesthesia. Signiﬁcance: This work will lead to fast, robust, broadly-applicable pediatric MRI protocols with less anes- thesia, making MRI safer, cheaper, and more available to children. MRI will be transformed into a workhorse modality, reducing CT radiation burden. The techniques will facilitate wide application in the community setting and permit new MRI applications, for both pediatric and adult diseases. Project Narrative Pediatric MRI often requires anesthesia. After considerable progress reducing the depth and duration of anes- thesia, this work aims to reduce the frequency of anesthesia through a synergistic combination of fast, quiet, motion-robust, automated, and adaptive scanning. This will make MRI safer, cheaper, and more widely available to children, reducing the population risk of radiation from CT.",Rapid Robust Pediatric MRI,9595406,R01EB009690,"['Acoustics', 'Address', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Body Image', 'Body part', 'Bolus Infusion', 'Breathing', 'Child', 'Child Health', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Computational Technique', 'Contrast Media', 'Coupled', 'Data', 'Data Quality', 'Development', 'Diagnostic Imaging', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Ensure', 'Exposure to', 'Frequencies', 'Funding', 'Goals', 'Healthcare', 'Image', 'Image Compression', 'Image Enhancement', 'Injections', 'Ionizing radiation', 'Legal patent', 'Letters', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modality', 'Morphologic artifacts', 'Motion', 'Motivation', 'Noise', 'Patients', 'Pediatric Oncology', 'Pediatrics', 'Population', 'Protocols documentation', 'Radiation', 'Resolution', 'Risk', 'Role', 'Running', 'Scanning', 'Speed', 'System', 'T2 weighted imaging', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transplantation', 'Validation', 'Work', 'base', 'cancer risk', 'clinical practice', 'clinical translation', 'community setting', 'compliance behavior', 'contrast enhanced', 'design and construction', 'experience', 'high dimensionality', 'image reconstruction', 'imaging system', 'innovation', 'multidisciplinary', 'novel', 'pediatric patients', 'programs', 'radiation risk', 'reconstruction', 'skills', 'soft tissue', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2018,703347,-0.002371628007305345
"Fast and Robust Low-Dose X-Ray CT Image Reconstruction Abstract:  The use of CT scans has recently increased, for example, in virtual colonoscopy, CT cardiac screening, screening of the lung in smokers, whole-body CT in asymptomatic patients, and CT imaging of children. Shortening of the scanning time to around 1 second, eliminating the strict need for the subject to remain still or be sedated, is one of the main reasons for the large increase in the pediatric population. CT scans of children have been estimated to produce non-negligible increases in the probability of lifetime cancer mortality, leading to calls for the use of reduced current settings for CT scans of children. For these reasons, the CT industry has put in a lot of effort to develop low-dose CT. One active area of research is methods to reduce the radiation counts by applying adaptive collimation to block unnecessary x-ray photons. Another active area of research is the development of more robust image reconstruction algorithms that are less sensitive to noise for low-count data.  This grant proposal is focused on the second approach — development of fast and robust reconstruction algorithms. It is known that some iterative image reconstruction algorithms outperform the analytical filtered backprojection (FBP) algorithm in terms of producing less-noisy images with the same data set. One disadvantage of these iterative algorithms is their long computation time, making them impractical in a real- world CT reconstruction tasks. For this reason, the FBP algorithm is still the main work horse for CT applications.  The main goal of the proposed research is to develop fast and robust iterative-algorithms so that their computation time is at the same order of an analytic FBP algorithm, using experimental low-dose phantom, cadaver data, and low-dose cancer screen chest CT patient data to perform comparison studies. We will answer the question: When the fast and robust algorithms are used, how much can the CT dose be reduced while retaining the image quality of a standard-dose CT produced by the conventional FBP?  This R15 project provides Weber State University (WSU) computer engineering and computer science students with hands-on opportunities and experiences of performing real-world research in the field of healthcare. It will stimulate the interests of students so that they consider a career in biomedical and bioengineering field/industry. Narrative:  CT dose is currently a major concern for the general public. Low-dose CT is under development. The proposed research will focus on developing fast, robust and practical image reconstruction methods that are able to produce a standard CT image using a lower CT dose.",Fast and Robust Low-Dose X-Ray CT Image Reconstruction,9440734,R15EB024283,"['Algorithms', 'Applications Grants', 'Area', 'Biomedical Engineering', 'Cadaver', 'Cancer Patient', 'Cardiac', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Collimator', 'Computed Tomographic Colonography', 'Computer Hardware', 'Computer Simulation', 'Computers', 'Contracts', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Disadvantaged', 'Disease', 'Dose', 'Engineering', 'Environment', 'Equilibrium', 'Equus caballus', 'Evaluation', 'General Population', 'Goals', 'Healthcare', 'Human', 'Image', 'Industry', 'Inferior', 'Internships', 'Investigation', 'Learning', 'Lesion', 'Liver Cirrhosis', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Morphologic artifacts', 'Noise', 'Patients', 'Performance', 'Photons', 'Population', 'Preparation', 'Probability', 'Radiation', 'Radiation exposure', 'Research', 'Resolution', 'Roentgen Rays', 'Running', 'Scanning', 'Screening for cancer', 'Smoker', 'Structure', 'Students', 'Supervision', 'Time', 'Training', 'Universities', 'Utah', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'career', 'chest computed tomography', 'clinical application', 'computer science', 'data acquisition', 'design', 'digital imaging', 'experience', 'high risk', 'image reconstruction', 'improved', 'interest', 'low-dose spiral CT', 'lung cancer screening', 'mortality', 'parallel computer', 'professor', 'radiologist', 'reconstruction', 'screening', 'tomography', 'university student']",NIBIB,WEBER STATE UNIVERSITY,R15,2018,88321,0.019065794416583386
"System-independent quantitative cardiac CT perfusion System-independent quantitative cardiac CT perfusion Summary BioInVision, Inc. and Case Western Reserve University researchers will develop software for quantitative anal- ysis of cardiac CT perfusion (CCTP), creating an important tool for evaluation of cardiovascular disease. With this product, cardiologists will be able to identify functional flow deficits in coronary artery territories. When one combines functional myocardial blood flow (MBF) with coronary anatomy from computed tomography angi- ography (CTA), it provides needed information on the physiologic significance of a stenosis. The CTA+CCTP combo could provide an ideal gateway exam for deciding whether to send a patient for percutaneous invasive coronary angiography and potential intervention (e.g., stenting). In addition, if flow is low and no stenosis is present, it will suggest microvascular disease, a very prevalent ailment of growing concern, especially among women and in diabetes. CT compares favorably to all other non-invasive cardiovascular imaging techniques (SPECT, PET, and MRI). It is available in many settings, including emergency departments. It provides both MBF and reliable coronary anatomy, not available in any other single modality. It has excellent resolution ena- bling detection of endocardial perfusion deficit, thought to be an early disease indicator that is impossible to assess with SPECT. CT is cheaper and has higher patient throughput than MRI or PET. With inclusion of MBF, CT would have an excellent opportunity to disrupt the diagnostic pathway leading to percutaneous intervention, a pathway now dominated by SPECT myocardial imaging, which includes zero information about coronary anatomy. To achieve reliable, accurate CT MBF measurements, we will invoke innovations to reduce beam hardening and to make reliable estimates of flow. Currently, CT perfusion is done on different CT machines with manufacturers’ proprietary software, using algorithms that can give erroneous MBFs. Applicable to any commercial scanner; our solution would harmonize measurements across acquisition systems providing trust- worthy, standardized measurements to clinicians, thereby improving management of cardiovascular patients. Narrative We will develop software to enable reliable evaluation of blood flow in heart tissue using CT imaging. With suc- cess, our project could lead to an improved gateway examination that could reduce unnecessary invasive cor- onary angiography, thereby reducing costs, patient discomfort, patient risk, and possibly unnecessary interven- tional therapies.",System-independent quantitative cardiac CT perfusion,9622204,R41HL144271,"['Accident and Emergency department', 'Affect', 'Algorithms', 'Anatomy', 'Angiography', 'Attention', 'Benchmarking', 'Blood Vessels', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cause of Death', 'Chest Pain', 'Clinical', 'Clinical Data', 'Computer software', 'Confidence Intervals', 'Coronary', 'Coronary Angiography', 'Coronary artery', 'Cost Savings', 'Coupled', 'Data', 'Detection', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Electrocardiogram', 'Evaluation', 'Family suidae', 'Heart', 'Image', 'Imaging Techniques', 'Inferior', 'Intervention', 'Iodine', 'Lead', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measurement', 'Methods', 'Microvascular Dysfunction', 'Modality', 'Modeling', 'Morphologic artifacts', 'Myocardial', 'Myocardium', 'Obesity', 'Pathway interactions', 'Patient risk', 'Patients', 'Perfusion', 'Persons', 'Phase', 'Physiological', 'Physiology', 'Positron-Emission Tomography', 'Pre-Clinical Model', 'Prevalence', 'Quantitative Evaluations', 'Research', 'Research Personnel', 'Resolution', 'Source', 'Standardization', 'Stenosis', 'Stents', 'System', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Tissues', 'Trust', 'Universities', 'Woman', 'X-Ray Computed Tomography', 'blood flow measurement', 'cardiovascular imaging', 'cost', 'design', 'detector', 'digital', 'imaging system', 'improved', 'innovation', 'noninvasive diagnosis', 'perfusion imaging', 'pre-clinical', 'prototype', 'research and development', 'single photon emission computed tomography', 'software development', 'success', 'tool', 'virtual']",NHLBI,"BIOINVISION, INC.",R41,2018,224240,-0.01653169578558666
"New Approach to Quantitative Beta Amyloid Imaging Using PET Summary This project seeks to prove the commercial feasibility of a new approach to analyzing dynamic positron emission tomography (PET) data that would improve sensitivity, quantitative accuracy, and accessibility of imaging the biomarkers of Alzheimer's disease (AD). Recent progress in understanding the nature of neurodegenerative diseases — especially evidence that the onset of cognitive symptoms of AD can be mitigated —amplify the critical need of improved quantitative evaluation of AD biomarkers. Dynamic PET may be the most accurate modality capable of achieving this goal. However, current strategies of analyzing dynamic PET images either require complex acquisition protocols with invasive arterial blood sampling procedures or rely on accuracy-degrading approximations such as compartment modeling. We have developed Intelligent Dynamics-Driven Quantitative Diagnostics (IDDQD), a novel processing approach based on factor analysis of dynamic structures with partial clustering used to initiate the process. We have shown that an early version of IDDQD can extract blood and tissue tracer dynamics and the corresponding spatial distributions from 11C-PIB PET scans. SolvingDynamics Inc plans to offer a Research-as-a-Service data processing workflow that will apply IDDQD to dynamic brain PET datasets acquired by the customers, producing accurate quantitative tracer dynamics time-activity curves (TACs) and the distribution of the targeted tissues, including the AD biomarkers beta-amyloid and tau. Our proprietary algorithm does not require the tracer dynamics model to achieve steady state, so a shorter scan can be used to generate results of similar or better accuracy than those produced by current approaches, such as reference tissue- based methods. In this proposal, SolvingDynamics seeks to prove the feasibility of our proposed approach by comparing the diagnostics obtained using IDDQD analysis of dynamic PET data and those obtained from independent measurements. A subcontract group at Lawrence Berkeley National Laboratory has been conducting dynamic 11C-PIB PET studies for several years and has accumulated over 70 cases with PET data matched to both cognitive-memory tests and to post-mortem pathology studies. SolvingDynamics will retrospectively apply its analysis technique to these datasets and compare its computed tissue distributions to standardized uptake volume ratio (SUVR) and distribution volume ratio (DVR) data. A subset of 20 dynamic 11C-PIB PET datasets ranging in length from 15 to 90 minutes will also be analyzed in order to validate the feasibility of reducing the imaging time. In addition, similar studies aimed at reducing imaging time with IDDQD will be performed for 20 PET scans acquired using 18F-AV1451 tracer to image tau. PROJECT NARRATIVE Positron emission tomography image analysis methodology to be validated in this project aims to improve sensitivity and specificity of tissue analysis in dynamic positron emission tomography, improving diagnosis of Alzheimer's diseases and other neurodegenerative disorders. The main benefits are expected in medical research developing treatments for dementia and in clinical diagnosis, allowing early detection of the disease with less cost and reduced radiation dose to the patients.",New Approach to Quantitative Beta Amyloid Imaging Using PET,9557192,R43AG059500,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Amyloid', 'Amyloid beta-Protein', 'Autopsy', 'Benchmarking', 'Binding', 'Biological Markers', 'Blood', 'Blood specimen', 'Brain', 'Brain imaging', 'Cause of Death', 'Clinic', 'Clinical Research', 'Cognition', 'Cognitive', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dementia', 'Diagnosis', 'Diagnostic', 'Disease', 'Dose', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Factor Analysis', 'Functional Imaging', 'Goals', 'Gold', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Injections', 'Kinetics', 'Laboratories', 'Length', 'Light', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Memory', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurodegenerative Disorders', 'Onset of illness', 'Pathology', 'Patients', 'Phase', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Protocols documentation', 'Quantitative Evaluations', 'Radiation', 'Research', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Services', 'Small Business Innovation Research Grant', 'Spatial Distribution', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'amyloid imaging', 'base', 'biomarker evaluation', 'clinical Diagnosis', 'computerized data processing', 'cost', 'heuristics', 'human subject', 'imaging biomarker', 'improved', 'molecular imaging', 'neuropathology', 'neurophysiology', 'novel', 'novel strategies', 'prevent', 'prototype', 'quantitative imaging', 'radiotracer', 'tau Proteins', 'uptake']",NIA,"SOLVINGDYNAMICS, INC.",R43,2018,149871,-0.04287296704682234
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9449456,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2018,64155,0.02220425523366067
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9595780,R01EB025468,"['Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2018,670762,0.0279000518841175
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9749865,R01EB025468,"['Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Organ', 'PDCD1LG1 gene', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'novel', 'oncology', 'parametric imaging', 'predicting response', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2018,141623,0.0279000518841175
"Fully-automated lesion characterization in ultrawide-field retinal images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-automated lesion characterization in ultrawide-field retinal images,9559582,R43EY028081,"['Agreement', 'Algorithms', 'Anti-HIV Agents', 'Applications Grants', 'Architecture', 'Area', 'Biological', 'Blindness', 'Cataract', 'Categories', 'Characteristics', 'Clinical', 'Cloud Computing', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Engineering', 'Ensure', 'Exposure to', 'Exudate', 'Eye', 'Eye diseases', 'Eyelash', 'Gold', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Lasers', 'Lesion', 'Light', 'Manuals', 'Measures', 'Microaneurysm', 'Modality', 'Morphologic artifacts', 'Normalcy', 'Ophthalmoscopy', 'Output', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Receiver Operating Characteristics', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Spottings', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Vision', 'Work', 'base', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fovea centralis', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'operation', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2018,216440,0.0032031076859183214
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9547416,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'heart imaging', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,597688,0.03226181940281394
"Automated coronary artery calcification scoring for cardiovascular risk screening ABSTRACT The World Health Organization lists cardiovascular disease as the most common cause of death worldwide at 31% of all deaths. Coronary artery calcium (CAC) scoring has become the most reliable predictor of future coronary artery disease (CAD) events in the asymptomatic population. CAC scores are currently only reported on ECG-gated CT examinations that are ordered when the primary indication is cardiac in nature. However, in 2007 there were 7.1 million non-cardiac thoracic CT scans ordered with lungs as the primary indication where CAC scores could have been reported. An additional 7-10 million CT lung screening scans are expected to be ordered per year as lung screening programs grow. Because lung cancer risk factors and CAD risk factors overlap significantly, most these patients could benefit greatly from having their CAC score reported as part of their non-cardiac CT examination. This could dramatically improve decision making, quality of care, and lower expenses due to future CAD interventions and cardiac specific CT scans. The goal of this project is to develop a fully automated software application that can report CAC scores on both gated and ungated thoracic CT scans with seamless integration into the Radiology workflow. A successful completion of this project will deliver a product capable of dramatically increasing the number of people that receive early intervention for CAD, thereby increasing quality of care and lowering costs. This Phase I application proposes first creating an algorithm capable of automatically calculating global CAC scores from both ECG-gated and ungated CT scans using CAC segmentations performed by an expert physician. If successful, the Phase II project will perform robust clinical validation adequate for an FDA 510(k) submission. NARRATIVE The goal of this project is to develop a fully automated software application that can report CAC scores on both gated and ungated thoracic CT scans with seamless integration into the Radiology workflow. A successful completion of this project will deliver a product capable of dramatically increasing the number of people that receive early intervention for CAD, thereby increasing quality of care and lowering costs.",Automated coronary artery calcification scoring for cardiovascular risk screening,9555974,R43HL139273,"['Agatston Score', 'Algorithms', 'Bone Density', 'Calcium', 'Cardiac', 'Cardiovascular Diseases', 'Categories', 'Cause of Death', 'Cessation of life', 'Chest', 'Chronic Obstructive Airway Disease', 'Clinical', 'Computer software', 'Coronary Arteriosclerosis', 'Coronary artery', 'Correlation Studies', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Intervention', 'Electrocardiogram', 'Event', 'Future', 'Goals', 'Human', 'Image', 'Interstitial Lung Diseases', 'Intervention', 'Label', 'Lesion', 'Literature', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Modeling', 'Multi-Ethnic Study of Atherosclerosis', 'Nature', 'Patients', 'Performance', 'Phase', 'Physicians', 'Population', 'Predictive Value', 'Preventive measure', 'Quality of Care', 'Radiology Specialty', 'Reporting', 'Risk Factors', 'Scanning', 'Techniques', 'Training', 'Validation', 'Vision', 'World Health Organization', 'X-Ray Computed Tomography', 'base', 'cardiovascular risk factor', 'clinical effect', 'clinically relevant', 'compliance behavior', 'coronary artery calcification', 'coronary artery calcium', 'coronary calcium scoring', 'cost', 'deep learning', 'imaging biomarker', 'improved', 'innovation', 'learning strategy', 'multitask', 'quantitative imaging', 'screening', 'screening program', 'smoking cessation', 'success']",NHLBI,"IMBIO, LLC",R43,2018,224403,-0.030325418051731126
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,0.014348848443787428
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9566167,K01DK110136,"['Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2018,154915,-0.04750062985058943
"Crowdsourcing-aided machine learning for colon cancer prevention ﻿    DESCRIPTION (provided by applicant): Computer-aided detection (CADe) has become a standard tool in diagnostic radiology. Because CADe systems are highly sensitive, they can help radiologists detect abnormalities in medical images. However, CADe systems also detect large numbers of false positives that distract radiologists and reduce their confidence in the CADe technology. Colon cancer is the second leading cause of cancer deaths for men and women in the United States, but it would be preventable by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) has been endorsed as a viable option for colorectal screening under the guidelines of the American Cancer Society, U.S. Multi-Society Task Force, and the American College of Radiology. However, the interpretation of CTC images requires skill and it is time-consuming. The first-reader CADe paradigm, where a radiologist interprets a CTC study by reviewing an image gallery of potential abnormalities detected by CADe at high sensitivity, has recently been shown to provide an accurate workflow for the detection of colorectal lesions. Although most of the false-positive (FP) CADe detections are easy to dismiss even for inexperienced human readers, for a radiologist a review of a large number of CADe detections is tedious, time-consuming, and expensive. If, however, we could use crowdsourcing to distribute the images of high-sensitivity CADe detections to knowledge workers (KWs) who have been trained to dismiss FP CADe detections, we could implement an advanced high-performance CTC interpretation system that yields both high detection sensitivity and specificity. Crowdsourcing with big data can also be used to improve the performance of machine learning that is largely the reason for the low specificity of current CADe systems. The incorporation of big data in the form of large and representative online training databases to improve the classification performance of machine learning can be implemented by identifying relevant new training cases by detecting disagreements between crowdsourcing-based interpretations and computer- estimated lesion likelihoods. The goal of this project is to develop a Crowdsourcing-Aided MachinE Learning (CAMEL) scheme that will integrate machine learning with crowdsourcing for the detection of colorectal lesions in CTC. Although we will use colon CADe as an example system, the proposed concept applies to other CADe applications as well. We hypothesize that the CAMEL scheme will achieve a classification accuracy that is higher than that of machine learning alone and equivalent to that of unaided expert radiologists, and that it can improve radiologists' performance in the detection of clinically significant lesion in CTC. To achieve the goal and to test the study hypothesis, we will explore the following specific aims: (1) Develop a decision support (DES) system which allows human participation; (2) Develop a CAMEL scheme for polyp detection with crowdsourcing; (3) Evaluate the clinical benefit of CAMEL. Successful development of CAMEL will demonstrate the clinical benefit of an engaging crowdsourcing platform for accurate colon cancer screening. PUBLIC HEALTH RELEVANCE: Successful development of Crowdsourcing-Aided MachinE Learning (CAMEL) will demonstrate the clinical benefit of a crowdsourcing platform for accurate colon cancer screening. Because computer-aided detection (CADe) systems excel at detecting lesions (high sensitivity), whereas humans excel at removing false-positive CADe detections (high specificity), a crowdsourcing-assisted machine learning scheme should outperform individual human readers and CADe systems. In long term, broad adoption and use of the CAMEL scheme will facilitate early and accurate diagnoses, and thus will reduce mortality from colon cancer that is the third leading cause of cancer deaths in the United States.",Crowdsourcing-aided machine learning for colon cancer prevention,9269542,UH2CA203730,"['Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Classification', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computers', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Early Diagnosis', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'High Performance Computing', 'Human', 'Image', 'Individual', 'Knowledge', 'Lesion', 'Machine Learning', 'Medical Imaging', 'Performance', 'Polyps', 'Reader', 'Retrieval', 'Scheme', 'Screening for cancer', 'Sensitivity and Specificity', 'Societies', 'Specificity', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'accurate diagnosis', 'base', 'cancer prevention', 'clinically significant', 'computer aided detection', 'crowdsourcing', 'digital imaging', 'improved', 'men', 'mortality', 'public health relevance', 'radiologist', 'screening', 'skills', 'tool', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,UH2,2017,341979,-0.01940078101736636
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9322408,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,30900,0.04475972274061687
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.02999571360265674
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9288493,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Learning', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'computer aided detection', 'cost', 'improved', 'innovation', 'minimally invasive', 'mortality', 'prevent', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,436007,0.0019452028517490177
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9315808,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Computing', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'image guided', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'public health relevance', 'quantitative imaging', 'response', 'task analysis', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2017,413289,0.04751249719771174
"New Approach to US Elasticity Imaging Project Summary To more fully exploit the basic science of mechanobiology as it pertains to breast cancer progression, the medical imaging field continues to search for fast, safe, and effective elasticity imaging methods. In this project we propose a fundamentally new approach to ultrasonic elasticity imaging in which the weak forces applied to patient tissues and the measured displacements that result are used to train a numerical model specifically for that patient. This constitutive model is developed using finite-element methods and neural networks assembled in a unique configuration called the AutoProgressive (AutoP) Method. AutoP “learns” complete stress and strain properties directly from sparse force and displacement measurements and without a mathematical model. Using quasi-static stimuli, AutoP exploits the fact that each force-displacement estimate contains information about mechanical properties at all locations in the contiguous tissue. From measurement information and conservation laws, AutoP generates an informational model without the need to make assumptions about tissue linearity, isotropy, or other material properties normally required when constructing images that display tissue mechanical properties. Once an accurate material-property model is formed by AutoP, we adopt a separate rheological model (e.g., Kelvin Voigt) to form viscoelastic parameters for image display. The AutoP method employs beamformed RF-echo acquisitions from which point displacements are estimated, applied compressional force sensed at the transducer surface, and tissue shape.  No other imaging method is capable of estimating all relevant stress fields, which gives AutoP unique capabilities. AutoP estimates the mechanical properties that one strives to obtain from an inverse problem approach, but AutoP is not a mathematical inverse technique and hence does not suffer from nonunique solutions. Without the need to assume material properties, AutoP can (in principle) model tissue properties in three dimensions and in time following large deformations in highly-nonlinear, anisotropic media. This R21 proposal focuses on establishing the feasibility of the AutoP methodology for subsequent clinical trials under future funding. At the completion of this two-year project, we will demonstrate a new tool for medical imaging capable of exploring the mechanical properties of tissues over a very broad range of deformations. We specifically target ultrasonic methods and quasi-static force stimuli in this project. However AutoP could eventually be coupled to other imaging modalities (e.g., MRE, OCE) or dynamic force-stimulus methods.  The scientific premise underlying AutoP is that we already record all of the information needed to generate a very broad range of elasticity images. The key to unlocking this information is to set aside mathematical models in favor of data-driven informational models built using the unique machine learning abilities of the AutoP method. If successful, AutoP will have a major influence on medical elasticity imaging methods. Project Narrative: A new type of machine-learning method is proposed for elasticity imaging of patient tissues that offers the potential to minimize many current limitations. If we are successful in this development, ultrasonic elasticity imaging would significantly improve in its ability to accurately represent mechanical properties of breast tissues, without any changes in current instrumentation and without increasing cost to the healthcare system or adding risk to patients.",New Approach to US Elasticity Imaging,9385425,R21EB023402,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Basic Science', 'Behavior', 'Biological Neural Networks', 'Breast', 'Clinical', 'Clinical Trials', 'Code', 'Coupled', 'Data', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Elasticity', 'Elements', 'Engineering', 'Environment', 'Feedback', 'Funding', 'Future', 'Goals', 'Healthcare Systems', 'Image', 'Inflammatory', 'Isotropy', 'Laws', 'Learning', 'Legal patent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammary Gland Parenchyma', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modulus', 'Patients', 'Procedures', 'Process', 'Property', 'Recording of previous events', 'Risk', 'Role', 'Scanning', 'Shapes', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Study Subject', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transducers', 'Ultrasonic Transducer', 'Ultrasonics', 'Writing', 'aged', 'base', 'breast imaging', 'cost', 'experience', 'healthy volunteer', 'human subject', 'imaging modality', 'imaging properties', 'improved', 'in vivo', 'information model', 'insight', 'instrumentation', 'learning strategy', 'malignant breast neoplasm', 'mathematical model', 'mechanical properties', 'model building', 'model development', 'novel strategies', 'object shape', 'processing speed', 'tool', 'tumor progression', 'viscoelasticity']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2017,220062,-0.014436657974882774
"Computerized Visualization and Prediction of Coronary Artery Ischemia ﻿    DESCRIPTION (provided by applicant):  Coronary artery disease (CAD) is the principal cause of morbidity and mortality. In the US, CAD affects >16 million adults and accounts for >1/3 deaths annually. Recently, computed tomography (CT) has emerged as a non-invasive option for imaging coronary arteries and myocardial perfusion. Nevertheless, diagnosis of ischemic CAD based on CT alone is less robust due to the lack of lesion-specific physiologic information. Computational fluid dynamics (CFD) has been applied to image-based modeling of patient-specific geometry from CT data, which now allows for non-invasive calculation of coronary pressure, flow and shear stress, and thus lesion-specific evaluation of coronary ischemia in higher diagnostic accuracy than the strategy based on CT alone. There is a pressing need to incorporate CT imaging, image-based modeling, and CFD into clinical practice for better diagnosis of coronary ischemia. However, progress has been thwarted by three major challenges: (1) lack of integrated tools to visualize immense data to assist diagnosis, (2) inabiliy to quantify and select salient anatomic and physiologic features for optimal prediction of ischemia, and (3) lack of comprehensive clinically relevant evaluation. In this proposal, we will develop and evaluate a novel computerized system to improve visual and predictive assessment of coronary ischemia from CT imaging and CFD. To accomplish this goal: (1) We will create tools to visualize coronary anatomy, physiology and myocardial perfusion for routine diagnosis assistance; The evaluation will be performed by comparing the diagnostic performance of two experienced cardiologists using our visualization tool and the conventional workstation using invasive ground truths; (2) We will develop methods to automatically quantify and select salient anatomic and physiologic features for maximizing predictive accuracy using machine learning. The evaluation will be assessed through cross-validation on a large existing database with respect to invasive ground truths. If successful, our developments will provide a new computerized system to assist the diagnosis of coronary ischemia by visualizing the totality of anatomic and physiologic findings over current unassisted approaches, and predict ischemia by machine learning methods that are superior to current heuristic techniques, and ultimately accelerate the translation of diagnostic performance gain into routine clinical practice. PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the principal cause of morbidity and mortality. Based on computed tomography and computational fluid dynamics, our proposed work will create and evaluate a new computerized system to improve the diagnosis of ischemic CAD by developing advanced visualization and prediction tools.",Computerized Visualization and Prediction of Coronary Artery Ischemia,9264013,R21HL132277,"['Accounting', 'Adult', 'Affect', 'Anatomy', 'Arterial Fatty Streak', 'Arteries', 'Biomechanics', 'Biomedical Engineering', 'Blood flow', 'Cardiology', 'Cardiovascular Diagnostic Techniques', 'Cardiovascular system', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Computer-Assisted Diagnosis', 'Computing Methodologies', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Artery Ischemia', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Databases', 'Decision Making', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Evaluation', 'Foundations', 'Functional Imaging', 'Future', 'Geometry', 'Goals', 'Hospitalization', 'Image', 'Imagery', 'Imaging Techniques', 'Individual', 'Ischemia', 'Lesion', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Motion', 'Multicenter Trials', 'Myocardial perfusion', 'Patients', 'Performance', 'Physiological', 'Physiology', 'Radionuclide Imaging', 'Reproducibility', 'Rest', 'Severities', 'Stenosis', 'Stress', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Translations', 'Validation', 'Visual', 'Visualization software', 'Work', 'X-Ray Computed Tomography', 'base', 'burden of illness', 'cardiovascular imaging', 'cardiovascular visualization', 'clinical practice', 'clinically relevant', 'computer science', 'computerized', 'design', 'diagnostic accuracy', 'experience', 'heuristics', 'imaging Segmentation', 'imaging modality', 'improved', 'learning strategy', 'mortality', 'novel', 'nuclear imaging', 'pressure', 'prognostic value', 'prospective', 'public health relevance', 'shear stress', 'simulation', 'success', 'targeted treatment', 'tool']",NHLBI,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2017,211875,0.044366328242329826
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,0.021815881968356928
"Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET ﻿    DESCRIPTION (provided by applicant): Ischemic cardiomyopathy affects approximately 3 million people in the United States. This form of heart failure is the result of myocardial infarcton or severe coronary heart disease that reduces the viability and function of the heart. Ischemic cardiomyopathy is associated with poor long-term survival when patients with viable myocardium are not revascularized. By imaging myocardial blood flow and glucose metabolism and seeking flow-metabolism mismatches, positron emission tomography (PET) method has been established as the gold standard of assessing myocardial viability for selecting patients who can benefit most from surgical revascularization. Current PET method employs two separate static scans with two different radiotracers for generation of the flow-metabolism image pair. While the image of glucose metabolism is acquired using the most widely used radiotracer 18F- fluorodeoxyglucose (FDG), myocardial blood flow imaging with the radiotracer 13N-ammonia or rubidium-82 suffers from limited clinical availability. In addition, the imaging protoco of two separate imaging sessions is time consuming and resource intensive. As a result, myocardial viability via PET is currently under-utilized in clinic despite its high accuracy and th fast-growing installation of PET/CT scanners in the past decade. In this project, we propose to develop a novel PET method for myocardial viability assessment that only uses a single injection of FDG without the need of a flow- specific radiotracer. We hypothesize that myocardial blood flow can be derived from the quantitative kinetic parameters of dynamic FDG PET. We will develop a new multi-variable prediction model using statistical machine learning to predict myocardial blood flow from dynamic FDG PET data. We will also develop a shortened dynamic FDG PET protocol to improve practicality. This innovation will provide the flow-metabolism image pair for myocardial viability assessment in a clinically favorable time, cost and with reduced radiation dose. Success of this research will make PET assessment of myocardial viability more widely available in clinic with easier access, lower radiation dose, cheaper imaging cost and shorter clinical visit time as compared with conventional two-session protocols, thus improving our clinical practice of treating ischemic cardiomyopathy. PUBLIC HEALTH RELEVANCE: Positron emission tomography (PET) is a gold standard method for detecting viable myocardium to select which patients with ischemic cardiomyopathy to benefit most from surgical revascularization. Its use in clinic, however, is under-utilized because of the limited clinical availability of the radiotracers needed. This research aims to develop a novel PET imaging method for assessment of myocardial viability that can be easily accessed in clinic with reduced lower radiation dose and imaging cost without compromising imaging performance.",Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET,9251317,R21HL131385,"['Address', 'Affect', 'Algorithms', 'Ammonia', 'Blood', 'Blood Glucose', 'Blood flow', 'Cardiac', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Trials', 'Coronary heart disease', 'Cyclotrons', 'Data', 'Dependence', 'Dose', 'Echocardiography', 'Evaluation', 'Generations', 'Goals', 'Gold', 'Heart failure', 'Hour', 'Image', 'Injection of therapeutic agent', 'Investments', 'Kinetics', 'Low Dose Radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial tissue', 'Myocardium', 'Noise', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Recruitment Activity', 'Research', 'Resolution', 'Resources', 'Rubidium', 'Scanning', 'Site', 'Testing', 'Time', 'Time Study', 'Tracer', 'United States', 'Visit', 'clinical practice', 'cost', 'experience', 'fluorodeoxyglucose', 'fluorodeoxyglucose positron emission tomography', 'glucose metabolism', 'glucose transport', 'heart function', 'image reconstruction', 'imaging modality', 'implantable device', 'improved', 'innovation', 'ischemic cardiomyopathy', 'mortality', 'novel', 'perfusion imaging', 'public health relevance', 'radiotracer', 'single photon emission computed tomography', 'success', 'uptake']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2017,195625,0.01003471696347674
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9197624,R01CA193730,"['Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2017,359444,-0.02811879369772713
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9315773,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Darkness', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2017,619539,0.04759382526157225
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,0.033519053927806707
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle. PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9355100,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Intuition', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Morphology', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscle function', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2017,391844,0.04058458004270967
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9268035,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2017,770494,-0.0011612519034232525
"Area B:  Multi-Tracer Volumetric PET (MTV-PET) to Measure Tumor Glutamine and Glucose Metabolic Rates in a Single Imaging Session Precision oncology places an increased demand on cancer diagnostics to characterize tumors at the time of diagnosis. Tissue diagnostics for precision oncology increasingly rely on multi-valent assays to characterize cancer biology and identify therapeutic targets. The power of molecular imaging for cancer diagnosis has been well demonstrated by [18F]fluorodexoyglucose positron emission tomography (FDG PET/CT), widely used in clinical oncology. PET tracers targeted to facets of tumor biology now enable multi-valent molecular imaging to identify therapeutic targets. Early studies show that combined tracer studies, commonly FDG plus a target- specific tracer, are highly predictive of tumor response to targeted therapy. However, emissions from different PET tracers are indistinguishable to a PET scanner, requiring separate imaging sessions on separate days for multiple 18F-based tracers (~ 2 hour half-life) in the same patient. This limits the clinical practicality of multi-tracer PET, and fails to exploit the full power of multi-tracer PET to quantify tumor in vivo biology and biologic heterogeneity for highly variable process such as cancer metabolism. We will overcome this limitation by taking advantage of recent developments in volumetric PET scanners, fast reconstruction, and 4D image analysis methods from our laboratories to develop Multi-Tracer Volumetric PET (MTV-PET) to generate multi-valent, quantitative biologic parametric images for two or more tracers in a single session to guide precision oncology and translational cancer biology research. As such, our proposed technology development project addresses a need, described under Priority Area B for “new capabilities for advancing precise clinical diagnosis of cancer patients”. Using methods developed in our laboratories, we now propose to integrate and enhance these methodologies to develop and validate Multi-Tracer Volumetric PET (MTV-PET) to generate quantitative biologic parametric images for two or more tracers in a single session. We will develop and test this approach for simultaneous glucose and glutamine metabolism imaging, with the goal of guiding metabolism-targeted therapy such as inhibitors of glutaminase (GLS) and lactate dehydrogenase (LDH). The project will focus on the technology developments (largely computational) that enable multi-tracer imaging. Ongoing and separately funded work on clinical studies will acquire data from two separate imaging PET sessions using current technology and will provide data for method development. We will first optimize tracer dose timing, image reconstruction, and image time binning for dual tracer MTV-PET (Aim 1), followed by implementation and technical validation of image analysis using a mixture analysis approach (Aim 2). This will set the stage for technical validation of MTV-PET (Aim 3) and an exploratory aim (Aim 4) testing image analytics based on machine learning. Successful completion of our technology development will yield a new method for multi-tracer PET that would change the landscape for cancer imaging diagnostic biomarker and precision oncology research, consistent with goals of RFA-CA-17-023 Priority Area B. PROJECT NARRATIVE Our proposed technology development in response to RFA-CA-17-023 (Integration and Validation of Emerging Technologies to Accelerate Cancer Research) addresses a need for more precise diagnosis for precision oncology, under Priority Area B: “New capabilities for advancing precise clinical diagnosis of cancer patients”. We will advantage of recent developments in volumetric positron emission tomography (PET) scanners, fast reconstruction, and 4D image analysis to develop methods for multi-tracer PET with the goal of generating quantitative, multi-parametric whole-body images of specific aspects of cancer biology, including cancer metabolism as the focus of our proposed technology development projects. Successful completion of our proposed technology development will yield a clinically practical method for multi-tracer PET that would provide multi-valent, whole body molecular parametric images that would change the landscape for cancer imaging diagnostic biomarkers and precision oncology research, targeted to RFA-CA-17-023 Priority Area B.",Area B:  Multi-Tracer Volumetric PET (MTV-PET) to Measure Tumor Glutamine and Glucose Metabolic Rates in a Single Imaging Session,9483034,R33CA225310,"['4D Imaging', 'Address', 'Agreement', 'Algorithms', 'Area', 'Biological Assay', 'Biology', 'Breast Cancer Patient', 'Cancer Biology', 'Cancer Diagnostics', 'Cancer Patient', 'Clinical', 'Clinical Data', 'Clinical Oncology', 'Clinical Research', 'Cluster Analysis', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Emerging Technologies', 'Funding', 'Glucose', 'Glutaminase', 'Glutamine', 'Glycolysis', 'Goals', 'Half-Life', 'Heterogeneity', 'Hour', 'Human', 'Image', 'Image Analysis', 'Injection of therapeutic agent', 'Kinetics', 'Laboratories', 'Lactate Dehydrogenase', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Outcome', 'Patients', 'Phenotype', 'Positron-Emission Tomography', 'Process', 'Radiation exposure', 'Reference Standards', 'Research', 'Technology', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Tracer', 'Tumor Biology', 'Validation', 'Work', 'analytical method', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'clinical Diagnosis', 'cohort', 'diagnostic biomarker', 'genomic biomarker', 'glucose metabolism', 'high dimensionality', 'image reconstruction', 'imaging biomarker', 'in vivo', 'inhibitor/antagonist', 'malignant breast neoplasm', 'metabolic rate', 'method development', 'molecular imaging', 'novel', 'parametric imaging', 'personalized diagnostics', 'phenotypic biomarker', 'precision oncology', 'radiotracer', 'reconstruction', 'response', 'targeted treatment', 'technology development', 'therapeutic target', 'tumor', 'tumor heterogeneity', 'tumor metabolism', 'whole body imaging']",NCI,UNIVERSITY OF PENNSYLVANIA,R33,2017,1448329,-0.005472299046032253
"Toward Diagnostics and Therapies of Molecular Subcategories of CAD ﻿    DESCRIPTION (provided by applicant): Coronary artery disease (CAD) is a leading cause of death worldwide and in the US. While the genetics of this disease are intrinsically complex, thanks to huge research investments during the last 5-10 years, particularly in genome-wide association studies (GWAS), a more unbiased, data-driven and realistic view of CAD has been achieved. As part of this achievement, ~160 common risk loci for CAD/myocardial infarction (MI) have been identified. An important task is now to understand the molecular mechanisms/pathways by which these loci exert risk for CAD/MI allowing to translating the initial findings into new therapies and diagnostics. However, since the loci identified thus far explain only ~10% of variation in CAD/MI risk, it is also essential to define additional CAD pathways operating in parallel with GWA loci. In recent years, clinical studies that consider intermediate phenotypes (between DNA and disease) have greatly enhanced interpretations of risk loci identified in GWA datasets. In addition, disease networks that can be identified from intermediate molecular phenotypes provide an essential framework to identify novel CAD pathways and targets for new CAD therapies. Over the last 6 years, we have performed a clinical study considering many intermediate phenotypes in CAD patients (the STARNET study). In this proposal we intend to use newly generated DNA genotype and RNA sequence data from the STARNET study to identify atherosclerosis and metabolic networks underlying CAD. We then propose a new prospective study of CAD (the NGS-PREDICT study) with the main purpose of validating findings from the STARNET study. We hypothesize that the extent and stability of coronary lesions, thus clinical outcomes can be accurately assessed by defining the status of key atherosclerosis gene networks. In turn, metabolic networks active in liver, abdominal fat, and skeletal muscle influence the status of the atherosclerosis gene networks. In addition, molecular data isolated from easily obtainable tissues (e.g., blood, subcutaneous fat and plasma) can be used to identify biomarkers that can predict risk for clinical events caused by CAD. To test these hypotheses, we propose the following specific aims. Aim 1: To identify regulatory Bayesian gene networks causally linked to CAD and/or CAD sub-phenotypes using the STARNET datasets and the CARDIoGRAM meta-analysis GWA datasets. Aim 2: Identify biomarkers predicting clinical events of CAD (reflected in SYNTAX score) by applying machine learning on DNA genotype, RNA sequence and CAD plasma protein data from easily obtainable tissues of the STARNET cases. Aim 3: To validate the identified causal CAD eQTLs/networks and the biomarkers using the NGS-PREDICT study performed at the Mt. Sinai Hospital, the Swedish Twin study and CAD cell and animal models. We believe the proposed studies can lead to a significantly better molecular understanding of CAD and thus, serve the more long-term goal of preventive and personalized therapies of CAD patients diagnosed in well-defined molecular subcategories. PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the world's leading cause of death. We will perform systems genetic analysis of DNA and RNAseq data from 9 CAD-relevant tissues in 700 well-characterized patients (STARNET) integrated with genome-wide association data to reveal CAD-causing metabolic and atherosclerosis gene networks, and within these, new inherited risk variants, CAD-mechanisms, therapeutic targets and biomarkers will be identified and validated in a new prospective clinical study of CAD (NGS-PREDICT). Our studies promise to significantly advance understanding of CAD towards achieving preventive and personalized care.",Toward Diagnostics and Therapies of Molecular Subcategories of CAD,9278295,R01HL125863,"['Abdomen', 'Achievement', 'Address', 'Alleles', 'Angiography', 'Animal Model', 'Area', 'Atherosclerosis', 'Benchmarking', 'Biochemical Pathway', 'Biological Markers', 'Biological Models', 'Biology', 'Biopsy', 'Blood', 'Blood Vessels', 'Cardiology', 'Cardiovascular system', 'Cause of Death', 'Cell Differentiation process', 'Cell model', 'Chest', 'Clinical', 'Clinical Research', 'Complex', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'DNA', 'DNA analysis', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Pathway', 'Engineering', 'Event', 'Family', 'Fatty acid glycerol esters', 'Foam Cells', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Models', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Heritability', 'Hospitals', 'In Vitro', 'Individual', 'Inherited', 'Institutes', 'Investments', 'Lead', 'Lesion', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Meta-Analysis', 'Metabolic', 'Modeling', 'Molecular', 'Myocardial Infarction', 'New York', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Plasma Proteins', 'Preventive', 'Preventive care', 'Preventive therapy', 'Prospective Studies', 'Quantitative Trait Loci', 'RNA', 'RNA Sequences', 'Recruitment Activity', 'Regulator Genes', 'Research', 'Research Proposals', 'Risk', 'Sampling', 'Single Nucleotide Polymorphism', 'Skeletal Muscle', 'Subcategory', 'System', 'Techniques', 'Testing', 'Tissues', 'Translating', 'Twin Multiple Birth', 'Twin Studies', 'Variant', 'Whole Blood', 'abdominal fat', 'biological systems', 'clinical predictors', 'clinical risk', 'computer based statistical methods', 'disorder risk', 'follow-up', 'genetic analysis', 'genome wide association study', 'in vivo Model', 'macrophage', 'medical schools', 'molecular phenotype', 'monocyte', 'multidisciplinary', 'novel', 'novel diagnostics', 'novel therapeutics', 'percutaneous coronary intervention', 'personalized care', 'personalized diagnostics', 'personalized medicine', 'predictive marker', 'prospective', 'protein biomarkers', 'public health relevance', 'risk variant', 'subcutaneous', 'therapeutic biomarker', 'therapeutic target', 'trait', 'transcriptome sequencing']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2017,802881,0.027448810508243257
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9360750,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,372360,-0.00263349913418846
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,0.06405792476765242
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9300962,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'success', 'tool', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2017,169609,0.0034700432868635884
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,9194390,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Internet', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'analytical method', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'public health relevance', 'sample fixation', 'screening', 'tool', 'transmission process', 'virtual']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,611703,0.033130482467253745
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9212187,R01HL121226,"['Acute', 'Anatomy', 'Autopsy', 'Bayesian Modeling', 'Biomechanics', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Heart Ventricle', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Pharmacology', 'Phase', 'Physiology', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'perfusion imaging', 'public health relevance', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2017,768639,0.013285799050126513
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9297792,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Ingestion', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2017,256500,0.012289507613652615
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9244841,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2017,63883,0.02220425523366067
"Deep-radiomics-learning for mass detection in CT colonography Project Summary/Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States. However, it would be prevented by early detection and removal of its precursor lesions. The use of CT colonography (CTC) would substantially increase the access, capacity, safety, cost-effectiveness, and patient compliance of colorectal examinations. The interpretation of CTC examinations would be most effective by use of a first-reader computer- aided detection (FR-CADe) paradigm, where a radiologist reviews only the lesion candidates detected automatically by a computer-aided detection (CADe) system. However, because CADe systems can miss large masses, radiologists still need to perform an additional two-dimensional (2D) review of the CT images of the colon, which increases reading time over 40% on average. Furthermore, also radiologists can occasionally miss some types of masses on CTC images. The goal of this project is to develop a DEep RAdiomics LEarning (DERALE) scheme for the detection of large masses on CTC images. The scheme will be used to integrate deep learning methods and radiomic biomarkers to perform a complete automated review of CTC images for reliable detection of colorectal masses. We hypothesize that the DERALE scheme will be able to detect colorectal masses at a sensitivity comparable to that of unaided expert radiologists and that it can be used to reduce the interpretation time of FR- CADe without degrading diagnostic accuracy in CTC. We will evaluate and compare the classification performance of DERALE with that of unaided expert radiologists and conduct an observer performance study to compare the detection accuracy of the use of DERALE in the FR-CADe paradigm with that of unaided expert radiologists in the detection of masses from CTC images. Successful development and broad adoption of DERALE in the FR-CADe paradigm will facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce the mortality rate from colon cancer, one of the largest threats of cancer deaths in the United States. Project Narrative Successful development and validation of DERALE will substantially advance the clinical implementation of CTC and the FR-CADe paradigm in large populations to facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce mortality from colon cancer, the second leading cause of cancer deaths in both men and women in the United States. The research is innovative in that robust mass detection has not been developed for CTC and FR- CADe, and that there have been no attempts to use deep learning for mass detection in CTC.",Deep-radiomics-learning for mass detection in CT colonography,9316607,R21EB022747,"['Abdomen', 'Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Anatomy', 'Biological Markers', 'Biological Neural Networks', 'Cancer Etiology', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Collection', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Excision', 'Fatigue', 'Goals', 'Guidelines', 'Image', 'Image Analysis', 'Learning', 'Lesion', 'Location', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Methods', 'Performance', 'Phenotype', 'Polyps', 'Population', 'Prevention', 'Reader', 'Reading', 'Reporting', 'Research', 'Safety', 'Scheme', 'Societies', 'System', 'Testing', 'Time', 'United States', 'Validation', 'Woman', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'compliance behavior', 'computer aided detection', 'cost effective', 'cost effectiveness', 'design', 'diagnostic accuracy', 'innovation', 'learning strategy', 'men', 'mortality', 'novel', 'prevent', 'radiologist', 'radiomics', 'screening', 'two-dimensional']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2017,213750,0.0011411248942922317
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9350173,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2017,597688,0.03226181940281394
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,0.014348848443787428
"Crowdsourcing-aided machine learning for colon cancer prevention DESCRIPTION (provided by applicant): Computer-aided detection (CADe) has become a standard tool in diagnostic radiology. Because CADe systems are highly sensitive, they can help radiologists detect abnormalities in medical images. However, CADe systems also detect large numbers of false positives that distract radiologists and reduce their confidence in the CADe technology. Colon cancer is the second leading cause of cancer deaths for men and women in the United States, but it would be preventable by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) has been endorsed as a viable option for colorectal screening under the guidelines of the American Cancer Society, U.S. Multi-Society Task Force, and the American College of Radiology. However, the interpretation of CTC images requires skill and it is time-consuming. The first-reader CADe paradigm, where a radiologist interprets a CTC study by reviewing an image gallery of potential abnormalities detected by CADe at high sensitivity, has recently been shown to provide an accurate workflow for the detection of colorectal lesions. Although most of the false-positive (FP) CADe detections are easy to dismiss even for inexperienced human readers, for a radiologist a review of a large number of CADe detections is tedious, time-consuming, and expensive. If, however, we could use crowdsourcing to distribute the images of high-sensitivity CADe detections to knowledge workers (KWs) who have been trained to dismiss FP CADe detections, we could implement an advanced high-performance CTC interpretation system that yields both high detection sensitivity and specificity. Crowdsourcing with big data can also be used to improve the performance of machine learning that is largely the reason for the low specificity of current CADe systems. The incorporation of big data in the form of large and representative online training databases to improve the classification performance of machine learning can be implemented by identifying relevant new training cases by detecting disagreements between crowdsourcing-based interpretations and computer- estimated lesion likelihoods. The goal of this project is to develop a Crowdsourcing-Aided MachinE Learning (CAMEL) scheme that will integrate machine learning with crowdsourcing for the detection of colorectal lesions in CTC. Although we will use colon CADe as an example system, the proposed concept applies to other CADe applications as well. We hypothesize that the CAMEL scheme will achieve a classification accuracy that is higher than that of machine learning alone and equivalent to that of unaided expert radiologists, and that it can improve radiologists' performance in the detection of clinically significant lesion in CTC. To achieve the goal and to test the study hypothesis, we will explore the following specific aims: (1) Develop a decision support (DES) system which allows human participation; (2) Develop a CAMEL scheme for polyp detection with crowdsourcing; (3) Evaluate the clinical benefit of CAMEL. Successful development of CAMEL will demonstrate the clinical benefit of an engaging crowdsourcing platform for accurate colon cancer screening. PUBLIC HEALTH RELEVANCE: Successful development of Crowdsourcing-Aided MachinE Learning (CAMEL) will demonstrate the clinical benefit of a crowdsourcing platform for accurate colon cancer screening. Because computer-aided detection (CADe) systems excel at detecting lesions (high sensitivity), whereas humans excel at removing false-positive CADe detections (high specificity), a crowdsourcing-assisted machine learning scheme should outperform individual human readers and CADe systems. In long term, broad adoption and use of the CAMEL scheme will facilitate early and accurate diagnoses, and thus will reduce mortality from colon cancer that is the third leading cause of cancer deaths in the United States.",Crowdsourcing-aided machine learning for colon cancer prevention,9077924,UH2CA203730,"['Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Classification', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computers', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Early Diagnosis', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'Health', 'High Performance Computing', 'Human', 'Image', 'Individual', 'Knowledge', 'Lesion', 'Machine Learning', 'Medical Imaging', 'Performance', 'Polyps', 'Reader', 'Retrieval', 'Scheme', 'Sensitivity and Specificity', 'Societies', 'Specificity', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'accurate diagnosis', 'base', 'cancer prevention', 'clinically significant', 'computer aided detection', 'crowdsourcing', 'improved', 'men', 'mortality', 'radiologist', 'screening', 'skills', 'tool', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,UH2,2016,341897,-0.01940078101736636
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9174605,R01CA200690,"['Adult', 'Algorithms', 'Architecture', 'Area', 'Association Learning', 'Behavior', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Event', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Property', 'Reference Standards', 'Research', 'Scanning', 'Skin', 'Slide', 'Specimen', 'Staging', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'visual tracking']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,408063,0.04475972274061687
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,0.0031679554126498592
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,0.041866879185446175
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,0.041866879185446175
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals. PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9137657,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Health', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'microscopic imaging', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2016,246750,-0.0025643641879558175
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9110984,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2016,412881,0.04751249719771174
"Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling ﻿    DESCRIPTION (provided by applicant): The quest for fast image acquisition speed has always been a perennial topic in the MRI community. To reduce the acquisition time for maximal spatial and temporal resolution, modern MRI protocols usually perform reduced acquisitions below the Nyquist rate. The reduced data is then used to reconstruct the image through advanced reconstruction techniques that leverage some prior information about the MRI system (e.g., parallel imaging) and/or MR signal (e.g., compressed sensing). Since such prior information is patient and system specific, recent techniques obtain the prior information using training data obtained through an empirical calibration procedure. All existing methods assume the prior models are linear. Since the intrinsic nonlinear relationship in the training data cannot be characterized in such simple models, the reconstruction is degraded by the inaccuracy of the prior information. Nonlinear learning from the training data have proven to be more powerful in machine learning because it is more general and includes the linear model as a special case. However, it is usually more challenging to learn the nonlinear models and even more challenging to incorporate the model in reconstruction due to the increased degree of freedom. We recently have introduced a novel concept of ""kernel"" in MR reconstruction to address the above challenges timely. Our preliminary results on parallel imaging and sparsity-constrained reconstruction demonstrate that the kernel-based algorithms improve the reconstruction quality over the original algorithms with linear prior models. Built upon our strong preliminary results, the objective of this application is to develop an innovative kernel-based framework for MR image reconstruction from undersampled data. This framework does not require explicit knowledge of nonlinear mapping (as in preliminary work) such that a broader family of nonlinear functions can be explored for different clinical applications. The proposed work is expected to advance the field of MR image reconstruction vertically. Specifically, the successful completion of the proposed project will result in a general framework leading to many new algorithms (including two developed in this project) for reconstruction from reduced acquisition. Therefore, virtually all of current clinical MRI could benefit from the improved resolution, image quality, and/or reduced acquisition times that the new framework will facilitate or the novel applications i may enable. PUBLIC HEALTH RELEVANCE: The proposed research is to develop a general framework and two specific new techniques to improve the spatial resolution and/or reduce the scan time in magnetic resonance imaging and evaluate the performance of the techniques for 3D parallel imaging and quantitative imaging in brain. The development of such novel fast imaging techniques may greatly enhance diagnosis of neurological disease. Therefore the project will potentially benefit numerous subjects and the healthcare system.",Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling,9119020,R21EB020861,"['Address', 'Algorithms', 'Brain', 'Calibration', 'Clinical', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Family', 'Freedom', 'Health', 'Healthcare Systems', 'Image', 'Imaging Techniques', 'Industry', 'Knowledge', 'Learning', 'Letters', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Non-linear Models', 'Patients', 'Performance', 'Phase', 'Physics', 'Polynomial Models', 'Principal Component Analysis', 'Procedures', 'Protocols documentation', 'Qualifying', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Signal Transduction', 'Software Tools', 'Speed', 'System', 'Techniques', 'Time', 'Training', 'Weight', 'Work', 'base', 'clinical application', 'image reconstruction', 'improved', 'innovation', 'nervous system disorder', 'neuroimaging', 'novel', 'quantitative imaging', 'reconstruction', 'temporal measurement']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R21,2016,222652,0.023104084222525356
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,0.021815881968356928
"Computerized Visualization and Prediction of Coronary Artery Ischemia ﻿    DESCRIPTION (provided by applicant):  Coronary artery disease (CAD) is the principal cause of morbidity and mortality. In the US, CAD affects >16 million adults and accounts for >1/3 deaths annually. Recently, computed tomography (CT) has emerged as a non-invasive option for imaging coronary arteries and myocardial perfusion. Nevertheless, diagnosis of ischemic CAD based on CT alone is less robust due to the lack of lesion-specific physiologic information. Computational fluid dynamics (CFD) has been applied to image-based modeling of patient-specific geometry from CT data, which now allows for non-invasive calculation of coronary pressure, flow and shear stress, and thus lesion-specific evaluation of coronary ischemia in higher diagnostic accuracy than the strategy based on CT alone. There is a pressing need to incorporate CT imaging, image-based modeling, and CFD into clinical practice for better diagnosis of coronary ischemia. However, progress has been thwarted by three major challenges: (1) lack of integrated tools to visualize immense data to assist diagnosis, (2) inabiliy to quantify and select salient anatomic and physiologic features for optimal prediction of ischemia, and (3) lack of comprehensive clinically relevant evaluation. In this proposal, we will develop and evaluate a novel computerized system to improve visual and predictive assessment of coronary ischemia from CT imaging and CFD. To accomplish this goal: (1) We will create tools to visualize coronary anatomy, physiology and myocardial perfusion for routine diagnosis assistance; The evaluation will be performed by comparing the diagnostic performance of two experienced cardiologists using our visualization tool and the conventional workstation using invasive ground truths; (2) We will develop methods to automatically quantify and select salient anatomic and physiologic features for maximizing predictive accuracy using machine learning. The evaluation will be assessed through cross-validation on a large existing database with respect to invasive ground truths. If successful, our developments will provide a new computerized system to assist the diagnosis of coronary ischemia by visualizing the totality of anatomic and physiologic findings over current unassisted approaches, and predict ischemia by machine learning methods that are superior to current heuristic techniques, and ultimately accelerate the translation of diagnostic performance gain into routine clinical practice.         PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the principal cause of morbidity and mortality. Based on computed tomography and computational fluid dynamics, our proposed work will create and evaluate a new computerized system to improve the diagnosis of ischemic CAD by developing advanced visualization and prediction tools.        ",Computerized Visualization and Prediction of Coronary Artery Ischemia,9093071,R21HL132277,"['Accounting', 'Adult', 'Affect', 'Anatomy', 'Arterial Fatty Streak', 'Arteries', 'Biomechanics', 'Biomedical Engineering', 'Blood flow', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Computer Simulation', 'Computer-Assisted Diagnosis', 'Computing Methodologies', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Artery Ischemia', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Databases', 'Decision Making', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Echocardiography', 'Evaluation', 'Foundations', 'Functional Imaging', 'Future', 'Geometry', 'Goals', 'Hospitalization', 'Image', 'Imagery', 'Imaging Techniques', 'Individual', 'Ischemia', 'Lesion', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Multicenter Trials', 'Myocardial perfusion', 'Nuclear', 'Patients', 'Performance', 'Physiological', 'Physiology', 'Radionuclide Imaging', 'Reproducibility', 'Rest', 'Severities', 'Stenosis', 'Stress', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Translations', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'burden of illness', 'cardiovascular imaging', 'cardiovascular visualization', 'clinical practice', 'clinically relevant', 'computer science', 'computerized', 'design', 'diagnostic accuracy', 'experience', 'heuristics', 'imaging modality', 'improved', 'learning strategy', 'mortality', 'novel', 'pressure', 'prognostic value', 'prospective', 'public health relevance', 'shear stress', 'simulation', 'success', 'targeted treatment', 'tool']",NHLBI,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2016,254250,0.044366328242329826
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment.         PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.            ",MRI-Based Radiation Therapy Treatment Planning,9026075,R01CA193730,"['Adopted', 'Adoption', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modality', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'public health relevance', 'quality assurance', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2016,362066,-0.02811879369772713
"Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET ﻿    DESCRIPTION (provided by applicant): Ischemic cardiomyopathy affects approximately 3 million people in the United States. This form of heart failure is the result of myocardial infarcton or severe coronary heart disease that reduces the viability and function of the heart. Ischemic cardiomyopathy is associated with poor long-term survival when patients with viable myocardium are not revascularized. By imaging myocardial blood flow and glucose metabolism and seeking flow-metabolism mismatches, positron emission tomography (PET) method has been established as the gold standard of assessing myocardial viability for selecting patients who can benefit most from surgical revascularization. Current PET method employs two separate static scans with two different radiotracers for generation of the flow-metabolism image pair. While the image of glucose metabolism is acquired using the most widely used radiotracer 18F- fluorodeoxyglucose (FDG), myocardial blood flow imaging with the radiotracer 13N-ammonia or rubidium-82 suffers from limited clinical availability. In addition, the imaging protoco of two separate imaging sessions is time consuming and resource intensive. As a result, myocardial viability via PET is currently under-utilized in clinic despite its high accuracy and th fast-growing installation of PET/CT scanners in the past decade. In this project, we propose to develop a novel PET method for myocardial viability assessment that only uses a single injection of FDG without the need of a flow- specific radiotracer. We hypothesize that myocardial blood flow can be derived from the quantitative kinetic parameters of dynamic FDG PET. We will develop a new multi-variable prediction model using statistical machine learning to predict myocardial blood flow from dynamic FDG PET data. We will also develop a shortened dynamic FDG PET protocol to improve practicality. This innovation will provide the flow-metabolism image pair for myocardial viability assessment in a clinically favorable time, cost and with reduced radiation dose. Success of this research will make PET assessment of myocardial viability more widely available in clinic with easier access, lower radiation dose, cheaper imaging cost and shorter clinical visit time as compared with conventional two-session protocols, thus improving our clinical practice of treating ischemic cardiomyopathy.         PUBLIC HEALTH RELEVANCE: Positron emission tomography (PET) is a gold standard method for detecting viable myocardium to select which patients with ischemic cardiomyopathy to benefit most from surgical revascularization. Its use in clinic, however, is under-utilized because of the limited clinical availability of the radiotracers needed. This research aims to develop a novel PET imaging method for assessment of myocardial viability that can be easily accessed in clinic with reduced lower radiation dose and imaging cost without compromising imaging performance.              ",Simultaneous imaging of myocardial blood flow and glucose metabolism using dynamic 18F-FDG PET,9020059,R21HL131385,"['Address', 'Affect', 'Algorithms', 'Ammonia', 'Blood', 'Blood Glucose', 'Blood flow', 'Cardiac', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Trials', 'Coronary heart disease', 'Cyclotrons', 'Data', 'Dependence', 'Dose', 'Echocardiography', 'Evaluation', 'Generations', 'Goals', 'Gold', 'Heart failure', 'Hour', 'Image', 'Injection of therapeutic agent', 'Investments', 'Kinetics', 'Low Dose Radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial tissue', 'Myocardium', 'Noise', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Perfusion', 'Physicians', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation', 'Recruitment Activity', 'Research', 'Resolution', 'Resources', 'Rubidium', 'Scanning', 'Site', 'Testing', 'Time', 'Tracer', 'United States', 'Visit', 'clinical practice', 'cost', 'experience', 'fluorodeoxyglucose', 'fluorodeoxyglucose positron emission tomography', 'glucose metabolism', 'glucose transport', 'heart function', 'image reconstruction', 'imaging modality', 'implantable device', 'improved', 'innovation', 'ischemic cardiomyopathy', 'mortality', 'novel', 'public health relevance', 'radiotracer', 'single photon emission computed tomography', 'success', 'uptake']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2016,234875,0.01003471696347674
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9108343,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Health', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2016,618809,0.04759382526157225
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle.           PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.              ",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9047634,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Genetic', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'quantitative imaging', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2016,609726,0.04058458004270967
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9061011,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'individual patient', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2016,770494,-0.0011612519034232525
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,0.06411900655460541
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,0.06405792476765242
"Toward Diagnostics and Therapies of Molecular Subcategories of CAD ﻿    DESCRIPTION (provided by applicant): Coronary artery disease (CAD) is a leading cause of death worldwide and in the US. While the genetics of this disease are intrinsically complex, thanks to huge research investments during the last 5-10 years, particularly in genome-wide association studies (GWAS), a more unbiased, data-driven and realistic view of CAD has been achieved. As part of this achievement, ~160 common risk loci for CAD/myocardial infarction (MI) have been identified. An important task is now to understand the molecular mechanisms/pathways by which these loci exert risk for CAD/MI allowing to translating the initial findings into new therapies and diagnostics. However, since the loci identified thus far explain only ~10% of variation in CAD/MI risk, it is also essential to define additional CAD pathways operating in parallel with GWA loci. In recent years, clinical studies that consider intermediate phenotypes (between DNA and disease) have greatly enhanced interpretations of risk loci identified in GWA datasets. In addition, disease networks that can be identified from intermediate molecular phenotypes provide an essential framework to identify novel CAD pathways and targets for new CAD therapies. Over the last 6 years, we have performed a clinical study considering many intermediate phenotypes in CAD patients (the STARNET study). In this proposal we intend to use newly generated DNA genotype and RNA sequence data from the STARNET study to identify atherosclerosis and metabolic networks underlying CAD. We then propose a new prospective study of CAD (the NGS-PREDICT study) with the main purpose of validating findings from the STARNET study. We hypothesize that the extent and stability of coronary lesions, thus clinical outcomes can be accurately assessed by defining the status of key atherosclerosis gene networks. In turn, metabolic networks active in liver, abdominal fat, and skeletal muscle influence the status of the atherosclerosis gene networks. In addition, molecular data isolated from easily obtainable tissues (e.g., blood, subcutaneous fat and plasma) can be used to identify biomarkers that can predict risk for clinical events caused by CAD. To test these hypotheses, we propose the following specific aims. Aim 1: To identify regulatory Bayesian gene networks causally linked to CAD and/or CAD sub-phenotypes using the STARNET datasets and the CARDIoGRAM meta-analysis GWA datasets. Aim 2: Identify biomarkers predicting clinical events of CAD (reflected in SYNTAX score) by applying machine learning on DNA genotype, RNA sequence and CAD plasma protein data from easily obtainable tissues of the STARNET cases. Aim 3: To validate the identified causal CAD eQTLs/networks and the biomarkers using the NGS-PREDICT study performed at the Mt. Sinai Hospital, the Swedish Twin study and CAD cell and animal models. We believe the proposed studies can lead to a significantly better molecular understanding of CAD and thus, serve the more long-term goal of preventive and personalized therapies of CAD patients diagnosed in well-defined molecular subcategories. PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the world's leading cause of death. We will perform systems genetic analysis of DNA and RNAseq data from 9 CAD-relevant tissues in 700 well-characterized patients (STARNET) integrated with genome-wide association data to reveal CAD-causing metabolic and atherosclerosis gene networks, and within these, new inherited risk variants, CAD-mechanisms, therapeutic targets and biomarkers will be identified and validated in a new prospective clinical study of CAD (NGS-PREDICT). Our studies promise to significantly advance understanding of CAD towards achieving preventive and personalized care.",Toward Diagnostics and Therapies of Molecular Subcategories of CAD,9134865,R01HL125863,"['Abdomen', 'Achievement', 'Address', 'Alleles', 'Angiography', 'Animal Model', 'Area', 'Atherosclerosis', 'Benchmarking', 'Biochemical Pathway', 'Biological Markers', 'Biological Models', 'Biology', 'Biopsy', 'Blood', 'Blood Vessels', 'Cardiology', 'Cardiovascular system', 'Cause of Death', 'Cell model', 'Clinical', 'Clinical Research', 'Complex', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Pathway', 'Disease model', 'Engineering', 'Event', 'Family', 'Fatty acid glycerol esters', 'Foam Cells', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Genotype', 'Goals', 'Health', 'Hereditary Disease', 'Heritability', 'Hospitals', 'In Vitro', 'Individual', 'Inherited', 'Institutes', 'Investments', 'Lead', 'Lesion', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Meta-Analysis', 'Metabolic', 'Modeling', 'Molecular', 'Myocardial Infarction', 'New York', 'Opening of the Thorax', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Plasma Proteins', 'Preventive', 'Preventive care', 'Preventive therapy', 'Prospective Studies', 'Quantitative Trait Loci', 'RNA', 'RNA Sequences', 'Reading', 'Recruitment Activity', 'Regulator Genes', 'Research', 'Research Proposals', 'Risk', 'Sampling', 'Single Nucleotide Polymorphism', 'Skeletal Muscle', 'Subcategory', 'System', 'Techniques', 'Testing', 'Tissues', 'Translating', 'Twin Multiple Birth', 'Twin Studies', 'Variant', 'Weight', 'Whole Blood', 'abdominal fat', 'biological systems', 'clinical risk', 'computer based statistical methods', 'disorder risk', 'follow-up', 'genetic analysis', 'genome wide association study', 'in vivo Model', 'macrophage', 'medical schools', 'molecular phenotype', 'monocyte', 'multidisciplinary', 'novel', 'novel diagnostics', 'novel therapeutics', 'percutaneous coronary intervention', 'personalized care', 'personalized diagnostics', 'personalized medicine', 'prospective', 'protein biomarkers', 'risk variant', 'subcutaneous', 'targeted treatment', 'therapeutic biomarker', 'therapeutic target', 'trait', 'transcriptome sequencing']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2016,807678,0.027448810508243257
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9132242,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Health', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2016,169609,0.0034700432868635884
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9002898,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2016,776460,0.013285799050126513
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8970690,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,624643,0.033130482467253745
"Computer-aided detection of focal cortical dysplasias ﻿    DESCRIPTION (provided by applicant): This project proposes to build computer-aided detection (CAD) software for use in identifying cortical malformations known as focal cortical dysplasia's (FCDs), which are a common cause of epileptic seizures. The intent is for the software, used by a neuroradiologist at a clinical workstation, to decrease the time- intensive nature of the visual search for cortical dysplasia's, while simultaneously increasing sensitivity o dysplasia identification, thus reducing the number of missed lesions and making neuroradiologists more effective and more efficient.  Epilepsy is a common neurological disorder, characterized by recurrent unprovoked seizures, that exacts a large toll upon society in terms of both quality of life and health care costs. Malformations of cortical development (MCD) are the most common cause of seizures in children and the second most common cause in adults. Focal cortical dysplasia is a common form of MCD that is responsible for the vast majority of treatment resistant epilepsy in patients with MCD, and when anti-epileptic medication is ineffective, detection of FCD becomes critical to the ability of the epilepsy team to offer surgery which is often these patient's last hope for seizure freedom.  Unfortunately, the radiological diagnosis of FCD is exceedingly difficult in a large percentage of cases due to their focal and subtle nature. Thus, while resection of these dysplasias can often cure seizures, they can be missed for years or decades, resulting in increased neurological damage and degradation of quality of life due to chronic seizures. In principle high resolution MRI can be used to increase diagnostic accuracy. While this is becoming more common in clinical practice, the need for high patient throughput, lack of clinical information and inexperience often results i these lesions being missed on routine clinical reads by neuroradiologists.  The project will build upon a foundation of existing technology for the generation of quantitative measures of the human brain based on MRI imaging, known in the neuroimaging research domain as FreeSurfer. The project will make use of an MRI dataset of 100 subjects with histologically-confirmed FCD to be labeled by four neuroradiologists, and control subjects with epilepsy that is not due to FCD. The project has three aims: gathering the dataset and expansion of the detection algorithms tested in Phase I to include additional MRI biomarkers; development of an MRI scanner slice prescription component to ensure imaging of an FCD at the optimal visualization plane; and an aim to submit a commercialized version of FreeSurfer for FDA 510(k) clearance. The latter aim is important for the long-term project goal of advancing the state of other clinical detection methods through the building of additional CAD tools making use of FreeSurfer's brain measures, including diseases as varied as Huntington's disease, Alzheimer's disease, tumor monitoring and hydrocephalus. PUBLIC HEALTH RELEVANCE: The proposal is to build software for computer-aided detection of focal cortical dysplasias (FCDs), a malformation of brain development that is a common cause of epileptic seizures in children and adults. The proposed software will offer a neuroradiologist a faster and more accurate detection method compared to visual inspection only. By identifying abnormalities otherwise missed, the ensuing surgical removal of an abnormality can often stop seizures.",Computer-aided detection of focal cortical dysplasias,9061843,R44NS083101,"['Adult', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Antiepileptic Agents', 'Back', 'Base of the Brain', 'Biological Markers', 'Brain', 'Brain region', 'Child', 'Chronic', 'Classification', 'Clinical', 'Code', 'Computer software', 'Cortical Dysplasia', 'Cortical Malformation', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Dysplasia', 'Ensure', 'Epilepsy', 'Equipment', 'Excision', 'Formulation', 'Foundations', 'Freedom', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Health', 'Health Care Costs', 'Histologic', 'Human', 'Huntington Disease', 'Hydrocephalus', 'Image', 'Imagery', 'Label', 'Lesion', 'Letters', 'Licensing', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Markov chain Monte Carlo methodology', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nervous System Trauma', 'Neurologic', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Prevalence', 'Procedures', 'Property', 'Quality of life', 'Reading', 'Recurrence', 'Refractory', 'Research', 'Resistance', 'Resolution', 'Scanning', 'Seizures', 'Slice', 'Societies', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'United States', 'Vendor', 'Visual', 'Work', 'base', 'brain malformation', 'clinical practice', 'computer aided detection', 'design', 'diagnostic accuracy', 'gray matter', 'interest', 'migration', 'nervous system disorder', 'neuroimaging', 'radiologist', 'screening', 'success', 'tool', 'tumor', 'vector', 'visual search', 'white matter']",NINDS,"CORTICOMETRICS, LLC",R44,2016,750677,0.0005778054515596588
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9044803,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Health', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2016,63620,0.02220425523366067
"Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Abstract: Advances in imaging technology offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to various large-scale imaging studies, i.e., ADNI, for discovering AD-related imaging biomarkers. In these imaging studies, image registration plays a key role in reducing the confounding inter-subject variability and also enhancing the statistical power of identifying abnormalities related to AD. However, automated processing of large-scale imaging data, i.e., involving anything from hundreds to thousands of 3D brain images, is not trivial and requires dedicated computational tools. The goal of this project is to develop a series of novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going large-scale imaging study, an efficient incremental groupwise registration method will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. Our key idea is to break down the complex groupwise registration problem into hierarchical sets of small- scale registration tasks that can be solved easily, thus making the large-scale registration more manageable and fast. Specifically, 1) for fast initialization of large-scale groupwise registration of brain images, we will develop in Aim 1 a hierarchical learning-based landmark detection algorithm, based on random forest regression, to detect salient anatomical landmarks and then jointly align all images with detected landmarks. Since all images are distributed in a complex manifold and also the registration of similar images is much faster and more accurate, we propose to first build a graph to link each image only with similar images, and then formulate groupwise registration as dynamic graph shrinkage. This avoids direct registration of each image to the group-mean image as done in the conventional methods, thus improving both speed and accuracy. 2) To significantly speed up and also improve this single-layer graph-based groupwise registration, we will further develop in Aim 2 a deep multi-layer groupwise registration by simultaneous layer-by-layer graph construction and layer-wise registration. 3) Finally, to significantly increase both the speed and accuracy of registration for new images acquired from on-going large-scale imaging study, we will develop in Aim 3 a novel incremental groupwise registration method to reuse previous registration results of existing images for guiding registration of new images. Specifically, each new image can be quickly registered to the common space of existing images by finding its most similar existing image(s). Accordingly, all new and existing images will become similar in the common space and then can be quickly updated for their overall groupwise registration. All computational tools developed will be made freely available to the research community, for accelerating the imaging study of Alzheimer's disease. Narrative Description of Project Modern imaging techniques offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to increasing number of large-scale imaging studies, including ADNI. However, the overwhelmingly big data poses new challenges to researchers in automated data processing. Thus, modern computational tools are expected to be able to handle the vast amount of data within a manageable time frame. In light of this, we aim to solve this large-scale spatial registration problem – a critical step directly related to accuracy and precision of imaging biomarkers to be discovered for AD. In particular, we will develop novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going study, an efficient incremental groupwise registration will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. The development of these advanced computational tools will eventually benefit for discovery of new imaging biomarkers for AD.",Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease,9240850,RF1AG053867,"['Advanced Development', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appearance', 'Automatic Data Processing', 'Big Data', 'Brain', 'Brain imaging', 'Communities', 'Complex', 'Computer software', 'Data', 'Detection', 'Documentation', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Imaging technology', 'Learning', 'Light', 'Link', 'Mainstreaming', 'Methods', 'Play', 'Process', 'Research', 'Research Personnel', 'Resources', 'Running', 'Series', 'Speed', 'Subgroup', 'Time', 'Update', 'Work', 'abstracting', 'base', 'computerized tools', 'cost', 'empowered', 'forest', 'image guided', 'image registration', 'imaging biomarker', 'improved', 'neuroimaging', 'novel', 'rapid technique']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,RF1,2016,2485857,-0.05063100959233335
"Deep-radiomics-learning for mass detection in CT colonography Project Summary/Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States. However, it would be prevented by early detection and removal of its precursor lesions. The use of CT colonography (CTC) would substantially increase the access, capacity, safety, cost-effectiveness, and patient compliance of colorectal examinations. The interpretation of CTC examinations would be most effective by use of a first-reader computer- aided detection (FR-CADe) paradigm, where a radiologist reviews only the lesion candidates detected automatically by a computer-aided detection (CADe) system. However, because CADe systems can miss large masses, radiologists still need to perform an additional two-dimensional (2D) review of the CT images of the colon, which increases reading time over 40% on average. Furthermore, also radiologists can occasionally miss some types of masses on CTC images. The goal of this project is to develop a DEep RAdiomics LEarning (DERALE) scheme for the detection of large masses on CTC images. The scheme will be used to integrate deep learning methods and radiomic biomarkers to perform a complete automated review of CTC images for reliable detection of colorectal masses. We hypothesize that the DERALE scheme will be able to detect colorectal masses at a sensitivity comparable to that of unaided expert radiologists and that it can be used to reduce the interpretation time of FR- CADe without degrading diagnostic accuracy in CTC. We will evaluate and compare the classification performance of DERALE with that of unaided expert radiologists and conduct an observer performance study to compare the detection accuracy of the use of DERALE in the FR-CADe paradigm with that of unaided expert radiologists in the detection of masses from CTC images. Successful development and broad adoption of DERALE in the FR-CADe paradigm will facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce the mortality rate from colon cancer, one of the largest threats of cancer deaths in the United States. Project Narrative Successful development and validation of DERALE will substantially advance the clinical implementation of CTC and the FR-CADe paradigm in large populations to facilitate early, accurate, and cost-effective diagnoses, and thus it will reduce mortality from colon cancer, the second leading cause of cancer deaths in both men and women in the United States. The research is innovative in that robust mass detection has not been developed for CTC and FR- CADe, and that there have been no attempts to use deep learning for mass detection in CTC.",Deep-radiomics-learning for mass detection in CT colonography,9167836,R21EB022747,"['Abdomen', 'Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Anatomy', 'Biological Markers', 'Biological Neural Networks', 'Cancer Etiology', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Collection', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Evaluation', 'Excision', 'Fatigue', 'Goals', 'Guidelines', 'Heating', 'Image', 'Image Analysis', 'Learning', 'Lesion', 'Location', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Methods', 'Performance', 'Polyps', 'Population', 'Prevention', 'Reader', 'Reading', 'Reporting', 'Research', 'Safety', 'Scheme', 'Societies', 'System', 'Testing', 'Time', 'United States', 'Validation', 'Woman', 'X-Ray Computed Tomography', 'abstracting', 'accurate diagnosis', 'base', 'compliance behavior', 'computer aided detection', 'cost effective', 'cost effectiveness', 'design', 'diagnostic accuracy', 'innovation', 'learning strategy', 'men', 'mortality', 'novel', 'prevent', 'radiologist', 'radiomics', 'screening', 'two-dimensional']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2016,256500,0.0011411248942922317
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9119513,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention Studies', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2016,597688,0.03226181940281394
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,0.014348848443787428
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,0.0031679554126498592
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,0.041866879185446175
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals.         PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.            ",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9053610,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Microscopic', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'public health relevance', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2015,239361,-0.0025643641879558175
"Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling ﻿    DESCRIPTION (provided by applicant): The quest for fast image acquisition speed has always been a perennial topic in the MRI community. To reduce the acquisition time for maximal spatial and temporal resolution, modern MRI protocols usually perform reduced acquisitions below the Nyquist rate. The reduced data is then used to reconstruct the image through advanced reconstruction techniques that leverage some prior information about the MRI system (e.g., parallel imaging) and/or MR signal (e.g., compressed sensing). Since such prior information is patient and system specific, recent techniques obtain the prior information using training data obtained through an empirical calibration procedure. All existing methods assume the prior models are linear. Since the intrinsic nonlinear relationship in the training data cannot be characterized in such simple models, the reconstruction is degraded by the inaccuracy of the prior information. Nonlinear learning from the training data have proven to be more powerful in machine learning because it is more general and includes the linear model as a special case. However, it is usually more challenging to learn the nonlinear models and even more challenging to incorporate the model in reconstruction due to the increased degree of freedom. We recently have introduced a novel concept of ""kernel"" in MR reconstruction to address the above challenges timely. Our preliminary results on parallel imaging and sparsity-constrained reconstruction demonstrate that the kernel-based algorithms improve the reconstruction quality over the original algorithms with linear prior models. Built upon our strong preliminary results, the objective of this application is to develop an innovative kernel-based framework for MR image reconstruction from undersampled data. This framework does not require explicit knowledge of nonlinear mapping (as in preliminary work) such that a broader family of nonlinear functions can be explored for different clinical applications. The proposed work is expected to advance the field of MR image reconstruction vertically. Specifically, the successful completion of the proposed project will result in a general framework leading to many new algorithms (including two developed in this project) for reconstruction from reduced acquisition. Therefore, virtually all of current clinical MRI could benefit from the improved resolution, image quality, and/or reduced acquisition times that the new framework will facilitate or the novel applications i may enable.         PUBLIC HEALTH RELEVANCE: The proposed research is to develop a general framework and two specific new techniques to improve the spatial resolution and/or reduce the scan time in magnetic resonance imaging and evaluate the performance of the techniques for 3D parallel imaging and quantitative imaging in brain. The development of such novel fast imaging techniques may greatly enhance diagnosis of neurological disease. Therefore the project will potentially benefit numerous subjects and the healthcare system.            ",Kernel-based Nonlinear Learning for Fast Magnetic Resonance Imaging with Sub-Nyquist Sampling,8953102,R21EB020861,"['Address', 'Algorithms', 'Brain', 'Calibration', 'Clinical', 'Communities', 'Data', 'Development', 'Diagnosis', 'Dictionary', 'Family', 'Freedom', 'Healthcare Systems', 'Image', 'Imaging Techniques', 'Industry', 'Knowledge', 'Learning', 'Letters', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Non-linear Models', 'Patients', 'Performance', 'Phase', 'Physics', 'Principal Component Analysis', 'Procedures', 'Protocols documentation', 'Qualifying', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Signal Transduction', 'Software Tools', 'Speed', 'System', 'Techniques', 'Time', 'Training', 'Weight', 'Work', 'base', 'clinical application', 'image reconstruction', 'improved', 'innovation', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'quantitative imaging', 'reconstruction', 'temporal measurement']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R21,2015,180330,0.023104084222525356
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,8902139,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2015,405249,0.04751249719771174
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,0.021815881968356928
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact).         PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.            ",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,8946754,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2015,658985,0.04759382526157225
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,0.015848466525419467
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,8848046,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,361050,0.007933415528982812
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,9050240,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,227070,0.007933415528982812
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,0.033519053927806707
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8842707,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2015,758935,-0.0011612519034232525
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,0.06405792476765242
"Toward Diagnostics and Therapies of Molecular Subcategories of CAD ﻿    DESCRIPTION (provided by applicant): Coronary artery disease (CAD) is a leading cause of death worldwide and in the US. While the genetics of this disease are intrinsically complex, thanks to huge research investments during the last 5-10 years, particularly in genome-wide association studies (GWAS), a more unbiased, data-driven and realistic view of CAD has been achieved. As part of this achievement, ~160 common risk loci for CAD/myocardial infarction (MI) have been identified. An important task is now to understand the molecular mechanisms/pathways by which these loci exert risk for CAD/MI allowing to translating the initial findings into new therapies and diagnostics. However, since the loci identified thus far explain only ~10% of variation in CAD/MI risk, it is also essential to define additional CAD pathways operating in parallel with GWA loci. In recent years, clinical studies that consider intermediate phenotypes (between DNA and disease) have greatly enhanced interpretations of risk loci identified in GWA datasets. In addition, disease networks that can be identified from intermediate molecular phenotypes provide an essential framework to identify novel CAD pathways and targets for new CAD therapies. Over the last 6 years, we have performed a clinical study considering many intermediate phenotypes in CAD patients (the STARNET study). In this proposal we intend to use newly generated DNA genotype and RNA sequence data from the STARNET study to identify atherosclerosis and metabolic networks underlying CAD. We then propose a new prospective study of CAD (the NGS-PREDICT study) with the main purpose of validating findings from the STARNET study. We hypothesize that the extent and stability of coronary lesions, thus clinical outcomes can be accurately assessed by defining the status of key atherosclerosis gene networks. In turn, metabolic networks active in liver, abdominal fat, and skeletal muscle influence the status of the atherosclerosis gene networks. In addition, molecular data isolated from easily obtainable tissues (e.g., blood, subcutaneous fat and plasma) can be used to identify biomarkers that can predict risk for clinical events caused by CAD. To test these hypotheses, we propose the following specific aims. Aim 1: To identify regulatory Bayesian gene networks causally linked to CAD and/or CAD sub-phenotypes using the STARNET datasets and the CARDIoGRAM meta-analysis GWA datasets. Aim 2: Identify biomarkers predicting clinical events of CAD (reflected in SYNTAX score) by applying machine learning on DNA genotype, RNA sequence and CAD plasma protein data from easily obtainable tissues of the STARNET cases. Aim 3: To validate the identified causal CAD eQTLs/networks and the biomarkers using the NGS-PREDICT study performed at the Mt. Sinai Hospital, the Swedish Twin study and CAD cell and animal models. We believe the proposed studies can lead to a significantly better molecular understanding of CAD and thus, serve the more long-term goal of preventive and personalized therapies of CAD patients diagnosed in well-defined molecular subcategories.         PUBLIC HEALTH RELEVANCE:  Coronary artery disease (CAD) is the world's leading cause of death. We will perform systems genetic analysis of DNA and RNAseq data from 9 CAD-relevant tissues in 700 well-characterized patients (STARNET) integrated with genome-wide association data to reveal CAD-causing metabolic and atherosclerosis gene networks, and within these, new inherited risk variants, CAD-mechanisms, therapeutic targets and biomarkers will be identified and validated in a new prospective clinical study of CAD (NGS-PREDICT). Our studies promise to significantly advance understanding of CAD towards achieving preventive and personalized care.                ",Toward Diagnostics and Therapies of Molecular Subcategories of CAD,8964154,R01HL125863,"['Abdomen', 'Achievement', 'Address', 'Alleles', 'Angiography', 'Animal Model', 'Area', 'Atherosclerosis', 'Benchmarking', 'Biochemical Pathway', 'Biological Markers', 'Biological Models', 'Biology', 'Biopsy', 'Blood', 'Blood Vessels', 'Cardiology', 'Cardiovascular system', 'Cause of Death', 'Cell model', 'Clinical', 'Clinical Research', 'Complex', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'DNA', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Pathway', 'Disease model', 'Engineering', 'Event', 'Family', 'Fatty acid glycerol esters', 'Foam Cells', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Transcription', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Heritability', 'Hospitals', 'In Vitro', 'Individual', 'Inherited', 'Institutes', 'Investments', 'Lead', 'Lesion', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Meta-Analysis', 'Metabolic', 'Modeling', 'Molecular', 'Myocardial Infarction', 'New York', 'Opening of the Thorax', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Plasma Proteins', 'Preventive', 'Prospective Studies', 'Proteins', 'Quantitative Trait Loci', 'RNA', 'RNA Sequences', 'Reading', 'Recruitment Activity', 'Regulator Genes', 'Research', 'Research Proposals', 'Risk', 'Sampling', 'Single Nucleotide Polymorphism', 'Skeletal Muscle', 'Subcategory', 'System', 'Techniques', 'Testing', 'Tissues', 'Translating', 'Twin Multiple Birth', 'Twin Studies', 'Variant', 'Weight', 'Whole Blood', 'abdominal fat', 'biological systems', 'clinical risk', 'computer based statistical methods', 'disorder risk', 'follow-up', 'genetic analysis', 'genome wide association study', 'in vivo Model', 'macrophage', 'medical schools', 'molecular phenotype', 'monocyte', 'multidisciplinary', 'novel', 'percutaneous coronary intervention', 'personalized care', 'personalized diagnostics', 'personalized medicine', 'prospective', 'public health relevance', 'risk variant', 'subcutaneous', 'therapeutic target', 'trait', 'transcriptome sequencing']",NHLBI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2015,828928,0.027448810508243257
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging.         PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.                ",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,8968015,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2015,169609,0.0034700432868635884
"Improvement of microcalcification detection in digital breast tomosynthesis DESCRIPTION (provided by applicant): Screening mammography has limited sensitivity and specificity. Digital Breast Tomosynthesis (DBT) is an emerging modality that has been shown to significantly improve the detection and characterization of soft- tissue lesions. However, initial studies have shown that subtle microcalcification (MC) clusters, which are often the only sign of early breast cancer, can be difficult to visualize in DBT. Some have suggested that DBT be used in parallel with FFDM in screening, (i.e., adding one- or two-view DBT to the two-view FFDMs so that FFDM could be used for MC detection while DBT could be used for mass detection). This approach would increase imaging costs, reading time, and patient dose, which are all major concerns with regards to introducing DBT into clinical practice. The main goal of the proposed Partnership between the University of Michigan Computer-Aided Diagnosis Research Laboratory (UM) and GE Global Research (GE) is to develop an integrated practical approach to resolving the MC visualization and detection problems in DBT without increasing patient dose, thereby facilitating the eventual replacement of FFDM by DBT. To achieve this goal, we propose two Specific Aims: (SA1) to develop specially designed MC enhancing methods to improve human and machine visualization of MCs in DBT and develop a computer-aided detection (CAD) system to highlight significant MC clusters, and (SA2) to implement the developed MC-enhancing and CAD reading tools in a DBT workstation and conduct observer performance studies to compare MC detection in DBT with that in FFDM. The following tasks will be conducted to accomplish the specific aims: (1) perform phantom studies to determine the best set of image acquisition parameters for data collection, (2) collect a database of human subject DBTs for development of algorithms and observer study, (3) develop lesion-specific reconstruction and MC enhancing methods to improve the visibility of MCs in DBT for radiologist's reading and computerized detection, (4) develop computer-vision methods to detect MC candidates, (5) develop MC analysis method to reduce false positives (FPs) and insignificant CAD marks, (6) design two-view analysis to further reduce FPs, (7) study dependence of MC detection on reconstruction methods and tomosynthesis acquisition parameters, and (8) design a DBT workstation implemented with the MC-enhancing and CAD- assisted tools to highlight significant MCs for radiologist's reading. We hypothesize that the specially designed DBT display system can assist radiologists in detection of MCs in DBT with accuracy at least comparable to that in FFDM. To test this hypothesis, we will (9) conduct observer ROC studies to compare the detection accuracy of MCs under three conditions: (a) two-view DBT without CAD vs. two-view FFDM without CAD, (b) two-view DBT with CAD vs. two-view FFDM with CAD, and (c) a special protocol of CC-view FFDM plus MLO-view DBT with CAD vs. two-view FFDM with CAD. DBT is a promising modality for improving breast cancer detection. It is widely regarded that DBT is superior to FFDM for detecting soft-tissue lesions. This Partnership between UM and GE aims at finding an integrated, effective solution to address the critical remaining issue of MC visualization and detection in DBT. The partners bring unique and complementary capabilities to the proposed program. GE has expertise in the design of DBT systems, image analysis, workstation implementation, and most importantly, limited-angle tomosynthesis and full-angle CT reconstruction in practical commercial imaging systems. UM has extensive experience in development of CAD methods and DBT imaging, medical physicists with expertise in the evaluation of x-ray systems, and strong clinical support from the Breast Imaging Division within one of the top academic radiology departments in the country. Together, UM and GE have the full complement of skills, experience, and resources required for success on this important public health project. If we are successful in achieving our aims, we will have a practical solution to the MC detection problems in DBT. We will produce an MC-enhanced and CAD-assisted reading protocol that will serve as a model for DBT system and workstation design. This will pave the way for the acceptance of DBT for clinical use, thereby improving the sensitivity and specificity of breast cancer screening which will benefit all women.",Improvement of microcalcification detection in digital breast tomosynthesis,8901759,R01CA151443,"['Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Breast Cancer Detection', 'Breast Microcalcification', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Country', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dependence', 'Detection', 'Development', 'Digital Breast Tomosynthesis', 'Digital Mammography', 'Dose', 'Evaluation', 'Freezing', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Laboratory Research', 'Lesion', 'Mammography', 'Medical Imaging', 'Methods', 'Michigan', 'Modality', 'Modeling', 'Patients', 'Performance', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'ROC Curve', 'Radiology Specialty', 'Reader', 'Reading', 'Reporting', 'Research', 'Research Design', 'Resources', 'Scanning', 'Sensitivity and Specificity', 'Solutions', 'System', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Training', 'Universities', 'Woman', 'base', 'breast imaging', 'clinical practice', 'computer aided detection', 'computerized', 'cost', 'design', 'experience', 'human subject', 'imaging system', 'improved', 'malignant breast neoplasm', 'prevent', 'programs', 'radiologist', 'reconstruction', 'screening', 'skills', 'soft tissue', 'success', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2015,550270,-0.023648971865212927
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8771432,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,639475,0.033130482467253745
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8807942,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2015,767996,0.013285799050126513
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2).          PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.                 ",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,8854343,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Minority', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2015,63363,0.02220425523366067
"Computer-aided detection of focal cortical dysplasias ﻿    DESCRIPTION (provided by applicant): This project proposes to build computer-aided detection (CAD) software for use in identifying cortical malformations known as focal cortical dysplasia's (FCDs), which are a common cause of epileptic seizures. The intent is for the software, used by a neuroradiologist at a clinical workstation, to decrease the time- intensive nature of the visual search for cortical dysplasia's, while simultaneously increasing sensitivity o dysplasia identification, thus reducing the number of missed lesions and making neuroradiologists more effective and more efficient.  Epilepsy is a common neurological disorder, characterized by recurrent unprovoked seizures, that exacts a large toll upon society in terms of both quality of life and health care costs. Malformations of cortical development (MCD) are the most common cause of seizures in children and the second most common cause in adults. Focal cortical dysplasia is a common form of MCD that is responsible for the vast majority of treatment resistant epilepsy in patients with MCD, and when anti-epileptic medication is ineffective, detection of FCD becomes critical to the ability of the epilepsy team to offer surgery which is often these patient's last hope for seizure freedom.  Unfortunately, the radiological diagnosis of FCD is exceedingly difficult in a large percentage of cases due to their focal and subtle nature. Thus, while resection of these dysplasias can often cure seizures, they can be missed for years or decades, resulting in increased neurological damage and degradation of quality of life due to chronic seizures. In principle high resolution MRI can be used to increase diagnostic accuracy. While this is becoming more common in clinical practice, the need for high patient throughput, lack of clinical information and inexperience often results i these lesions being missed on routine clinical reads by neuroradiologists.  The project will build upon a foundation of existing technology for the generation of quantitative measures of the human brain based on MRI imaging, known in the neuroimaging research domain as FreeSurfer. The project will make use of an MRI dataset of 100 subjects with histologically-confirmed FCD to be labeled by four neuroradiologists, and control subjects with epilepsy that is not due to FCD. The project has three aims: gathering the dataset and expansion of the detection algorithms tested in Phase I to include additional MRI biomarkers; development of an MRI scanner slice prescription component to ensure imaging of an FCD at the optimal visualization plane; and an aim to submit a commercialized version of FreeSurfer for FDA 510(k) clearance. The latter aim is important for the long-term project goal of advancing the state of other clinical detection methods through the building of additional CAD tools making use of FreeSurfer's brain measures, including diseases as varied as Huntington's disease, Alzheimer's disease, tumor monitoring and hydrocephalus.         PUBLIC HEALTH RELEVANCE: The proposal is to build software for computer-aided detection of focal cortical dysplasias (FCDs), a malformation of brain development that is a common cause of epileptic seizures in children and adults. The proposed software will offer a neuroradiologist a faster and more accurate detection method compared to visual inspection only. By identifying abnormalities otherwise missed, the ensuing surgical removal of an abnormality can often stop seizures.            ",Computer-aided detection of focal cortical dysplasias,8903251,R44NS083101,"['Adult', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Antiepileptic Agents', 'Back', 'Base of the Brain', 'Biological Markers', 'Brain', 'Brain region', 'Child', 'Chronic', 'Classification', 'Clinical', 'Code', 'Computer software', 'Cortical Dysplasia', 'Cortical Malformation', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Drug Formulations', 'Dysplasia', 'Ensure', 'Epilepsy', 'Equipment', 'Excision', 'Foundations', 'Freedom', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Health Care Costs', 'Histologic', 'Human', 'Huntington Disease', 'Hydrocephalus', 'Image', 'Imagery', 'Label', 'Lesion', 'Letters', 'Licensing', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Markov chain Monte Carlo methodology', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nervous System Trauma', 'Neurologic', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Prevalence', 'Procedures', 'Property', 'Quality of life', 'Reading', 'Recurrence', 'Refractory', 'Research', 'Resistance', 'Resolution', 'Scanning', 'Seizures', 'Slice', 'Societies', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'United States', 'Vendor', 'Visual', 'Work', 'base', 'brain malformation', 'clinical practice', 'computer aided detection', 'design', 'diagnostic accuracy', 'gray matter', 'interest', 'migration', 'nervous system disorder', 'neuroimaging', 'public health relevance', 'radiologist', 'screening', 'success', 'tool', 'tumor', 'vector', 'visual search', 'white matter']",NINDS,"CORTICOMETRICS, LLC",R44,2015,750677,0.0005778054515596588
"Quantitative Image Analysis Techniques for Optic Nerve Disease DESCRIPTION (provided by applicant): Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Americans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multipl sclerosis (MS) cases (which impacts over 400 thousand Americans and introduces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irreversibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment. We propose to translate computational imaging methods from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interventions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively predict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.",Quantitative Image Analysis Techniques for Optic Nerve Disease,8774908,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'clinical sequencing', 'computerized tools', 'contrast imaging', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'prognostic value', 'quantitative imaging', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2015,185147,0.01046180401490167
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8887334,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2015,591379,0.03226181940281394
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,0.06541589347163716
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,0.014348848443787428
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,142837,0.03373802962087668
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,0.037468695039391244
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,0.041866879185446175
"ENTROPY-BASED TISSUE DISCRIMINATORS     DESCRIPTION (provided by applicant): The major problem addressed in this proposal is the development and evaluation of an automated noninvasive approach to discriminate different normal and pathological tissue types using machine learning algorithms; previous applications of machine learning have been based on features of the backscattered ultrasound that are essentially energy based. Our approach will be based on extracting features from images whose pixels are determined by the entropy contained in segments of the backscattered ultrasound. The unique attributes of entropy imaging suggest that the automated analysis we propose would be particularly robust for discrimination of deep tissues in a clinical environment.        PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8737902,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'signal processing', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2014,184300,0.00993397386609273
"Graph-Based Medical Image Segmentation in 3D and 4D     DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care.         PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.            ",Graph-Based Medical Image Segmentation in 3D and 4D,8759436,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'public health relevance', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2014,395708,0.04751249719771174
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,0.021815881968356928
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,0.015848466525419467
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8657936,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2014,350219,0.007933415528982812
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging     DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient.         PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.            ",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8674683,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2014,782871,-0.0011612519034232525
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,0.06405792476765242
"Improvement of microcalcification detection in digital breast tomosynthesis DESCRIPTION (provided by applicant): Screening mammography has limited sensitivity and specificity. Digital Breast Tomosynthesis (DBT) is an emerging modality that has been shown to significantly improve the detection and characterization of soft- tissue lesions. However, initial studies have shown that subtle microcalcification (MC) clusters, which are often the only sign of early breast cancer, can be difficult to visualize in DBT. Some have suggested that DBT be used in parallel with FFDM in screening, (i.e., adding one- or two-view DBT to the two-view FFDMs so that FFDM could be used for MC detection while DBT could be used for mass detection). This approach would increase imaging costs, reading time, and patient dose, which are all major concerns with regards to introducing DBT into clinical practice. The main goal of the proposed Partnership between the University of Michigan Computer-Aided Diagnosis Research Laboratory (UM) and GE Global Research (GE) is to develop an integrated practical approach to resolving the MC visualization and detection problems in DBT without increasing patient dose, thereby facilitating the eventual replacement of FFDM by DBT. To achieve this goal, we propose two Specific Aims: (SA1) to develop specially designed MC enhancing methods to improve human and machine visualization of MCs in DBT and develop a computer-aided detection (CAD) system to highlight significant MC clusters, and (SA2) to implement the developed MC-enhancing and CAD reading tools in a DBT workstation and conduct observer performance studies to compare MC detection in DBT with that in FFDM. The following tasks will be conducted to accomplish the specific aims: (1) perform phantom studies to determine the best set of image acquisition parameters for data collection, (2) collect a database of human subject DBTs for development of algorithms and observer study, (3) develop lesion-specific reconstruction and MC enhancing methods to improve the visibility of MCs in DBT for radiologist's reading and computerized detection, (4) develop computer-vision methods to detect MC candidates, (5) develop MC analysis method to reduce false positives (FPs) and insignificant CAD marks, (6) design two-view analysis to further reduce FPs, (7) study dependence of MC detection on reconstruction methods and tomosynthesis acquisition parameters, and (8) design a DBT workstation implemented with the MC-enhancing and CAD- assisted tools to highlight significant MCs for radiologist's reading. We hypothesize that the specially designed DBT display system can assist radiologists in detection of MCs in DBT with accuracy at least comparable to that in FFDM. To test this hypothesis, we will (9) conduct observer ROC studies to compare the detection accuracy of MCs under three conditions: (a) two-view DBT without CAD vs. two-view FFDM without CAD, (b) two-view DBT with CAD vs. two-view FFDM with CAD, and (c) a special protocol of CC-view FFDM plus MLO-view DBT with CAD vs. two-view FFDM with CAD. DBT is a promising modality for improving breast cancer detection. It is widely regarded that DBT is superior to FFDM for detecting soft-tissue lesions. This Partnership between UM and GE aims at finding an integrated, effective solution to address the critical remaining issue of MC visualization and detection in DBT. The partners bring unique and complementary capabilities to the proposed program. GE has expertise in the design of DBT systems, image analysis, workstation implementation, and most importantly, limited-angle tomosynthesis and full-angle CT reconstruction in practical commercial imaging systems. UM has extensive experience in development of CAD methods and DBT imaging, medical physicists with expertise in the evaluation of x-ray systems, and strong clinical support from the Breast Imaging Division within one of the top academic radiology departments in the country. Together, UM and GE have the full complement of skills, experience, and resources required for success on this important public health project. If we are successful in achieving our aims, we will have a practical solution to the MC detection problems in DBT. We will produce an MC-enhanced and CAD-assisted reading protocol that will serve as a model for DBT system and workstation design. This will pave the way for the acceptance of DBT for clinical use, thereby improving the sensitivity and specificity of breast cancer screening which will benefit all women.",Improvement of microcalcification detection in digital breast tomosynthesis,8701878,R01CA151443,"['Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Breast', 'Breast Cancer Detection', 'Breast Microcalcification', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Country', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dependence', 'Detection', 'Development', 'Digital Breast Tomosynthesis', 'Digital Mammography', 'Dose', 'Evaluation', 'Freezing', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Laboratory Research', 'Lesion', 'Mammography', 'Medical Imaging', 'Methods', 'Michigan', 'Modality', 'Modeling', 'Patients', 'Performance', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'ROC Curve', 'Radiology Specialty', 'Reader', 'Reading', 'Reporting', 'Research', 'Research Design', 'Resources', 'Scanning', 'Sensitivity and Specificity', 'Simulate', 'Solutions', 'System', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Training', 'Universities', 'Woman', 'base', 'clinical practice', 'computer aided detection', 'computerized', 'cost', 'design', 'experience', 'human subject', 'improved', 'malignant breast neoplasm', 'prevent', 'programs', 'radiologist', 'reconstruction', 'screening', 'skills', 'soft tissue', 'success', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2014,589382,-0.023648971865212927
"Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography    DESCRIPTION (provided by applicant): Urinary tract neoplasm is a common type of cancer that can cause substantial morbidity and mortality among patients.  Bladder and upper urinary tract cancer causes 14800 deaths per year in the United States. It is expected that 71100 new bladder and upper urinary tract cancer cases would be diagnosed in 2008. Multi-detector row CT (MDCT) urography is currently a very promising imaging modality for early detection of bladder and upper urinary tract cancer, which can be a cause of hematuria.  The prevalence of hematuria can be as high as 19% in elderly patients.  Interpretation of MDCT urograms (CTU) that commonly exceeds 400 slices is a demanding task for radiologists who have to visually track the upper and lower urinary tract and look for lesions which usually are small in size. In addition, some bladder lesions can be in the bladder area filled with contrast and some in the area without contrast. The long term goal of the project is to develop an effective computer-aided diagnosis (CADx) system to assist radiologists in interpretation of CTUs.  In this proposed project, we will concentrate on the development of the first computer-aided detection (CAD) system for the detection of bladder and upper urinary tract lesions on CTU images.  We hypothesize that the use of CAD system can improve the radiologists' accuracy in detecting bladder and upper urinary tract cancer on CTUs.  To test this hypothesis, we will perform the following specific tasks: (1) collect a database of bladder and upper urinary tract malignant and benign lesions; (2) develop new computer vision techniques to process 3-dimensional (3D) volumetric CTUs; (3) develop algorithms to detect bladder lesions; (4) develop algorithms to detect upper urinary tract lesions; and (5) compare the detection accuracy of bladder and upper urinary tract lesions on CTUs with and without CAD by observer ROC studies. In order to accomplish these tasks, we will develop new image analysis techniques for automated tracking of the ureter and segmentation of the inner and outer walls of the bladder and the ureter. New methods will be designed specifically for detection of lesion candidates in the bladder and the ureter. We will design methods and 3D measures for estimating asymmetries of the bladder wall thickness and detection of ureteral wall thickening.  Feature extraction techniques and robust classification methods will be developed for identification of true positive and elimination of false positive lesions using the extracted features. If successfully developed, the CAD system can potentially improve the performance of the radiologists in detecting urothelial neoplasm as well as in interpreting CTU for patients with hematuria, allowing the detection of additional cancers at earlier stage. Early detection can improve the prognosis and survival of the patients.         PUBLIC HEALTH RELEVANCE:  The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.         ",Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography,8665805,R01CA134688,"['3-Dimensional', 'Algorithms', 'Area', 'Benign', 'Bladder', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Classification', 'Collection', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Computers', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Future', 'Goals', 'Hematuria', 'Image', 'Image Analysis', 'Investigation', 'Knowledge', 'Left', 'Lesion', 'Lower urinary tract', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Patients', 'Performance', 'Prevalence', 'Process', 'Public Health', 'Reading', 'Resources', 'Scanning', 'Slice', 'Staging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'TimeLine', 'Training', 'United States', 'Ureter', 'Urinary tract', 'Urography', 'Urologic Cancer', 'Urologic Neoplasms', 'Urothelial Neoplasm', 'base', 'cancer type', 'computer aided detection', 'computerized', 'cost', 'design', 'detector', 'experience', 'graphical user interface', 'imaging modality', 'improved', 'innovation', 'malignant breast neoplasm', 'mortality', 'older patient', 'outcome forecast', 'public health relevance', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2014,353464,0.04774201566416179
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8601692,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,623127,0.033130482467253745
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography  Project Summary/Abstract  Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induced stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quan- titative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational im- age analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentiallly between rest and stress - that will identify my- ocardial tissue at-risk after dobutamine-induced stress. This work will involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to hu- mans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.            ",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8614454,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Frequencies', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Radio', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'novel', 'novel strategies', 'public health relevance', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2014,819740,0.007349610136912745
"Quantitative Image Analysis Techniques for Optic Nerve Disease  PROJECT SUMMARY/ABSTRACT  Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Ameri- cans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multiple sclerosis (MS) cases (which impacts over 400 thousand Americans and intro- duces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irre- versibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment.  We propose to translate computational imaging methods from the neuroimaging community to provide ro- bust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interven- tions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively pre- dict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.                ",Quantitative Image Analysis Techniques for Optic Nerve Disease,8620598,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'computerized tools', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'public health relevance', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2014,225089,0.010013391127821876
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8761531,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Build-it', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2014,611476,0.03226181940281394
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,0.06541589347163716
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8522756,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2013,150000,0.03373802962087668
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,0.03688967212067235
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,0.0008591067313317905
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8522304,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2013,216041,0.0095044834593412
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.028580391021264504
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,0.021815881968356928
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8494421,R01CA166816,"['Adoption', 'American Cancer Society', 'Belief', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2013,339387,0.007933415528982812
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,0.015848466525419467
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8541012,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIVERSITY OF HOUSTON,R01,2013,361799,0.013282651301805528
"Improvement of microcalcification detection in digital breast tomosynthesis DESCRIPTION (provided by applicant): Screening mammography has limited sensitivity and specificity. Digital Breast Tomosynthesis (DBT) is an emerging modality that has been shown to significantly improve the detection and characterization of soft- tissue lesions. However, initial studies have shown that subtle microcalcification (MC) clusters, which are often the only sign of early breast cancer, can be difficult to visualize in DBT. Some have suggested that DBT be used in parallel with FFDM in screening, (i.e., adding one- or two-view DBT to the two-view FFDMs so that FFDM could be used for MC detection while DBT could be used for mass detection). This approach would increase imaging costs, reading time, and patient dose, which are all major concerns with regards to introducing DBT into clinical practice. The main goal of the proposed Partnership between the University of Michigan Computer-Aided Diagnosis Research Laboratory (UM) and GE Global Research (GE) is to develop an integrated practical approach to resolving the MC visualization and detection problems in DBT without increasing patient dose, thereby facilitating the eventual replacement of FFDM by DBT. To achieve this goal, we propose two Specific Aims: (SA1) to develop specially designed MC enhancing methods to improve human and machine visualization of MCs in DBT and develop a computer-aided detection (CAD) system to highlight significant MC clusters, and (SA2) to implement the developed MC-enhancing and CAD reading tools in a DBT workstation and conduct observer performance studies to compare MC detection in DBT with that in FFDM. The following tasks will be conducted to accomplish the specific aims: (1) perform phantom studies to determine the best set of image acquisition parameters for data collection, (2) collect a database of human subject DBTs for development of algorithms and observer study, (3) develop lesion-specific reconstruction and MC enhancing methods to improve the visibility of MCs in DBT for radiologist's reading and computerized detection, (4) develop computer-vision methods to detect MC candidates, (5) develop MC analysis method to reduce false positives (FPs) and insignificant CAD marks, (6) design two-view analysis to further reduce FPs, (7) study dependence of MC detection on reconstruction methods and tomosynthesis acquisition parameters, and (8) design a DBT workstation implemented with the MC-enhancing and CAD- assisted tools to highlight significant MCs for radiologist's reading. We hypothesize that the specially designed DBT display system can assist radiologists in detection of MCs in DBT with accuracy at least comparable to that in FFDM. To test this hypothesis, we will (9) conduct observer ROC studies to compare the detection accuracy of MCs under three conditions: (a) two-view DBT without CAD vs. two-view FFDM without CAD, (b) two-view DBT with CAD vs. two-view FFDM with CAD, and (c) a special protocol of CC-view FFDM plus MLO-view DBT with CAD vs. two-view FFDM with CAD. DBT is a promising modality for improving breast cancer detection. It is widely regarded that DBT is superior to FFDM for detecting soft-tissue lesions. This Partnership between UM and GE aims at finding an integrated, effective solution to address the critical remaining issue of MC visualization and detection in DBT. The partners bring unique and complementary capabilities to the proposed program. GE has expertise in the design of DBT systems, image analysis, workstation implementation, and most importantly, limited-angle tomosynthesis and full-angle CT reconstruction in practical commercial imaging systems. UM has extensive experience in development of CAD methods and DBT imaging, medical physicists with expertise in the evaluation of x-ray systems, and strong clinical support from the Breast Imaging Division within one of the top academic radiology departments in the country. Together, UM and GE have the full complement of skills, experience, and resources required for success on this important public health project. If we are successful in achieving our aims, we will have a practical solution to the MC detection problems in DBT. We will produce an MC-enhanced and CAD-assisted reading protocol that will serve as a model for DBT system and workstation design. This will pave the way for the acceptance of DBT for clinical use, thereby improving the sensitivity and specificity of breast cancer screening which will benefit all women.",Improvement of microcalcification detection in digital breast tomosynthesis,8514397,R01CA151443,"['Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Breast', 'Breast Cancer Detection', 'Breast Microcalcification', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Country', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dependence', 'Detection', 'Development', 'Digital Mammography', 'Dose', 'Evaluation', 'Freezing', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Laboratory Research', 'Lesion', 'Mammography', 'Medical Imaging', 'Methods', 'Michigan', 'Modality', 'Patients', 'Performance', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'ROC Curve', 'Radiology Specialty', 'Reader', 'Reading', 'Reporting', 'Research', 'Research Design', 'Resources', 'Scanning', 'Sensitivity and Specificity', 'Simulate', 'Solutions', 'System', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Training', 'Universities', 'Woman', 'base', 'clinical practice', 'computer aided detection', 'computerized', 'cost', 'design', 'digital', 'digital models', 'experience', 'human subject', 'improved', 'malignant breast neoplasm', 'prevent', 'programs', 'radiologist', 'reconstruction', 'screening', 'skills', 'soft tissue', 'success', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2013,589550,-0.023648971865212927
"Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography    DESCRIPTION (provided by applicant): Urinary tract neoplasm is a common type of cancer that can cause substantial morbidity and mortality among patients.  Bladder and upper urinary tract cancer causes 14800 deaths per year in the United States. It is expected that 71100 new bladder and upper urinary tract cancer cases would be diagnosed in 2008. Multi-detector row CT (MDCT) urography is currently a very promising imaging modality for early detection of bladder and upper urinary tract cancer, which can be a cause of hematuria.  The prevalence of hematuria can be as high as 19% in elderly patients.  Interpretation of MDCT urograms (CTU) that commonly exceeds 400 slices is a demanding task for radiologists who have to visually track the upper and lower urinary tract and look for lesions which usually are small in size. In addition, some bladder lesions can be in the bladder area filled with contrast and some in the area without contrast. The long term goal of the project is to develop an effective computer-aided diagnosis (CADx) system to assist radiologists in interpretation of CTUs.  In this proposed project, we will concentrate on the development of the first computer-aided detection (CAD) system for the detection of bladder and upper urinary tract lesions on CTU images.  We hypothesize that the use of CAD system can improve the radiologists' accuracy in detecting bladder and upper urinary tract cancer on CTUs.  To test this hypothesis, we will perform the following specific tasks: (1) collect a database of bladder and upper urinary tract malignant and benign lesions; (2) develop new computer vision techniques to process 3-dimensional (3D) volumetric CTUs; (3) develop algorithms to detect bladder lesions; (4) develop algorithms to detect upper urinary tract lesions; and (5) compare the detection accuracy of bladder and upper urinary tract lesions on CTUs with and without CAD by observer ROC studies. In order to accomplish these tasks, we will develop new image analysis techniques for automated tracking of the ureter and segmentation of the inner and outer walls of the bladder and the ureter. New methods will be designed specifically for detection of lesion candidates in the bladder and the ureter. We will design methods and 3D measures for estimating asymmetries of the bladder wall thickness and detection of ureteral wall thickening.  Feature extraction techniques and robust classification methods will be developed for identification of true positive and elimination of false positive lesions using the extracted features. If successfully developed, the CAD system can potentially improve the performance of the radiologists in detecting urothelial neoplasm as well as in interpreting CTU for patients with hematuria, allowing the detection of additional cancers at earlier stage. Early detection can improve the prognosis and survival of the patients.         PUBLIC HEALTH RELEVANCE:  The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.         ",Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography,8476785,R01CA134688,"['3-Dimensional', 'Algorithms', 'Area', 'Benign', 'Bladder', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Classification', 'Collection', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Computers', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Future', 'Goals', 'Hematuria', 'Image', 'Image Analysis', 'Investigation', 'Knowledge', 'Left', 'Lesion', 'Lower urinary tract', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Patients', 'Performance', 'Prevalence', 'Process', 'Public Health', 'Reading', 'Resources', 'Scanning', 'Slice', 'Staging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'TimeLine', 'Training', 'United States', 'Ureter', 'Urinary tract', 'Urography', 'Urologic Cancer', 'Urologic Neoplasms', 'Urothelial Neoplasm', 'base', 'cancer type', 'computer aided detection', 'computerized', 'cost', 'design', 'detector', 'experience', 'graphical user interface', 'imaging modality', 'improved', 'innovation', 'malignant breast neoplasm', 'mortality', 'older patient', 'outcome forecast', 'public health relevance', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2013,319827,0.04774201566416179
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8420220,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,682340,0.033130482467253745
"Spatially Accurate Deformable Image Registration for Thoracic C Applications    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.    Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.      ",Spatially Accurate Deformable Image Registration for Thoracic C Applications,8558551,DP2OD007044,"['4D Imaging', 'Aftercare', 'Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computers', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Malignant neoplasm of lung', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Patients', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Validation', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'imaging modality', 'lung injury', 'novel', 'public health relevance', 'pulmonary function', 'small airways disease', 'treatment planning']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2013,201518,0.0022442174977984654
"ENTROPY-BASED TISSUE DISCRIMINATORS No abstract available PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8636638,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'computerized data processing', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2013,228000,-0.00521195186192826
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,0.044491927666834845
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.        PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.              Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8266132,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2012,199915,0.004988708257686361
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8323502,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2012,234509,0.0095044834593412
"A suite of diagnostic aids based on image retrieval  Project Summary The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx).  We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker.  In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies.  Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid.  The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance.  Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,8300707,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Lead', 'Learning', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Systems Development', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,320346,0.06230382569265746
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.02832556272573544
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.        PUBLIC HEALTH RELEVANCE: Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                  Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8276007,R01CA166816,"['Adoption', 'American Cancer Society', 'Belief', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2012,361569,-0.009057931887897034
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8323998,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIVERSITY OF HOUSTON,R01,2012,406394,0.013282651301805528
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8234040,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,424407,0.041987976750380844
"Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography    DESCRIPTION (provided by applicant): Urinary tract neoplasm is a common type of cancer that can cause substantial morbidity and mortality among patients.  Bladder and upper urinary tract cancer causes 14800 deaths per year in the United States. It is expected that 71100 new bladder and upper urinary tract cancer cases would be diagnosed in 2008. Multi-detector row CT (MDCT) urography is currently a very promising imaging modality for early detection of bladder and upper urinary tract cancer, which can be a cause of hematuria.  The prevalence of hematuria can be as high as 19% in elderly patients.  Interpretation of MDCT urograms (CTU) that commonly exceeds 400 slices is a demanding task for radiologists who have to visually track the upper and lower urinary tract and look for lesions which usually are small in size. In addition, some bladder lesions can be in the bladder area filled with contrast and some in the area without contrast. The long term goal of the project is to develop an effective computer-aided diagnosis (CADx) system to assist radiologists in interpretation of CTUs.  In this proposed project, we will concentrate on the development of the first computer-aided detection (CAD) system for the detection of bladder and upper urinary tract lesions on CTU images.  We hypothesize that the use of CAD system can improve the radiologists' accuracy in detecting bladder and upper urinary tract cancer on CTUs.  To test this hypothesis, we will perform the following specific tasks: (1) collect a database of bladder and upper urinary tract malignant and benign lesions; (2) develop new computer vision techniques to process 3-dimensional (3D) volumetric CTUs; (3) develop algorithms to detect bladder lesions; (4) develop algorithms to detect upper urinary tract lesions; and (5) compare the detection accuracy of bladder and upper urinary tract lesions on CTUs with and without CAD by observer ROC studies. In order to accomplish these tasks, we will develop new image analysis techniques for automated tracking of the ureter and segmentation of the inner and outer walls of the bladder and the ureter. New methods will be designed specifically for detection of lesion candidates in the bladder and the ureter. We will design methods and 3D measures for estimating asymmetries of the bladder wall thickness and detection of ureteral wall thickening.  Feature extraction techniques and robust classification methods will be developed for identification of true positive and elimination of false positive lesions using the extracted features. If successfully developed, the CAD system can potentially improve the performance of the radiologists in detecting urothelial neoplasm as well as in interpreting CTU for patients with hematuria, allowing the detection of additional cancers at earlier stage. Early detection can improve the prognosis and survival of the patients.        PUBLIC HEALTH RELEVANCE:  The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.           7. Project Narrative The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.",Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography,8281589,R01CA134688,"['3-Dimensional', 'Algorithms', 'Area', 'Benign', 'Bladder', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Classification', 'Collection', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Computers', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Future', 'Goals', 'Hematuria', 'Image', 'Image Analysis', 'Investigation', 'Knowledge', 'Left', 'Lesion', 'Lower urinary tract', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Patients', 'Performance', 'Prevalence', 'Process', 'Public Health', 'Reading', 'Resources', 'Scanning', 'Slice', 'Staging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'TimeLine', 'Training', 'United States', 'Ureter', 'Urinary tract', 'Urography', 'Urologic Cancer', 'Urologic Neoplasms', 'Urothelial Neoplasm', 'base', 'cancer type', 'computer aided detection', 'computerized', 'cost', 'design', 'detector', 'experience', 'graphical user interface', 'imaging modality', 'improved', 'innovation', 'malignant breast neoplasm', 'mortality', 'older patient', 'outcome forecast', 'public health relevance', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,313395,0.05367887506312563
"Improvement of microcalcification detection in digital breast tomosynthesis DESCRIPTION (provided by applicant): Screening mammography has limited sensitivity and specificity. Digital Breast Tomosynthesis (DBT) is an emerging modality that has been shown to significantly improve the detection and characterization of soft- tissue lesions. However, initial studies have shown that subtle microcalcification (MC) clusters, which are often the only sign of early breast cancer, can be difficult to visualize in DBT. Some have suggested that DBT be used in parallel with FFDM in screening, (i.e., adding one- or two-view DBT to the two-view FFDMs so that FFDM could be used for MC detection while DBT could be used for mass detection). This approach would increase imaging costs, reading time, and patient dose, which are all major concerns with regards to introducing DBT into clinical practice. The main goal of the proposed Partnership between the University of Michigan Computer-Aided Diagnosis Research Laboratory (UM) and GE Global Research (GE) is to develop an integrated practical approach to resolving the MC visualization and detection problems in DBT without increasing patient dose, thereby facilitating the eventual replacement of FFDM by DBT. To achieve this goal, we propose two Specific Aims: (SA1) to develop specially designed MC enhancing methods to improve human and machine visualization of MCs in DBT and develop a computer-aided detection (CAD) system to highlight significant MC clusters, and (SA2) to implement the developed MC-enhancing and CAD reading tools in a DBT workstation and conduct observer performance studies to compare MC detection in DBT with that in FFDM. The following tasks will be conducted to accomplish the specific aims: (1) perform phantom studies to determine the best set of image acquisition parameters for data collection, (2) collect a database of human subject DBTs for development of algorithms and observer study, (3) develop lesion-specific reconstruction and MC enhancing methods to improve the visibility of MCs in DBT for radiologist's reading and computerized detection, (4) develop computer-vision methods to detect MC candidates, (5) develop MC analysis method to reduce false positives (FPs) and insignificant CAD marks, (6) design two-view analysis to further reduce FPs, (7) study dependence of MC detection on reconstruction methods and tomosynthesis acquisition parameters, and (8) design a DBT workstation implemented with the MC-enhancing and CAD- assisted tools to highlight significant MCs for radiologist's reading. We hypothesize that the specially designed DBT display system can assist radiologists in detection of MCs in DBT with accuracy at least comparable to that in FFDM. To test this hypothesis, we will (9) conduct observer ROC studies to compare the detection accuracy of MCs under three conditions: (a) two-view DBT without CAD vs. two-view FFDM without CAD, (b) two-view DBT with CAD vs. two-view FFDM with CAD, and (c) a special protocol of CC-view FFDM plus MLO-view DBT with CAD vs. two-view FFDM with CAD. DBT is a promising modality for improving breast cancer detection. It is widely regarded that DBT is superior to FFDM for detecting soft-tissue lesions. This Partnership between UM and GE aims at finding an integrated, effective solution to address the critical remaining issue of MC visualization and detection in DBT. The partners bring unique and complementary capabilities to the proposed program. GE has expertise in the design of DBT systems, image analysis, workstation implementation, and most importantly, limited-angle tomosynthesis and full-angle CT reconstruction in practical commercial imaging systems. UM has extensive experience in development of CAD methods and DBT imaging, medical physicists with expertise in the evaluation of x-ray systems, and strong clinical support from the Breast Imaging Division within one of the top academic radiology departments in the country. Together, UM and GE have the full complement of skills, experience, and resources required for success on this important public health project. If we are successful in achieving our aims, we will have a practical solution to the MC detection problems in DBT. We will produce an MC-enhanced and CAD-assisted reading protocol that will serve as a model for DBT system and workstation design. This will pave the way for the acceptance of DBT for clinical use, thereby improving the sensitivity and specificity of breast cancer screening which will benefit all women.",Improvement of microcalcification detection in digital breast tomosynthesis,8327742,R01CA151443,"['Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Breast', 'Breast Cancer Detection', 'Breast Microcalcification', 'Clinical', 'Complement', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Country', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dependence', 'Detection', 'Development', 'Digital Mammography', 'Dose', 'Evaluation', 'Freezing', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Laboratory Research', 'Lesion', 'Mammography', 'Medical Imaging', 'Methods', 'Michigan', 'Modality', 'Patients', 'Performance', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'ROC Curve', 'Radiology Specialty', 'Reader', 'Reading', 'Reporting', 'Research', 'Research Design', 'Resources', 'Scanning', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Solutions', 'System', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Training', 'Universities', 'Woman', 'base', 'clinical practice', 'computer aided detection', 'computerized', 'cost', 'design', 'digital', 'digital models', 'experience', 'human subject', 'improved', 'malignant breast neoplasm', 'prevent', 'programs', 'radiologist', 'reconstruction', 'skills', 'soft tissue', 'success', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,628690,-0.023648971865212927
"Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is one of leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include (1) collecting a large data set to develop and evaluate our CAD algorithms and systems, (2) establishing ""gold standard"" for performance evaluation, (3) developing robust pulmonary vessel segmentation methods, (4) developing robust pulmonary vessel tree reconstruction method to accurately track pulmonary vessels, trim veins and surrounding extensive lung diseases from vessel tree, and label reconstructed arterial tree, (5) developing and improving PE detection algorithms, including multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, PE features extraction for development of classification methods, false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) developing automatic PE index estimation method, (7) exploring performance evaluation methodology for computerized detection of PEs, and (8) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. PUBLIC HEALTH RELEVANCE: The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.            The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.",Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,8315984,R01HL092044,"['Affect', 'Algorithms', 'Angiography', 'Archives', 'Arteries', 'Benign', 'Biological Neural Networks', 'Blood Vessels', 'Cause of Death', 'Characteristics', 'Classification', 'Complex', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Evaluation', 'Evaluation Methodology', 'Goals', 'Gold', 'Health', 'Image', 'Interobserver Variability', 'Label', 'Location', 'Lung', 'Lung diseases', 'Malignant - descriptor', 'Methods', 'Morbidity - disease rate', 'Patients', 'Performance', 'Public Health', 'Pulmonary Embolism', 'Pulmonary vessels', 'Reading', 'Recovery', 'Reporting', 'Research', 'Scanning', 'Scheme', 'Screening procedure', 'Second Opinions', 'Seeds', 'Slice', 'Speed', 'Structure', 'Structure of parenchyma of lung', 'System', 'Techniques', 'Testing', 'TimeLine', 'Training', 'Trees', 'United States', 'Veins', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer aided detection', 'computerized', 'design', 'improved', 'indexing', 'mortality', 'radiologist', 'reconstruction', 'soft tissue']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,470300,0.05540148709807646
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis  Project Summary All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This proposal takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.  Project Narrative This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8300746,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2012,151744,0.035274701787558274
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8299311,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2011,239426,0.0095044834593412
"Improving Breast Cancer Detection and Diagnosis with CAD    DESCRIPTION (provided by applicant): Computer-aided detection (CAD) of breast cancer is rapidly becoming a well accepted clinical practice. Studies have found that radiologists' attitude toward and acceptance of CAD-cued micro-calcification clusters and masses were substantially different. Due to the high sensitivity, radiologists heavily rely on CAD-cued results while searching for micro-calcifications. However, the lower CAD sensitivity for mass detection (including a fraction of subtle masses being cued only on one view) and the higher false-positive detection (FP) rates reduce radiologists' confidence in CAD-cued masses. As a result, radiologists frequently discard CAD-cued subtle masses in the clinical practice. To improve CAD performance and increase radiologists' confidence in using CAD-cued masses in their decision making, we propose two observer-focused innovative approaches to develop and optimize CAD schemes. By maintaining a comparable FP rate to current commercial CAD systems, the new approaches aim to either increase the number of masses being cued on both ipsilateral (CC and MLO) views or cue more subtle masses by eliminating a fraction of other regions that can be easily identified and classified by radiologists without using CAD. To test these approaches, we propose three specific tasks. First, we will develop a unique multi-view based CAD scheme. To more sensitively detect and better match subtle mass regions, we introduce a concept of limited viewing of specific regions into the arena of CAD development. After detecting a matching strip on the ipsolateral view, the scheme applies a second highly sensitive detection scheme only to this strip to identify matched regions. To control for and reduce FP rates, the scheme limits the number of possible matched candidates to less than one per image. Second, we will develop an integrated CAD scheme that includes a combined score for both detection and classification. To improve direct use of features computed by the detection module in the classification task, we will apply a new dual active contour algorithm that should improve mass region segmentation. We will separately optimize two machine learning classifiers to generate a detection score (the likelihood of being a true-positive mass) and a classification score (the likelihood of each detected mass for malignancy) for each segmented region. We will then develop a fusion method to combine these two scores and generate a new summary index that is more heavily weighted for subtle masses. Using this scheme, we can change the current mass detection based cuing method to a new cancer-based cueing method. Third, we will conduct a pilot observer performance study to investigate radiologists' performance under three CADcueing modes (using the current commercial single-image based, the new multi-view based, and the new integrated CAD schemes). The reading results will be compared and analyzed using both ROC and JAFROC methodologies. We note that the approach is substantially different than focusing on incremental improvements in image based detection schemes in that the observer's actual use (or not) of the CADcued regions drives our objectives in this project, resulting in a targeted development effort.          n/a",Improving Breast Cancer Detection and Diagnosis with CAD,8065906,R01CA077850,"['Algorithms', 'Area', 'Attention', 'Attitude', 'Benign', 'Breast', 'Breast Cancer Detection', 'Cancer Detection', 'Classification', 'Clinical', 'Computer Assisted', 'Cues', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Diagnostic', 'Environment', 'Eye', 'Genetic Programming', 'Hybrids', 'Image', 'Investigation', 'Ipsilateral', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Perception', 'Performance', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Role', 'Scheme', 'Specific qualifier value', 'System', 'Testing', 'Time', 'Weight', 'Work', 'base', 'calcification', 'cancer diagnosis', 'clinical practice', 'follow-up', 'improved', 'indexing', 'innovation', 'novel strategies', 'radiologist', 'visual search']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,269902,0.029052791524308362
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,8119450,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Health', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Lead', 'Learning', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Systems Development', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,320034,0.053159090833232336
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.02832556272573544
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0.0296620859330336
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0.03481657439566452
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,8135352,R01EB012070,"['Agreement', 'Algorithms', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'image processing', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2011,29247,0.013282651301805528
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8037095,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,417204,0.041987976750380844
"Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography    DESCRIPTION (provided by applicant): Urinary tract neoplasm is a common type of cancer that can cause substantial morbidity and mortality among patients.  Bladder and upper urinary tract cancer causes 14800 deaths per year in the United States. It is expected that 71100 new bladder and upper urinary tract cancer cases would be diagnosed in 2008. Multi-detector row CT (MDCT) urography is currently a very promising imaging modality for early detection of bladder and upper urinary tract cancer, which can be a cause of hematuria.  The prevalence of hematuria can be as high as 19% in elderly patients.  Interpretation of MDCT urograms (CTU) that commonly exceeds 400 slices is a demanding task for radiologists who have to visually track the upper and lower urinary tract and look for lesions which usually are small in size. In addition, some bladder lesions can be in the bladder area filled with contrast and some in the area without contrast. The long term goal of the project is to develop an effective computer-aided diagnosis (CADx) system to assist radiologists in interpretation of CTUs.  In this proposed project, we will concentrate on the development of the first computer-aided detection (CAD) system for the detection of bladder and upper urinary tract lesions on CTU images.  We hypothesize that the use of CAD system can improve the radiologists' accuracy in detecting bladder and upper urinary tract cancer on CTUs.  To test this hypothesis, we will perform the following specific tasks: (1) collect a database of bladder and upper urinary tract malignant and benign lesions; (2) develop new computer vision techniques to process 3-dimensional (3D) volumetric CTUs; (3) develop algorithms to detect bladder lesions; (4) develop algorithms to detect upper urinary tract lesions; and (5) compare the detection accuracy of bladder and upper urinary tract lesions on CTUs with and without CAD by observer ROC studies. In order to accomplish these tasks, we will develop new image analysis techniques for automated tracking of the ureter and segmentation of the inner and outer walls of the bladder and the ureter. New methods will be designed specifically for detection of lesion candidates in the bladder and the ureter. We will design methods and 3D measures for estimating asymmetries of the bladder wall thickness and detection of ureteral wall thickening.  Feature extraction techniques and robust classification methods will be developed for identification of true positive and elimination of false positive lesions using the extracted features. If successfully developed, the CAD system can potentially improve the performance of the radiologists in detecting urothelial neoplasm as well as in interpreting CTU for patients with hematuria, allowing the detection of additional cancers at earlier stage. Early detection can improve the prognosis and survival of the patients.        PUBLIC HEALTH RELEVANCE:  The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.           7. Project Narrative The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.",Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography,8120679,R01CA134688,"['3-Dimensional', 'Algorithms', 'Area', 'Benign', 'Bladder', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Classification', 'Collection', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Computers', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Future', 'Goals', 'Hematuria', 'Image', 'Image Analysis', 'Investigation', 'Knowledge', 'Left', 'Lesion', 'Lower urinary tract', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Patients', 'Performance', 'Prevalence', 'Process', 'Public Health', 'Reading', 'Resources', 'Scanning', 'Slice', 'Staging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'TimeLine', 'Training', 'United States', 'Ureter', 'Urinary tract', 'Urography', 'Urologic Cancer', 'Urologic Neoplasms', 'Urothelial Neoplasm', 'base', 'cancer type', 'computerized', 'cost', 'design', 'detector', 'experience', 'graphical user interface', 'imaging modality', 'improved', 'innovation', 'malignant breast neoplasm', 'mortality', 'older patient', 'outcome forecast', 'public health relevance', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,292234,0.05367887506312563
"Improvement of microcalcification detection in digital breast tomosynthesis DESCRIPTION (provided by applicant): Screening mammography has limited sensitivity and specificity. Digital Breast Tomosynthesis (DBT) is an emerging modality that has been shown to significantly improve the detection and characterization of soft- tissue lesions. However, initial studies have shown that subtle microcalcification (MC) clusters, which are often the only sign of early breast cancer, can be difficult to visualize in DBT. Some have suggested that DBT be used in parallel with FFDM in screening, (i.e., adding one- or two-view DBT to the two-view FFDMs so that FFDM could be used for MC detection while DBT could be used for mass detection). This approach would increase imaging costs, reading time, and patient dose, which are all major concerns with regards to introducing DBT into clinical practice.  The main goal of the proposed Partnership between the University of Michigan Computer-Aided Diagnosis Research Laboratory (UM) and GE Global Research (GE) is to develop an integrated practical approach to resolving the MC visualization and detection problems in DBT without increasing patient dose, thereby facilitating the eventual replacement of FFDM by DBT. To achieve this goal, we propose two Specific Aims: (SA1) to develop specially designed MC enhancing methods to improve human and machine visualization of MCs in DBT and develop a computer-aided detection (CAD) system to highlight significant MC clusters, and (SA2) to implement the developed MC-enhancing and CAD reading tools in a DBT workstation and conduct observer performance studies to compare MC detection in DBT with that in FFDM.  The following tasks will be conducted to accomplish the specific aims: (1) perform phantom studies to determine the best set of image acquisition parameters for data collection, (2) collect a database of human subject DBTs for development of algorithms and observer study, (3) develop lesion-specific reconstruction and MC enhancing methods to improve the visibility of MCs in DBT for radiologist's reading and computerized detection, (4) develop computer-vision methods to detect MC candidates, (5) develop MC analysis method to reduce false positives (FPs) and insignificant CAD marks, (6) design two-view analysis to further reduce FPs, (7) study dependence of MC detection on reconstruction methods and tomosynthesis acquisition parameters, and (8) design a DBT workstation implemented with the MC-enhancing and CAD- assisted tools to highlight significant MCs for radiologist's reading.  We hypothesize that the specially designed DBT display system can assist radiologists in detection of MCs in DBT with accuracy at least comparable to that in FFDM. To test this hypothesis, we will (9) conduct observer ROC studies to compare the detection accuracy of MCs under three conditions: (a) two-view DBT without CAD vs. two-view FFDM without CAD, (b) two-view DBT with CAD vs. two-view FFDM with CAD, and (c) a special protocol of CC-view FFDM plus MLO-view DBT with CAD vs. two-view FFDM with CAD. DBT is a promising modality for improving breast cancer detection. It is widely regarded that DBT is superior to FFDM for detecting soft-tissue lesions. This Partnership between UM and GE aims at finding an integrated, effective solution to address the critical remaining issue of MC visualization and detection in DBT. The partners bring unique and complementary capabilities to the proposed program. GE has expertise in the design of DBT systems, image analysis, workstation implementation, and most importantly, limited-angle tomosynthesis and full-angle CT reconstruction in practical commercial imaging systems. UM has extensive experience in development of CAD methods and DBT imaging, medical physicists with expertise in the evaluation of x-ray systems, and strong clinical support from the Breast Imaging Division within one of the top academic radiology departments in the country. Together, UM and GE have the full complement of skills, experience, and resources required for success on this important public health project. If we are successful in achieving our aims, we will have a practical solution to the MC detection problems in DBT. We will produce an MC-enhanced and CAD-assisted reading protocol that will serve as a model for DBT system and workstation design. This will pave the way for the acceptance of DBT for clinical use, thereby improving the sensitivity and specificity of breast cancer screening which will benefit all women.",Improvement of microcalcification detection in digital breast tomosynthesis,8108142,R01CA151443,"['Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Breast', 'Breast Cancer Detection', 'Breast Microcalcification', 'Clinical', 'Complement', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Country', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dependence', 'Detection', 'Development', 'Digital Mammography', 'Dose', 'Evaluation', 'Freezing', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Laboratory Research', 'Lesion', 'Mammography', 'Medical Imaging', 'Methods', 'Michigan', 'Modality', 'Patients', 'Performance', 'Process', 'Protocols documentation', 'Public Health', 'Publications', 'ROC Curve', 'Radiology Specialty', 'Reader', 'Reading', 'Reporting', 'Research', 'Research Design', 'Resources', 'Scanning', 'Screening procedure', 'Sensitivity and Specificity', 'Simulate', 'Solutions', 'System', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Training', 'Universities', 'Woman', 'base', 'clinical practice', 'computerized', 'cost', 'design', 'digital', 'digital models', 'experience', 'human subject', 'improved', 'malignant breast neoplasm', 'prevent', 'programs', 'radiologist', 'reconstruction', 'skills', 'soft tissue', 'success', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,672019,-0.023648971865212927
"Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is one of leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include (1) collecting a large data set to develop and evaluate our CAD algorithms and systems, (2) establishing ""gold standard"" for performance evaluation, (3) developing robust pulmonary vessel segmentation methods, (4) developing robust pulmonary vessel tree reconstruction method to accurately track pulmonary vessels, trim veins and surrounding extensive lung diseases from vessel tree, and label reconstructed arterial tree, (5) developing and improving PE detection algorithms, including multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, PE features extraction for development of classification methods, false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) developing automatic PE index estimation method, (7) exploring performance evaluation methodology for computerized detection of PEs, and (8) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. PUBLIC HEALTH RELEVANCE: The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.            The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.",Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,8112600,R01HL092044,"['Affect', 'Algorithms', 'Angiography', 'Archives', 'Arteries', 'Benign', 'Biological Neural Networks', 'Blood Vessels', 'Cause of Death', 'Characteristics', 'Classification', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Evaluation', 'Evaluation Methodology', 'Goals', 'Gold', 'Health', 'Image', 'Interobserver Variability', 'Label', 'Location', 'Lung', 'Lung diseases', 'Malignant - descriptor', 'Methods', 'Morbidity - disease rate', 'Patients', 'Performance', 'Public Health', 'Pulmonary Embolism', 'Pulmonary vessels', 'Reading', 'Recovery', 'Reporting', 'Research', 'Scanning', 'Scheme', 'Screening procedure', 'Second Opinions', 'Seeds', 'Slice', 'Speed', 'Structure', 'Structure of parenchyma of lung', 'System', 'Techniques', 'Testing', 'TimeLine', 'Training', 'Trees', 'United States', 'Veins', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computerized', 'design', 'improved', 'indexing', 'mortality', 'radiologist', 'reconstruction', 'soft tissue']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,474145,0.05540148709807646
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,8123240,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Clinical Research', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost effective', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'two-dimensional', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,677070,0.045249201997225354
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8192056,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2011,148255,0.02216711019723537
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7921476,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2010,110591,0.0095044834593412
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7902171,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2010,350000,0.015425397092128246
"Improving Breast Cancer Detection and Diagnosis with CAD    DESCRIPTION (provided by applicant): Computer-aided detection (CAD) of breast cancer is rapidly becoming a well accepted clinical practice. Studies have found that radiologists' attitude toward and acceptance of CAD-cued micro-calcification clusters and masses were substantially different. Due to the high sensitivity, radiologists heavily rely on CAD-cued results while searching for micro-calcifications. However, the lower CAD sensitivity for mass detection (including a fraction of subtle masses being cued only on one view) and the higher false-positive detection (FP) rates reduce radiologists' confidence in CAD-cued masses. As a result, radiologists frequently discard CAD-cued subtle masses in the clinical practice. To improve CAD performance and increase radiologists' confidence in using CAD-cued masses in their decision making, we propose two observer-focused innovative approaches to develop and optimize CAD schemes. By maintaining a comparable FP rate to current commercial CAD systems, the new approaches aim to either increase the number of masses being cued on both ipsilateral (CC and MLO) views or cue more subtle masses by eliminating a fraction of other regions that can be easily identified and classified by radiologists without using CAD. To test these approaches, we propose three specific tasks. First, we will develop a unique multi-view based CAD scheme. To more sensitively detect and better match subtle mass regions, we introduce a concept of limited viewing of specific regions into the arena of CAD development. After detecting a matching strip on the ipsolateral view, the scheme applies a second highly sensitive detection scheme only to this strip to identify matched regions. To control for and reduce FP rates, the scheme limits the number of possible matched candidates to less than one per image. Second, we will develop an integrated CAD scheme that includes a combined score for both detection and classification. To improve direct use of features computed by the detection module in the classification task, we will apply a new dual active contour algorithm that should improve mass region segmentation. We will separately optimize two machine learning classifiers to generate a detection score (the likelihood of being a true-positive mass) and a classification score (the likelihood of each detected mass for malignancy) for each segmented region. We will then develop a fusion method to combine these two scores and generate a new summary index that is more heavily weighted for subtle masses. Using this scheme, we can change the current mass detection based cuing method to a new cancer-based cueing method. Third, we will conduct a pilot observer performance study to investigate radiologists' performance under three CADcueing modes (using the current commercial single-image based, the new multi-view based, and the new integrated CAD schemes). The reading results will be compared and analyzed using both ROC and JAFROC methodologies. We note that the approach is substantially different than focusing on incremental improvements in image based detection schemes in that the observer's actual use (or not) of the CADcued regions drives our objectives in this project, resulting in a targeted development effort.          n/a",Improving Breast Cancer Detection and Diagnosis with CAD,7797472,R01CA077850,"['Algorithms', 'Area', 'Attention', 'Attitude', 'Benign', 'Breast', 'Breast Cancer Detection', 'Cancer Detection', 'Classification', 'Clinical', 'Computer Assisted', 'Cues', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Environment', 'Eye', 'Genetic Programming', 'Hybrids', 'Image', 'Investigation', 'Ipsilateral', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Perception', 'Performance', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Role', 'Scheme', 'Specific qualifier value', 'System', 'Testing', 'Time', 'Weight', 'Work', 'base', 'calcification', 'clinical practice', 'follow-up', 'improved', 'indexing', 'innovation', 'novel strategies', 'radiologist', 'visual search']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,278249,0.029052791524308362
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,7899840,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Cade', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer Systems Development', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hand', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Knowledge', 'Label', 'Lead', 'Learning', 'Left', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'public health relevance', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,328969,0.053159090833232336
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.028580391021264504
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7845601,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,TULANE UNIVERSITY OF LOUISIANA,R21,2010,186306,0.013819768845911483
"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",Reliable Human-Model Observers for Emission Tomography,7948792,R01EB012070,"['Agreement', 'Algorithms', 'Arts', 'Attention', 'Characteristics', 'Clinical', 'Collimator', 'Computer Assisted', 'Computer Systems Development', 'Data', 'Deoxyglucose', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Disease Management', 'Early Diagnosis', 'Early identification', 'Emission-Computed Tomography', 'Ensure', 'Evaluation', 'Eye', 'Fluorine', 'Functional Imaging', 'Goals', 'Grant', 'Human', 'Hybrids', 'Image', 'Indium-111', 'Investigation', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Metric', 'Modality', 'Modeling', 'Morphology', 'Neuroendocrine Tumors', 'Pattern', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Process', 'Research', 'Role', 'Scanning', 'Slice', 'Stress', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'base', 'cancer diagnosis', 'cancer type', 'design', 'digital', 'imaging modality', 'improved', 'interest', 'mathematical model', 'new technology', 'novel', 'public health relevance', 'radiologist', 'simulation', 'single photon emission computed tomography', 'tomography', 'tool', 'tumor', 'visual search']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2010,546827,0.013282651301805528
"Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography    DESCRIPTION (provided by applicant): Urinary tract neoplasm is a common type of cancer that can cause substantial morbidity and mortality among patients.  Bladder and upper urinary tract cancer causes 14800 deaths per year in the United States. It is expected that 71100 new bladder and upper urinary tract cancer cases would be diagnosed in 2008. Multi-detector row CT (MDCT) urography is currently a very promising imaging modality for early detection of bladder and upper urinary tract cancer, which can be a cause of hematuria.  The prevalence of hematuria can be as high as 19% in elderly patients.  Interpretation of MDCT urograms (CTU) that commonly exceeds 400 slices is a demanding task for radiologists who have to visually track the upper and lower urinary tract and look for lesions which usually are small in size. In addition, some bladder lesions can be in the bladder area filled with contrast and some in the area without contrast. The long term goal of the project is to develop an effective computer-aided diagnosis (CADx) system to assist radiologists in interpretation of CTUs.  In this proposed project, we will concentrate on the development of the first computer-aided detection (CAD) system for the detection of bladder and upper urinary tract lesions on CTU images.  We hypothesize that the use of CAD system can improve the radiologists' accuracy in detecting bladder and upper urinary tract cancer on CTUs.  To test this hypothesis, we will perform the following specific tasks: (1) collect a database of bladder and upper urinary tract malignant and benign lesions; (2) develop new computer vision techniques to process 3-dimensional (3D) volumetric CTUs; (3) develop algorithms to detect bladder lesions; (4) develop algorithms to detect upper urinary tract lesions; and (5) compare the detection accuracy of bladder and upper urinary tract lesions on CTUs with and without CAD by observer ROC studies. In order to accomplish these tasks, we will develop new image analysis techniques for automated tracking of the ureter and segmentation of the inner and outer walls of the bladder and the ureter. New methods will be designed specifically for detection of lesion candidates in the bladder and the ureter. We will design methods and 3D measures for estimating asymmetries of the bladder wall thickness and detection of ureteral wall thickening.  Feature extraction techniques and robust classification methods will be developed for identification of true positive and elimination of false positive lesions using the extracted features. If successfully developed, the CAD system can potentially improve the performance of the radiologists in detecting urothelial neoplasm as well as in interpreting CTU for patients with hematuria, allowing the detection of additional cancers at earlier stage. Early detection can improve the prognosis and survival of the patients.        PUBLIC HEALTH RELEVANCE:  The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.           7. Project Narrative The main goals of this project are (1) to develop a computer aided detection (CAD) system to assist radiologists in detection of bladder and upper urinary tract abnormalities on multi-detector row CT urography (CTU) using advanced computer vision techniques and (2) to evaluate the effects of CAD on radiologists' detection of lesions on CTUs. The proposed CAD system for CTU will be a new and unique application of computerized techniques for analysis of urothelial neoplasms. The relevance of this project to public health is that CAD can potentially increase the efficacy of CTU for urothelial neoplasm detection by improving the performance and reducing the variability of both the experienced and the less experienced radiologists. Accurate identification of the cause of disease such as hematuria by CTU can spare the patient considerable effort of undergoing a potentially large number of imaging studies, and thus reduce cost by eliminating the additional imaging. Early detection can improve the prognosis and survival of the patients.",Computer-Aided Detection of Urinary Tract Cancer on MDCT Urography,7782907,R01CA134688,"['3-Dimensional', 'Algorithms', 'Area', 'Benign', 'Bladder', 'Breast', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Classification', 'Collection', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Computers', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Future', 'Goals', 'Hematuria', 'Image', 'Image Analysis', 'Investigation', 'Knowledge', 'Left', 'Lesion', 'Lower urinary tract', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Patients', 'Performance', 'Prevalence', 'Process', 'Public Health', 'Reading', 'Resources', 'Scanning', 'Slice', 'Staging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'TimeLine', 'Training', 'United States', 'Ureter', 'Urinary tract', 'Urography', 'Urologic Cancer', 'Urologic Neoplasms', 'Urothelial Neoplasm', 'base', 'cancer type', 'computerized', 'cost', 'design', 'detector', 'experience', 'graphical user interface', 'imaging modality', 'improved', 'innovation', 'mortality', 'older patient', 'outcome forecast', 'public health relevance', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,308668,0.05367887506312563
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7769507,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,420313,0.041987976750380844
"Spatially Accurate Deformable Image Registration for Thoracic CT Application    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.   Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.       n/a",Spatially Accurate Deformable Image Registration for Thoracic CT Application,7980382,DP2OD007044,"['Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computer Vision Systems', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'pulmonary function', 'small airways disease']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2010,1645038,0.0026023073794092543
"A computer aided chromosome imaging technique for cancer diagnosis    DESCRIPTION (provided by applicant): Identification of recurrent chromosomal aberrations is important for diagnosis, prognosis, and therapy of most hematological malignancies. Due to difficulties with culture of tumor cells, low mitotic index, poor chromosomal morphologies, and low prevalence, it takes tremendous effort and time for a cytogenetic clinician to obtain a sufficient number of analyzable metaphase cells under microscope before he/she can make an accurate clinical diagnosis. This process is not only very inefficient but also subject to human errors. In order to improve the efficiency and accuracy of leukemia diagnosis, we propose to develop a computer aided chromosome imaging technique. Specifically, we will develop an innovative high-speed microscopic imaging system based on a time-delay-integration technique. The system can scan the entire sample-slide at high magnification to obtain high resolution digital images to reveal metaphase chromosomes as required by clinical diagnosis. We will also develop a novel computer aided diagnosis (CAD) scheme including four specific modules to (1) detect analyzable metaphase chromosome cells, (2) segment overlapped chromosomes, (3) identify and classify distorted chromosomes associated with cancer cells, and (4) predict the cancer prognosis. After identification and segmentation of analyzable chromosomes, we will compute and search for the effective and robust image features. Genetic algorithm will be used to train and optimize an artificial neural network and a Bayesian belief network for the classification and prediction tasks, respectively. Using the integrated CAD workstation, we will conduct an observer performance study to assess the performance of the technique and its clinical feasibility. In summary, the proposed imaging technique is highly efficient, and no or only minimal human interventions are required from initial slide-scanning up to the presentation of CAD results. With such a new computerized clinical tool, cytogeneticists can effectively focus their efforts on analyzing/verifying chromosomal abnormal patterns and making final diagnostic decisions. It is therefore expected that the proposed technology can significantly improve the efficiency and accuracy of cancer (i.e., leukemia) diagnosis. The proposed technique has significant clinical potentials in monitoring therapeutic efficacy of cancer treatment as well.          n/a",A computer aided chromosome imaging technique for cancer diagnosis,7841805,R01CA115320,"['Algorithms', 'Belief', 'Biological Neural Networks', 'Cancer Prognosis', 'Cells', 'Chromosome Pairing', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 3', 'Classification', 'Clinical', 'Computer Assisted', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Congenital chromosomal disease', 'Cultured Tumor Cells', 'Custom', 'Cytogenetics', 'Databases', 'Deletion Mutation', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Effectiveness', 'Future', 'Genetic', 'Genetic Programming', 'Graph', 'Hematologic Neoplasms', 'Hour', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Label', 'Laboratories', 'Location', 'Low Prevalence', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Metaphase', 'Methods', 'Microscope', 'Microscopic', 'Molecular', 'Monitor', 'Morphology', 'Normal Cell', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Receiver Operating Characteristics', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'S-Phase Fraction', 'Sampling', 'Scanning', 'Scheme', 'Skin', 'Slide', 'Solutions', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Treatment Efficacy', 'base', 'cancer cell', 'cancer diagnosis', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinical application', 'computerized', 'design', 'detector', 'digital imaging', 'experience', 'improved', 'innovation', 'interest', 'leukemia', 'malignant breast neoplasm', 'novel', 'outcome forecast', 'programs', 'tool', 'user-friendly']",NCI,UNIVERSITY OF OKLAHOMA NORMAN,R01,2010,313901,0.0050711532481939586
"Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is one of leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include (1) collecting a large data set to develop and evaluate our CAD algorithms and systems, (2) establishing ""gold standard"" for performance evaluation, (3) developing robust pulmonary vessel segmentation methods, (4) developing robust pulmonary vessel tree reconstruction method to accurately track pulmonary vessels, trim veins and surrounding extensive lung diseases from vessel tree, and label reconstructed arterial tree, (5) developing and improving PE detection algorithms, including multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, PE features extraction for development of classification methods, false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) developing automatic PE index estimation method, (7) exploring performance evaluation methodology for computerized detection of PEs, and (8) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. PUBLIC HEALTH RELEVANCE: The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.            The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.",Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,7896682,R01HL092044,"['Affect', 'Algorithms', 'Angiography', 'Archives', 'Arteries', 'Benign', 'Biological Neural Networks', 'Blood Vessels', 'Cause of Death', 'Characteristics', 'Classification', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Evaluation', 'Evaluation Methodology', 'Goals', 'Gold', 'Image', 'Interobserver Variability', 'Label', 'Location', 'Lung', 'Lung diseases', 'Malignant - descriptor', 'Methods', 'Morbidity - disease rate', 'Patients', 'Performance', 'Public Health', 'Pulmonary Embolism', 'Pulmonary vessels', 'Reading', 'Recovery', 'Reporting', 'Research', 'Scanning', 'Scheme', 'Screening procedure', 'Second Opinions', 'Seeds', 'Slice', 'Speed', 'Structure', 'Structure of parenchyma of lung', 'System', 'Techniques', 'Testing', 'TimeLine', 'Training', 'Trees', 'United States', 'Veins', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computerized', 'design', 'improved', 'indexing', 'mortality', 'public health relevance', 'radiologist', 'reconstruction', 'soft tissue']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,499892,0.05540148709807646
"Computational Photography Project for Pill Identification (C3PI) In a national effort to promote patient safety, the National Library of Medicine (NLM) proposes to create a comprehensive, public digital image inventory of the nation's commercial prescription solid dose medications. The primary intention of this effort is create a test data collection for the advancement of automatic pharmaceutical identification through computer analysis from photographic data. NLM expects to promote computer-based image research applied to the domain of content-based information retrieval (CBIR) of solid-dose pharmaceuticals, and anticipates the need for generating a test environment, including variations of photographs of the same drug or sample under different environments. n/a",Computational Photography Project for Pill Identification (C3PI),8174192,76201000698P,"['Algorithms', 'Collection', 'Color', 'Computer Analysis', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Dose', 'Environment', 'Equipment', 'Equipment and supply inventories', 'Image', 'Imagery', 'Information Retrieval', 'Intention', 'Measurement', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Photography', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Solid', 'Structure', 'Surface Properties', 'Testing', 'Text', 'United States National Library of Medicine', 'Variant', 'base', 'digital imaging', 'patient safety', 'pill']",NLM,"MEDICOS CONSULTANTS, LLC",N03,2010,500000,0.0024476363847618764
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7936871,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2010,805328,0.045249201997225354
"Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses    DESCRIPTION (provided by applicant): Digital tomosynthesis mammography (DTM) is a new modality that holds the promise of improving mammographic sensitivity of breast cancer detection and diagnosis, especially for dense breasts. The main goals of the proposed research are (1) to develop a computer-aided detection (CADd) system for breast masses in DTM, (2) to develop a computer-aided diagnosis (CADx) system for classification of malignant and benign masses in DTM, and (3) to evaluate the effects of CAD (either CADd or CADx) on radiologists' interpretation of DTMs. Previous CAD systems are developed for regular projection mammograms (PMs).The proposed CAD system makes use of the 3-dimensional (3D) information in DTM to improve mass detection and characterization. The innovations in the proposed project include: (1) development of new computer-vision techniques to exploit the 3D volumetric information in DTMs, (2) evaluation of the dependence of CAD performance on reconstruction algorithms, and (3) comparison of computerized mass detection and characterization in DTMs, projection view mammograms (PVs) (the non-reconstructed mammograms taken at multiple angles during tomosynthesis imaging), and PMs. We hypothesize that detection and characterization of masses on DTMs will be more accurate than corresponding tasks on regular PMs, and that the CAD systems can improve radiologists' accuracy. 3D breast phantoms with test objects will be designed and imaged with a prototype DTM system. The dependence of DTM image quality on reconstruction algorithms and their parameters, and on image acquisition techniques will be studied. The appropriate reconstruction techniques will be selected based on phantom and patient studies. A database of DTMs and corresponding PMs with malignant and benign masses and a set of normal cases will be collected with patient informed consent. CAD systems for detection and classification of masses will be developed. Two approaches will be compared: one uses the reconstructed DTM slices and the other uses the PVs as input to the CAD systems. For the DTMs, new techniques for 3D preprocessing, image segmentation, feature extraction, and feature classification will be designed. For the PVs, our previous techniques developed for regular PMs will be adapted to these low- dose images, and information fusion methods using techniques such as neural networks or support vector machines will be developed to merge the multiple-PV information. To test our hypotheses, we will compare the CAD system performances from these two approaches and that from the corresponding regular PMs, and conduct observer ROC studies to evaluate effects of the CAD systems on radiologists' performance. CAD will be an important tool that can help accelerate the implementation of DTM in clinical practice. DTM with CAD is expected to help fully utilize the potential of this new modality to improve breast cancer detection.           n/a",Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses,7668403,R33CA120234,"['3-Dimensional', 'Abbreviations', 'Algorithms', 'Benign', 'Biological Neural Networks', 'Breast', 'Breast Cancer Detection', 'Classification', 'Collection', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Database Management Systems', 'Databases', 'Dependence', 'Detection', 'Development', 'Diagnosis', 'Doctor of Philosophy', 'Dose', 'Evaluation', 'Goals', 'Image', 'Imaging Phantoms', 'Informed Consent', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Mammography', 'Mass in breast', 'Methods', 'Modality', 'Patients', 'Performance', 'Phase', 'Process', 'Reading', 'Research', 'Research Personnel', 'Slice', 'Specific qualifier value', 'Staging', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'base', 'clinical practice', 'computerized', 'design', 'digital', 'experience', 'graphical user interface', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'programs', 'prototype', 'radiologist', 'reconstruction', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R33,2009,389926,0.007410604484079264
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7739714,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2009,104963,0.0095044834593412
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7747873,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2009,350000,0.015425397092128246
"Improving Breast Cancer Detection and Diagnosis with CAD    DESCRIPTION (provided by applicant): Computer-aided detection (CAD) of breast cancer is rapidly becoming a well accepted clinical practice. Studies have found that radiologists' attitude toward and acceptance of CAD-cued micro-calcification clusters and masses were substantially different. Due to the high sensitivity, radiologists heavily rely on CAD-cued results while searching for micro-calcifications. However, the lower CAD sensitivity for mass detection (including a fraction of subtle masses being cued only on one view) and the higher false-positive detection (FP) rates reduce radiologists' confidence in CAD-cued masses. As a result, radiologists frequently discard CAD-cued subtle masses in the clinical practice. To improve CAD performance and increase radiologists' confidence in using CAD-cued masses in their decision making, we propose two observer-focused innovative approaches to develop and optimize CAD schemes. By maintaining a comparable FP rate to current commercial CAD systems, the new approaches aim to either increase the number of masses being cued on both ipsilateral (CC and MLO) views or cue more subtle masses by eliminating a fraction of other regions that can be easily identified and classified by radiologists without using CAD. To test these approaches, we propose three specific tasks. First, we will develop a unique multi-view based CAD scheme. To more sensitively detect and better match subtle mass regions, we introduce a concept of limited viewing of specific regions into the arena of CAD development. After detecting a matching strip on the ipsolateral view, the scheme applies a second highly sensitive detection scheme only to this strip to identify matched regions. To control for and reduce FP rates, the scheme limits the number of possible matched candidates to less than one per image. Second, we will develop an integrated CAD scheme that includes a combined score for both detection and classification. To improve direct use of features computed by the detection module in the classification task, we will apply a new dual active contour algorithm that should improve mass region segmentation. We will separately optimize two machine learning classifiers to generate a detection score (the likelihood of being a true-positive mass) and a classification score (the likelihood of each detected mass for malignancy) for each segmented region. We will then develop a fusion method to combine these two scores and generate a new summary index that is more heavily weighted for subtle masses. Using this scheme, we can change the current mass detection based cuing method to a new cancer-based cueing method. Third, we will conduct a pilot observer performance study to investigate radiologists' performance under three CADcueing modes (using the current commercial single-image based, the new multi-view based, and the new integrated CAD schemes). The reading results will be compared and analyzed using both ROC and JAFROC methodologies. We note that the approach is substantially different than focusing on incremental improvements in image based detection schemes in that the observer's actual use (or not) of the CADcued regions drives our objectives in this project, resulting in a targeted development effort.          n/a",Improving Breast Cancer Detection and Diagnosis with CAD,7617655,R01CA077850,"['Algorithms', 'Area', 'Attention', 'Attitude', 'Benign', 'Breast', 'Breast Cancer Detection', 'Cancer Detection', 'Classification', 'Clinical', 'Computer Assisted', 'Cues', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Environment', 'Eye', 'Genetic Programming', 'Hybrids', 'Image', 'Investigation', 'Ipsilateral', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Perception', 'Performance', 'Play', 'Process', 'Reading', 'Reporting', 'Research', 'Role', 'Scheme', 'Specific qualifier value', 'System', 'Testing', 'Time', 'Weight', 'Work', 'base', 'calcification', 'clinical practice', 'follow-up', 'improved', 'indexing', 'innovation', 'novel strategies', 'radiologist', 'visual search']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,246949,0.029052791524308362
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,7730016,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Cade', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer Systems Development', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hand', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Knowledge', 'Label', 'Lead', 'Learning', 'Left', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'public health relevance', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,347642,0.053159090833232336
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7641582,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Classification', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,UNIVERSITY OF MISSOURI KANSAS CITY,R21,2009,219972,0.013819768845911483
"Accurate detection of chromosomal abnormalities with multi-color image processing    DESCRIPTION (provided by applicant): The combination of high resolution assays in genomics with microscopic imaging has been used for the detection of complex chromosomal rearrangements, a significant but difficult problem in prenatal and postnatal diagnosis, birth defect detection and cancer research. As a recently developed molecular cytogenetic technique, multiplex fluorescence in situ hybridization (M-FISH) imaging has provided rapid and high resolution detection of chromosomal abnormalities associated with cancer and genetic disorders. However, the technique is currently limited to research use and only serves as an adjunct tool to the G-banding based monochromatic chromosomal karyotyping in a clinical laboratory. A primary barrier of the technique is the lower classification accuracy when classifying chromosomes from multi-color microscopic imaging data. Therefore, the goal of this R15 project is to develop innovative multi-spectral image processing and machine learning techniques for M-FISH image analysis so that chromosomal rearrangement detection can be made more reproducible, robust, and faster, thereby significantly increasing the ability and efficacy of this newly developed cellular imaging technique. Our proposed approaches such as multiscale feature extraction, nonlinear manifold analysis and adaptive fuzzy clustering are able to target specific features of multi-spectral imaging data, promising a significant improvement over the current techniques. In order to validate the technique and bring it into clinical use, we will partner with a clinical geneticist, Dr. Merlin Butler, and a cytogeneticist, Dr. Diane Persons both at Kansas University Medical Center. In addition, we will collaborate with an industrial scientist, Dr. Kenneth Castleman, who is the pioneer in developing and commercializing cytogenetic imaging products. Through our interdisciplinary research and collaboration, we will accomplish the following specific aims: 1) develop image normalization approaches to improve the acquisition of multi-color FISH images; 2) develop multiscale dimension analysis to extract features from multi-color images; 3) design adaptive fuzzy clustering and incorporate contextual information to improve the pixel-wise classification of chromosomes; and 4) validate computational approaches with clinical testing in collaboration with medical and industrial partners. This research project will also enhance our research infrastructure in biomedical image informatics and provide undergraduate and graduate students opportunities to touch the frontier of molecular and cellular imaging by participating in the proposed research activities. PUBLIC HEALTH RELEVANCE: Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.           Project Narrative Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.",Accurate detection of chromosomal abnormalities with multi-color image processing,7727717,R15GM088802,"['Academic Medical Centers', 'Academic Research Enhancement Awards', 'Address', 'Algorithms', 'Biological Assay', 'Cells', 'Chromosomal Rearrangement', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 4', 'Cities', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Color', 'Communities', 'Complex', 'Computational Technique', 'Congenital Abnormality', 'Cytogenetic Analysis', 'Cytogenetics', 'DNA Sequence Rearrangement', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Engineering', 'Environment', 'Figs - dietary', 'Fluorescent in Situ Hybridization', 'G-Banding', 'Genetic', 'Genomics', 'Goals', 'Health Benefit', 'Hereditary Disease', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging problem', 'Interdisciplinary Study', 'Kansas', 'Karyotype', 'Karyotype determination procedure', 'Laboratories', 'Learning', 'Machine Learning', 'Masks', 'Medical', 'Methods', 'Microscopic', 'Missouri', 'Molecular Probes', 'Neurofibromin 2', 'Patients', 'Persons', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Project Grants', 'Resolution', 'Resources', 'Schools', 'Scientist', 'Signal Transduction', 'Spectral Karyotyping', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Training', 'United States National Institutes of Health', 'Universities', 'anticancer research', 'assay development', 'base', 'bioimaging', 'cancer diagnosis', 'cancer genetics', 'cellular imaging', 'clinical application', 'clinical effect', 'design', 'experience', 'frontier', 'graduate student', 'high throughput screening', 'image processing', 'imaging informatics', 'improved', 'innovation', 'leukemia', 'meetings', 'molecular/cellular imaging', 'multidisciplinary', 'novel', 'postnatal', 'prenatal', 'prevent', 'programs', 'public health relevance', 'research clinical testing', 'response', 'tool']",NIGMS,UNIVERSITY OF MISSOURI KANSAS CITY,R15,2009,229519,0.02907221688151491
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7837005,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,229517,0.041987976750380844
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7585774,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,411032,0.041987976750380844
"A computer aided chromosome imaging technique for cancer diagnosis    DESCRIPTION (provided by applicant): Identification of recurrent chromosomal aberrations is important for diagnosis, prognosis, and therapy of most hematological malignancies. Due to difficulties with culture of tumor cells, low mitotic index, poor chromosomal morphologies, and low prevalence, it takes tremendous effort and time for a cytogenetic clinician to obtain a sufficient number of analyzable metaphase cells under microscope before he/she can make an accurate clinical diagnosis. This process is not only very inefficient but also subject to human errors. In order to improve the efficiency and accuracy of leukemia diagnosis, we propose to develop a computer aided chromosome imaging technique. Specifically, we will develop an innovative high-speed microscopic imaging system based on a time-delay-integration technique. The system can scan the entire sample-slide at high magnification to obtain high resolution digital images to reveal metaphase chromosomes as required by clinical diagnosis. We will also develop a novel computer aided diagnosis (CAD) scheme including four specific modules to (1) detect analyzable metaphase chromosome cells, (2) segment overlapped chromosomes, (3) identify and classify distorted chromosomes associated with cancer cells, and (4) predict the cancer prognosis. After identification and segmentation of analyzable chromosomes, we will compute and search for the effective and robust image features. Genetic algorithm will be used to train and optimize an artificial neural network and a Bayesian belief network for the classification and prediction tasks, respectively. Using the integrated CAD workstation, we will conduct an observer performance study to assess the performance of the technique and its clinical feasibility. In summary, the proposed imaging technique is highly efficient, and no or only minimal human interventions are required from initial slide-scanning up to the presentation of CAD results. With such a new computerized clinical tool, cytogeneticists can effectively focus their efforts on analyzing/verifying chromosomal abnormal patterns and making final diagnostic decisions. It is therefore expected that the proposed technology can significantly improve the efficiency and accuracy of cancer (i.e., leukemia) diagnosis. The proposed technique has significant clinical potentials in monitoring therapeutic efficacy of cancer treatment as well.          n/a",A computer aided chromosome imaging technique for cancer diagnosis,7609064,R01CA115320,"['Algorithms', 'Belief', 'Biological Neural Networks', 'Cancer Prognosis', 'Cells', 'Chromosome Pairing', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 3', 'Classification', 'Clinical', 'Computer Assisted', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Congenital chromosomal disease', 'Cultured Tumor Cells', 'Custom', 'Cytogenetics', 'Databases', 'Deletion Mutation', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Effectiveness', 'Future', 'Genetic', 'Genetic Programming', 'Graph', 'Hematologic Neoplasms', 'Hour', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Label', 'Laboratories', 'Location', 'Low Prevalence', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Metaphase', 'Methods', 'Microscope', 'Microscopic', 'Molecular', 'Monitor', 'Morphology', 'Normal Cell', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Receiver Operating Characteristics', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'S-Phase Fraction', 'Sampling', 'Scanning', 'Scheme', 'Skin', 'Slide', 'Solutions', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Treatment Efficacy', 'base', 'cancer cell', 'cancer diagnosis', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinical application', 'computerized', 'design', 'detector', 'digital imaging', 'experience', 'improved', 'innovation', 'interest', 'leukemia', 'malignant breast neoplasm', 'novel', 'outcome forecast', 'programs', 'tool', 'user-friendly']",NCI,UNIVERSITY OF OKLAHOMA NORMAN,R01,2009,308319,0.0050711532481939586
"Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is one of leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include (1) collecting a large data set to develop and evaluate our CAD algorithms and systems, (2) establishing ""gold standard"" for performance evaluation, (3) developing robust pulmonary vessel segmentation methods, (4) developing robust pulmonary vessel tree reconstruction method to accurately track pulmonary vessels, trim veins and surrounding extensive lung diseases from vessel tree, and label reconstructed arterial tree, (5) developing and improving PE detection algorithms, including multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, PE features extraction for development of classification methods, false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) developing automatic PE index estimation method, (7) exploring performance evaluation methodology for computerized detection of PEs, and (8) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. PUBLIC HEALTH RELEVANCE: The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.            The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.",Computer-aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,7730533,R01HL092044,"['Affect', 'Algorithms', 'Angiography', 'Archives', 'Arteries', 'Benign', 'Biological Neural Networks', 'Blood Vessels', 'Cause of Death', 'Characteristics', 'Classification', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Evaluation', 'Evaluation Methodology', 'Goals', 'Gold', 'Image', 'Interobserver Variability', 'Label', 'Location', 'Lung', 'Lung diseases', 'Malignant - descriptor', 'Methods', 'Morbidity - disease rate', 'Patients', 'Performance', 'Public Health', 'Pulmonary Embolism', 'Pulmonary vessels', 'Reading', 'Recovery', 'Reporting', 'Research', 'Scanning', 'Scheme', 'Screening procedure', 'Second Opinions', 'Seeds', 'Slice', 'Speed', 'Structure', 'Structure of parenchyma of lung', 'System', 'Techniques', 'Testing', 'TimeLine', 'Training', 'Trees', 'United States', 'Veins', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computerized', 'design', 'improved', 'indexing', 'mortality', 'public health relevance', 'radiologist', 'reconstruction', 'soft tissue']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2009,497626,0.05540148709807646
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,0.012521572902688185
"Multimodality CAD system with image references for breast mass characterization    DESCRIPTION (provided by applicant): The long term goal of the project is to develop an effective computer-aided diagnosis (CAD) system to assist radiologists in making diagnostic decisions in breast imaging. In this proposed project, we will concentrate on the characterization of masses using mammograms and ultrasound images. We propose a new approach to CAD based on a classifier that can simultaneously estimate the likelihood of malignancy for the mass and retrieve similar cases from a large library of cases with known diagnosis for the radiologist's references. The new CAD system thus combines the advantages of a rating-based and an image-retrieval- based CAD system. It will aid radiologists not only by the malignancy estimate but also by enhancing their similarity-based decision making process. We will also design a relevance feedback image retrieval system that allows the radiologist to interactively and efficiently retrieve similar cases from a large data set as a tool to help develop the automated CAD system. We hypothesize that the reference images will increase the characterization accuracy of less experienced readers for masses, and that the computerized classification and image retrieval system to be developed in this study will significantly improve radiologists' accuracy. To test these hypotheses, we will perform the following specific tasks: (1) collect a database of sonograms and mammograms containing masses; (2) extract features for mass characterization; (3) develop decision tree and k-nearest neighbor classifiers, compare decision tree training with and without boosting, and investigate methods for the retrieval of similar cases based on the developed classifiers; (4) develop a relevance feedback image retrieval method; (5) compare the performances of less experienced radiologists without and with aid by reference images retrieved by experienced radiologists; and (6) compare radiologists' performances without and with the fully-automated classification and image-retrieval CAD system by a receiver operating characteristic (ROC) study. If successfully developed, the CAD system may not only reduce benign biopsies, but also reduce the variation in interpretation between experienced and less experienced radiologists. The relevance of this project to public health is that 70-85% of breast biopsies are performed for benign lesions. Any reduction in this number without a decrease in breast cancer detection sensitivity will decrease health care costs, as well as contribute to the well-being of the patient by reducing anxiety and morbidity.           n/a",Multimodality CAD system with image references for breast mass characterization,7677385,R33CA118305,"['Address', 'Anxiety', 'Benign', 'Biopsy', 'Breast', 'Breast Cancer Detection', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Computers', 'Data Set', 'Databases', 'Decision Making', 'Decision Trees', 'Diagnosis', 'Diagnostic', 'Feedback', 'Goals', 'Health Care Costs', 'Image', 'Image retrieval system', 'Label', 'Lesion', 'Libraries', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Methods', 'Morbidity - disease rate', 'Patients', 'Performance', 'Personal Satisfaction', 'Phase', 'Process', 'Public Health', 'Reader', 'Receiver Operating Characteristics', 'Research', 'Retrieval', 'System', 'Testing', 'TimeLine', 'Training', 'Ultrasonography', 'Variant', 'base', 'case-based', 'computerized', 'design', 'digital imaging', 'experience', 'improved', 'innovation', 'multimodality', 'novel strategies', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R33,2009,307479,0.0074521374083219485
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7686733,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2009,819428,0.045249201997225354
"Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S    DESCRIPTION (provided by applicant): Magnetic Resonance imaging (MRI) is a powerful imaging tool but many important clinical applications are limited by long scan times and/or poor SNR. This proposal aims to improve the speed of MRI without losing SNR, through a Bayesian inference approach. Improvement in scan speed can enable new time-critical clinical and diagnostic MR applications, like cardiac imaging, time-resolved 4D coronary angiography, high-resolution volumetric brain imaging, dynamic contrast enhanced imaging, etc. A Bayesian framework for the reconstruction of raw MR data from multiple coils in parallel will be developed. This framework makes it possible to reduce the time taken during scanning multiple times by reducing the sampling rate of raw MR data. Our method will be generally applicable to most MR imaging modalities, targets and sampling schemes. Our method will then be validated and tested on the specific clinical application of volumetric structural brain imaging, which is an important procedure for the detection and diagnosis of neurodegenerative diseases, tumors, white matter lesions, measuring brain atrophy and hippocampal subfields, etc. The main goal of this project is to create a set of computational tools to perform the reconstruction of accelerated MRI data on arbitrary imaging targets, modalities and acquisition schemes, including random sampling schemes. Design of models to capture prior spatial information about images will be undertaken. Finally, the method will be validated on structural brain data in terms of metrics like SNR, partial voluming, test- retest repeatability, and the performance of subsequent processing steps like image segmentation. PUBLIC HEALTH RELEVANCE: This project has the potential to make clinical MR imaging much faster than currently possible. This will make many time-critical clinical applications of MRI more feasible, for instance real-time MRI of the heart. The resolving power of MRI to image finer, clinically interesting anatomical features will also increase, making more reliable diagnosis possible.          n/a",Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S,7688029,R21EB008138,"['Acceleration', 'Address', 'Algorithms', 'Anatomy', 'Brain', 'Brain Diseases', 'Brain imaging', 'Breathing', 'Cardiac', 'Clinical', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Coronary Angiography', 'Data', 'Data Quality', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Drug Formulations', 'Future', 'Generic Drugs', 'Goals', 'Graph', 'Heart', 'Hippocampus (Brain)', 'Image', 'Imaging Device', 'Imaging Techniques', 'Knowledge', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Metric', 'Modality', 'Modification', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Problem Solving', 'Procedures', 'Process', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Weight', 'Work', 'base', 'cerebral atrophy', 'clinical application', 'combinatorial', 'computerized data processing', 'computerized tools', 'design', 'expectation', 'heart motion', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'in vivo', 'interest', 'model design', 'nervous system disorder', 'public health relevance', 'reconstruction', 'simulation', 'tumor', 'white matter']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2009,211250,0.004409590163051674
"Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses    DESCRIPTION (provided by applicant): Digital tomosynthesis mammography (DTM) is a new modality that holds the promise of improving mammographic sensitivity of breast cancer detection and diagnosis, especially for dense breasts. The main goals of the proposed research are (1) to develop a computer-aided detection (CADd) system for breast masses in DTM, (2) to develop a computer-aided diagnosis (CADx) system for classification of malignant and benign masses in DTM, and (3) to evaluate the effects of CAD (either CADd or CADx) on radiologists' interpretation of DTMs. Previous CAD systems are developed for regular projection mammograms (PMs).The proposed CAD system makes use of the 3-dimensional (3D) information in DTM to improve mass detection and characterization. The innovations in the proposed project include: (1) development of new computer-vision techniques to exploit the 3D volumetric information in DTMs, (2) evaluation of the dependence of CAD performance on reconstruction algorithms, and (3) comparison of computerized mass detection and characterization in DTMs, projection view mammograms (PVs) (the non-reconstructed mammograms taken at multiple angles during tomosynthesis imaging), and PMs. We hypothesize that detection and characterization of masses on DTMs will be more accurate than corresponding tasks on regular PMs, and that the CAD systems can improve radiologists' accuracy. 3D breast phantoms with test objects will be designed and imaged with a prototype DTM system. The dependence of DTM image quality on reconstruction algorithms and their parameters, and on image acquisition techniques will be studied. The appropriate reconstruction techniques will be selected based on phantom and patient studies. A database of DTMs and corresponding PMs with malignant and benign masses and a set of normal cases will be collected with patient informed consent. CAD systems for detection and classification of masses will be developed. Two approaches will be compared: one uses the reconstructed DTM slices and the other uses the PVs as input to the CAD systems. For the DTMs, new techniques for 3D preprocessing, image segmentation, feature extraction, and feature classification will be designed. For the PVs, our previous techniques developed for regular PMs will be adapted to these low- dose images, and information fusion methods using techniques such as neural networks or support vector machines will be developed to merge the multiple-PV information. To test our hypotheses, we will compare the CAD system performances from these two approaches and that from the corresponding regular PMs, and conduct observer ROC studies to evaluate effects of the CAD systems on radiologists' performance. CAD will be an important tool that can help accelerate the implementation of DTM in clinical practice. DTM with CAD is expected to help fully utilize the potential of this new modality to improve breast cancer detection.           n/a",Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses,7500088,R33CA120234,"['3-Dimensional', 'Abbreviations', 'Algorithms', 'Benign', 'Biological Neural Networks', 'Breast', 'Breast Cancer Detection', 'Classification', 'Clinical', 'Collection', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Database Management Systems', 'Databases', 'Dependence', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Doctor of Philosophy', 'Dose', 'Evaluation', 'Goals', 'Image', 'Imaging Phantoms', 'Informed Consent', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Mammography', 'Mass in breast', 'Methods', 'Modality', 'Patients', 'Performance', 'Phase', 'Process', 'Reading', 'Research', 'Research Personnel', 'Slice', 'Specific qualifier value', 'Staging', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'base', 'computerized', 'design', 'digital', 'experience', 'graphical user interface', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'programs', 'prototype', 'radiologist', 'reconstruction', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R33,2008,379995,0.007410604484079264
"Improving Breast Cancer Detection and Diagnosis with CAD    DESCRIPTION (provided by applicant): Computer-aided detection (CAD) of breast cancer is rapidly becoming a well accepted clinical practice. Studies have found that radiologists' attitude toward and acceptance of CAD-cued micro-calcification clusters and masses were substantially different. Due to the high sensitivity, radiologists heavily rely on CAD-cued results while searching for micro-calcifications. However, the lower CAD sensitivity for mass detection (including a fraction of subtle masses being cued only on one view) and the higher false-positive detection (FP) rates reduce radiologists' confidence in CAD-cued masses. As a result, radiologists frequently discard CAD-cued subtle masses in the clinical practice. To improve CAD performance and increase radiologists' confidence in using CAD-cued masses in their decision making, we propose two observer-focused innovative approaches to develop and optimize CAD schemes. By maintaining a comparable FP rate to current commercial CAD systems, the new approaches aim to either increase the number of masses being cued on both ipsilateral (CC and MLO) views or cue more subtle masses by eliminating a fraction of other regions that can be easily identified and classified by radiologists without using CAD. To test these approaches, we propose three specific tasks. First, we will develop a unique multi-view based CAD scheme. To more sensitively detect and better match subtle mass regions, we introduce a concept of limited viewing of specific regions into the arena of CAD development. After detecting a matching strip on the ipsolateral view, the scheme applies a second highly sensitive detection scheme only to this strip to identify matched regions. To control for and reduce FP rates, the scheme limits the number of possible matched candidates to less than one per image. Second, we will develop an integrated CAD scheme that includes a combined score for both detection and classification. To improve direct use of features computed by the detection module in the classification task, we will apply a new dual active contour algorithm that should improve mass region segmentation. We will separately optimize two machine learning classifiers to generate a detection score (the likelihood of being a true-positive mass) and a classification score (the likelihood of each detected mass for malignancy) for each segmented region. We will then develop a fusion method to combine these two scores and generate a new summary index that is more heavily weighted for subtle masses. Using this scheme, we can change the current mass detection based cuing method to a new cancer-based cueing method. Third, we will conduct a pilot observer performance study to investigate radiologists' performance under three CADcueing modes (using the current commercial single-image based, the new multi-view based, and the new integrated CAD schemes). The reading results will be compared and analyzed using both ROC and JAFROC methodologies. We note that the approach is substantially different than focusing on incremental improvements in image based detection schemes in that the observer's actual use (or not) of the CADcued regions drives our objectives in this project, resulting in a targeted development effort.          n/a",Improving Breast Cancer Detection and Diagnosis with CAD,7522346,R01CA077850,"['Algorithms', 'Area', 'Attention', 'Attitude', 'Benign', 'Breast', 'Breast Cancer Detection', 'Cancer Detection', 'Classification', 'Clinical', 'Computer Assisted', 'Cues', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Environment', 'Eye', 'Genetic Programming', 'Hybrids', 'Image', 'Institution', 'Investigation', 'Ipsilateral', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Numbers', 'Perception', 'Performance', 'Play', 'Process', 'Purpose', 'Rate', 'Reading', 'Reporting', 'Research', 'Role', 'Scheme', 'Score', 'Specific qualifier value', 'System', 'Testing', 'Time', 'Weight', 'Work', 'base', 'calcification', 'concept', 'desire', 'follow-up', 'improved', 'indexing', 'innovation', 'novel strategies', 'radiologist']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,247081,0.029052791524308362
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7480255,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2008,89733,-0.004030902659353899
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7496032,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2008,189850,0.03829187026306417
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7355521,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Class', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Pliability', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Score', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'desire', 'experience', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2008,431744,0.041987976750380844
"A computer aided chromosome imaging technique for cancer diagnosis    DESCRIPTION (provided by applicant): Identification of recurrent chromosomal aberrations is important for diagnosis, prognosis, and therapy of most hematological malignancies. Due to difficulties with culture of tumor cells, low mitotic index, poor chromosomal morphologies, and low prevalence, it takes tremendous effort and time for a cytogenetic clinician to obtain a sufficient number of analyzable metaphase cells under microscope before he/she can make an accurate clinical diagnosis. This process is not only very inefficient but also subject to human errors. In order to improve the efficiency and accuracy of leukemia diagnosis, we propose to develop a computer aided chromosome imaging technique. Specifically, we will develop an innovative high-speed microscopic imaging system based on a time-delay-integration technique. The system can scan the entire sample-slide at high magnification to obtain high resolution digital images to reveal metaphase chromosomes as required by clinical diagnosis. We will also develop a novel computer aided diagnosis (CAD) scheme including four specific modules to (1) detect analyzable metaphase chromosome cells, (2) segment overlapped chromosomes, (3) identify and classify distorted chromosomes associated with cancer cells, and (4) predict the cancer prognosis. After identification and segmentation of analyzable chromosomes, we will compute and search for the effective and robust image features. Genetic algorithm will be used to train and optimize an artificial neural network and a Bayesian belief network for the classification and prediction tasks, respectively. Using the integrated CAD workstation, we will conduct an observer performance study to assess the performance of the technique and its clinical feasibility. In summary, the proposed imaging technique is highly efficient, and no or only minimal human interventions are required from initial slide-scanning up to the presentation of CAD results. With such a new computerized clinical tool, cytogeneticists can effectively focus their efforts on analyzing/verifying chromosomal abnormal patterns and making final diagnostic decisions. It is therefore expected that the proposed technology can significantly improve the efficiency and accuracy of cancer (i.e., leukemia) diagnosis. The proposed technique has significant clinical potentials in monitoring therapeutic efficacy of cancer treatment as well.          n/a",A computer aided chromosome imaging technique for cancer diagnosis,7423851,R01CA115320,"['Algorithms', 'Belief', 'Biological Neural Networks', 'Cancer Prognosis', 'Cells', 'Chromosome Pairing', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 3', 'Classification', 'Clinical', 'Computer Assisted', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Congenital chromosomal disease', 'Cultured Tumor Cells', 'Custom', 'Cytogenetics', 'Databases', 'Deletion Mutation', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Effectiveness', 'Future', 'Genetic', 'Genetic Programming', 'Graph', 'Hematologic Neoplasms', 'Hour', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Label', 'Laboratories', 'Location', 'Low Prevalence', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Metaphase', 'Methods', 'Microscope', 'Microscopic', 'Molecular', 'Monitor', 'Morphology', 'Normal Cell', 'Numbers', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Rate', 'Receiver Operating Characteristics', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'S-Phase Fraction', 'Sampling', 'Scanning', 'Scheme', 'Skin', 'Slide', 'Solutions', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Treatment Efficacy', 'base', 'cancer cell', 'cancer diagnosis', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinical application', 'computerized', 'concept', 'day', 'design', 'detector', 'digital imaging', 'experience', 'improved', 'innovation', 'interest', 'leukemia', 'malignant breast neoplasm', 'novel', 'outcome forecast', 'programs', 'size', 'tool', 'user-friendly']",NCI,UNIVERSITY OF OKLAHOMA NORMAN,R01,2008,312688,0.0050711532481939586
"In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE)    DESCRIPTION (provided by applicant): Fluorescence-based molecular Imaging in small animals is having a major impact on drug development and disease research. However, a significant challenge to imaging targeted fluorescent markers in vivo remains: unless the labeled regions are located superficially; localization, quantitation and host organ identification are impeded by the effects of light scattering and absorption. Orthotopic tumor and disease models are increasingly preferred over less biologically relevant subcutaneous xenografts. In such studies, substantial difficulties are encountered in longitudinal studies where animals are growing and are positioned differently for each measurement. We believe that a single imaging advance could address many of these issues, and advance the utility of in-vivo molecular imaging: an exact anatomical co-registration technique that does not rely on multimodal techniques. This proposal describes dynamic molecular imaging (DMI), an approach that can provide co-registered anatomical information by exploiting in-vivo pharmacokinetics of dyes in small animals in a simple and inexpensive way. We demonstrate that by acquiring a time-series of optical images during injection of an inert dye, we can repeatably and accurately delineate the major internal organs of mice using optical imaging alone. This is possible because each major organ is ""illuminated"" by the kinetics of dye passing through it in such a manner as to make it distinguishable from other structures. Spatiotemporal analysis can exploit these characteristic time courses to allow the body-surface representation of each organ to be visualized. These in- vivo anatomical maps can be overlaid onto simultaneously acquired images of a targeted molecular probe (detected and distinguished from the mapping dye via multispectral imaging techniques, if necessary) to significantly aid in identification of the probe's anatomical and physical location. Using CRi's existing and prototype 2D, ""2.5D"" and true 3D multispectral mouse imaging systems, we propose to test and refine a DMI approach. Based on our findings to date, we will examine and exploit in-vivo pharmacokinetics of the near-infrared dye, indocyanine green, to generate delineated surface projections of individual organs. Co-registering this surface map with surface projections of detected targeted labels will allow the targeted probe's 3D spatial location to be inferred. This information can further be used to improve quantitative accuracy in longitudinal molecular imaging studies of deep targets.           n/a",In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE),7485551,R43EB008627,"['Address', 'Adoption', 'Algorithms', 'Anatomy', 'Animals', 'Automatic Data Processing', 'Back', 'Basic Science', 'Body Surface', 'Bolus Infusion', 'Characteristics', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Contrast Media', 'Data', 'Data Display', 'Depth', 'Detection', 'Development', 'Disease', 'Disease model', 'Drug Kinetics', 'Dyes', 'Fluorescence', 'General Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Indocyanine Green', 'Injection of therapeutic agent', 'Kinetics', 'Label', 'Legal patent', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Massachusetts', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Probes', 'Mus', 'Nature', 'Optics', 'Organ', 'Paper', 'Performance', 'Physiological', 'Positioning Attribute', 'Protocols documentation', 'Purpose', 'Range', 'Research', 'Research Personnel', 'Retrieval', 'Series', 'Signal Transduction', 'Small Animal Imaging Systems', 'Software Tools', 'Solutions', 'Source', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'Tissues', 'Validation', 'Variant', 'Virginia', 'Visualization software', 'X-Ray Computed Tomography', 'Xenograft procedure', 'absorption', 'base', 'blind', 'data acquisition', 'drug development', 'drug discovery', 'experience', 'hemodynamics', 'image reconstruction', 'improved', 'in vivo', 'instrumentation', 'light scattering', 'longitudinal animal study', 'millimeter', 'molecular imaging', 'novel strategies', 'optical imaging', 'photonics', 'prototype', 'response', 'spatiotemporal', 'subcutaneous', 'tumor']",NIBIB,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R43,2008,167462,-0.019101912777282334
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,0.012521572902688185
"Multimodality CAD system with image references for breast mass characterization    DESCRIPTION (provided by applicant): The long term goal of the project is to develop an effective computer-aided diagnosis (CAD) system to assist radiologists in making diagnostic decisions in breast imaging. In this proposed project, we will concentrate on the characterization of masses using mammograms and ultrasound images. We propose a new approach to CAD based on a classifier that can simultaneously estimate the likelihood of malignancy for the mass and retrieve similar cases from a large library of cases with known diagnosis for the radiologist's references. The new CAD system thus combines the advantages of a rating-based and an image-retrieval- based CAD system. It will aid radiologists not only by the malignancy estimate but also by enhancing their similarity-based decision making process. We will also design a relevance feedback image retrieval system that allows the radiologist to interactively and efficiently retrieve similar cases from a large data set as a tool to help develop the automated CAD system. We hypothesize that the reference images will increase the characterization accuracy of less experienced readers for masses, and that the computerized classification and image retrieval system to be developed in this study will significantly improve radiologists' accuracy. To test these hypotheses, we will perform the following specific tasks: (1) collect a database of sonograms and mammograms containing masses; (2) extract features for mass characterization; (3) develop decision tree and k-nearest neighbor classifiers, compare decision tree training with and without boosting, and investigate methods for the retrieval of similar cases based on the developed classifiers; (4) develop a relevance feedback image retrieval method; (5) compare the performances of less experienced radiologists without and with aid by reference images retrieved by experienced radiologists; and (6) compare radiologists' performances without and with the fully-automated classification and image-retrieval CAD system by a receiver operating characteristic (ROC) study. If successfully developed, the CAD system may not only reduce benign biopsies, but also reduce the variation in interpretation between experienced and less experienced radiologists. The relevance of this project to public health is that 70-85% of breast biopsies are performed for benign lesions. Any reduction in this number without a decrease in breast cancer detection sensitivity will decrease health care costs, as well as contribute to the well-being of the patient by reducing anxiety and morbidity.           n/a",Multimodality CAD system with image references for breast mass characterization,7665198,R33CA118305,"['Anxiety', 'Benign', 'Biopsy', 'Breast', 'Breast Cancer Detection', 'Classification', 'Computer-Assisted Diagnosis', 'Data Set', 'Databases', 'Decision Making', 'Decision Trees', 'Diagnosis', 'Diagnostic', 'Feedback', 'Goals', 'Health Care Costs', 'Image', 'Image retrieval system', 'Lesion', 'Libraries', 'Malignant Neoplasms', 'Mammography', 'Methods', 'Morbidity - disease rate', 'Multimodal Imaging', 'Numbers', 'Patients', 'Performance', 'Personal Satisfaction', 'Process', 'Public Health', 'Rate', 'Reader', 'Receiver Operating Characteristics', 'Retrieval', 'System', 'Testing', 'Training', 'Ultrasonography', 'Variant', 'base', 'case-based', 'computerized', 'design', 'experience', 'improved', 'novel strategies', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R33,2008,302577,0.0074521374083219485
"Developing Virtual Colonoscopy for Cancer Screening    DESCRIPTION (provided by applicant):    Colorectal carcinoma is the third most commonly diagnosed cancer and the second leading cause of death from cancer in the United States. Often it is diagnosed at an advanced stage, after the patient has developed symptoms, explaining its high mortality rate. Since most cancers arise from polyps over a 5 to 15 year period of malignant transformation, screening programs to detect small polyps less than 1 cm in diameter have been advocated. Unfortunately most people do not follow this recommendation. The health relatedness of this project is to dramatically increase the number of people willing to participate in screening programs by using a convenient, nearly risk-free procedure.      Virtual colonoscopy (VC) is a new procedure in which computed tomographic (CT) images of the patient's abdomen are taken and a computer visualization system is used to virtually navigate within a constructed 3-D image model of the colon, mimicking the current gold-standard optical colonoscopy (OC). The broad, long-term objective of this project is to develop VC as an accurate, cost-effective, minimalinvasive, least-stressful technique to screen large segments of the population.      To further advance this technology, the specific aims of this project renewal are: (1) to investigate low-dose CT techniques for VC towards massive screening of colonic polyps; (2) to extend electronic colon cleansing strategies to extract the colon mucosa layer by mixture-based image segmentation; (3) to investigate integrated feature-extraction techniques for polyp modeling towards computed aided detection (CAD) of colonic polyps; and (4) to extend our current real-time volume-rendering based navigation algorithms to include CAD and interactive virtual biopsy means for analysis of suspected abnormalities.      The research design and methodology will include evaluating from low-dose CT images the ability to electronically clean the colon lumen and extract the mucosa layer with less-stressful bowel preparation; the feasibility of bringing the technology to a readily accessible environment by documenting VC speed and quality with CAD and interactive virtual biopsy tools through the entire colon; and the accuracy by comparing virtual and optical colonoscopy polyp detection in the same patient using a pilot study.         n/a",Developing Virtual Colonoscopy for Cancer Screening,7429730,R01CA082402,"['Abdomen', 'Advocate', 'Affect', 'Algorithms', 'Area', 'Barium', 'Biopsy', 'Caliber', 'Cause of Death', 'Clinical', 'Colon', 'Colonic Polyps', 'Colonoscopy', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer software', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diatrizoate Meglumine', 'Diatrizoate Sodium', 'Dose', 'Effectiveness', 'Electronics', 'Ensure', 'Environment', 'Exposure to', 'Facility Construction Funding Category', 'Feces', 'Genus Cola', 'Gold', 'Health', 'Image', 'Imagery', 'Intervention', 'Intestines', 'Iodine', 'Laboratory Research', 'Large Intestine Carcinoma', 'Licensing', 'Liquid substance', 'Long Island', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Marketing', 'Methodology', 'Modality', 'Modeling', 'Morphologic artifacts', 'Mucous Membrane', 'Nature', 'Navigation System', 'Noise', 'Numbers', 'Optics', 'Patients', 'Physicians', 'Pilot Projects', 'Polishes', 'Polyps', 'Population', 'Preparation', 'Principal Investigator', 'Procedures', 'Progress Reports', 'Protocols documentation', 'Purpose', 'Radiation', 'Rate', 'Reading', 'Recommendation', 'Reporting', 'Research Design', 'Resolution', 'Risk', 'Scanning', 'Screening for cancer', 'Screening procedure', 'Second Primary Cancers', 'Slice', 'Solutions', 'Speed', 'Staging', 'Standards of Weights and Measures', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Tube', 'United States', 'Universities', 'Validation', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cost', 'data acquisition', 'density', 'detector', 'digital imaging', 'healthy volunteer', 'imaging Segmentation', 'improved', 'mortality', 'programs', 'prototype', 'radiologist', 'technology development', 'tool', 'virtual']",NCI,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2008,304959,0.028775158195644402
"Information-Theoretic Based CAD in Mammography DESCRIPTION (provided by applicant):    The purpose of the study is to develop and evaluate a novel computer-assisted decision (CAD) scheme for improving the clinical detection of breast masses in screening mammograms. The CAD scheme combines information-theoretic similarity metrics with knowledge-based decision algorithms. It will help radiologists scrutinize mammograms providing evidence-based decision support. Given a query mammographic region, the CAD system will interrogate a database of archived mammograms, examine similar eases, and assign a likelihood measure regarding the presence of a potentially malignant mass.  The study proposes the formulation of information-theoretic metrics to quantify the similarity of two mammographic regions. The similarity metrics are based on Sharmon's entropy; a measure of complexity (or information) contained in an image. Theoretically, if two mammographic regions depict similar structures, they should contain diagnostic information for each other. The amount of relevant diagnostic information can be measured by entropy-based similarity metrics that are computed directly from the images without requiring segmentation or feature extraction. Using the similarity metrics and an image databank of mammographic cases with known truth, a knowledge-bussed CAD scheme will be implemented for the detection of masses in screening mammograms. Preliminary studies have established that standard mutual information (MI) is an effective similarity metric for the task.  The specific aims of the study are: (1) To fully exploit information-theoretic metrics that measure the similar content of two mammographic regions, (2) To optimize their contributions in an evidence-based decision algorithm for the early detection of potentially malignant masses, and (3) To perform preliminary clinical evaluation of the CAD system.  As digital image libraries are an upcoming trend in radiology, the proposed CAD system will take advantage of continuously deposited mammograms with established ground truth. The system aims to reduce the interpretation error associated with screening mammograms and/or the false positives generated by cuing CAD schemes, Overall, the study aims to improve the sensitivity while maintaining or improving the specificity of screening mammography for masses. n/a",Information-Theoretic Based CAD in Mammography,7336275,R01CA101911,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Classification', 'Clinical', 'Computer Assisted', 'Computer Interface', 'Cues', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Drug Formulations', 'Early Diagnosis', 'Entropy', 'Image', 'Information Theory', 'Knowledge', 'Knowledge Base (Computer)', 'Libraries', 'Malignant - descriptor', 'Mammography', 'Mass in breast', 'Measures', 'Metric', 'Physicians', 'Purpose', 'Radiology Specialty', 'Scheme', 'Screening procedure', 'Specificity', 'Standards of Weights and Measures', 'Structure', 'System', 'Techniques', 'Uncertainty', 'base', 'concept', 'digital imaging', 'improved', 'knowledge base', 'novel', 'radiologist', 'research clinical testing', 'statistics', 'trend']",NCI,DUKE UNIVERSITY,R01,2008,230712,0.039984023008409364
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7467385,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2008,5140823,0.007738745322401967
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7494022,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2008,856688,0.045249201997225354
"Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S    DESCRIPTION (provided by applicant): Magnetic Resonance imaging (MRI) is a powerful imaging tool but many important clinical applications are limited by long scan times and/or poor SNR. This proposal aims to improve the speed of MRI without losing SNR, through a Bayesian inference approach. Improvement in scan speed can enable new time-critical clinical and diagnostic MR applications, like cardiac imaging, time-resolved 4D coronary angiography, high-resolution volumetric brain imaging, dynamic contrast enhanced imaging, etc. A Bayesian framework for the reconstruction of raw MR data from multiple coils in parallel will be developed. This framework makes it possible to reduce the time taken during scanning multiple times by reducing the sampling rate of raw MR data. Our method will be generally applicable to most MR imaging modalities, targets and sampling schemes. Our method will then be validated and tested on the specific clinical application of volumetric structural brain imaging, which is an important procedure for the detection and diagnosis of neurodegenerative diseases, tumors, white matter lesions, measuring brain atrophy and hippocampal subfields, etc. The main goal of this project is to create a set of computational tools to perform the reconstruction of accelerated MRI data on arbitrary imaging targets, modalities and acquisition schemes, including random sampling schemes. Design of models to capture prior spatial information about images will be undertaken. Finally, the method will be validated on structural brain data in terms of metrics like SNR, partial voluming, test- retest repeatability, and the performance of subsequent processing steps like image segmentation. PUBLIC HEALTH RELEVANCE: This project has the potential to make clinical MR imaging much faster than currently possible. This will make many time-critical clinical applications of MRI more feasible, for instance real-time MRI of the heart. The resolving power of MRI to image finer, clinically interesting anatomical features will also increase, making more reliable diagnosis possible.          n/a",Bayesian Parallel Imaging For Arbitrarily Sampled MR Data Using Edge-Preserving S,7528771,R21EB008138,"['Acceleration', 'Address', 'Algorithms', 'Anatomy', 'Blur', 'Brain', 'Brain Diseases', 'Brain imaging', 'Breathing', 'Cardiac', 'Class', 'Clinical', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Condition', 'Coronary Angiography', 'Data', 'Data Quality', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Drug Formulations', 'Future', 'Generic Drugs', 'Goals', 'Graph', 'Heart', 'Hippocampus (Brain)', 'Image', 'Imaging Device', 'Imaging Techniques', 'Knowledge', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Metric', 'Modality', 'Modification', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Noise', 'Numbers', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Problem Solving', 'Procedures', 'Process', 'Public Health', 'Pulse taking', 'Purpose', 'Range', 'Rate', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Specific qualifier value', 'Speed', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Weight', 'Work', 'base', 'cerebral atrophy', 'clinical application', 'combinatorial', 'computerized data processing', 'computerized tools', 'design', 'expectation', 'heart motion', 'image reconstruction', 'imaging Segmentation', 'improved', 'in vivo', 'interest', 'model design', 'nervous system disorder', 'reconstruction', 'simulation', 'tumor', 'white matter']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R21,2008,252375,0.004409590163051674
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,0.0005400592277145473
"Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses    DESCRIPTION (provided by applicant): Digital tomosynthesis mammography (DTM) is a new modality that holds the promise of improving mammographic sensitivity of breast cancer detection and diagnosis, especially for dense breasts. The main goals of the proposed research are (1) to develop a computer-aided detection (CADd) system for breast masses in DTM, (2) to develop a computer-aided diagnosis (CADx) system for classification of malignant and benign masses in DTM, and (3) to evaluate the effects of CAD (either CADd or CADx) on radiologists' interpretation of DTMs. Previous CAD systems are developed for regular projection mammograms (PMs).The proposed CAD system makes use of the 3-dimensional (3D) information in DTM to improve mass detection and characterization. The innovations in the proposed project include: (1) development of new computer-vision techniques to exploit the 3D volumetric information in DTMs, (2) evaluation of the dependence of CAD performance on reconstruction algorithms, and (3) comparison of computerized mass detection and characterization in DTMs, projection view mammograms (PVs) (the non-reconstructed mammograms taken at multiple angles during tomosynthesis imaging), and PMs. We hypothesize that detection and characterization of masses on DTMs will be more accurate than corresponding tasks on regular PMs, and that the CAD systems can improve radiologists' accuracy. 3D breast phantoms with test objects will be designed and imaged with a prototype DTM system. The dependence of DTM image quality on reconstruction algorithms and their parameters, and on image acquisition techniques will be studied. The appropriate reconstruction techniques will be selected based on phantom and patient studies. A database of DTMs and corresponding PMs with malignant and benign masses and a set of normal cases will be collected with patient informed consent. CAD systems for detection and classification of masses will be developed. Two approaches will be compared: one uses the reconstructed DTM slices and the other uses the PVs as input to the CAD systems. For the DTMs, new techniques for 3D preprocessing, image segmentation, feature extraction, and feature classification will be designed. For the PVs, our previous techniques developed for regular PMs will be adapted to these low- dose images, and information fusion methods using techniques such as neural networks or support vector machines will be developed to merge the multiple-PV information. To test our hypotheses, we will compare the CAD system performances from these two approaches and that from the corresponding regular PMs, and conduct observer ROC studies to evaluate effects of the CAD systems on radiologists' performance. CAD will be an important tool that can help accelerate the implementation of DTM in clinical practice. DTM with CAD is expected to help fully utilize the potential of this new modality to improve breast cancer detection.           n/a",Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses,7498781,R33CA120234,"['3-Dimensional', 'Abbreviations', 'Algorithms', 'Benign', 'Biological Neural Networks', 'Breast', 'Breast Cancer Detection', 'Classification', 'Clinical', 'Collection', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Database Management Systems', 'Databases', 'Dependence', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Digital Mammography', 'Doctor of Philosophy', 'Dose', 'Evaluation', 'Goals', 'Image', 'Imaging Phantoms', 'Informed Consent', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Mammography', 'Mass in breast', 'Methods', 'Modality', 'Patients', 'Performance', 'Phase', 'Process', 'Reading', 'Research', 'Research Personnel', 'Slice', 'Specific qualifier value', 'Staging', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'base', 'computerized', 'design', 'digital', 'experience', 'graphical user interface', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'programs', 'prototype', 'radiologist', 'reconstruction', 'tool']",NCI,UNIVERSITY OF MICHIGAN,R33,2007,389685,0.007410604484079264
"Digital Mammography: Advanced Computer-Aided Breast Can* DESCRIPTION (provided by applicant): The major goals of the proposed research are (1) to develop a computer-aided diagnosis (CAD) system for full field digital mammography (FFDM) using advanced computer vision techniques and (2) to evaluate the effects of CAD on interpretation of DMs. Previous CAD methods for lesion (mass and microcalcification) detection and characterization have been designed for digitized film mammograms and have generally been based on image features extracted from a single view. Our proposed approach is distinctly different from the previous approaches in that image information from two-view mammograms and bilateral mammograms will be fused using machine intelligence techniques. This fundamental change will expand the amount of information utilized in CAD and is expected to improve lesion detection and characterization. New computer vision techniques will be specifically designed for FFDM in order to exploit the advantages offered by digital detectors. This will produce a CAD system that is integrated with and takes full advantage of the latest imaging technologies to further improve the health care of women. We hypothesize that these advanced multiple-image information fusion techniques will lead to a more effective CAD system for FFDMs in comparison to a single-image approach, and that the CAD system will significantly improve radiologists' accuracy in the four most important areas of mammography: (i) detection of masses, (ii) classification of masses, (iii) detection of microcalcifications, and (iv) classification of microcalcifications. A database of digital mammograms (DMs) with malignant and benign lesions and a set of normal cases will be collected. We will first adapt our current film-based CAD algorithms to DMs in each of the four areas, taking into account the differences in the imaging characteristics between DMs and digitized mammograms. New computer vision techniques will then be developed to improve upon the current methods and to exploit the potential advantages of the high contrast sensitivity, high detective quantum efficiency, wide dynamic range, and the linear response to x-ray intensity of digital detectors. Novel regional registration methods for identifying corresponding lesions on CC and MLO views and for comparing the density symmetry on bilateral mammograms will be developed. Innovative fuzzy classification schemes will be designed to fuse multiple-image information and one-view information to reduce false positives and to improve detection sensitivity. Multiple-view morphological and texture features of a lesion will be merged using neural networks or other statistical classifiers for characterization of malignant and benign lesions. To test the hypotheses, we will (1) compare the performance of the multiple-image fusion CAD algorithm for DMs in each area to that of the corresponding one-view algorithm, (2) compare the detection accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies, and (3) compare the classification accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies. It is expected that this research will not only lead to an effective CAD system for FFDM, the multiple-image fusion approach and the new computer vision techniques will also advance CAD technology for mammography in general. n/a",Digital Mammography: Advanced Computer-Aided Breast Can*,7215135,R01CA095153,"['Accounting', 'Algorithms', 'Archives', 'Area', 'Artificial Intelligence', 'Benign', 'Bilateral', 'Biological Neural Networks', 'Breast', 'Breast Microcalcification', 'Budgets', 'Characteristics', 'Classification', 'Classification Scheme', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Contrast Sensitivity', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Digital Mammography', 'Doctor of Philosophy', 'Film', 'Goals', 'Healthcare', 'Image', 'Imaging technology', 'Lead', 'Lesion', 'Localized', 'Malignant - descriptor', 'Mammography', 'Measures', 'Methods', 'Performance', 'Process', 'Range', 'Research', 'Research Personnel', 'Staging', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'TimeLine', 'Tissues', 'Training', 'Woman', 'base', 'computerized', 'density', 'design', 'detector', 'digital', 'improved', 'innovation', 'method development', 'novel', 'novel strategies', 'programs', 'quantum', 'radiologist', 'response']",NCI,UNIVERSITY OF MICHIGAN,R01,2007,580689,0.05312517012193038
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7298516,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2007,88539,-0.004030902659353899
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7362843,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2007,235138,0.03829187026306417
"Computer-Aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is a leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Preliminary results from the PIOPED II study indicated a sensitivity of 83% by multi-detector CTPA. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE on CTPA scans and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include: (1) developing image preprocessing method to enhance vessel characteristics, (2) developing a new rolling balloon technique in combination with structure analysis to track vessels accurately, including vessels partially or completely occluded by PEs, (3) developing multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, especially for PEs in small subsegmental arteries, (4) analyzing PE features for development of classification methods, (5) developing false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) exploring performance evaluation methodology for computerized detection of PEs, and (7) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.         n/a",Computer-Aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,7229841,R21EB005851,"['3-Dimensional', 'Algorithms', 'Angiography', 'Archives', 'Arteries', 'Benign', 'Biological Neural Networks', 'Blood Vessels', 'Cause of Death', 'Characteristics', 'Classification', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Computer-Assisted Diagnosis', 'Condition', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Evaluation', 'Evaluation Methodology', 'Evaluation Studies', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Interobserver Variability', 'Location', 'Lung', 'Malignant - descriptor', 'Methods', 'Morbidity - disease rate', 'Numbers', 'Patients', 'Performance', 'Phase', 'Public Health', 'Pulmonary Embolism', 'Pulmonary vessels', 'Range', 'Rate', 'Reading', 'Recovery', 'Reporting', 'Research', 'Scanning', 'Scheme', 'Screening procedure', 'Second Opinions', 'Slice', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'TimeLine', 'Training', 'Trees', 'United States', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computerized', 'design', 'detector', 'improved', 'mortality', 'programs', 'radiologist']",NIBIB,UNIVERSITY OF MICHIGAN,R21,2007,194580,0.05465265684108839
"A computer aided chromosome imaging technique for cancer diagnosis    DESCRIPTION (provided by applicant): Identification of recurrent chromosomal aberrations is important for diagnosis, prognosis, and therapy of most hematological malignancies. Due to difficulties with culture of tumor cells, low mitotic index, poor chromosomal morphologies, and low prevalence, it takes tremendous effort and time for a cytogenetic clinician to obtain a sufficient number of analyzable metaphase cells under microscope before he/she can make an accurate clinical diagnosis. This process is not only very inefficient but also subject to human errors. In order to improve the efficiency and accuracy of leukemia diagnosis, we propose to develop a computer aided chromosome imaging technique. Specifically, we will develop an innovative high-speed microscopic imaging system based on a time-delay-integration technique. The system can scan the entire sample-slide at high magnification to obtain high resolution digital images to reveal metaphase chromosomes as required by clinical diagnosis. We will also develop a novel computer aided diagnosis (CAD) scheme including four specific modules to (1) detect analyzable metaphase chromosome cells, (2) segment overlapped chromosomes, (3) identify and classify distorted chromosomes associated with cancer cells, and (4) predict the cancer prognosis. After identification and segmentation of analyzable chromosomes, we will compute and search for the effective and robust image features. Genetic algorithm will be used to train and optimize an artificial neural network and a Bayesian belief network for the classification and prediction tasks, respectively. Using the integrated CAD workstation, we will conduct an observer performance study to assess the performance of the technique and its clinical feasibility. In summary, the proposed imaging technique is highly efficient, and no or only minimal human interventions are required from initial slide-scanning up to the presentation of CAD results. With such a new computerized clinical tool, cytogeneticists can effectively focus their efforts on analyzing/verifying chromosomal abnormal patterns and making final diagnostic decisions. It is therefore expected that the proposed technology can significantly improve the efficiency and accuracy of cancer (i.e., leukemia) diagnosis. The proposed technique has significant clinical potentials in monitoring therapeutic efficacy of cancer treatment as well.          n/a",A computer aided chromosome imaging technique for cancer diagnosis,7261406,R01CA115320,"['Algorithms', 'Belief', 'Biological Neural Networks', 'Cancer Prognosis', 'Cells', 'Chromosome Pairing', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 3', 'Classification', 'Clinical', 'Computer Assisted', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Congenital chromosomal disease', 'Cultured Tumor Cells', 'Custom', 'Cytogenetics', 'Databases', 'Deletion Mutation', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Effectiveness', 'Future', 'Genetic', 'Genetic Programming', 'Graph', 'Hematologic Neoplasms', 'Hour', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Label', 'Laboratories', 'Location', 'Low Prevalence', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Metaphase', 'Methods', 'Microscope', 'Microscopic', 'Molecular', 'Monitor', 'Morphology', 'Normal Cell', 'Numbers', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Rate', 'Receiver Operating Characteristics', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'S-Phase Fraction', 'Sampling', 'Scanning', 'Scheme', 'Skin', 'Slide', 'Solutions', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Treatment Efficacy', 'base', 'cancer cell', 'cancer diagnosis', 'cancer therapy', 'cancer type', 'clinical Diagnosis', 'clinical application', 'computerized', 'concept', 'day', 'design', 'detector', 'digital imaging', 'experience', 'improved', 'innovation', 'interest', 'leukemia', 'malignant breast neoplasm', 'novel', 'outcome forecast', 'programs', 'size', 'tool', 'user-friendly']",NCI,UNIVERSITY OF OKLAHOMA NORMAN,R01,2007,309600,0.0050711532481939586
"Multimodality CAD system with image references for breast mass characterization    DESCRIPTION (provided by applicant): The long term goal of the project is to develop an effective computer-aided diagnosis (CAD) system to assist radiologists in making diagnostic decisions in breast imaging. In this proposed project, we will concentrate on the characterization of masses using mammograms and ultrasound images. We propose a new approach to CAD based on a classifier that can simultaneously estimate the likelihood of malignancy for the mass and retrieve similar cases from a large library of cases with known diagnosis for the radiologist's references. The new CAD system thus combines the advantages of a rating-based and an image-retrieval- based CAD system. It will aid radiologists not only by the malignancy estimate but also by enhancing their similarity-based decision making process. We will also design a relevance feedback image retrieval system that allows the radiologist to interactively and efficiently retrieve similar cases from a large data set as a tool to help develop the automated CAD system. We hypothesize that the reference images will increase the characterization accuracy of less experienced readers for masses, and that the computerized classification and image retrieval system to be developed in this study will significantly improve radiologists' accuracy. To test these hypotheses, we will perform the following specific tasks: (1) collect a database of sonograms and mammograms containing masses; (2) extract features for mass characterization; (3) develop decision tree and k-nearest neighbor classifiers, compare decision tree training with and without boosting, and investigate methods for the retrieval of similar cases based on the developed classifiers; (4) develop a relevance feedback image retrieval method; (5) compare the performances of less experienced radiologists without and with aid by reference images retrieved by experienced radiologists; and (6) compare radiologists' performances without and with the fully-automated classification and image-retrieval CAD system by a receiver operating characteristic (ROC) study. If successfully developed, the CAD system may not only reduce benign biopsies, but also reduce the variation in interpretation between experienced and less experienced radiologists. The relevance of this project to public health is that 70-85% of breast biopsies are performed for benign lesions. Any reduction in this number without a decrease in breast cancer detection sensitivity will decrease health care costs, as well as contribute to the well-being of the patient by reducing anxiety and morbidity.           n/a",Multimodality CAD system with image references for breast mass characterization,7295701,R21CA118305,"['Address', 'Anxiety', 'Benign', 'Biopsy', 'Breast', 'Breast Cancer Detection', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Computers', 'Data Set', 'Databases', 'Decision Making', 'Decision Trees', 'Diagnosis', 'Diagnostic', 'Feedback', 'Goals', 'Health Care Costs', 'Image', 'Image retrieval system', 'Label', 'Lesion', 'Libraries', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Methods', 'Morbidity - disease rate', 'Multimodal Imaging', 'Numbers', 'Patients', 'Performance', 'Personal Satisfaction', 'Phase', 'Process', 'Public Health', 'Rate', 'Reader', 'Receiver Operating Characteristics', 'Research', 'Retrieval', 'Score', 'System', 'Testing', 'TimeLine', 'Training', 'Ultrasonography', 'Variant', 'base', 'case-based', 'computerized', 'design', 'digital imaging', 'experience', 'improved', 'innovation', 'novel strategies', 'radiologist', 'tool']",NCI,UNIVERSITY OF MICHIGAN,R21,2007,151477,0.0074521374083219485
"Developing Virtual Colonoscopy for Cancer Screening    DESCRIPTION (provided by applicant):    Colorectal carcinoma is the third most commonly diagnosed cancer and the second leading cause of death from cancer in the United States. Often it is diagnosed at an advanced stage, after the patient has developed symptoms, explaining its high mortality rate. Since most cancers arise from polyps over a 5 to 15 year period of malignant transformation, screening programs to detect small polyps less than 1 cm in diameter have been advocated. Unfortunately most people do not follow this recommendation. The health relatedness of this project is to dramatically increase the number of people willing to participate in screening programs by using a convenient, nearly risk-free procedure.      Virtual colonoscopy (VC) is a new procedure in which computed tomographic (CT) images of the patient's abdomen are taken and a computer visualization system is used to virtually navigate within a constructed 3-D image model of the colon, mimicking the current gold-standard optical colonoscopy (OC). The broad, long-term objective of this project is to develop VC as an accurate, cost-effective, minimalinvasive, least-stressful technique to screen large segments of the population.      To further advance this technology, the specific aims of this project renewal are: (1) to investigate low-dose CT techniques for VC towards massive screening of colonic polyps; (2) to extend electronic colon cleansing strategies to extract the colon mucosa layer by mixture-based image segmentation; (3) to investigate integrated feature-extraction techniques for polyp modeling towards computed aided detection (CAD) of colonic polyps; and (4) to extend our current real-time volume-rendering based navigation algorithms to include CAD and interactive virtual biopsy means for analysis of suspected abnormalities.      The research design and methodology will include evaluating from low-dose CT images the ability to electronically clean the colon lumen and extract the mucosa layer with less-stressful bowel preparation; the feasibility of bringing the technology to a readily accessible environment by documenting VC speed and quality with CAD and interactive virtual biopsy tools through the entire colon; and the accuracy by comparing virtual and optical colonoscopy polyp detection in the same patient using a pilot study.         n/a",Developing Virtual Colonoscopy for Cancer Screening,7237911,R01CA082402,"['Abdomen', 'Advocate', 'Affect', 'Algorithms', 'Area', 'Barium', 'Biopsy', 'Caliber', 'Cause of Death', 'Clinical', 'Colon', 'Colonic Polyps', 'Colonoscopy', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer software', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diatrizoate Meglumine', 'Diatrizoate Sodium', 'Dose', 'Effectiveness', 'Electronics', 'Ensure', 'Environment', 'Exposure to', 'Facility Construction Funding Category', 'Feces', 'Genus Cola', 'Gold', 'Health', 'Image', 'Imagery', 'Intervention', 'Intestines', 'Iodine', 'Laboratory Research', 'Large Intestine Carcinoma', 'Licensing', 'Liquid substance', 'Long Island', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Marketing', 'Methodology', 'Modality', 'Modeling', 'Morphologic artifacts', 'Mucous Membrane', 'Nature', 'Navigation System', 'Noise', 'Numbers', 'Optics', 'Patients', 'Physicians', 'Pilot Projects', 'Polishes', 'Polyps', 'Population', 'Preparation', 'Principal Investigator', 'Procedures', 'Progress Reports', 'Protocols documentation', 'Purpose', 'Radiation', 'Rate', 'Reading', 'Recommendation', 'Reporting', 'Research Design', 'Resolution', 'Risk', 'Scanning', 'Screening for cancer', 'Screening procedure', 'Second Primary Cancers', 'Slice', 'Solutions', 'Speed', 'Staging', 'Standards of Weights and Measures', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Tube', 'United States', 'Universities', 'Validation', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cost', 'data acquisition', 'density', 'detector', 'digital imaging', 'healthy volunteer', 'imaging Segmentation', 'improved', 'mortality', 'programs', 'prototype', 'radiologist', 'technology development', 'tool', 'virtual']",NCI,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2007,304959,0.028775158195644402
"Information-Theoretic Based CAD in Mammography DESCRIPTION (provided by applicant):    The purpose of the study is to develop and evaluate a novel computer-assisted decision (CAD) scheme for improving the clinical detection of breast masses in screening mammograms. The CAD scheme combines information-theoretic similarity metrics with knowledge-based decision algorithms. It will help radiologists scrutinize mammograms providing evidence-based decision support. Given a query mammographic region, the CAD system will interrogate a database of archived mammograms, examine similar eases, and assign a likelihood measure regarding the presence of a potentially malignant mass.  The study proposes the formulation of information-theoretic metrics to quantify the similarity of two mammographic regions. The similarity metrics are based on Sharmon's entropy; a measure of complexity (or information) contained in an image. Theoretically, if two mammographic regions depict similar structures, they should contain diagnostic information for each other. The amount of relevant diagnostic information can be measured by entropy-based similarity metrics that are computed directly from the images without requiring segmentation or feature extraction. Using the similarity metrics and an image databank of mammographic cases with known truth, a knowledge-bussed CAD scheme will be implemented for the detection of masses in screening mammograms. Preliminary studies have established that standard mutual information (MI) is an effective similarity metric for the task.  The specific aims of the study are: (1) To fully exploit information-theoretic metrics that measure the similar content of two mammographic regions, (2) To optimize their contributions in an evidence-based decision algorithm for the early detection of potentially malignant masses, and (3) To perform preliminary clinical evaluation of the CAD system.  As digital image libraries are an upcoming trend in radiology, the proposed CAD system will take advantage of continuously deposited mammograms with established ground truth. The system aims to reduce the interpretation error associated with screening mammograms and/or the false positives generated by cuing CAD schemes, Overall, the study aims to improve the sensitivity while maintaining or improving the specificity of screening mammography for masses. n/a",Information-Theoretic Based CAD in Mammography,7162911,R01CA101911,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Classification', 'Clinical', 'Computer Assisted', 'Computer Interface', 'Cues', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Drug Formulations', 'Early Diagnosis', 'Entropy', 'Image', 'Information Theory', 'Knowledge', 'Knowledge Base (Computer)', 'Libraries', 'Malignant - descriptor', 'Mammography', 'Mass in breast', 'Measures', 'Metric', 'Physicians', 'Purpose', 'Radiology Specialty', 'Scheme', 'Screening procedure', 'Specificity', 'Standards of Weights and Measures', 'Structure', 'System', 'Techniques', 'Uncertainty', 'base', 'concept', 'digital imaging', 'improved', 'knowledge base', 'novel', 'radiologist', 'research clinical testing', 'statistics', 'trend']",NCI,DUKE UNIVERSITY,R01,2007,230712,0.039984023008409364
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7253351,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSP,U24,2007,5123449,0.007738745322401967
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7289973,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2007,853883,0.045249201997225354
"Digital Mammography: Advanced Computer-Aided Breast Can* DESCRIPTION (provided by applicant): The major goals of the proposed research are (1) to develop a computer-aided diagnosis (CAD) system for full field digital mammography (FFDM) using advanced computer vision techniques and (2) to evaluate the effects of CAD on interpretation of DMs. Previous CAD methods for lesion (mass and microcalcification) detection and characterization have been designed for digitized film mammograms and have generally been based on image features extracted from a single view. Our proposed approach is distinctly different from the previous approaches in that image information from two-view mammograms and bilateral mammograms will be fused using machine intelligence techniques. This fundamental change will expand the amount of information utilized in CAD and is expected to improve lesion detection and characterization. New computer vision techniques will be specifically designed for FFDM in order to exploit the advantages offered by digital detectors. This will produce a CAD system that is integrated with and takes full advantage of the latest imaging technologies to further improve the health care of women. We hypothesize that these advanced multiple-image information fusion techniques will lead to a more effective CAD system for FFDMs in comparison to a single-image approach, and that the CAD system will significantly improve radiologists' accuracy in the four most important areas of mammography: (i) detection of masses, (ii) classification of masses, (iii) detection of microcalcifications, and (iv) classification of microcalcifications. A database of digital mammograms (DMs) with malignant and benign lesions and a set of normal cases will be collected. We will first adapt our current film-based CAD algorithms to DMs in each of the four areas, taking into account the differences in the imaging characteristics between DMs and digitized mammograms. New computer vision techniques will then be developed to improve upon the current methods and to exploit the potential advantages of the high contrast sensitivity, high detective quantum efficiency, wide dynamic range, and the linear response to x-ray intensity of digital detectors. Novel regional registration methods for identifying corresponding lesions on CC and MLO views and for comparing the density symmetry on bilateral mammograms will be developed. Innovative fuzzy classification schemes will be designed to fuse multiple-image information and one-view information to reduce false positives and to improve detection sensitivity. Multiple-view morphological and texture features of a lesion will be merged using neural networks or other statistical classifiers for characterization of malignant and benign lesions. To test the hypotheses, we will (1) compare the performance of the multiple-image fusion CAD algorithm for DMs in each area to that of the corresponding one-view algorithm, (2) compare the detection accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies, and (3) compare the classification accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies. It is expected that this research will not only lead to an effective CAD system for FFDM, the multiple-image fusion approach and the new computer vision techniques will also advance CAD technology for mammography in general. n/a",Digital Mammography: Advanced Computer-Aided Breast Can*,7088818,R01CA095153,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasms', 'calcification', 'clinical research', 'computer assisted diagnosis', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'digital imaging', 'human data', 'information systems', 'mammography', 'mathematics', 'neoplasm /cancer diagnosis', 'neoplastic growth']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2006,565364,0.05312517012193038
"Computer-Aided Detection of Pulmonary Embolism on CT Pulmonary Angiography    DESCRIPTION (provided by applicant): Pulmonary embolism (PE) is a leading cause of death in the United States if untreated. Prompt diagnosis and treatment can dramatically reduce the mortality rate and morbidity of the disease. Computed tomographic pulmonary angiography (CTPA) has been reported to be an effective means for clinical diagnosis of PE. Interpretation of a CT scan for PE demands extensive reading efforts from a radiologist who has to visually track a large number of vessels in the lungs to detect suspected PEs. Despite the efforts, the sensitivities were reported to range from 53% to 100%. Preliminary results from the PIOPED II study indicated a sensitivity of 83% by multi-detector CTPA. Computer-aided diagnosis (CAD) can be a viable approach to improving the sensitivity and efficiency of PE detection in CTPA images, as well as reducing inter-observer variability. The overall goal of the proposed project is to develop a robust CAD system that can provide a systematic screening of PE on CTPA scans and serve as a second opinion by automatically alerting the radiologists to suspicious locations on 2D slice and 3D volume rendering display of the CTPA images. We will develop advanced computer vision techniques to enhance the characteristics of vessels, automatically extract the pulmonary vessels, reconstruct the vessel tree, detect candidate PEs, differentiate PE from normal pulmonary structures, and identify the true PEs. The techniques will be specifically designed for analysis of the complex vascular structures on CTPA images. The specific aims of this project include: (1) developing image preprocessing method to enhance vessel characteristics, (2) developing a new rolling balloon technique in combination with structure analysis to track vessels accurately, including vessels partially or completely occluded by PEs, (3) developing multi-prescreening method for the identification of suspicious PEs at different levels of artery branches, especially for PEs in small subsegmental arteries, (4) analyzing PE features for development of classification methods, (5) developing false positive reduction method based on feature analysis and fuzzy rule-based, linear, or neural network classifiers, (6) exploring performance evaluation methodology for computerized detection of PEs, and (7) performing observer ROC study to evaluate the effects of CAD on radiologists' accuracy in PE diagnosis. The relevance of this research to public health lies in the fact that there is substantial false-negative diagnosis of PEs. CAD will potentially reduce missed PEs and improve the chance of timely treatment of patients, thus reducing the mortality rate and speed up recovery from this condition.         n/a",Computer-Aided Detection of Pulmonary Embolism on CT Pulmonary Angiography,7015959,R21EB005851,"['angiography', 'artery', 'classification', 'computers', 'diagnosis', 'health science profession', 'information systems', 'performance', 'radiology', 'vision']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2006,217615,0.05465265684108839
"Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses    DESCRIPTION (provided by applicant): Digital tomosynthesis mammography (DTM) is a new modality that holds the promise of improving mammographic sensitivity of breast cancer detection and diagnosis, especially for dense breasts. The main goals of the proposed research are (1) to develop a computer-aided detection (CADd) system for breast masses in DTM, (2) to develop a computer-aided diagnosis (CADx) system for classification of malignant and benign masses in DTM, and (3) to evaluate the effects of CAD (either CADd or CADx) on radiologists' interpretation of DTMs. Previous CAD systems are developed for regular projection mammograms (PMs).The proposed CAD system makes use of the 3-dimensional (3D) information in DTM to improve mass detection and characterization. The innovations in the proposed project include: (1) development of new computer-vision techniques to exploit the 3D volumetric information in DTMs, (2) evaluation of the dependence of CAD performance on reconstruction algorithms, and (3) comparison of computerized mass detection and characterization in DTMs, projection view mammograms (PVs) (the non-reconstructed mammograms taken at multiple angles during tomosynthesis imaging), and PMs. We hypothesize that detection and characterization of masses on DTMs will be more accurate than corresponding tasks on regular PMs, and that the CAD systems can improve radiologists' accuracy. 3D breast phantoms with test objects will be designed and imaged with a prototype DTM system. The dependence of DTM image quality on reconstruction algorithms and their parameters, and on image acquisition techniques will be studied. The appropriate reconstruction techniques will be selected based on phantom and patient studies. A database of DTMs and corresponding PMs with malignant and benign masses and a set of normal cases will be collected with patient informed consent. CAD systems for detection and classification of masses will be developed. Two approaches will be compared: one uses the reconstructed DTM slices and the other uses the PVs as input to the CAD systems. For the DTMs, new techniques for 3D preprocessing, image segmentation, feature extraction, and feature classification will be designed. For the PVs, our previous techniques developed for regular PMs will be adapted to these low- dose images, and information fusion methods using techniques such as neural networks or support vector machines will be developed to merge the multiple-PV information. To test our hypotheses, we will compare the CAD system performances from these two approaches and that from the corresponding regular PMs, and conduct observer ROC studies to evaluate effects of the CAD systems on radiologists' performance. CAD will be an important tool that can help accelerate the implementation of DTM in clinical practice. DTM with CAD is expected to help fully utilize the potential of this new modality to improve breast cancer detection.           n/a",Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses,7080103,R21CA120234,"['classification', 'clinical research', 'computers', 'diagnosis', 'health science profession', 'information systems', 'mammary gland', 'mammography', 'performance', 'radiology', 'vision']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2006,215772,0.007410604484079264
"Multimodality CAD system with image references for breast mass characterization    DESCRIPTION (provided by applicant): The long term goal of the project is to develop an effective computer-aided diagnosis (CAD) system to assist radiologists in making diagnostic decisions in breast imaging. In this proposed project, we will concentrate on the characterization of masses using mammograms and ultrasound images. We propose a new approach to CAD based on a classifier that can simultaneously estimate the likelihood of malignancy for the mass and retrieve similar cases from a large library of cases with known diagnosis for the radiologist's references. The new CAD system thus combines the advantages of a rating-based and an image-retrieval- based CAD system. It will aid radiologists not only by the malignancy estimate but also by enhancing their similarity-based decision making process. We will also design a relevance feedback image retrieval system that allows the radiologist to interactively and efficiently retrieve similar cases from a large data set as a tool to help develop the automated CAD system. We hypothesize that the reference images will increase the characterization accuracy of less experienced readers for masses, and that the computerized classification and image retrieval system to be developed in this study will significantly improve radiologists' accuracy. To test these hypotheses, we will perform the following specific tasks: (1) collect a database of sonograms and mammograms containing masses; (2) extract features for mass characterization; (3) develop decision tree and k-nearest neighbor classifiers, compare decision tree training with and without boosting, and investigate methods for the retrieval of similar cases based on the developed classifiers; (4) develop a relevance feedback image retrieval method; (5) compare the performances of less experienced radiologists without and with aid by reference images retrieved by experienced radiologists; and (6) compare radiologists' performances without and with the fully-automated classification and image-retrieval CAD system by a receiver operating characteristic (ROC) study. If successfully developed, the CAD system may not only reduce benign biopsies, but also reduce the variation in interpretation between experienced and less experienced radiologists. The relevance of this project to public health is that 70-85% of breast biopsies are performed for benign lesions. Any reduction in this number without a decrease in breast cancer detection sensitivity will decrease health care costs, as well as contribute to the well-being of the patient by reducing anxiety and morbidity.           n/a",Multimodality CAD system with image references for breast mass characterization,7147093,R21CA118305,"['classification', 'clinical research', 'computers', 'diagnosis', 'experience', 'health science profession', 'information systems', 'mammary gland', 'performance', 'radiology', 'ultrasonography']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2006,162252,0.0074521374083219485
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6985366,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,183324,0.005568572717038687
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7078667,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2006,5010926,0.007738745322401967
"Digital Mammography: Advanced Computer-Aided Breast Can* DESCRIPTION (provided by applicant): The major goals of the proposed research are (1) to develop a computer-aided diagnosis (CAD) system for full field digital mammography (FFDM) using advanced computer vision techniques and (2) to evaluate the effects of CAD on interpretation of DMs. Previous CAD methods for lesion (mass and microcalcification) detection and characterization have been designed for digitized film mammograms and have generally been based on image features extracted from a single view. Our proposed approach is distinctly different from the previous approaches in that image information from two-view mammograms and bilateral mammograms will be fused using machine intelligence techniques. This fundamental change will expand the amount of information utilized in CAD and is expected to improve lesion detection and characterization. New computer vision techniques will be specifically designed for FFDM in order to exploit the advantages offered by digital detectors. This will produce a CAD system that is integrated with and takes full advantage of the latest imaging technologies to further improve the health care of women. We hypothesize that these advanced multiple-image information fusion techniques will lead to a more effective CAD system for FFDMs in comparison to a single-image approach, and that the CAD system will significantly improve radiologists' accuracy in the four most important areas of mammography: (i) detection of masses, (ii) classification of masses, (iii) detection of microcalcifications, and (iv) classification of microcalcifications. A database of digital mammograms (DMs) with malignant and benign lesions and a set of normal cases will be collected. We will first adapt our current film-based CAD algorithms to DMs in each of the four areas, taking into account the differences in the imaging characteristics between DMs and digitized mammograms. New computer vision techniques will then be developed to improve upon the current methods and to exploit the potential advantages of the high contrast sensitivity, high detective quantum efficiency, wide dynamic range, and the linear response to x-ray intensity of digital detectors. Novel regional registration methods for identifying corresponding lesions on CC and MLO views and for comparing the density symmetry on bilateral mammograms will be developed. Innovative fuzzy classification schemes will be designed to fuse multiple-image information and one-view information to reduce false positives and to improve detection sensitivity. Multiple-view morphological and texture features of a lesion will be merged using neural networks or other statistical classifiers for characterization of malignant and benign lesions. To test the hypotheses, we will (1) compare the performance of the multiple-image fusion CAD algorithm for DMs in each area to that of the corresponding one-view algorithm, (2) compare the detection accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies, and (3) compare the classification accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies. It is expected that this research will not only lead to an effective CAD system for FFDM, the multiple-image fusion approach and the new computer vision techniques will also advance CAD technology for mammography in general. n/a",Digital Mammography: Advanced Computer-Aided Breast Can*,6903375,R01CA095153,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasms', 'calcification', 'clinical research', 'computer assisted diagnosis', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'digital imaging', 'human data', 'information systems', 'mammography', 'mathematics', 'neoplasm /cancer diagnosis', 'neoplastic growth']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2005,519009,0.05312517012193038
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6951380,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2005,374972,0.020017569434017668
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6935840,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2005,399984,-0.011086413040261004
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6850297,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2005,172385,0.005568572717038687
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6952714,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2005,5013536,0.007738745322401967
"Digital Mammography: Advanced Computer-Aided Breast Can* DESCRIPTION (provided by applicant): The major goals of the proposed research are (1) to develop a computer-aided diagnosis (CAD) system for full field digital mammography (FFDM) using advanced computer vision techniques and (2) to evaluate the effects of CAD on interpretation of DMs. Previous CAD methods for lesion (mass and microcalcification) detection and characterization have been designed for digitized film mammograms and have generally been based on image features extracted from a single view. Our proposed approach is distinctly different from the previous approaches in that image information from two-view mammograms and bilateral mammograms will be fused using machine intelligence techniques. This fundamental change will expand the amount of information utilized in CAD and is expected to improve lesion detection and characterization. New computer vision techniques will be specifically designed for FFDM in order to exploit the advantages offered by digital detectors. This will produce a CAD system that is integrated with and takes full advantage of the latest imaging technologies to further improve the health care of women. We hypothesize that these advanced multiple-image information fusion techniques will lead to a more effective CAD system for FFDMs in comparison to a single-image approach, and that the CAD system will significantly improve radiologists' accuracy in the four most important areas of mammography: (i) detection of masses, (ii) classification of masses, (iii) detection of microcalcifications, and (iv) classification of microcalcifications. A database of digital mammograms (DMs) with malignant and benign lesions and a set of normal cases will be collected. We will first adapt our current film-based CAD algorithms to DMs in each of the four areas, taking into account the differences in the imaging characteristics between DMs and digitized mammograms. New computer vision techniques will then be developed to improve upon the current methods and to exploit the potential advantages of the high contrast sensitivity, high detective quantum efficiency, wide dynamic range, and the linear response to x-ray intensity of digital detectors. Novel regional registration methods for identifying corresponding lesions on CC and MLO views and for comparing the density symmetry on bilateral mammograms will be developed. Innovative fuzzy classification schemes will be designed to fuse multiple-image information and one-view information to reduce false positives and to improve detection sensitivity. Multiple-view morphological and texture features of a lesion will be merged using neural networks or other statistical classifiers for characterization of malignant and benign lesions. To test the hypotheses, we will (1) compare the performance of the multiple-image fusion CAD algorithm for DMs in each area to that of the corresponding one-view algorithm, (2) compare the detection accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies, and (3) compare the classification accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies. It is expected that this research will not only lead to an effective CAD system for FFDM, the multiple-image fusion approach and the new computer vision techniques will also advance CAD technology for mammography in general. n/a",Digital Mammography: Advanced Computer-Aided Breast Can*,6753540,R01CA095153,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasms', 'calcification', 'clinical research', 'computer assisted diagnosis', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'digital imaging', 'human data', 'information systems', 'mammography', 'mathematics', 'neoplasm /cancer diagnosis', 'neoplastic growth']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2004,492610,0.05312517012193038
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6833334,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2004,374972,0.020017569434017668
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6773880,R44RR016393,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computed axial tomography', 'computer system design /evaluation', 'image processing', 'laboratory mouse', 'noninvasive diagnosis', 'single photon emission computed tomography', 'technology /technique development', 'whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2004,368960,0.006521428850643829
"COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY   DESCRIPTION (Adapted from Applicant's Abstract): The applicants proposed to          develop computer-aided diagnostic (CAD) schemes for detection and                    characterization of pulmonary nodules in digital chest images. For development       of reliable and predictable CAD schemes, they proposed to establish a large          database with 2,000 cases of chest radiographs, which include 1,000 nodule           cases and 1,000 non-nodule cases, in collaboration with Richard M. Slone, M.D.,      Mallinckrodt Institute of Radiology, Washington University, under a consortium       arrangement. An advanced CAD scheme for detection of lung nodules will be            developed by incorporating three subtraction techniques--temporal subtraction,       contralateral subtraction and energy subtraction--in order to achieve, on            average, a high sensitivity of 80-90% with a low false positive rate of              approximately 0.5 per chest image. They would investigate the usefulness of the      temporal subtraction technique in increasing the detection of subtle nodules         overlapped with ribs and also decreasing the number of false positives due to        rib-crossings, when a previous chest image of the same patient is available.         Contralateral subtraction, which is a novel technique for removal of peripheral      ribs in a single PA chest image, will be examined for enhancement in the             detection of overlapped nodules and reduction in the number of false positives.      They would also investigate the usefulness of energy subtraction soft-tissue         image for improved computerized detection of lung nodules in combination with        conventional chest images. In addition to the detection task, they would to          develop CAD schemes for characterization of nodules in order to distinguish          between benign and malignant nodules. This characterization task is to provide       the likelihood of malignance of lung nodules based on quantitative analysis of       image features of nodules detected by computer and/or by radiologists. With the      high level of detection performance that they expect to achieve, they propose        to develop a prototype CAD workstation and carry out a pilot study to examine        the clinical usefulness of CAD schemes on detection and characterization of          pulmonary nodules.                                                                                                                                                        n/a",COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY,6719070,R01CA062625,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer human interaction', 'computer system design /evaluation', 'diagnosis design /evaluation', 'digital imaging', 'disease /disorder classification', 'human data', 'image processing', 'information systems', 'lung neoplasms', 'neoplasm /cancer radiodiagnosis', 'noninvasive diagnosis', 'thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2004,397291,0.040395020427611644
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6834860,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2004,350214,-0.011086413040261004
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6909355,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2004,3821536,0.007738745322401967
"Digital Mammography: Advanced Computer-Aided Breast Can* DESCRIPTION (provided by applicant): The major goals of the proposed research are (1) to develop a computer-aided diagnosis (CAD) system for full field digital mammography (FFDM) using advanced computer vision techniques and (2) to evaluate the effects of CAD on interpretation of DMs. Previous CAD methods for lesion (mass and microcalcification) detection and characterization have been designed for digitized film mammograms and have generally been based on image features extracted from a single view. Our proposed approach is distinctly different from the previous approaches in that image information from two-view mammograms and bilateral mammograms will be fused using machine intelligence techniques. This fundamental change will expand the amount of information utilized in CAD and is expected to improve lesion detection and characterization. New computer vision techniques will be specifically designed for FFDM in order to exploit the advantages offered by digital detectors. This will produce a CAD system that is integrated with and takes full advantage of the latest imaging technologies to further improve the health care of women. We hypothesize that these advanced multiple-image information fusion techniques will lead to a more effective CAD system for FFDMs in comparison to a single-image approach, and that the CAD system will significantly improve radiologists' accuracy in the four most important areas of mammography: (i) detection of masses, (ii) classification of masses, (iii) detection of microcalcifications, and (iv) classification of microcalcifications. A database of digital mammograms (DMs) with malignant and benign lesions and a set of normal cases will be collected. We will first adapt our current film-based CAD algorithms to DMs in each of the four areas, taking into account the differences in the imaging characteristics between DMs and digitized mammograms. New computer vision techniques will then be developed to improve upon the current methods and to exploit the potential advantages of the high contrast sensitivity, high detective quantum efficiency, wide dynamic range, and the linear response to x-ray intensity of digital detectors. Novel regional registration methods for identifying corresponding lesions on CC and MLO views and for comparing the density symmetry on bilateral mammograms will be developed. Innovative fuzzy classification schemes will be designed to fuse multiple-image information and one-view information to reduce false positives and to improve detection sensitivity. Multiple-view morphological and texture features of a lesion will be merged using neural networks or other statistical classifiers for characterization of malignant and benign lesions. To test the hypotheses, we will (1) compare the performance of the multiple-image fusion CAD algorithm for DMs in each area to that of the corresponding one-view algorithm, (2) compare the detection accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies, and (3) compare the classification accuracy of masses and microcalcifications on DMs with and without CAD by observer ROC studies. It is expected that this research will not only lead to an effective CAD system for FFDM, the multiple-image fusion approach and the new computer vision techniques will also advance CAD technology for mammography in general. n/a",Digital Mammography: Advanced Computer-Aided Breast Can*,6574171,R01CA095153,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' calcification', ' clinical research', ' computer assisted diagnosis', ' computer system design /evaluation', ' data management', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' human data', ' information systems', ' mammography', ' mathematics', ' neoplasm /cancer diagnosis', ' neoplastic growth']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2003,482072,0.05312517012193038
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6621877,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2003,147213,0.05060211416195289
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,0.010121791771971362
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6643700,R43HL071470,"['artificial intelligence', ' atherosclerotic plaque', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical automation', ' cardiovascular disorder diagnosis', ' diagnosis design /evaluation', ' human data', ' image processing', ' magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R43,2003,99850,0.020017569434017668
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6693866,R44RR016393,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computed axial tomography', ' computer system design /evaluation', ' image processing', ' laboratory mouse', ' noninvasive diagnosis', ' single photon emission computed tomography', ' technology /technique development', ' whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2003,379863,0.006521428850643829
"Estimating Neural Network Precision for Cancer Diagnosis   DESCRIPTION (Provided by Applicant): This application's broad, long-term             objective is to diagnose cancer accurately, reducing both false-negative and         false-positive diagnoses. The research proposed in this application concerns         artificial neural networks (ANNs) which are important statistical tools that         are used frequently in computer-aided diagnosis (CAD) methods intended to            improve cancer diagnosis. The goal of this research is to provide error bars         for ANN output. The significance and health-relatedness of this research is          that the goal, if achieved, could represent a fundamental advance to ANNs in         CAD applications, by making ANN output more reliable for subsequent computer         processing and more intuitive to understand for radiologists to interpret and        incorporate (the diagnostic predictions made by ANNs) in their own diagnoses.        The proposed method could become the standard of practice, replacing the             conventional, one-ANN approach. The hypothesis to be tested is that artificial       neural network output has finite uncertainty which can be estimated and              expressed in terms of confidence intervals. The specific aims are:                                                                                                        (1) To demonstrate qualitatively the concept of uncertainty in ANN output and        the feasibility of developing multiple ANNs from a single set of training            cases.                                                                                                                                                                    (2) To develop and validate quantitative method(s) of ANN-precision estimation.                                                                                           (3) To apply ANN-precision estimation to a real-world CAD problem: computer          classification of malignant and benign clustered microcalcifications.                                                                                                     The research design is to use primarily computer simulations to investigate          properties of the output from multiple ANNs obtained from the same training          cases and to develop and validate practical method(s) for computing confidence       intervals in ANN output from these multiple ANNs, then to apply the new methods      to a real-world CAD task. The methods to be used include computer simulation,        ROC analysis, computation of confidence intervals, bootstrapping, parametric         estimation of statistical distributions, analytical analysis, and computer           analysis of breast lesions in mammograms.                                                                                                                                 n/a",Estimating Neural Network Precision for Cancer Diagnosis,6620862,R21CA093989,"['artificial intelligence', ' breast neoplasm /cancer diagnosis', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' female', ' human data', ' neoplasm /cancer classification /staging', "" women's health""]",NCI,UNIVERSITY OF CHICAGO,R21,2003,185585,-0.0013494932835861342
"Vessel Segmentation/Registration from Ultrasound Images    DESCRIPTION (provided by applicant):    Ultrasound is widely used for imaging of blood vessels as it is non-invasive, real-time, and relatively inexpensive. This proposal focuses on segmentation of abdominal aortic aneurysms (AAA) from ultrasound images with extension to other vascular imaging applications in the long term. Reliable quantitative evaluation of AAAs plays a pivotal role in diagnoses and frequent follow-up studies needed to avoid life-threatening rupture. These studies require vessel segmentation (for size analysis) and registration between serial studies (for monitoring the progression of the disease before and/or after vascular repair). AAA evaluation is routinely carried out for both high-risk patient populations and those treated with endovascular repair. Currently, AAA management is primarily based on measurements from two-dimensional (2-D) slices in CT scans. AAA monitoring and follow-up could be improved by 1) measurement from 3-D reconstructions, and 2) use of ultrasound imaging to minimize radiation exposure and reduce costs. 3-D ultrasound reconstructions provide accuracy comparable to that of CT. However, large inter-observer variability and long processing times preclude routine clinical use of 3-D image information. This research aims to develop software solutions for improved ultrasound-based AAA monitoring and other vascular diseases (in the long term). The tools used will be based on advanced image segmentation and registration algorithms involving curvature-driven image processing techniques and deformable models. The goal of the Phase I study is to establish feasibility of the proposed methods by demonstrating an improvement in the repeatability and accuracy of measurements and reduction in delineation time.         n/a",Vessel Segmentation/Registration from Ultrasound Images,6641019,R43HL069540,"['abdomen', ' aorta aneurysm', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' gastrointestinal circulation disorder', ' gastrointestinal imaging /visualization', ' human data', ' mathematics', ' three dimensional imaging /topography']",NHLBI,INSIGHTFUL CORPORATION,R43,2003,99621,0.02899838094115807
"COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY   DESCRIPTION (Adapted from Applicant's Abstract): The applicants proposed to          develop computer-aided diagnostic (CAD) schemes for detection and                    characterization of pulmonary nodules in digital chest images. For development       of reliable and predictable CAD schemes, they proposed to establish a large          database with 2,000 cases of chest radiographs, which include 1,000 nodule           cases and 1,000 non-nodule cases, in collaboration with Richard M. Slone, M.D.,      Mallinckrodt Institute of Radiology, Washington University, under a consortium       arrangement. An advanced CAD scheme for detection of lung nodules will be            developed by incorporating three subtraction techniques--temporal subtraction,       contralateral subtraction and energy subtraction--in order to achieve, on            average, a high sensitivity of 80-90% with a low false positive rate of              approximately 0.5 per chest image. They would investigate the usefulness of the      temporal subtraction technique in increasing the detection of subtle nodules         overlapped with ribs and also decreasing the number of false positives due to        rib-crossings, when a previous chest image of the same patient is available.         Contralateral subtraction, which is a novel technique for removal of peripheral      ribs in a single PA chest image, will be examined for enhancement in the             detection of overlapped nodules and reduction in the number of false positives.      They would also investigate the usefulness of energy subtraction soft-tissue         image for improved computerized detection of lung nodules in combination with        conventional chest images. In addition to the detection task, they would to          develop CAD schemes for characterization of nodules in order to distinguish          between benign and malignant nodules. This characterization task is to provide       the likelihood of malignance of lung nodules based on quantitative analysis of       image features of nodules detected by computer and/or by radiologists. With the      high level of detection performance that they expect to achieve, they propose        to develop a prototype CAD workstation and carry out a pilot study to examine        the clinical usefulness of CAD schemes on detection and characterization of          pulmonary nodules.                                                                                                                                                        n/a",COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY,6633169,R01CA062625,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' disease /disorder classification', ' human data', ' image processing', ' information systems', ' lung neoplasms', ' neoplasm /cancer radiodiagnosis', ' noninvasive diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2003,388688,0.040395020427611644
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by investigator):  The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47% to 58% of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy, with 8% stating that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side-effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better-informed treatment decisions, and facilitate coping when it occurs.         n/a",Computer Imaging to Diminish Alopecia Distress,6586963,R43CA099873,"['alopecia', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted patient care', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' coping', ' desensitization psychotherapy', ' drug adverse effect', ' female', ' imaging /visualization /scanning', ' psychological aspect of cancer', ' quality of life', "" women's health""]",NCI,"BARRON ASSOCIATES, INC.",R43,2003,99973,-0.01114138648746243
"Novel Methods for Automated Key Image Selection    DESCRIPTION (provided by the applicant):  Significant new knowledge about human behavior and the brain has come to light in recent years, due in part to rapid technical developments in imaging. As the role of imaging becomes increasingly important in neurosciences, effective methods for managing and retrieving images will become even more critical; without such advances, further progress will be hindered. The goal of this proposal is the automated summarization of large imaging sets. Image summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files. In Phase I, development is focused on a customizable brain atlas used for registering patient imaging studies in order to select key images. This phase addresses selection of images from ""normal"" studies and studies with only subtle morphological changes, as typical of most patients with psychiatric disorders. Automatic techniques for customizing the atlas to imaging study acquisition parameters are developed, in addition to registration methods for mapping the atlas to the patient's original study. Building from this initial work, Phase II expands to encompass selection of images from ""abnormal"" studies that exhibit gross morphological changes through principle component analysis, further customization of the atlas for different age groups (e.g., pediatric), and incorporation of structured data entry (SDE) and natural language processing (NLP) of medical reports to help guide automatic selection of key images. The resultant product will be a fully automated software system that can select relevant images from any imaging study. Initial evaluation in Phase I will examine the performance of the contrast customizable atlas and summarization/relevant slice selection, as compared to human experts.         n/a",Novel Methods for Automated Key Image Selection,6583176,R43MH065764,"['archives', ' biomedical automation', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' human data', ' image processing', ' method development']",NIMH,MEDAXIS CORPORATION,R43,2003,93365,0.02953373484112299
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6437170,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2002,143782,0.05060211416195289
"Ultrasonic Registration of Knee Anatomy to MRI Images  DESCRIPTION (provided by applicant): The proposed research will investigate the feasibility of using intra-operative ultrasound (US) images to noninvasively register the bone surfaces of the knee to preoperative magnetic resonance (MR) images. A surgical navigation system, KneeNav, is being developed by CASurgica for intraoperatively planning the proper location of ligament attachment sites and drill tunnel locations and then guiding the surgeon to execute the plan. Despite agreement on the correct points of insertion, great variability exists in tunnel placement among surgeons and the rate of misplaced tunnels in ACL reconstruction surgery has been reported to be between 10-40 percent. Malpositioning of the bone tunnels is the main reason for revision surgery. The proposed research would increase the accuracy of the procedure versus current videoscopic techniques or versus competitive image guidance systems. The research plan is to establish a ""gold standard"" for registration accuracy using reconstructed CT scans, point-based surface matching algorithms, and optical tracking. Reconstructed MR models will be substituted for CT models and the accuracy reassessed. The US probe will then be calibrated and US surface collection will then be substituted for point based collection and the accuracy reassessed. Finally, registration of US directly to MR without reconstruction will be assessed.  PROPOSED COMMERCIAL APPLICATION: Not Available. n/a",Ultrasonic Registration of Knee Anatomy to MRI Images,6550304,R41AR049104,"['artificial intelligence', ' bioimaging /biomedical imaging', ' bone imaging /visualization /scanning', ' computed axial tomography', ' computer program /software', ' knee', ' magnetic resonance imaging', ' orthopedics', ' surgery material /equipment']",NIAMS,"CASURGICA, INC.",R41,2002,99995,0.016812547753495694
"Estimating Neural Network Precision for Cancer Diagnosis   DESCRIPTION (Provided by Applicant): This application's broad, long-term             objective is to diagnose cancer accurately, reducing both false-negative and         false-positive diagnoses. The research proposed in this application concerns         artificial neural networks (ANNs) which are important statistical tools that         are used frequently in computer-aided diagnosis (CAD) methods intended to            improve cancer diagnosis. The goal of this research is to provide error bars         for ANN output. The significance and health-relatedness of this research is          that the goal, if achieved, could represent a fundamental advance to ANNs in         CAD applications, by making ANN output more reliable for subsequent computer         processing and more intuitive to understand for radiologists to interpret and        incorporate (the diagnostic predictions made by ANNs) in their own diagnoses.        The proposed method could become the standard of practice, replacing the             conventional, one-ANN approach. The hypothesis to be tested is that artificial       neural network output has finite uncertainty which can be estimated and              expressed in terms of confidence intervals. The specific aims are:                                                                                                        (1) To demonstrate qualitatively the concept of uncertainty in ANN output and        the feasibility of developing multiple ANNs from a single set of training            cases.                                                                                                                                                                    (2) To develop and validate quantitative method(s) of ANN-precision estimation.                                                                                           (3) To apply ANN-precision estimation to a real-world CAD problem: computer          classification of malignant and benign clustered microcalcifications.                                                                                                     The research design is to use primarily computer simulations to investigate          properties of the output from multiple ANNs obtained from the same training          cases and to develop and validate practical method(s) for computing confidence       intervals in ANN output from these multiple ANNs, then to apply the new methods      to a real-world CAD task. The methods to be used include computer simulation,        ROC analysis, computation of confidence intervals, bootstrapping, parametric         estimation of statistical distributions, analytical analysis, and computer           analysis of breast lesions in mammograms.                                                                                                                                 n/a",Estimating Neural Network Precision for Cancer Diagnosis,6422575,R21CA093989,"['artificial intelligence', ' breast neoplasm /cancer diagnosis', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' female', ' human data', ' neoplasm /cancer classification /staging', "" women's health""]",NCI,UNIVERSITY OF CHICAGO,R21,2002,182408,-0.0013494932835861342
"COMPUTERIZED DETECTION OF PULMONARY NODULES   DESCRIPTION (Adapted from Applicant's Abstract): An essential factor in lung         cancer survival is early detection, with up to 50% long term survival among          patients whose tumors are detected at clinical stage I. Unfortunately, only 15%      of lung cancers are currently detected at this stage. A major problem in early       detection is the limitation of chest radiography, the initial procedure for          detection of pulmonary nodules; it is estimated that 30% of positive nodules         are currently missed. Therefore, the applicants proposed to develop an advanced      computer-aided diagnosis (CAD) scheme that assists radiologists in detecting         pulmonary nodules in chest radiographs by providing them with a ""second              opinion."" The main obstacle to achieving a clinically acceptable level of            performance in such schemes is the large number of false-positive detections.        Thus, this proposal focuses on improving the performance of pulmonary nodule         detection by substantially reducing the number of false positives detected. The      specific aims are: (1) To establish image databases of pulmonary nodules for         development and evaluation of a CAD scheme by (a)extracting regions of interest      containing nodule candidates from an existing database, and (b) developing a         new database of digital chest images for evaluation of the CAD schemes; (2) To       develop methods for removal of normal anatomic structures by implementing            radiologists' visual analysis strategy that (a) identify regions with similar        normal anatomic structures in the lung, and (b) remove anatomic structures           through non-linear registration and subtraction; (3) To develop methods to           select and combine image features for reduction of false positives by (a)            extracting image features characteristic of nodules from                             normal-structure-subtracted regions, (b) by applying adaptive rule-based tests,      (c) combining features by artificial neural networks to obtain a single index        for the reduction of false positives, and (d) using genetic algorithms to            select features that are most effective in distinguishing nodules from false         positives; and (4) To evaluate the benefit of the overall CAD scheme by (a)          performing observer studies to estimate improvement of radiologists' diagnostic      accuracy in the detection of pulmonary nodules without and with computer aid,        and (b) performing pilot prospective studies for preclinical evaluation. The         hypothesis is that a CAD scheme with a clinically acceptable sensitivity and         specificity will substantially improve radiologists' accuracy in the detection       of pulmonary nodules. Such a high-performance CAD scheme should advance the          early detection of pulmonary nodules, and therefore has the potential to             improve the prognosis for patients.                                                                                                                                       n/a",COMPUTERIZED DETECTION OF PULMONARY NODULES,6514433,R01CA085668,"['artificial intelligence', ' bioimaging /biomedical imaging', ' cancer information system', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' human data', ' image processing', ' lung neoplasms', ' neoplasm /cancer diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2002,169875,0.00251431467494615
"Multiresolution Autofocusing for Automated Cytogenetics The goal of this project is to develop innovative digital microscope autofocusing techniques for automated cytogenetics applications.  We propose a novel multi-resolution image analysis approach to focus measurement and detection, based on the recently developed mathematical theory of wavelet transform.  In comparison to currently available single-resolution techniques, the proposed method overcomes their fundamental limitations and promises considerably more accurate, reliable and faster means to compute and determine in-focus image position for image acquisition.  This will significantly increase the ability and efficacy of automated scanning microscope instruments for clinical and cancer cytogenetics applications. In Phase 1 we will investigate the feasibility of the proposed method based on its utilization in fluorescence microscopy.  We will develop and implement the algorithm and software for multi-resolution focus function computation and in-focus position determination.  We will test and evaluate the new method against the current best-performing algorithms by comparing (1) Accuracy; (2)  Range; (3)  Insensitivity to other parameters; and (4)  Speed. If the new approach achieves superior performance, in Phase 2 the technique will be further developed and extended to bright-field microscopy applications.  When fully developed, the new technology will be made available to Applied Imaging (AIC) for integration into the PowerGene cytogenetics automation products. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new techniques are developed and qualified for routine application, they will be made available to AIC for incorporation into the PowerGene product line of cytogenetics automation equipment, both in new systems sold and as an upgrade to existing systems already in use in cytogenetics labs, thus commercializing the technology quickly. n/a",Multiresolution Autofocusing for Automated Cytogenetics,6443502,R43RR016817,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' cytogenetics', ' digital imaging', ' fluorescence microscopy', ' fluorescent in situ hybridization', ' human data', ' image enhancement', ' image processing', ' mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R43,2002,91727,0.022872333755221273
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,0.02844565450499426
"COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY   DESCRIPTION (Adapted from Applicant's Abstract): The applicants proposed to          develop computer-aided diagnostic (CAD) schemes for detection and                    characterization of pulmonary nodules in digital chest images. For development       of reliable and predictable CAD schemes, they proposed to establish a large          database with 2,000 cases of chest radiographs, which include 1,000 nodule           cases and 1,000 non-nodule cases, in collaboration with Richard M. Slone, M.D.,      Mallinckrodt Institute of Radiology, Washington University, under a consortium       arrangement. An advanced CAD scheme for detection of lung nodules will be            developed by incorporating three subtraction techniques--temporal subtraction,       contralateral subtraction and energy subtraction--in order to achieve, on            average, a high sensitivity of 80-90% with a low false positive rate of              approximately 0.5 per chest image. They would investigate the usefulness of the      temporal subtraction technique in increasing the detection of subtle nodules         overlapped with ribs and also decreasing the number of false positives due to        rib-crossings, when a previous chest image of the same patient is available.         Contralateral subtraction, which is a novel technique for removal of peripheral      ribs in a single PA chest image, will be examined for enhancement in the             detection of overlapped nodules and reduction in the number of false positives.      They would also investigate the usefulness of energy subtraction soft-tissue         image for improved computerized detection of lung nodules in combination with        conventional chest images. In addition to the detection task, they would to          develop CAD schemes for characterization of nodules in order to distinguish          between benign and malignant nodules. This characterization task is to provide       the likelihood of malignance of lung nodules based on quantitative analysis of       image features of nodules detected by computer and/or by radiologists. With the      high level of detection performance that they expect to achieve, they propose        to develop a prototype CAD workstation and carry out a pilot study to examine        the clinical usefulness of CAD schemes on detection and characterization of          pulmonary nodules.                                                                                                                                                        n/a",COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY,6512959,R01CA062625,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' disease /disorder classification', ' human data', ' image processing', ' information systems', ' lung neoplasms', ' neoplasm /cancer radiodiagnosis', ' noninvasive diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2002,381567,0.040395020427611644
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6445973,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2001,354009,0.0009725506021441902
"COMPUTERIZED DETECTION OF PULMONARY NODULES   DESCRIPTION (Adapted from Applicant's Abstract): An essential factor in lung         cancer survival is early detection, with up to 50% long term survival among          patients whose tumors are detected at clinical stage I. Unfortunately, only 15%      of lung cancers are currently detected at this stage. A major problem in early       detection is the limitation of chest radiography, the initial procedure for          detection of pulmonary nodules; it is estimated that 30% of positive nodules         are currently missed. Therefore, the applicants proposed to develop an advanced      computer-aided diagnosis (CAD) scheme that assists radiologists in detecting         pulmonary nodules in chest radiographs by providing them with a ""second              opinion."" The main obstacle to achieving a clinically acceptable level of            performance in such schemes is the large number of false-positive detections.        Thus, this proposal focuses on improving the performance of pulmonary nodule         detection by substantially reducing the number of false positives detected. The      specific aims are: (1) To establish image databases of pulmonary nodules for         development and evaluation of a CAD scheme by (a)extracting regions of interest      containing nodule candidates from an existing database, and (b) developing a         new database of digital chest images for evaluation of the CAD schemes; (2) To       develop methods for removal of normal anatomic structures by implementing            radiologists' visual analysis strategy that (a) identify regions with similar        normal anatomic structures in the lung, and (b) remove anatomic structures           through non-linear registration and subtraction; (3) To develop methods to           select and combine image features for reduction of false positives by (a)            extracting image features characteristic of nodules from                             normal-structure-subtracted regions, (b) by applying adaptive rule-based tests,      (c) combining features by artificial neural networks to obtain a single index        for the reduction of false positives, and (d) using genetic algorithms to            select features that are most effective in distinguishing nodules from false         positives; and (4) To evaluate the benefit of the overall CAD scheme by (a)          performing observer studies to estimate improvement of radiologists' diagnostic      accuracy in the detection of pulmonary nodules without and with computer aid,        and (b) performing pilot prospective studies for preclinical evaluation. The         hypothesis is that a CAD scheme with a clinically acceptable sensitivity and         specificity will substantially improve radiologists' accuracy in the detection       of pulmonary nodules. Such a high-performance CAD scheme should advance the          early detection of pulmonary nodules, and therefore has the potential to             improve the prognosis for patients.                                                                                                                                       n/a",COMPUTERIZED DETECTION OF PULMONARY NODULES,6377798,R01CA085668,"['artificial intelligence', ' bioimaging /biomedical imaging', ' cancer information system', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' human data', ' image processing', ' lung neoplasms', ' neoplasm /cancer diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2001,169875,0.00251431467494615
"COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY   DESCRIPTION (Adapted from Applicant's Abstract): The applicants proposed to          develop computer-aided diagnostic (CAD) schemes for detection and                    characterization of pulmonary nodules in digital chest images. For development       of reliable and predictable CAD schemes, they proposed to establish a large          database with 2,000 cases of chest radiographs, which include 1,000 nodule           cases and 1,000 non-nodule cases, in collaboration with Richard M. Slone, M.D.,      Mallinckrodt Institute of Radiology, Washington University, under a consortium       arrangement. An advanced CAD scheme for detection of lung nodules will be            developed by incorporating three subtraction techniques--temporal subtraction,       contralateral subtraction and energy subtraction--in order to achieve, on            average, a high sensitivity of 80-90% with a low false positive rate of              approximately 0.5 per chest image. They would investigate the usefulness of the      temporal subtraction technique in increasing the detection of subtle nodules         overlapped with ribs and also decreasing the number of false positives due to        rib-crossings, when a previous chest image of the same patient is available.         Contralateral subtraction, which is a novel technique for removal of peripheral      ribs in a single PA chest image, will be examined for enhancement in the             detection of overlapped nodules and reduction in the number of false positives.      They would also investigate the usefulness of energy subtraction soft-tissue         image for improved computerized detection of lung nodules in combination with        conventional chest images. In addition to the detection task, they would to          develop CAD schemes for characterization of nodules in order to distinguish          between benign and malignant nodules. This characterization task is to provide       the likelihood of malignance of lung nodules based on quantitative analysis of       image features of nodules detected by computer and/or by radiologists. With the      high level of detection performance that they expect to achieve, they propose        to develop a prototype CAD workstation and carry out a pilot study to examine        the clinical usefulness of CAD schemes on detection and characterization of          pulmonary nodules.                                                                                                                                                        n/a",COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY,6362584,R01CA062625,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' disease /disorder classification', ' human data', ' image processing', ' information systems', ' lung neoplasms', ' neoplasm /cancer radiodiagnosis', ' noninvasive diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2001,373412,0.040395020427611644
"KNOWLEDGE DISCOVERY IN DISTRIBUTED CARDIAC IMAGE BASES DESCRIPTION (taken from application abstract):  Heart disease continues          to be the primary cause of death in the U.S., with 25% of all deaths             related to coronary artery disease (CAD). In addition to the loss of             irreplaceable human life, there are also staggering health care costs            and losses in productivity associated with the 1.5 million myocardial            infarctions suffered in the U.S. every year.  The present competing              renewal application seeks to make a contribution toward this vital               health care problem by exploring frontier computing methods to support           and facilitate CAD assessment.  The objective of the proposed research           is to develop and evaluate a methodology to accomplish the following             specific aims:                                                                                                                                                    (1)Knowledge Discovery: To design, implement and test novel database             (DB) ""mining"" algorithms to uncover associations and inferences imbedded         in clinical DBs and which can improve diagnostic performance.                    (2)Knowledge Base Enrichment: To use the knowledge resulting from DB             mining as well as conventional knowledge-acquisition methods to create           and evaluate a robust knowledge base (KB) with which to interpret                cardiovascular SPECT imagery and other types of relevant, patient-               specific information.                                                            (3)Distributed Knowledge Discovery and Processing:  To extend both the           Knowledge-discovery and knowledge-based processing methods to                    distributed, Internet-based setting for a twofold purpose: (I) to                provide users with widespread access to the resulting KB, and (ii) to            access and mine remote multi center DBs to further improve our knowledge         regarding the assessment of CAD.                                                                                                                                  The proposed work represents pioneering research in several ways,                especially: (I) the creation of innovative algorithms to mine image DBs,         (II) the application of these algorithms to the clinical assessment of           CAD, and (III) the creation of distributed DB mining and knowledge-based         processing methods to link geographically dispersed users and clinical           DBs.  The proposed research builds on our previous work on knowledge-            guided image interpretation, and represents an interinstitutional and            interdisciplinary effort between Georgia Tech and Emory University, a            longstanding collaboration that has previously resulted in numerous              joint publications and valuable insights centering on diagnostic                 imaging, and which has also supported several academic degrees.                   n/a",KNOWLEDGE DISCOVERY IN DISTRIBUTED CARDIAC IMAGE BASES,6351635,R01LM006726,"['Internet', ' angiography', ' artificial intelligence', ' bioimaging /biomedical imaging', ' cardiovascular imaging /visualization', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer data analysis', ' coronary disorder', ' diagnosis design /evaluation', ' heart disorder diagnosis', ' human data', ' information system analysis', ' mathematical model', ' myocardium', ' perfusion', ' single photon emission computed tomography']",NLM,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2001,362213,-0.00035179112943032665
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6376842,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2001,607399,0.03630039458475842
"INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE This application is a request for support of the July 2001 meeting on Information Processing in Medical Imaging (IPMI'01) to be held on the campus of the University of California, Davis. During 16 previous meetings, this biennial workshop-style conference has traditionally concentrated on the latest advancements in the acquisition, processing, analysis, display, and perception of medical images. At the 2001 meeting, we intend to continue this tradition while encouraging contributions from young investigators, specifically advanced graduate students, postdoctoral fellows, and junior faculty. The emphasis is on applied mathematical techniques in computer vision, microimaging techniques, and information technology. Advances reported at this meeting are especially important in the study of neurological disorders, cardiovascular disease and cancer, although applications in the area of functional genomics, orthopedics and soft tissue biomechanics are also represented. The conference attracts researchers from a broad range of disciplines, particularly computer scientists, neuroscientists, electrical engineers, cardiologists, mathematicians, oncologists, and physicists. All share an interest in improving the quality of health care through the extraction and presentation of diagnostic information from medical image data. Approximately 130 individuals will be invited to attend; there will be approximately 25-30 speakers and 25-30 poster presentations. Papers are accepted based on peer review by a 25 member scientific committee of 15-20 page manuscripts. Selected papers will be published in proceedings that will be available at the conference.  n/a",INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE,6231502,R13RR015416,"['bioimaging /biomedical imaging', ' biomechanics', ' cardiovascular disorder', ' computer data analysis', ' diagnosis design /evaluation', ' functional /structural genomics', ' image processing', ' informatics', ' mathematics', ' meeting /conference /symposium', ' neoplasm /cancer', ' nervous system disorder', ' orthopedics']",NCRR,UNIVERSITY OF CALIFORNIA DAVIS,R13,2001,5000,-0.008313691237320106
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6210821,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2000,395990,0.0009725506021441902
"IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY DESCRIPTION:  The research and development of teleradiology and telemedicine     systems has progressed through many technical and clinical endeavors.  When      dealing with large volume image transmission and storage, image data             compression is an outstanding issue in medical applications to which current     techniques were not designed to address.  The technical objectives of this       project are to develop optimized error-free as well as error-controllable        methods for medical image compression based on wavelet transform and             associated methods.  In this project, we employ both advanced artificial         intelligent and compression techniques to achieve these goals.                                                                                                    Our recent research outcomes include:  (a) development of a mathematics          approach to unify prediction, subband, and wavelet transforms, (b)               development of convolution neural network training methods to obtain             optimized wavelet kernel, (c) development of a data splitting technique to       improve edge accuracy and to provide error-control methods, and (d)              development of an integer implementation method for all wavelet transforms,      etc.  Based on the above technical advances, we propose to use integer form      of an adaptive (optimized) wavelets in conjunction with newly developed          coding methods such as ""partitioning in hierarchical trees"" (PHT) for            lossless compression.  For error-controllable approaches, we propose to use      adaptive wavelets coupled with optimized neural network prediction methods       in this study.  Since lossless compression is a part of the error -              controllable method, both systems can be implemented in the same scheme          which is a breakthrough approach in the field.  We will compare the              compression results (i.e., compression ratio and speed) of the proposed          compression methods with those of the current wavelet techniques using the       embedded zero-tree coding method.  At the end of the project, we will            deliver a software package for the radiological society.  Hence, the             evaluation for various clinical applications using the proposed methods can      be performed by the investigators.                                                                                                                                As the field of telemedicine is rapidly growing, we believe that development     of a dedicated compression module for economical storage and fast                communication of patient data (particularly for patient images) is               necessary.  This project is designed to address the related technical issues     with a strong clinical consideration.                                             n/a",IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY,6173899,R01CA079139,"['artificial intelligence', ' bioimaging /biomedical imaging', ' charge coupled device camera', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' radiology', ' telemedicine']",NCI,GEORGETOWN UNIVERSITY,R01,2000,176034,0.018287946802609503
"COMPUTERIZED DETECTION OF PULMONARY NODULES   DESCRIPTION (Adapted from Applicant's Abstract): An essential factor in lung         cancer survival is early detection, with up to 50% long term survival among          patients whose tumors are detected at clinical stage I. Unfortunately, only 15%      of lung cancers are currently detected at this stage. A major problem in early       detection is the limitation of chest radiography, the initial procedure for          detection of pulmonary nodules; it is estimated that 30% of positive nodules         are currently missed. Therefore, the applicants proposed to develop an advanced      computer-aided diagnosis (CAD) scheme that assists radiologists in detecting         pulmonary nodules in chest radiographs by providing them with a ""second              opinion."" The main obstacle to achieving a clinically acceptable level of            performance in such schemes is the large number of false-positive detections.        Thus, this proposal focuses on improving the performance of pulmonary nodule         detection by substantially reducing the number of false positives detected. The      specific aims are: (1) To establish image databases of pulmonary nodules for         development and evaluation of a CAD scheme by (a)extracting regions of interest      containing nodule candidates from an existing database, and (b) developing a         new database of digital chest images for evaluation of the CAD schemes; (2) To       develop methods for removal of normal anatomic structures by implementing            radiologists' visual analysis strategy that (a) identify regions with similar        normal anatomic structures in the lung, and (b) remove anatomic structures           through non-linear registration and subtraction; (3) To develop methods to           select and combine image features for reduction of false positives by (a)            extracting image features characteristic of nodules from                             normal-structure-subtracted regions, (b) by applying adaptive rule-based tests,      (c) combining features by artificial neural networks to obtain a single index        for the reduction of false positives, and (d) using genetic algorithms to            select features that are most effective in distinguishing nodules from false         positives; and (4) To evaluate the benefit of the overall CAD scheme by (a)          performing observer studies to estimate improvement of radiologists' diagnostic      accuracy in the detection of pulmonary nodules without and with computer aid,        and (b) performing pilot prospective studies for preclinical evaluation. The         hypothesis is that a CAD scheme with a clinically acceptable sensitivity and         specificity will substantially improve radiologists' accuracy in the detection       of pulmonary nodules. Such a high-performance CAD scheme should advance the          early detection of pulmonary nodules, and therefore has the potential to             improve the prognosis for patients.                                                                                                                                       n/a",COMPUTERIZED DETECTION OF PULMONARY NODULES,6088420,R01CA085668,"['artificial intelligence', ' bioimaging /biomedical imaging', ' cancer information system', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' human data', ' image processing', ' lung neoplasms', ' neoplasm /cancer diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2000,169875,0.00251431467494615
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6137486,R01CA053877,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2000,442719,-0.005639786106950336
"COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY   DESCRIPTION (Adapted from Applicant's Abstract): The applicants proposed to          develop computer-aided diagnostic (CAD) schemes for detection and                    characterization of pulmonary nodules in digital chest images. For development       of reliable and predictable CAD schemes, they proposed to establish a large          database with 2,000 cases of chest radiographs, which include 1,000 nodule           cases and 1,000 non-nodule cases, in collaboration with Richard M. Slone, M.D.,      Mallinckrodt Institute of Radiology, Washington University, under a consortium       arrangement. An advanced CAD scheme for detection of lung nodules will be            developed by incorporating three subtraction techniques--temporal subtraction,       contralateral subtraction and energy subtraction--in order to achieve, on            average, a high sensitivity of 80-90% with a low false positive rate of              approximately 0.5 per chest image. They would investigate the usefulness of the      temporal subtraction technique in increasing the detection of subtle nodules         overlapped with ribs and also decreasing the number of false positives due to        rib-crossings, when a previous chest image of the same patient is available.         Contralateral subtraction, which is a novel technique for removal of peripheral      ribs in a single PA chest image, will be examined for enhancement in the             detection of overlapped nodules and reduction in the number of false positives.      They would also investigate the usefulness of energy subtraction soft-tissue         image for improved computerized detection of lung nodules in combination with        conventional chest images. In addition to the detection task, they would to          develop CAD schemes for characterization of nodules in order to distinguish          between benign and malignant nodules. This characterization task is to provide       the likelihood of malignance of lung nodules based on quantitative analysis of       image features of nodules detected by computer and/or by radiologists. With the      high level of detection performance that they expect to achieve, they propose        to develop a prototype CAD workstation and carry out a pilot study to examine        the clinical usefulness of CAD schemes on detection and characterization of          pulmonary nodules.                                                                                                                                                        n/a",COMPUTER AIDED DIAGNOSIS IN CHEST RADIOGRAPHY,6044779,R01CA062625,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' disease /disorder classification', ' human data', ' image processing', ' information systems', ' lung neoplasms', ' neoplasm /cancer radiodiagnosis', ' noninvasive diagnosis', ' thoracic radiography']",NCI,UNIVERSITY OF CHICAGO,R01,2000,380968,0.040395020427611644
"DEVELOPMENT OF COMPUTER BASED TECHNIQUES IN MAMMOGRAPHY The goal of the proposed research is to develop computer-aided diagnosis         (CAD) schemes in order to improve the diagnostic accuracy of breast cancer       in mammography. Four specific aims are included: (l) development of              computer programs for the detection and characterization of                      microcalcifications, (2) development of computer programs for detection          and characterization of masses, (3) implementation of the CAD algorithms         in a dedicated workstation to perform a pilot preclinical testing of the         accuracy of the CAD programs, and (4) evaluation of the effects of the CAD       schemes on radiologists' performance. The proposed CAD schemes will aid          radiologists in screening mammograms for suspicious lesions and provide          estimate of the likelihood of malignancy for the detected lesions. The           information is expected to reduce the miss rate and to improve the               positive predictive value of the mammographic findings.                                                                                                           A data base of clinical mammograms which include malignant and benign            microcalcifications and masses will be established. Physical measures            which characterize the significant image features of the lesions will be         developed. Based on these measures, linear discriminant classifiers or           neural network classifiers will be optimized using a genetic algorithm           approach to classify true and false signals and to estimate the likelihood       of malignancy for each type of lesions.                                                                                                                           For automated detection and classification of microcalcifications, we will       investigate the usefulness of multiresolution analysis for enhancement of        the signal-to-noise ratio of the microcalcifications and for improvement         of feature extraction techniques. Physical characteristics such as size,         shape, frequency spectrum, spatial distribution, clustering properties,          and texture features will be extracted and analyzed with the classifiers.                                                                                         For automated detection and classification of masses, we will improve the        background correction and signal segmentation techniques, and develop            effective false-positive reduction methods. Adaptive filtering, edge             enhancement, and clustering segmentation methods will be developed for           extraction of the mass margins. Physical characteristics such as size,           density, edge sharpness, calcifications, shape, lobulation, spiculation,         and multiresolution wavelet texture features will be extracted from the          masses and analyzed with the classifiers.                                                                                                                         The algorithms will be implemented in a dedicated CAD workstation and            preclinical testing will be conducted. The performance of the programs in        a clinical setting will be assessed. The algorithms will be revised and          improved based on the information obtained with the preclinical testing.         The study is a vital step for the development of a clinically reliable CAD       scheme.                                                                                                                                                           Observer performance studies using receiver operating characteristic (ROC)       methodology will be conducted to evaluate the effects of the CAD schemes         on radiologists'performance.                                                      n/a",DEVELOPMENT OF COMPUTER BASED TECHNIQUES IN MAMMOGRAPHY,6164055,R01CA048129,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasm /cancer diagnosis', ' breast neoplasms', ' computational neuroscience', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mammography', ' mathematical model']",NCI,UNIVERSITY OF MICHIGAN,R01,2000,452383,0.03429354333805444
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING DESCRIPTION (Applicant's Abstract):  Facial expression communicates              information about emotional response and plays a critical role in the            regulation of interpersonal behavior.  Current human-observer based methods      for measuring facial expression are labor intensive, qualitative, and            difficult to standardize across laboratories and over time.  To make             feasible more rigorous, quantitative measurement of facial expression in         diverse applications, we formed an interdisciplinary research group which        covers expertise in facial expression analysis and image processing.  In the     funding period, we developed and demonstrated the first version of an            automated system for measuring facial expression in digitized images.  The       system can discriminate nine combinations of FACS action units in the upper      and lower face, quantity the timing and topography of action unit intensity      in the brow region; and geometrically normalize image sequences within a         range of plus or minus 20 degrees of out of-plane.                                                                                                                In the competing renewal, we will increase the number of action unit             combinations that are recognized, implement convergent methods of                quantifying action unit intensity, increase the generalizability of action       unit estimation to a wider range of image orientations, test facial image        processing (FIP) in image sequences from directed facial action tasks and        laboratory studies of emotion regulation, and facilitate the integration of      FIP into existing data management and statistical analysis software for use      by behavioral science researchers and clinicians.  With these goals              completed, FIP will eliminate the need for human observers in coding facial      expression, promote standardize measurement, make possible the collection        and processing of larger, more representative data sets, and open new areas      of investigation and clinical application.                                        n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6185949,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,MELLON PITTS CORPORATION (MPC CORP),R01,2000,233574,-0.025082428868250822
"KNOWLEDGE DISCOVERY IN DISTRIBUTED CARDIAC IMAGE BASES DESCRIPTION (taken from application abstract):  Heart disease continues          to be the primary cause of death in the U.S., with 25% of all deaths             related to coronary artery disease (CAD). In addition to the loss of             irreplaceable human life, there are also staggering health care costs            and losses in productivity associated with the 1.5 million myocardial            infarctions suffered in the U.S. every year.  The present competing              renewal application seeks to make a contribution toward this vital               health care problem by exploring frontier computing methods to support           and facilitate CAD assessment.  The objective of the proposed research           is to develop and evaluate a methodology to accomplish the following             specific aims:                                                                                                                                                    (1)Knowledge Discovery: To design, implement and test novel database             (DB) ""mining"" algorithms to uncover associations and inferences imbedded         in clinical DBs and which can improve diagnostic performance.                    (2)Knowledge Base Enrichment: To use the knowledge resulting from DB             mining as well as conventional knowledge-acquisition methods to create           and evaluate a robust knowledge base (KB) with which to interpret                cardiovascular SPECT imagery and other types of relevant, patient-               specific information.                                                            (3)Distributed Knowledge Discovery and Processing:  To extend both the           Knowledge-discovery and knowledge-based processing methods to                    distributed, Internet-based setting for a twofold purpose: (I) to                provide users with widespread access to the resulting KB, and (ii) to            access and mine remote multi center DBs to further improve our knowledge         regarding the assessment of CAD.                                                                                                                                  The proposed work represents pioneering research in several ways,                especially: (I) the creation of innovative algorithms to mine image DBs,         (II) the application of these algorithms to the clinical assessment of           CAD, and (III) the creation of distributed DB mining and knowledge-based         processing methods to link geographically dispersed users and clinical           DBs.  The proposed research builds on our previous work on knowledge-            guided image interpretation, and represents an interinstitutional and            interdisciplinary effort between Georgia Tech and Emory University, a            longstanding collaboration that has previously resulted in numerous              joint publications and valuable insights centering on diagnostic                 imaging, and which has also supported several academic degrees.                   n/a",KNOWLEDGE DISCOVERY IN DISTRIBUTED CARDIAC IMAGE BASES,6151289,R01LM006726,"['Internet', ' angiography', ' artificial intelligence', ' bioimaging /biomedical imaging', ' cardiovascular imaging /visualization', ' computer assisted diagnosis', ' computer assisted medical decision making', ' coronary disorder', ' diagnosis design /evaluation', ' heart disorder diagnosis', ' human data', ' information system analysis', ' mathematical model', ' myocardium', ' perfusion', ' single photon emission computed tomography']",NLM,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2000,351662,-0.00035179112943032665
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6173999,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2000,563099,0.03630039458475842
"TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH Developing artificial intelligence technology for medical imaging applications requires training models on large and diverse datasets.  Currently, aggregation of large data repositories, including radiology and pathology images, is limited by concerns around patient privacy.  In order to successfully share medical images, an institution must be able to quickly and accurately de-identify large numbers of images in batches.  This process is currently manual and time-consuming. We propose a pipeline to remove PHI from both radiology DICOM images and pathology whole slide images by leveraging machine learning, natural language processing, and compartmentalized workflow techniques to significantly reduce the human intervention needed to anonymize medical images.  In addition to examining header data in the images, we will use optical character recognition and computer vision algorithms to detect text in any location or orientation in the image, then automatically record and subsequently purge these regions. These techniques will be configured to work on a variety of image types (CT, MRI, radiograph, etc) and cover multiple OEM vendors for both radiology and pathology images. This phase I statement of work will construct the software tools, methods, and datasets necessary to facilitate a phase II where the complex algorithms needed for autonomous deidentification will be developed.  This phase II processing will be referred to throughout this document as the workflow. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH,10274086,5N91020C00023,"['Algorithms', 'Artificial Intelligence', 'Complex', 'Computer Vision Systems', 'Consumption', 'Contracts', 'Data', 'Data Set', 'Digital Imaging and Communications in Medicine', 'Elements', 'Excision', 'Head', 'Human', 'Image', 'Ingestion', 'Institution', 'Intervention', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Medical Imaging', 'Medical Technology', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology', 'Phase', 'Process', 'Radiology Specialty', 'Research', 'Sampling', 'Slide', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Vendor', 'Work', 'cancer imaging', 'data ingestion', 'data warehouse', 'file format', 'optical character recognition', 'pathology imaging', 'patient privacy', 'purge', 'radiological imaging', 'whole slide imaging']",NCI,"BIODATA CONSORTIUM, LLC",N43,2020,386526,0.02547522357312058
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,10000961,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2020,702450,0.023818029343018247
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.03522473419855748
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,0.017612407975322222
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9913520,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'algorithm training', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,235027,-0.002304033587648173
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,9867431,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,806128,0.026207714641749077
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.035937349662512386
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning.",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,10140491,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis ', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'software infrastructure', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2020,742405,-0.019980157256598657
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9997914,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,498014,0.040199242665563954
"Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization Project Summary Prostate cancer (PCa) is the most diagnosed form of non-cutaneous cancer in US men. The selection of patients who require immediate treatment from those suitable for active surveillance currently relies on non- specific and inaccurate measurements. A method that allows clinicians to more confidently discriminate clinically relevant from non-life-threatening tumors is needed to improve patient management. Multiparametric magnetic resonance imaging (mpMRI) is the preferred non-invasive imaging modality for characterizing primary PCa. However, its accuracy for detecting clinically significant PCa is variable. We propose to address this limitation by combining mpMRI with positron emission tomography (PET) with a PCa-specific radiotracer and using advanced multimodal machine learning models (i.e. radiomics and deep learning) to characterize tumor aggressiveness based on the imaging data. Recently, scanners capable of simultaneous PET and MR data acquisition in human subjects have become commercially available. An integrated MR-PET scanner is the ideal tool for comparing MR and PET derived image features to identify those that provide complementary information and build a hybrid PET-mpMRI model that most accurately identifies clinically significant tumors. While this novel technology allows the acquisition of perfectly coregistered complementary anatomical, functional and metabolic data in a single imaging session, a new challenge needs to first be addressed to obtain quantitatively accurate PET data. In an integrated MR-PET scanner, the information needed for PET attenuation correction (AC) has to be derived from the MR data and the methods currently available for this task are inadequate for advanced quantitative studies. We have formed an academic-industrial partnership to accelerate the translation of multimodal MR-PET machine learning approaches into PCa research and clinical applications by addressing the AC challenge and validating machine learning models for detecting clinically significant disease against gold standard histopathology in patients undergoing radical prostatectomy. Specifically, we will: (1) Develop and validate an MR-based approach for obtaining quantitatively accurate PET data. We hypothesize that attenuation maps as accurate as those obtained using a 511 keV transmission source – the true gold standard for PET AC – will be obtained; (2) Identify the multimodal radiomics model that most accurately predicts PCa aggressiveness. We hypothesize that the diagnostic accuracy of this approach will be superior to that offered by the stand-alone modalities; (3) Evaluate radiomics and deep learning approaches for predicting pPCa aggressiveness. We hypothesize that machine learning approaches will achieve a higher predictive accuracy when applied to data acquired simultaneously than sequentially. Project narrative A better method to non-invasively characterize primary prostate cancer is needed to improve patient management. Extracting additional information from multimodality quantitative MR-PET data using machine learning approaches is expected to result in better diagnostic performance. In this work, we propose to accelerate the translation of quantitative MR-PET to prostate cancer research and clinical applications. In particular, we will develop and validate an MR-based attenuation correction approach to guarantee that quantitatively accurate PET data are obtained in an integrated MR-PET scanner and then use machine learning approaches to characterize the aggressiveness of the tumors in patients undergoing radical prostatectomy.",Multimodal MR-PET Machine Learning Approaches for Primary Prostate Cancer Characterization,9853761,R01CA218187,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Biopsy', 'Cancer Death Rates', 'Cancer Patient', 'Classification', 'Computer software', 'Data', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Early treatment', 'FOLH1 gene', 'Gold', 'Guidelines', 'Hand', 'Histopathology', 'Hybrids', 'Image', 'Individual', 'Interobserver Variability', 'Kinetics', 'Lesion', 'Life Expectancy', 'Ligands', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Meta-Analysis', 'Metabolic', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Morphology', 'PSA level', 'Patient Selection', 'Patients', 'Pelvis', 'Performance', 'Phenotype', 'Physiological', 'Positron-Emission Tomography', 'Prostate', 'Quality of life', 'Radical Prostatectomy', 'Reproducibility', 'Risk', 'Scanning', 'Source', 'Testing', 'Time', 'Translations', 'Work', 'anticancer research', 'attenuation', 'base', 'bone imaging', 'cancer classification', 'cancer imaging', 'clinical application', 'clinically relevant', 'clinically significant', 'data acquisition', 'deep learning', 'diagnostic accuracy', 'human subject', 'imaging modality', 'improved', 'industry partner', 'men', 'multimodal data', 'multimodality', 'new technology', 'non-invasive imaging', 'radiologist', 'radiomics', 'radiotracer', 'tool', 'transmission process', 'tumor']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,671823,-0.039777567456558506
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,0.03325858635083918
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9984379,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Chemotherapy and/or radiation', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'automated segmentation', 'cancer care', 'cancer recurrence', 'cancer therapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2020,77450,-0.00797514888349274
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9976466,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'neural network classifier', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,385010,0.04475972274061687
"Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy PROJECT SUMMARY Introduction: PhotoniCare, Inc. is a medical device company developing the TOMi Scope, a handheld, optical imaging device for improved diagnosis of middle ear health. The purpose of this proposal is to establish and evaluate a machine learning approach to facilitate both: (1) ease and reliability of quality data capture in a pediatric population from users with a range of otscopy expertise, and; (2) assist interpretation of the TOMi Scope’s correlated otoscopy and depth-resolved images in order to enable improved diagnostic accuracy and, ultimately, effective management. Significance: Ear infections affect 93% of all children, yet they are one of the most poorly diagnosed (~50% accuracy) and managed diseases in all of medicine, resulting in high antimicrobial over-prescription and resistance development. Correctly identifying the absence or presence/type of middle ear effusion (MEE; fluid) through the non-transparent eardrum is critical to accurate diagnosis, and the limited current diagnostic tools suffer poor diagnostic adoption (7-38% reported use) and accuracy (50-70%) due to inherent subjectivity and dependence on user expertise. Therefore, there is a clear and unmet need for superior, objective screening, starting with a definitive yet easily and reliably usable diagnostic tool for this extremely prevalent yet poorly managed disease. Hypothesis: Applying a machine learning approach to TOMi Scope imaging guidance and diagnostic classification will facilitate both: 1) ease-of-use and reliable quality data collection improvement, and 2) accurate detection of the presence or absence of MEE, as well as classification of the type of infection, regardless of user experience. Specific Aims: (1) Collect labeled TOMi Scope data (otoscopy and depth-scan images) from 268 patients at pediatric offices affiliated with UPMC Children’s Hospital of Pittsburgh, (2) Achieve reliable usability of the TOMi Scope by guiding image capture using TOMi-net, a deep learning model, (3) Develop a multimodal deep learning model to provide diagnostic assistance using TOMi Scope otoscopy and depth-scan data. Commercial Opportunity: The TOMi Scope will provide physicians with a superior user experience and new, objective information, enabling better decision-making for antibiotic prescription and surgical intervention. This has the potential to impact the standard of care for ~1B children worldwide that experience ear infections, representing a multi-billion-dollar commercial opportunity. PROJECT NARRATIVE Ear infections (otitis media) are highly prevalent in the pediatric population and represent a significant clinical challenge due to the limitations of the gold-standard diagnostic tools, resulting in high antimicrobial prescription and consequent resistance development. Accurate detection and classification of effusion (fluid) in the middle ear is a critical element for this diagnosis, and for making informed medical treatment decisions, particularly regarding antibiotic stewardship. The long-term goal of this work is to reduce antibiotic resistance and healthcare costs through improving patient outcomes by addressing the low diagnostic accuracy and user experience issues of current subjective methods, with a novel, non-invasive imaging tool capable of quantitative depth-resolved measurements to not only visualize the underlying infection behind the eardrum, but also, with automated machine learning image analysis algorithms, minimize user experience dependence and variability.",Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy,10156035,R44DC017422,"['Acute', 'Address', 'Adoption', 'Affect', 'Algorithmic Analysis', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Appointment', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials Unit', 'Collection', 'Custom', 'Data', 'Data Collection', 'Decision Making', 'Dependence', 'Detection', 'Development', 'Development Plans', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Elements', 'External auditory canal', 'Feedback', 'Focus Groups', 'Goals', 'Gold', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Imaging Device', 'Infection', 'Label', 'Light', 'Liquid substance', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medical center', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopy', 'Patient-Focused Outcomes', 'Patients', 'Pediatric Hospitals', 'Pediatrics', 'Phase', 'Physicians', 'Population', 'Prevalence', 'Primary Health Care', 'Recording of previous events', 'Reporting', 'Resistance development', 'Scanning', 'Schedule', 'Surface', 'Surveys', 'Testing', 'Time', 'Training', 'Tympanic membrane', 'Universities', 'Work', 'accurate diagnosis', 'antimicrobial', 'bacterial resistance', 'clinical development', 'clinically relevant', 'convolutional neural network', 'deep learning', 'diagnostic accuracy', 'ear infection', 'effusion', 'electronic data capture system', 'experience', 'hearing impairment', 'image guided', 'improved', 'middle ear', 'middle ear fluid', 'multimodality', 'non-invasive imaging', 'novel', 'optical imaging', 'prevent', 'recruit', 'research clinical testing', 'screening', 'standard of care', 'tool', 'usability']",NIDCD,"PHOTONICARE, INC.",R44,2020,1136886,0.027253808840319894
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,-0.0030251648283383457
"Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention, which is critical in reducing long term toxicity of cancers. To avoid excessively high radiation doses to organs-at-risk (OARs), OARs need to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dose distribution. Despite tremendous effort in developing semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability, as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria, thus leading to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. In summary, an accurate and fast process for segmenting OARs in treatment planning using CT scans is needed for improving patient outcomes and reducing the cost of radiation therapy of cancers. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, an automatic OAR segmentation product will be developed in this project with the three aims: 1) further improve the performance and robustness of OAR segmentation algorithms, focusing on addressing the heterogeneity issue of different clinical environments; 2) further enrich the functionalities and enhance usability of the cloud- based software product; and 3) perform clinical validation study on the algorithm performance and software usability at collaborating sites. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. The time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based automatic OAR segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers,10081752,R44CA254844,"['3-Dimensional', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Area', 'Artificial Intelligence', 'Atlases', 'Attention', 'Body Regions', 'Body part', 'Cancer Patient', 'Chest', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data', 'Development', 'Digital Imaging and Communications in Medicine', 'Dose', 'Early Diagnosis', 'Environment', 'Healthcare', 'Heterogeneity', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Label', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medical', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Online Systems', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Survival Rate', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Treatment Cost', 'Update', 'X-Ray Computed Tomography', 'algorithm development', 'automated segmentation', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinical heterogeneity', 'cloud based', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'dosimetry', 'healthcare community', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'life-long learning', 'millimeter', 'novel', 'phase 1 study', 'prototype', 'satisfaction', 'segmentation algorithm', 'simulation', 'software development', 'success', 'tool', 'treatment planning', 'usability', 'user-friendly', 'validation studies']",NCI,"CARINA MEDICAL, LLC",R44,2020,1000000,-0.011156989438783653
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.0005973775706005567
"Cardiac CT Deblooming PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the most common type of heart disease, killing over 370,000 Americans annu- ally2. Cardiac CT is a safe, accurate, non-invasive method widely employed for diagnosis of CAD and planning therapeutic interventions. With the current CT technology, calcium blooming artifacts severely limit the accuracy of coronary stenosis assessment. Similarly, stent blooming artifacts lead to overestimation of in-stent restenosis. As a result, many coronary CT angiography (CCTA) scans are non-diagnostic and result in patients receiving costly and invasive coronary angiography (ICA) procedures.  Based on extensive feasibility results, the goal of this project is to use deep learning innovations to fundamen- tally eliminate blooming artifacts without costly redesign of the CT hardware. A consortium between GE Re- search, Rensselaer Polytechnic Institute and Weill Cornell Medicine will develop dedicated imaging protocols and machine learning methods to avoid or minimize blooming artifacts and evaluate the clinical impact of the proposed solutions. In Aim 1, the CT scan protocol will be optimized and paired with deep learning reconstruc- tion and post-processing algorithms to generate high-resolution CT images and prevent blooming artifacts. In Aim 2, image-domain and raw-data-domain deep learning processing algorithms will be developed to correct for residual blooming. After successful demonstration of the proposed methods on phantom scans and emulated clinical datasets, in Aim 3 the proposed CT methods will be clinically demonstrated and optimized based on 100 patients with coronary artery disease, using intravascular ultrasound as the ground-truth reference.  At the end of the project, we will have demonstrated and publicly disseminated a systematic methodology to essentially remove blooming artifacts in cardiac CT without a costly hardware upgrade. This will be another suc- cess of deep learning, enabling accurate coronary stenosis assessment and eliminating many unnecessary diag- nostic catheterizations. PROJECT NARRATIVE Blooming artifacts severely limit the accuracy of coronary stenosis assessment with cardiac CT, leading to un- necessary invasive coronary angiography procedures. The goal of this project is to eliminate blooming artifacts without costly redesign of the CT hardware, but based on optimized scan protocols and deep-learning-based image reconstruction and post-processing techniques. The proposed CT methods will be clinically demonstrated and optimized based on CT scans of 100 patients with coronary artery disease and using intravascular ultrasound as the ground-truth reference.",Cardiac CT Deblooming,9943684,R01HL151561,"['Address', 'Algorithms', 'American', 'Angiography', 'Area', 'Attenuated', 'Calcium', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Collaborations', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Data Set', 'Diagnosis', 'Goals', 'Heart', 'Heart Diseases', 'High Resolution Computed Tomography', 'Hospitals', 'Image', 'In Vitro', 'Institutes', 'Lead', 'Measurement', 'Medicine', 'Metals', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'New York', 'Noise', 'Outcome', 'Patients', 'Physics', 'Plant Roots', 'Presbyterian Church', 'Prevention', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Scanning', 'Speed', 'Stenosis', 'Stents', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Training', 'Ultrasonography', 'Validation', 'X-Ray Computed Tomography', 'base', 'calcification', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'diagnostic catheterization', 'image reconstruction', 'improved', 'in silico', 'in vivo', 'innovation', 'learning network', 'machine learning method', 'man', 'microCT', 'mortality', 'prevent', 'reconstruction', 'recruit', 'restenosis', 'simulation', 'success', 'temporal measurement', 'virtual', 'virtual reality simulation']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2020,900092,0.0013491802379861587
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,10193990,R33AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Models', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'automated segmentation', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'feature extraction', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'large datasets', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R33,2020,403748,0.02084212756475931
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9927625,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,458900,0.017058058629856283
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9928429,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'algorithm training', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'segmentation algorithm', 'software infrastructure', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2020,195000,0.01750158404912466
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10040835,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2020,113350,-0.01971407506653399
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.03149062215255328
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,-0.008831960365919385
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,9828620,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,385444,0.007902707125735443
"International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020 Project summary  The Medical Image Computing and Computer Assisted Interventions (MICCAI) society is dedicated to the promotion, preservation and facilitation of research and education in the fields of medical image computing and computer assisted interventions, including biomedical imaging and robotics. This aim is achieved through the organization and operation of regular international conferences of the highest quality, and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their origin in three separate but related conferences beginning in early 1990s--Visualization in Biomedical Computing, Computer Vision and Virtual Reality in Robotics and Medicine, and Medical Robotics and Computer Assisted Surgery--, which merged into a single annual conference in 1998. MICCAI Conferences have defined new scientific disciplines over the years and have become the premier meeting in the field. The conference proceedings have an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & medical image processing, computer-aided diagnosis, interventions & surgery, machine learning in medical imaging, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry.  The MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance). Selected presented papers became landmark publications over the years with up to 2,000 citations. The conference series includes satellite events like community-driven software challenges, workshops and tutorials just before and/or after the main conference. These events focus on the current status and advances in topics relevant to MICCAI and are very well attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendees are typically from over 45 countries, with strong student representation (>40%). The MICCAI 2020 Conference will be held in Lima, Peru in October 4th-8th, 2020. Since 2018, a Mentorship Program to connect students and young investigators with established mentors from academia and industry is also part of the conference. Along with the Mentorship Program and mission of the “Women in MICCAI” Committee, this proposal requests funds to support student and early investigator travel awards to enhance diversity in conference attendance (including women, underrepresented minorities, students with disabilities, and people from disadvantaged backgrounds) and provide minority groups with a unique opportunity to reach an international audience for career development and collaborations. Project narrative The Medical Image Computing and Computer Assisted Intervention (MICCAI) 2020 Conference will be held in Lima, Peru, October 4th-8th, 2020. MICCAI is the premier meeting in the medical image computing and computer assisted intervention communities, having introduced landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students and early investigators to present their work at MICCAI 2020--with focus on minority groups and underrepresented populations--providing them with an opportunity to attend the meeting, foster professional development and identify collaborations in an established international community.",International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020,10070479,R13EB030422,"['Academia', 'Academy', 'American', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Costs and Benefits', 'Country', 'Development', 'Disabled Persons', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority Groups', 'Mission', 'Oncology', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Peru', 'Physicians', 'Physiology', 'Policies', 'Postdoctoral Fellow', 'Psychiatry', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Robotics', 'Role', 'Scientist', 'Series', 'Societies', 'Students', 'Training', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Populations', 'United States National Institutes of Health', 'Visualization', 'Woman', 'Women&apos', 's Group', 'Work', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'community organizations', 'cost', 'disabled students', 'early-career faculty', 'experience', 'graduate student', 'image guided', 'image processing', 'imaging system', 'innovation', 'interest', 'meetings', 'operation', 'posters', 'preservation', 'programs', 'racial and ethnic', 'robotic system', 'social', 'student participation', 'success', 'supportive environment', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NIBIB,CHILDREN'S RESEARCH INSTITUTE,R13,2020,9850,-0.01652640528038313
"Data-driven Head Motion Correction in PET Imaging Using Deep Learning Project Summary Positron-emission tomography (PET) is an imaging modality that allows clinicians and researchers to study the physiological or pathological processes of the human body, and in particular the brain via the use of specific tracers. For brain PET imaging, patient head movement during scanning presents a challenge for accurate PET image reconstruction and subsequent quantitative analysis. Problems due to head motion are exacerbated by the long duration of the scans, with scan times commonly over one hour. Furthermore, some PET studies specifically involve subjects that either have trouble staying still due to psychological variations, e.g. patients with neurodegenerative disorders such as Alzheimer's disease and Parkinson's disease, or psychological variations, e.g. subjects with anxiety disorders, or are required to participate in tasks that involve movement, e.g. smoking cigarettes while scanning. In brain scans, the average head motion can vary from 7 mm in clinical scans to triple this amount for longer research scans. Quantitatively, a 5 mm head motion can produce biases of up to ~35% in regional intensities and ∼15% in volume of distribution estimates, which could much larger than the difference observed in regional intensities or binding potential that distinguish different demographic groups being studied. The ability to track and correct head motion, therefore, would be of high utility in both clinical and research PET studies. In the past, many motion correction methods have been proposed. However, except for hardware-based approaches, there has been no method that can track frequent head motion on-the-fly during the PET acquisition. Hardware-based approaches are not readily available for clinical translation or used by other research facilities due to highly-customized software/hardware setup. To address this challenge, we propose to develop a data-driven methodology using deep learning to track and estimate rigid head motion using PET raw data, and incorporate both tracer type and time as conditional variables into this deep neural network design in order to handle diverse PET tracer types and their dynamic behavior. Overall, these solutions will provide for a data-driven motion estimation methodology to improve the quality of PET imaging. Specifically, we will start with the development and testing of our methodology for rigid head motion estimation using single-tracer PET raw data. Then we will perform evaluation of our multi-tracer motion estimation methodology applied to real PET data with a diverse range of tracers. Finally, in the exploratory phase, we will integrate time-of-flight information into deep learning-based motion prediction. The significance of this proposal is that it will allow for improved quality of PET imaging in real time and potentially allow for its use in clinical PET systems that do not have special motion tracking hardware. This work will serve as a first step towards developing data-driven motion estimation algorithms for full body PET imaging. The innovation lies in the development of what is a data-driven solution to the problem of real time motion estimation. Project Narrative Positron-emission tomography (PET) imaging of the brain is a highly useful tool for biomedical research and clinical practice. Head motion during scanning degrades PET image quality and introduces image artifacts. We propose to develop new data-driven methods, based on PET raw data, to estimate head motion using deep learning, which can be used for real time motion estimation in PET imaging.",Data-driven Head Motion Correction in PET Imaging Using Deep Learning,9877261,R21EB028954,"['Address', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anxiety Disorders', 'Behavior', 'Binding', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain scan', 'Cigarette', 'Clinical', 'Clinical Research', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Development', 'Devices', 'Effect Modifiers (Epidemiology)', 'Evaluation', 'Event', 'Funding', 'Gold', 'Head', 'Head Movements', 'Hour', 'Human', 'Human body', 'Image', 'Individual', 'Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Movement', 'Neurodegenerative Disorders', 'Parkinson Disease', 'Pathologic Processes', 'Patients', 'Performance', 'Phase', 'Physiological Processes', 'Positron-Emission Tomography', 'Research', 'Research Personnel', 'Scanning', 'Smoking', 'Synapses', 'System', 'Testing', 'Time', 'Tracer', 'Training', 'Variant', 'Work', 'base', 'clinical practice', 'clinical translation', 'deep learning', 'deep neural network', 'density', 'design', 'effectiveness evaluation', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'interest', 'neural network', 'novel', 'psychologic', 'reconstruction', 'research facility', 'simulation', 'statistics', 'tool']",NIBIB,YALE UNIVERSITY,R21,2020,243150,0.01925934968600229
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,9972122,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,193784,0.02060171000956677
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,9888240,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2020,808131,-0.013827093203715618
"Machine learning for fast motion compensated quantitative abdominal DCE-MRI Project Summary: Functional imaging with dynamic contrast-enhanced MRI (DCE-MRI) provides important physiological markers of permeability, perfusion and glomerular filtration rate (GFR), a measure of kidney function, without exposing patients to ionizing radiation. DCE-MR images are at the same time used for evaluation of anatomy. Functional markers from DCE-MRI, if computed accurately, would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. One of the most important applications of DCE-MRI is assessing kidney function (GFR) in hydronephrosis patients with obstruction. In the absence of GFR information, children who stand to benefit from immediate surgical reconstruction might be overlooked or delayed in receiving treatment, and those who might benefit from a more conservative approach (i.e., “watchful waiting”) might receive an unnecessary surgical intervention. While the current reference standard, nuclear renography (MAG3), yields some useful diagnostic information, it is slow, provides low resolution, does not offer anatomic detail, and delivers potentially harmful ionizing radiation. There is a clinical need for accurate computation of quantitative functional markers. Unfortunately, current methods of DCE-MRI in neonates and children are less than optimal, and therefore, DCE-MRI is underutilized in clinical practice. The technical challenges include insufficient temporal resolution to capture fast arterial input function (AIF) dynamics (which are required for accurate computation of quantitative markers), unavoidable respiratory motion and bulk motion (which reduce image quality and significantly lower the accuracy of parameter estimates), and a lack of robust, fast, automated post processing techniques for accurate computation of markers. Thus, there is an urgent, unmet need to develop a motion-compensated, high spatiotemporal resolution DCE-MRI method addressing these challenges. The primary objective of this exploratory, three-year study, is three-fold: first, to develop and evaluate a new bulk and respiratory motion-compensated, high spatiotemporal resolution DCE-MRI technique for accurate estimation of functional markers; second, to further improve the robustness and speed of DCE-MRI using a fast, deep learning (DL) technique with integrated temporal prior for the reconstruction of motion-compensated, higher quality, high temporal resolution images; and third, to develop an automatic quantitative analysis pipeline including segmentation and tracer kinetic model-fitting using DL techniques for fast, robust and accurate quantification of functional markers. The successful completion of these aims will provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time parameter estimation from high temporal and spatial resolution DCE-MRI. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need for repeated scans and sedation in infants. ! ! Project Narrative: This project addresses the need to develop advanced methods of magnetic resonance imaging (MRI) to provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time estimation of clinically important quantitative imaging markers from high temporal and spatial resolution DCE-MRI. These markers will be used to evaluate the extent of several disorders and would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need of repeated scans, sedation and anesthesia when imaging newborns with congenital abnormalities such as congenital hydronephrosis, which if left untreated, can result in permanent damage to the child's kidneys.",Machine learning for fast motion compensated quantitative abdominal DCE-MRI,9957672,R21EB029627,"['Abdomen', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Anesthesia procedures', 'Breathing', 'Child', 'Childhood', 'Clinical', 'Congenital Abnormality', 'Crohn&apos', 's disease', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Financial compensation', 'Functional Imaging', 'Glomerular Filtration Rate', 'Hydronephrosis', 'Image', 'Imaging Techniques', 'Infant', 'Ionizing radiation', 'Kidney', 'Lead', 'Left', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Newborn Infant', 'Nuclear', 'Obstruction', 'Operative Surgical Procedures', 'Organ', 'Patient observation', 'Patients', 'Performance', 'Perfusion', 'Permeability', 'Physiological', 'Play', 'Reference Standards', 'Renal function', 'Resolution', 'Role', 'Scanning', 'Sedation procedure', 'Series', 'Signal Transduction', 'Speed', 'Techniques', 'Time', 'Tracer', 'Ureteropelvic junction obstruction', 'Work', 'analysis pipeline', 'anxious', 'base', 'bulk motion', 'clinical decision-making', 'clinical practice', 'contrast enhanced', 'deep learning', 'image reconstruction', 'imaging biomarker', 'imaging capabilities', 'imaging modality', 'improved', 'kinetic model', 'neonate', 'neural network architecture', 'pediatric patients', 'quantitative imaging', 'radiologist', 'real-time images', 'reconstruction', 'recursive neural network', 'respiratory', 'spatiotemporal', 'temporal measurement', 'time use', 'tumor']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R21,2020,708000,-0.034714169578653524
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9929633,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2020,1011405,0.012744833478338834
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",9936447,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury to Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'statistical learning', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2020,357486,0.006096882754608996
"Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer Abstract. In cancer, body-wide FDG-PET/CT is a prime modality for diagnosis, staging, and treatment assessment. Despite its paramount importance to enable precision medicine in cancer, no method is currently available for automated disease burden estimation and standardized reporting on PET/CT images regionally and globally in anatomic organs and lymph node zones within a body region or body-wide. Automated production- mode body-wide/ body-region-wide disease measurement with standardized reporting will foster cancer research discovery and will be of great interest to oncologists, radiologists/ nuclear medicine physicians, Medicare and private health insurers, and pharmaceutical companies that conduct clinical trials of new cancer therapeutics and currently rely on manual methods of response assessment. The overarching goal of this Phase I project is, therefore, to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide. The project has two aims: Aim 1: Develop, implement, and validate algorithms for disease burden estimation in thoracic cancer via FDG-PET/CT. Aim 2: Develop and demonstrate a prototype software implementing the above algorithms for disease measurement and reporting. Aim 1 will be accomplished in 3 stages: Tasks 1, 2: PET/CT image data sets which are radiologically near normal for the thoracic body region will be gathered from existing whole-body scans of 100 patients. In these data sets, 7 key anatomic organs and 5 key lymph node zones in the thorax will be delineated under expert guidance. These data will be used to build population fuzzy anatomy models following our established Automatic Anatomy Recognition (AAR) methodology. An additional 100 whole-body PET/CT scans of patients with different types of cancer will be gathered to test our methods. Using available commercial clinical software, the PET uptake properties of lesions in organs and diseased lymph nodes in lymph node zones will be measured manually and used as reference ground truth of disease burden. Task 3: Deep learning (DL) algorithms anatomically guided by AAR will be developed to very accurately localize (but not delineate) organs and lymph node zones in PET/CT images using the models. Task 4: Novel methods based on fuzzy principles will be developed to automatically tag and quantify pathological regions (without explicitly delineating them) within located organs and nodal zones, and the accuracy of disease measurement will be evaluated (Task 5). Aim 2 will be accomplished by incorporating the disease measurement methodology into a prototype software named AAR-DQ (Tasks 6, 7) based on our earlier software platform CAVASS. AAR-DQ will report disease burden in a hierarchical manner – (i) at the body-region level; (ii) at each organ/ lymph node zone level; (ii) at each lesion/ lymph node level. Expected milestones. Aim 1: AAR-DQ disease measurement not to deviate more than 10% from clinical ground truth measurement. Aim 2: Disease measurement/ reporting in under 5 minutes per patient PET/CT study. Automated production-mode body-wide/ body-region-wide disease measurement has numerous potential applications in cancer and other diseases and has considerable commercial potential. The overarching goal of this Phase I STTR project is to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide.",Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer,10076938,R41CA236492,"['Abbreviations', 'Abdomen', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Body Burden', 'Body Regions', 'Cancer Patient', 'Chest', 'Clinical', 'Communication', 'Computer software', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Distant', 'Fostering', 'Geography', 'Glycolysis', 'Goals', 'Head and neck structure', 'Health', 'Image', 'Image Analysis', 'Insurance Carriers', 'Knowledge', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Medicare', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Monitor', 'Names', 'Nodal', 'Normalcy', 'Oncologist', 'Organ', 'PET/CT scan', 'Pathologic', 'Patient-Focused Outcomes', 'Patients', 'Pelvis', 'Pharmacologic Substance', 'Phase', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Privatization', 'Production', 'Property', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research Personnel', 'Sampling Biases', 'Scanning', 'Small Business Technology Transfer Research', 'Staging', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Training', 'X-Ray Computed Tomography', 'algorithm training', 'anticancer research', 'base', 'burden of illness', 'cancer diagnosis', 'cancer type', 'deep learning', 'deep learning algorithm', 'evidence based guidelines', 'fluorodeoxyglucose positron emission tomography', 'imaging modality', 'improved', 'innovation', 'interest', 'learning strategy', 'lymph nodes', 'lymphoid organ', 'model building', 'novel', 'object recognition', 'outcome forecast', 'payment', 'precision medicine', 'prototype', 'radiologist', 'response', 'software development', 'treatment response', 'uptake', 'whole body imaging']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R41,2020,252131,0.0060471250638843245
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,0.017880308887311604
"Machine learning accelerated on-line adaptive replanning Abstract. The overall goal of this proposal is to develop and test a novel machine learning (ML) accelerated On-Line Adaptive Replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided radiation therapy (RT) (MRgRT). During the multi-fraction RT process, the location, shape and size of tumors and normal organs vary significantly between the fractions. These interfraction variations are among the major factors that can limit the accuracy of RT targeting. The current standard practice of image-guided RT (IGRT), developed to address the interfraction variations based on cone-beam CT (CBCT), can only correct for translational errors, and thus does not fully account for interfraction changes. To address this issue, researchers recently introduced online adaptive replanning (OLAR) that generates a new plan based on the anatomy of the day and delivers the plan for the fraction. Currently, two main obstacles affect the success of OLAR: (1) the anatomy of the day cannot be delineated accurately based on CBCT, and (2) the time required to perform OLAR is long enough to render it impractical. One way to improve the delineation accuracy is to use MRI versus CT. MRI-guided OLAR is currently being introduced into the clinics to substantially improve RT targeting. However, the bottleneck is still the impractical length of time required to segment the anatomy of the day, which can exceed 30 minutes. Furthermore, available synthetic CT (sCT) generation methods are slow or inaccurate for MRI-guided OLAR. There is no method available to quickly and objective determine when OLAR is necessary. To address these issues, we plan to develop novel techniques in the MOLAR solution. We hypothesize that the MRI-based MOLAR solution will fully account for interfraction changes, thereby substantially improving tumor targeting during RT delivery and the effectiveness of RT. Specifically, we aim to (1) develop practical ML-based solutions to quickly determine the necessity of OLAR and to rapidly generate accurate synthetic CTs; (2) develop ML-based techniques to substantially accelerate segmentation for OLAR using a progressive three-step process; and (3) verify clinical practicality and effectiveness of MOLAR by retrospectively and prospectively applying the MOLAR on MRI sets to test its speed and effectiveness in accounting for interfraction variations. We will develop this novel MOLAR solution by forging unique collaborations between clinical physicists, radiation oncologists and industry developers via an established academic-industry partnership. The successful completion of this project will enable clinicians to routinely practice “image-plan-treat”, which is the optimal solution for MRgRT. This new paradigm will fully account for interfraction variations, improve tumor targeting, reduce normal tissue toxicity, and ultimately encourage clinicians to revise the current doses and/or dose fractionations to increase therapeutic gain, enhance patient quality of life, and/or substantially save on healthcare costs. Our proposed strategy represents a drastic departure from current practice. We firmly believe that this strategy is the future of RT delivery. Project Narrative: This R01 application proposes to develop and test a novel machine learning accelerated online adaptive replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided adaptive radiation therapy through a unique academic and industry partnership. The MOLAR solution aims to fully account for interfraction variations, thereby substantially improving the accuracy and effectiveness of radiation therapy (RT) for cancer. This solution will enable clinicians to routinely practice “image-plan-treat”, a drastic departure from current practice and representing the future of RT delivery.",Machine learning accelerated on-line adaptive replanning,9941621,R01CA247960,"['3-Dimensional', 'Accounting', 'Address', 'Adoption', 'Affect', 'Air', 'Anatomy', 'Clinic', 'Clinical', 'Collaborations', 'Dose Fractionation', 'Effectiveness', 'Electron Transport', 'Future', 'Generations', 'Goals', 'Health Care Costs', 'Image', 'Industry', 'Learning', 'Length', 'Location', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of pancreas', 'Maps', 'Methodology', 'Methods', 'Modality', 'Normal tissue morphology', 'Organ', 'Patients', 'Physiology', 'Process', 'Quality of life', 'Radiation Oncologist', 'Radiation therapy', 'Research Personnel', 'Shapes', 'Site', 'Speed', 'Surface', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Toxic effect', 'Variant', 'automated segmentation', 'base', 'bone', 'cancer radiation therapy', 'cone-beam computed tomography', 'convolutional neural network', 'electron density', 'forging', 'image guided', 'image guided radiation therapy', 'imaging modality', 'improved', 'industry partner', 'innovation', 'large datasets', 'neural network algorithm', 'novel', 'pancreatic cancer patients', 'prospective', 'prospective test', 'quantitative imaging', 'routine practice', 'soft tissue', 'success', 'targeted treatment', 'tool', 'treatment response', 'tumor']",NCI,MEDICAL COLLEGE OF WISCONSIN,R01,2020,517299,-0.026066485660284914
"Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers Superficially spreading types of skin cancers such as lentigo maligna melanomas (LMMs) and non-melanoma skin cancers (NMSCs) occur mostly on older patients, with diffuse sub-clinical sub-surface spread over large areas and with poorly defined margins that are difficult to detect. To treat these cancers, dermatologists rou- tinely perform a large number of mapping biopsies to determine the spread and margins, followed by surgical excision with wide ""safety"" margins. Not surprisingly, such a ""blind"" approach results in under-sampling of the margins, over-sampling of normal skin, too many false positives and false negatives, and too much loss of normal skin tissue. What may help address this problem is reflectance confocal microscopy (RCM) imaging to noninvasively delineate margins, directly on patients. RCM imaging detects skin cancers in vivo with sensitivity of 85-95% and specificity 80-70%. In 2016, the Centers for Medicare and Medicaid Services granted reim- bursement codes for RCM imaging of skin. RCM imaging is now being increasingly used to noninvasively guide diagnosis, sparing patients from unnecessary biopsies of benign lesions. While the two-decade effort leading to the granting of these codes was focused on imaging-guided diagnosis, emerging applications are in imaging to guide therapy. We propose to create an approach called RCM video-mosaicking, to noninvasively map skin cancer margins over large areas on patients, with increased sampling, accuracy and sparing of nor- mal tissue. The innovation will be in designing a highly robust (against tissue warping and motion artifacts) and high speed (real-time, seconds) approach for RCM video-mosaicking: we will develop an optical flow ap- proach with a novel hybrid 3-stage deep learning network comprising of 8 parameters that will model global and local rigid and non-rigid tissue motion dynamics, learn and adapt to variable tissue and speckle noise con- ditions in patients, and predict and automatically detect motion blur artifacts. As required by PAR-18-009, our academic-industrial partnership will deliver RCM video-mosaicking to clinicians for real-time implementation at the bedside (translational novelty). Our proposed application is for guiding surgical excision, but the approach will have wider impact, for guiding new and emerging less invasive non-surgical treatments for superficial skin cancers. In a preliminary study, we demonstrated RCM video-mosaicking with real-time speed (125 millisec- onds per frame, 8 frames per second), and registration errors of 1.02 ± 1.3 pixels relative to field-of-view of 1000 x 1000 pixels. Our specific aims are (1) to develop a real-time and robust RCM video-mosaicking ap- proach and incorporate into a handheld confocal microscope for use at the bedside, (2) to test the approach for image quality and clinical acceptability, and (3) to prospectively test on 100 patients, with pre-surgical video- mosaicking of LMM margins and superficial NMSC margins, followed by validation against post-surgical pa- thology. We are a highly synergistic team from Memorial Sloan Kettering Cancer Center, Northeastern Uni- versity, and Caliber Imaging and Diagnostics (formerly, Lucid Inc.), with a 13-year record of collaboration. RELEVANCE TO PUBLIC HEALTH Reflectance confocal microscopy (RCM) imaging can noninvasively diagnose skin cancers, and spare patients from biopsies of benign skin conditions. We propose to develop an approach to noninvasively delineate skin cancer margins, to help guide less invasive surgery, and help more accurately and completely remove cancer while preserving more of the surrounding normal skin.",Confocal video-mosaicking microscopy to guide surgery of superficially spreading skin cancers,9951013,R01CA240771,"['Ablation', 'Address', 'Area', 'Benign', 'Biopsy', 'Caliber', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Confocal Microscopy', 'Dermatologist', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Excision', 'Funding Opportunities', 'Grant', 'Hutchinson&apos', 's Melanotic Freckle', 'Hybrids', 'Image', 'Lasers', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopy', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Mosaicism', 'Motion', 'Noise', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pharmacotherapy', 'Procedures', 'Process', 'Public Health', 'Radiation therapy', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Skin Tissue', 'Specificity', 'Speed', 'Standardization', 'Surface', 'Surgeon', 'Surgical Pathology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Validation', 'Video Microscopy', 'Visit', 'Visual', 'blind', 'cellular imaging', 'clinical practice', 'deep learning', 'design', 'expectation', 'human imaging', 'image guided', 'image guided therapy', 'imaging approach', 'in vivo', 'industry partner', 'innovation', 'interest', 'learning network', 'microscopic imaging', 'noninvasive diagnosis', 'novel', 'older patient', 'preservation', 'prospective test', 'reflectance confocal microscopy', 'response', 'vector']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2020,641884,-0.011602623048767089
"An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic ABSTRACT More than 20 million patients suffer from age-related macular degeneration, diabetic retinopathy, or glaucoma. These degenerative eye diseases develop over decades, and their prevalence is increasing. Retinal imaging technologies such as optical coherence tomography and adaptive optics ophthalmoscopy are essential tools in the investigation and management of eye disease. New quantitative biomarkers derived from these and other imaging modalities are critical to the clinical translation of emerging ophthalmic innovations. However, biomarker development in the era of artificial intelligence requires large volumes of annotated images and transparent, reproducible processes, which places new demands on the management of living subjects research, data sharing, and algorithm development. Unfortunately, current software platforms are not effective in integrating these data in a manner that meets specific requirements in ophthalmology, Our goal in this Direct-to-Phase II SBIR, consistent with objectives of the NIH Strategic Plan for Data Science, is to create an integrated platform (PaaS) for the collection, curation, analysis, and sharing of ocular images and data. We will extend the capabilities of systems developed by the Advanced Ocular Imaging Program (AOIP), Medical College of Wisconsin (MCW), which include: (a) LATTICE - a software solution that reduces costs, reduces errors, and improves communications in the management of living-subjects research; (b) MOSAIC - an image processing platform and algorithm library with traditional and AI-trained algorithms; and (c) The AOIP Image Bank - a Repository that houses images and data on 1578 fully-consent human research subjects. To create the integrative platform, we will address four aims: (a) Extend LATTICE to meet the workflow requirements of academic and sponsored research in local and multisite environments, including the extensible direct integration of data relevant to ocular studies; (b) Design and implement a hybrid (local + cloud) REPOSITORY architecture, data schema, knowledge ontology, and query architecture for Owners and Readers of data.; (c) Integrate and demonstrate LATTICE, REPOSITORY and MOSAIC into a continuous ocular science workflow and (d) integrate and demonstrate Lattice, Repository and Mosaic into a continuous ocular science workflow. Our Integrated Translational Imaging platform will enable ophthalmic innovators to translate sight-saving insights and interventions to the clinic faster, with less frustration, and greater confidence. Our proposal fills an important technology gap in the field of ophthalmic data science and biomarker development. While the number and type of imaging devices continues to grow, the tools to develop and deploy new biomarkers and clinical endpoints using these exquisite imaging devices has not kept pace. With this program we will enable a new generation of image-driven innovation to find its way to the clinic. Project Narrative With more than 20 million patients suffering from age-related macular degeneration, diabetic retinopathy, or glaucoma, it is crucial to develop non-invasive biomarkers as early predictors of eye disease and reliable tests of the safety and efficacy of new preventative and restorative therapies. To meet the unmet need for rapid access and analysis of ophthalmic research data for the discovery of these biomarkers, we will create an integrated platform (PaaS) for the collection, curation, sharing, and analysis of ocular images and data. If we meet our objectives, our platform will reduce the cost of clinical research and increase the speed of translating critical research insights to saving the sight of millions of patients.",An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic,9908389,R44EY031198,"['Address', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Collection', 'Communication', 'Computer software', 'Consent', 'Data', 'Data Discovery', 'Data Science', 'Diabetic Retinopathy', 'Docking', 'Economics', 'Environment', 'Eye diseases', 'Foundations', 'Frustration', 'Funding', 'Glaucoma', 'Goals', 'Housing', 'Human Subject Research', 'Hybrids', 'Image', 'Imaging Device', 'Imaging technology', 'Influentials', 'Intervention', 'Investigation', 'Knowledge', 'Libraries', 'Mosaicism', 'Ontology', 'Ophthalmology', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Phase', 'Policies', 'Prevalence', 'Process', 'Reader', 'Research', 'Research Subjects', 'Savings', 'Science', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Translating', 'Translations', 'United States National Institutes of Health', 'Validation', 'Vision', 'Wisconsin', 'adaptive optics', 'algorithm development', 'algorithm training', 'application programming interface', 'biomarker development', 'biomarker discovery', 'clinical translation', 'cost', 'data access', 'data exchange', 'data integration', 'data sharing', 'data warehouse', 'deep learning', 'design', 'efficacy testing', 'experience', 'fighting', 'image processing', 'image reconstruction', 'imaging modality', 'imaging platform', 'imaging program', 'improved', 'innovation', 'insight', 'medical schools', 'microsystems', 'ocular imaging', 'process repeatability', 'programs', 'repository', 'retinal imaging', 'safety testing', 'software systems', 'structured data', 'tool', 'verification and validation', 'vision science']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R44,2020,743347,0.01899540993987437
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Abstract Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,10052989,R01EB022075,"['90Y', 'Address', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Disease', 'Dose', 'Ensure', 'Evaluable Disease', 'External Beam Radiation Therapy', 'Failure', 'Foundations', 'Funding', 'Future', 'Goals', 'Hepatotoxicity', 'Image', 'Joint repair', 'Joints', 'Lesion', 'Liver', 'Liver parenchyma', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motivation', 'Noise', 'PET/CT scan', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Photons', 'Physics', 'Pilot Projects', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Reporting', 'Safety', 'Scanning', 'Testing', 'Time', 'Toxic effect', 'Training', 'base', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'multimodal data', 'multimodality', 'next generation', 'novel', 'novel strategies', 'personalized cancer therapy', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,670584,-0.026428020699937212
"Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks PROJECT SUMMARY The long-term goal of this project is to improve the care of patients with laryngeal disorders through development of automated diagnostic support for in-office flexible laryngoscopy. To accomplish this goal, we propose developing neural network-based algorithms to detect and classify structural laryngeal lesions in laryngoscopy images. An automated diagnostic tool for in-office laryngoscopy such as we propose will have several benefits: (1) It will improve access to care for patients with symptoms of laryngeal dysfunction living in communities with limited otolaryngology resources, (2) It will improve early detection of laryngeal cancers potentially reducing the morbidity of treatment, and (3) It will prove a valuable teaching tool for students and residents first learning to interpret laryngoscopic exams. Flexible laryngoscopy is a common in-office procedure performed by otolaryngologists to evaluate the upper aerodigestive tract in patients with symptoms of laryngeal dysfunction. Subtle differences in the appearance of laryngeal lesions enable otolaryngologists to differentiate benign lesions from suspected malignant ones. The expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training and therefore laryngoscopy is largely only performed in subspecialty otolaryngology clinics. The primary objective of this project is to develop neural network-based algorithms to detect and classify structural laryngeal lesions. Our hypothesis is that these algorithms can be trained using a large dataset of laryngeal images to accurately detect and classify structural laryngeal lesions on flexible laryngoscopic exam. To test this hypothesis, we propose the following aims: (1) Generate a dataset of high-quality, labeled endoscopic laryngeal images corresponding to normal and structural lesions of the larynx, (2) Develop a location-aware anchor-based reasoning neural network for accurate detection of laryngeal lesions, and (3) Develop an adaptive network model for classification of structural laryngeal pathologies including papilloma, polyp, leukoplakia and suspected malignancy. With expertise in the diagnosis and treatment of laryngeal disorders and computer vision, including object detection and classification, our multidisciplinary team is uniquely qualified to complete this project. PROJECT NARRATIVE We propose to revolutionize in-office laryngoscopy through development of a deep neural network-based automated detection and classification system for diagnosis of structural diseases of the larynx. Currently, flexible laryngoscopy is only performed by expert subspecialists with years of experience because developing the expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training. Through development of deep neural network-based algorithms to detect and classify laryngeal lesions on in- office laryngoscopy, we will improve access to care for patients living in communities without subspecialty otolaryngology care and will develop an important teaching tool for clinicians learning to interpret laryngoscopic exams.",Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks,10043172,R03CA253212,"['Aerodigestive Tract', 'Algorithms', 'Anesthesia procedures', 'Appearance', 'Architecture', 'Awareness', 'Benign', 'Caring', 'Categories', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Colonic Polyps', 'Colonoscopy', 'Communities', 'Computer Vision Systems', 'Custom', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Distal', 'Drops', 'Early Diagnosis', 'Educational process of instructing', 'Ensure', 'Fellowship', 'Functional disorder', 'Gastroesophageal reflux disease', 'Goals', 'Health Services Accessibility', 'Hoarseness', 'Image', 'Improve Access', 'Infection', 'Label', 'Laryngeal Diseases', 'Laryngoscopes', 'Laryngoscopy', 'Larynx', 'Learning', 'Lesion', 'Leukoplakia', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of larynx', 'Manuals', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Network-based', 'Normal Range', 'Otolaryngologist', 'Otolaryngology', 'Papilloma', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Pilot Projects', 'Plug-in', 'Polyps', 'Positioning Attribute', 'Procedures', 'Recurrence', 'Resources', 'Sampling', 'Semantics', 'Structure', 'Students', 'Symptoms', 'System', 'Technical Expertise', 'Testing', 'Training', 'Vision research', 'Work', 'base', 'classification algorithm', 'cost', 'deep neural network', 'detector', 'digital', 'experience', 'feature extraction', 'flexibility', 'improved', 'large datasets', 'learning algorithm', 'multidisciplinary', 'network models', 'neural network', 'tool']",NCI,UNIVERSITY OF KANSAS MEDICAL CENTER,R03,2020,154375,0.018544463225859086
"IEEE Medical Imaging Conference Abstract  The IEEE Medical Imaging Conference (MIC) is the leading international scientific meeting bringing together a broad community interested in the physics, engineering and mathematical aspects of medical imaging, with special emphasis on nuclear medicine and multi-modal systems. The MIC runs in conjunction with the IEEE Nuclear Science Symposium (NSS) and the Workshop on Room Temperature Semiconductor X-ray and Gamma-ray Detectors (RTSD).  The purpose of the MIC is to disseminate and foster new research in physics and bio-engineering methods in medical imaging. While the traditional topics of primary interest are related to nuclear medicine techniques such as positron emission tomography (PET) and single photon emission computerized tomography (SPECT), increasing space will be also given to recently evolving imaging modalities such as X-ray, CT, optical, MR, with special emphasis on their multi-modal combination with nuclear medical imaging. Recently there has also been additional interest in employing deep learning and AI to enhance the field medical imaging. The conference provides a well-established forum of scientific exchange and dialogue between researchers in academia, industry, and government as well as education of the public, with special emphasis on young generations. This is reflected by the large spectrum of educational refresher sessions and short courses. One of the major objectives of the conference is the education of young investigators, and therefore this NIH R13 proposal seeks $10,000 in funding for each of the next three years to provide 20 trainee grants of $500 each to partially cover costs of MIC conference registration, housing and/or short course fees for graduate students and postdoctoral fellows based at US institutions.  We anticipate that the main impact of this grant program will be to increase attendance of students and postdocs at the 2020 meeting, especially those typically underrepresented, as well as to support their participation in educational activities. It is important to bring young generations, especially women, minorities, and those with disabilities, into the medical imaging field, where they could become main actors in the coming years. They will attend plenary and oral presentations given by many of the world leaders in the nuclear medical imaging instrumentation, image processing, and quantitative analysis fields. Moreover, they will be given the unique opportunity of direct personal interaction through the short courses and dedicated poster presentations. In turn their work will be exposed to the other participants for critical evaluation, constructive suggestions and dissemination. Furthermore, many of these trainees will likely continue in this field, thereby contributing to advancing technology with high societal relevance as being increasingly used in the clinical management of disease and therapeutic interventions. Narrative  The IEEE Medical Imaging Conference (MIC) has the purpose to disseminate and foster new research in physics and bio-engineering methods in medical imaging. The conference covers a variety of medical imaging topics including quantitative imaging, PET/SPECT techniques, image reconstruction, imaging in radiation therapy, portable imaging, multi-modality systems, new medical imaging technologies, CT/MR/optical/ultrasound, parametric/kinetic image modeling, and signal/image processing and modeling. One of the major objectives of the conference is the education and encouragement of young investigators, and therefore this NIH R13 proposal seeks funding to provide twenty grants for each of the next three years to graduate students and postdoctoral fellows based at US institutions to partially cover costs of MIC conference registration and short course fees.",IEEE Medical Imaging Conference,10071524,R13EB030423,"['Academia', 'Animals', 'Area', 'Artificial Intelligence', 'Attention', 'Award', 'Biological', 'Biomedical Engineering', 'Brain', 'Clinical Management', 'Collaborations', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'Detection', 'Development', 'Diagnosis', 'Disabled Persons', 'Discipline of Nuclear Medicine', 'Disease Management', 'Education', 'Educational Activities', 'Educational workshop', 'Emission-Computed Tomography', 'Engineering', 'Evaluation', 'Exposure to', 'Fees', 'Fostering', 'Funding', 'Gamma Rays', 'Generations', 'Government', 'Grant', 'Housing', 'Image', 'Image Analysis', 'Imaging technology', 'Industrialization', 'Industry', 'Institution', 'International', 'Italy', 'Japan', 'Joints', 'Kinetics', 'Lead', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Care Costs', 'Medical Imaging', 'Medical Technology', 'Methods', 'Minority', 'Modeling', 'Modernization', 'Monitor', 'Multimodal Imaging', 'Nuclear', 'Optics', 'Oral', 'Participant', 'Photons', 'Physics', 'Positron-Emission Tomography', 'Postdoctoral Fellow', 'Radiation therapy', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Roentgen Rays', 'Running', 'Scientist', 'Semiconductors', 'Signal Transduction', 'Students', 'Suggestion', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic Intervention', 'Time', 'Tracer', 'Translations', 'Ultrasonography', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'Work', 'base', 'clinical imaging', 'clinical practice', 'cost', 'deep learning', 'design', 'detector', 'disability', 'graduate student', 'image processing', 'image reconstruction', 'imaging modality', 'innovation', 'instrumentation', 'interest', 'kinetic model', 'meetings', 'member', 'models and simulation', 'multidisciplinary', 'multimodality', 'nanoparticle', 'novel', 'nuclear science', 'parametric imaging', 'portability', 'posters', 'programs', 'public education', 'quantitative imaging', 'radiation detector', 'reconstruction', 'signal processing', 'statistics', 'symposium', 'theranostics']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R13,2020,10000,0.022677965787614662
"SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring Image-based evaluation of lymph nodes is an essential step in cancer diagnosis, treatment and monitoring. Current clinical practice mostly uses qualitative or semi-quantitative measures in evaluation and thus suffers from inaccuracy due to intra- and inter-observer variability and increased human efforts. This becomes a more serious issue in head and neck cancers due to the large number of clinically relevant lymph nodes. In this project an AI-based automatic segmentation software will be developed for quantitative cervical lymph node evaluation to increase the accuracy and reduce the cost. However, there are a few challenges in developing and deploying such a software due to different clinical practices such as usage of different modalities (MRI and/or CT) and complex clinical workflow. To address these challenges, a novel AI algorithm that can handle the variability in imaging modalities and support incremental learning using site-specific data to enhance its robustness will be developed; a private-cloud-based software framework with high usability will then be developed to incorporate this algorithm and provide advanced visualization and reporting for clinical usage. This software will have high impact on all stages of patient care for head and neck cancers and can be further extended to other cancers. n/a","SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269836,5N91020C00048,"['Address', 'Algorithms', 'Artificial Intelligence', 'Cervical lymph node group', 'Clinical', 'Complex', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Evaluation', 'Head and Neck Cancer', 'Human', 'Image', 'Interobserver Variability', 'Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Modality', 'Monitor', 'Patient Care', 'Performance', 'Phase', 'Privatization', 'Reporting', 'Site', 'Small Business Innovation Research Grant', 'Software Framework', 'Visualization', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer prevention', 'clinical practice', 'clinically relevant', 'cloud based', 'cost', 'imaging modality', 'lymph nodes', 'novel', 'segmentation algorithm', 'usability']",NCI,"CARINA MEDICAL, LLC",N43,2020,400000,-0.0013228246014778636
"Multi-modal and Extreme PET/MRI Reconstruction Methods Project Summary / Abstract  Hybrid PET/MRI systems are very advantageous for a variety of clinical applications by combining the soft tissue contrast of MRI with the functional and metabolic information of PET. These systems have found success for oncology studies, particularly in head and abdomen/pelvis, as well as for epilepsy, neurological diseases, heart disease, and pediatrics for dose reduction. However, the PET resolution and SNR is typically worse than MRI, and suffers from the loss of feature and data due to motion as well. PET/MRI systems offer the potential to create more accurate, higher resolution PET reconstructions, including correction of artifacts, motion, and im- proved localization, by performing synergistic reconstructions that leverage the simultaneous data acquisition. In particular, this fellowship proposes to develop novel physics-constrained machine learning models for informa- tion sharing between PET and MRI for enhanced spatial localization, estimation of attenuation and activity, and motion. We propose to develop a deep maximum-likelihood estimation of attenuation and activity (MLAA) that can compensate for artifacts and improve PET reconstruction accuracy. We also propose a motion-enhanced joint PET/MRI reconstruction to capture arbitrary motions and reduce dose requirements for chest and abdomen studies. Together, these models aim to improve the PET spatio-temporal resolution, SNR, and quantiﬁcation for a broad range of clinical applications, and will be evaluated for cancer assessment in the pelvis, liver, and lung.  This fellowship will be performed in the Department of Radiology and Biomedical Imaging at UCSF under the guidance of Prof. Peder Larson, who leads a research program on advanced imaging methods development, and Dr. Thomas Hope, a radiologist and nuclear medicine physician who leads multiple PET/MRI projects. The Department is one of the leading centers in biomedical imaging research, and has been at the forefront on translating PET/MRI systems into clinical practice. The UCSF PET/MRI scanner has dedicated research time, which is also available on other MRI and PET/CT research systems, and extensive computational resources to support the proposed project. The applicant, Dr. Abhejit Rajagopal, has a background in computational imaging and machine learning, will be jointly mentored by this engineer/physician team. He will be trained to become a biomedical imaging scientist by participating in formal coursework on medical imaging systems, training on the PET/MRI system, grant writing, and performing clinical research, supporting his development into a creative, independent biomedical researcher. Project Narrative  Hybrid positron emission tomography (PET) and magnetic resonance imagery (MRI) imaging systems cur- rently aid in diagnosis and prognosis of numerous types of cancer and disease, but are not always precise enough to accurately measure and track a patient’s response to therapy, particularly in organs and tissue that are sub- ject to motion. There is an unrealized potential here to synergistically combine complimentary PET-MRI data to dramatically improve the spatial resolution and SNR of PET, as well as to create motion-resolved 4D (x,y,z,t) imagery by combining information across modalities and time-frames to combat severe undersampling. These methods will be evaluated in human studies of cancer to capture ﬁne structure and micro-features on moving organs (e.g. lung nodules, liver metastases), ultimately aiding in quantitative characterization of disease.",Multi-modal and Extreme PET/MRI Reconstruction Methods,10069132,F32EB030411,"['3-Dimensional', 'Abdomen', 'Address', 'Affect', 'Algorithms', 'Attention', 'Chest', 'Childhood', 'Clinical', 'Clinical Research', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Dose', 'Engineering', 'Epilepsy', 'FOLH1 gene', 'Fellowship', 'Financial compensation', 'Goals', 'Grant', 'Head', 'Head and Neck Cancer', 'Heart Diseases', 'Human', 'Hybrids', 'Image', 'Imagery', 'Implant', 'Joint repair', 'Joints', 'Learning', 'Liver', 'Lung', 'Lung nodule', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Female Reproductive System Neoplasm', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Medical Imaging', 'Mentors', 'Metabolic', 'Metals', 'Metastatic Neoplasm to the Liver', 'Methods', 'Modality', 'Modeling', 'Morphologic artifacts', 'Motion', 'Neurodegenerative Disorders', 'Oncology', 'Organ', 'Output', 'Patients', 'Pediatrics', 'Pelvis', 'Performance', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Scanning', 'Signal Transduction', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Tracer', 'Training', 'Translating', 'Writing', 'attenuation', 'bioimaging', 'bone', 'cancer type', 'clinical application', 'clinical practice', 'combat', 'computing resources', 'data acquisition', 'deep learning', 'heart imaging', 'high resolution imaging', 'imaging modality', 'imaging scientist', 'imaging system', 'improved', 'information model', 'lung imaging', 'method development', 'multimodality', 'nervous system disorder', 'neuro-oncology', 'novel', 'outcome forecast', 'patient response', 'programs', 'radiological imaging', 'radiologist', 'reconstruction', 'respiratory', 'soft tissue', 'spatiotemporal', 'success', 'systems research', 'uptake']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2020,69426,0.017980393590352656
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,10017876,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Computed Tomography Scanners', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2020,1279629,0.026216067615325574
"Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection PROJECT SUMMARY Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project is part of a larger scientific effort to accelerate MRI while maintaining the diagnostic quality. Acceleration, even by a factor of two would result in a major advance for public health. Two of the current approaches to accelerate MRI rely on collecting less data (under-sampling) and constrained or deep learning reconstruction. These approaches can lead to images with diagnostic quality with significant under-sampling but may suffer from artifacts which are hard to characterize. Specifically, this project will optimize the performance of constrained reconstruction and deep learning on detecting subtle lesions in acquiring and reconstructing under-sampled MRI. To carry out this optimization, we will first develop the methods required for detection of lesions by machine and human observer models. Then the models will be validated by psychophysical studies where humans perform the detection task. In the first aim of this project, we will optimize constrained reconstruction based on the ideal linear observer. We will consider under-sampled acquisition strategies in 2D MRI including one and two dimensional subsampling methods with constrained reconstruction using both wavelet and total variation constraints. We will perform simulations using anatomical backgrounds both for lesions which match the prior information of the constraints and those which do not to better understand how choices in acquisition and reconstruction affect ideal detection. While the ideal linear observer approximates the best possible detection, typically the signal detection is carried out by a human. In the second aim, we will optimize constrained reconstruction using human observer models and validate the models using human observer studies. A recent approach to reconstruction of under- sampled images is based on deep learning. In the third aim, this work will optimize deep learning reconstruction based on ideal and human observers. Due to the complexity of the deep learning approach, having this task-based approach to optimization is particularly relevant. This project will optimize a network using signal detection to better understand how training and architecture choices in the neural network affect detection of lesions which are not included in training images. This research project will help to strengthen the research environment at Manhattan College by involving students in biomedical research incorporating applied mathematics, statistics and data science. PROJECT NARRATIVE Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients and improve public health both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project would advance a larger scientific effort to accelerate MRI while maintaining the diagnostic quality by optimizing the performance of constrained reconstruction and deep learning on detecting subtle lesions in accelerated MRI.",Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection,9880534,R15EB029172,"['Acceleration', 'Affect', 'Anatomy', 'Architecture', 'Biomedical Research', 'Collaborations', 'Data', 'Data Science', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Evaluation', 'Gaussian model', 'Grant', 'Health Care Costs', 'Human', 'Image', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Mathematics', 'Methods', 'Modeling', 'Morphologic artifacts', 'Patients', 'Performance', 'Positron-Emission Tomography', 'Psychophysics', 'Public Health', 'Research', 'Research Project Grants', 'Resolution', 'Sampling', 'Signal Transduction', 'Students', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'college', 'deep learning', 'density', 'flexibility', 'imaging modality', 'improved', 'insight', 'neural network', 'neural network architecture', 'predictive modeling', 'reconstruction', 'simulation', 'single photon emission computed tomography', 'statistics', 'two-dimensional']",NIBIB,MANHATTAN COLLEGE,R15,2020,395210,0.020880496294094025
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9996604,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'data streams', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2020,1198860,0.023935330639796595
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10246250,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2020,750000,0.013172382952431096
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.04797123976040416
"Super-multiplexed fluorescence nanoscopy for imaging-based proteomics PROJECT SUMMARY In situ immunofluorescence imaging is a powerful method to study the locations, expression levels and structures of proteins in cells and tissues. In particular, multiplexed imaging reveals the interaction networks of proteins, which allows us to understand the underlying mechanisms of many diseases. However, it has been challenging to perform multiplexed immunofluorescence imaging due to its extremely time-consuming process, high cost and lack of signal amplification. The limited spatial resolution achievable with confocal microscopy often fails to reveal complex spatial organization and to determine localizations of proteins. Here we propose super-multiplexed immunofluorescence nanoscopy that is capable of imaging more than twenty different proteins in 24 hours with nanoscale resolution. We will employ DNA-barcoded secondary nanobodies that are monovalent, open-source and designed for quantitative labeling. Repeated introduction and washing of fluorescent DNA imagers will generate highly multiplexed images. Moreover, we will develop unprecedentedly fast stimulated emission depletion (STED) microscopy that employs a parallelized line array of doughnut beams. It will feature a large imaging area and excellent optical sectioning capability. Photon reassignment, hyperspectral imaging and deep-learning will further facilitate rapid super-resolution-based protein profiling. Our new biochemical and optical tools will play crucial roles in diverse biomedical areas including brain proteomics and cancer profiling. PROJECT NARRATIVE We propose to develop highly multiplexed immunofluorescence super-resolution imaging tools. Our approach is fast, low cost and readily accessible, which will facilitate nanoscale imaging-based proteomics in cells and tissues.",Super-multiplexed fluorescence nanoscopy for imaging-based proteomics,10028050,R35GM138039,"['Area', 'Bar Codes', 'Biochemical', 'Brain', 'Cells', 'Complex', 'Confocal Microscopy', 'Consumption', 'DNA', 'Disease', 'Fluorescence', 'Hour', 'Image', 'Imaging Device', 'Immunofluorescence Immunologic', 'In Situ', 'Label', 'Location', 'Malignant Neoplasms', 'Methods', 'Microscopy', 'Nanoscopy', 'Optics', 'Photons', 'Play', 'Process', 'Proteins', 'Proteomics', 'Resolution', 'Role', 'Signal Transduction', 'Structural Protein', 'Time', 'Tissues', 'base', 'cost', 'deep learning', 'design', 'imager', 'multiplexed imaging', 'nanobodies', 'nanoscale', 'open source', 'protein profiling', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R35,2020,267626,-0.0022672230254402823
"Next-Generation Ultrasound Localization Microscopy Project Summary/Abstract Abnormal alterations of tissue microcirculation are often associated with early stage of tissue pathology. Detection and characterization of these early microvascular abnormalities can greatly benefit clinical diagnosis and treatment monitoring as well as facilitating the creation of new therapies to counter disease development. For decades, there has been a longstanding quest for the development of a clinical imaging modality that can noninvasively and directly image such tissue microvascular variations. To date, however, such an imaging method remains elusive due to the fundamental compromise between imaging spatial resolution and depth penetration. Therefore, the long-term objective of this project is to fulfill this unmet clinical need by developing the next-generation ultrasound localization microscopy (ULM), which is an ultrasound-based imaging technique that can directly assess structural and functional tissue microvasculature in vivo in humans at a clinically relevant depth. Different from other imaging modalities, ULM is not limited by the resolution-penetration compromise: ULM can noninvasively image capillary-scale microvessels at several centimeters depth and quantitatively measure their blood flow speed (as low as 1 mm/s). Such combination of deep imaging penetration and exquisite spatial resolution and the unique functionality of measuring small vessel blood flow speed make ULM a promising technique for many clinical applications including cancer and cardiovascular diseases. At present, however, ULM is not ready for clinical use due to several key technical limitations: 1) ULM data acquisition is very slow (tens of seconds with breath holding); 2) ULM post-processing is very expensive computationally (several hours to generate a single 2D ULM image); 3) ULM is difficult to be extended to 3D imaging (which is important for comprehensive evaluation of tissue microvasculature such as in cancer applications). These limitations largely forbids ULM from being effectively used in the clinic to provide useful microvascular biomarkers. In this proposal, we will concentrate on addressing these technical barriers and transform ULM to a truly useful clinical imaging tool. Our approach synergistically combines deep learning (DL), parallel computing, and ultrafast 3D ultrasound imaging to fundamentally shorten ULM data acquisition time, substantially accelerate ULM post-processing, and enhance ULM to 3D imaging. Our first aim will develop and validate DL-based ULM data processing algorithms that would enable real-time 4D morphometric ULM and fast 3D quantitative ULM. Our method uniquely collects real labeled optical imaging data on a chicken embryo microvessel model for DL training. Our second aim will focus on realizing 3D-ULM on a 2D row-column-addressing transducer with ultrafast 3D plane wave imaging. We will develop a DL-based beamforming technique to enable high-fidelity 3D microbubble imaging for robust 3D-ULM. Our final aim will focus on validating the in vivo performance of the newly developed 3D-ULM imaging techniques on a mouse tumor model. We will be collaborating with world-renowned experts in deep learning, optical imaging, and comparative medicine at the University of Illinois to accomplish these aims of the proposal. Project Narrative Imaging-based detection and characterization of abnormal tissue microvascular variations is clinically significant for diagnosis, treatment evaluation, and therapy development in many pathologies such as cancer, cardiovascular diseases, inflammation, and neurodegenerative diseases. At present, there is no viable noninvasive imaging tool that can fulfill this important clinical need. To fill this gap, we propose to develop a new ultrasound-based super-resolution microvessel imaging technique that can directly and quantitatively assess the structure and the function of tissue microcirculation in vivo in humans.",Next-Generation Ultrasound Localization Microscopy,10039725,R21EB030072,"['3-Dimensional', '3D ultrasound', '4T1', 'Address', 'Adopted', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Biological Markers', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Breast Carcinoma', 'Cardiovascular Diseases', 'Chickens', 'Clinic', 'Clinical', 'Clinical Treatment', 'Complex', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Evaluation', 'Goals', 'Health', 'Hour', 'Human', 'Illinois', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Incentives', 'Inflammation', 'Knowledge', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medicine', 'Metabolic', 'Methods', 'Microbubbles', 'Microcirculation', 'Microscopy', 'Modality', 'Modeling', 'Modification', 'Monitor', 'Morphologic artifacts', 'Mus', 'Neurodegenerative Disorders', 'Noise', 'Nutrient', 'Organ', 'Oxygen', 'Pathogenesis', 'Pathology', 'Patients', 'Penetration', 'Performance', 'Property', 'Provider', 'Resolution', 'Series', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Transducers', 'Transportation', 'Ultrasonic Transducer', 'Ultrasonography', 'Universities', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically relevant', 'clinically significant', 'comparative', 'computerized data processing', 'cost', 'data acquisition', 'deep learning', 'deep neural network', 'hemodynamics', 'imaging detection', 'imaging modality', 'in vivo', 'in vivo imaging', 'innovation', 'instrumentation', 'microCT', 'microscopic imaging', 'next generation', 'non-invasive imaging', 'novel', 'novel therapeutics', 'optical imaging', 'parallel computer', 'performance tests', 'quantitative ultrasound', 'real-time images', 'therapy development', 'tool', 'tumor', 'two photon microscopy']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565346,-0.003576637795230419
"Fast motion-robust fetal neuroimaging with MRI PROJECT SUMMARY/ABSTRACT Fetal-brain magnetic resonance imaging (MRI) has become an invaluable tool for studying the early development of the brain and can resolve diagnostic ambiguities that may remain after routine ultrasound exams. Unfortunately, high levels of fetal and maternal motion (1) limit fetal MRI to rapid two-dimensional (2D) sequences and frequently introduce dramatic artifacts such as (2) image misorientation relative to the standard sagittal, coronal, axial planes needed for clinical assessment and (3) partial to complete signal loss. These factors lead to the inefficient practice of repeating ~30 s stack-of-slices acquisitions until motion-free images have been obtained. Throughout the session, technologists manually adjust the orientation of scans in response to motion, and about 38% of datasets are typically discarded. Thus, subject motion is the fundamental impediment to reaping the full benefits of MRI for answering clinical and investigational questions in the fetus. The overarching goal of this project is to overcome the challenges posed by motion by exploiting innovations in deep learning, which have enabled image-analysis algorithms with unprecedented speed and reliability. We propose to integrate these into the MRI acquisition pipeline to unlock the potential of fetal MRI. We will develop practical pulse-sequence technology for automated and dynamically motion-corrected fetal neuroimaging without the need for external hardware or calibration. We hypothesize that this will radically improve the quality and success rates of clinical and research studies, while dramatically reducing patient discomfort and cost. We propose as Aim 1 to eradicate (2) the vulnerability of acquisitions to image-brain misorientation with rapid, automated prescription of standard anatomical planes. In Aim 2, we propose to address (3) motion during the scan with real-time correction of fetal-head motion. An anatomical stack-of-slices acquisition will be interleaved with volumetric navigators. These will be used to measure motion as it happens in the scanner and to adaptively update the slice tilt/position. We propose as Aim 3 to develop a 3D radial sequence and estimate motion between subsets of radial spokes for real-time self-navigation. Adaptively updating the orientation of spokes and selectively re-acquiring corrupted subsets at the end of the scan will enable 3D imaging of the fetal brain (1). Since the applicant has a physics background, the proposed training program at MIT and HMS will focus on deep learning and fetal development/neuroscience during the K99 phase to develop the skills needed for transitioning to independence in the R00 phase. The applicant’s goal is to become a fetal image acquisition and analysis scientist acting as bridge between deep learning, MRI and clinical fetal-imaging applications to shift the boundaries of what is currently possible with state-of-the-art technology. Fulfilling the research aims will promote this, as it will result in a practical framework for automation and motion correction, applicable to a wide variety of fetal neuroimaging sequences. PROJECT NARRATIVE Subject motion is the fundamental impediment to reaping the full benefits of fetal-brain magnetic resonance imaging, as it frequently produces images with dramatic artifacts. The goal of this project is to exploit innovations in deep learning and integrate them into the acquisition pipeline to overcome the challenges posed by motion in fetal neuroimaging studies. This will be achieved by using fast, automated scan prescription of standard anatomical planes and by adaptively updating the acquisition as motion happens in the scanner, based on sub-second navigator scans interleaved with the imaging sequence.",Fast motion-robust fetal neuroimaging with MRI,9950474,K99HD101553,"['3-Dimensional', 'Address', 'Algorithmic Analysis', 'Amniotic Fluid', 'Anatomy', 'Automation', 'Brain', 'Brain imaging', 'Calibration', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Data Set', 'Development', 'Diagnostic', 'Echo-Planar Imaging', 'Fetal Development', 'Fetus', 'Geometry', 'Goals', 'Head', 'Image', 'Individual', 'Label', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measures', 'Morphologic artifacts', 'Motion', 'Neurosciences', 'Patients', 'Phase', 'Physics', 'Physiologic pulse', 'Population', 'Positioning Attribute', 'Radial', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Sampling', 'Scanning', 'Scientist', 'Signal Transduction', 'Slice', 'Speed', 'Technology', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Training Programs', 'Translating', 'Ultrasonography', 'Update', 'Work', 'base', 'clinical investigation', 'convolutional neural network', 'cost', 'deep learning', 'echo detection', 'experience', 'fetal', 'image archival system', 'improved', 'innovation', 'interest', 'neuroimaging', 'novel', 'prospective', 'radiologist', 'reconstruction', 'repaired', 'research study', 'response', 'skills', 'success', 'tool', 'two-dimensional']",NICHD,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,108601,0.0030947544173273835
"Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction Nuclear medicine imaging in children has been shown to have significant clinical value across all organ systems. In providing this significant benefit it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that of adults, owing to their higher tissue sensitivity and longer potential lifespan. The governing principle of this project will be to minimize radiation dose while methodically ensuring that lesion detection performance is fully preserved. This will be accomplished by using validations based on both numerical and physician observers measuring performance in tasks that emulate those performed clinically. We will employ two approaches in tandem to enable lowering dose while maintaining performance. First, we will use advanced image reconstruction and processing techniques. Corrections for various forms of image quality degradation will be incorporated in the reconstruction, and deep learning (DL) will be used for post-reconstruction denoising. Second, we will develop methods to correct for both body and respiratory motion, which degrade diagnostic accuracy. Correcting for body and respiratory motion will allow dose to be reduced without loss of image quality and will also offer a technological alternative to using sedation or even general anesthesia to minimize motion when imaging children. For this investigation we have selected 99mTc-labeled dimercaptosuccinic acid (DMSA) renal imaging as a testbed to demonstrate our approaches. Damage to the renal cortex resulting from infection of the kidneys is a critical issue in children, including newborns and toddlers. DMSA SPECT is the “gold-standard” in the evaluation of pyelonephritis and renal scarring post- infection. The concepts we will demonstrate for reduction of radiation dose and correction of motion with DMSA will be translatable to other SPECT (and PET) studies in pediatric imaging and beyond.  Our Specific Aims are: 1. Establish infrastructure for investigating and evaluating advanced reconstruction and motion correction; 2. Determine the extent of radiation dose reduction to pediatric patients through improved reconstruction and DL denoising while maintaining optimal full-dose lesion detection accuracy; 3. Develop data-driven and depth-sensing camera methods for body and respiratory motion estimation and correction; and 4. Conduct numerical and physician observer studies to validate the level of dose reduction enabled by DL denoising and motion correction. Narrative  In nuclear medicine imaging, it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that in adults, owing to their higher tissue sensitivity and longer potential lifespan. Correcting for body and respiratory motion occurring during imaging will improve the quality of the formed three-dimensional images of the patient by reducing blurring and image artifacts and offer a technological alternative to using sedation or even general anesthesia to reduce motion when imaging children, which can bear health risks of its own. We propose an advanced reconstruction methodology which would enable reduction in the amount of activity administered and compensate for patient motion during imaging.",Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction,9914572,R01EB029315,"['3-Dimensional', 'Adult', 'Algorithms', 'American', 'Area', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'DMSA', 'Data', 'Databases', 'Detection', 'Development', 'Discipline of Nuclear Medicine', 'Dose', 'Enhancing Lesion', 'Ensure', 'European', 'Evaluation', 'Freedom', 'Gaussian model', 'General Anesthesia', 'Gold', 'Guidelines', 'Health', 'Hybrids', 'Image', 'Imaging problem', 'Infection', 'Infrastructure', 'Investigation', 'Kidney', 'Label', 'Lesion', 'Longevity', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Motion', 'Newborn Infant', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Pyelonephritis', 'ROC Curve', 'Radiation Dose Unit', 'Respiration', 'Risk', 'Scheme', 'Sedation procedure', 'Societies', 'Statistical Study', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toddler', 'Ursidae Family', 'Validation', 'base', 'body system', 'cardiac single photon emission computed tomography', 'clinically significant', 'deep learning', 'denoising', 'denoising deep learning', 'diagnostic accuracy', 'image processing', 'image reconstruction', 'improved', 'innovation', 'kidney cortex', 'kidney infection', 'molecular imaging', 'pediatric patients', 'preservation', 'reconstruction', 'renal scarring', 'respiratory', 'response', 'single photon emission computed tomography']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,773763,0.023089562551078704
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10011054,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2020,1159612,0.03432304153806453
"Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB) Project Summary Each major human disease is associated with a specific range of morphological changes to cells and tissues in the micron scale. Normal and abnormal structure was discovered and is still characterized using histology - a microscopic technique that depends on physical tissue slices. Presently, histology’s use in systems biology is limited by its largely descriptive and two-dimensional nature. Making histology quantitative and three-dimensional would be potentially transformational for research and diagnostics, but has been impractical. Accordingly, we have now created a 3D form of histology by customizing X-ray microtomography (micro-CT) of fixed and stained, millimeter-scale, whole organisms and tissue samples. We used fixed and metal-stained, whole zebrafish because they contain a full range of tissues within the size range currently studied histologically. The result is the first practical way to create virtual histology-like “sections” in any plane. Three-dimensional, complete histological phenotyping has potential use in genetic and chemical screens, and in clinical and toxicological tissue diagnostics. Here, we propose the next steps needed to enable high-throughput, quantitative, 3D histological phenotyping of whole, millimeter-scale animals. The proposed work applies the principles of chemistry, physics, and computer science to improve image resolution, throughput, and analytics, organized into three specific aims. Specific Aim 1 will build on our developments in this project and further improve imaging volume and resolution by upgrading imaging array, optics, and sub-pixel shifting, and to throughput by changes in sample embedding, loading geometry and mechanics, helical CT scanning, scintillator material, and to data sharing by improvements to the ViewTool infrastructure and user interface. Specific Aim 2 will yield reference images to define the range of normal phenotypic variation and to obtain samples related to a range of potential applications. Specific Aim 3 will apply the power of machine learning to segmentation, annotation, and analytics. Together, this work will establish a practical foundation for large-scale genetic and chemical screens involving mm-scale, whole organisms based on 3-dimensional, quantitative, histological phenotyping. The instrumentation and analytics will be state-of-the-art in its combination of resolution, field-of-view, pancellularity, image quality, analytical potential, throughput, sample stability, and reproducibility and largely usable with both tube and synchrotron X-ray sources. The voxel resolution will be at least 0.5 μm across fields-of-view of up to 1 cm. Representation of every cell type make the images suitable for cross-referencing across imaging modalities. Potential applications will be explored, “wild-type” will begin to be defined, and training sets for automated segmentation generated. The potential impact will encompass the missions of most NIH Institutes and Centers. The whole-animal genetic and chemical screens enabled are expected to impact drug development, diagnostics, and our basic understanding of how genes and environment define phenotype. Project Narrative Our group has established the only three-dimensional form of histology that is suitable for histopathology and quantitative tissue phenotyping, tissue X-ray microtomography (micro-CT). We outline here a plan to establish mechanisms for increasing resolution and field-of-view, to add sample multiplexing, to simply sample preparation, and to explore machine learning mechanisms for defining normal and abnormal structure towards whole-organism complete tissue phenotyping. The resulting tools will allow the community to comprehensively and computationally determine the roles of genes and environment in defining phenotype, which has implications in drug development, biomedical research, and medicine.",Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB),9991958,R24OD018559,"['3-Dimensional', 'Adolescent', 'Age', 'Animal Genetics', 'Animals', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Body measure procedure', 'Caenorhabditis elegans', 'Cells', 'Cellular Structures', 'Cesium', 'Chemicals', 'Chemistry', 'Communities', 'Custom', 'Data', 'Development', 'Diagnostic', 'Drosophila genus', 'Embryo', 'Environment', 'Fishes', 'Foundations', 'Genes', 'Genetic', 'Geometry', 'Goals', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Infrastructure', 'Institutes', 'Iodides', 'Machine Learning', 'Measures', 'Mechanics', 'Medicine', 'Metals', 'Microscopic', 'Mission', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Nerve', 'Normal Range', 'Online Systems', 'Optics', 'Organ', 'Output', 'Pharmaceutical Preparations', 'Phenotype', 'Physics', 'Preparation', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Robotics', 'Roentgen Rays', 'Role', 'Sampling', 'Scanning', 'Series', 'Siblings', 'Signal Transduction', 'Slice', 'Source', 'Spiral Computed Tomography', 'Stains', 'Structural defect', 'Structure', 'Synchrotrons', 'Systems Biology', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Training', 'Travel', 'Tube', 'United States National Institutes of Health', 'Variant', 'Whole Organism', 'Work', 'Writing', 'X-Ray Computed Tomography', 'Zebrafish', 'automated segmentation', 'base', 'bone', 'cell type', 'clinical toxicology', 'computer science', 'computerized tools', 'crowdsourcing', 'data dissemination', 'data sharing', 'detector', 'disease phenotype', 'drug development', 'feature detection', 'histological studies', 'human disease', 'imaging modality', 'improved', 'instrumentation', 'microCT', 'millimeter', 'mutant', 'programs', 'supervised learning', 'tool', 'two-dimensional', 'unsupervised learning', 'virtual']",OD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R24,2020,655482,0.009679540716732821
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,9885175,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Body mass index', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Individual', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2020,590183,0.03769254089662115
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10026443,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2020,630000,0.0049937669005903846
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,-0.00279805997175053
"Generation of parametric images for FDG PET using dual-time-point scans Project Summary/Abstract Positron emission tomography combined with computed tomography (PET/CT) using the radiolabeled tracer 2- deoxy-2-(18F)fluoro-D-glucose (FDG) has become a standard imaging tool for cancer patient management. The semi-quantitative parameter standardized uptake value (SUV) is routinely used in clinical for tumor uptake quantification, which is computed on the static PET image acquired at a certain time (typically 60 min) post tracer injection for a short interval (typically 5-15 min). However, the quantification accuracy of SUV from a single PET scan suffers from the variabilities of tracer plasma clearance and acquisition start time. The dual- time-point FDG PET imaging has been intensively investigated and used in both clinical and research studies, typically one scan at 60 min and the other at 120 min, showing the potential to enhance the diagnostic accuracy of FDG PET by differentiating malignancy from inflammation and normal tissue. However, the current clinical dual-time-point FDG PET studies use the relative SUV change between two scans as the quantification index, which cannot eliminate the variations in tracer plasma clearance. Meanwhile, the dual-time-point protocol has not been optimized and standardized currently, leading to conflicting results. The fully-quantitative parameter, tracer net uptake rate constant Ki, is the most accurate parameter to quantify FDG PET, which is calculated using dynamic imaging with compartmental modeling. Ki is independent on the plasma clearance or acquisition start time. However, the long and complex acquisition protocol (typically at least 60 min), which requires dynamic scanning and sequential arterial blood sampling (or image-derived blood activity) used as input function from the time of injection, limits its application in clinical practice. Meanwhile, generation of the parametric Ki image, which can provide additional heterogeneity information for FDG PET, is challenging clinically using voxel-by-voxel compartmental modeling due to the computational cost and being sensitive to noise using non-linear least squares. The graphical Patlak plot, can be used for simplified Ki calculation and Ki image generation by voxel-by-voxel fitting. However, it still needs dynamic scanning starting from 15-30 min after injection and input function from the time of injection. The aims of this proposal are 1) to optimize the dual-time-point protocol for accurate Ki quantification using Patlak plot without the need for individual patient's input function, and 2) to generate high-quality low-noise dual-time-point Ki images using novel techniques based on deep learning. Upon the success of this project, our proposed approach can obtain reliable tumor Ki quantification and parametric Ki image ""for free"" without adding any additional complexity on the existing dual- time-point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology. We expect the translation of this approach to clinical investigation to be fast, as this is a post-processing approach and is based on data already acquired using clinically used protocol without imposing additional burden to technologists. Project Narrative For FDG PET imaging, we propose to develop a novel and simple approach of quantifying tumor Ki and generating parametric Ki image ""for free"" without adding any additional complexity on the existing dual-time- point protocol currently used in clinical practice, with great potential of improving diagnosis and therapy assessment in oncology.",Generation of parametric images for FDG PET using dual-time-point scans,9896329,R03EB027864,"['Blood', 'Blood specimen', 'Cancer Patient', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Data', 'Diagnosis', 'Generations', 'Glucose', 'Heterogeneity', 'Image', 'Imaging Device', 'Inflammation', 'Injections', 'Label', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Noise', 'Normal tissue morphology', 'Oncology', 'Patients', 'Plasma', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation exposure', 'Radiolabeled', 'Scanning', 'Standardization', 'Techniques', 'Time', 'Tracer', 'Training', 'Translations', 'Variant', 'X-Ray Computed Tomography', 'attenuation', 'base', 'clinical investigation', 'clinical practice', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'diagnostic accuracy', 'image reconstruction', 'improved', 'indexing', 'individual patient', 'innovation', 'novel', 'parametric imaging', 'population based', 'research study', 'simulation', 'success', 'tumor', 'uptake']",NIBIB,YALE UNIVERSITY,R03,2020,80375,0.006783506069457371
"MRI-Based Radiation Therapy Treatment Planning ﻿    DESCRIPTION (provided by applicant): CT is currently the gold standard in radiation therapy treatment planning. MRI provides a number of advantages over CT, including improved accuracy of target delineation, reduced radiation exposure, and simplified clinical workflow. There are two major technical hurdles that are impeding the clinical adoption of MRI-based radiation treatment planning: (1) geometric distortion, and (2) lack of electron density information. The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation treatment planning. We hypothesize that accurate patient geometry and electron density information can be derived from MRI if the appropriate MR image acquisition, reconstruction, and analysis methods are applied. In Aim 1, we will improve the geometric accuracy of MRI by minimizing system-level and patient- specific distortions. To maintain sufficient system-level accuracy, we will perform comprehensive machine- specific calibrations and ongoing quality assurance procedures. To correct patient-induced distortions, we will develop novel computational tools to derive a detailed magnetic field distortion map based on physical principles, which is used to correct susceptibility-induced spatial distortions. In Aim 2, we will develop a unifying Bayesian method for quantitative electron density mapping, by combining the complementary intensity and geometry information. By utilizing multiple patient atlases and panoramic, multi-parametric MRI with differential contrast, we will apply machine learning techniques to encode the information given by intensity and geometry into two conditional probability density functions. These will be combined into one unifying posterior probability density function, which provides the optimal electron density on a continuous scale. In Aim 3, we will clinically evaluate the geometric and dosimetric accuracy of MRI for treatment planning in terms of 3 primary end points: (1) organ contours, (2) patient setup based on reference images, and (3) 3D dose distributions (both photon and proton), using CT as the ground truth. These evaluations will be conducted through patient studies at multiple disease sites, including brain, head and neck, and prostate. Success of the project will afford distortion-free MRI with reliable, quantitative electron density information. This will pave the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process. It will streamline the treatment workflow for the MRI-guided radiation delivery systems under active development. With minimal modification, the proposed techniques can be applied to MR-based PET attenuation correction in PET/MR imaging. More broadly, the unifying Bayesian formalism can be used to improve current imaging biomarkers by integrating a wide variety of disparate information including anatomical and functional imaging such as perfusion/diffusion-weighted imaging and MR spectroscopic imaging. It will facilitate the incorporation of multimodality MRI into the entire process of cancer management: diagnosis, staging, radiation treatment planning, and treatment response assessment. PUBLIC HEALTH RELEVANCE:  The goal of this project is to develop novel image analysis and computational tools to enable MRI-based radiation therapy treatment planning. Success of the project will overcome the major technical hurdles in the use of MRI in radiation therapy and will afford distortion-free MRI with reliable, quantitative electron density information. It will pve the way for MRI-based radiation treatment planning, leading to an improved accuracy in the overall radiation therapy process.",MRI-Based Radiation Therapy Treatment Planning,9843490,R01CA193730,"['3-Dimensional', 'Adopted', 'Adoption', 'Anatomy', 'Atlases', 'Bayesian Method', 'Bayesian Modeling', 'Brain', 'Calibration', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Dose', 'Evaluation', 'Functional Imaging', 'Geometry', 'Goals', 'Gold', 'Head and neck structure', 'Image', 'Image Analysis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Methods', 'Modeling', 'Modification', 'Organ', 'Patients', 'Perfusion', 'Photons', 'Positron-Emission Tomography', 'Predisposition', 'Probability', 'Procedures', 'Process', 'Prostate', 'Protons', 'Radiation Dose Unit', 'Radiation exposure', 'Radiation therapy', 'Site', 'Source', 'Staging', 'System', 'Techniques', 'anatomic imaging', 'attenuation', 'base', 'computerized tools', 'cost', 'density', 'electron density', 'image guided', 'imaging biomarker', 'imaging modality', 'improved', 'magnetic field', 'multimodality', 'novel', 'primary endpoint', 'public health relevance', 'quality assurance', 'radiation delivery', 'reconstruction', 'spectroscopic imaging', 'success', 'tool', 'treatment planning', 'treatment response']",NCI,STANFORD UNIVERSITY,R01,2020,354198,-0.02811879369772713
"Rapid Comprehensive Cardiac MRI Exam for Diagnosis of Coronary Artery Disease PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the leading cause of death in the United States. The clinical gold standards to diagnose and guide treatment of patients with CAD are based on invasive catheter-based procedures, such as x-ray coronary angiography (XCA) for anatomic assessment or fractional flow reserve (FFR) for physiologic assessment. However, there are costs and risks associated with such invasive procedures. Such concerns are further highlighted by the fact that large studies have shown nearly two-thirds of patients referred for their initial elective invasive XCA were found to have no significant stenoses. Thus, better non-invasive diagnostic tools are needed. Cardiac MRI (CMR) is the only non-invasive imaging modality that provides a comprehensive assessment of CAD in a single examination, including an assessment of myocardial perfusion, cardiac function and viability, as well as angiographic evaluation of stenoses, without requiring ionizing radiation. These properties also allow for repeat testing as may be clinically indicated. However, despite its great potential to serve as the non- invasive gatekeeper for costly invasive procedures, lengthy examination times have prevented CMR from clinical translation. Although several accelerated imaging techniques have been proposed, these still require trade-offs between coverage, resolution and signal-to-noise ratio. In this proposal, we will develop and validate novel acquisition and reconstruction strategies to enable a highly accelerated high-resolution whole heart CMR exam for comprehensive CAD assessment in under 10 minutes. We will develop fast and low specific absorption rate outer volume suppression modules to reduce the source of aliasing artifacts from the chest and the back. This will enable higher rates for simultaneous multi-slice imaging in perfusion and cine CMR, improving coverage substantially with minimal noise amplification. For coronary MRI and viability imaging, simultaneous multi-slab imaging will be introduced to CMR, facilitating high isotropic resolution acquisitions with fast coverage. These acquisitions will be supplemented with regularized leakage-blocking and patient- specific machine learning reconstructions for further artifact and noise removal. Finally, we will implement and validate the proposed rapid comprehensive CMR exam in a cohort of suspected CAD patients, comparing our approach with conventional clinical CMR for the assessment of function, perfusion, and viability, and with invasive XCA for the assessment of coronary stenosis. Successful completion of this project has the potential to transform CMR into a leading rapid non-invasive tool for safe and accurate diagnosis of CAD, improving the healthcare of several million patients with chest pain and other CAD symptoms annually. PROJECT NARRATIVE Coronary artery disease (CAD) is the leading cause of death in the United States, accounting for one in six deaths. Cardiac MRI is a non-invasive non-ionizing technique for comprehensive evaluation of CAD, but its clinical translation is hampered by lengthy exam times. In this work, we will develop and validate techniques for rapid cardiac MRI in a short exam time for comprehensive CAD assessment.",Rapid Comprehensive Cardiac MRI Exam for Diagnosis of Coronary Artery Disease,10030978,R01HL153146,"['3-Dimensional', 'Acceleration', 'Accounting', 'Anatomy', 'Award', 'Back', 'Breathing', 'Cardiac', 'Catheters', 'Cause of Death', 'Cessation of life', 'Chest', 'Chest Pain', 'Clinical', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Evaluation', 'Excision', 'Extravasation', 'Gadolinium', 'Gatekeeping', 'Gold', 'Healthcare', 'Heart', 'Image', 'Imaging Techniques', 'Ionizing radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Care Costs', 'Methods', 'Morphologic artifacts', 'Myocardial perfusion', 'Noise', 'Patients', 'Perfusion', 'Physiological', 'Preparation', 'Procedures', 'Property', 'Resolution', 'Risk', 'Roentgen Rays', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Source', 'Symptoms', 'Techniques', 'Testing', 'Time', 'United States', 'Work', 'absorption', 'accurate diagnosis', 'artificial neural network', 'base', 'clinical translation', 'cohort', 'cost', 'diagnosis standard', 'disease diagnosis', 'heart function', 'high resolution imaging', 'imaging modality', 'improved', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'prevent', 'rapid technique', 'reconstruction', 'temporal measurement', 'tool']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2020,504903,-0.007754693913842249
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10019348,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2020,314388,0.017616536713597968
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9997783,R01AR074492,"['3-Dimensional', 'Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Canes', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Extracellular Matrix', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Societies', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'flexibility', 'gait examination', 'gait rehabilitation', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'kinetic model', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2020,435694,0.0032422561550509684
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10006737,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2020,820709,0.023212821048434445
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,9860776,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2020,649717,0.033394118214232285
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,9877188,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2020,265345,0.02517998997746958
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10033192,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Validation', 'Veterans', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,336293,0.012259267382834194
"Development of a Fast Large Area Multiphoton Exoscope (FLAME) Summary. Our long-term goal is to develop a powerful tool based on multiphoton microscopy (MPM) for non- invasive human skin imaging in order to improve clinical diagnosis, guide effective treatment and advance clinical and cosmetic/pharmaceutical research by providing access to dynamic cellular and molecular processes during therapy. MPM is a nonlinear optical imaging technique that provides unique structural and molecular contrast based on endogenous signals such as second harmonic generation from collagen and two- photon excited fluorescence from NADH/FAD+, keratin, melanin and elastin fibers. This contrast allows MPM to provide multi-color, rich molecular information content images that can enhance diagnostic accuracy. MPM overcomes fundamental limitations of existing optical imaging technologies for sub-surface skin imaging and extends the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. Validation of the clinical potential of this technology has been facilitated over the past 10 years by a device developed by Jenlab in Germany, currently the only clinical MPM system on the market. This device has technical limitations in terms of field-of-view (FOV), imaging speed, complexity and cost, which are major barriers to clinical adoption. The goal of this Phase I proposal is to develop and test the technical feasibility for in vivo human skin imaging of a MPM system that is highly optimized for rapid, label-free, macroscopic imaging of human skin with microscopic resolution. The Fast Large Area Multiphoton Exoscope (FLAME) imaging platform will incorporate the innovative optical engine of a benchtop prototype developed at BLI. InfraDerm will innovate on this design to transform it into a compact, portable device, suitable for human skin imaging in clinical setting. Key innovations include: 1) a compact engineering design based on integrating a compact fs fiber laser into the imaging head along with a customized folded optical design to reduce complexity and cost and enhance portability; 2) hardware and software strategies that include a customized patient interface and a combination of optical and mechanical scanning mechanisms with deep learning image restoration to allow millimeter-to-centimeter scale imaging within minutes while maintaining sub-micron resolution. This approach will expand the in vivo imaging area from mm to cm scale, which will be scanned within minutes with sub- cellular resolution. In Aim 1 we will develop the FLAME prototype that incorporates these features. In Aim 2 we will test its technical feasibility for in vivo human skin imaging by evaluating potential effects of motion artifacts. In Aim 3, we will demonstrate the FLAME system potential for non-invasive assessment of melanin content, an ability with potential impact in differential diagnosis and early assessment of treatment efficacy of pigmentary skin disorders, such as melasma. Phase II will refine the technological approach and will test the device feasibility in a first clinical application, differential diagnosis of patients with melasma, a long time dermatology challenge and a particular interest for pharma companies developing therapies for this skin condition. Narrative  InfraDerm LLC proposes to develop and test the technical feasibility for in vivo human skin imaging of a laser scanning microscope based on multiphoton microscopy (MPM) that addresses fundamental and technical limitations of existing optical imaging technologies for sub-surface skin imaging, extending the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. The proposed Fast Large Area Multiphoton Exoscope (FLAME) prototype will be highly optimized for rapid, label- free, macroscopic imaging of human skin with microscopic resolution. An MPM clinical platform, uniquely equipped with this combination of features would embody an innovative and commercially viable product that will broadly impact clinical diagnosis and research in dermatology as well as in cosmetic and pharmaceutical research.",Development of a Fast Large Area Multiphoton Exoscope (FLAME),10153566,R43EB030931,"['3-Dimensional', 'Address', 'Adoption', 'Alopecia', 'Appearance', 'Area', 'Automobile Driving', 'Biopsy', 'Cell physiology', 'Chloasma', 'Clinic', 'Clinical', 'Clinical Research', 'Collagen', 'Color', 'Computer software', 'Cosmetics', 'Custom', 'Dermatology', 'Development', 'Devices', 'Diagnosis', 'Differential Diagnosis', 'Disclosure', 'Elastin', 'Elastin Fiber', 'Excision', 'Extracellular Matrix', 'Face', 'Fiber', 'Fluorescence', 'Generations', 'Germany', 'Goals', 'Head', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Institutes', 'Keratin', 'Label', 'Laboratories', 'Lasers', 'Legal patent', 'Lesion', 'Mechanics', 'Medical', 'Medical Device', 'Melanins', 'Microscope', 'Microscopic', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'NADH', 'Nevus', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacologic Substance', 'Phase', 'Physiological', 'Pigments', 'Process', 'Publications', 'Research', 'Resolution', 'Scalp structure', 'Scanning', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'base', 'cellular imaging', 'clinical Diagnosis', 'clinical application', 'cost', 'cost effective', 'deep learning', 'design', 'diagnostic accuracy', 'effective therapy', 'engineering design', 'human imaging', 'image guided', 'image guided therapy', 'imaging platform', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'millimeter', 'multiphoton imaging', 'multiphoton microscopy', 'optical imaging', 'portability', 'prototype', 'response', 'restoration', 'second harmonic', 'skin disorder', 'skin lesion', 'submicron', 'therapy development', 'tool', 'two-photon']",NIBIB,"INFRADERM, LLC",R43,2020,263074,0.008739022620459728
"Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) remains the main cause of morbidity and mortality in the United States. Cardiac CT provides fast non-invasive assessment of CAD with a high sensitivity and negative predictive value – provided that the lumen can be visualized. However, heavily calcified or stented coronary segments are non- assessable, precluding non-invasive diagnosis of flow-limiting coronary plaques in an estimated 2 million U.S. adults. In addition, the spatial resolution of state-of-the-art CT systems is insufficient for robust visualization of features associated with high risk plaques. Further, while CT can quantitatively evaluate the impact of obstructive CAD on myocardial function using dynamic perfusion imaging, this requires relatively high patient radiation doses, which has limited widespread adoption. Considering the high personal and societal cost of CAD, robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam is critically needed. Built by Siemens Healthcare, a first-of-its-kind, whole-body, photon-counting-detector (PCD) CT system was installed in 2014 at the Mayo Clinic. With support from NIH award EB016966, we showed that the increased iodine contrast-to-noise ratio, decreased electronic noise, spectral imaging capabilities, and improved spatial resolution of PCD-CT relative to commercial CT enabled us to accurately measure increased vasa vasorum density in injured swine carotid arterial walls, demonstrating the exceptional potential of PCD-CT in vascular imaging. Because this system lacks cardiac imaging capabilities, our objective is to develop and validate a PCD dual-source (DS) CT system and novel imaging algorithms to accurately assess CAD in humans, especially in patients with heavily calcified, stented, or high-risk plaques, and to identify patients with myocardial perfusion defects. Our premise is that the established benefits of PCD-CT, used with a DS geometry and advanced noise reduction and material decomposition algorithms, can meet these objectives. Our proposal is significant in many ways: the technology developments will benefit all of CT imaging; robust, accurate, non-invasive imaging of calcified and stented coronary arteries, high-risk plaque features, and myocardial perfusion defects in a single, low-radiation-dose exam will obviate the need for additional imaging, reducing the overall time and cost to comprehensively evaluate CAD and its clinical significance. To extend the demonstrated benefits of PCDs to cardiac CT will require numerous physics, engineering, and algorithm innovations, including novel noise reduction and material decomposition algorithms using energy, spatial and temporal domain redundancies, as well as deep learning. These advances will culminate in a large clinical study to demonstrate not merely that the images are “better,” as is so often done, but that PCD-DSCT provides clinically-significant improvements in the diagnosis and management of patients with suspected CAD. PROJECT NARRATIVE This project will develop a new type of cardiac computed tomography (CT) scanner that is able to comprehensively assess coronary artery disease in humans. This technology, known as photon-counting- detector dual-source CT, is capable of exceptional spatial and temporal resolution, multi-energy spectral imaging and reduced radiation doses, allowing it to image the coronary artery and myocardium with unparalleled quality. This will enable comprehensive assessment of coronary artery anatomy and myocardial function from a single imaging exam, reducing time to diagnosis and cost, while also improving patient diagnosis and management.",Comprehensive characterization of coronary atherosclerotic disease using photon-counting-detector dual-source CT and its impact on patient management,9972330,R01EB028590,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Award', 'Blood Vessels', 'Cardiac', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computed Tomography Scanners', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary artery', 'Defect', 'Diagnosis', 'Diagnostic', 'Dose', 'Engineering', 'Equipment', 'Family suidae', 'Geometry', 'Goals', 'Healthcare', 'Heart failure', 'Human', 'Image', 'Individual', 'Iodine', 'Lesion', 'Low Dose Radiation', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Morbidity - disease rate', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Noise', 'Patients', 'Perfusion', 'Physics', 'Physiological', 'Predictive Value', 'Radiation', 'Radiation Dose Unit', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Societies', 'Source', 'Specimen', 'Stents', 'Sudden Death', 'System', 'Techniques', 'Technology', 'Time', 'Translating', 'United States', 'United States National Institutes of Health', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'algorithm development', 'calcification', 'clinically significant', 'coronary plaque', 'cost', 'deep learning', 'density', 'design', 'detector', 'heart imaging', 'heart motion', 'high risk', 'human subject', 'imaging capabilities', 'improved', 'industry partner', 'injured', 'innovation', 'mortality', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'perfusion imaging', 'photon-counting detector', 'routine practice', 'single photon emission computed tomography', 'societal costs', 'spectral energy', 'spectrograph', 'technology development', 'temporal measurement', 'vasa vasorum']",NIBIB,MAYO CLINIC ROCHESTER,R01,2020,628053,0.02846492379710784
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9961508,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computed Tomography Scanners', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'feature extraction', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2020,175505,-0.05460105646023631
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,0.01593457485188789
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10021685,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,344862,-0.0016572128775645112
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10082348,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2020,1000000,-0.008935320085445059
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,10023268,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'feature extraction', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2020,155784,-0.014416597010063342
"2020 OSA Optical Coherence Tomography Meeting NIBIB PROPOSAL – ABSTRACT 2020 OSA Optical Coherence Tomography Meeting  Biophotonics technologies have clear medical and clinical applications. However, the transformation and translation from the research lab to the clinic, and then to market is a complex process. The 2020 OSA Optical Coherence Tomography meeting will be held on 20-23 April 2020 in Fort Lauderdale, Florida, in parallel with other four topical meetings (Clinical and Translational Biophotonics, Optical Tomography and Spectroscopy, Microscopy, Histopathology and Analytics, Optics and the Brain) within the same congress, the 2020 OSA Biophotonics Congress: Biomedical Optics. The ultimate objective of this conference is to disseminate recent developments in the field of optical coherence tomography (OCT) and inspire new ideas through various forms of interactions within a broad audience that includes engineers, natural scientists (physicists, biologists, chemists, etc.), clinical researchers, industrial R&D and market experts. The meeting will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. New topics to be covered are the development and application of advanced image processing algorithms to interpret to imaging data.  A unique advantage of co-locating this meeting within a congress and presenting joint plenary sessions is the extended cross-fertilization between experts in in the distinct but synergic fields. Technical sessions that include innovative methods such as campfire, fishbowl sessions or unconference, and special programming will ensure the meetings' success as the leading forum for presenting the latest advances, while providing an ideal setting to learn. This meeting will provide an opportunities for students and early career professionals to present their work, participate in professional development activities, hear from and network with internationally-renowned speakers and participate in special programming. Ultimately, holding high-quality scientific and technical meeting, where best-in-class research is presented and discussed will advance knowledge in the field of biomedical optics and biophotonics and propel technological development forward, while augmenting standard academic training and presenting opportunities for career advancement, especially for students and early career professionals. NIBIB PROPOSAL – PROJECT NARRATIVE 2020 OSA Optical Coherence Tomography Meeting The 2020 OSA Optical Coherence Tomography Meetings will bring together many of the leaders in the OCT field, who will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future, including developing and evaluating new imaging approaches to solve important clinical problems. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. These meeting will bring together researchers working in all aspects of this field and will serve as a forum for discussion of existing and emerging techniques as well as future directions.",2020 OSA Optical Coherence Tomography Meeting,9914797,R13EB029301,"['Academic Training', 'Address', 'Algorithms', 'Area', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophotonics', 'Brain', 'Career Mobility', 'Clinic', 'Clinical', 'Collaborations', 'Complex', 'Congresses', 'Data', 'Development', 'Diagnostic Imaging', 'Engineering', 'Ensure', 'Equilibrium', 'Event', 'Fertilization', 'Florida', 'Functional Imaging', 'Future', 'Goals', 'Hearing', 'Histopathology', 'Image', 'Industrialization', 'Industry', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Methods', 'Microscopy', 'National Institute of Biomedical Imaging and Bioengineering', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optical Tomography', 'Optics', 'Paper', 'Participant', 'Peer Review', 'Performance', 'Physicians', 'Process', 'Published Comment', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Services', 'Special Event', 'Spectrum Analysis', 'Students', 'Techniques', 'Technology', 'Time', 'Translating', 'Translational Research', 'Translations', 'Work', 'academic standard', 'adaptive optics', 'bioimaging', 'career', 'clinical application', 'design', 'graduate student', 'image processing', 'imaging approach', 'improved', 'innovation', 'lectures', 'meetings', 'novel', 'posters', 'programs', 'research and development', 'success', 'symposium', 'tool']",NIBIB,OPTICAL SOCIETY OF AMERICA,R13,2020,10000,0.019685757035312768
"Simulation Tools for 3D and 4D CT and Dosimetry Abstract Photon-counting CT (PCCT) is a major technological advance in CT imaging. Using photon-counting instead of current energy-integrating detectors, PCCT can offer superior performance in terms of spatial resolution, artifact reduction, and most notably, material decomposition. PCCT’s energy differentiation utility offers an ability to more precisely distinguish different materials and optimize and expand the use of contrast agents in CT. With these abilities, PCCT can significantly facilitate quantitative imaging, reduce radiation exposure, and enable revolutionary new applications in functional and physiological imaging beyond existing CT techniques. To realize the full potential of PCCT in clinical practice, the technology needs comprehensive assessments and application-based optimizations. Effective design and deployment of PCCT depends on many design and use choices that should be made in view of the eventual clinical utility. Making these choices requires large scale trials on actual patients. However, such trials are challenging, considering the need to make many decisions prior to prototyping, the limited numbers of prototype PCCT scanners available today, and the often-unknown ground-truth in the patient images. Even for existing prototype systems, many decisions require repetitive trials with multiple acquisitions. This is both unethical and impractical considering radiation safety concerns and costs. These challenges can be overcome by utilizing virtual imaging trials (VITs) using computerized patients and imaging models. VITs provide an efficient means with which to determine the most effective and optimized design and use of imaging technologies with complete control over the study design. In our prior funded project, we developed a VIT framework to evaluate standard energy-integrating detector CT technologies. In this project, we expand the applicability of this framework to photon-counting detector CT. Specifically, we enhance our computational XCAT phantoms to model the necessary higher-resolution detail including normal and abnormal tissue heterogeneities and intra-organ contrast perfusion diversity across populations (Aim 1). To image the phantoms, we develop the first PCCT simulator capable of mimicking existing and emerging prototypes (Aim 2). The enhanced VIT framework will provide the essential foundation with which to comprehensively evaluate and optimize PCCT technologies and applications. In Aim 3, we assess and optimize the use of PCCT for morphological, textural, and compositional quantification in select oncologic and cardiac applications, two leading health detriments in the US where PCCT can offer a notable impact. The results will be the first of their kind in comprehensively evaluating the task-based merits and capabilities of PCCT, determining optimum dose per patient size for PCCT imaging of patients for cancerous lesions and cardiac plaque/stenoses, and helping to establish the effective utility of PCCT in clinical care. The purpose of this project is to develop and utilize a virtual framework to comprehensively evaluate and optimize emerging photon-counting devices and applications in CT imaging. The results will be the first of their kind evaluating the task-based merits and capabilities of photon-counting CT and will help establish its effectual utility in oncologic and cardiac care.",Simulation Tools for 3D and 4D CT and Dosimetry,10051026,R01EB001838,"['3-Dimensional', 'Abdomen', 'Anatomy', 'Cancerous', 'Cardiac', 'Caring', 'Clinic', 'Clinical', 'Computer software', 'Contrast Media', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Dose', 'Ensure', 'Ethics', 'Evaluation', 'Foundations', 'Functional Imaging', 'Funding', 'Health', 'Heterogeneity', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Industry', 'Lesion', 'Manufacturer Name', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Noise', 'Organ', 'Pathologic', 'Patient imaging', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Population', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Research Design', 'Resolution', 'Resources', 'Role', 'Safety', 'Scientist', 'Series', 'Specimen', 'Stenosis', 'System', 'Task Performances', 'Techniques', 'Technology', 'Texture', 'Tissue Model', 'Tissues', 'Work', 'X-Ray Computed Tomography', 'analytical method', 'base', 'cardiac plaque', 'clinical application', 'clinical care', 'clinical practice', 'computerized', 'computerized tools', 'cost', 'cost efficient', 'deep learning', 'design', 'detector', 'dosimetry', 'experimental study', 'human imaging', 'human subject', 'improved', 'insight', 'learning strategy', 'photon-counting detector', 'prototype', 'quantitative imaging', 'simulation', 'soft tissue', 'tool', 'virtual', 'virtual imaging']",NIBIB,DUKE UNIVERSITY,R01,2020,545403,0.011810667290300274
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,9924591,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Oncology', 'Organ', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'kinetic model', 'novel', 'parametric imaging', 'predicting response', 'programmed cell death ligand 1', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2020,679852,0.0279000518841175
"Quantitative Low-Dose PET Imaging Project summary Quantitative PET has become increasingly important in clinical management and research, in particular for predicting and assessing response to therapy for cancer patients. Current PET protocols involve injection of PET tracers that typically result in ~6-7 mSv radiation dose to patients. For patients who require multiple repeated PET scans to monitor the response to therapy, and for patients who need PET scans with two or more tracers (e.g., FDG + FLT) to optimally predict response to therapy, it is critical to reduce the radiation dose from the PET tracer injection, while still maintaining the quantitative accuracy and image quality for cancer management. When reducing injection dose, the PET images will have higher noise due to fewer detected counts, which will subsequently introduce errors in quantitative measurements. For moving organs and tumors such as those in the lung and abdomen, respiratory motion can substantially degrade quantitative accuracy, so motion correction is required. Conventional motion correction uses a gating strategy that rebins the PET data, resulting in substantially higher noise in each gate. More advanced methods incorporate motion vector estimation in the image domain for post-registration or motion compensated image reconstruction using all detected events without increasing noise. The motion vectors need to be derived from gated PET, which are even noisier when using a reduced tracer injection in low-dose studies, imposing substantial challenges for accurate and reliable voxel-by-voxel motion vector estimation. In dynamic PET studies with clinical cardiac tracers and other novel oncology and neurology tracers, quantification is even more challenging for low-dose PET as each dynamic frame only contains a small fraction of detected events so the high image noise will affect the determination of image-derived input functions and can lead to bias and high noise in parametric images. In this project, to reduce image noise and maintain quantitative accuracy in PET, we propose to develop, optimize, and evaluate multiple innovative imaging methods for low-dose PET data to achieve comparable quantitative accuracy as full-dose PET. While the imaging developments are generally applicable to all PET tracers in oncology, neurology, and cardiology, since cancer is the primary clinical application of PET, we will focus our investigation and optimization in this project on three lung cancer imaging tracers at different clinical adoption stages as examples: 1) 18F-FDG as a routine clinical tracer, 2) 18F-FMISO for hypoxia studies as a tracer for human research, and 3) 18F-PD-L1 that specifically binds to human PD-L1 in tumors and other organs as a recent first-in-human tracer. For each tracer, we will investigate 1) static PET, 2) gated and respiratory motion corrected PET, and 3) dynamic PET. Project narrative Patient radiation dose is a major concern in PET imaging. This project will be an important step to develop and standardize low-dose PET imaging methods and provide guidance for clinical practice, research studies, and both single and multiple site clinical trials for PET dose reduction. This project will lead to the development of imaging approaches to achieve the lowest level of PET radiation dose for applications not only in evaluation and prediction of response to cancer therapy, but for other applications in oncology, neurology, and cardiology.",Quantitative Low-Dose PET Imaging,10137354,R01EB025468,"['3-Dimensional', 'Abdomen', 'Adoption', 'Affect', 'Anatomy', 'Binding', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Data Set', 'Development', 'Dose', 'Evaluation', 'Event', 'Goals', 'Gold', 'Human', 'Hypoxia', 'Image', 'Injections', 'Investigation', 'Lead', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Neurology', 'Noise', 'Oncology', 'Organ', 'Patients', 'Positron-Emission Tomography', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Standardization', 'Texture', 'Tracer', 'Training', 'Translating', 'Translations', 'Vendor', 'attenuation', 'base', 'cancer imaging', 'cancer therapy', 'clinical application', 'clinical practice', 'clinical research site', 'deep learning', 'first-in-human', 'fluorodeoxyglucose', 'image reconstruction', 'imaging approach', 'imaging modality', 'innovation', 'kinetic model', 'novel', 'parametric imaging', 'predicting response', 'programmed cell death ligand 1', 'reconstruction', 'research study', 'respiratory', 'response', 'tumor', 'vector']",NIBIB,YALE UNIVERSITY,R01,2020,149331,0.0279000518841175
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9970217,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'feature extraction', 'feature selection', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'segmentation algorithm', 'statistical learning', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2020,371369,-0.00263349913418846
"Optimization of PET Image Reconstruction for Lesion Detection Optimization of PET Image Reconstruction for Lesion Detection Abstract PET is a molecular imaging modality widely used in oncology studies due to its high sensitivity and the potential of early diagnosis. For neuroendocrine tumors (NETs), 68Ga-DOTATATE PET has been recently used in clinical routine for imaging NETs in adult and pediatric patients since 2016. It plays an important role in the diagnosis and staging of NETs. However, compared to 18F-FDG PET, the image quality of 68Ga-DOTATATE PET is lower due to much larger positron range, shorter half-life, and lower dose administration limited by generator capacity. All of these compromises the lesion detectability of 68Ga-DOTATATE PET, especially for small lesions, and can potentially lead to inaccurate NET diagnosis. As 68Ga-DOTATATE PET is increasingly used in clinics, there is an urgent and unmet need to further optimize 68Ga-DOTATATE PET/CT imaging for NET detection. Recently, data-driven methods have been developed for PET image denoising, where the PET system model is not considered. As the tumor-to-background ratio of 68Ga-DOTATATE PET is greater than 18F-FDG PET, the lesion recovery of 68Ga-DOTATATE PET can be hugely influenced by the smoothing effects as well as potential mismatches between training and testing datasets. In this study, we propose a novel data- informed and lesion detection-driven image reconstruction framework. The PET system model, image denoising module, and lesion-detection module will all be included in this reconstruction framework. The two specific aims of this exploratory proposal are (1) to develop a lesion detection-driven PET image reconstruction framework and validate it based on comprehensive computer simulations, (2) to apply the proposed reconstruction framework to existing clinical 68Ga-DOTATATE PET/CT datasets and test it based on various figure-of-merits. We expect that the integrated outcome of the specific aims will be a novel and robust image reconstruction framework to better recover lesions in a 68Ga- DOTATATE PET scan, which is essential for NET managements. Optimization of PET Image Reconstruction for Lesion Detection  Project Narrative Positron emission tomography (PET) is an imaging modality widely used in oncology. This project aims to develop a novel lesion detection-driven PET image reconstruction framework. Success of this project can enhance the lesion detectability of current PET imaging protocols, e.g. 68Ga-DOTATATE PET/CT scanning for neuroendocrine tumors (NETs).",Optimization of PET Image Reconstruction for Lesion Detection,10041119,R03EB030280,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Biological Models', 'Clinic', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Distant Metastasis', 'Dose', 'Early Diagnosis', 'Enhancing Lesion', 'FOLH1 gene', 'Gallium', 'Goals', 'Half-Life', 'Image', 'Incidence', 'Injections', 'Label', 'Lead', 'Lesion', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neuroendocrine Tumors', 'Noise', 'Oncology', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Physics', 'Play', 'Positron', 'Positron-Emission Tomography', 'Prevalence', 'Protocols documentation', 'Radionuclide Imaging', 'Reader', 'Recovery', 'Recurrence', 'Resolution', 'Role', 'Savings', 'Sensitivity and Specificity', 'Staging', 'Testing', 'Time', 'Tracer', 'Training', 'United States', 'Validation', 'Vendor', 'X-Ray Computed Tomography', 'base', 'cancer type', 'deep learning', 'denoising', 'effectiveness validation', 'experience', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'molecular imaging', 'neural network', 'neuroendocrine differentiation', 'novel', 'outcome forecast', 'pediatric patients', 'pentetreotide', 'radiologist', 'radiotracer', 'reconstruction', 'routine imaging', 'success', 'treatment optimization', 'treatment planning', 'tumor']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R03,2020,94255,0.03848290099751452
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning ABSTRACT The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and multi-organ auto-segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will optimize multi-organ auto-segmentation based on MT-MR images. In Aim 3, we will assess the performance of MT-MR in the context of pancreatic cancer stereotactic body radiotherapy planning. Successful completion of the project will dramatically improve treatment precision and clinical outcomes, thus further promoting the adoption of radiotherapy in the management of abdominal cancers. Moreover, the developed techniques will open the door to future studies aiming at optimizations in many aspects of radiotherapy. PROJECT NARRATIVE Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and multi-organ auto- segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10053211,R01EB029088,"['3-Dimensional', '4D MRI', 'Abdomen', 'Adoption', 'Agreement', 'Algorithms', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Institution', 'Interobserver Variability', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of abdomen', 'Malignant neoplasm of pancreas', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Patients', 'Performance', 'Phase', 'Planning Techniques', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Translations', 'Variant', 'Water', 'Weight', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'experience', 'image reconstruction', 'improved', 'interest', 'multimodality', 'multitask', 'novel', 'prevent', 'reconstruction', 'respiratory', 'segmentation algorithm', 'simulation', 'soft tissue', 'success', 'treatment planning', 'tumor']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2020,556712,-0.017172137905610174
"Enabling the Next Generation of High Performance Pediatric Whole Body MR Imaging Project Abstract Motivation: We aim to develop and implement a new approach to transform pediatric MRI. The ultimate goal is ultra-fast and motion-robust imaging in a dedicated child-friendly environment to enable more children undergo MRI without anesthesia. For those who still require anesthesia, it will be briefer and lighter, and performed in a safer environment. This project leverages a small compact magnet, designed for adult brain MRI, with gradients that enable very fast imaging. With this magnet as an outstanding starting point, we will tailor our deep experience and multiple successes in developing new MRI approaches to high-density receiver coils, fast imaging sequences, and new image reconstruction methods to set a new standard for pediatric MRI. Approach: Although the compact scanner is designed for adult heads, with a 37 cm inner diameter, it can accommodate children under eight to ten years of age to image any body part. To transform this system for ideal pediatric scanning, three development aims will be pursued. The ﬁrst is to enable optimal signal reception. This will be accomplished through creating new receive chain electronics that are matched to the gradient capabilities, for ultra-high bandwidth imaging. This will be coupled to very thin and formed receive arrays that maximize the size of the patient that can be accommodated in the small bore of the scanner. The second aim is to develop methods of obtaining the highest performance out of the system by characterizing and correcting for its imperfections. This will be coupled to a bespoke approach to peripheral nerve stimulation, enabling maximal use of the gradients on each patient. These two developments will then be leveraged for high efﬁciency and motion robust noncartesian scanning. The ﬁnal aim is to develop a full environment and infrastructure that is well suited to pediatric imaging. Patient preparation and acclimation to MRI will be enhanced by virtual reality. Support equipment for anesthesia, new physiological sensors, and a novel child-friendly audiovisual system will be created. Signiﬁcance: The result of this project will be a revolutionary change in the way that MRI is used and per- formed for children. MRI will be more available, cheaper, safer, and have markedly improved image quality. Project Narrative We will leverage the outstanding magnet and gradients of a unique small bore MRI scanner to create a new standard for unprecedented whole-body pediatric MR imaging. We will develop, integrate, and validate a set of technologies speciﬁcally for pediatric imaging. These include ultra-high bandwidth MRI signal reception from thin form-ﬁtting hardware, high-speed image data acquisition and image reconstruction, and environmental support appropriate for children.",Enabling the Next Generation of High Performance Pediatric Whole Body MR Imaging,9944392,U01EB029427,"['10 year old', '8 year old', 'Acclimatization', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Anesthesia procedures', 'Body part', 'Brain', 'Caliber', 'Caregivers', 'Child', 'Child Health', 'Childhood', 'Cone', 'Coupled', 'Custom', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Electrocardiogram', 'Electronics', 'Environment', 'Equipment', 'Flare', 'Goals', 'Head', 'Image', 'Immersion', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Morphologic artifacts', 'Motion', 'Motivation', 'Noise', 'Partner in relationship', 'Patients', 'Pediatrics', 'Performance', 'Peripheral Nerve Stimulation', 'Physiologic pulse', 'Physiological', 'Preparation', 'Radiation', 'Resolution', 'Respiration', 'Role', 'Scanning', 'Side', 'Signal Transduction', 'Speed', 'Support System', 'System', 'T2 weighted imaging', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Thinness', 'Time', 'Vendor', 'base', 'commercialization', 'contrast imaging', 'data acquisition', 'density', 'design', 'digital', 'experience', 'hemodynamics', 'image reconstruction', 'imaging capabilities', 'imaging system', 'improved', 'innovation', 'next generation', 'novel', 'novel strategies', 'open source', 'pediatric patients', 'reconstruction', 'respiratory', 'sensor', 'success', 'tool', 'virtual reality', 'whole body imaging']",NIBIB,STANFORD UNIVERSITY,U01,2020,887058,0.012165977127165965
"Rapid Robust Pediatric MRI Project Abstract Motivation: This is a competing renewal of our successful project, Rapid Robust Pediatric MRI, R01 EB009690. MRI offers superb soft tissue contrast for children, without the ionizing radiation and cancer risk of CT. However, MRI use has been limited due to long exams, low spatial resolution, and motion-artifacts. Thus, MRI often requires prolonged anesthesia with breath-holds and attendant risk; hence, children often lack the beneﬁts of cross-sectional imaging altogether or are exposed to ionizing radiation. The previous project addressed these concerns by creating a dedicated pediatric imaging system. Highly par- allel, high-SNR 3T receive coil arrays were designed and constructed speciﬁcally for pediatric body imaging. The high SNR was used to accelerate scans reconstructed with a combination of parallel imaging, new mo- tion correction algorithms, compressed sensing (CS), and higher dimensional imaging. The resulting system is now being used extensively in clinical practice, signiﬁcantly reducing anesthesia depth and duration, and has markedly increased our MRI utilization. Key technologies have been or are now being commercialized with GE Healthcare, including the pediatric receive array, CS, 4D ﬂow, full-Fourier single-shot T2-weighted scanning, and coil compression. Siemens has licensed ﬁve of our patents, implemented them in work-in-progress packages, and productized our coil compression and our ESPIRiT coil sensitivity estimation. Philips has licensed three of our patents. This ensures broad impact. Approach: Despite signiﬁcant progress and reduced anesthesia depth and duration, patient cooperation re- mains the main limitation to eliminate anesthesia in all pediatric body MRI exams. Many children will cooperate for several minutes, but then ﬁdget and get out of the scanner. Others are content until acoustic noise agi- tates them. Therefore the major emphasis now is greater exam execution speed, comprehensive elimination of acoustic noise, and increased robustness, particularly to contrast agent injection. The project has three interrelated development aims, validated by clinical studies. Aim 1 will enable fast 2D imag- ing for quiet T2 and quiet low-distortion diffusion weighted imaging. A second aim is to develop free-breathing 3D contrast-enhanced and diffusion-weighted imaging that is silent and motion-robust. The third aim will enable au- tomated, smart scanning to speed the exam execution and adaptive protocols to increase the exam robustness. The impact of all of these developments in the clinic will then be assessed to assess the resulting reduction of anesthesia. Signiﬁcance: This work will lead to fast, robust, broadly-applicable pediatric MRI protocols with less anes- thesia, making MRI safer, cheaper, and more available to children. MRI will be transformed into a workhorse modality, reducing CT radiation burden. The techniques will facilitate wide application in the community setting and permit new MRI applications, for both pediatric and adult diseases. Project Narrative Pediatric MRI often requires anesthesia. After considerable progress reducing the depth and duration of anes- thesia, this work aims to reduce the frequency of anesthesia through a synergistic combination of fast, quiet, motion-robust, automated, and adaptive scanning. This will make MRI safer, cheaper, and more widely available to children, reducing the population risk of radiation from CT.",Rapid Robust Pediatric MRI,9927622,R01EB009690,"['3-Dimensional', 'Acoustics', 'Address', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Body part', 'Bolus Infusion', 'Breathing', 'Child', 'Child Health', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Computational Technique', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Development', 'Diagnostic Imaging', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Ensure', 'Exposure to', 'Frequencies', 'Funding', 'Goals', 'Healthcare', 'Image', 'Image Compression', 'Image Enhancement', 'Injections', 'Ionizing radiation', 'Legal patent', 'Letters', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modality', 'Morphologic artifacts', 'Motion', 'Motivation', 'Noise', 'Patients', 'Pediatric Oncology', 'Pediatrics', 'Population', 'Protocols documentation', 'Radiation', 'Resolution', 'Risk', 'Role', 'Running', 'Scanning', 'Speed', 'System', 'T2 weighted imaging', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transplantation', 'Validation', 'Work', 'base', 'cancer risk', 'clinical practice', 'clinical translation', 'community setting', 'compliance behavior', 'contrast enhanced', 'data quality', 'design and construction', 'experience', 'high dimensionality', 'image reconstruction', 'imaging system', 'innovation', 'multidisciplinary', 'novel', 'patient tolerability', 'pediatric patients', 'programs', 'radiation risk', 'reconstruction', 'skills', 'soft tissue', 'volunteer']",NIBIB,STANFORD UNIVERSITY,R01,2020,664041,-0.002371628007305345
"Permeability Imaging using Simultaneous Dynamic PET and Arterial Spin Labeling MRI Abstract Candidate's Career Goals: Dr. Han has a strong background in magnetic resonance (MR) imaging, image reconstruction and arterial spin labeling (ASL), with a Ph.D. in bio and brain engineering. Dr. Han is currently at a junior-faculty rank of instructor at Massachusetts General Hospital (MGH). His goal is to expand his future career to multi-modality positron emission tomography (PET)-MR imaging for translational research and clinical improvement. His long-term goal is to become an independent, accomplished investigator that can lead future scientific and clinical imaging projects taking full advantage of multi-modality PET-MR imaging. Career Development Plan: Foundational training in PET/PET-MR imaging as well as neurology is proposed for the candidate, an area that the candidate currently lacks knowledge and experience in. The candidate plans to engage in formal course work/seminars, research via one-on-one instructions with mentors and collaborators, conferences/presentations, manuscript/grant preparations, and teaching/leadership roles to grow as an independent investigator in the field of PET-MR imaging and neurology. Research Project: The overall goal of the proposed research is to take advantage of simultaneous dynamic PET and ASL-MR imaging to estimate the permeability surface product (PS) of the PET tracer, which is new physiological information that cannot be obtained with PET or MR alone. PS describes the unidirectional flux rate of macromolecules from the blood plasma into the interstitial space of cellular tissue and is the key metric for assessing the integrity of the blood-brain barrier (BBB). Knowing the PS of the PET tracer provides powerful capability to probe the physiological delivery process of essential macromolecules involved in the pathogenesis of diseases in relation to BBB, due to the theoretically unlimiting potential in the design of radioactive analogs of important biological compounds. We plan to develop a PET tracer PS mapping method, achieve the first phantom and human study with PS mapping, and study the changes in the spatial distribution of tau neurofibrillary tangles (tau) and amyloid-beta (Aß) plaque depositions in relation to the BBB integrity changes with pathological events associated with the progression of AD, by performing dynamic-PET/mPLD-ASL studies using 18F-T807 and 11C- Pittsburgh compound B (PiB) PET tracers on AD and normal subjects. Environment: MGH provides an ideal setting for conducting research in MR, PET, and PET-MR imaging since multiple state-of-the-art imaging systems are available for preclinical/clinical MR scanners and preclinical simultaneous PET-MR scanners. There is a dynamic flow phantom designed to simulate blood flow for two compartment pharmacokinetics and an MR-compatible pump and detection system for continuous blood sampling suitable for performing ASL flow and PET imaging studies with arterial sampling. Also, there is a shared memory supercomputer ideal for the image reconstruction proposed in the project. MGH is also home to many experts in both PET-MR imaging and neurology who can provide their expertise to this project. Narrative The overall goal of the proposed research is to take advantage of simultaneous dynamic positron emission tomography (PET) and arterial spin labeling (ASL) magnetic resonance imaging (MRI) to estimate the permeability surface product (PS) of the PET tracer, which is new physiological information that cannot be obtained with PET or MR alone. Knowing the PS of the PET tracer provides powerful capability to probe the physiological delivery process of essential macromolecules involved in the pathogenesis of diseases in relation to blood-brain barrier (BBB), due to the theoretically unlimiting potential in the design of radioactive analogs of important biological compounds (e.g., glucose, amino-acids or proteins). If successful, the proposed technique will allow the extraction of new physiological information, PS, while facilitating a new understanding of the relationships between BBB integrity, neurovascular function and proteinopathy in the etiology and progression of diseases such as AD.",Permeability Imaging using Simultaneous Dynamic PET and Arterial Spin Labeling MRI,10039839,K01EB030045,"['3-Dimensional', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Amino Acids', 'Amyloid beta-Protein', 'Anatomy', 'Area', 'Base Sequence', 'Biological', 'Blood - brain barrier anatomy', 'Blood flow', 'Blood specimen', 'Brain', 'Clinical', 'Cognitive', 'Data', 'Deposition', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Drug Kinetics', 'Educational process of instructing', 'Engineering', 'Environment', 'Etiology', 'Event', 'Faculty', 'Foundations', 'Functional disorder', 'Future', 'General Hospitals', 'Glucose', 'Goals', 'Grant', 'Home environment', 'Image', 'Imaging Device', 'Instruction', 'Kinetics', 'Knowledge', 'Label', 'Lead', 'Leadership', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuscripts', 'Maps', 'Massachusetts', 'Measurement', 'Mentors', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Multimodal Imaging', 'Neurology', 'Noise', 'Pathogenesis', 'Pathologic', 'Performance', 'Permeability', 'Physiological', 'Pittsburgh Compound-B', 'Plasma', 'Play', 'Positron-Emission Tomography', 'Preparation', 'Process', 'Proteins', 'Pump', 'Radial', 'Radioactive', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Senile Plaques', 'Spatial Distribution', 'Spin Labels', 'Surface', 'System', 'Techniques', 'Time', 'Tissues', 'Tracer', 'Training', 'Translational Research', 'Work', 'analog', 'attenuation', 'base', 'career', 'career development', 'clinical imaging', 'deep learning', 'design', 'experience', 'human study', 'image reconstruction', 'imaging modality', 'imaging study', 'imaging system', 'improved', 'instructor', 'interstitial', 'macromolecule', 'multimodality', 'neurovascular', 'novel', 'pre-clinical', 'reconstruction', 'shared memory', 'supercomputer', 'symposium', 'tau Proteins', 'tau aggregation']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K01,2020,123012,0.006088440486031554
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,10011565,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'automated segmentation', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2020,154915,-0.04750062985058943
