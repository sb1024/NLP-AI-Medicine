text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Innovative Vaccine Approaches ABSTRACT Support is requested for a Keystone Symposia conference entitled Innovative Vaccine Approaches, organized by Drs. Mariagrazia Pizza, Galit Alter and Gordon Dougan. The conference will be held in Vancouver, Canada from June 27- July 1, 2021. Vaccines have the power to prevent and potentially eradicate a wide range of infectious diseases, representing one of the most effective life-saving measures at our disposal against global health threats. The recent coronavirus pandemic has brought the importance and urgency of vaccine development efforts into sharp focus. Moreover, the vaccinology field is evolving very rapidly, thanks to advances in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis of antigens and antigen- antibody complexes and impacts of variation. Over the years, this field has also experienced an elucidation of mechanisms of immunity and protection, and identification of correlates. However, many questions are still unsolved and innovative approaches are needed to address new vaccine challenges like antimicrobial resistance, emerging infectious diseases, cancer and diseases associated with our aging population. This conference will cover the latest advances and novel approaches towards vaccine development, including: (1) novel antigen delivery systems; (2) in vitro and in vivo model systems for vaccine appraisal (3) the use of human challenge models; (4) the role of ‘systems biology’ in the comprehensive analysis of immune correlates, biomarker identification and safety; (5) machine-learning approaches to define correlations between antibody repertoires and protection; and (6) strategies for developing low cost vaccines for economically challenged populations. Together these topics will provide attendees with the new ideas and tools to continue to forge new frontiers in vaccine capabilities. PROJECT NARRATIVE Vaccines have the power to prevent and potentially eradicate a wide range of both infectious and non- infectious diseases. The field is evolving very rapidly due to improvements in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis techniques. This conference will accelerate advances the field, bringing together public and private communities to ensure the end of the COVID-19 pandemic and other epidemics that afflict the population. This event provides a unique opportunity for discussion of the key challenges in making low cost vaccines for economically challenged populations and how to address burning topics such as pandemics, antimicrobial resistance, emerging infectious diseases, cancer and an aging population.",Innovative Vaccine Approaches,10237543,R13AI161938,"['Address', 'Antibody Repertoire', 'Antigen-Antibody Complex', 'Antigens', 'Antimicrobial Resistance', 'Biological Models', 'COVID-19 pandemic', 'Canada', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Coronavirus', 'Disease', 'Educational workshop', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Event', 'Future', 'Genomics', 'Human', 'Immersion', 'Immune', 'Immunity', 'Immunology', 'In Vitro', 'Knowledge', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Microbiology', 'Modeling', 'Outcome', 'Population', 'Privatization', 'Research', 'Research Personnel', 'Role', 'Safety', 'Savings', 'Scientist', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Vaccines', 'Variant', 'aging population', 'biomarker identification', 'clinical practice', 'cost', 'experience', 'frontier', 'global health', 'in vivo Model', 'innovation', 'manufacturability', 'next generation', 'novel', 'novel strategies', 'novel vaccines', 'pandemic disease', 'posters', 'prevent', 'symposium', 'tool', 'vaccine development', 'vaccine discovery', 'vaccinology']",NIAID,KEYSTONE SYMPOSIA,R13,2021,8000
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591
"AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms Abstract This project aims to develop WormInvestigator™, a novel, highly innovative system for performing automated, high-throughput and longitudinal studies of the behavior of C. elegans worms freely moving and socially interacting on agar plates (hereafter: ""freely moving worms"") across multiple time points over extended times (e.g., multiple days) with repeated measures designs. Work in Phase I will focus on demonstrating feasibility of our novel, patent pending, WormRecognizer™ technology – the ability to perform automatic, image-based identification of individual C. elegans worms within a group of freely moving worms (""digital tagging of freely moving worms""). Work in Phase II will focus on creating the full functionality of WormInvestigator for the commercial release. The innovation inherent in WormRecognizer will serve as the basis for enabling a game- changing innovation in the field – the ability to perform high throughput longitudinal, repeated measures design analyses of locomotion and other behavior of freely moving C. elegans worms from discrete, non-continuous video sequences. Compared to study designs that have independent groups repeated measures designs offer more statistical power and the possibility to track an effect over time. Specifically, repeated measures designs for analyzing locomotion and other behavior of freely moving worms will allow researchers to definitively assess the likelihood that a particular behavior is associated with a prior behavior, which is impossible without repeated measures designs or impractical continuous imaging and tracking under constant illumination. WormRecognizer will leverage the Deep Convolutional Neural Network (CNN) architecture to perform automatic identification of the tracks of the same worm in videos of groups of freely moving worms recorded at different time points; encouraging pilot data were generated during preparation of this application. C. elegans is increasingly used as a model organism in research focusing on brain mechanisms underlying complex behaviors and pathological alterations thereof, including research into neurodevelopment, Alzheimer's disease, autism, schizophrenia and traumatic brain injury. Thus, WormInvestigator will enable significant advancements in various mental neuroscience applications that use C. elegans as a model organism. Specifically, the fact that C. elegans express many of the neurotransmitters and associated receptors that are found in higher eukaryotes, including humans, makes C. elegans highly attractive for the (high throughput) screening of next generation therapeutics for mental diseases such as Alzheimer's disease, as well as for disorders that rely on neurotransmitter release modulation such as next generation treatments for schizophrenia. We will perform extensive feasibility studies, product validation and usability studies of WormInvestigator in close collaboration with expert neuroscientists. Market research performed during preparation of this application indicated that WormInvestigator will expand the use of C. elegans as a model organism to many laboratories that do not currently use them. A competing technology is not available. We anticipate the global market size for WormInvestigator to be more than 300 systems. Narrative Performing longitudinal studies and repeated measures design analyses in both short-term and long-term experimental assays focusing on the analysis of locomotion and other behavior of multiple C. elegans worms holds the promise of profound progress in next-generation neuroscience studies such as understanding neurodevelopmental, neuropsychiatric and neurodegenerative disorders, as well as aging research, drug discovery and toxicology. Our proposed product will be a transformative technology, using new analytical methods based on artificial intelligence algorithms that, for the first time, will enable researchers to perform these data-rich longitudinal studies and, thus, repeated measures design analyses in assays using C. elegans as a model organism. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.","AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms",10258638,R43MH126834,"['Acetylcholine', 'Address', 'Agar', 'Aging', 'Alzheimer&apos', 's Disease', 'Animal Behavior', 'Animal Model', 'Appearance', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Behavioral Research', 'Biological Assay', 'Biotechnology', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Dopamine', 'Eukaryota', 'Feasibility Studies', 'Glutamates', 'Goals', 'Human', 'Image', 'Individual', 'Laboratories', 'Legal patent', 'Lighting', 'Locomotion', 'Longevity', 'Longitudinal Studies', 'Market Research', 'Massachusetts', 'Measures', 'Microscope', 'Molecular', 'Motion', 'Mus', 'Names', 'National Institute of Mental Health', 'Nematoda', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neurosciences', 'Neurotransmitters', 'Pathologic', 'Pharmacologic Substance', 'Phase', 'Population Analysis', 'Preparation', 'Psyche structure', 'Rattus', 'Research', 'Research Design', 'Research Personnel', 'Rodent', 'Schizophrenia', 'Schools', 'Serotonin', 'Speed', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'Validation', 'Visual Fields', 'Work', 'analytical method', 'autism spectrum disorder', 'base', 'behavioral study', 'convolutional neural network', 'design', 'digital', 'drug discovery', 'fighting', 'free behavior', 'gamma-Aminobutyric Acid', 'high throughput screening', 'innovation', 'intelligent algorithm', 'longitudinal analysis', 'neural network architecture', 'neurodevelopment', 'neuropsychiatric disorder', 'neurotransmitter release', 'next generation', 'novel', 'novel therapeutics', 'prevent', 'prototype', 'receptor', 'social', 'usability']",NIMH,"MICROBRIGHTFIELD, LLC",R43,2021,449987
"Thalamocortical Responsive Neurostimulation for the Treatment of Lennox-Gastaut Syndrome Project Summary / Abstract  Lennox-Gastaut Syndrome (LGS) is a devastating form of childhood onset epilepsy with cognitive dysfunction and very frequent generalized onset seizures (GOS) often leading to injury. Driven by the lack of effective therapies and the demonstrated safety and efficacy of brain-responsive stimulation for medically intractable focal onset seizures (FOS), this study will test whether brain-responsive neurostimulation of thalamocortical networks (RNS-TCN) is a feasible strategy to treat LGS. Specifically, the project aims to: (1) acquire preliminary evidence for safety and efficacy in treating GOS of LGS with RNS-TCN; (2) create an interactive therapy-decision support system based on patient-specific computational network models and machine learning to identify optimal lead placement and stimulation parameters.  Using the RNS® System, which is FDA approved for FOS, an early feasibility IDE study will be conducted at 6 epilepsy centers in 20 patients with LGS and medically intractable GOS. The patients will be enrolled in two cohorts of 10, with safety and efficacy milestones in the first cohort governing the enrollment of the second cohort. Patients will have two depth leads placed bilaterally in the centromedian nucleus of the thalamus and two subdural strip leads placed bilaterally on the medial prefrontal cortex. These targets are selected because they are implicated in the onset and spread of GOS in LGS. Leads will be located within each target such that stimulation maximally engages the thalamocortical network, guided by finite-element biophysical models created from structural magnetic resonance imaging and diffusion weighted imaging. The finite-element biophysical models will also be used to identify the initial RNS-TCN stimulation pathway and current amplitude. During the blinded evaluation period patients will be randomized to receive either high-frequency short burst (HFSB) or low-frequency long burst (LFLB) RNS-TCN, then enter a washout period before crossing over to receive the other treatment condition. During the open label period stimulation parameters can be modified at the discretion of the physician. Parameter adjustments will be informed by using a Bayesian optimization model developed for specifically for each patient. All clinical and electrophysiological data collected during the study will be used to identify a biomarker of clinical response; if found, these will aid future epilepsy research and clinical practice. If safety is favorable and there is preliminary evidence for efficacy, then this early experience will inform the design of a future larger feasibility study.  In addition to treating a population in need, this project engages in fundamental discovery of biomarkers in generalized network epilepsies, and develops novel automated therapy selection policies that have the potential to improve the lives of patients with LGS and other seizure disorders. Project Narrative Lennox-Gastaut Syndrome (LGS) is a devastating form of childhood onset epilepsy characterized by cognitive dysfunction and very frequent generalized onset seizures (GOS) that often lead to injury. Driven by the lack of effective therapies and the demonstrated safety and efficacy of brain-responsive stimulation for treating medically intractable focal onset seizures, this study will test whether brain-responsive neurostimulation can also be used to treat LGS. The intent of the proposed research is to test the safety and preliminary efficacy of responsive neurostimulation of thalamocortical networks (RNS-TCN) involved in GOS, to identify promising detection and stimulation approaches, and to characterize neurophysiological biomarkers of clinical efficacy that will aid future research and clinical practice.",Thalamocortical Responsive Neurostimulation for the Treatment of Lennox-Gastaut Syndrome,9958791,UH3NS109557,"['12 year old', 'Adverse effects', 'Bilateral', 'Biological Markers', 'Blinded', 'Brain', 'Centromedian Thalamic Nucleus', 'Childhood', 'Clinical', 'Clinical Research', 'Clonic Seizure', 'Computer Models', 'Crossover Design', 'Data', 'Decision Support Systems', 'Deep Brain Stimulation', 'Detection', 'Device Designs', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electrodes', 'Electroencephalography', 'Electrophysiology (science)', 'Elements', 'Enrollment', 'Epilepsy', 'Etiology', 'Evaluation', 'FDA approved', 'Feasibility Studies', 'Follow-Up Studies', 'Frequencies', 'Functional disorder', 'Future', 'Gastaut syndrome', 'Generalized Epilepsy', 'Genetic Crossing Over', 'Goals', 'Impaired cognition', 'Implant', 'Injury', 'Ipsilateral', 'Lead', 'Longterm Follow-up', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medial', 'Medical', 'Medical Imaging', 'Mental Depression', 'Modeling', 'Neurons', 'Online Systems', 'Operative Surgical Procedures', 'Outcome', 'Parkinson Disease', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Pilot Projects', 'Policies', 'Population', 'Post-Traumatic Stress Disorders', 'Prefrontal Cortex', 'Randomized', 'Research', 'Safety', 'Seizures', 'Selection for Treatments', 'Single-Blind Study', 'Structure', 'System', 'Testing', 'Time', 'Tonic Seizures', 'Update', 'addiction', 'atonic seizure', 'base', 'biomarker discovery', 'biophysical model', 'blind', 'clinical efficacy', 'clinical practice', 'cohort', 'computational network modeling', 'design', 'diaries', 'early experience', 'effective therapy', 'improved', 'interactive therapy', 'lead optimization', 'machine learning method', 'mortality', 'neuroimaging', 'neurophysiology', 'neuroregulation', 'novel', 'open label', 'potential biomarker', 'predict clinical outcome', 'prototype', 'recruit', 'response', 'safety testing', 'tool']",NINDS,"NEUROPACE, INC.",UH3,2021,831388
"Maximizing Investigators' Research Award (R35) PROJECT SUMMARY The “Tools for Transmission of Agents and Conditions (TRAC)” program will synergize statistical and mathematical modeling work in three areas of application: 1) Tuberculosis (TB) incidence and transmission; 2) monitoring substance use disorder (SUD) patterns; and 3) SARS CoV-2 transmission modeling. These three conditions are major public health problems, with TB being the leading cause of infectious disease death globally, SUD causing more deaths in the United States than HIV/AIDS in its peak, and SARS CoV-2 causing a pandemic with societal disruption and mortality exceeding anything we have experienced in the last century. We need improved analytical tools that leverage existing data to monitor these diseases, infer transmission hot spots, determine the efficacy of interventions, and understand the burden of these conditions. This program will bring together an expert group of quantitative researchers with skills that are readily applied to these problems. We also leverage our strong collaborations with clinician researchers and public health officials to ensure that the methods we develop are addressing important questions and consistent with our current understanding of these diseases. By creating a program to facilitate communication between these experts, we will enable greater innovation in modeling key aspects of these diseases and create exciting methodological synergies across diseases. Our team is well positioned to incorporate data from emerging technologies, including high throughput sequencing data to determine TB risk signatures and inform transmission links for TB and SARS CoV-2. Our expertise in machine learning, a broad range of statistical methodologies, and mathematical modeling will enable us to leverage the rich information in large databases that are emerging to better understand SUD patterns and identify risk signatures. We will also build infrastructure with our partners to make the analytical tools that we develop more accessible to public health practitioners and other researchers. The impact of this work is to develop a suite of analytical tools that leverage rapidly emerging rich data sets to improve our understanding of disease transmission patterns, monitor changing dynamics of these conditions, and understand intervention strategies that are most effective. This work will inform public health practice for these diseases and create reproducible tools that can be used in an ongoing way. PROJECT NARRATIVE This project will generate analytical tools to address three major public health challenges: 1) Tuberculosis, 2) Substance use disorders, and 3) SARS CoV-2. These tools will improve our understanding of the transmission patterns of these diseases, advance our ability to monitor them, and inform intervention strategies. We will build infrastructure to make these methods available to public health practitioners and other researchers.",Maximizing Investigators' Research Award (R35),10205596,R35GM141821,"['2019-nCoV', 'AIDS/HIV problem', 'Address', 'Area', 'Award', 'Cessation of life', 'Collaborations', 'Communicable Diseases', 'Communication', 'Data', 'Data Set', 'Databases', 'Disease', 'Emerging Technologies', 'Ensure', 'High-Throughput Nucleotide Sequencing', 'Hot Spot', 'Incidence', 'Infrastructure', 'Intervention', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Pattern', 'Positioning Attribute', 'Public Health', 'Public Health Practice', 'Reproducibility', 'Research', 'Research Personnel', 'Risk', 'SARS-CoV-2 transmission', 'Statistical Models', 'Substance Use Disorder', 'Treatment Efficacy', 'Tuberculosis', 'United States', 'Work', 'analytical tool', 'disease transmission', 'experience', 'improved', 'innovation', 'mathematical model', 'mortality', 'pandemic disease', 'programs', 'skills', 'synergism', 'tool', 'transmission process']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R35,2021,171876
"A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth This project provides a data science framework and a toolbox of best practices for systematic and reproducible data-driven methods for validating and deriving RDoC constructs with relevance to psychopathology. Despite recent advances in methods for data-driven constructs, results are often hard to reproduce using samples from other studies. There is a lack of systematic statistical methods and analytical design for enhancing reproducibility. To fill this gap, we will develop a data science framework, including novel scalable algorithms and software, to derive and validate RDoC constructs. Although the proposed methods will generally apply to all RDoC domains and constructs, we focus specifically on furthering understanding of the RDoC domains of cognitive control (CC) and attention (ATT) constructs implicated in attention deficit disorder (ADHD) and obsessive-compulsive disorder (OCD). Our application will use multi-modal neuroimaging, behavioral, and clinical/self-report data from large, nationally representative samples from the on Adolescent Brain Cognitive Development (ABCD) study and multiple local clinical samples with ADHD and OCD. Specifically, using the baseline ABCD samples, in aim 1, we will apply and develop methods to assess and validate the current configuration of RDoC for CC and ATT using confirmatory latent variable modeling. We will implement and develop new unsupervised learning methods to construct new computational-driven, brain-based domains from multi-modal image data. In Aim 2, We will introduce network analysis (via Gaussian graphical models) to characterize heterogeneity in the interrelationship of RDoC measurements due to observed characteristics (i.e., age and sex). We will further model the heterogeneity of the population due to unobserved characteristics by introducing the data-driven precision phenotypes, which are the subgroup of participants with similar RDoC dimensions. We propose a Hierarchical Bayesian Generative Model and scalable algorithm for simultaneous dimension reduction and identify precision phenotypes. The model also serves as a tool to transfer information from the community sample ABCD to local clinical enriched studies. In aim 3, we will utilize the follow-up samples from ABCD and local clinical enriched data sets to validate the results from Aims 1 and 2 and assess the clinical utility of the precision phenotypes in predicting psychological development in follow-up time. Our project will provide a suite of analytical tools to validate existing RDoC constructs and derive new, reproducible constructs by accounting for various sources of heterogeneity. To advance the understanding of psychopathology using dimensional constructs of measurements from multiple units of analysis, we propose reproducible statistical framework for validating and deriving RDoC constructs with relevance to psychopathology. We will use multi-modal neuroimaging, behavioral and clinical/self-report data from multiple samples to develop this framework. The design of our study consists of analyzing large, nationally representative samples, validating the results in local clinically enriched samples, and transfer information from the large community samples to local clinical samples.",A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth,10250553,R01MH124106,"['11 year old', 'Accounting', 'Adolescent', 'Age', 'Algorithmic Software', 'Algorithms', 'Attention', 'Attention Deficit Disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Characteristics', 'Child', 'Chronology', 'Clinical', 'Clinical Data', 'Communities', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Dimensions', 'Ensure', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Goals', 'Heterogeneity', 'Image', 'Knowledge', 'Learning', 'Link', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Obsessive-Compulsive Disorder', 'Participant', 'Pathway Analysis', 'Patient Self-Report', 'Phenotype', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Psychological Transfer', 'Psychopathology', 'Reproducibility', 'Reproducibility of Results', 'Research Domain Criteria', 'Sampling', 'Source', 'Statistical Methods', 'Structure', 'Subgroup', 'Symptoms', 'Time', 'Variant', 'Youth', 'age effect', 'analytical tool', 'autoencoder', 'base', 'biological sex', 'cognitive control', 'cognitive development', 'deep learning', 'design', 'follow up assessment', 'follow-up', 'high dimensionality', 'independent component analysis', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'multimodality', 'network models', 'neuroimaging', 'novel', 'psychologic', 'response', 'sex', 'tool', 'unsupervised learning']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,660324
"Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center The “clinical high risk” (CHR) for psychosis syndrome is an antecedent period characterized by attenuated psychotic symptoms that are marked by subtle deviations from normal development in thinking, motivation, affect, behavior, and a decline in functioning. Early intervention in this CHR population is critical to prevent psychosis onset as well as other adverse outcomes. However, the presentation of symptoms and subsequent course is highly variable, and there is a paucity of biomarkers to guide treatment development. Thus, to improve predictive models that are clinically relevant, several issues need to be addressed: 1) focusing on outcomes beyond psychosis; 2) taking into account heterogeneity in samples and outcomes; and 3) integrating data sets with a broad array of variables using innovative algorithms to overcome variability across studies. To address these challenges, the proposed “Psychosis Risk Evaluation Data Integration and Computational Technologies: Data Processing, Analysis, and Coordination Center” (PREDICT-DPACC) brings together a multidisciplinary team of highly experienced researchers with proven capabilities in all aspects of large-scale studies, CHR studies, as well as computational expertise. The ultimate goal is to identify new CHR biomarkers, and CHR subtypes that will enhance future clinical trials. To do so, the PREDICT-DPACC will 1) aggregate extant CHR- related data sets from legacy datasets; 2) provide collaborative management, direction, data processing and coordination for new U01 multisite network(s); and 3) develop and apply advanced algorithms to identify biomarkers that predict outcomes, and to stratify CHR into subtypes based on outcome trajectories, first from the extant data and then refined and applied to the new data. The PREDICT-DPACC team has the broad, comprehensive, and robust infrastructure that is sufficiently flexible to accommodate the inclusion of multiple data types and to optimally address the needs of the CHR U01 network(s). Carefully selected extant data will be rapidly obtained, processed, and uploaded to the NIMH Data Archive (NDA). Proposed analysis methods are powerful and robust, leveraging the expertise and experience of computer scientist developers, and experienced clinical researchers. The U01 network(s) will be coordinated by a team that is experienced in managing large studies, familiar with the needs of such studies, flexible, and is knowledgeable in all aspects of CHR studies, including measures, outcomes, biomarkers, and cohorts. Upon meeting the goals of this U24, and the supported U01 network(s), the expected outcomes of the PREDICT-DPACC will be new predictive biomarkers for CHR outcomes, new definitions of CHR subtypes that are clinically useful, and new curated and comprehensive CHR datasets (extant and new) as well as processing tools and prediction algorithms that are shared with the research community through the NIMH Data Archive. NARRATIVE The “Clinical High Risk” (CHR) for psychosis syndrome in young people represents an opportune window for early intervention to prevent the onset of psychosis and other disorders, and to forestall disability; however, clinical heterogeneity and the paucity of biomarkers have hampered the development of effective intervention. To address these challenges, working with NIMH and key stakeholders, we will harmonize and aggregate existing “legacy” CHR data, and guide and coordinate the collection of new data across a network of sites, to develop biomarker algorithms that can predict individual trajectories for diverse outcomes. This proposal leverages a multidisciplinary team with broad and CHR-specific experience in large-scale multisite and multimodal studies (including clinical trials), along with expertise in data type-specific processing, coordination, analysis, and computational analyses (e.g., machine and deep learning tools from artificial intelligence, and advanced statistical approaches), ethics, community outreach, and data dissemination, all of which will ensure the success of this project.","Psychosis Risk Evaluation, Data Integration and Computational Technologies (PREDICT): Data Processing, Analysis, and Coordination Center",10256796,U24MH124629,"['Address', 'Adolescent', 'Affect', 'Algorithms', 'Anxiety Disorders', 'Artificial Intelligence', 'Attenuated', 'Behavior', 'Big Data', 'Biological Markers', 'Child', 'Clinical', 'Clinical Trials', 'Collection', 'Common Data Element', 'Communities', 'Community Outreach', 'Computer Analysis', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Disease remission', 'Early Intervention', 'Early identification', 'Enrollment', 'Ensure', 'Ethics', 'Evaluation', 'FAIR principles', 'Follow-Up Studies', 'Funding', 'Future', 'Goals', 'Heterogeneity', 'Human Resources', 'Impaired cognition', 'Individual', 'Informatics', 'Infrastructure', 'Instruction', 'Intervention', 'Lead', 'Leadership', 'Longterm Follow-up', 'Machine Learning', 'Measures', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Monitor', 'Moods', 'Motivation', 'National Institute of Mental Health', 'Online Systems', 'Outcome', 'Output', 'Perception', 'Procedures', 'Process', 'Protocols documentation', 'Psychotic Disorders', 'Quality Control', 'Recovery', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sampling', 'Scientist', 'Secure', 'Site', 'Social Functioning', 'Standardization', 'Substance Use Disorder', 'Suggestion', 'Symptoms', 'Technology', 'Thinking', 'Time', 'Training', 'Transact', 'United States', 'Validation', 'Visualization software', 'adverse outcome', 'analytical tool', 'attenuated psychosis syndrome', 'base', 'bioinformatics infrastructure', 'candidate marker', 'clinical heterogeneity', 'clinical risk', 'clinical subtypes', 'clinically relevant', 'cloud based', 'cohort', 'computerized data processing', 'data acquisition', 'data archive', 'data dictionary', 'data dissemination', 'data harmonization', 'data infrastructure', 'data integration', 'data tools', 'deep learning', 'demographics', 'design', 'disability', 'effective intervention', 'experience', 'flexibility', 'functional decline', 'functional disability', 'high risk', 'high risk population', 'improved', 'inclusion criteria', 'innovation', 'meetings', 'member', 'multidisciplinary', 'multimodal data', 'multimodality', 'multiple data types', 'outcome prediction', 'persistent symptom', 'prediction algorithm', 'predictive marker', 'predictive modeling', 'prevent', 'prospective', 'psychotic symptoms', 'quality assurance', 'recruit', 'research study', 'resilience', 'response', 'risk prediction', 'risk stratification', 'success', 'therapy development', 'tool', 'working group']",NIMH,BRIGHAM AND WOMEN'S HOSPITAL,U24,2021,3917810
"Non-target analysis of maternal and cord blood samples: Advancing computational tools and discovering novel chemicals PROJECT SUMMARY/ABSTRACT  Non-targeted analysis (NTA) provides a comprehensive approach to analyze environmental and biological samples for nearly all chemicals present. Despite the recent advancements in NTA, the number of confirmed chemicals with analytical standards remains fairly small compared to the number of detected features. There is, thus, a need to further develop computational tools to derive more chemical structures and leverage the full potential of HRMS. Enhancing our ability to derive more chemical structures will enable the discovery of new industrial chemicals that humans are exposed to, especially in critical windows of development, such as pregnancy. It will also enable the discovery of endogenously produced metabolites that may be related to biological outcomes of importance, such as preterm birth. The objective of my proposal is to develop novel computational methods to significantly advance our ability to analyze and interpret non-targeted analysis data from high-resolution mass spectrometry (HRMS) and apply them to study prenatal exposures to industrial chemicals and endogenous metabolites in a large cohort of pregnant women from Northern California. My proposal builds on my expertise in analytical and environmental chemistry and my current postdoctoral experience in computational chemistry and applications in human exposure. I seek additional training to develop and apply innovative computational methods to better characterize the human exposome and in particular the exposome of preterm birth. The contribution of my proposal will be two-fold: (1) developing novel computational structure-prediction algorithms for HRMS datasets based on MS data and physicochemical properties (equilibrium partition ratios between organic solvents and water, e.g., octanol/water, chlorobenzene/water, diethyl ether/water etc.) (Aim 1) and apply them to derive potential structures for chemical features detected in a HRMS dataset from 340 maternal and 340 matched cord blood samples to complement the limited number of chemicals identified through MS/MS and analytical standards (Aim 2); and (2) study the interplay between the exposome and the metabolome in preterm birth using molecular interaction networks to visualize and compare how molecular interactions between industrial chemicals and endogenous metabolites differ between preterm and full-term birth (Aim 3). The K99 training will expand my prior research experience through coursework, research apprenticeship, and mentored reading, with specific training in: (1) advanced analytical skills including -omics data analysis, machine learning, and biostatistics; (2) epidemiology, risk assessment, human exposure to chemical stressors; and (3) human pregnancy and development. The skills acquired during this award are critical to my long-term goal to advance computational methods to better analyze and interpret non-targeted analysis data to support efforts to better characterize the human exposome. This work will produce new scientific knowledge to greatly advance the understanding of the influence of environmental exposures in the development of adverse health outcomes and in particular, preterm birth. PROJECT NARRATIVE  Advances in high-resolution mass spectrometry (HRMS) offer unique opportunities to study the human exposome and the development of adverse health outcomes. Despite advances in non-targeted analysis, the number of confirmed chemicals remains fairly limited compared to the number of detected chemical features. The goal of this proposal is to develop novel computational methods to derive chemical structures and apply them to a large dataset of HRMS data from blood samples of pregnant women to study the influence of the exposome on pregnancy outcomes with a focus on preterm birth.",Non-target analysis of maternal and cord blood samples: Advancing computational tools and discovering novel chemicals,10191991,K99ES032892,"['Algorithms', 'Analytical Chemistry', 'Area', 'Award', 'Bile fluid', 'Binding', 'Bioinformatics', 'Biological', 'Biological Monitoring', 'Biometry', 'Birth', 'Blood specimen', 'California', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Chlorobenzene', 'Clinical Data', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Endocrine Disruptors', 'Ensure', 'Environmental Exposure', 'Epidemiology', 'Equilibrium', 'Ethyl Ether', 'Exposure to', 'Flame Retardants', 'Goals', 'Health', 'Human', 'Human Development', 'Industrialization', 'Knowledge', 'Liquid Chromatography', 'Low Birth Weight Infant', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mentors', 'Metabolic Diseases', 'Methods', 'Neurodevelopmental Disorder', 'Octanols', 'Organic solvent product', 'Outcome', 'Pathway interactions', 'Pesticides', 'Plasticizers', 'Poly-fluoroalkyl substances', 'Pregnancy', 'Pregnancy Outcome', 'Pregnant Women', 'Premature Birth', 'Property', 'Reading', 'Research', 'Resolution', 'Risk Assessment', 'Sampling', 'Science', 'Stimulus', 'Structure', 'Sum', 'Term Birth', 'Time', 'Toxicity Tests', 'Training', 'Umbilical Cord Blood', 'Water', 'Work', 'advanced analytics', 'apprenticeship', 'base', 'case control', 'cohort', 'computational chemistry', 'computer framework', 'computerized tools', 'data integration', 'developmental toxicity', 'environmental chemistry', 'experience', 'exposed human population', 'human disease', 'in silico', 'innovation', 'insight', 'large datasets', 'machine learning algorithm', 'metabolome', 'metabolomics', 'molecular mass', 'novel', 'prediction algorithm', 'prenatal', 'prenatal exposure', 'psychologic', 'reproductive toxicity', 'response', 'skills', 'small molecule libraries', 'stressor', 'success', 'time of flight mass spectrometry', 'tool']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K99,2021,99848
"Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches Project Summary  Familial hypercholesterolemia (FH) is a common genetic disorder, affecting every 200-1000 people, depending on the population and diagnostic criteria. FH leads to lifetime raised low-density lipoprotein (LDL) cholesterol, a high risk for premature atherosclerosis and downstream coronary heart disease. FH is designated as Tier 1 disease by the Center for Disease Control and Prevention, notably one of only three such diseases, because it is common, is associated with a high risk of premature illness, and is treatable with lifestyle or medications. Great uncertainty exists about the optimal approach to FH screening, which is reflected in conflicting recommendations in national screening guidelines.  We propose to synthesize high quality data from national surveys and population-based cohort studies in a health policy computer simulation model comparing the health and economic value of different FH screening strategies. This study will prioritize the optimal approaches to FH screening in the U.S. population, identifying optimal initial screening age and defining the role of genetic testing in screening.  We have assembled a team of experts in pediatric preventive cardiology, decision analysis, cardiovascular disease epidemiology, population genetics, biostatistics, health economic evaluation, and computer simulation modeling in order to evaluate and compare different FH screening strategies in children and adults. We aim to use this expertise and these methods in order to:   Quantify diagnostic yield, clinical effectiveness, and economic value of universal FH phenotype  screening in childhood or adulthood, and the added value of FH genotype screening   Compare universal FH screening to the alternatives of using family history or a Big Data-based  algorithm to direct targeted screening limited to children and adults with possible FH diagnosis   Quantify the health and economic value of cascade screening families of FH cases  We hypothesize that FH screening in childhood will be the highest value screening strategy in the U.S. population, and that genetic testing will improve diagnosis and treatment decisions most in cases of diagnostic uncertainty (e.g., borderline high cholesterol or absent family history). We hypothesize that a machine-learning algorithm will avoid the costs and complexity of universal screening, while yielding a similar case yield, as long as cholesterol testing is sufficiently common in children.  This study will identify the optimal approach to FH screening in the U.S. population and the most influential data based on current knowledge and set the stage for efficiently designed clinical trials of FH screening. This study will be a test case for the concept of a “precision” population health approach to screening for genetically-determined diseases in the general population. Familial hypercholesterolemia (FH) is a common genetic disorder characterized by lifetime elevated cholesterol, which, if uncontrolled, is associated with premature atherosclerotic cardiovascular disease. Conflicting current national guidelines highlight that the optimal approach to FH screening in the U.S. population is controversial: it is unclear if screening should start in childhood or adulthood, or if it should include genetic testing. We propose to synthesize data from national surveys, high quality cohort studies, and clinical trials of cholesterol lowering interventions in a lifetime cardiovascular disease risk computer simulation model to project the life time health impact of different FH screening approaches and identify optimal screening strategies in children and adults.","Familial hypercholesterolemia screening in children: population impact of phenotype, genotype, and cascade approaches",10152666,R01HL141823,"['Adult', 'Adverse effects', 'Advisory Committees', 'Affect', 'Age', 'Algorithms', 'Atherosclerosis', 'Big Data', 'Biometry', 'Cardiology', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Cholesterol', 'Clinical Trials', 'Clinical Trials Design', 'Clinical effectiveness', 'Cohort Studies', 'Computer Simulation', 'Conflict (Psychology)', 'Coronary heart disease', 'County', 'Data', 'Decision Analysis', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Event', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Future', 'General Population', 'Genetic Diseases', 'Genetic Screening', 'Genotype', 'Guidelines', 'Health', 'Health Benefit', 'Health Policy', 'Hepatocyte', 'Influentials', 'Intervention', 'Knowledge', 'LDL Cholesterol Lipoproteins', 'Laboratories', 'Life', 'Life Style', 'Low Prevalence', 'Low-Density Lipoproteins', 'Medical Care Costs', 'Methods', 'Mutation', 'Parents', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Population Genetics', 'Prevalence', 'Preventive', 'Preventive service', 'Preventive treatment', 'Proxy', 'Puberty', 'Public Health', 'Randomized Controlled Trials', 'Recommendation', 'Recording of previous events', 'Role', 'Serum', 'Surveys', 'Testing', 'Time', 'Uncertainty', 'Visit', 'Youth', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'clinical practice', 'cost', 'cost effective', 'cost effectiveness', 'diagnostic accuracy', 'economic evaluation', 'economic value', 'genetic testing', 'health economics', 'high risk', 'improved', 'improved outcome', 'lifestyle intervention', 'machine learning algorithm', 'machine learning method', 'models and simulation', 'pediatric patients', 'population based', 'population health', 'premature', 'premature atherosclerosis', 'prevent', 'screening', 'screening guidelines', 'screening program', 'treatment strategy', 'uptake']",NHLBI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,788885
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10204992,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'lateral flow assay', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2021,295514
"Clinical significance and genetic determinants of novel imaging measures of emphysema distribution in 9,743 smokers PROJECT SUMMARY/ABSTRACT Candidate: Dr. Adel El Boueiz is a pulmonary and critical care physician-scientist completing a period of T32- funded support at the Channing Division of Network Medicine (CDNM) and Harvard Medical School (HMS). He received a Master's of Medical Science in Biomedical Informatics from HMS in May 2016. He will be promoted to Instructor of Medicine at the CDNM and HMS on July 1, 2017. His principal research interests are the genetic epidemiology of chronic obstructive pulmonary disease (COPD) and the translation of genomic discoveries into clinical practice and public health. His long-term goal is to be an independent investigator with expertise in imaging phenotyping, genomics, and predictive analytics of the regional heterogeneity of the various aspects of COPD (emphysema, airway disease, and pulmonary vascular remodeling). Environment: Dr. El Boueiz will continue to pursue his research and career development in the rich and multidisciplinary environment of the CDNM and the Brigham and Women's Hospital Applied Chest Imaging Lab (ACIL). He will be mentored by Drs. Edwin K. Silverman, Peter J. Castaldi, and Raúl San José Estépar, leaders in the field of COPD quantitative imaging, genetic epidemiology, and predictive analytics with excellent track records of mentoring young investigators towards independent research careers. His career development will also be overseen by an advisory committee with expertise related to key areas of his proposal. Research: COPD is a major cause of morbidity and mortality that is of increasing public health importance. COPD is a heterogeneous disease and this heterogeneity complicates the identification of the predictors of disease progression and consequently, the development of effective therapies. Emphysema distribution is an important COPD-related phenotype that emerged as a strong predictor of the response to lung volume reduction procedures. Despite the availability of advanced texture-based CT quantification methods, global threshold-based quantitative metrics have to date been the cornerstone for the radiological characterization of emphysema distribution with inability to differentiate centrilobular, panlobular, and paraseptal emphysema patterns. In this project, we will apply a texture-based CT quantification method to discover novel imaging biomarkers of the regional heterogeneity of centrilobular, panlobular, and paraseptal emphysema in a large cohort of well-characterized smokers and identify their genetic determinants using whole genome sequencing and integrative genomics analyses. The results will be considered for inclusion along with other rich phenotypic and imaging data in COPD disease progression machine learning predictive models. Relevance: Through improved radiographic phenotyping of emphysema distribution, better understanding of disease pathobiology, and more accurate prediction of disease progression, the proposed work will open new avenues of investigation for the development of personalized and improved COPD therapeutic strategies. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is a common disease that affects up to 24 million people in the United States, is associated with considerable and increasing morbidity and mortality, and for which there is no available disease-modifying therapy. COPD is associated with significant variation in radiographic, symptomatic and physiologic presentation and exhibits variability in progression. Currently, there is no satisfactory method for progression prediction. This project will identify novel imaging biomarkers of the regional distribution of centrilobular, panlobular, and paraseptal emphysema with particular emphasis on their associations with clinical relevant COPD-related outcomes, their genetic determinants, and their ability to improve prediction of COPD disease progression, above and beyond that provided by the traditional clinical, radiographic, and genetic features. This is an important area of research as predicting those patients who will remain stable from those who will have rapid disease progression is critical in defining prognosis and selecting patients for specific therapeutic interventions.","Clinical significance and genetic determinants of novel imaging measures of emphysema distribution in 9,743 smokers",10208938,K08HL141601,"['ACVR1B gene', 'Accounting', 'Advisory Committees', 'Affect', 'Airway Disease', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological Process', 'Chest', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Clinical/Radiologic', 'Cohort Studies', 'Collection', 'Complex', 'Computing Methodologies', 'Critical Care', 'Data', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Disease', 'Disease Progression', 'Dyspnea', 'Environment', 'Evaluation', 'Exhibits', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Polymorphism', 'Genomic approach', 'Genomics', 'Goals', 'Heterogeneity', 'Hospitals', 'Image', 'Investigation', 'Lobar', 'Lobe', 'Lung', 'Lung Volume Reductions', 'Lung diseases', 'Machine Learning', 'Measures', 'Medical', 'Medical Genetics', 'Medical Research', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Outcome', 'Pathologic', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Physiological', 'Positioning Attribute', 'Predictive Analytics', 'Procedures', 'Public Health', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quantitative Trait Loci', 'Radiology Specialty', 'Records', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Smoker', 'Structure of parenchyma of lung', 'Subgroup', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Intervention', 'Tissues', 'Translations', 'United States', 'Variant', 'Vascular remodeling', 'Visual', 'Walking', 'Woman', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'biomedical informatics', 'career', 'career development', 'clinical practice', 'clinically relevant', 'clinically significant', 'cohort', 'comorbidity', 'data mining', 'disease heterogeneity', 'disease phenotype', 'disorder risk', 'disorder subtype', 'effective therapy', 'genetic architecture', 'genetic association', 'genetic epidemiology', 'genetic predictors', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic predictors', 'imaging biomarker', 'imaging genetics', 'improved', 'instructor', 'interest', 'machine learning method', 'medical schools', 'mortality', 'multidisciplinary', 'novel', 'outcome forecast', 'personalized care', 'predicting response', 'predictive modeling', 'prognostic', 'pulmonary function', 'quantitative imaging', 'rare variant', 'research and development', 'respiratory', 'whole genome']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,170639
"Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale Project Summary This project aims to leverage the best of both computational and human expertise in neuronal reconstruction towards the goal of accelerating global neuroscience discovery from internationally-sourced imaging data. We propose to create a cloud-based unified platform for converging 3-dimensional images of neurons onto a single analysis platform to (1) train and grow a new expert community of global reconstructors to work across the data from these groups, to (2) generate a community-sourced neuronal reconstruction database of open imaging data that can be incorporated into a 3-dimensional map of neuronal interconnectivity - onto which (3) novel annotations and more complex functional and molecular data can be overlaid. Our approach will evolve with the growing needs of the neuroscience community over time. To do this, in Aim One (Neuronal Reconstruction at Scale), we will test if the newly developed crowd-sourced game-based platform Mozak can develop a collective of new human experts at scale, capable of accelerating the rate of current reconstruction by at least an order of magnitude, at the same time as increasing the robustness, quality and unbiasedness of the final reconstructions. In Aim Two (Robust Multi-Purpose Annotation), we will enhance basic neuronal reconstruction by adding specific semantic annotation— including soma volume and morphological quantification, volumetric analysis, and ongoing features (e.g. dendritic spines, axonal varicosities) requested from the neuroscience community. Experienced and high-ranking members will be given the opportunity to advance through increasingly complex neurons into full arbor brain-wide neuronal projections and multiple clustered groups of neurons in localized circuits. Finally, in Aim 3 (Creation of a Research-Adaptive Data Repository), we aim to develop a database of neuronal images reconstructed using the Mozak interface that will directly serve the general and specific needs of different research groups. Our goal is to make this database dynamically adaptive — as new research questions will invariably bring new needs for additional annotations and cross-referencing with other data modalities. This highquality unbiased processing repository will also be perfectly suited for training sets for automated algorithms, and the generation of a 3-dimensional maps such as Allen Institute for Brain Science (AIBS) common coordinate framework. We expect that the computational reconstruction methods will further improve with the new large corpus of “gold standard” reconstructions. Collectively, the completion of these three aims will create an analysis suite as well as an online community of experts capable of performing in depth analysis of large-scale datasets that will significantly accelerate neuroscience research, enhance machine learning for reconstruction analysis, and create a common platform of baseline neuronal morphology data against which aberrantly functioning neurons can be analyzed. Project Narrative  This project will create a new central nexus point for neuronal reconstruction and semantic annotation (Mozak) that can be used by all research labs via an accessible online portal. We will develop a new cadre of neuronal reconstruction experts that will— in conjunction with automated tools that are enhanced by their work — drastically increase the volume, quality and robustness of neuron reconstructions and annotations. Mozak reconstructions will be shared with existing repositories and will be continually updated and re-annotated based on emerging needs of research - ensuring perpetual relevance, and allowing us to generate a platform to establish the range of “baseline” 3-dimensional readouts of neuronal morphology against which diseased or malfunctioning neurons can be analyzed and understood. 1",Mozak: Creating an Expert Community to accelerate neuronal reconstruction at scale,10204729,R01MH116247,"['3-Dimensional', 'Adopted', 'Algorithms', 'Area', 'Axon', 'Brain', 'Characteristics', 'Classification', 'Communities', 'Complex', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Dendritic Spines', 'Disease', 'Ensure', 'Future', 'Gap Junctions', 'Generations', 'Goals', 'Gold', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Molecular', 'Morphology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Output', 'Process', 'Research', 'Science', 'Semantics', 'Slice', 'Source', 'Standardization', 'Structure', 'Techniques', 'Testing', 'Three-dimensional analysis', 'Time', 'Training', 'Update', 'Variant', 'Varicosity', 'Work', 'automated algorithm', 'base', 'citizen science', 'cloud based', 'crowdsourcing', 'data repository', 'experience', 'improved', 'large scale data', 'member', 'neuronal cell body', 'novel', 'online community', 'petabyte', 'programs', 'reconstruction', 'repository', 'tool', 'two-dimensional', 'web portal']",NIMH,UNIVERSITY OF WASHINGTON,R01,2021,639861
"Coordinating Research on Emerging Arboviral Threats Encoing the Neotropics (CREATE-NEO) Project Summary In recent decades, Central and South America have experienced spillover of endemic arthropod-borne viruses (arboviruses) from wildlife reservoirs into humans, exchange and recombination of emerging arboviruses within the region, resurgence of arboviruses previously controlled by vaccination or vector control, introduction and spread of novel arboviruses, and exportation of viruses to other regions. Furthermore, there is great concern that newly-introduced Zika virus may spill back into an enzootic transmission cycle in the Americas. Central and South America encompass enormous vertebrate and invertebrate biodiversity, and these species harbor a broad range of arboviruses whose risk of spillover and spread in humans is presently unknown. Increases in the rates of global travel, invasion of novel vector species, urban expansion, deforestation, and global climate change all elevate the risk of further arbovirus emergence, as does the breakdown of public health structures in Venezuela.  The Coordinating Research on Emerging Arboviral Threats Encompassing the Neotropics (CREATE- NEO) project will provide a network of surveillance sites in the neotropics coupled to cutting-edge modeling approaches in order to anticipate and counter emerging arboviruses. Aim 1 will identify novel and known arboviruses as well as the host-vector networks that sustain transmission of these viruses within the neotropics, map the spatial distribution of these transmission networks, and characterize virus transmission dynamics within these networks. To do so, we will collect mosquitoes and other vectors as well as non-human primates and other vertebrate hosts at multiple sites in areas of high and varied biodiversity in Panama and Brazil and screen these samples for known and novel arboviruses. These data will then be analyzed using niche modeling, machine learning to predict undiscovered hosts and vectors, and dynamical transmission models. Aim 2 will focus on prospective and retrospective analysis of human infection and disease. To do so, we will leverage ongoing human clinical cohorts at multiple sites in Brazil and Panama. We will extend and expand these cohorts, with a particular focus on the immune-mediated interactions among multiple arboviruses at sites of hyperendemicity. We will also develop novel diagnostics to capture known and novel arboviruses and model the impact of human and non-human primate movement on spillover and spillback of target arboviruses.  Data and models generated via these two aims will forewarn local, regional and global public health agencies of arboviruses within Central and South America that pose particularly high risk of spillover, emergence into transmission among humans, and/or international spread. Moreover CREATE-NEO will build local capacity to predict, detect and respond to emerging arboviruses at their point of origin, thereby maximizing the potential to avert full-blown emergence. Project Narrative Arthropod-borne viruses, such as dengue, Zika and Mayaro, are emerging at an accelerating rate in Central and South America. The Coordinating Research on Emerging Arboviral Threats Encompassing the Neotropics (CREATE-NEO) project will provide a nimble and flexible network of surveillance sites in Central and South America coupled to cutting-edge modeling approaches in order to anticipate and counter these threats to public health.",Coordinating Research on Emerging Arboviral Threats Encoing the Neotropics (CREATE-NEO),10170251,U01AI151807,"['Acute', 'Address', 'Age', 'Americas', 'Animals', 'Arbovirus Infections', 'Arboviruses', 'Area', 'Back', 'Biodiversity', 'Biological', 'Blood Circulation', 'Brazil', 'Central America', 'Chikungunya virus', 'Cities', 'Clinical', 'Cohort Studies', 'Collection', 'Coupled', 'Culicidae', 'Data', 'Deforestation', 'Dengue', 'Detection', 'Disease', 'Emergency Situation', 'Enzyme-Linked Immunosorbent Assay', 'Frequencies', 'Genetic Recombination', 'Genetic Variation', 'Habitats', 'Human', 'Immune', 'Infection', 'International', 'Invertebrates', 'Machine Learning', 'Malaria', 'Maps', 'Measles', 'Mediating', 'Modeling', 'Movement', 'Panama', 'Public Health', 'Research', 'Risk', 'Route', 'Sampling', 'Site', 'South America', 'Spatial Distribution', 'Structure', 'Testing', 'Time', 'Travel', 'Vaccination', 'Vector-transmitted infectious disease', 'Venezuela', 'Virus', 'West Nile virus', 'Yellow Fever', 'ZIKA', 'Zika Virus', 'Zoonoses', 'chikungunya', 'climate change', 'cohort', 'design', 'diagnostic technologies', 'enzootic', 'experience', 'flexibility', 'high risk', 'insight', 'nanobodies', 'nonhuman primate', 'novel', 'novel diagnostics', 'pathogen', 'prospective', 'seroconversion', 'surveillance network', 'transmission process', 'vector', 'vector control', 'viral transmission']",NIAID,UNIVERSITY OF TEXAS MED BR GALVESTON,U01,2021,1519214
"Evidence to improve heat warning effectiveness in reducing morbidity and mortality. Project Summary/Abstract  While exposure to high ambient temperature (i.e., heat) has long been recognized as a threat to public health, the burden of illness and death attributable to heat in the US remains high. In an effort to reduce heat- related mortality and morbidity, the US National Weather Service (NWS) issues heat alerts in advance of forecasted extreme heat events to communicate these risks to the public and government officials. However, it is largely unknown: (1) what are the optimal metrics of heat stress to inform when to issue heat alerts, (2) how effective are heat alerts in protecting the public’s health and (3) what factors make heat alerts comparatively more or less effective in some places or in some people versus others. In the absence of such information, we will fail to maximize the public health benefits of heat alerts.  The goals of this proposal are to identify the optimal health-based and location-specific metrics for issuing heat alerts, to estimate the causal benefits of heat alerts, and to identify characteristics of individuals or communities associated with the greatest reductions in morbidity or mortality following heat alerts. Specifically, using national claims data on deaths and hospital admissions among the large, geographically diverse population of >60 million US Medicare beneficiaries age ≥65 years enrolled between 2001 and 2015, and on emergency department visits among >130 million participants of all ages from one of the nation’s largest health insurers, we propose to: (Aim 1) Use novel machine learning methods to identify the heat metric(s) (e.g., heat index, ambient temperature, spatial synoptic classification, wet bulb globe temperature, absolute humidity) that best predict excess heat-related deaths, emergency hospitalizations, and emergency departments visits in each location, (Aim 2) estimate the causal effects of NWS heat alerts on rates of mortality, hospitalizations, and emergency department visits across the country and within groups stratified by health outcome, sex, and age group, and (Aim 3) assess how the benefits of heat alerts vary across characteristics of communities.  Key innovations of this proposal include a very large sample size, geographic diversity encompassing the entire US, the assessment across multiple health endpoints and age groups, and the use of sophisticated methods in statistical learning and causal inference. Collectively, the findings from this proposal will provide meteorologists, public health and emergency management officials, and local policy-makers with critical information to better protect public health during extreme heat events and guide more targeted future research on strategies to mitigate the adverse health effects of heat. Project Narrative Extreme heat is recognized as an important threat to public health, and the burden of illness and death attributable to heat in the US remains high. In an effort to reduce heat-related mortality and morbidity, the US National Weather Service (NWS) issues heat alerts in advance of forecast extreme heat events to communicate these risks to the public and local government officials, although it remains largely unknown whether such alerts are effective in protecting people. We propose to provide forecasters and public health officials across the country with location-specific, health-based evidence as to the effectiveness of heat alerts and insights into how to improve them to better protect the public’s health.",Evidence to improve heat warning effectiveness in reducing morbidity and mortality.,10051418,R01ES029950,"['Age', 'Air Conditioning', 'Cessation of life', 'Characteristics', 'Classification', 'Communities', 'Country', 'Data', 'Effectiveness', 'Emergency Situation', 'Emergency department visit', 'Enrollment', 'Ethnic Origin', 'Event', 'Exposure to', 'Geography', 'Goals', 'Government Agencies', 'Government Officials', 'Health', 'Health Benefit', 'Heat Stress Disorders', 'Hospitalization', 'Humidity', 'Individual', 'Insurance Carriers', 'Knowledge', 'Local Government', 'Location', 'Medicare', 'Methods', 'Morbidity - disease rate', 'Outcome', 'Participant', 'Policy Maker', 'Population Heterogeneity', 'Predisposition', 'Prevalence', 'Public Health', 'Race', 'Research Personnel', 'Risk', 'Sample Size', 'Seasons', 'Services', 'Socioeconomic Status', 'Structure', 'Temperature', 'United States', 'Weather', 'age group', 'attributable mortality', 'base', 'beneficiary', 'burden of illness', 'comparative', 'evidence base', 'extreme heat', 'human old age (65+)', 'improved', 'indexing', 'innovation', 'insight', 'learning strategy', 'machine learning method', 'mortality', 'mortality risk', 'novel', 'prevent', 'public health emergency', 'response', 'sex', 'statistical learning']",NIEHS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2021,627397
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,10135813,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device', 'wearable sensor technology']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,298890
"Tracking the dynamics of how schemas scaffold recall Project Summary Every new experience in our life takes place within the context of familiar environments and situations. However, most research on memory has focused on the artificial memorization of word lists, symbols or pictures; these studies do not meaningfully address how structured prior knowledge about the world (e.g., in the form of a familiar spatial map, or knowledge of how restaurant meals unfold over time) can scaffold new learning. In the proposed studies, I aim to precisely characterize how and where prior knowledge and new information are represented, how they get linked at encoding, and how they interact at recall to allow memories to be retrieved. In the first proposed study of my F99 phase, I test the hypothesis that hippocampal engagement at event boundaries during learning binds new information (i.e. objects) to the scaffold of existing knowledge (i.e. knowledge of a familiar location), and that hippocampal activation during recall mediates the successful retrieval of the bound object from the location in which it was stored. I also test the hypothesis that distinctive representations of spatial locations in the brain will reduce interference between objects stored in those locations. There is a potential downside to using prior knowledge as a scaffold: When there is too much information attached to one part of the scaffold, old and new memories will interfere with each other. How, then, could someone prioritize the retrieval of new memories over older (now-irrelevant) memories that were linked to the scaffold? Recent research on intentional forgetting suggests a solution to this limitation. Specifically, in my second proposed study, I test the hypothesis (supported by neurophysiological evidence, prior neuroimaging results, and computational models) that previously encoded memories can be weakened by moderately activating their neural representation, thereby “cleaning” the scaffold and reducing interference. In the K00 phase, I will extend my research to identify pathologies in how clinical populations use prior knowledge to interpret and remember their experiences, using tools from computational psychiatry; I also plan to design new technological tools to address these issues. Overall, the proposed project makes use of naturalistic and ecologically valid stimuli (in the form of continuous stimuli and immersive virtual reality) paired with advanced machine learning tools applied to brain imaging data, to study the fundamental nature of how new and old information are linked to allow learning. In the long-term, the findings from this project regarding how prior knowledge can be optimally leveraged to support new learning will lead to the development of tools to help memory-impaired individuals make better use of prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly. Project Narrative In my dissertation, I will use newly-developed machine learning techniques to study how the brain uses prior knowledge (about the spatial structure of an environment, or how certain types of events unfold in time) to scaffold new learning. By precisely characterizing how this scaffolding process works, my research will help to identify ways in which prior knowledge can be more optimally leveraged to support learning. This will lead to the development of tools to help memory-impaired individuals make better use of intact prior knowledge to support new learning, as well as remedies for groups where deficiencies in prior knowledge prevent them from learning properly.",Tracking the dynamics of how schemas scaffold recall,10156352,F99NS120644,"['Address', 'Behavioral', 'Binding', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Cognitive', 'Computer Models', 'Cues', 'Data', 'Doctor of Philosophy', 'Environment', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'General Population', 'Goals', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Institution', 'Knowledge', 'Lead', 'Learning', 'Life', 'Link', 'Literature', 'Location', 'Machine Learning', 'Maps', 'Mediating', 'Memory', 'Memory impairment', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Participant', 'Pathology', 'Perception', 'Performance', 'Phase', 'Play', 'Population', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Psyche structure', 'Psychiatry', 'Research', 'Research Project Grants', 'Restaurants', 'Retrieval', 'Scanning', 'Scientist', 'Self-Help Devices', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'Work', 'computerized tools', 'design', 'experience', 'field study', 'forgetting', 'memory encoding', 'memory retrieval', 'neuroimaging', 'neurophysiology', 'phase 1 testing', 'prevent', 'relating to nervous system', 'scaffold', 'skills', 'statistics', 'tool', 'tool development', 'virtual', 'virtual reality', 'virtual reality environment', 'virtual world']",NINDS,PRINCETON UNIVERSITY,F99,2021,47036
"Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health) PROJECT SUMMARY  To expand the kidney-related biomedical workforce and counter the increasing disparity between the growing prevalence of renal disease and the disproportionate level of trainees, researchers and practitioners in nephrology and kidney health, we developed the Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health). ADVANCE Kidney Health is an education- based, hands-on research, education and clinical experience that applies pillars of 1) science, medical and engineering education; 2) training in innovation, entrepreneurialism and scientific translation; 3) experiential learning, mentorship and clinical immersion; and 4) needs-based application and practical translation – all aimed at producing motivated, trained and committed biomedical trainees interested in renal health and science to advance the workforce and develop the new health-related therapies of the future. The program recruits undergraduate students from across 15 departments within the College of Engineering at the University of Arizona (UArizona) that include: Biomedical Engineering, Electrical and Computer Engineering, Mechanical Engineering and Chemical Engineering. ADVANCE Kidney Health is structured to provide trainees a medical school experience for early-stage undergraduate learners geared to instill an understanding of renal anatomy and kidney function. The core structure accesses a clinical experience to instill a motivation to pursue kidney- related patient care and/or translational research and progresses to an already established innovation bootcamp that culminates in an interdisciplinary capstone that has doubled in size over 10 years and accesses by more than 450 captive engineering students. The program leverages new infrastructure in medical and engineering education along with transdisciplinary programs aimed at innovation, technology development and entrepreneurialism with 15 physician navigators in kidney health and 23 engineering and scientific mentors spanning renal physiology, biomedical engineering, optical sciences and machine learning. The result is an interrelated program that bridges renal medicine, engineering and product development to develop new pipelines and on-ramps to impact career decisions and grow the future kidney-related workforce. PROJECT NARRATIVE  The prevalence of end-stage renal failure (ESRD) has increased ~40% over 20 years, but the kidney-related biomedical workforce has been unable to keep pace. New pathways to a career in nephrology and kidney-related medicine and research are vitally needed that combine early and frequent experiential opportunities to engage in patient-oriented kidney care and contribute to innovative technologies that will one-day change how renal dysfunction is diagnosed and treated. ADVANCE Kidney Health responds to this need by assembling diverse mentors, interdisciplinary infrastructure and novel engineering technologies to impact career trajectories and develop the new technological cures of tomorrow.",Arizona Technology Development and Clinical Education Program for Students in Kidney Health (ADVANCE Kidney Health),10230895,R25DK128859,"['Active Learning', 'Acute Renal Failure with Renal Papillary Necrosis', 'Address', 'Anatomy', 'Arizona', 'Biomedical Engineering', 'Businesses', 'COVID-19', 'Career Mobility', 'Caring', 'Chemical Engineering', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Computers', 'Coupled', 'Critical Thinking', 'Diabetes Mellitus', 'Diagnosis', 'Dialysis procedure', 'Disease', 'Education', 'Elderly', 'Elements', 'End stage renal failure', 'Engineering', 'Faculty', 'Future', 'Generations', 'Growth', 'Health', 'Health Sciences', 'Health Technology', 'Hypertension', 'Immersion', 'Infrastructure', 'Internal Medicine', 'Internships', 'Kidney', 'Kidney Diseases', 'Laws', 'Legal patent', 'Machine Learning', 'Mechanics', 'Medical', 'Medicine', 'Mentors', 'Mentorship', 'Motivation', 'Nephrology', 'Optics', 'Pathway interactions', 'Patient Care', 'Patients', 'Physicians', 'Physiology', 'Population', 'Prevalence', 'Problem Solving', 'Ramp', 'Renal function', 'Research', 'Research Personnel', 'Running', 'Schools', 'Science', 'Scientist', 'Seeds', 'Solid', 'Stimulus', 'Structure', 'Students', 'Technology', 'Technology Transfer', 'Thinking', 'Time', 'Touch sensation', 'Training', 'Translational Research', 'Translations', 'United States', 'Universities', 'base', 'bridge program', 'cancer therapy', 'career', 'career development', 'career preparation', 'cohort', 'college', 'design', 'early experience', 'education research', 'experience', 'fascinate', 'graduate student', 'hands on research', 'innovation', 'innovative technologies', 'interest', 'kidney dysfunction', 'medical schools', 'new technology', 'novel', 'patient oriented', 'product development', 'programs', 'recruit', 'response', 'skills', 'summer research', 'technology development', 'undergraduate education', 'undergraduate student']",NIDDK,UNIVERSITY OF ARIZONA,R25,2021,140400
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,10197938,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process', 'vaccine hesitancy']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,321062
"SMART NANPs: new molecular platform for communication with human immune system and modulation of therapeutic responses Principal Investigator/Program Director (Last, First, Middle): Afonin, Kirill, A  PROJECT SUMMARY  What if healthcare providers were equipped with biocompatible, biodegradable, robust, and affordable treatment options that combine therapeutic modalities with controlled mechanisms of action? What if this versatile technology had learning capacity and could be educated to recognize patient-specific diseases and interfere with their progression by redirecting fundamental cellular processes? What if the very same formulation could offer an additional means of control over patients’ immune responses and further advance favorable therapeutic outcomes with minimal toxicities? These next generation therapies would then become a game changer in helping to prevent, detect, diagnose, and treat diseases and disabilities at their source. With the support from MIRA (R35) funding, we envision a data-driven platform, SMART NANPs (specific, modular, adjustable, reproducible, and targeted nucleic acid nanoparticles), encoded by self-assembling nucleic acids. By controlling the flow of genetic information across all forms of life, nucleic acids have become instrumental in acquiring new knowledge about major cellular processes and origins of diseases. Besides their diverse biological roles, these biopolymers can be programmed into NANPs with specified physicochemical properties and functionalities that dictate NANPs’ biological actions with endless possibilities for reprogramming cellular behavior through molecular signaling. We recently discovered that different architectural parameters and compositions of NANPs, delivered to primary human immune cells, can activate monocytes and dendritic cells to produce type I and type III interferons. This pioneering work on NANPs’ immunorecognition highlighted an unforeseen clinical application for this technology in the field of vaccines and immunotherapy. A defined structure-function relationship for any given NANP would then allow conditional actuation of its immunorecognition or any other therapeutic activity through a set of embedded architectural codes. With this notion, we introduced two orthogonal concepts of therapeutic NANPs which can be conditionally activated in human cancer cells to release pre-programmed therapeutics. By uniting these breakthroughs and other preliminary findings from my lab, as highlighted in the current application, and integrating them into a unified network of SMART NANPs with programmable control of biodistribution, immunological activity, and therapeutic modules, we will advance the current repertoire of therapies against infectious diseases and cancers (through NANP-based vaccines and immunotherapies), cardiovascular diseases (through regulated coagulation by thrombin-targeting NANPs), and address drug overdose and safety issues (through the biodegradable nature of NANPs and their controlled deactivation). To maximize the successful translation of this technology, the proposed program will employ a multidisciplinary approach that spans the fields of nucleic acid nanotechnology, immunology, drug delivery, translational oncology, and machine learning. The long-term goal of this program is to elevate SMART NANPs to the level of clinical use. Principal Investigator/Program Director (Last, First, Middle): Afonin, Kirill, A PROJECT NARRATIVE  Beyond their traditionally known roles as carriers and regulators of genetic information, nucleic acids have auspiciously emerged as versatile therapies for taking advantage of cellular pathways to drive the sensing, targeting, and silencing of a variety of diseases. With MIRA support, we will explore additional nanotechnology- based therapeutic options that enlist a biocompatible nucleic acid-encoded platform (SMART NANPs) for the controlled immunostimulation and modulation of therapeutic responses. This research program aims to advance the envisioned technology towards personalized medicine and aid in addressing top public health challenges in the U.S. as they relate to cancer (through vaccines and immunotherapies), cardiovascular diseases (through regulated coagulation), and drug overdose and safety (through the biodegradable nature of the platform and its functional regulation).",SMART NANPs: new molecular platform for communication with human immune system and modulation of therapeutic responses,10086567,R35GM139587,"['Address', 'Architecture', 'Biodistribution', 'Biological', 'Biopolymers', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Clinical', 'Coagulation Process', 'Code', 'Communicable Diseases', 'Communication', 'Data', 'Dendritic Cells', 'Diagnosis', 'Disease', 'Drug Delivery Systems', 'Formulation', 'Funding', 'Goals', 'Health Personnel', 'Human', 'Immune', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Immunotherapy', 'Interferons', 'Knowledge', 'Learning', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Modality', 'Molecular', 'Nanotechnology', 'Nature', 'Nucleic Acids', 'Oncology', 'Overdose', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Principal Investigator', 'Property', 'Public Health', 'Regulation', 'Reproducibility', 'Research', 'Role', 'Safety', 'Signal Transduction', 'Source', 'Specific qualifier value', 'Structure-Activity Relationship', 'Technology', 'Therapeutic', 'Thrombin', 'Toxic effect', 'Translations', 'Vaccines', 'Work', 'base', 'biomaterial compatibility', 'cancer cell', 'cell behavior', 'clinical application', 'disability', 'genetic information', 'immunoregulation', 'interdisciplinary approach', 'monocyte', 'nanoparticle', 'next generation', 'personalized medicine', 'prevent', 'programs', 'therapy outcome', 'treatment response']",NIGMS,UNIVERSITY OF NORTH CAROLINA CHARLOTTE,R35,2021,141556
"Diagnostic and prognostic biomarkers for subtypes of addiction-related circuit dysfunction Project Summary Substance use disorders (SUDs) are increasing in prevalence and are already a leading cause of disability, due in part to the fact that our understanding of the underlying pathophysiology is incomplete. Like most neuropsychiatric syndromes, SUDs are highly heterogeneous, and distinct mechanisms may be operative in some individuals but not in others, even within a single diagnostic category. Furthermore, SUDs frequently co- occur with depression, anxiety, and other psychiatric syndromes, complicating efforts to identify molecular and circuit-level mechanisms, and disentangle them from those involved in mood and anxiety disorders. Diagnostic heterogeneity is thus a fundamental obstacle to developing better treatments, identifying biomarkers for quantifying risk for different forms of addiction, and predicting treatment response and relapse. Recently, we developed and validated an approach to discovering and diagnosing subtypes of depression using fMRI measures of functional connectivity, which in turn predicted subtype-specific clinical symptom profiles and treatment outcomes. Here, in response to PAR-18-062, we propose a secondary data analysis that would extend this approach to SUDs, leveraging multiple deeply characterized and large-scale neuroimaging datasets. Our central hypothesis is that individual differences in mechanisms underlying impairments in response inhibition and salience attribution (iRISA) are mediated by distinct forms of dysfunctional connectivity in addiction-related circuits, which in turn interact and give rise to distinct neurophysiological addiction subtypes. In Aim 1, we will use statistical clustering and machine learning methods to delineate these subtypes and optimize classifiers (fMRI biomarkers) for diagnosing them in individual patients, focusing initially on cocaine addiction. In Aim 2, we will validate these subtype-specific biomarkers by first replicating them in a new dataset and then evaluating their longitudinal stability and predictive utility. In Aim 3, we will test whether subtype-specific circuit mechanisms generalize to mediate iRISA functions in other forms of addiction, and define their interactions with distinct mechanisms mediating anhedonia and anxious arousal in patients with comorbid depression and anxiety. Project Narrative Biomarkers have transformed how physicians care for patients with cancer, cardiovascular disease, and a host of other medical conditions by providing quantitative tools for diagnosing disease processes and individualizing treatment decisions. In contrast, biomarkers for addictions remain relatively elusive. This project will test a new strategy for developing neuroimaging (brain scan) biomarkers for diagnosing novel subtypes of addiction in individual patients and then investigate how dysfunction in specific circuits gives rise to specific addiction- related behaviors and clinical symptoms.",Diagnostic and prognostic biomarkers for subtypes of addiction-related circuit dysfunction,10177987,R01DA047851,"['Abstinence', 'Amygdaloid structure', 'Anhedonia', 'Animal Model', 'Anterior', 'Anxiety', 'Anxiety Disorders', 'Arousal', 'Behavior', 'Biological Markers', 'Brain', 'Brain scan', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Cocaine', 'Cocaine Dependence', 'Cognition', 'Cognitive', 'Communities', 'Corpus striatum structure', 'Data Analyses', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Dorsal', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Habits', 'Heterogeneity', 'Impairment', 'Individual', 'Individual Differences', 'Lateral', 'Lead', 'Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medial', 'Mediating', 'Medical', 'Mental Depression', 'Molecular', 'Mood Disorders', 'Motivation', 'Negative Reinforcements', 'Neurobiology', 'Nicotine', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacology', 'Physicians', 'Prediction of Response to Therapy', 'Prevalence', 'Process', 'Prognostic Marker', 'Psychiatric Diagnosis', 'Regulation', 'Relapse', 'Research', 'Research Personnel', 'Rest', 'Rewards', 'Risk', 'Scanning', 'Subgroup', 'Substance Use Disorder', 'Symptoms', 'Syndrome', 'Testing', 'Transcend', 'Treatment outcome', 'Ventral Striatum', 'Withdrawal', 'addiction', 'animal data', 'anxious', 'base', 'biobank', 'biomarker validation', 'cocaine use', 'comorbid depression', 'comorbidity', 'craving', 'diagnostic biomarker', 'diagnostic platform', 'disability', 'disease classification', 'disease diagnosis', 'drug seeking behavior', 'individual patient', 'individualized medicine', 'interest', 'large scale data', 'machine learning method', 'negative affect', 'negative emotional state', 'network dysfunction', 'neuroimaging', 'neurophysiology', 'neuropsychiatry', 'novel', 'novel therapeutic intervention', 'novel therapeutics', 'patient subsets', 'reinforcer', 'response', 'specific biomarkers', 'substance misuse', 'tool']",NIDA,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2021,603973
"Nathan Shock Center for Excellence in Basic Biology of Aging OVERALL—PROJECT SUMMARY Healthspan is a complex trait, influenced by many interacting polymorphic alleles and environmental factors that may accelerate or delay aging, reduce or increase disease risk, and/or promote extended lifespan. Thus, assessing the role of genetic variation in aging requires an experimental strategy capable of modeling the genetic and biological complexity of human populations while allowing for efficient identification and validation of candidate genes. With this proposal, the JAX NSC seeks support to further develop and disseminate the next generation of genetic, phenotyping, and information resources necessary to enable a systems-wide approach to understanding healthy aging. Over the past 15 years, The JAX NSC has transformed aging research both at JAX and across the geroscience community, providing central resources to support investigators that have resulted in 26 peer-reviewed publications in the last funding period. The Center has developed nascent regional and national resources for aging research, including aging mouse resources and tissues that support our numerous collaborations and external researchers. All JAX NSC data and tools are publicly disseminated on the Mouse Phenome Database and the JAX NSC website, thus ensuring that the resources generated and expertise acquired through the Center is readily available to the aging research community. In this renewal, we will advance towards our goal by providing unique resources, tools, and support to geroscience investigators while leveraging JAX's unparalleled expertise in the large-scale identification and functional validation of complex polygenic traits in mice. We will do this by providing effective Center administration and enhancing the utility of JAX NSC resources throughout the aging community (Aim 1); expanding the research focus on aging, healthspan and age-related diseases through a robust Research Development Core (Aim 2); increasing the diversity of mouse resources available for aging research, including a new study to, for the first time, investigate the effect of genetic variation on cellular senescence and treatment with senolytic drugs (Aim 3); strengthening the data and computational and support available to the aging community (Aim 4); expanding the use of machine learning technologies in interpretation of aging pathologies (Aim 5). The Center will be led by a highly experienced team of Principal Investigators and Core Leaders who, with oversight from an External Advisory Board, will provide effective management to facilitate the goals and objectives of the Center. The Center will leverage unparalleled institutional resources, facilities and expertise of The Jackson Laboratory, a globally renowned institution for mouse genetics research, to enhance its goals and the utility of the resources it generates for the aging research community. OVERALL—PUBLIC HEALTH RELEVANCE Human aging is influenced by genetic factors, whereby differences in longevity as well as changes in health and disease risk with time are linked to variation in individuals' genetic codes. The Jackson Laboratory Nathan Shock Center will develop resources to encourage the use of a wider range of mouse models in aging research. Resources—including aged mouse models that mirror human genetic variation, metabolic and microbiome data, and methods to reveal genetic factors tied to human aging—will be available to the scientific community, accelerating research to understand and ultimately prolong healthy human aging.",Nathan Shock Center for Excellence in Basic Biology of Aging,10261436,P30AG038070,"['Advisory Committees', 'Aging', 'Alleles', 'Animals', 'Biological', 'Biology of Aging', 'Candidate Disease Gene', 'Cell Aging', 'Collaborations', 'Communities', 'Complex', 'Computer Assisted', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Educational workshop', 'Ensure', 'Environmental Risk Factor', 'Funding', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Models', 'Genetic Research', 'Genetic Variation', 'Geroscience', 'Goals', 'Health', 'Heart', 'Histologic', 'Human', 'Human Genetics', 'Image Analysis', 'Inbred Strain', 'Individual', 'Information Resources', 'Institution', 'Joints', 'Laboratories', 'Leadership', 'Link', 'Liver', 'Longevity', 'Lung', 'Machine Learning', 'Maps', 'Mentorship', 'Metabolic', 'Methods', 'Mus', 'Pathology', 'Peer Review', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Pilot Projects', 'Polygenic Traits', 'Population', 'Principal Investigator', 'Process', 'Protocols documentation', 'Publications', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Shock', 'Statistical Methods', 'Structure', 'System', 'Technology', 'The Jackson Laboratory', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Validation', 'Variant', 'Visit', 'age related', 'aged', 'animal tissue', 'behavioral phenotyping', 'candidate validation', 'career development', 'data dissemination', 'data management', 'data tools', 'disorder risk', 'experience', 'healthspan', 'healthy aging', 'insight', 'microbiome', 'mouse genetics', 'mouse model', 'next generation', 'novel', 'open source', 'phenome', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'senescence', 'symposium', 'tool', 'trait', 'user-friendly', 'web site']",NIA,JACKSON LABORATORY,P30,2021,1069526
"TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS ABSTRACT There is a growing interest in dietary patterns that capture the overall quality of diet as well as its constituent foods and nutrients. Commonly used dietary patterns are a priori diet score/index based on a set of dietary recommendations for a healthy diet (e.g., Mediterranean diet, Healthy Eating Index) or data-driven dietary patterns (e.g., prudent diet, western diet). Numerous studies have shown that those dietary patterns were related to the risk of chronic diseases such as heart disease, diabetes, and cancer. However, none of these dietary patterns incorporates eating behavior such as when we eat (i.e., eating time) and how often we eat (i.e. eating frequency) during a day. Since the amount of foods and nutrients consumed at one eating occasion influences the food consumption at the subsequent eating occasion and overall intake of the day, eating time and frequency are integral parts of dietary patterns. Furthermore, several lines of evidence consistently suggest that eating time and frequency as well as a meal composition play roles in body weight regulation and metabolic health and also regulate circadian rhythms, all of which may lead to metabolic dysfunctions and ultimately chronic diseases. Given a clear need to expand the dietary patterns framework and close a gap in dietary patterns methodological work, we propose to 1) develop a “temporal” dietary patterns based on temporal distribution of eating time and frequency during a day; and 2) evaluate if the identified temporal dietary patterns are associated with i) overall diet quality and nutrient intakes, ii) adiposity (e.g., BMI, waist circumference), and iii) metabolic biomarkers (e.g., insulin, HOMA-IR, LDL-cholesterol, c-reactive protein). To overcome a limitation that a conventional statistical method cannot capture multidimensional aspects of temporal dietary patterns (e.g., 24-dimensional feature vectors, multivariate dietary intake time-series data), we will use a novel approach combining nutrition and systems science—machine learning method. The Interactive Diet and Activity Tracking in AARP (IDATA) study that repeatedly collected diet, anthropometry, and blood samples from 1,021 men and women, 50-74 years old will be used. During one year, the IDATA study collected 24-hour recalls with clock time for each eating occasion, every other month (total six 24-hour recalls); measured anthropometry three times (baseline and at month 6 and 12); and collected blood twice, 6-month apart. Successful completion of our proposed study will identify temporal dietary patterns that are related to diet quality and metabolic health and validate the utility of temporal dietary patterns as a new tool for future research on diet-health relations and prevention of chronic diseases. NARRATIVE Eating behaviors and its impact on health are complex and multidimensional. The proposed study provides an excellent opportunity to develop new dietary patterns that capture eating behaviors such as when we eat and how often we eat during a day. The findings of the study about healthy eating patterns will also improve dietary recommendations by adding messages on when and how often to eat during a day.",TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS,10053329,R01CA226937,"['Advisory Committees', 'Affect', 'Algorithms', 'Animals', 'Anthropometry', 'Biological Markers', 'Blood', 'Blood specimen', 'Body Weight', 'Body mass index', 'C-reactive protein', 'Calories', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Circadian Rhythms', 'Complex', 'Consumption', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Diet Habits', 'Dietary Practices', 'Dietary intake', 'Dimensions', 'Eating', 'Eating Behavior', 'Energy Intake', 'Evaluation', 'Fasting', 'Fatty acid glycerol esters', 'Food', 'Frequencies', 'Health', 'Healthy Eating', 'Heart Diseases', 'Hour', 'Human', 'Individual', 'Insulin', 'Intake', 'LDL Cholesterol Lipoproteins', 'Lead', 'Macronutrients Nutrition', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediterranean Diet', 'Metabolic', 'Metabolic dysfunction', 'Metabolic syndrome', 'Methodology', 'Modeling', 'Nutrient', 'Obesity', 'Outcome', 'Pattern', 'Persons', 'Physical activity', 'Play', 'Population', 'Positioning Attribute', 'Prevention', 'Recommendation', 'Regulation', 'Risk', 'Role', 'Science', 'Series', 'Statistical Methods', 'System', 'Techniques', 'Time', 'Waist-Hip Ratio', 'Weight maintenance regimen', 'Woman', 'Work', 'base', 'cardiovascular disorder risk', 'dietary', 'dietary guidelines', 'doubly-labeled water', 'epidemiology study', 'food consumption', 'good diet', 'improved', 'indexing', 'interest', 'machine learning method', 'men', 'novel', 'novel strategies', 'nutrient metabolism', 'nutrition', 'obesity risk', 'prudent diet', 'tool', 'vector', 'waist circumference', 'western diet']",NCI,WASHINGTON UNIVERSITY,R01,2021,224806
"Predicting Short- and Long-term Future Occurrence of Atrial Fibrillation from Single-Lead ECG in Normal Sinus Rhythm with an Explainable Deep Learning Model. Project Summary/Abstract More than 30 million individuals worldwide are diagnosed with atrial fibrillation (AF), however, another 13% of individuals with AF are left undiagnosed. People with AF have a five-fold increased risk of stroke with up to one-third of all strokes shown to be related to AF. Timely administration of appropriate preventative therapies, especially anticoagulants, can significantly decrease the complications of AF, including strokes, by 65% and mortality by 30%. Digital health technologies offer new approaches to identify individuals with undiagnosed AF, in particular paroxysmal AF (PAF), characterized by occasional episodes of limited duration, for whom a 10-second 12-lead electrocardiography (ECG) performed in the clinical setting is unlikely to overlap with an AF event. Continuous monitoring is promising, but still costly and burdensome for elderly individuals, who are at higher risk. To maximize the diagnostic yield of these technologies, we propose novel methods to predict the future occurrence of AF from a single-lead ECG during normal sinus rhythm. Only recently it was shown that it is possible to predict the future occurrence of AF from 12-lead ECGs in normal sinus rhythm collected in a clinical setting. Here, we propose to predict the occurrence of AF with commercially available single- lead ECG devices, which will enable a scalable alternative for early detection in a non-clinical setting. To achieve this goal, we will analyze retrospectively the raw single-lead ECG data of 10,000+ individuals with PAF over 14 days of monitoring. Validation work will then be carried out in a unique set of 1,718 asymptomatic individuals who participated in the prospective mSToPS clinical trial of AF screening (mean age 73), with full clinical information and co-morbidities. The three aims of this project are:  1. Compute the probability of a future AF event in the short-term for an individual in normal sinus rhythm using classic single-lead ECG features and representation learning based features.  2. Develop a method for long-term prediction of AF onset by evaluating individuals with AF detected in 1, 3, 6 and 12 months from the initial monitored period of normal sinus rhythm and by validating the algorithms using the mSToPS dataset with 3 years of clinical follow-up and annotated co-morbidities.  3. Develop a technique to provide a preliminary interpretation of representation learning features for time-series data applied to the short- and long-term prediction. This retrospective study will develop and optimize new predictive techniques from single-lead ECGs, available through consumer devices, with the goal of identifying individuals at high risk of developing AF. A future direction to build on from this study's results would include a prospective study of AF prediction using consumer single-lead ECG to improve clinical outcomes. Project Narrative In this project we propose novel methods to predict the future occurrence of AF from single-lead ECGs during normal sinus rhythm, collected from commercially available single-lead ECG devices, which will enable a scalable alternative for early detection in a non-clinical setting. To achieve this goal, we will analyze retrospectively the raw single-lead ECG data of 10,000+ individuals with paroxysmal AF over 14 days of monitoring and we will validate the developed modes using a unique set of 1,718 asymptomatic individuals who participated in the prospective mSToPS clinical trial of AF screening (mean age 73), with full clinical information and co- morbidities. This retrospective study will develop and optimize new predictive techniques from single-lead ECGs, available through consumer devices, with the goal of identifying individuals at high risk of developing AF.",Predicting Short- and Long-term Future Occurrence of Atrial Fibrillation from Single-Lead ECG in Normal Sinus Rhythm with an Explainable Deep Learning Model.,10195981,R21AG072349,"['Address', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Data', 'Data Science', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'EKG P Wave', 'Early Diagnosis', 'Early identification', 'Elderly', 'Electrocardiogram', 'Event', 'Future', 'Goals', 'Health', 'Health Technology', 'Home environment', 'Hour', 'Individual', 'Ischemic Stroke', 'Lead', 'Learning', 'Left', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Participant', 'Persons', 'Photoplethysmography', 'Play', 'Population', 'Preventive therapy', 'Probability', 'Prospective Studies', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Series', 'Signal Transduction', 'Sinus', 'Stroke', 'Techniques', 'Technology', 'Time', 'Validation', 'Work', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'cost', 'deep learning', 'design', 'diagnostic accuracy', 'digital health', 'follow-up', 'high risk', 'improved', 'learning strategy', 'mortality', 'novel', 'novel strategies', 'prospective', 'screening', 'smart watch', 'stroke risk', 'tool', 'uptake', 'wearable sensor technology']",NIA,SCRIPPS RESEARCH INSTITUTE,R21,2021,266250
"Multimodal Approaches to Neurobiology of Traumatic Dissociation Dissociative symptoms in traumatized individuals are common, debilitating, and costly; however, little is known about how its biological mechanisms interact with PTSD treatment. Traumatic dissociation broadly encompasses a range of distinct, yet clinically interrelated symptoms: depersonalization, derealization, amnesia, numbing, flashbacks, passive influence phenomena, and identity disturbances. Either alone or in various combinations, these symptoms serve as diagnostic criteria and commonly associated features across multiple psychiatric disorders. Traumatic dissociation is also associated with significant personal and societal burden. Traumatized individuals with dissociative symptoms typically have co-occurring psychiatric conditions, high rates of self-destructive behaviors and suicidality, and are disproportionate treatment utilizers. In addition, they are at increased risk for attrition, non-response and relapse following treatment interventions. Despite the significant and disabling nature of traumatic dissociative symptoms, little is known about the neurobiology of these processes and targeted interventions do not exist.  PTSD treatment studies have neither looked at neural intermediate phenotypes of dissociation, nor how these are associated with psychophysiological and digital phenotypes. Compared to clinical symptom measures, these biological and in-the-moment digital markers of dissociation may more robustly map onto the underlying core aspects of the disorder differentiating dissociation subtypes following childhood and adult trauma. We propose to build upon our prior Exploratory R21 to now capture longitudinal multimodal phenotype data related to dissociation, pre-, post- and during PTSD treatment modalities that include empirically-derived, exposure-based components.  The goals of this study will be 1) to understand the differential biomarkers that map onto dissociative symptoms, and 2) to understand how these biomarkers may best predict trajectory of response to empirically based standard-of-care treatments. For each of these Aims, we will collect Neuroimaging, Physiology, and Digital Phenotyping data, applying computational modeling with multimodal data to provide machine-learning based, unbiased predictive models of dissociative intermediate phenotypes at baseline and longitudinally. This naturalistic study will allow us to map the biology of dissociation, and importantly, the change in dissociative symptoms and underlying biomarkers over time, using naturalistic evidenced-based treatment for PTSD in 130 treatment-seeking patients with PTSD, and a range of dissociative symptoms.  Successful completion of these Aims will provide a novel and powerful understanding of the biological markers of dissociation subtypes following trauma exposure, and will identify biological mechanisms for understanding and treating PTSD with dissociation. Pathological trauma-related dissociation is a significant personal and societal burden. This proposal will examine behavioral and biological correlates of dissociation across imaging, physiology, and digital assessments. Results from this proposal will inform how to identify those at risk for these debilitating symptoms, potential brain regions to target for treatment, and may support a new standard of clinical care for PTSD with dissociation. ",Multimodal Approaches to Neurobiology of Traumatic Dissociation,10129433,R01MH119227,"['Address', 'Adult', 'Aftercare', 'Amnesia', 'Anterior', 'Arousal', 'Attention', 'Behavioral', 'Biological', 'Biological Markers', 'Biology', 'Brain', 'Brain region', 'Childhood', 'Clinical', 'Clinical Trials', 'Complex', 'Computer Models', 'Data', 'Depersonalization', 'Derealizations', 'Diagnosis', 'Diagnostic', 'Disease', 'Dissociation', 'Dorsal', 'Ecological momentary assessment', 'Emotional', 'Environment', 'Equipment and supply inventories', 'Evidence based treatment', 'Exhibits', 'Fright', 'Future', 'Goals', 'Image', 'Individual', 'Intervention', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medial', 'Mental disorders', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Numbness', 'Participant', 'Pathologic', 'Patient Self-Report', 'Patients', 'Phase', 'Phenotype', 'Physiological', 'Physiology', 'Post-Traumatic Stress Disorders', 'Prefrontal Cortex', 'Process', 'Psychometrics', 'Psychophysiology', 'Recording of previous events', 'Recovery', 'Reflex action', 'Refractory', 'Regulation', 'Relapse', 'Rest', 'Risk', 'Role', 'Self Destructive Behavior', 'Sinus Arrhythmia', 'Suicide', 'Symptoms', 'System', 'Time', 'Trauma', 'Work', 'base', 'cingulate cortex', 'clinical care', 'cost', 'digital', 'disabling symptom', 'emotion regulation', 'heart rate variability', 'multimodal data', 'multimodality', 'neuroimaging', 'novel', 'pediatric trauma', 'phenotypic data', 'predictive modeling', 'relating to nervous system', 'respiratory', 'response', 'skills', 'standard of care', 'targeted biomarker', 'targeted therapy trials', 'time use', 'trauma exposure']",NIMH,MCLEAN HOSPITAL,R01,2021,723138
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,10171859,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'detection sensitivity', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2021,381543
"Driver Genes for Engineered Rotator Cuff Development Rotator cuff tears affect over 15% of Americans and impair shoulder joint biomechanics and function. Following repair of symptomatic tears, functional deficits frequently persist and re-tears are common, due to the complex anatomy and high functional demands on the rotator cuff tendons. Rotator cuff tendon tissue engineering research is focused on devices to improve immediate mechanical support to the repair and to stimulate early and rapid tendon regeneration rather than scarring and fibrosis, particularly for the supraspinatus tendon (SST), the most commonly torn tendon in the rotator cuff. Aligned electrospun scaffolds that mimic both the highly aligned medial region of the SST, and bi-axially aligned electrospun scaffolds that mimic the multi-axially aligned isotropic anterior region of the SST have been evaluated with promising results when seeded with adipose- derived stem cells (ASCs). However, progress in this area of rotator cuff tendon engineering and in other areas of tendon research is hindered by the lack of definitive markers for SST or for its regional heterogeneity, the lack of understanding to what extent ASCs are tenogenic and can assume the identity of tendon fibroblasts, the lack of specific markers for tendon fibroblast identity and tenogenic differentiation, and by a lack of markers for tendon maturation and response to mechanical loading in engineered tendon. Therefore, is it difficult to assess how successful current tendon tissue engineering approaches really are, or to predict how well tendon tissue engineered approaches will function in translation when autologous or allogeneic ASCs from diverse human populations are used to enhance rotator cuff repair via augmentation or interposition with engineered tendon devices. These studies will evaluate the epigenome (methylome), transcriptome, proteome, lipidome, metabolome and phenome (phenotype) of native human SST and donor-matched tissue engineered tendon produced from SST fibroblasts and ASCs. Bioinformatics approaches will be used to integrate the data to an integrated multiome, which will then be used with machine learning approaches to extract key causal ‘driver’ genes, or tendon specific genes or molecules responsible for: 1) SST heterogeneity between medial and anterior regions. 2) Tendon cell identity and the extent of tenogenesis by ASCs on electrospun scaffolds. 3) The heterogenetic response by ASCs on uni- vs. bi-axially aligned electrospun scaffolds that mimic the native heterogeneity of the SST. 4) The response of engineered tendon to dynamic loading. Identified driver genes or molecules will be validated though over-expression or silencing approaches, thus providing therapeutic targets for manipulation to enhance tenogenesis, and engineered tendon development and maturation. Together these innovative studies will provide a template for improved external validity of benchtop tendon tissue engineering and pre-clinical studies towards successful translation in diverse patient populations. In addition, the bioinformatics and multiomics toolboxes and assays that result from this work will be invaluable to not only the tendon research community, but also to the wider musculoskeletal and regenerative medicine fields. A small number of driver genes in other medical fields are responsible for changes in expression and protein levels in hundreds of other genes, and subsequent tissue metabolism. The process of tissue engineered rotator cuff tendon development and formation as it relates to adult tendon after surgical repair is not well understood, despite rotator cuff tears being an important clinical problem and representing almost one third of orthopedic injuries. Evaluating changes in the ability of genes to be translated to proteins at the DNA, RNA, small metabolite, and protein level of tissue engineered tendon formation under different loading conditions compared to normal adult tendon will identify driver genes and potential new ways to improve currently available options for rotator cuff repair.",Driver Genes for Engineered Rotator Cuff Development,10098302,R01AR073882,"['Address', 'Adipose tissue', 'Adult', 'Affect', 'Allogenic', 'American', 'Anatomy', 'Anterior', 'Area', 'Autologous', 'Biochemical', 'Biocompatible Materials', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cadaver', 'Cells', 'Cicatrix', 'Clinical', 'Communities', 'Complex', 'Computational Technique', 'Cues', 'DNA', 'Data', 'Data Set', 'Development', 'Devices', 'Engineered Gene', 'Engineering', 'Evaluation', 'Extracellular Matrix', 'Fibroblasts', 'Fibrosis', 'Genes', 'Genetic', 'Harvest', 'Head', 'Heterogeneity', 'Human', 'Impairment', 'In Vitro', 'Injury', 'Investigation', 'Joint structure of shoulder region', 'Knowledge', 'Machine Learning', 'Measures', 'Mechanical Stimulation', 'Mechanics', 'Medial', 'Medical', 'Mesenchymal Stem Cells', 'Metabolism', 'Methylation', 'Modeling', 'Modification', 'Molecular', 'Musculoskeletal', 'Natural regeneration', 'Operative Surgical Procedures', 'Orthopedics', 'Outcome', 'Phenotype', 'Population', 'Process', 'Property', 'Proteins', 'Proteome', 'RNA', 'Regenerative Medicine', 'Research', 'Resources', 'Rotator Cuff', 'Seeds', 'Techniques', 'Tendon structure', 'Testing', 'Tissue Engineering', 'Tissues', 'Translating', 'Translations', 'Work', 'design', 'epigenome', 'improved', 'innovation', 'interest', 'lipidome', 'mechanical load', 'mechanical properties', 'metabolome', 'methylome', 'multiple omics', 'overexpression', 'patient population', 'phenome', 'phenomics', 'preclinical study', 'regenerative', 'repaired', 'response', 'rotator cuff tear', 'scaffold', 'spatial relationship', 'stem cells', 'supraspinatus muscle', 'tendon development', 'therapeutic target', 'transcriptome', 'translation to humans']",NIAMS,PURDUE UNIVERSITY,R01,2021,479770
"Targeting Multiple Kinases to Treat Experimental Spinal Cord Injury Title: Targeting Multiple Kinases to Treat Experimental Spinal Cord Injury Project Summary:  Spinal cord injury (SCI) patients experience limited functional recovery, owing in part to the paucity of axon regrowth from injured CNS neurons. Effective treatments are lacking, likely because of multiple factors, intrinsic and extrinsic, that inhibit axon growth. Thus we require agents that target more than one source of regeneration failure.  Kinases are ubiquitous signal transducers that regulate most cellular processes, including axon growth. To begin to identify compounds that positively regulate axon growth, we screened 1600 small-molecule kinase inhibitors (KIs) in an in vitro CNS neurite outgrowth assay and identified “hit” KIs that reproducibly and strongly promote outgrowth. Due to homology of catalytic domains, KIs typically inhibit multiple kinases. This makes it difficult to identify the kinase(s) that mediate a KI's effects on cells. We used information theory and machine learning to analyze the inhibition profiles of KIs in relation to their effects on neurite outgrowth. This enabled us to identify, and later validate via siRNA knockdown in primary neurons, multiple kinase targets (i.e. kinases that should be inhibited to promote neurite outgrowth). These included previously known targets that regulate intrinsic and extrinsic inhibitor factors, in addition to several novel candidates. Conversely, we identified kinases whose activity is critical for neurite outgrowth, and whose inhibition must be avoided (anti-targets). We discovered several KIs that inhibit multiple targets and no anti-targets. These KIs strongly promoted neurite outgrowth in vitro.  We tested the KI, RO48, that had the largest effect in vitro in two in vivo models. Our preliminary experiments indicate that RO48 is remarkably effective in vivo. It promoted robust axonal growth of the corticospinal tract (CST) in three separate models of CST injury (pyramidotomy, funiculotomy, dorsal hemisection), and in the dorsal hemisection model, improved forelimb function. We propose to build on these remarkable results to test the working hypothesis that the simultaneous inhibition of RO48's five target kinases (ROCK, PKC, PRKG1, PRKX, and RPS6K) promotes sprouting and regeneration of CST axons. This will be accomplished using viral vectors to knock down expression of the different target kinases individually and in combination. We will do knockdown in CST neurons in the cortex. We will assess CST axon growth at the injury site using light microscopy. We will also perform experiments to determine if RO48-induced CST axon growth promotes axon sprouting, regeneration, or both, and whether RO48 improves behavioral outcomes such as grasping and walking after a contusion injury.  These experiments will 1) validate novel kinases as in vivo targets for future development of SCI therapeutics 2) determine whether these kinases regulate CST axon sprouting, regeneration, or both, and 3) confirm whether the substantial stimulation of axon growth induced by treatment with RO48 improves motor outcomes in a clinically relevant contusion model.  Title: Targeting Multiple Kinases to Treat Experimental Spinal Cord Injury Project Narrative: The proposed experiments aim to understand how small-molecule drug-like compounds increase the ability of nerve cells to grow long processes and re-form connections. Validating the molecular targets of these compounds for in vivo nerve growth will enable future drug discovery projects focused on these targets.",Targeting Multiple Kinases to Treat Experimental Spinal Cord Injury,10160972,R01NS100531,"['Axon', 'Behavioral', 'Biochemical', 'Biological', 'Biological Assay', 'Catalytic Domain', 'Cell physiology', 'Cells', 'Cervical', 'Complement 5a', 'Confocal Microscopy', 'Control Animal', 'Contusions', 'Corticospinal Tracts', 'Data', 'Development', 'Distal', 'Dorsal', 'Dose', 'Failure', 'Forelimb', 'Future', 'Gold', 'Growth', 'In Vitro', 'Individual', 'Information Theory', 'Injury', 'Institution', 'Label', 'Lesion', 'Light', 'Machine Learning', 'Mediating', 'Microscopy', 'Modeling', 'Molecular', 'Molecular Target', 'Morphology', 'Motor', 'Motor Cortex', 'Mus', 'Natural regeneration', 'Nerve', 'Neurites', 'Neurons', 'Outcome', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Process', 'Rattus', 'Recovery of Function', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Small Interfering RNA', 'Source', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Spinal cord injury patients', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Transducers', 'Viral Vector', 'Walking', 'axon growth', 'axon regeneration', 'axonal sprouting', 'behavior test', 'behavioral outcome', 'central nervous system injury', 'clinically relevant', 'design', 'drug discovery', 'effective therapy', 'experience', 'experimental study', 'grasp', 'gray matter', 'improved', 'in vivo', 'in vivo Model', 'inhibitor/antagonist', 'injured', 'insight', 'kinase inhibitor', 'knock-down', 'light microscopy', 'novel', 'reconstruction', 'regenerative', 'screening', 'small molecule', 'targeted agent', 'therapeutic target']",NINDS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2021,465464
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,10128442,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2021,167900
"Biomarkers of Alcoholic Hepatitis Abstract Our overarching goal is to develop minimally invasive approaches to better predict outcome and novel mechanisms in alcoholic hepatitis (AH). AH is characterized by acute hepatic decompensation and multiple organ failure. Although supportive care for AH has improved, short-term mortality has largely remained unchanged (30-40%) for decades. Effective approaches to predict risk hamper the treatment of AH. The hepatic extracellular matrix (ECM) responds dynamically to organ injury and ECM turnover increases; we propose to take advantage of this to develop new biomarkers for AH. The peptidome, low molecular weight peptides in biologic fluids, includes not only synthesized peptides, but fragments of degraded proteins (i.e., ‘degradome’). We hypothesize that the ECM degradome in plasma will yield new biomarkers to predict outcome and mechanisms in AH. We will test this hypothesis via the following Specific Aims: 1). To identify key changes in the peptidome as predictive biomarkers of outcome in AH. Unbiased peptidomics and multivariate analyses will identify degradomic features independently linked to prognosis. Protease activity that could produce significantly changed peptides will be predicted using Proteasix. We will also determine the mechanistic role of ECM turnover in the in parallel established models of alcohol-induced liver injury. 2) To develop probabilistic graphical models to predict outcome in AH. Whereas we expect the results of Aim 1 to establish that the peptidome profile in patients correlates with overall outcome, biomarkers alone are often insufficient to accurately predict individual patient outcome. We will therefore employ machine learning methods like probabilistic graphical models (PGMs) over mixed data types to integrate peptidomic and individual patient clinical data, into a single probabilistic graphical framework. The resulting graphs will then be used to infer causal interactions between variables, select informative biomarkers that will more specifically predict the outcome, and gain new mechanistic insight into the biology of AH (hypothesis generation). 3) To validate the use of the peptidome as a predictive tool for determining outcome in AH. Using a large prospectively-designed patient cohort with established outcomes, we will test the ability of the algorithms and biomarkers generated in this study to predict outcome. The successful completion of the proposed work will produce significant results at various levels: (1) Biomarker discovery: we will identify biomarkers and conditional biomarkers for AH prognosis. (2) Mechanistic understanding of AH: our models will generate hypotheses about the interactions between variables at different scales (molecular, individual) that will provide insights on the proteins that are involved in AH. (3) Algorithm development: through this project we will extend our mixed data graph learning algorithms to include censored variables (i.e., survival data). As a result of the above, this project is likely to yield novel diagnostic tools for AH that may also translate to other liver diseases. Narrative Alcoholic hepatitis (AH) is a severe acute form of alcoholic liver disease with a very high mortality rate. Despite years of research, the standard-of-care and mortality rate has not changed dramatically in over 50 years. Our goal is to develop new computational and experimental methods and discover new biomarkers for AH outcome that can efficiently identify at-risk individuals. A second goal of the project is to identify molecular mechanisms of AH, which could be targeted therapeutically.",Biomarkers of Alcoholic Hepatitis,10170180,R01AA028436,"['Acute', 'Address', 'Alcoholic Hepatitis', 'Alcoholic Liver Diseases', 'Alcohols', 'Algorithms', 'Area', 'Biological', 'Biological Markers', 'Biology', 'Cells', 'Clinical Data', 'Collagen', 'Data', 'Development', 'Disease', 'Extracellular Matrix', 'Extracellular Matrix Proteins', 'Generations', 'Goals', 'Graph', 'Health', 'Hepatic', 'Homeostasis', 'Human', 'Individual', 'Informatics', 'Injury', 'Lead', 'Link', 'Liquid substance', 'Liver Fibrosis', 'Liver diseases', 'Matrix Metalloproteinases', 'Mediating', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Weight', 'Multiple Organ Failure', 'Multivariate Analysis', 'Neoplasm Metastasis', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Peptide Fragments', 'Peptide Hydrolases', 'Peptides', 'Plasma', 'Population', 'Predictive Value', 'Process', 'Production', 'Prognostic Marker', 'Protease Inhibitor', 'Protein Fragment', 'Proteins', 'Research', 'Risk', 'Role', 'Severities', 'Signal Transduction', 'Supportive care', 'Surrogate Markers', 'Testing', 'Tissues', 'Translating', 'Work', 'acute liver injury', 'algorithm development', 'biomarker discovery', 'chronic alcohol ingestion', 'cohort', 'design', 'improved', 'individual patient', 'insight', 'interest', 'learning algorithm', 'machine learning method', 'minimally invasive', 'mortality', 'mouse model', 'new therapeutic target', 'novel', 'novel diagnostics', 'organ injury', 'outcome forecast', 'outcome prediction', 'predictive marker', 'predictive tools', 'profiles in patients', 'prospective', 'standard of care', 'targeted treatment', 'tool']",NIAAA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,600979
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,10086862,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2021,171720
"Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort Project summary Our long-term goal is to demonstrate the utility of ultrasound for OA assessment, standardize its acquisition and scoring, and promote increased uptake of US for use in clinical, research, and trial settings. Knee osteoarthritis (KOA) is highly prevalent and frequently debilitating. Development of potential treatments has been hampered by the heterogenous nature of this common chronic condition, which is characterized by a number of subgroups, or phenotypes, with different underlying pathophysiological mechanisms. Imaging, genetics, biochemical biomarkers, and other features can be used to characterize phenotypes, but variations in data types can make it difficult to harmonize definitions. While radiography is widely used in KOA imaging, it is limited in its ability to assess early disease (when interventions are most likely to succeed) and is insensitive to change. Ultrasound (US) is a widely accessible, time-efficient and cost-effective imaging modality that can provide detailed and reliable information about all joint tissues (e.g., cartilage, meniscus, synovium, bone), and could therefore inform phenotypes in KOA (e.g., by presence of synovitis, effusion, cartilage damage, calcium crystal deposition, and popliteal cysts). Use of US is currently limited by the lack of systematically performed studies in well-characterized non-clinical populations. To address this gap and further the use of this advantageous imaging modality for KOA, we will obtain standardized US and radiography in the population- based Johnston County Health Study (JoCoHS), the new enrollment phase of the 25+ year Johnston County OA Project which includes white, African American, and Hispanic men and women aged 35-70, to achieve three aims. In Aim 1, we will determine the population prevalence (n~3000) of knee US features including cartilage and meniscal damage, synovitis/effusion, calcium crystal deposition, popliteal cysts and osteophytes overall and in key subgroups by age, sex, race/ethnicity, and symptom status. Aim 2 will allow quantification of the associations between these US features and radiographic findings and symptom scores overall and in key subgroups (e.g., those with and without radiographic KOA, by sex, by race/ethnicity). For Aim 3, we will apply novel machine learning methodologies (e.g., Direction-projection-permutation [DiProPerm] hypothesis testing, Joint and Individual Variation [JIVE], and Distance-Weighted Discrimination [DWD]) to a) develop an overall US score for symptomatic KOA and b) identify the contribution of US variables to phenotypes relevant to KOA based on general health, physical activity, and functional assessments. This study is a crucial step to establish the foundation for US as an assessment tool for clinical use, research, and clinical trials in KOA, providing unique population-based cross-sectional data regarding the utility of US and forming the basis for future longitudinal work evaluating its value and performance characteristics related to incident and progressive KOA. Project narrative Osteoarthritis is an enormous and increasing public health problem that, like many other chronic conditions, is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. Ultrasound is an accessible, time-efficient, and cost-effective imaging modality that provides invaluable data about all joint tissues involved in osteoarthritis and has the potential to identify important phenotypes. The proposed work is relevant to the NIAMS mission and represents a crucial step to establish the foundation for ultrasound as an assessment tool for use in clinics, research, and clinical trials in osteoarthritis.",Assessment of ultrasound features of knee osteoarthritis in a population-based community cohort,10158441,R01AR077060,"['Address', 'African American', 'Age', 'Area', 'Assessment tool', 'Bilateral', 'Biochemical', 'Biological Markers', 'Bone Spur', 'Calcium', 'Cartilage', 'Categories', 'Characteristics', 'Chronic', 'Claustrophobias', 'Clinic', 'Clinical', 'Clinical Assessment Tool', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Communities', 'County', 'Crystal Formation', 'Crystallization', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Discrimination', 'Disease', 'Enrollment', 'Ethnic Origin', 'Etiology', 'Foundations', 'Future', 'General Population', 'Goals', 'Health', 'Hispanics', 'Image', 'Implant', 'Individual', 'Infrastructure', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Mission', 'Modality', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Outcome', 'Pain', 'Participant', 'Pathology', 'Performance', 'Phase', 'Phenotype', 'Physical activity', 'Popliteal Cyst', 'Population', 'Population Study', 'Prevalence', 'Public Health', 'Race', 'Receiver Operating Characteristics', 'Research', 'Risk Factors', 'Sex Differences', 'Specialist', 'Standardization', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Synovitis', 'Testing', 'Time', 'Tissues', 'Ultrasonography', 'Variant', 'Woman', 'Work', 'aged', 'base', 'bone', 'cohort', 'cost', 'cost effective', 'effusion', 'follow-up', 'imaging genetics', 'imaging modality', 'individual variation', 'interest', 'men', 'novel', 'point of care', 'population based', 'recruit', 'rheumatologist', 'sex', 'uptake']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,331837
"1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. IN particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 26,000 antidepressant-treated individuals and 2,500 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",1/2 Leveraging electronic health records for pharmacogenomics of psychiatric disorders,10064583,R01MH116270,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'determinants of treatment resistance', 'effective therapy', 'efficacious treatment', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'in silico', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk stratification', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,421250
"2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders Abstract  Schizophrenia (SCZ) and major depressive disorder (MDD) are highly heritable, debilitating diseases with lifetime prevalences of ~1% and 15%, respectively. Both disorders carry substantial morbidity and mortality and are associated with severe societal and personal costs. Despite the availability of efficacious treatments for both disorders, ~1/3 of individuals will not achieve symptomatic improvement even after multiple rounds of medication. Identifying individuals at greater risk for such treatment nonresponse, or treatment resistance, could facilitate more targeted interventions for these individuals.  A burgeoning literature has identified genomic variation associated with treatment response. In particular, antidepressant response has been suggested to be highly heritable; convergent data from rodent studies likewise suggest that antipsychotic and antidepressant response phenotypes are influenced by genetic variation. However, treatment studies to date have had minimal success in identifying variants associated with psychotropic response, likely as a result of limited sample sizes: prior efforts required sequential treatment trials and prospective assessment to characterize outcomes. Longitudinal electronic health records (EHR) data provide an opportunity to efficiently characterize treatment response in many individuals in real-world settings. Coupled with large and expanding biobanks, these cohorts allow for low- cost, large-scale genomic studies that finally achieve sufficient power to detect realistic effect sizes.  The investigators now propose to apply these approaches to the EHRs of two large regional health systems, each linked to a large biobank, to investigate treatment resistance in SCZ and MDD. They will apply canonical indicators of treatment resistance - clozapine treatment for SCZ, and electroconvulsive therapy (ECT) for MDD - to identify coded and uncoded clinical features associated with high probability of treatment resistance in EHR data. These predictors will themselves provide a useful baseline for identifying high risk individuals. Then, they will apply these to study the entire affected population of each biobank, extending existing genomic data with additional genome-wide association, yielding more than 25,000 antidepressant-treated individuals and 2,200 antipsychotic-treated individuals. Rather than simply conducting a case-control study, they will examine treatment resistance as a quantitative trait, applying a method developed by the investigators and shown to substantially increase power for such traits.  The project combines expertise in clinical informatics, machine learning, and analysis of large scale genomics, as well as domain-specific expertise in psychiatric treatment resistance. Spanning two distinct health systems, the algorithms and methods developed have maximal portability, facilitating next- step investigations. Successful identification of risk variants will facilitate efforts at clinical risk stratification as well as investigation of the biology underlying treatment resistance. Public Health Statement Despite the availability of effective treatments for schizophrenia and major depressive disorder, around 1/3 of individuals will not have symptomatic improvement after multiple treatment trials. If individuals at high risk for treatment resistance could be identified early, it might be possible to find more effective treatments for them. In particular, this study seeks to use electronic health records and biobanks to identify genomic variation associated with treatment resistance.",2/2 Leveraging electronic health records for pharmacogenomics of psychiatric diorders,10074155,R01MH116269,"['Academic Medical Centers', 'Address', 'Affect', 'Antidepressive Agents', 'Antipsychotic Agents', 'Biology', 'Case-Control Studies', 'Clinical', 'Clinical Informatics', 'Clozapine', 'Code', 'Consumption', 'Coupled', 'DNA', 'Data', 'Development', 'Discrimination', 'Disease', 'Effectiveness', 'Electroconvulsive Therapy', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'General Hospitals', 'Generations', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Heritability', 'Hospitals', 'Individual', 'Intervention', 'Investigation', 'Label', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Massachusetts', 'Measures', 'Medical Genetics', 'Mental disorders', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patient Triage', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Population', 'Prevalence', 'Probability', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Public Health', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Risk', 'Rodent', 'Role', 'Sample Size', 'Sampling', 'Schizophrenia', 'Sequential Treatment', 'Site', 'Structure', 'Suicide attempt', 'Supervision', 'System', 'Therapeutic', 'Time', 'Treatment Failure', 'Treatment Step', 'Treatment outcome', 'Variant', 'Work', 'adverse outcome', 'algorithmic methodologies', 'base', 'biobank', 'biomedical resource', 'clinical predictors', 'clinical risk', 'cohort', 'cost', 'design', 'determinants of treatment resistance', 'effective therapy', 'efficacious treatment', 'genetic association', 'genome wide association study', 'genomic data', 'genomic predictors', 'genomic variation', 'high risk', 'improved', 'in silico', 'mortality', 'neuropsychiatric disorder', 'personalized intervention', 'portability', 'predictive modeling', 'prevent', 'prospective', 'recruit', 'response', 'risk stratification', 'risk variant', 'success', 'symptomatic improvement', 'therapy resistant', 'trait', 'treatment response', 'treatment risk', 'treatment strategy', 'treatment trial']",NIMH,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,425000
"Structural, Biochemical and Functional Connectivity in Osteoarthritis using Quantitative Magnetic Resonance Imaging and Skeletal Biomechanics Osteoarthritis (OA), a multifactorial disease that causes joint degeneration, affects 27 million U.S. adults, and often leads to severe disability. The prevalence of OA is 33.6% in adults older than 65 years. Despite the fact that OA is a widespread and debilitating disease, treatment options are currently extremely limited, and established disease-modifying therapies do not exist. The solution generally offered to treat late stage, symptomatic knee OA is joint replacement (total knee/hip arthroplasty, TKA/THA), and while this surgically invasive and expensive remedy offers temporary relief, replacements often fail after 10-15 years, with shorter life spans in obese individuals. In order to reduce the number of TKA/THA procedures, preventive efforts and interventions targeting early stage OA are essential – the first step would be identifying subjects at high risk for disease development, at a stage when tissue is not yet lost, and cartilage matrix abnormalities are potentially reversible. Understanding the complex pathophysiology of joint degeneration, knee and hip joint interactions, impact of gait biomechanics, are all critical to determine the mechanistic basis of hip OA.  Hip OA progression marked by changes in cartilage biochemistry has complex multi-joint interactions with several mechanistic factors, including morphological features, gait biomechanics and demographics. However, studies to date have mostly focused on the relationship between single mechanistic factors and semi-quantitative/ quantitative imaging measures, gait biomechanics, or non-objective symptomatic evidence of hip OA. The overall goal of this competitive renewal is to extend our longitudinal work to determine the structure-function-connectivity and mechanistic factors that mediate biochemical degeneration of hip cartilage associated with OA progression over the mid-term (6-8-year) period.  In this proposal, subjects will be recruited for a longitudinal study (covering 5-8 year follow up) from our existing cohort (n=184 hips, 92 subjects), with the availability of existing 3-year follow-up data including bi- lateral hip radiographs and MR images, gait biomechanics and patient reported outcomes. We will use novel, fully automated and translational methods to measure MRI-based T1ρ and T2 relaxation time on a voxel basis, which will provide precise and localized information on cartilage proteoglycan and collagen integrity and water content. Automatic segmentation techniques combined with machine learning algorithms will be used to analyze cartilage T1ρ/T2 in a well-characterized dataset with quantifiable T1ρ/T2 values on a voxel-level, and to automatically detect the patterns of focal T1ρ/T2 elevations that lead to later stage OA and drive progression of degenerative disease (over 8 years). Detailed analysis of gait biomechanics using functional principal component analysis will utilize the rich skeletal biomechanics data and imaging (over 8 years). Imaging the knee and hip longitudinally will provide a multi-joint analysis of OA progression (over 4 years) not done previously and will provide unique insights in the mechanisms in hip OA, connections with knee changes. Osteoarthritis (OA), a multifactorial disease and understanding the complex pathophysiology of joint degeneration, knee and hip joint interactions, and the impact of gait biomechanics, are all critical to determine the mechanistic basis of hip OA. In this proposal subjects will be recruited for a longitudinal study (covering 5-8 year follow up) from our existing cohort and we will use novel, fully automated and translational methods to measure MRI-based measures of cartilage degeneration and determine the role of gait biomechanics on disease progression.","Structural, Biochemical and Functional Connectivity in Osteoarthritis using Quantitative Magnetic Resonance Imaging and Skeletal Biomechanics",10317687,R01AR069006,"['3-Dimensional', 'Adult', 'Affect', 'Age', 'American', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Cartilage', 'Cartilage Matrix', 'Collagen', 'Complex', 'Contralateral', 'Data', 'Data Analyses', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Etiology', 'Exhibits', 'Financial Hardship', 'Functional disorder', 'Gait', 'Goals', 'Head', 'Health', 'Hip Joint', 'Hip Osteoarthritis', 'Hip region structure', 'Image', 'Individual', 'Injury', 'Intervention', 'Ipsilateral', 'Joints', 'Kinetics', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Lead', 'Lesion', 'Limb structure', 'Link', 'Longevity', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Methods', 'Modeling', 'Morphology', 'Motivation', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Outcome Measure', 'Pain', 'Patient Outcomes Assessments', 'Patients', 'Pattern', 'Phenotype', 'Prevalence', 'Preventive', 'Preventive treatment', 'Principal Component Analysis', 'Procedures', 'Progress Reports', 'Proteoglycan', 'Relaxation', 'Replacement Arthroplasty', 'Reporting', 'Role', 'Rotation', 'Severities', 'Shapes', 'Structure', 'Subgroup', 'Techniques', 'Time', 'Tissues', 'Water', 'Work', 'automated segmentation', 'base', 'bone', 'cartilage degradation', 'cohort', 'demographics', 'disability', 'disorder risk', 'follow-up', 'functional outcomes', 'gait examination', 'high risk', 'hip replacement arthroplasty', 'innovation', 'insight', 'joint destruction', 'kinematics', 'knee replacement arthroplasty', 'machine learning algorithm', 'multidimensional data', 'novel', 'obese person', 'quantitative imaging', 'rate of change', 'recruit', 'skeletal']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,709418
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10216259,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data repository', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2021,886029
Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring No abstract available n/a,Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring,10331914,R00EB028311,"['Acute respiratory infection', 'Aftercare', 'Amides', 'Amines', 'Animals', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Pneumonia', 'Bar Codes', 'Biological Assay', 'Blinded', 'Blood', 'Classification', 'Clinical', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Drug resistance', 'Early Diagnosis', 'Engineering', 'Enzymes', 'Fingerprint', 'Fluorocarbons', 'Goals', 'Immune response', 'In Vitro', 'Infection', 'Inhalation', 'Leukocyte Elastase', 'Ligands', 'Lung', 'Mass Spectrum Analysis', 'Measures', 'Mentors', 'Methods', 'Monitor', 'Mus', 'Peptide Hydrolases', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Predisposition', 'Pseudomonas aeruginosa', 'Randomized', 'Reporter', 'Research Personnel', 'Resistance', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Sputum', 'Survival Rate', 'System', 'Testing', 'Time', 'Tissues', 'Validation', 'Work', 'antimicrobial drug', 'base', 'classification algorithm', 'cohort', 'diagnostic platform', 'extracellular', 'in vivo', 'in-vivo diagnostics', 'mouse model', 'nanoparticle', 'nanosensors', 'outcome forecast', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'pathogenic virus', 'portability', 'random forest', 'resistant strain', 'respiratory pathogen', 'response', 'urinary', 'ventilator-associated pneumonia', 'volatile organic compound']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R00,2021,249000
"Metal-nutrient mixtures in epidemiologic and toxicologic studies of cardiovascular disease Abstract This proposal is designed to extend and complement our R01-funded case-cohort study of cadmium (Cd) and acute myocardial infarction (AMI). Herein we will add arsenic (As), calcium (Ca), and magnesium (Mg) to our case-cohort study and include epidemiologic and toxicologic mixtures analyses. The four elements we have selected are compelling for their independent role in cardiovascular disease (CVD) and as a mixture. As increases plaque formation and adhesion to endothelium and Cd also induces endothelial dysfunction and atherosclerosis; yet it is not clear if the effects of As and Cd are synergistic or competing. To potentially counteract these processes, Mg is important for modulating endothelial function. While Ca’s role is equivocal, its role in calcification of the arteries is undeniable, making it important to consider as well. Our efficient case-cohort study design includes 810 cases of AMI and a comparison subcohort of 600 men and 600 women selected randomly from never smokers at risk of AMI at the start of follow-up, leveraging the prospective population-based Danish Diet Cancer and Health Cohort. We are already funded to measure Cd, creatinine, osmolality, and cotinine in baseline urine samples. We now propose to additionally analyze As species, Mg, and Ca in urine among ~2000 participants selected into this case-cohort study, along with pre-existing food frequency questionnaire data on Mg and Ca. In Aim 1 we will evaluate the association between each of As, Ca, and Mg, and incidence of AMI. This will be one of the largest prospective studies of these elements in relation to AMI. In Aim 2 we will apply mixtures methods (Bayesian kernel machine regression, weighted quantile sum regression, random forests) to evaluate the interactive and joint effects of Cd, As, Ca, and Mg in relation to AMI risk. In Aim 3 we will apply in vitro and in vivo approaches to study combined effects of exposure to these elements to investigate the toxicologic mechanisms and pathways of activity. Each Aim is independently compelling and will provide important scientific contributions but together the complementary approaches have the potential to provide evidence of consistency in findings across the distinct approaches. Triangulating data across in vitro, in vivo and epidemiologic analyses represents a translational bridge as depicted in the NIEHS translational research framework. The scope of this virtual consortium will enrich our understanding of the relationships between Cd, As, Mg, Ca, and CVD. Other innovative features of our study include leveraging an existing efficient case-cohort design, large sample size, a large number of incident AMI events, controlling for tobacco smoking, in vitro assays of pro-atherogenic mechanisms, and in vivo studies of atherosclerosis. Sources of exposure to these elements are well known, therefore the identification of mixtures of these elements as cardiovascular risk/protective factors can have major implications for the prevention and control of CVD. Public Health Relevance Mechanistic and epidemiologic studies suggest a mixture of elements including cadmium, arsenic, magnesium, and calcium may play an important role in cardiovascular disease as risk and protective factors. We propose to create a virtual consortium to study chemical mixtures of these elements in relation to risk of cardiovascular disease using state-of-the-art techniques in exposure science, epidemiology, biostatistics, and cardio-toxicology. Sources of exposure to these elements are well known, therefore the identification of mixtures of these elements as cardiovascular risk/protective factors can have major implications for the prevention and control of cardiovascular disease.",Metal-nutrient mixtures in epidemiologic and toxicologic studies of cardiovascular disease,10254343,R01ES030938,"['Acute myocardial infarction', 'Adhesions', 'Apolipoprotein E', 'Arsenic', 'Arteries', 'Atherosclerosis', 'Behavioral', 'Biological Markers', 'Biometry', 'Cadmium', 'Calcium', 'Cardiovascular Diseases', 'Cell Adhesion', 'Chemicals', 'Cholesterol', 'Clinical Data', 'Cohort Studies', 'Collection', 'Complement', 'Cotinine', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Elements', 'Endothelial Cells', 'Endothelium', 'Epidemiology', 'Event', 'Exposure to', 'Food', 'Frequencies', 'Funding', 'Generations', 'Health', 'Hypertension', 'In Vitro', 'Incidence', 'Joints', 'Knockout Mice', 'Lipids', 'Magnesium', 'Measures', 'Metals', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Institute of Environmental Health Sciences', 'Nutrient', 'Osmolalities', 'Participant', 'Pathway interactions', 'Physical activity', 'Play', 'Population', 'Prevention', 'Process', 'Prospective Studies', 'Prospective cohort', 'Questionnaires', 'Reactive Oxygen Species', 'Regression Analysis', 'Reporting', 'Research Design', 'Risk', 'Risk Factors', 'Role', 'Sample Size', 'Sampling', 'Science', 'Side', 'Smoking', 'Source', 'Spottings', 'Sum', 'Techniques', 'Tobacco smoking behavior', 'Toxicology', 'Translational Research', 'Urine', 'Woman', 'calcification', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'cohort', 'design', 'diet and cancer', 'endothelial dysfunction', 'epidemiology study', 'follow-up', 'hazard', 'in vitro Assay', 'in vivo', 'innovation', 'macrophage', 'men', 'mortality', 'mouse model', 'never smoker', 'novel', 'population based', 'prospective', 'protective factors', 'public health relevance', 'random forest', 'recruit', 'urinary', 'virtual']",NIEHS,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2021,601096
"Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index Project Summary  Delayed cerebral ischemia (DCI) is the most devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. Only after medical management fails, is endovascular treatment (EVT) including intraarterial vasodilator infusion and/or intracranial angioplasty initiated. This reactive practice does not account for early predictors of DCI and may miss the optimal EVT window at an early stage of DCI development before symptoms or severe deviations from normal hemodynamics. The goal of this project is to develop algorithms to predict DCI and related targets at an early stage in their development. An accurate prediction of DCI will enable a more proactive strategy to prevent and treat the underlying cause of DCI.  The following three aims will be pursued towards the goal of the project: 1) Develop aSAH-specific intracranial pressure (ICP) pulse-based cerebral arterial state index; 2) Develop and validate predictive models of targets related to delayed cerebral ischemia after aSAH; 3) Conduct a prospective institution- specific adaption and validation of the developed models.  Our DCI predictive algorithms only need data available in current clinical practice hence they can be readily adopted. If validated, these algorithms will enable clinicians to monitor risk of DCI continuously and to proactively deliver appropriate treatment. The proposed prospective study of algorithm implementation and adaptation will well prepare future clinical trials to test the efficacy of algorithm-informed interventions. Project Narrative  Delayed cerebral ischemia (DCI) is a devastating complication after aneurysmal subarachnoid hemorrhage (aSAH) and has an incidence rate of 30%. Current practice relies on intermittent assessment of neurological status and daily cerebral blood flow velocity (CBFV) by Transcranial Doppler ultrasound (TCD) to guide medical management to prevent DCI. The goal of this project is to develop algorithms to predict DCI and other related targets at an early stage in their development to enable a more proactive strategy to prevent and treat the underlying cause of DCI.",Learning to Predict Delayed Cerebral Ischemia with Novel Continuous Cerebral Arterial State Index,10251348,R01NS113541,"['Acute', 'Adopted', 'Algorithms', 'Aneurysmal Subarachnoid Hemorrhages', 'Angioplasty', 'Appearance', 'Area', 'Blood Flow Velocity', 'Cerebral Ischemia', 'Cerebral perfusion pressure', 'Cerebrovascular Circulation', 'Cerebrum', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Trials', 'Complication', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Diagnosis', 'Dilatation - action', 'Distal', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Future', 'Goals', 'Hydrocephalus', 'Incidence', 'Individual', 'Infusion procedures', 'Injury', 'Institution', 'Intervention', 'Intracranial Pressure', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Neurologic', 'Neurological status', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Procedures', 'Process', 'Prospective Studies', 'Pulse Pressure', 'Recurrence', 'Reproducibility', 'Research', 'Risk', 'Shapes', 'Signal Transduction', 'Source', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcranial Doppler Ultrasonography', 'Validation', 'Vasodilator Agents', 'base', 'clinical practice', 'constriction', 'data streams', 'diagnostic accuracy', 'efficacy testing', 'electronic data', 'hemodynamics', 'improved', 'indexing', 'machine learning algorithm', 'novel', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'recurrent neural network', 'relating to nervous system', 'temporal measurement', 'vector']",NINDS,DUKE UNIVERSITY,R01,2021,582524
"Combining Voice and Genetic Information to Detect Heterogeneity in Major Depressive Disorder PROJECT SUMMARY This application aims to advance our understanding of major depressive disorder (MDD) by combining genetic information and analyzing speech patterns of those with MDD to identify subtypes. MDD is the leading cause of disability throughout the world, yet, relative to other common disorders, less is known about its origins. There are less effective treatments and much less is spent on trying to understand how it arises and how to cure it. Current treatments are relatively ineffective, with up 50% of patients refractory and many suffering severe recurrence. Understanding the mechanisms underlying MDD has been recognized as a grand challenge in global mental health. Thus, developing new treatments for MDD is a major priority for public health. A major challenge for MDD research is the presence of heterogeneity. The existence of multiple subtypes of MDD has been suspected for a long time, and likely confounds the ability to treat the disorder appropriately with existing treatments, as well as making it hard to identify the causes of MDD as a prelude to developing new treatments. However finding subtypes has been hard. Given that the way people talk can reflect alterations in mood, we expect voice to be able to predict mood, and hence potentially be used as biomarker to recognize heterogeneity. In preliminary data show that in combination with genetic data high-dimensional vocal features extracted from recordings can be used to identify subtypes. Furthermore, the use of genetic data allows us to impute voice features into large biobanks where no recordings exist, making it possible to explore the relationship between vocal features and a rich array of clinically important indicators. We explore the power of voice to make a diagnosis of MDD, to predict severity and other clinical features. Applying our approach to will inform clinical management, improving diagnosis, refine treatment and aid the development of new treatments PROJECT NARRATIVE The research proposed here will contribute to an understanding of major depressive disorder, the commonest psychiatric disorder and a leading cause of disability throughout the world. The proposal will combine information from voice recordings and genetics to identify subtypes of depression and develop robust predictors of mood, severity of illness and other clinical indicators. Our research will thereby provide new insights into disease, and well enable the more effective targeting of therapy to those who will most benefit at the appropriate time.",Combining Voice and Genetic Information to Detect Heterogeneity in Major Depressive Disorder,10238767,R01MH122569,"['Affect', 'Alleles', 'Anxiety', 'Behavioral Genetics', 'Biological Markers', 'Biology', 'Case-Control Studies', 'China', 'Chinese People', 'Classification', 'Clinical', 'Clinical Management', 'Collection', 'Data', 'Data Set', 'Depressed mood', 'Development', 'Diagnosis', 'Disease', 'Disease remission', 'Engineering', 'Ensure', 'Far East', 'Frequencies', 'Genetic', 'Genetic study', 'Genomics', 'Genotype', 'Heritability', 'Heterogeneity', 'Interview', 'Investigation', 'Linkage Disequilibrium', 'Major Depressive Disorder', 'Manuals', 'Maps', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'Morphologic artifacts', 'Neurobiology', 'Participant', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Phenotype', 'Population', 'Psychiatry', 'Psychological Transfer', 'Recurrence', 'Refractory', 'Research', 'Resources', 'Sampling', 'Scheme', 'Severities', 'Severity of illness', 'Signal Transduction', 'Specificity', 'Speech', 'Suicide', 'System', 'Testing', 'Time', 'Ursidae Family', 'Voice', 'Voice Quality', 'Woman', 'accurate diagnosis', 'base', 'biobank', 'clinical application', 'clinical phenotype', 'comorbidity', 'computer science', 'data sharing', 'deep neural network', 'disability', 'disorder subtype', 'effective therapy', 'efficacy evaluation', 'flexibility', 'genetic analysis', 'genetic architecture', 'genetic information', 'genetic predictors', 'improved', 'innovation', 'insight', 'long short term memory', 'multidimensional data', 'neuroimaging', 'preservation', 'psychogenetics', 'public health priorities', 'statistics', 'targeted treatment', 'trait', 'treatment response', 'vector']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,667757
"Meta-analysis in human brain mapping This is the competing renewal of the R01 (MH074457-14) which sustains the BrainMap Project (www.brainmap.org). BrainMap is a neuroimaging research resource facilitating cognitive neuroscience and disease-biomarker discovery via coordinate-based meta-analysis (CBMA). BrainMap provides its end-user community with: curated 3-D coordinate data and experimental metadata from peer-reviewed publications; extensively validated computational tools for CBMA; CBMA-derived tools for data interpretation (e.g., functional property and disease loadings by location) and data analysis (e.g., via CBMA-derived disease models); instructional materials and on-site and on-line venues for learning CBMA methods; and, on-going end-user support. At present, BrainMap.org hosts two coordinate-based databases: task-activation (TA DB) and voxel- based morphometry (VBM DB). A voxel-based physiology database (VBP DB) is in the planning and piloting phase. BrainMap maintains an integrated pipeline of cross-platform (Java) tools for data coding (Scribe), filtered retrieval (Sleuth), activation-likelihood estimation (ALE) CBMA (GingerALE), data visualization (Mango), and data interpretation (CBMA-derived Mango plugins). Multiple network-modeling approaches have been successfully applied to BrainMap data – independent components analysis (ICA), author-topic modeling (ATM), graph-theory modeling (GTM), structural equation modeling (SEM), connectivity-based parcellation (CBP), and meta-analytic connectivity modeling (MACM) – but none are yet optimized and “pipelined” for general use. Utilization of BrainMap resources is substantial: our software, data and meta-data have been used in >1,000 peer-reviewed articles. Of these, > 500 were published in the current funding cycle (2015- 2020). Four aims are proposed, to maintain and extend this high-impact research resource.  Aim 1. Voxel-based Physiology DataBase (VBP DB) with Analysis Exemplars. Aim 2. BrainMap Community Portal for Multivariate Modeling with Applications & Exemplars. Aim 3. Large-scale Parameter Estimations. Aim 4. BrainMap Pipeline Enhancements and Community Support. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data.",Meta-analysis in human brain mapping,10157292,R01MH074457,"['3-Dimensional', 'Address', 'Brain Mapping', 'Categories', 'Code', 'Cognition Disorders', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Disease model', 'Educational workshop', 'Equation', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Java', 'Learning', 'Location', 'Machine Learning', 'Mango - dietary', 'Manuals', 'Mental disorders', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Multivariate Analysis', 'Output', 'Peer Review', 'Phase', 'Physiology', 'Property', 'Publications', 'Publishing', 'Research Domain Criteria', 'Resources', 'Retrieval', 'Site', 'Software Framework', 'Structure', 'Surface', 'Symptoms', 'Taxonomy', 'Texas', 'Training', 'Uncertainty', 'Validation', 'base', 'biomarker discovery', 'case control', 'cognitive neuroscience', 'cohort', 'computerized tools', 'connectome', 'data submission', 'data tools', 'data visualization', 'design', 'experimental study', 'graph theory', 'hemodynamics', 'independent component analysis', 'learning materials', 'lectures', 'morphometry', 'network models', 'neuroimaging', 'simulation', 'webinar']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2021,637306
"A novel technology to assess chronic toxicity in genetically diverse nematode populations Project Abstract The number of new products such as drugs, cosmetics and food additives introduced into the market is growing and poses a significant challenge for risk prediction. Currently, vertebrate testing is the industry standard for hazard assessment but has limitations including high costs, and the growing public and corporate sentiment against using vertebrates for chemical testing. Importantly, current toxicity assessment does not incorporate genetic diversity leading to failure of drug candidates and unintended risks to human sub-populations. The celebrated invertebrate model C. elegans has the potential to fill this gap since thousands of genetically diverse nematode populations are available. However, the main challenge is that chronic studies of chemicals in the nematode model is still tedious, precluding large-scale toxicity testing in nematode populations. This proposal aims to develop a high-throughput technology for chronic toxicity screening of diverse genetic populations in adult C. elegans. The focus of our Phase I plan is to pursue chronic toxicity studies on select toxins and generate foundational data highlighting the impact of genetic diversity, and subsequently scale the NemaLife technology to enable large-scale genetic diversity screening. AIM 1: To generate chronic dose-response data on toxins affecting diverse C. elegans strains. We will test the effects of five toxins for which we know the variability in human and rodent responses. Animals will be exposed to toxins daily, followed by scoring of survival, reproductive and neuromuscular health. About 1200 whole-life assays will be conducted with data acquired on 500+ animals per assay condition. We will generate data that will define the rank-order of C. elegans toxin response vis-à-vis mammalian systems, optimize phenotyping conditions for large numbers of strains per species, and define the amount of heritable variation in toxin responses. These pilot data will validate the capabilities afforded by our screening platform. AIM 2: To scale the throughput of NemaLife Technology for thousands of chronic toxicity assays. Currently, NemaLife’s technology has a throughput of hundreds of chronic toxicity assays. However, given the large number of toxins and vast library of genetic strains and wild isolates available, there is a significant need to increase the throughput of our technology. Therefore, we will develop the technology infrastructure and workflow to scale the throughput which includes multiplexing our approach, scale-up of chip fabrication and streamlining data analysis. Technology development at the scale of thousands of whole-life toxicity assays in a few weeks with readouts on animal death and neuromuscular impairments will be a major breakthrough in the field opening up new business opportunities in toxicity testing in the drug and consumer industry. Project Narrative Non-parasitic nematodes offer a powerful in vivo model to scale and measure toxin responses in genetically diverse species anchoring a transformative means to bridge current gaps in predictive toxicology with clinically-relevant end points. Our study aims to combine state-of-the art advances in microfluidics, computer vision, laboratory automation and a massively curated genetically diverse nematode species to produce a new screening approach capable of testing thousands of chemicals relevant to agriculture, nutraceutical and biotech markets.",A novel technology to assess chronic toxicity in genetically diverse nematode populations,10112054,R43ES032516,"['Adult', 'Affect', 'Agriculture', 'Animals', 'Arsenic', 'Automation', 'Biological Assay', 'Biotechnology', 'Businesses', 'Cadmium', 'Caenorhabditis elegans', 'Cells', 'Cessation of life', 'Chemicals', 'Chronic', 'Clinical Trials', 'Computer Vision Systems', 'Cosmetics', 'Data', 'Data Analyses', 'Dose', 'Environment', 'Exposure to', 'Failure', 'Food Additives', 'Foundations', 'Gait', 'Gene Library', 'Genetic Models', 'Genetic Variation', 'Genome', 'Hazard Assessment', 'Health', 'Heritability', 'Human', 'Impairment', 'Industry', 'Industry Standard', 'Infrastructure', 'Invertebrates', 'Laboratories', 'Life', 'Life Cycle Stages', 'Liquid substance', 'Maintenance', 'Measures', 'Metformin', 'Methods', 'Microfluidics', 'Modeling', 'Molecular', 'Nematoda', 'Nutraceutical', 'Paraquat', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Predisposition', 'Public Health', 'Risk', 'Rodent', 'Safety', 'System', 'Technology', 'Testing', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Toxin', 'Variant', 'Vertebrates', 'Work', 'base', 'clinically relevant', 'cost', 'drug candidate', 'genetic resource', 'genetic strain', 'high throughput technology', 'in vivo Model', 'neuromuscular', 'new technology', 'reproductive', 'resistant strain', 'response', 'risk prediction', 'scale up', 'screening', 'technology development']",NIEHS,NEMALIFE INC.,R43,2021,251040
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring Abstract  Building on its commercially available Absolute Q digital PCR platform, during the 24-month Phase 2 SBIR project, Combinati will complete the development of the first Digital Melt Curve Analysis (DMCA) platform to the market to further advance the adoption of digital genomics for highly accurate, sensitive and reproducible nucleic acid quantification for longitudinal patient monitoring. To provide the “whole product” solution and prove the function, we will demonstrate the DMCA platform with Luminex’s 11- plex ESR1 (Estrogen Receptor 1) assay and conduct Beta testing at Dana Farber Cancer Institute: 1. Three beta instruments and the analysis software capable of digital melt curve analysis. 2. Complete dMCA validation internally with commercially available melt calibration kits. 3. Demonstrate <0.1% Mutation Allele Frequency of 11 cell-free DNA targets using Luminex  Corporation’s discrete melt assay. 4. Beta testing at Dana Farber Cancer Institute Narrative  Since PCR was invented back in 1983, it has become the gold standard for applications requiring quantification of nucleic acids. The continuous evolution of the technology enables PCR to be more quantitative (qPCR), more accurate, precise and reproducible (digital PCR). In parallel, with the invention of melt curve analysis in 1997, it opens another dimension in melt temperatures for applications requiring simple and inexpensive genotyping, high degree qualitative multiplexing without sequencing, and assay optimization. Despite that there is a handful of dPCR platforms in the market, none of them supports Melt Curve Analysis. By combining melt curve analysis with digital PCR, Combinati strives to accelerate the adoption of digital genomics for all nucleic acid quantification needs in research and clinical markets.",Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring,10256226,R44CA261523,"['Adopted', 'Adoption', 'Architecture', 'Back', 'Biological Assay', 'Blinded', 'Breast Cancer Patient', 'Calibration', 'Cancer Patient', 'Chemistry', 'Clinical', 'Collection', 'Color', 'Computer software', 'Computers', 'DNA', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'ESR1 gene', 'Evolution', 'Gene Frequency', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Journals', 'Letters', 'Light', 'Mainstreaming', 'Manuscripts', 'Mechanics', 'Memory', 'Metastatic breast cancer', 'Microfluidics', 'Monitor', 'Mutation', 'Nucleic Acids', 'Optics', 'Oranges', 'Patient Monitoring', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Running', 'Sampling', 'Science', 'Small Business Innovation Research Grant', 'Source', 'Speed', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Validation', 'cell free DNA', 'clinically relevant', 'cost', 'cyanine dye 5', 'data exchange', 'design', 'detection limit', 'digital', 'fluorescence imaging', 'graphical user interface', 'image processing', 'improved', 'instrument', 'invention', 'lens', 'liquid biopsy', 'machine learning algorithm', 'meetings', 'melting', 'multidimensional data', 'mutant', 'mutation assay', 'neural network', 'product development', 'sensor', 'simulation']",NCI,"COMBINATI, INC.",R44,2021,772720
"Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles PROJECT SUMMARY Genomic and other “omic” profiles hold immense potential for advancing personalize/precision medicine by enabling the accurate prediction of disease phenotypes or outcomes for individual patients, which can be used by a clinician to design an appropriate plan of care. However, despite this potential, the actual impact of these omic profiles on disease phenotype prediction may be limited by the fact that even large cohorts collecting these data do not cover large enough numbers of individuals. In contrast, a variety of clinical data types, such as laboratory tests and physician notes, are routinely collected and studied for a much larger number of patients undergoing treatment for such diseases at medical centers. The abundance of these clinical data, and their complementarity with multi-omic data, offer an opportunity to advance personalized medicine by integrating these disparate types of data. However, this disparity in data formats, namely several omic profiles being structured, and several clinical data types, such as physician notes, being unstructured, poses challenges for this integration. An associated challenge due to this disparity is that different classes of computational methods are likely to be the most effective for predicting disease phenotypes from these clinical and omics datasets. These challenges pose barriers for current data integration methods to address this problem. Here, we propose an innovative approach to this integration by assimilating diverse base phenotype predictors inferred from individual clinical and omics datasets into heterogeneous ensembles. These ensembles, which have shown promise for several other computational genomics problems, can aggregate an unrestricted number and variety of base predictors, which is ideal for this integration problem. Specifically, we describe how existing heterogeneous ensemble methods for single datasets can be transformed and advanced to address the multiple clinical and omic dataset integration problem. In particular, we detail novel algorithms for improving these integrative ensembles by modeling and incorporating the inherent patient and dataset heterogeneity in these datasets. We also propose novel algorithms for leveraging the inherent complementarity among clinical and omic datasets, as well as an innovative approach for handling expected missing data, both with the goal of making ensemble phenotype predictors more accurate and applicable to patient cohorts. To assess the performance of this novel suite of data integration-oriented heterogeneous ensembles, we will validate their effectiveness for predicting asthma and Inflammatory Bowel Disease phenotypes in substantial patient cohorts with diverse omics and clinical datasets. We will publicly release efficient software implementations of the methods developed in this project to enable others to carry out similar analyses with other diverse data collections. Successful accomplishment of the proposed work will contribute to the advancement of personalized medicine through accurate individualized prediction of disease phenotypes. Predictive modeling is expected to become a cornerstone on the path to achieving precision/personalized medicine, as one of the key tasks here will be making individualized predictions of disease characteristics/phenotypes like subtype and risk of progression and/or recurrence. We propose several innovative computational algorithms for developing accurate predictive models that integrate diverse clinical and omic data, as well as several rigorous validation exercises that will demonstrate the capabilities of these models. Successful accomplishment of the proposed work will contribute to the advancement of personalized/precision medicine through more accurate individualized prediction of disease characteristics.",Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles,10218766,R01HG011407,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Disease', 'Disease Outcome', 'Docking', 'Effectiveness', 'Electronic Health Record', 'Encapsulated', 'Exercise', 'Genomics', 'Goals', 'Health', 'Individual', 'Inflammatory Bowel Diseases', 'Institution', 'Laboratories', 'Learning', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Patients', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Recurrence', 'Research Personnel', 'Risk', 'Sampling', 'Structure', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Validation', 'Variant', 'Work', 'advanced disease', 'base', 'clinical phenotype', 'cohort', 'data format', 'data integration', 'deep learning', 'design', 'disease phenotype', 'diverse data', 'feature selection', 'flexibility', 'genomic data', 'heterogenous data', 'improved', 'individual patient', 'innovation', 'insight', 'member', 'multiple datasets', 'multiple omics', 'multitask', 'novel', 'novel strategies', 'outreach', 'patient population', 'personalized medicine', 'personalized predictions', 'precision medicine', 'predictive modeling', 'programs', 'rapid growth', 'repository', 'scale up', 'transcriptomics', 'vector']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,539951
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"Consortium for Immunotherapeutics against Emerging Viral Threats SUMMARY: OVERALL  This proposal, Consortium for Immunotherapeutics Against Emerging Viral Diseases, addresses a critical gap in the biodefense portfolio by building an academic-industry partnership to advance effective, fully human, antibody-based immunotherapeutics against three major families of emerging/re-emerging viruses: Lassa virus, Ebola and other Filoviruses, and mosquito-transmitted Alphaviruses that threaten millions worldwide. This program follows directly from our significant body of preliminary data (the largest available for these families of viruses), therapeutics in hand, multidisciplinary expertise, and demonstrated collaborative success. Included in the proposed CETR portfolio are: (1) the only available immunotherapeutics against endemic Lassa virus, with reversal of late-stage disease and complete survival in infected non-human primates, (2) novel Ebola and pan- ebolavirus therapeutics that also completely protect non-human primates from disease, and that were built by the paradigm-shifting and comprehensive analysis of a global consortium, and (3) much needed, first-in-class therapeutics against the re-emerging alphaviruses that have tremendous epidemic potential in the United States and around the globe. These multidisciplinary studies, founded upon pioneering structural biology of the antigen targets, include innovations such as agnostic, high-throughput Fc profiling and optimization, coupled with Fv evolution to enhance potency and developability, as well as a sophisticated statistical and computational analysis core to evaluate thresholds and correlates of protection across the major families of pathogens. Together, we aim to understand what findings represent general rules and what data are specific to each virus family. We also aim to provide streamlined systems for antibody choice and optimization that do not yet exist, and to build a broadly applicable platform for mAb discovery and delivery against any novel pathogen as they emerge. The recent resurgence of Lassa, the epidemic nature of Ebola virus and other re-emerging filoviruses, as well as the major population at risk by global movement of mosquito-borne alphaviruses together demonstrate the tremendous global need for immunotherapeutics developed and advanced by this program. NARRATIVE Three major families of emerging viruses (Lassa and other arenaviruses, Ebola and other filoviruses, and mosquito-borne alphaviruses) threaten human health worldwide, but lack approved therapeutics or vaccines. The proposed multidisciplinary consortium, an academic-industry partnership, will advance safe and effective, fully human, monoclonal antibody therapies against these viruses, using candidate therapies that confer complete protection in non-human primates as our starting point. Our collaborative databases, multivariate analyses and innovative antibody optimization strategies will establish platforms for discovery and delivery of much-needed treatments against these and other infectious diseases.",Consortium for Immunotherapeutics against Emerging Viral Threats,10158446,U19AI142790,"['Address', 'Alphavirus', 'Antibodies', 'Antigen Targeting', 'Arenavirus', 'Arthritogenic', 'Biological Assay', 'Communicable Diseases', 'Computer Analysis', 'Computer Models', 'Computing Methodologies', 'Coupled', 'Culicidae', 'Data', 'Databases', 'Developed Countries', 'Developing Countries', 'Disease', 'Ebola', 'Ebola virus', 'Epidemic', 'Evolution', 'Family', 'Filovirus', 'Fostering', 'Goals', 'Hand', 'Health', 'Human', 'Immune', 'Immunotherapeutic agent', 'Lassa virus', 'Machine Learning', 'Mathematics', 'Mediating', 'Monoclonal Antibodies', 'Monoclonal Antibody Therapy', 'Movement', 'Multivariate Analysis', 'Nature', 'Populations at Risk', 'Primate Diseases', 'Reagent', 'Research Project Grants', 'Resources', 'Statistical Data Interpretation', 'System', 'Talents', 'Testing', 'Therapeutic', 'Therapeutic Monoclonal Antibodies', 'Translating', 'Translations', 'United States', 'Vaccines', 'Viral', 'Virus', 'Virus Diseases', 'base', 'biodefense', 'chikungunya', 'clinical development', 'design', 'experience', 'human monoclonal antibodies', 'improved', 'industry partner', 'innovation', 'insight', 'mosquito-borne', 'multidisciplinary', 'nonhuman primate', 'novel', 'pandemic disease', 'pathogen', 'programs', 'research study', 'structural biology', 'success', 'synergism', 'tool']",NIAID,LA JOLLA INSTITUTE FOR IMMUNOLOGY,U19,2021,7065330
"The plasticity of well-being:  A research network to define, measure and promote human flourishing PROJECT SUMMARY/ABSTRACT This U24 application is written in response to RFA-AT-20-003 to establish a high-priority research network on emotional well-being (EWB). While psychological research on well-being has dramatically increased over the past 15 years, virtually all of this work has been descriptive and has not emphasized the “how” of well-being: How might well-being be cultivated? In addition, virtually all of the extant work on the correlates of individual differences in well-being has used responses on retrospective questionnaires as the primary tool to assess well-being. While there have been exciting findings, particularly relating individual differences in well-being to various indices of physical health, many questions remain and methodological limitations plague the validity of this work. This U24 network will assemble a highly multi-disciplinary group of 10 investigators across 3 (or more in the future) institutions to significantly advance our understanding of the “how” of EWB, identify the core plastic constituents of EWB, specify and/or develop robust measures of these constituents at biological, behavioral and experiential levels of analysis and characterize the plasticity of these constituents. The measurement strategy will ultimately focus on the development of technology-based passive measures of EWB that require no explicit user input and are highly scalable. The network will also focus its efforts on the development and evaluation of programs to train EWB and will assess whether such programs might serve as prevention strategies. The network will consist of scientists and scholars from a broad range of fields including psychology, neuroscience, electrical and computer engineering, population health and biology, computer science and the humanities. These scientists and scholars will focus on the following major aims: Aim 1: To arrive at a core consensus of the minimal set of constituents that can be described and measured at biological, behavioral and experiential levels that constitute the plastic elements of EWB and to specify already existing measures and /or develop novel measures of each of these constructs at each level of analysis. Aim 2: Using the active measures described in Aim 1, to develop passive measures using digital technologies of at least two of the core constituents of well-being. Aim 3: To develop pilot projects specifically focusing on prevention strategies for learning well-being in various samples. The network will train new investigators and bring established investigators into this new field, disseminate a framework for understanding the plasticity of well- being, a toolbox of measures for assessing the plasticity of components of well-being, and several pilot datasets that showcase the novel passive and field-friendly biological measures. In these ways, the network will dramatically accelerate progress in the nascent field of EWB. PROJECT NARRATIVE This U24 network on emotional well-being (EWB) will catalyze the emerging field of the plasticity of well-being and will showcase how well-being can be learned and the consequences of such skill development on physical and emotional health and on prevention of disease. A framework for understanding how well-being can be learned along with measures of the core components of well-being that can be learned will be developed and disseminated. The network will also train new investigators in this area and will engage established investigators to contribute to this field.","The plasticity of well-being:  A research network to define, measure and promote human flourishing",10151850,U24AT011289,"['Area', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Biological', 'Cellular Phone', 'Communities', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Distal', 'Drug abuse', 'Elements', 'Emotional', 'Engineering', 'Face', 'Future', 'Gold', 'Grant', 'Health', 'Human', 'Humanities', 'Individual Differences', 'Institution', 'Interruption', 'Literature', 'Measurement', 'Measures', 'Mental Depression', 'Methodology', 'Mind', 'Modernization', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Personal Satisfaction', 'Pilot Projects', 'Plague', 'Population Biology', 'Prevention strategy', 'Program Evaluation', 'Psychology', 'Publications', 'Questionnaires', 'Randomized Controlled Trials', 'Regulation', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specific qualifier value', 'Subgroup', 'Techniques', 'Technology', 'To specify', 'Training', 'Well in self', 'Work', 'base', 'computer science', 'cost', 'digital', 'disorder prevention', 'indexing', 'learning strategy', 'mHealth', 'machine learning algorithm', 'meetings', 'member', 'mindfulness meditation', 'multidisciplinary', 'novel', 'physical conditioning', 'population health', 'prevent', 'programs', 'psychologic', 'response', 'skill acquisition', 'social', 'standard measure', 'technology development', 'tool', 'virtual', 'web site']",NCCIH,UNIVERSITY OF WISCONSIN-MADISON,U24,2021,30000
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,10168611,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,315727
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,10168488,R37DA009757,"['Address', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'substance use treatment', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2021,360584
"Developing Computational Methods for Surveillance of Antimicrobial Resistant Agents PROJECT ABSTRACT  Antimicrobial resistance is a critical public health issue. Infections with drug resistant pathogens are estimated to cause an additional eight million hospitalization days annually over the hospitalizations that would be seen for infections with susceptible agents. The use of antibiotics (in both clinical and agricultural settings) is being viewed as precursor for these infections and thus, is a major public health concern—particularly as outbreaks become more frequent and severe. However, scientiﬁc evidence describing the hazards associated with antibiotic use is lacking due to inability to quantify the risk of these practices. One promising avenue to elucidate this risk is to use shotgun metagenomics to identify the AMR genes in samples taken through systematic spatiotemporal surveillance. The goal of this proposed work is to develop algorithms that will provide such a means for analysis. The algorithms need to be scalable to very large datasets and thus, will require the development and use succinct data structures.  In order to achieve this goal, the investigative team will develop the theoretical foundations and applied meth- ods needed to study AMR through the use of shotgun metagenomics. A major focus of the proposed work is developing algorithms that can handle very large datasets. To achieve this scalability, we will create novel means to create, compress, reconstruct and update very large de Bruijn graphs that metagenomics data in a manner needed to study AMR. In addition, we will pioneer the study of AMR through long read data by proposing new algorithmic problems and solutions that use data. For example, identifying the location of speciﬁc genes in a metagenomics sample using long read data has not been proposed or studied. Thus, the algorithmic ideas and techniques developed in this project will not only advance the study of AMR, but contribute to the growing domain of big data analysis and pan-genomics.  Lastly, we plan to apply our methods to samples collected from both agricultural and clinical settings in Florida. Analysis of preliminary and new data will allow us to conclude about (1) the public risk associated with antimicro- bial use in agriculture; (2) the effectiveness of interventions used to reduce resistant bacteria, and lastly, (3) the factors that allow resistant bacteria to grow, thrive and evolve. A–1 PROJECT NARRATIVE  Antibiotic use in agriculture is a major public health concern that is receiving a lot of media attention, par- ticularly as antibiotic-resistant infections in become more frequent and severe. This research will build a novel bioinformatics framework for determining how antimicrobial resistant genes evolve, grow, and persist in a system that has been affected by antibiotic use. This will, in turn, facilitate the development of effective intervention methods that reduce resistant pathogens in clinical and agricultural settings. N–1",Developing Computational Methods for Surveillance of Antimicrobial Resistant Agents,10053321,R01AI141810,"['Affect', 'Agriculture', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Attention', 'Bacteria', 'Base Pairing', 'Big Data', 'Bioinformatics', 'Clinical', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Compression', 'Data Set', 'Development', 'Disease Outbreaks', 'Effectiveness of Interventions', 'Florida', 'Food production', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Graph', 'Hospitalization', 'Infection', 'International', 'Investigation', 'Length', 'Location', 'Measures', 'Memory', 'Metagenomics', 'Methods', 'Monitor', 'Noise', 'Organism', 'Pathogenicity', 'Plasmids', 'Prevention', 'Public Health', 'Research', 'Resistance', 'Risk', 'Sampling', 'Shotguns', 'Structure', 'Surveillance Methods', 'System', 'Techniques', 'Time', 'Translating', 'Update', 'Work', 'antibiotic resistant infections', 'bacterial resistance', 'base', 'combinatorial', 'drug resistant pathogen', 'effective intervention', 'foodborne outbreak', 'genetic variant', 'hazard', 'improved', 'large datasets', 'machine learning algorithm', 'method development', 'microbial', 'microbiome analysis', 'microbiome research', 'multiple datasets', 'novel', 'pathogen', 'petabyte', 'reconstruction', 'research and development', 'resistance gene', 'spatiotemporal', 'standard care']",NIAID,UNIVERSITY OF FLORIDA,R01,2021,422334
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10263268,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'dietary', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,317579
"High Throughput Screen and High Information Follow-Up Tests for Genotoxicants Project Summary  Current batteries of genetic toxicology assays exhibit several critical deficiencies. First, the throughput capacity of in vitro genotoxicity tests is low, and does not meet current needs, especially for early, high volume screening environments that need to prioritize chemicals for further testing and/or development. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no information provided about genotoxic mode of action. This is severely limiting, as it does not generate key information necessary for prioritizing chemicals for further testing, guiding subsequent assays’ endpoints/experimental designs, or conducting risk assessments. Finally, most current assays do not place requisite emphasis on dose response relationships, and therefore do not contextualize the results in terms of potency. These deficiencies prevent genotoxicity data from optimally contributing to modern risk assessments, where all of these capabilities and high information content are essential. We will solve these issues by developing, optimizing, and validating a two-tiered testing strategy based on multiplexed DNA damage responsive biomarkers and high-speed flow cytometric analysis. The first-tier focuses on throughput and is used to prioritize likely genotoxicants for more comprehensive analysis in second tier testing. Specifically, it involves a collection of several multiplexed biomarkers that will be used to identify likely genotoxic agents and provide a preliminary assessment of genotoxic mode of action. The gH2AX biomarker detects DNA double strand breaks, phospho-histone H3 identifies mitotic cells, nuclear p53 content reports on p53 activation in response to DNA damage, the frequency of 8n+ cells measure polyploidization, and the ratio of nuclei to microsphere counts provides information about treatment-related cytotoxicity. The second tier focuses on information content and considers many more concentrations as well as additional biomarkers, including micronucleus formation. Collectively, the tier two results provide definitive predictions about test chemicals’ genotoxic potential, mode of action, and potency. Over the course of this project we will study more than 3,000 diverse chemicals in order to understand the performance characteristics and generalizability of the two-tiered testing strategy. An interlaboratory trial will be conducted with prototype assay kits to assess the transferability of the methods, with the ultimate goal of providing the Nation with commercially available kits and testing services. Project Narrative Some chemicals in commercial use and in the environment can cause DNA damage and this damage can contribute to the development of cancer and other severe diseases. We will develop, optimize, and validate an improved testing strategy based on highly automated processes tracking several DNA damage biomarkers that can be analyzed without the need for animal testing. These methods will be configured into commercially available kits and testing services.",High Throughput Screen and High Information Follow-Up Tests for Genotoxicants,10255405,R44ES033138,"['Address', 'Animal Testing', 'Biological Assay', 'Biological Markers', 'Buffers', 'Canada', 'Cell Line', 'Cell Nucleus', 'Cells', 'Characteristics', 'Chemicals', 'Code', 'Collection', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Elements', 'End Point Assay', 'Environment', 'Exhibits', 'Experimental Designs', 'Flow Cytometry', 'Formulation', 'Frequencies', 'Goals', 'Health', 'Histone H3', 'Human', 'In Vitro', 'Industry', 'Logistics', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metabolic Activation', 'Methods', 'Microspheres', 'Miniaturization', 'Mitotic', 'Modeling', 'Modernization', 'Mutagenicity Tests', 'Mutagens', 'National Toxicology Program', 'Nuclear', 'Performance', 'Phase', 'Process', 'Protease Inhibitor', 'Reagent', 'Recommendation', 'Reporting', 'Risk Assessment', 'Sampling', 'Scheme', 'Sensitivity and Specificity', 'Speed', 'Statistical Data Interpretation', 'System', 'TP53 gene', 'Techniques', 'Temperature', 'Testing', 'Time', 'Toxicogenetics', 'Toxicology', 'Training', 'Validation', 'Work', 'base', 'blind', 'cell type', 'climate change', 'computerized tools', 'cytotoxicity', 'design', 'experimental study', 'follow-up', 'genotoxicity', 'high throughput screening', 'improved', 'innovation', 'instrumentation', 'micronucleus', 'phosphatase inhibitor', 'prevent', 'programs', 'prototype', 'response', 'response biomarker', 'screening', 'testing services']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2021,204743
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,10085664,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'detection limit', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,305167
"Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine The overall goal of this project is to develop a safe, broadly effective, and affordable vaccine to prevent group A streptococcal infections. Antibodies against the N-terminal hypervariable region (HVR) of surface M (Emm) proteins of GAS are opsonic and are associated with protection against infection. Immunity has classically been described as “type-specific”, leading to the assumption that natural immunity confers protection against only one of the more than 200 different emm types of GAS. We now have new information that calls into question this classic view and serves as the basis for an entirely different approach to GAS vaccine design and development. A recent comprehensive sequence analysis of M proteins from a global collection of 175 emm types of GAS resulted in a new emm cluster typing system that classified 96.2% of all contemporary GAS isolates into 48 emm clusters containing structurally and functionally related M proteins. Moreover, 117 emm types contained in 16 clusters accounted for 94.4% of GAS infections in the world. Indeed, preclinical studies indicated that a multivalent vaccine containing N-terminal peptides from 30 prevalent M types cross-opsonized a significant number of non-vaccine emm types of GAS that co-localized in clusters with vaccine emm types. The frequency of cross-opsonic antibodies, combined with the emm cluster data, prompted us to conclude that there is a need for a paradigm shift away from the concept of “type-specific” immunity against GAS infections to one of “cluster-specific” immunity. Our overall hypothesis is that immunity to GAS infections is the result of both type-specific and cross-reactive antibodies against the N-terminal regions of M proteins and that a new approach employing computational predictions of peptide structures will result in a multivalent vaccine that will induce broadly protective immunity in populations throughout the world. Our preliminary results indicate the feasibility of using structure-based design to predict the antigenic relatedness of M peptides within a cluster. The specific aims of this proposal are to: 1) Apply computational structure-based design in an iterative process with immunological data from Aim 2 to predict the minimal number of M peptide sequences that are most representative of the structural and physicochemical properties of the peptides in one emm cluster containing 17 GAS emm types, 2) determine the cross-reactive immunogenicity of the selected peptides with all seventeen emm types of GAS in the cluster, and apply the results to refine the computational design predictions in Aim 1, 3) apply the refined computational parameters from Aims 1 and 2 to analyze the remaining epidemiologically important emm clusters, select a comprehensive panel of peptides representing all emm types, construct four multivalent recombinant vaccine proteins, and assess potential cross-protective immunogenicity using in vitro bactericidal assays against all 117 emm types of GAS, and 4) determine the protective immunogenicity of the final multivalent vaccine in unique transgenic mice expressing human C4BP and factor H that will be immunized and then challenged with multiple emm types of GAS. The world needs an effective, safe and affordable vaccine to prevent group A streptococcal (GAS) infections. Although most GAS infections are mild, there are more than 18 million people with a chronic complication of a severe GAS disease worldwide, over 15 million of whom have rheumatic heart disease, another 2 million cases of severe disease occur each year and a total of 517,000 deaths annually are estimated to be due to this organism. Vaccine prevention of even a fraction of these life-threatening diseases could have a significant impact on the health of people around the world.",Structure-Based Design of a Broadly Protective Group A Streptococcal Vaccine,10183147,R01AI132117,"['Animals', 'Antibodies', 'Bacteria', 'Base Sequence', 'Binding', 'Biological Assay', 'Cell surface', 'Cells', 'Cessation of life', 'Chronic', 'Collection', 'Complement Factor H', 'Complementarity Determining Regions', 'Complication', 'Computer Analysis', 'Data', 'Development', 'Disease', 'Ensure', 'Enzyme-Linked Immunosorbent Assay', 'Epidemiology', 'Epitopes', 'Frequencies', 'Goals', 'Health', 'Human', 'Immune', 'Immune Sera', 'Immunity', 'Immunize', 'Immunologics', 'In Vitro', 'Infection', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Mus', 'N-terminal', 'Natural Immunity', 'Organism', 'Oryctolagus cuniculus', 'Peptide Vaccines', 'Peptide antibodies', 'Peptides', 'Population', 'Prevention', 'Process', 'Property', 'Proteins', 'Recombinant Vaccines', 'Recombinants', 'Rheumatic Heart Disease', 'Sequence Analysis', 'Streptococcal Infections', 'Streptococcal Vaccines', 'Streptococcus pyogenes', 'Structure', 'Surface', 'System', 'Testing', 'Transgenic Mice', 'Vaccine Antigen', 'Vaccine Design', 'Vaccines', 'bactericide', 'base', 'cross reactivity', 'design', 'experimental study', 'flexibility', 'hybrid protein', 'immunogenic', 'immunogenicity', 'innovation', 'molecular dynamics', 'multiple myeloma M Protein', 'novel', 'novel strategies', 'peptide structure', 'preclinical study', 'prevent', 'protein aminoacid sequence', 'protein structure', 'retinal S antigen peptide M', 'synthetic peptide', 'tool', 'vaccine development', 'vaccine evaluation']",NIAID,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R01,2021,729285
"Macrophage Phenotype Transition as the Biological Mechanism of Chronic Wound Healing Treated with Non-Thermal, Non-Cavitational Therapeutic Ultrasound PROJECT SUMMARY/ ABSTRACT Chronic wounds affect approximately 6.5 million patients in the United States. Current standard protocols for wound management do not guarantee healing and focus on maintaining a wound environment that is conducive to passive self-healing. Hence, there is a need to develop alternative treatments that promote active healing and shorten healing time leading to reduced costs. We have previously reported that treatment with low-frequency (20-100 kHz), low-intensity (50-150 mW/cm2) ultrasound (LFLI US) significantly (p<0.03) reduces venous ulcer size in vivo as compared to wounds treated with a sham device. This proposal aims at determining the biological mechanisms by which LFLI US promotes chronic wound healing in vitro. There is evidence that the cause of impaired healing is the dysregulation of macrophage phenotype, especially the defective transition from pro- inflammatory (M1) to pro-healing (M2) macrophages. Our characterization of tissue debrided from chronic wounds has shown that healing chronic wounds contain higher proportions of M1-like than M2- like macrophages. Additionally, the signaling protein Rac2, downstream of integrin and focal adhesion kinase activation, is a key regulator of mechanotransduction in macrophages and facilitates the transition of macrophages from the M1 to M2 phenotype. The proposed study will systematically examine the effects of LFLI ultrasound on macrophage phenotype, using macrophages cultured in three-dimensional (3D) scaffolds. We hypothesize that LFLI US directly and indirectly stimulates the transition of pro-inflammatory M1 macrophages to pro-healing M2 macrophages via Rac2. This project will enhance our understanding of chronic wound healing and the potential of therapeutic ultrasound to accelerate healing. Aim 1 will elucidate the direct effects of LFLI US on macrophage function and phenotype by treating inflammatory macrophages directly with LFLI US and characterizing functional changes (proliferation, migration, and phagocytosis), protein/cytokine secretion, and gene expression. Concurrently, we will validate Rac2 as the potential mechanotransduction pathway which promotes M1 to M2 macrophages transition by analyzing integrins, focal adhesion kinases, and Rac2 via confocal microscopy and RNA characterization. [Aim 2 will validate the in vitro findings from Aim 1 using our previously developed diagnostic M1/M2 score on debrided tissue from chronic wound patients treated with LFLI US.] Aim 3 will elucidate the indirect effects of LFLI US on macrophage function and phenotype via a 3D macrophage fibroblast co-culture. The results of this study will inform the optimal design of LFLI ultrasound therapy protocols, lead to a personalized, active treatment for chronic wounds, accelerate chronic wound healing, and contribute to reduced annual wound care costs. Project Narrative Chronic wounds currently affect approximately 6.5 million patients in the United States and an excess of 25 billion dollars is spent annually on treatment. Current standards of care for chronic wounds, including months of weekly re-dressings and debridement, fails to guarantee active wound healing or closure. To address this issue, we propose to determine the biological mechanism responsible for therapeutic ultrasound mediated healing, low-intensity (<100mW/cm2), low-frequency (20kHz) ultrasound that has been shown to accelerate chronic wound closure in pilot clinical studies.","Macrophage Phenotype Transition as the Biological Mechanism of Chronic Wound Healing Treated with Non-Thermal, Non-Cavitational Therapeutic Ultrasound",10137782,F31AR074847,"['3-Dimensional', 'Address', 'Adhesions', 'Affect', 'Biological', 'Cells', 'Chronic', 'Chronic Care', 'Clinical Research', 'Clinical Trials', 'Coculture Techniques', 'Confocal Microscopy', 'Debridement', 'Devices', 'Diagnostic', 'Enzyme-Linked Immunosorbent Assay', 'Exhibits', 'Extracellular Matrix', 'Fibroblasts', 'Focal Adhesion Kinase 1', 'Frequencies', 'Gene Expression', 'Genes', 'Goals', 'Human', 'Impaired healing', 'In Vitro', 'Inflammation', 'Inflammatory', 'Integrins', 'Lead', 'Mechanics', 'Mediating', 'Pathway interactions', 'Patients', 'Phagocytosis', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Play', 'Process', 'Proteins', 'Protocols documentation', 'Prunella vulgaris', 'RNA', 'RNA analysis', 'Reporting', 'Role', 'Signaling Protein', 'Source', 'Sterile coverings', 'Stimulus', 'Therapeutic', 'Time', 'Tissues', 'Ultrasonic Therapy', 'Ultrasonography', 'United States', 'Varicose Ulcer', 'active method', 'alternative treatment', 'angiogenesis', 'behavioral phenotyping', 'care costs', 'cell type', 'chronic wound', 'cost', 'cytokine', 'design', 'diabetic ulcer', 'healing', 'human tissue', 'in vivo', 'knock-down', 'machine learning algorithm', 'macrophage', 'mechanotransduction', 'migration', 'rac2 GTP-binding protein', 'scaffold', 'three dimensional cell culture', 'wound', 'wound care', 'wound closure', 'wound environment', 'wound healing', 'wound treatment']",NIAMS,DREXEL UNIVERSITY,F31,2021,46036
"Pro-inflammatory activation of human macrophages regulated by lncRNAs Project Summary Macrophage activation promotes major inflammatory disorders, including arterial diseases. Its underlying mechanisms, however, remain obscure. The present study will establish a systems approach, involving computational prediction analyses, multi-omics, network science, and in vitro and in vivo validation, to discover long noncoding RNA (lncRNA)-mediated mechanisms for pro-inflammatory activation of macrophages and arterial disease. In Specific Aim 1, we will involve omics studies of human macrophages to identify lncRNAs and their interacting proteins and develop computational analyses to predict human lncRNAs that regulate macrophage activation. Specific Aim 2 will examine the functionality of candidate lncRNAs in macrophage activation in vitro and in vivo. The findings from the study will help to identify new mechanisms for macrophage activation and may provide molecular bases for new therapies. Project Narrative Inflammation plays a key role in coronary artery disease and other major vascular diseases, global health threats. Even with potent risk modifiers, e.g., statins, many patients still suffer vascular events. Long noncoding RNAs (lncRNAs) regulate various biological processes. We aim to discover lncRNAs that promotes vascular inflammation. The potential outcomes will offer new targets for much needed therapies for vascular diseases.",Pro-inflammatory activation of human macrophages regulated by lncRNAs,10199025,R01HL149302,"['Address', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Vessels', 'Cells', 'Communities', 'Complex', 'Computational Biology', 'Computer Analysis', 'Coronary Arteriosclerosis', 'Data', 'Development', 'Discipline', 'Disease', 'Drug usage', 'Endotoxemia', 'Event', 'Gene Expression Profiling', 'Goals', 'Hematopoietic Stem Cell Transplantation', 'Heterogeneity', 'Human', 'In Vitro', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lesion', 'Leukocytes', 'Life', 'Link', 'Machine Learning', 'Macrophage Activation', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Myocardial', 'NF-kappa B', 'Network-based', 'Outcome', 'Pathway Analysis', 'Patients', 'Plasma', 'Play', 'Protein Analysis', 'Proteins', 'Proteomics', 'RNA', 'Reporting', 'Residual state', 'Risk', 'Risk Factors', 'Role', 'Science', 'Signal Transduction', 'Small Interfering RNA', 'Splenocyte', 'System', 'Systems Biology', 'Tissues', 'Untranslated RNA', 'Validation', 'Vascular Diseases', 'arterial lesion', 'base', 'cytokine', 'experimental study', 'femoral artery', 'gain of function', 'global health', 'human disease', 'humanized mouse', 'in vivo', 'injured', 'loss of function', 'macrophage', 'modifiable risk', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel therapeutics', 'overexpression', 'protein protein interaction', 'single cell analysis', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'vascular inflammation']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,724962
"Screening of Glycan Markers in Serum for Early Detection of HCC in Different Etiologies of Disease Abstract: Hepatocellular carcinoma (HCC) is the third most common cause of cancer-related death worldwide and is rising in incidence in the US. 90% of patients in the US with liver cancer have underlying cirrhosis, thus guideline recommendations recommend surveillance in all patients with cirrhosis to facilitate early detection. Unfortunately, only 20-30% of patients are detected with early detection and are thus eligible for potentially curative treatments. There is an unmet need for reliable biomarkers for HCC to facilitate adherence to screening and for early detection. In the proposed work we will develop early detection strategies for HCC based on glycoproteomic profiles. Unique changes in glycosylation in proteins, which involve structural changes in glycan groups, have been shown to be important serum biomarkers for early cancer detection. Importantly, the subtle changes may only involve minor structures but they can be very specific in differentiating cirrhosis versus early versus late stage HCC. In addition, these changes may be specific to the etiology of liver disease. These glycan structural changes will be detected and monitored quantitatively using a mass spectrometry approach which has proven to be an accurate way to characterize even minor changes in structure which may be significant as biomarkers based on our previous mass analysis, tandem mass spectrometry measurements and databases which have been developed for glycan and glycopeptide analysis. This will be demonstrated for both glycan and glycopeptide screening from serum using novel extraction and separation methods coupled to mass spectrometry which can ultimately be used to distinguish early stage HCC from cirrhosis. The proposed work will deliver separations and mass spec methods enabling isomeric separation of glycans and glycopeptides, permitting unequivocal assignment of protein glycosylation related to disease state. We will be able to distinguish different isomeric forms of fucosylation and sialylation which may contain important disease related markers. Novel software will be developed and used to assign these glycan structures. The markers will be discovered for specific etiologies of HCV-related, alcohol-related and NAFLD-related etiologies of HCC. This will be a multisite study to include all components required for a tumor biomarker lab including samples and sample preparation, separations and mass spec analysis, bioinformatics evaluation and statistical analysis. Ultimately, we will develop methods for discovery of glycan/glycopeptide markers from patient serum, the identification of potential markers and the development of new assays to provide a limited confirmation of these markers. Project Narrative: The proposed work will use new separations and mass spec methods to provide isomeric separation of glycans and glycopeptides, resulting in detailed assignment of protein glycosylation related to disease state. We expect to be able to distinguish different isomeric forms of fucosylation and sialylation which may contain important disease related markers. The markers will be discovered for specific etiologies of HCV- related, alcohol-related and NAFLD-related etiologies of HCC. Ultimately, we will develop new assays to provide a limited confirmation of these markers.",Screening of Glycan Markers in Serum for Early Detection of HCC in Different Etiologies of Disease,10135856,U01CA225753,"['Adherence', 'Alcohol-Related Hepatocellular Carcinoma', 'Alcohols', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Cancer Etiology', 'Carbon', 'Cessation of life', 'Cirrhosis', 'Complex', 'Computer software', 'Coupled', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Etiology', 'Europe', 'Evaluation', 'Frequencies', 'Glycopeptides', 'Glycoproteins', 'Guidelines', 'Hepatitis B Virus', 'Hepatitis C virus', 'Incidence', 'Isomerism', 'Japan', 'Lectin', 'Liver Cirrhosis', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Mass Spectrum Analysis', 'Measurement', 'Methods', 'Minor', 'Monitor', 'Natural graphite', 'Patients', 'Pattern', 'Peptides', 'Performance', 'Polysaccharides', 'Preparation', 'Primary carcinoma of the liver cells', 'Protein Glycosylation', 'Protein Isoforms', 'Proteins', 'Proteome', 'Recommendation', 'Risk', 'Sampling', 'Screening for cancer', 'Serum', 'Serum Markers', 'Site', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Survival Rate', 'Testing', 'Time', 'Tumor Markers', 'Ultrasonography', 'Work', 'alpha-Fetoproteins', 'base', 'carbohydrate structure', 'curative treatments', 'diagnostic screening', 'early detection biomarkers', 'early onset', 'glycoproteomics', 'glycosylation', 'improved', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'novel', 'patient screening', 'patient stratification', 'precision medicine', 'screening', 'sialylation', 'tandem mass spectrometry', 'tumor']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U01,2021,473414
"Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing 7. Project Summary/Abstract Adult human skin heals by developing fibrotic scar tissue, which can result in devastating disfigurement, growth restriction, and permanent functional loss. Despite a plethora of clinical options, no current treatment strategies successfully prevent or reverse this fibrotic process, and scars and their sequelae cost the United States over $20 billion every year. Progress towards the development of new therapies has been significantly hindered by a lack of understanding of the specific cell populations responsible for scarring. In 2015, our group reported that Engrailed-1 (En-1) lineage-positive fibroblasts (EPFs) are responsible for the vast majority of dorsal scar production in postnatal mice. In early fetal gestation, mice heal scarlessly via skin regeneration, an ideal outcome mediated by En-1 lineage-negative fibroblasts (ENFs; the predominant fetal fibroblast). However, it has not been established if ENFs contribute to postnatal wound healing. In this proposal, we explore for the first time the postnatal conversion of ENFs to pro-fibrotic EPFs (postnatally-derived EPFs; pEPFs) within the wound environment. First, histology, immunohistochemistry, and wounding in a novel transgenic mouse model will be used to study the conversion of ENFs to pEPFs during wound healing. By examining the behavior of ENF subpopulations (derived from papillary dermis, reticular dermis, and hypodermis) in the wound environment and confirming our findings in a tamoxifen-inducible mouse model of En-1 activation, we will precisely define the ENF population that gives rise to pro-fibrotic pEPFs. Second, we will establish the specific wound environment cues that drive ENF-to-EPF transition. Given that mechanical forces are known to modulate both scar burden and fibroblast activity, we will use in vitro and in vivo models to examine the effects of mechanical environment on En-1 activation. We will further use transcriptomic and epigenomic profiling to explore the role of mechanotransduction signaling in ENF-to-EPF transition and pEPF function. Third, having established a mechanotransduction mechanism underlying En-1 activation in wound ENFs, we will inhibit mechanotransduction signaling with the goal of blocking ENF-to-EPF transition. Specifically, we will assess whether blocking mechanotransduction results in ENF-mediated wound healing with reduced fibrosis. Our ultimate translational goal is to develop therapeutics that target fibrogenic fibroblasts to promote regenerative healing. Collectively, the proposed work will significantly enhance our understanding of the key molecular and cellular determinants of cutaneous scarring, inform the development of novel anti-scarring therapies, and shed light on the cellular origin of dermal scarring fibroblasts. 8. Project Narrative Scarring is the end result of injury in adult human skin and results in an enormous financial and medical burden for our society. There are currently no effective molecular therapies that prevent scarring or its sequelae, and development of therapeutics has been hindered by lack of understanding of the precise cell populations that mediate fibrosis in wound healing. Therefore, we propose to explore the contribution of a specific fibroblast subpopulation (Engrailed-1 lineage-negative fibroblasts; ENFs) in fibrotic wound healing, in order to inform novel directions for targeted treatments that minimize scarring and promote regenerative wound healing.",Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing,10130573,R01GM136659,"['3-Dimensional', 'Adult', 'Algorithms', 'Anatomic Surface', 'Behavior', 'Cells', 'Cellular Assay', 'Characteristics', 'Chemicals', 'Chromatin', 'Cicatrix', 'Clinical', 'Collagen', 'Connective Tissue', 'Cues', 'Cultured Cells', 'Cutaneous', 'Data', 'Dermal', 'Dermis', 'Development', 'Dipeptidyl-Peptidase IV', 'Dorsal', 'Elements', 'Engraftment', 'Environment', 'Extracellular Matrix', 'Fiber', 'Fibroblasts', 'Fibrosis', 'Fluorescence-Activated Cell Sorting', 'Focal Adhesion Kinase 1', 'Genetic Transcription', 'Goals', 'Growth', 'Hair follicle structure', 'High-Throughput Nucleotide Sequencing', 'Histologic', 'Histology', 'Hydrogels', 'Immunohistochemistry', 'In Vitro', 'Individual', 'Injury', 'Light', 'Maps', 'Measures', 'Mechanical Stress', 'Mechanics', 'Mediating', 'Medical', 'Microscopy', 'Molecular', 'Morbidity - disease rate', 'Mus', 'Outcome', 'Papillary', 'Pathway interactions', 'Population', 'Pregnancy', 'Process', 'Production', 'Protein Inhibition', 'Proteins', 'Reporting', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skin', 'Societies', 'Specimen', 'Subcutaneous Tissue', 'Surface', 'Tamoxifen', 'Time', 'Tissues', 'Transgenic Mice', 'Transposase', 'United States', 'Verteporfin', 'Visual', 'Wild Type Mouse', 'Work', 'analog', 'base', 'cost', 'digital', 'epigenomics', 'experimental study', 'fetal', 'functional loss', 'healing', 'in vivo', 'in vivo Model', 'inhibitor/antagonist', 'machine learning algorithm', 'mechanical force', 'mechanotransduction', 'mortality', 'mouse model', 'novel', 'novel therapeutics', 'postnatal', 'prevent', 'reconstruction', 'regenerative', 'response', 'single-cell RNA sequencing', 'skin regeneration', 'skin wound', 'therapeutic development', 'therapeutic target', 'tissue culture', 'tool', 'transcriptomics', 'treatment strategy', 'wound', 'wound bed', 'wound environment', 'wound healing']",NIGMS,STANFORD UNIVERSITY,R01,2021,317427
"Multi-omic networks associated with COPD progression in TOPMed Cohorts PROJECT SUMMARY Chronic obstructive pulmonary disease (COPD) is the fourth leading cause of death in the US. Although COPD occurs predominantly in smokers, it is unknown why only a minority of smokers (~20-40%) develop chronic airflow limitation or destruction of distal airspaces (emphysema). The difference susceptibility to tobacco smoke could be explained by differences in genetics or environment, which lead to activation or repression of pathways that are important in the pathogenesis and progression of COPD. Recent advances in high throughput omics (whole genome sequencing, DNA methylation, RNA-Seq, proteomics and metabolomics) applied to NHLBI cohorts now permits a comprehensive assessment of the molecular profiles of susceptible patients. This proposal will use sparse multiple canonical correlation network analysis (SmCCNet) to integrate these existing -omics data from three NHLBI cohorts: COPDGene, Jackson Heart Study, and SPIROMICS. The three independent cohorts will allow replication of specific molecular networks which can be used to target new therapies or more precise prognostic information to individuals (i.e., precision medicine). The first two of these cohorts have large numbers of African American subjects, who are underrepresented in omics studies. We will perform population specific analyses, which will allow us to determine which molecular signatures and pathways might be specific to African Americans. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is the fourth leading cause of death in the US. To help identify why only some smokers develop COPD, this proposal will integrate recently collected extensive molecular profiles from three NHLBI cohorts (COPDGene, Jackson Heart Study, and SPIROMICS) to discover molecular networks that are important in both diagnosis and progression. In addition to non- Hispanic Whites, by focusing on African Americans, which are highly underrepresented in these types of studies, we expect that there are specific molecular network differences that may lead to specific therapies (i.e., precision medicine) based on race/ethnicity.",Multi-omic networks associated with COPD progression in TOPMed Cohorts,10138019,R01HL152735,"['African American', 'Biology', 'Cause of Death', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Complex', 'Computers', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease Progression', 'Distal', 'Environment', 'Epidemiologist', 'Epigenetic Process', 'Ethnic Origin', 'Genetic', 'Genetic Markers', 'Individual', 'Investigation', 'Jackson Heart Study', 'Knowledge', 'Lead', 'Lung', 'Methods', 'Minority', 'Molecular', 'Molecular Disease', 'Molecular Profiling', 'National Heart, Lung, and Blood Institute', 'Not Hispanic or Latino', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Proteomics', 'Publications', 'Pulmonary Emphysema', 'Quantitative Trait Loci', 'Race', 'Repression', 'Research', 'Research Design', 'Research Personnel', 'Sample Size', 'Scanning', 'Scientist', 'Smoker', 'Spirometry', 'System', 'Technology', 'Tobacco smoke', 'Trans-Omics for Precision Medicine', 'Transcript', 'Underrepresented Minority', 'Work', 'X-Ray Computed Tomography', 'airway obstruction', 'alpha 1-Antitrypsin', 'base', 'chronic airflow obstruction', 'clinical phenotype', 'cohort', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'metabolomics', 'multidisciplinary', 'multiple omics', 'new therapeutic target', 'novel', 'novel diagnostics', 'precision medicine', 'prognostic', 'protein metabolite', 'single molecule', 'soluble RAGE', 'transcriptome sequencing', 'transcriptomics', 'unsupervised learning', 'whole genome']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2021,759026
"Modeling to Design Treatments for Idiopathic Lung Fibrosis PROJECT SUMMARY Every year in this country 40,000 patients are diagnosed with idiopathic pulmonary fibrosis (IPF), a progressive and terminal disease caused by excessive extracellular matrix production by myofibroblasts in distributed lesions, or “fibrotic foci”, throughout the lung. Despite the availability of two FDA-approved drugs that are considered standard of care, the mortality rate for IPF patients exceeds 30% at four years, and there are no drugs that halt disease progression, making diagnosis with IPF a death sentence for over 500,000 Americans living with this disease. Identifying the cells of origin that give rise to myofibroblasts is necessary for finding treatments that can halt or cure IPF. Based on experimental data and computational simulations from our research team, we hypothesize that myofibroblasts arise from microvascular pericytes (cells that normally enwrap capillaries) when heterotypic pericyte-endothelial interactions become disrupted. We further posit that strategic modulation of kinase-mediated signaling in pericytes can prevent pericyte-to-myofibroblast transitions and halt the progression of IPF. We propose to combine computational modeling with experiments to study pericyte-to-myofibroblast differentiation and to investigate how microvessel adaptations in the lung contribute to IPF. Specifically, we will develop a new agent-based model (ABM) that incorporates logic-based intracellular signaling networks to simulate cell behaviors and leverages Bayesian inference for rule refinement (Aim 1), validate the ABM's ability to predict pericyte phenotype transitions and the emergence of fibrotic foci in response to drugs using the murine bleomycin model of IPF (Aim 2), and bridge murine experiments with clinical data in order to predict how druggable kinase-driven signaling pathways affect IPF progression via modulation of pericytes and microvessels (Aim 3). To our knowledge, our proposed studies will be the first to combine computational modeling with experiments to study microvascular contributors to IPF progression. In addition to producing a new computational model that is validated for bridging pre-clinical study results to clinical outcomes, we expect to identify new therapeutic approaches for IPF that target microvascular cells, previously underexplored but potentially critical contributors to this deadly disease. PROJECT NARRATIVE Idiopathic pulmonary fibrosis (IPF) is a deadly disease caused by uncontrolled tissue fibrosis in the lungs. There are no FDA-approved drugs that cure or prevent disease progression. We propose to combine computational modeling with experiments study how fibroblasts and microvessel remodeling in the lung contribute to disease and to identify novel drugs and drug combinations that target these processes in order to effectively treat IPF.",Modeling to Design Treatments for Idiopathic Lung Fibrosis,10305193,R01HL155143,"['Affect', 'Alveolar', 'American', 'Bayesian Analysis', 'Biological', 'Bleomycin', 'Blood capillaries', 'Cardiac', 'Cell Communication', 'Cells', 'Cessation of life', 'Cicatrix', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Computer Models', 'Computer Simulation', 'Country', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Drug Combinations', 'Drug Targeting', 'Drug usage', 'Endothelial Cells', 'Endothelium', 'Environment', 'Extracellular Matrix', 'FDA approved', 'Fibroblasts', 'Fibrosis', 'Harvest', 'Heterogeneity', 'Histology', 'Human', 'Impairment', 'Lesion', 'Logic', 'Lung', 'Machine Learning', 'Mediating', 'Modeling', 'Molecular', 'Mus', 'Myofibroblast', 'Nature', 'New Agents', 'Outcome', 'Output', 'Patients', 'Pericytes', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Pirfenidone', 'Platelet-Derived Growth Factor', 'Platelet-Derived Growth Factor Receptor', 'Process', 'Production', 'Progressive Disease', 'Publishing', 'Pulmonary Fibrosis', 'Research', 'Retina', 'Signal Pathway', 'Signal Transduction', 'Tamoxifen', 'Terminal Disease', 'Time', 'Tissues', 'To specify', 'Transforming Growth Factors', 'Translating', 'Validation', 'Vascular Endothelial Growth Factor Receptor-1', 'Vascular Endothelial Growth Factors', 'base', 'cell behavior', 'experimental study', 'human data', 'idiopathic pulmonary fibrosis', 'kinase inhibitor', 'models and simulation', 'mortality', 'mouse model', 'new therapeutic target', 'novel', 'novel drug combination', 'novel therapeutic intervention', 'novel therapeutics', 'pre-clinical', 'preclinical study', 'predicting response', 'predictive modeling', 'prevent', 'pulmonary agents', 'pulmonary function', 'response', 'skeletal', 'standard of care', 'therapy design', 'transcriptome sequencing', 'transcriptomics']",NHLBI,UNIVERSITY OF VIRGINIA,R01,2021,548214
"Metabolic Basis of Bacterial Community Function in the Cystic Fibrosis Airway Abstract. Cystic fibrosis (CF) is a fatal genetic disease characterized by overproduction of mucus in the lungs followed by chronic lung infections. Conventional wisdom has been that most CF lung infections involve a single dominant organism, most commonly the pathogenic bacterium Pseudomonas aeruginosa. Advances in culture-independent techniques have revealed that CF lung infections are rarely mono-microbial and instead usually involve complex microbial communities, yet the interspecies interactions that drive these communities are poorly understood. Furthermore, numerous studies have demonstrated that polymicrobial infections are more difficult than mono-microbial infections to eradicate with antibiotics, leading to the concept of recalcitrant communities. The mechanisms underlying recalcitrance are thought to involve synergistic interactions between community members, but very little data are available to understand this phenomenon. Combined with the realization that many CF patients respond poorly to available antibiotic regimens compels a more detailed understanding of interspecies interactions and their impacts on antibiotic recalcitrance to improve the treatment of CF infections, as well as other polymicrobial diseases. Here, we combine big-data bioinformatics, in silico computational modeling and in vitro culture experiments to gain insights into the metabolic interactions that drive CF disease outcomes and antibiotic recalcitrance. The research will leverage an available data set of hundreds of CF patient samples that provide both bacterial composition data and clinical metadata, including measures of lung function. These samples will be clustered according to their measured compositions and metabolic capabilities predicted through computational metabolic modeling to test the hypothesis that the vast complexity of these many bacterial communities can be collapsed into a small number of model communities that capture most of the observed metabolic variability. These computational predictions will be tested by developing in vitro cell culture models that recapitulate the most important metabolic features of the in vivo polymicrobial communities (Aim 1). By applying bioinformatics and modeling to the same clinical data, we will test the hypothesis that community metabolic features drive disease outcomes and the virulence potential of these communities (Aim 2). Finally, we will interrogate the clinical data and in vitro communities to test the hypothesis that community metabolic features drive antibiotic recalcitrance and differentiate community responsiveness to antibiotics according to these metabolic features (Aim 3). Our research will yield novel insights into how complex polymicrobial communities are compositionally structured, interact metabolically, contribute to disease and respond to antibiotics. Moreover, the research will validate in vitro models that offer the potential for development of novel antimicrobial strategies to better treat chronic, polymicrobial infections in CF and other diseases. Our transdisciplinary team offers the necessary expertise in bioinformatics, computational modeling, microbial physiology and CF polymicrobial infections to tackle this complex problem. Project Narrative: Infections associated with cystic fibrosis, and other polymicrobial infections, are still a significant cause of morbidity and mortality. Here we propose to apply bioinformatics, modeling and experimental tools to a large clinical data set to gain new insight into how to treat complex, chronic polymicrobial infections.",Metabolic Basis of Bacterial Community Function in the Cystic Fibrosis Airway,10293007,R01AI155424,"['Acute', 'Acute Disease', 'Antibiotics', 'Antimicrobial Resistance', 'Bacteria', 'Big Data', 'Bioinformatics', 'Cell Culture Techniques', 'Chronic', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Communities', 'Complex', 'Computer Models', 'Consumption', 'Culture-independent methods', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Outcome', 'Dose', 'Energy-Generating Resources', 'Event', 'Exhibits', 'Experimental Models', 'Exposure to', 'Feeding Patterns', 'Genetic Diseases', 'Genetic study', 'In Vitro', 'Individual', 'Infection', 'Lung', 'Lung infections', 'Machine Learning', 'Measures', 'Metabolic', 'Metadata', 'Microbe', 'Microbial Physiology', 'Minimum Inhibitory Concentration measurement', 'Modeling', 'Morbidity - disease rate', 'Mucous body substance', 'Mutation', 'Nature', 'Organism', 'Outcome', 'Outcome Measure', 'Output', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Pseudomonas aeruginosa', 'Pseudomonas aeruginosa infection', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Regimen', 'Research', 'Resistance', 'Role', 'Sampling', 'Sputum', 'Staphylococcus aureus', 'Streptococcus', 'Structure', 'Testing', 'Virulence', 'Work', 'antibiotic tolerance', 'antimicrobial', 'antimicrobial drug', 'bacterial community', 'base', 'bioinformatics tool', 'cystic fibrosis airway', 'cystic fibrosis infection', 'cystic fibrosis patients', 'experimental study', 'feeding', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'insight', 'member', 'metabolomics', 'microbial', 'microbial community', 'mortality', 'novel', 'novel therapeutics', 'pathogenic bacteria', 'polymicrobial biofilm', 'polymicrobial disease', 'pulmonary function', 'pulmonary function decline', 'success', 'tool', 'translational impact']",NIAID,DARTMOUTH COLLEGE,R01,2021,466513
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10202460,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2021,749956
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home environment', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization PROJECT SUMMARY Assisted Reproduction Technology (ART) is a clinical treatment for infertile couples who want to achieve a pregnancy. In ART, embryologists fertilize eggs retrieved from the patient or a donor, culture the resulting embryos in vitro, and then transfer the selected embryo(s) to the mother's uterus. While ART is responsible for 1.9% of babies born in the United States as of 2018, selecting which embryo to transfer is a signiﬁcant challenge. The difﬁculty comes from the complexity of confounding factors and the lack of understanding of human pre-implantation embryo development. Because of this difﬁculty, multiple embryos are often transferred to increases the potential of success, resulting in multiple pregnancy rates of nearly 20%, which can lead to signiﬁcant morbidity and medical expenses to patients. The ideal is to transfer only a single embryo, but this necessitates the ability to select the best embryo from a cohort. Here, we propose to create a clinical decision support system to improve embryo selection in ART. To this end, we will develop novel deep learning models for robust embryo feature extraction and interactive data visualization methods for human-in-the-loop analysis. We will ﬁrst extract and analyze visual features from routinely collected images of embryos. We will then combine these visual features with patients' electronic health record (EHR) data to develop interpretable computation models that score embryos on their viability. We plan to integrate our machine learning solutions into an easily accessible cloud service platform that will be adaptable across clinics to improve ART embryo selection and clinical data analysis. Our research goals will be achieved by novel machine learning-based models for morphological feature extrac- tion and importance estimation of each confounding factor and a clinical decision support system for ART. For morphological feature extraction, we plan to conduct semi-supervised learning of convolutional neural networks to minimize manual labeling that requires extensive human effort. Our feature extraction model will be the ﬁrst comprehensive classiﬁcation and segmentation method for ART. To aid in embryo selection, we will develop novel deep learning-based models to predict probabilities of achieving pregnancy by accepting visual features and EHR data as the input. We will also develop visual analytic tools that allow analysts to better understand and steer these deep learning models. We will estimate the importance of each input interpretable factor in embryo selection to explain the prediction to embryologists. Finally, we will develop EmbryoProﬁler, a clinical decision support system for ART, that combines our machine learning-based models with a user-facing suite of visual analytic tools to support user guidance and clinical decision making. EmbryoProﬁler will help facilitate daily operation in clinics, foster human-guided decision making, enrich data-driven embryo analysis, and enhance the ability to select the developmentally most competent embryo for transfer to improve ART success rates. Our project will create state-of-the-art analysis approaches for ART clinicians. PROJECT NARRATIVE Assisted Reproductive Technology (ART) is a widespread treatment for infertility, over 300,000 treatment cycles were performed in the US in 2018, but success rates remain low. In this project, we will develop novel machine learning algorithms and a clinical decision support system to assist embryologists in embryo selection. Our tools will also enable embryologists and biologists to obtain new information on the earliest stages of human embryo development, which will advance the fundamental science of human biology and lead to further improvements in ART practice.",Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization,10185936,R01HD104969,"['Adopted', 'Age', 'Assisted Reproductive Technology', 'Back', 'Cell Lineage', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Cloud Service', 'Communities', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Computers', 'Couples', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Making', 'Detection', 'Development', 'Discipline', 'E-learning', 'Electronic Health Record', 'Embryo', 'Embryo Transfer', 'Embryonic Development', 'Fostering', 'Goals', 'Human', 'Human Biology', 'Image', 'Image Analysis', 'In Vitro', 'Judgment', 'Knowledge', 'Label', 'Lead', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Mothers', 'Multiple Pregnancy', 'Obesity', 'Patients', 'Pattern', 'Physiological', 'Pre-implantation Embryo Development', 'Pregnancy', 'Pregnancy Rate', 'Privacy', 'Probability', 'Research', 'Science', 'Scientist', 'Secure', 'Security', 'Text', 'Time', 'Trees', 'United States', 'Ursidae Family', 'Uterus', 'Visual', 'Visualization', 'Visualization software', 'analytical tool', 'base', 'blastocyst', 'clinical decision-making', 'clinical practice', 'cloud based', 'cohort', 'convolutional neural network', 'data cleaning', 'data curation', 'data management', 'data visualization', 'deep learning', 'embryo cell', 'embryo monitoring', 'feature extraction', 'human-in-the-loop', 'implantation', 'improved', 'infertility treatment', 'insight', 'large scale data', 'machine learning algorithm', 'microscopic imaging', 'model design', 'multi-task learning', 'multimodality', 'novel', 'operation', 'predictive modeling', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'zygote']",NICHD,HARVARD UNIVERSITY,R01,2021,730410
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,10105327,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'tool']",NEI,DUKE UNIVERSITY,K23,2021,193774
"Machine Learning Models for Identifying Neural Predictors of TMS Treatment Response in MDD Transcranial magnetic stimulation (TMS) is an effective and easy-to-tolerate treatment for major depressive disorder (MDD). TMS is costly and time-intensive so identifying markers of response would reduce financial and psychological burden. Further, treatment response is highly variable. Clinical and diagnostic heterogeneity of depression contributes to significant variability in neural markers of response. The literature on neural markers is complicated by variability in TMS intensity and targets, which may further modify response. Electrical field models estimate the degree to which a target is stimulated by considering both the intensity and structural information of each participant but at this time there are no studies that have investigated the association between brain electrical fields and treatment response. Moreover, the neurobiological correlates of dorsolateral (dlPFC) TMS treatment response are not well understood. Machine learning may be able to help us understand these complex set of features and their association to treatment response. Thus to appropriately personalize treatments, I will develop a data-driven machine learning model that uses the following: (1) pre- treatment resting state connectivity that reflects circuit dysregulation; (2) electrical field modeling to estimate the electrical field or voltage on individual patient’s brain, as a marker of sufficiency of stimulation; and (3) expected target network connectivity as a marker of target engagement. We have previously demonstrated feasibility of machine learning to predict antidepressant response in MDD. We will optimize and expand a model developed on archival University of Toronto data that predicted dlPFC TMS response. We will validate this externally on three sets of data: data we collect at University of Pittsburgh, archival data from Brown University, and sham TMS data. As an exploratory aim, we will identify whether our model that predicts dlPFC TMS treatment response is capable of predicting response to dmPFC TMS stimulation. During my PhD in Bioengineering, I developed kernel-based machine learning models to personalize neural networks markers of antidepressant response. Given the clinical and neural heterogeneity of depression, I will leverage my machine learning and neuroimaging experience by receiving training in advanced optimization approaches and depression neurobiology to identify stable, reproducible neural predictors of TMS treatment response to achieve clinically translatable personalized treatments. This will allow me to develop optimized models of treatment response and facilitate my long-term career goal to develop personalized treatment algorithms using large-scale data. My previous experiences in machine learning, bioengineering, neuroimaging, as well as the preliminary understanding of depression uniquely position me to maximize the benefits of training aims outlined in this proposal. 1 This is a K01 application designed to develop a data-driven machine learning model that will take into account several neural markers of response to Transcranial Magnetic Stimulation (TMS). The application proposes expanded training in machine learning optimization approaches and depression neurobiology for the applicant, who has a PhD in Bioengineering. The goal of the study is to identify stable, reproducible neural predictors of TMS treatment response to achieve clinically translatable personalized treatments, which matches the candidate’s long-term goal to conduct research on and develop models that personalize medicine for depression. 1",Machine Learning Models for Identifying Neural Predictors of TMS Treatment Response in MDD,10125330,K01MH122741,"['Algorithms', 'Anterior', 'Antidepressive Agents', 'Archives', 'Biological', 'Biomedical Engineering', 'Brain', 'Clinical', 'Clinical Treatment', 'Complex', 'Corpus striatum structure', 'Data', 'Data Set', 'Development', 'Doctor of Philosophy', 'Goals', 'Heterogeneity', 'Individual', 'Left', 'Literature', 'Machine Learning', 'Major Depressive Disorder', 'Measures', 'Mental Depression', 'Modeling', 'Motor', 'Neurobiology', 'Neurosciences', 'Participant', 'Patients', 'Placebos', 'Positioning Attribute', 'Prediction of Response to Therapy', 'Reproducibility', 'Research', 'Rest', 'Rewards', 'Structure', 'Testing', 'Time', 'Training', 'Transcranial magnetic stimulation', 'Universities', 'archive data', 'archived data', 'base', 'career', 'clinical Diagnosis', 'clinical diagnostics', 'clinically translatable', 'cohort', 'cost', 'design', 'electric field', 'executive function', 'experience', 'individual patient', 'large scale data', 'neural network', 'neuroimaging', 'personalized medicine', 'predicting response', 'predictive modeling', 'psychologic', 'random forest', 'relating to nervous system', 'response', 'response biomarker', 'support vector machine', 'translational scientist', 'treatment response', 'voltage']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K01,2021,170027
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10260577,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'risk stratification', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2021,332101
"Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning Project Summary/Abstract A plethora of neuroscience studies shows mounting evidence that neurodegenerative diseases manifest distinct network dysfunction patterns much earlier prior to the onset of clinical symptoms. Since the subject-specific longitudinal network changes are more relevant to the neuropathological process than topological patterns derived from cross-sectional data, recognizing the subtle and dynamic longitudinal network biomarkers from noisy network data is of great demand to enhance the sensitivity and specificity of computer-assisted diagnosis in neurodegenerative diseases. However, current popular statistical inference or machine learning approaches used for neuroimages (in a regular data structure such as grid and lattice) are not fully optimized for the learning task on brain network data which is often encoded in a high dimensional graph (an irregular and non-linear data structure). Such gross adaption is partially responsible for the lack of reliable biomarkers that can be used to predict cognitive decline in routine clinical practice. To address this challenge, we aim to (1) develop a novel GNN (graph neural network) based learning framework to hierarchically discover the multi-scale network biomarkers that can recognize the disease-relevant network alterations over time, and (2) examine the diagnostic power of the new network biomarkers derived from our GNN-based machine learning engine across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia. The success of this project will allow us to integrate the novel GNN-based learning component into our current longitudinal network analysis toolbox and release the AI (artificial intelligence) based network analysis software to the neuroscience and neuroimaging community. Project Narrative The goal of this project is to continue the tool development of longitudinal network analysis for neurodegenerative diseases with the focus on the machine learning component. To do so, we will first develop the GNN (graph neural network) based learning framework to discover the multi-scale network biomarkers from the population of brain network data. After examining the diagnostic value of the network biomarkers discovered by our learning- based method across neurodegenerative diseases such as Alzheimer’s disease, Parkinson’s disease, and frontotemporal dementia, we will integrate the machine learning component into our current longitudinal network analysis software and release to the neuroscience and neuroimaging community.",Continuing Tool Development for Longitudinal Network Analysis: Enriching the Diagnostic Power of Disease-Specific Connectomic Biomarkers by Deep Graph Learning,10109509,R03AG070701,"['Address', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease diagnosis', 'Artificial Intelligence', 'Biological Markers', 'Brain', 'Clinical', 'Cognitive', 'Communities', 'Computer software', 'Computer-Assisted Diagnosis', 'Data', 'Databases', 'Diagnostic', 'Dimensions', 'Disease', 'Early Diagnosis', 'Event', 'Evolution', 'Frontotemporal Dementia', 'Goals', 'Graph', 'Image', 'Impaired cognition', 'Individual', 'Industry', 'Investigation', 'Label', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Nerve Degeneration', 'Network-based', 'Neural Network Simulation', 'Neurodegenerative Disorders', 'Neurofibrillary Tangles', 'Neurosciences', 'Outcome', 'Parkinson Disease', 'Pathway Analysis', 'Pattern', 'Population', 'Process', 'Research', 'Resolution', 'Resources', 'Sample Size', 'Senile Plaques', 'Sensitivity and Specificity', 'Source Code', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Text', 'Time', 'United States National Institutes of Health', 'base', 'clinical practice', 'cohort', 'collaboratory', 'comparison group', 'computerized tools', 'data mining', 'data structure', 'deep learning', 'design', 'high dimensionality', 'machine learning method', 'method development', 'network dysfunction', 'neural network', 'neuroimaging', 'novel', 'outcome forecast', 'software development', 'success', 'tool', 'tool development']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R03,2021,158733
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,10089451,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,376028
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10224845,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2021,388750
"Identifying treatment responders in medication trials for AUD using machine learning approaches ABSTRACT Alcohol use disorder (AUD), as defined in DSM-5, represents a highly prevalent, costly, and often untreated condition in the United States. Pharmacotherapy offers a promising avenue for treating AUD and for improving clinical outcomes for this debilitating disorder. While developing novel medications to treat AUD remains a high priority research area, there remain major opportunities to further elucidate clinical response in completed medication trials. To that end, a key question in randomized clinical trials (RCTs) is which patients respond to a given pharmacotherapy. Identifying treatment responders provides major opportunities to advance clinical care for AUD by personalizing medication practices on the bases of variables/predictors of good clinical response. For example, while the effect size for medications such as naltrexone is deemed small-to-moderate, a host of studies over the past decade have shown that its effect size may be considerably larger for certain subgroups of patients. Towards advancing precision medicine for AUD and leveraging data from a host of carefully conducted RCTs for AUD, this R03 application seeks to conduct secondary data analysis. Specifically, we propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG). These state-of-the-art RCTs for AUD have tested the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. In this R03 application, we propose to use a machine learning approach to identify treatment responders in the NCIG RCTs. Machine learning represents a highly promising and underutilized data analytic strategy in the field of AUD treatment response. Machine learning models prioritize the ability to predict future outcomes over creating perfectly fitting models for the data at hand. This results in models which are more generalizable to future observations, which fits well with our goal of identifying responders in RCTs. Leveraging data from these pivotal RCTs through secondary data analysis and using novel analytic methods, namely machine learning, provides a cost-effective approach to identifying AUD pharmacotherapy responders. PROJECT NARRATIVE In this R03 application, we propose to use a machine learning approach to identify treatment responders in pivotal clinical trials for AUD. We propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG), testing the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. Leveraging resources through secondary data analysis and using novel analytic methods provides a cost- effective approach to identifying AUD pharmacotherapy responders.",Identifying treatment responders in medication trials for AUD using machine learning approaches,10195465,R03AA029244,"['Age', 'Age of Onset', 'Alcohols', 'Anxiety', 'Area', 'Chantix', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Conduct Clinical Trials', 'DSM-V', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Ethnic Origin', 'Faculty', 'Future', 'Goals', 'Hand', 'Heavy Drinking', 'Human', 'Keppra', 'Laboratories', 'Levetiracetam', 'Machine Learning', 'Manuscripts', 'Marital Status', 'Mental Depression', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Modeling', 'Motivation', 'Naltrexone', 'National Institute on Alcohol Abuse and Alcoholism', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Policies', 'Psychologist', 'Psychology', 'Randomized Clinical Trials', 'Recommendation', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Scientist', 'Secondary to', 'Self Administration', 'Severities', 'Sum', 'Symptoms', 'Technical Expertise', 'Testing', 'United States', 'Withdrawal', 'Work', 'alcohol use disorder', 'analytical method', 'base', 'cigarette smoking', 'clinical care', 'clinical investigation', 'clinically relevant', 'cost', 'cost effective', 'cost effectiveness', 'craving', 'data sharing', 'drinking', 'gabapentin', 'improved', 'insight', 'machine learning method', 'material transfer agreement', 'novel', 'patient subsets', 'precision medicine', 'quetiapine', 'random forest', 'response', 'secondary analysis', 'sex', 'success', 'tenure track', 'treatment responders', 'treatment response', 'varenicline']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R03,2021,74776
"Personalized Deep Learning Models of Rapid Changes in Major Depressive Disorder Symptoms using Passive Sensor Data from Smartphones and Wearable Devices ABSTRACT Major depressive disorder (MDD) is highly prevalent and the leading cause of global disease burden. Associated with over 1,000 different symptom profiles, MDD is highly heterogeneous. The majority of MDD symptom change occurs across hours. Consequently, there is a need to increasingly focus MDD research on personalized assessment of these rapid symptom fluctuations. To date, personalized models of MDD have shown promise, but relied solely on self-report measures. There is thus a critical need to develop personalized models of MDD that incorporate objective signals. Passively collected information from smartphones and wearable sensors can continuously and unobtrusively track behavioral and physiological signals related to core disturbances associated with MDD, including psychomotor retardation, sleep disturbances, social contact, behavioral activation, heart rate variability, and screen time. Preliminary data suggest that personalized artificial intelligence (i.e., personally weighted deep learning models) are well suited for creating novel personalized digital biomarkers of these passive indicators, and that these biomarkers can predict rapid changes in MDD symptoms. This proposal will investigate the ability to develop personalized deep learning models of rapid changes in MDD symptoms among a nationally representative sample of 120 treatment seeking adults with MDD across 90 days using passively collected data from smartphones and wearable sensors. This proposal aims to test the accuracy of personalized, subtyped, and cohort-based modeling techniques and uncover personalized digital biomarkers of moment-to-moment changes in MDD symptoms. The project proposes the following innovations: it will (1) conduct the first passive-sensing study of MDD in a nationally-representative cohort; (2) utilize deep learning models to aid in the discovery of novel maintenance factors of MDD symptom changes; and (3) use personalized multimodal assessments of MDD to address the heterogeneity in MDD. In line with the aims of the NIMH Research Domain Criteria (RDoC), this project will study MDD symptom changes across multiple units of analysis and integrate multiple systems. This study will provide a critical step towards uncovering novel personalized maintenance patterns of MDD symptom changes in daily life. Further, it will allow for scalable personalized treatments to be developed using technology to deliver behavioral interventions in the moments immediately preceding rapid MDD symptom changes. PROJECT NARRATIVE This project aims to utilize personalized artificial intelligence techniques and objective data (collected from smartphones and wearable devices) to create individualized digital biomarkers of rapid changes in major depressive disorder symptoms. This is important because, if we were to uncover personalized patterns between objectively measured physiology and behavioral changes and understand their resulting impact on rapid fluctuations in major depressive disorder symptoms, we would be able to define new, person-specific maintenance patterns that underlie the wide-ranging heterogeneity that is currently seen in patients suffering from major depressive disorder. Moreover, these advancements will provide a crucial step forward towards developing personalized, scalable, technology-based interventions that will be able to be delivered immediately (and, ideally, before rapid symptom changes) among those persons with major depressive disorder.",Personalized Deep Learning Models of Rapid Changes in Major Depressive Disorder Symptoms using Passive Sensor Data from Smartphones and Wearable Devices,10229551,R01MH123482,"['Address', 'Adult', 'Affect', 'Arousal', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological Markers', 'Cellular Phone', 'Cessation of life', 'Collection', 'Data', 'Depressed mood', 'Deterioration', 'Devices', 'Ecological momentary assessment', 'Enrollment', 'Exposure to', 'Fostering', 'Heterogeneity', 'Hour', 'Individual', 'Intervention', 'Life', 'Light', 'Location', 'Maintenance', 'Major Depressive Disorder', 'Measures', 'Modeling', 'Moods', 'Motor', 'National Institute of Mental Health', 'Negative Valence', 'Participant', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Persons', 'Photoplethysmography', 'Physiological', 'Physiology', 'Population', 'Positive Valence', 'Process', 'Research', 'Research Domain Criteria', 'Sampling', 'Signal Transduction', 'Sleep', 'Sleep disturbances', 'Subgroup', 'Surveys', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'Wrist', 'actigraphy', 'analog', 'base', 'biomarker-driven', 'burden of illness', 'cohort', 'deep learning', 'depressive symptoms', 'digital', 'disability', 'heart rate variability', 'innovation', 'learning strategy', 'meetings', 'microphone', 'multimodality', 'novel', 'personalized medicine', 'phenomenological models', 'premature', 'prevent', 'sensor', 'social', 'treatment planning', 'treatment response', 'tv watching', 'wearable device', 'wearable sensor technology']",NIMH,DARTMOUTH COLLEGE,R01,2021,173784
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287
"SCH: INT: Collaborative Research: Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy The research objective of this proposal, Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy Prediction, with Pl Dominique Duncan from the University of Southern California, is to predict the onset of epileptic seizures following traumatic brain injury (TBI), using innovative analytic tools from machine learning and applied mathematics to identify features of epileptiform activity, from a multimodal dataset collected from both an animal model and human patients. The proposed research will accelerate the discovery of salient and robust features of epileptogenesis following TBI from a rich dataset, collected from the Epilepsy Bioinformatics Study for Antiepileptogenic Therapy (EpiBioS4Rx), as it is being acquired by investigating state-of-the-art models, methods, and algorithms from contemporary machine learning theory. This secondary use of data to support automated discovery of reliable knowledge from aggregated records of animal model and human patient data will lead to innovative models to predict post-traumatic epilepsy (PTE). This machine learning based investigation of a rich dataset complements ongoing data acquisition and classical biostatistics-based analyses ongoing in the study and can lead to rigorous outcomes for the development of antiepileptogenic therapies, which can prevent this disease. Identifying salient features in time series and images to help design a predictor of PTE using data from two species and multiple individuals with heterogeneous TBI conditions presents significant theoretical challenges that need to be tackled. In this project, it is proposed to adopt transfer learning and domain adaptation perspectives to accomplish these goals in multimodal biomedical datasets across two populations. Specifically, techniques emerging from d,eep learning literature will be exploited to augment data, share parameters across model components to reduce the number of parameters that need to be optimized, and use state-of-the-art architectures to develop models for feature extraction. These will be compared against established pipelines of hand-crafted feature extraction in rigorous cross-validation analyses. Developed techniques for transfer learning will be able to extract features that generalize across animal and human data. Moreover, these theoretical techniques with associated models and optimization methods will be applicable to other multi-species transfer learning challenges that may arise in the context of health and medicine. Multimodal feature extraction and discriminative model learning for disease onset prediction using novel classifiers also offer insights into biomarker discovery using advanced machine learning techniques through joint multimodal data analysis. A significant percentage of people develop epilepsy after a moderate-severe traumatic brain injury. If we can identify who will develop post-traumatic epilepsy and at what time point after the injury, those patients can be treated with antiepileptogenic therapies and medications to stop or prevent the seizures from occurring. It is likely that biomarkers of epileptogenesis after TBI can only be found by analyzing multimodal data from a large population, which requires advanced mathematical tools and models.",SCH: INT: Collaborative Research: Multimodal Signal Analysis and Data Fusion for Post-traumatic Epilepsy,10093160,R01NS111744,"['Adopted', 'Algorithms', 'Animal Model', 'Antiepileptogenic', 'Architecture', 'Bioinformatics', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Brain imaging', 'California', 'Chemicals', 'Complement', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Graph', 'Hand', 'Health', 'High Frequency Oscillation', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Injury', 'Intuition', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Length', 'Limbic System', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical', 'Medicine', 'Methodology', 'Methods', 'MicroRNAs', 'Modeling', 'Onset of illness', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Post-Traumatic Epilepsy', 'Property', 'Proteins', 'Psychological Techniques', 'Psychological Transfer', 'Rattus', 'Records', 'Research', 'Rest', 'Scalp structure', 'Seizures', 'Series', 'Signal Transduction', 'Statistical Models', 'Structure', 'Techniques', 'Thalamic structure', 'Time', 'Tissues', 'Traumatic Brain Injury', 'Universities', 'Update', 'Validation', 'Voting', 'Work', 'analytical tool', 'animal data', 'base', 'biomarker discovery', 'data acquisition', 'data fusion', 'deep learning', 'design', 'feature extraction', 'human data', 'imaging modality', 'improved', 'innovation', 'insight', 'laboratory experiment', 'learning strategy', 'multimodal data', 'multimodality', 'neural network', 'neural network classifier', 'neurophysiology', 'novel', 'post-trauma', 'predictive modeling', 'prevent', 'random forest', 'support vector machine', 'theories', 'tool']",NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,243545
"Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes PROJECT SUMMARY  Schizophrenia (SCZ) and bipolar disorder (BD) are highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity. Despite this, case-control studies often ignore such heterogeneity through their focus on the average patient, which may be the core reason for a lack of robust biomarkers indicative of an individual’s treatment response and outcome. Although they are classified as independent diagnostic entities, SCZ and BD are highly genetically correlated, exhibit high relative risks among relatives of both BD & SCZ patients, and have partially overlapping symptomatology and treatment. In this project we will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD in our VA discovery cohort comprising the Million Veteran Program (MVP) and Cooperative Studies Program 572 (CSP #572, “The Genetics of Functional Disability in Schizophrenia and Bipolar Illness”), as an intermediate molecular phenotype, to identify, characterize and target subphenotypes of these disorders. Findings from the VA discovery cohort will be validated in the PsycheMERGE and BioMe cohorts.  First, we will impute tissue and cell-type specific transcriptomes for all individuals with schizophrenia (SCZ) or bipolar disorder (BD) in the VA discovery cohort. To achieve this, we will train tissue (brain and peripheral tissues) and cell-type (glutamatergic & GABAergic neurons, astrocytes, oligodendrocytes, and microglia from DLPFC) specific EpiXcan transcriptomic imputation models at the gene and isoform level. Secondly, we will use the imputed transcriptomes as an intermediate molecular phenotype to identify genetically-regulated gene expression (GReX) based subpopulations and within them the key molecular drivers using deep neural networks (DNNs). Lastly, we will identify key non-genetic biomarkers and effective treatments for each validated subphenotype. Non-genetic biomarkers will be based on pre-mined features available from the electronic health records (EHR) and features extracted from the EHR via natural language processing (NLP). The subphenotypes will be validated in the civilian cohorts PsycheMERGE and BioMe.  This project will take place at the Icahn School of Medicine, one of the leading centers of data science, genomics and precision medicine. The mentoring committee comprises experts in the fields of computational and functional genomics, integrative analysis, machine learning (including DNNs and NLP), and EHR mining. Dr. Voloudakis will develop the skills necessary to launch an independent academic career in genetically based EHR-informed precision psychiatry. PROJECT NARRATIVE  Schizophrenia (SCZ) and bipolar disorder (BD) are genetically correlated, highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity with partially overlap- ping symptomatology and treatment. This project will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD to identify, characterize and target subphenotypes of those disorders. We will use the Million Veteran Program and Cooperative Studies Program 572 (“The Genetics of Functional Disability in Schizophrenia and Bipolar Illness”) as the discovery cohorts and will validate our findings in the PsycheMERGE and BioMe cohorts.",Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes,10166951,K08MH122911,"['Astrocytes', 'Biological', 'Biological Markers', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Case-Control Studies', 'Classification', 'Complex', 'Data Science', 'Development', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Epigenetic Process', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Glutamates', 'Goals', 'Heritability', 'Heterogeneity', 'Individual', 'Intervention', 'Machine Learning', 'Mentors', 'Methods', 'Microglia', 'Mining', 'Modeling', 'Molecular', 'Natural Language Processing', 'Neurons', 'Neurosciences', 'Oligodendroglia', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Population Genetics', 'Positioning Attribute', 'Precision therapeutics', 'Prefrontal Cortex', 'Productivity', 'Protein Isoforms', 'Psychiatry', 'Relative Risks', 'Research', 'Risk', 'Sample Size', 'Schizophrenia', 'Selection for Treatments', 'Severity of illness', 'Symptoms', 'Tissues', 'Training', 'Treatment outcome', 'Variant', 'Veterans', 'base', 'biological heterogeneity', 'career', 'cell type', 'clinical heterogeneity', 'cohort', 'comorbidity', 'computational basis', 'cooperative study', 'deep learning', 'deep neural network', 'drug repurposing', 'effective therapy', 'experience', 'functional disability', 'functional genomics', 'improved', 'medical schools', 'molecular phenotype', 'neuropsychiatric disorder', 'next generation', 'non-genetic', 'novel', 'novel therapeutic intervention', 'patient subsets', 'polygenic risk score', 'precision medicine', 'programs', 'psychopharmacologic', 'skills', 'symptomatology', 'trait', 'transcriptome', 'transcriptomics', 'treatment response']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,K08,2021,192240
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"Swift.ai: research and development of an integrated platform for machine-assisted research synthesis Project Abstract (30 lines of text)  1 Systematic review and evidence mapping, both forms of research synthesis, are formal, sequential processes  2 for identifying, assessing, and integrating the primary scientific literature. These approaches, already  3 cornerstones of evidence-based medicine, have recently gained significant popularity in several other  4 disciplines including environmental, agricultural, and public health research and are increasingly utilized for  5 informed decision making by governmental organizations. It has been estimated that more than 25,000  6 systematic reviews are conducted and published annually and selecting studies for inclusion is one of the most  7 resource intensive steps for any systematic review or evidence map. In Phase I of our research plan, we have  8 developed a web-based, collaborative systematic review web application called SWIFT-Active Screener, an  9 innovative document screening tool that allows users to identify the majority of relevant articles after screening 10 only a fraction of the total number of abstracts. Our goal for the current proposal is to conduct additional 11 research and development required to make SWIFT-Active Screener a commercial success, while also 12 building on and leveraging methods and software we have previously built to address other stages in the 13 systematic review pipeline. Therefore, one of the primary aims of our ongoing research and development is to 14 address this need by expanding the Active Screener application into an integrated platform for research 15 synthesis by uniting it with several of our other related software products. The resulting platform, which we call 16 “swift.ai,” is described in detail in “Aim 1 – Software engineering to create a unified platform for research 17 synthesis.” In “Aim 2 – Improved statistical methods for Active Screener 2.0”, we expand on the methodological 18 research completed during Phase I of this SBIR, to further develop and refine our methods. Specifically, we 19 investigate new ways to integrate state-of-the art methods in deep learning and new ways to better utilize the 20 large amounts of screening data collected from our users in order to improve our models. Finally, in “Aim 3 – 21 Living evidence maps powered by Active Screener 2.0,” we explore new approaches for using machine 22 learning to facilitate evidence mapping. Project narrative Systematic review is a formal process used widely in evidence-based medicine and environmental health research to identify, assess, and integrate the primary scientific literature with the goal of answering a specific, targeted question in pursuit of the current scientific consensus. By conducting research and development to build a unified, web-based, collaborative, systematic review software application that integrates the latest developments in deep-learning, machine learning, natural language processing and artificial intelligence, we will make an important contribution toward ongoing efforts to automate systematic review. These efforts will serve to make systematic reviews both more efficient to produce and less expensive to maintain, a result which will greatly accelerate the process by which scientific consensus is obtained in a variety of medical and health-related disciplines having great public significance.",Swift.ai: research and development of an integrated platform for machine-assisted research synthesis,10259172,R44ES029001,"['Active Learning', 'Address', 'Adoption', 'Agriculture', 'Artificial Intelligence', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Set', 'Decision Making', 'Development', 'Discipline', 'Elements', 'Endocrine disruption', 'Environmental Health', 'Evidence Based Medicine', 'Feedback', 'Focus Groups', 'Goals', 'Government', 'Health', 'Influentials', 'Internet', 'Learning', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Methods', 'Mission', 'Modeling', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Online Systems', 'Phase', 'Policies', 'Positioning Attribute', 'Problem Formulations', 'Procedures', 'Process', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Review Literature', 'Sampling', 'Scientist', 'Screening procedure', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Statistical Methods', 'System', 'Testing', 'Text', 'Toxicology', 'Uncertainty', 'Update', 'active method', 'cost', 'data modeling', 'data sharing', 'deep learning', 'evidence base', 'improved', 'innovation', 'novel strategies', 'public health research', 'research and development', 'response', 'screening', 'simulation', 'success', 'systematic review', 'user-friendly', 'web app']",NIEHS,"SCIOME, LLC",R44,2021,820314
"Deep learning based antibody design using high-throughput affinity testing of synthetic sequences Project Summary We will develop and apply a new high-throughput methodology for rapidly designing and testing antibodies for a myriad of purposes, including cancer and infectious disease immunotherapeutics. We will improve upon current approaches for antibody design by providing time, cost, and humane benefits over immunized animal methods and greatly improving the power of present synthetic methods that use randomized designs. To accomplish this, we will display millions of computationally designed antibody sequences using recently available technology, test the displayed antibodies in a high-throughput format at low cost, and use the resulting test data to train molecular dynamics and machine learning methods to generate new sequences for testing. Based on our test data our computational method will identify sequences that have ideal properties for target binding and therapeutic efficacy. We will accomplish these goals with three specific aims. We will develop a new approach to integrated molecular dynamics and machine learning using control targets and known receptor sequences to refine our methods for receptor generalization and model updating from observed data (Aim 1). We will design an iterative framework intended to enable identification of highly effective antibodies within a minimal number of experiments, in which our methods automatically propose promising antibody sequences to profile in subsequent assays (Aim 2). We will employ rounds of automated synthetic design, affinity test, and model improvement to produce highly target-specific antibodies. (Aim 3). ! Project Narrative We will develop new computational methods that learn from millions of examples to design antibodies that can be used to help cure a wide variety of human diseases such as cancer and viral infection. Previous antibody design approaches used a trial and error approach to find antibodies that worked well. In contrast our mathematical methods will directly produce new antibody designs by learning from large-scale experiments that test antibodies for function against disease targets. !",Deep learning based antibody design using high-throughput affinity testing of synthetic sequences,10116306,R01CA218094,"['Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Binding', 'Biological Assay', 'Budgets', 'Classification', 'Cloud Computing', 'Communicable Diseases', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Fc Receptor', 'Goals', 'Human', 'Immunize', 'Immunotherapeutic agent', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modeling', 'Molecular Machines', 'Oligonucleotides', 'Output', 'Performance', 'Phage Display', 'Property', 'Randomized', 'Research', 'Services', 'Specific qualifier value', 'Specificity', 'Statistical Models', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Thinness', 'Time', 'Training', 'Treatment Efficacy', 'Update', 'Virus Diseases', 'Work', 'antibody test', 'base', 'cloud based', 'commercialization', 'computing resources', 'cost', 'deep learning', 'design', 'experimental study', 'human disease', 'improved', 'iterative design', 'learning strategy', 'machine learning method', 'mathematical methods', 'molecular dynamics', 'novel', 'novel strategies', 'outcome prediction', 'predictive test', 'receptor']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,591130
"Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation Project Summary / Abstract  Almost 400,000 cases of out-of-hospital cardiac arrest (OHCA) occur each year in the United States. In patients requiring cardiopulmonary resuscitation (CPR) for prolonged periods, current CPR methods are unable to maintain adequate blood flow and oxygen delivery to the vital organs. Survival is <10% in patients with shockable rhythms and ~0% in those with non-shockable rhythms. Current American Heart Association (AHA) recommendations for CPR follow a “one-size-fits-all” paradigm. Our goal is to improve vital organ perfusion during prolonged CPR by “personalizing” compression/decompression therapy with a dynamic CPR method that changes compression characteristics over the course of CPR after taking into account the temporal changes of chest wall compliance and hemodynamics in order to increase the rate of neurologically intact survival after OHCA.  In this grant proposal, we are investigating the deployment of machine learning algorithms incorporated into a mechanical CPR device to predict and optimize hemodynamics during CPR. We will use state-of-the-art dynamical modeling in conjunction with closed-loop control algorithms to individualize CPR characteristics and optimize temporal blood flow. Our preliminary results suggest that deployment of machine learning prediction algorithms paired with control algorithms in a preclinical Ventricular Fibrillation model can adapt compression and decompression depth in real time, resulting in increased vital organ blood flow as compared to standard CPR techniques Based on these results, we hypothesize that optimization of compression depth, decompression depth, duty cycle, and compression rate of CPR will lead to better outcomes. Our proposed research will: 1) identify the most promising algorithm for the prediction of CPR hemodynamics 2) identify the best control algorithm to pair with this prediction algorithm in terms of optimizing CPR hemodynamics and return of spontaneous circulation 3) use the prediction and control pairing to improve 48h neurologically intact survival in a porcine model of ventricular fibrillation, as compared to standard CPR techniques. Throughout this process, we will identify non-invasive alternative measurements to provide to the algorithms with the ultimate goal of proceeding with device development and human trials. Project Narrative In light of a growing body of evidence which suggests that prolonged duration CPR is a dynamic process, without universally optimal “one-size-fits-all” parameters, advanced methods of CPR individualization may be applied to optimize cardiac and cerebral perfusion for these patients. We propose to study the effects of machine learning and optimal control techniques within the context of CPR, thus creating a closed-loop CPR system that has been trained by pre-clinical data to modify CPR characteristics and optimize blood flow. Our preliminary studies suggest that machine learning and control algorithms can be successfully deployed in a preclinical model to adapt compression and decompression depth, increasing vital organ blood flow as compared to standard CPR techniques. If our hypotheses are verified, a gateway for the first human trials is open.",Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation,10186125,R01HL157625,"['Acute', 'Algorithms', 'American Heart Association', 'Animal Experiments', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biofeedback', 'Blood Circulation', 'Blood flow', 'Carbon Dioxide', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Cerebrum', 'Cessation of life', 'Characteristics', 'Chest wall structure', 'Choices and Control', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Databases', 'Device or Instrument Development', 'Devices', 'E-learning', 'Early Mobilizations', 'Evaluation', 'Family suidae', 'Feedback', 'Frequencies', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Hospitals', 'Hour', 'Human', 'Knowledge', 'Learning', 'Light', 'Linear Regressions', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Near-Infrared Spectroscopy', 'Neurologic', 'Organ', 'Outcome', 'Oxygen', 'Patients', 'Performance', 'Perfusion', 'Phase I Clinical Trials', 'Pre-Clinical Model', 'Process', 'Publishing', 'Recommendation', 'Research', 'Resuscitation', 'Shock', 'Survival Rate', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Ventricular Fibrillation', 'Ventricular Tachycardia', 'algorithm training', 'base', 'clinically relevant', 'coronary perfusion', 'experience', 'experimental study', 'hemodynamics', 'improved', 'in vivo', 'indexing', 'innovation', 'machine learning algorithm', 'neural network', 'out-of-hospital cardiac arrest', 'pre-clinical', 'prediction algorithm', 'pressure', 'prospective', 'time interval']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2021,547699
"Multimodal monitoring and high-dimensional data for episode prediction in bipolar disorder SUMMARY Bipolar disorder (BD) is a mood disorder with high recurrence and disability rates, high economic burden, and an estimated suicide risk 20 times higher than the general population. While efficacious treatment is available, BD patients spend a large proportion of their life symptomatic. Predicting the onset of episodes is a valuable strategy to decrease suicide and disability rates and to optimize healthcare costs. The overall objective of this (R21) Exploratory/Developmental study is to obtain pilot data to support the feasibility and potential value of a new approach to predict mood episodes in stable adult patients with BD. This proposal aims to develop new data modeling and inference techniques that will enable more tailored clinical signal detection: examining changes within each individual, over time. To do so, we propose integrating multimodal, high-dimensional telemonitoring data, nonlinear techniques and artificial intelligence classification systems. This approach builds on our preliminary work on: (i) nonlinear techniques for the study of mood regulation in BD; (ii) an award-winning simulation using a machine learning technique (Markov Brains) for episode prediction in BD. AIMS: Aim 1 (feasibility): To obtain and integrate multimodal data to perform time-series analysis and to calculate entropy levels in 90 euthymic BD adults. Exploratory Aim 2 (potential value): To use machine learning techniques (Markov Brains) to distinguish participants at higher risk for a depressive or manic relapse based on their time-series and entropy levels (from Aim 1). HYPOTHESES: H1: We will be able to collect enough data in 80% of our participants and to integrate multimodal data to perform time-series analysis and to calculate entropy levels. H2: Markov Brains will identify participants at higher risk for a mood episode based on high (vs. low) auto-correlated time-series and low (vs. high) entropy levels. SIGNIFICANCE: This R21 application challenges more traditional prediction models by conceptualizing inter- and intra-individual variability as a dynamic property of biological systems. By leveraging densely-sampled objective and subjective data, autonomic, clinical and demographic data, this proposal aims to develop inference techniques that will examine changes within each individual, over time, in order to enhance the estimation performance. Ultimately, if we develop the capacity to predict mood episodes, we should be able to prevent them. NARRATIVE The proposed research is clinically relevant as it could develop new data modeling and inference techniques that will enable more tailored clinical signal detection: examining changes within each individual, over time, in order to predict mood changes indicative of an imminent episode of illness in bipolar disorder. The project supports the goals of strategy 2.2 of NIMH Strategic Research priorities by creating predictive algorithms at the individual level (what is an individual’s digital signature like, and how well does deviation from that signature predict an event?)",Multimodal monitoring and high-dimensional data for episode prediction in bipolar disorder,10217550,R21MH123849,"['Address', 'Adult', 'Anxiety', 'Arrhythmia', 'Artificial Intelligence', 'Award', 'Behavior', 'Bipolar Disorder', 'Brain', 'Classification', 'Clinical', 'Collection', 'Complex', 'Data', 'Detection', 'Disease', 'Economic Burden', 'Entropy', 'Event', 'Exploratory/Developmental Grant', 'First Degree Relative', 'Future', 'General Population', 'Goals', 'Health Care Costs', 'Health Technology', 'Heart Diseases', 'Individual', 'International', 'Life', 'Machine Learning', 'Manic', 'Mathematics', 'Measures', 'Mental Health', 'Mental disorders', 'Metabolic Diseases', 'Methods', 'Modeling', 'Monitor', 'Mood Disorders', 'Moods', 'National Institute of Mental Health', 'Paper', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physics', 'Physiological', 'Population', 'Property', 'Recommendation', 'Recurrence', 'Relapse', 'Research', 'Research Priority', 'Sampling', 'Series', 'Signal Transduction', 'Sleep', 'Societies', 'Suicide', 'System', 'Techniques', 'Time', 'Time Series Analysis', 'Visual', 'Work', 'analog', 'analytical method', 'base', 'biological systems', 'clinically relevant', 'data modeling', 'depressive symptoms', 'digital', 'digital health', 'disability', 'efficacious treatment', 'heart rate variability', 'high dimensionality', 'high risk', 'individual variation', 'mHealth', 'mood regulation', 'multidimensional data', 'multimodal data', 'multimodality', 'new technology', 'novel', 'novel strategies', 'prediction algorithm', 'predictive modeling', 'predictive signature', 'prevent', 'simulation', 'suicidal risk', 'telemonitoring', 'tool']",NIMH,CENTRE FOR ADDICTION AND MENTAL HEALTH,R21,2021,136658
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746
"Advanced machine learning algorithms that integrate genomewide, longitudinal MRI and demographic data to predict future cognitive decline toward dementia ABSTRACT The “preclinical” phase of Alzheimer’s disease (AD) is characterized by abnormal levels of brain amyloid accumulation in the absence of major symptoms, can last decades, and potentially holds the key to successful therapeutic strategies. Today there is an urgent need for quantitative biomarkers and genetic tests that can predict clinical progression at the individual level. This project will develop cutting edge machine learning algorithms that will mine high dimensional, multi-modal, and longitudinal data to derive models that yield individual-level clinical predictions in the context of dementia. The developed prognostic models will specifically utilize ubiquitous and affordable data types: structural brain MRI scans, saliva or blood-derived genome-wide sequence data, and demographic variables (age, education, and sex). Prior research has demonstrated that all these variables are strongly associated with clinical decline to dementia, however to date we have no model that can harvest all the predictive information embedded in these high dimensional data. Machine learning (ML) algorithms are increasingly used to compute clinical predictions from high- dimensional biomedical data such as clinical scans. Yet, most prior ML methods were developed for applications where the ``prediction’’ task was about concurrent condition (e.g., discriminate cases and controls); and established risk factors (e.g., age), multiple modalities (e.g., genotype and images) and longitudinal data were not fully exploited. This application’s core innovation will be to develop rigorous, flexible, and practical ML methods that can fully exploit multi-modal, longitudinal, and high- dimensional biomedical data to compute prognostic clinical predictions. The proposed project will build on the PI’s strong background in computational modeling and analysis of large-scale biomedical data. We will employ an innovative Bayesian ML framework that offers the flexibility to handle and exploit real-life longitudinal and multi-modal data. We hypothesize that the developed models will be more useful than alternative benchmarks for identifying preclinical individuals who are at heightened risk of imminent clinical decline. We will use a statistically rigorous approach for discovery, cross-validation, and benchmarking the developed tools. This project will yield freely distributed, documented, and validated software and models for predicting future clinical progression based on whole-genome, longitudinal structural MRI and demographic data. We believe the algorithms and software we develop will yield invaluable tools for stratifying preclinical AD subjects in drug trials, optimizing future therapies, and minimizing the risk of adverse effects. NARRATIVE Emerging technologies allow us to identify clinically healthy subjects harboring Alzheimer’s pathology. While many of these preclinical individuals progress to dementia, sometimes quite quickly, others remain asymptomatic for decades. The proposed project will develop sophisticated data mining algorithms to derive models that can predict future clinical decline based on ubiquitous, easy- to-collect, and affordable data modalities: brain MRI scans, saliva or blood- derived whole-genome sequences, and clinical and demographic variables.","Advanced machine learning algorithms that integrate genomewide, longitudinal MRI and demographic data to predict future cognitive decline toward dementia",10188360,R01AG053949,"['Activities of Daily Living', 'Adverse effects', 'Age', 'Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Alzheimer&apos', 's disease pathology', 'Amyloid', 'Amyloid beta-Protein', 'Anatomy', 'Bayesian learning', 'Benchmarking', 'Biological Markers', 'Blood', 'Brain', 'Clinical', 'Clinical Data', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer software', 'Data', 'Dementia', 'Education', 'Elderly', 'Emerging Technologies', 'Foundations', 'Funding', 'Future', 'Genetic', 'Genomics', 'Genotype', 'Harvest', 'Hippocampus (Brain)', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Laboratories', 'Life', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Methods', 'Mining', 'Modality', 'Modeling', 'Outcome', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Prevention approach', 'Research', 'Risk', 'Risk Factors', 'Saliva', 'Scanning', 'Secondary Prevention', 'Site', 'Structure', 'Study Subject', 'Symptoms', 'Testing', 'Therapeutic', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'aging brain', 'base', 'big biomedical data', 'case control', 'clinical predictors', 'clinical risk', 'cognitive ability', 'cognitive testing', 'data mining', 'flexibility', 'functional disability', 'genetic testing', 'genome-wide', 'genomic data', 'genomic locus', 'high dimensionality', 'imaging biomarker', 'imaging genetics', 'improved', 'innovation', 'large scale data', 'machine learning algorithm', 'machine learning method', 'mild cognitive impairment', 'multidimensional data', 'multimodal data', 'multimodality', 'neuroimaging', 'novel', 'pre-clinical', 'predictive modeling', 'prognostic', 'risk minimization', 'serial imaging', 'sex', 'software development', 'sound', 'tool', 'whole genome']",NIA,CORNELL UNIVERSITY,R01,2021,410000
"Investigation of Stereotyped High-Frequency Oscillations with Computational Intelligence for the Prediction of Seizure Onset Zone in Epilepsy PROJECT SUMMARY Neurosurgical therapy of refractory epilepsy requires accurate localization of seizure onset zone (SOZ). In clinical practice, intracranial EEG (iEEG) is recorded in the epilepsy monitoring unit (EMU) over many days where multiple seizures are recorded to provide information to localize the SOZ. The prolonged monitoring in the EMU adds to the risk of complications and can include intracranial bleeding and potentially death. Recently, high frequency oscillations (HFO) of iEEG between 80 to 500 Hz are highly valued as a promising clinical biomarker for epilepsy. HFOs are believed to be clinically significant, and thus could be used for SOZ localization. However, HFOs can also be recorded from normal and non-epileptic cerebral structures. When defined only by rate or frequency, pathological HFOs are indistinguishable from physiological ones, which limit their application in epilepsy pre-surgical planning. In this proposal, to the best of our knowledge, we show of a recurrent waveform pattern that distinguishes pathological HFOs from physiological ones. In particular, we observed that the SOZ generates repeatedly a set of stereotyped HFO waveforms whereas the HFOs from nonepileptic regions were irregular in their waveform morphology. Based on these observations, using computational tools built on recent advances in sparse coding and unsupervised machine learning techniques, we propose to detect these stereotyped recurrent HFO waveform patterns directly from the continuous iEEG data of adult and pediatric patients and test their prognostic value by correlating the spatial distribution of detected events to clinical findings such as SOZ, resection zone and seizure freedom. We hypothesize that accurate detection of pathologic HFOs in brief iEEG recordings can identify the SOZ and eliminate the necessity of prolonged EMU monitoring and reduce the associated risks. With these motivations, in this project an interdisciplinary team composed of biomedical engineers, epileptologists and neurosurgeons will work together to develop and test novel computational tools to detect stereotyped HFOs and its subtypes in large iEEG datasets recorded with clinical electrodes. Developed algorithms and iEEG data will be shared with the research community to contribute to the reproducible research and help other research groups to develop novel methods. The results of this study will be essential for achieving our group's long term goal of developing an online neural signal processing system for the rapid and accurate identification of SOZ with brief invasive recording. PROJECT NARRATIVE Prolonged iEEG monitoring for SOZ localization does add to the risk of complications and may include serious issues, such as intracranial bleeding, meningoencephalitis, and eventually death. The intellectual merit of this project is to develop computational intelligence tools based on recent advances in sparse coding and unsupervised machine learning techniques to investigate stereotyped high frequency oscillations (HFOs) in long-term iEEG and test the hypothesis whether the automated detection of HFOs will yield accurate and fast identification of SOZ.",Investigation of Stereotyped High-Frequency Oscillations with Computational Intelligence for the Prediction of Seizure Onset Zone in Epilepsy,10131881,R01NS112497,"['Adult', 'Algorithms', 'Area', 'Biomedical Engineering', 'Brain', 'Cerebrum', 'Cessation of life', 'Characteristics', 'Child', 'Clinical', 'Code', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Electrodes', 'Electroencephalography', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Freedom', 'Frequencies', 'Goals', 'Hemorrhage', 'High Frequency Oscillation', 'Hospitals', 'Hour', 'Intractable Epilepsy', 'Investigation', 'Laboratories', 'Language', 'Lesion', 'Meningoencephalitis', 'Methods', 'Modernization', 'Monitor', 'Morphology', 'Motivation', 'Motor', 'Motor Cortex', 'Multicenter Studies', 'Neocortex', 'Neurosurgeon', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Pattern', 'Physiological', 'Recurrence', 'Reproducibility', 'Research', 'Risk', 'Scheme', 'Seizures', 'Site', 'Spatial Distribution', 'Stereotyping', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Visual', 'Work', 'awake', 'base', 'clinical biomarkers', 'clinical practice', 'clinically significant', 'computational intelligence', 'computerized tools', 'cost', 'neurotransmission', 'novel', 'pediatric patients', 'prognostic value', 'prospective', 'signal processing', 'tool', 'unsupervised learning']",NINDS,UNIVERSITY OF HOUSTON,R01,2021,459231
"A Comprehensive Strategy to Detect Glaucoma Worsening Earlier and With Fewer Tests ABSTRACT  This is an application for a K23 Mentored Patient-Oriented Research Career Development Award. The goal of this proposal is to provide the candidate with the advanced skills needed to establish an independent research program in the area of glaucoma diagnostic testing with special expertise in test error correction and predictive modeling of future glaucoma outcomes. To facilitate this long-term goal, in the current proposal, the candidate’s main research goal is to reduce the time and number of tests necessary to detect glaucoma worsening by (1) correcting for errors in previously obtained visual field (VF) and peripapillary optical coherence tomography (OCT) tests by using multilevel models with Bayesian analysis (MLB) and generative adversarial networks (GAN) (2) stratifying eyes at high and low risk for rapid glaucoma worsening at the baseline clinical visit using deep convolutional neural networks (DCNN). These aims are based on high quality preliminary data which show that: (1) the effect of VF reliability metrics and OCT signal strength on test error can be quantified and thus corrected for and (2) machine learning methods can predict risk of future VF progression with fair accuracy with baseline visit VF data alone and therefore adding structural (OCT) and clinical information from the baseline visit is likely to improve model accuracy. The main hypotheses of the proposed research aims are (1) correcting for test errors with MLB and GAN will reduce the time needed to detect worsening by 10 and 20% respectively (2) combining baseline visit structural (OCT), functional (VF) and clinical data as inputs into DCNNs will allow us to achieve an area under the receiver operating curve of at least 0.8 at predicting the risk of future rapid glaucoma worsening. The candidate proposes a comprehensive training plan, combining formal coursework, meetings, seminars and workshops overseen by his diverse group of mentors. Specific training goals include: (1) Receiving training in multi-level regression modeling and Bayesian analysis techniques. (2) Becoming adept at data science with a special emphasis on learning Python for data extraction, manipulation and analysis. (3) Furthering knowledge of machine learning techniques with a specific emphasis on deep learning including DCNNs and GANs. (4) Continuing training in the ethical and responsible conduct of research. The training plan will be executed in coordination with the set of research activities mentioned above. Results from this research proposal will be used to develop a subsequent R01 research proposal that will facilitate the candidate’s transition to an independent researcher. PROJECT NARRATIVE The main aim of this study is to reduce the time and number of tests needed to accurately detect worsening of glaucoma by 1) correcting visual field and optical coherence tomography tests for errors and 2) accurately predicting future disease worsening based on baseline visit clinical, functional and structural data. This research will impact public health by identifying high risk patients earlier so that they can be appropriately managed to prevent vision loss and also by reducing unnecessary testing which places a significant burden on the healthcare system and patients.",A Comprehensive Strategy to Detect Glaucoma Worsening Earlier and With Fewer Tests,10105960,K23EY032204,"['Accounting', 'Affect', 'Area', 'Bayesian Analysis', 'Blindness', 'Calendar', 'Clinical', 'Clinical Data', 'Coupled', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnostic tests', 'Disease', 'Educational workshop', 'Effectiveness', 'Ethics', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Healthcare', 'Healthcare Systems', 'Image', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Physiologic Intraocular Pressure', 'Population', 'Public Health', 'Pythons', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resources', 'Risk', 'Signal Transduction', 'Stream', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Visit', 'Visual Acuity', 'Visual Fields', 'Work', 'base', 'clinical decision-making', 'compare effectiveness', 'convolutional neural network', 'deep learning', 'demographics', 'field study', 'high risk', 'improved', 'longitudinal database', 'machine learning method', 'meetings', 'model design', 'multilevel analysis', 'neural network architecture', 'predictive modeling', 'preservation', 'prevent', 'programs', 'responsible research conduct', 'retinal nerve fiber layer', 'skills', 'tool', 'wasting']",NEI,JOHNS HOPKINS UNIVERSITY,K23,2021,191187
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"Validating of Machine Learning-Based EEG Treatment Biomarkers in Depression SUMMARY/ABSTRACT The overarching aim of Alto Neuroscience is to advance brain-based biomarkers for psychiatric disorders in order to both optimize treatment pathways and drive the development of novel pharmacological and non- pharmacological interventions. Alto does this by developing and applying sophisticated machine learning computational models to electroencephalography (EEG) data collected at scale in real-world clinical treatment contexts. Specifically, in this direct-to-phase II SBIR proposal we will refine, and then independently validate, two EEG-based candidate biomarkers we have identified for stratifying patients with depression in a manner that both factors biological heterogeneity and informs treatment response. One of our biomarkers was derived in a “top-down” (i.e. supervised) manner by trying to directly predict treatment outcome, while the other biomarker presents a complimentary “bottom-up” (i.e. unsupervised) approach that begins by first identifying the most biologically homogeneous subset of patients and then testing the treatment relevance of the subtyping. Together, these findings represent very robust individual patient-level treatment-relevant EEG biomarkers, and in both cases, help define a critically-important objective approach to prospectively identifying and treating treatment- resistant depressed patients. A successful outcome of the proposed work would yield the first FDA-cleared biomarkers for stratifying psychiatric conditions. It would also provide a basis for targeted development of pharmacological and non-pharmacological interventions based on the EEG biomarkers. Both outcomes hold substantial commercial value and exciting potential for transforming psychiatry. PROJECT NARRATIVE The overarching aim of Alto Neuroscience is to advance brain-based biomarkers for psychiatric disorders in order to both optimize treatment pathways and drive the development of novel pharmacological and non- pharmacological interventions. Here we propose to refine, and then independently validate, two EEG-based candidate biomarkers we have identified for stratifying patients with depression in a manner that both factors biological heterogeneity and informs treatment response. A successful outcome of the proposed work would yield the first FDA-cleared biomarkers for stratifying psychiatric conditions. It would also provide a basis for targeted development of pharmacological and non-pharmacological interventions based on the EEG biomarkers.",Validating of Machine Learning-Based EEG Treatment Biomarkers in Depression,10116492,R44MH123373,"['Address', 'Antidepressive Agents', 'Award', 'Base of the Brain', 'Biological', 'Biological Factors', 'Biological Markers', 'Caring', 'Clinic', 'Clinical', 'Clinical Treatment', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Electroencephalography', 'Enrollment', 'Extravasation', 'Feedback', 'Funding', 'Intervention', 'Laboratories', 'Lead', 'Machine Learning', 'Maps', 'Medical Device', 'Mental Depression', 'Mental disorders', 'Methods', 'Neurosciences', 'Outcome', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Placebos', 'Procedures', 'Psychiatry', 'Regulation', 'Research', 'Resistance', 'Resistance profile', 'Scientist', 'Seeds', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Source', 'Supervision', 'System', 'Testing', 'Training', 'Training Programs', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'base', 'biological heterogeneity', 'candidate marker', 'clinical care', 'cohort', 'commercialization', 'comorbidity', 'computerized data processing', 'cost', 'data acquisition', 'depressed patient', 'individual patient', 'meetings', 'novel', 'patient stratification', 'patient subsets', 'programs', 'prospective', 'repetitive transcranial magnetic stimulation', 'response', 'software development', 'supervised learning', 'therapy resistant', 'tool', 'treatment optimization', 'treatment response', 'treatment-resistant depression', 'unsupervised learning']",NIMH,"ALTO NEUROSCIENCE, INC.",R44,2021,1184093
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"Real time colon histopathology by infrared spectroscopic imaging Abstract Colorectal cancer (CRC) is one of the leading causes of death in the US. Active screening and early intervention in risky cancers can lead to good outcomes; however, a bottleneck in rapidly delivering appropriate patient care is the long time period for histologic assessment and lack of precision in predicting disease severity. Morphological assessments prevalent in histology are useful but resource intensive and not predictive enough. Molecular techniques to complement traditional pathology are emerging but often require much more effort and time, without being especially compatible with histologic assessments. Here, we seek to develop a technology that measures the chemical content of tissues, does not require reagents, is entirely compatible with clinical workflows and leverages modern artificial intelligence (AI) techniques to provide real-time histologic assessment. The foundation of our approach is a new design for an infrared spectroscopic imaging system that is faster than any reported, offers a higher spatial and spectral quality and uses a solid immersion lens with a fixed focus at the sealed surface of the lens to enable use by a minimally trained person. In conjunction with the instrument, we develop AI algorithms that measure the chemical content of tissue and use it to provide (a) conventional pathology images without the use of dyes (“stainless staining”), and (b) histologic assessment based on molecular data, which can provide complementary composition, disease and risk of lethal cancer images akin to conventional pathology. The instrument will be usable by laboratory technicians, without the need to prepare thin sections from excised tissue and will provide information in minutes. Using preliminary data from human patients on over 850 tissue microarray (TMA) samples from 8 TMAs and 30 surgical resections, we validate the use of technology in providing complete histologic and disease grade assessment. Statistical methods will be used to assess the results rigorously and quantitative milestones guide the entire approach. We then translate the results to fresh tissue chunks, providing histology minutes after tissue is extracted from the body. Finally, we use the detailed tumor and microenvironment information available from the tissue to segment patients into a “high risk” and “low risk” group. The availability of rapid histologic assessment can help prevent delays in providing care, provide intraoperative assessment, and add more information to morphologic assessments following screening, enabling a wide use in CRC and other cancer pathologies. Project Narrative Colorectal cancers (CRC) are among the leading causes of death from cancers in the US. Morphologically assessing excised tissue is the gold standard but requires fixation, staining, microscopy and pathology review, taking days and the information not being especially prognostic. This project develops an alternate technology based on chemical imaging evaluation that can provide an assessment within minutes, resulting in a new instrument, artificial intelligence methods for histology and microenvironment-powered prediction of disease course.",Real time colon histopathology by infrared spectroscopic imaging,10318008,R01CA260830,"['Analysis of Variance', 'Archives', 'Artificial Intelligence', 'Benchmarking', 'Cancerous', 'Caring', 'Cause of Death', 'Chemicals', 'Clinical', 'Code', 'Collaborations', 'Colon', 'Color', 'Colorectal Cancer', 'Complement', 'Computer software', 'Confusion', 'Custom', 'Data', 'Detection', 'Disease', 'Dyes', 'Early Intervention', 'Electronics', 'Epithelial Cells', 'Excision', 'Foundations', 'Fourier Transform', 'Fresh Tissue', 'Future', 'Goals', 'Gold', 'Histocompatibility Testing', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immersion', 'Laboratories', 'Laboratory Chemicals', 'Laboratory Technicians', 'Lead', 'Logistic Regressions', 'Lymph Node Involvement', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microtomy', 'Modeling', 'Modernization', 'Molecular', 'Molecular Analysis', 'Morphology', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Polyps', 'Process', 'Protocols documentation', 'ROC Curve', 'Reagent', 'Regression Analysis', 'Reporting', 'Research', 'Resources', 'Risk', 'Route', 'Sampling', 'Severity of illness', 'Solid', 'Spectroscopy, Fourier Transform Infrared', 'Staging', 'Stains', 'Statistical Methods', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Microarray', 'Tissues', 'Training', 'Translating', 'Validation', 'Work', 'analytical method', 'base', 'cancer diagnosis', 'cancer imaging', 'cell type', 'clinical translation', 'colorectal cancer treatment', 'coronavirus disease', 'deep learning', 'design', 'design and construction', 'disorder risk', 'experience', 'follow-up', 'high risk', 'human data', 'imaging system', 'improved outcome', 'instrument', 'intelligent algorithm', 'learning strategy', 'lens', 'novel', 'pathology imaging', 'pre-clinical', 'prevent', 'prognostic', 'real-time images', 'rural setting', 'sample fixation', 'screening', 'seal', 'spectroscopic imaging', 'success', 'technology validation', 'tissue archive', 'tool', 'tumor microenvironment']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,466088
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10265769,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,482268
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10113533,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,596017
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,10214625,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2021,3125
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,10149998,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air Movements', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Smoking History', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'Visualization', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'former smoker', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'respiratory morbidity', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2021,185497
"Optical Coherence Elastography of the Cornea PROJECT SUMMARY The fundamental physical properties of the outer tunic of the eye determine the structural characteristics of the ocular globe and may be altered in several devastating disease states including axial elongation in myopia, pathological deformation in keratoconus, and iatrogenic keratoectasia following corneal refractive surgery. These biomechanical tissue characteristics not only influence our clinical interpretation of diagnostic tests, e.g. measurement of intraocular pressure, but have been implicated as important factors in the development of glaucoma. Currently, there is no available reliable method to perform quantitative measurement of corneal elasticity in vivo. Here we will develop novel method for the assessment of corneal elastic properties that could potentially be used for routine clinical diagnostic and treatment. This method will take advantages of highly localized air pressure stimulation and ultra-sensitive detection and analysis of the pressure waves propagation on corneal posterior and anterior surfaces with a line-field Optical Coherence Tomography to reconstruct volumetric biomechanical properties of the cornea. Our previous work has made fundamental advances in the understanding of corneal biomechanics through a novel approach with potentially impactful applications in other disciplines (e.g. cataract surgery, LAISK, corneal cross-linking, and tissue transplants with personalize treatments). The proposed studies will accelerate transition of this technology into clinics, influence our selection and application of corneal surgical treatments and will help us to understand the structural consequences of corneal disease and wound healing: Aim 1. Develop a line-field OCE (LF-OCE) system for ultrafast 3D clinical imaging. Aim 2. In vivo studies with rabbits. Aim 3. Preliminary clinical studies in humans. Aim 4. Refine numerical (FEM) and Artificial Intelligence (AI) models of the depth-dependent nonlinear viscoelastic properties of the cornea. PROJECT NARRATIVE This proposal will focus on the development of novel technology and methods for noninvasive assessment of biomechanical properties of the cornea. Development of such a technique would significantly advance our understanding of the corneal disorders, allow developing novel clinical therapies and interventions, and improve outcome of current surgical ant therapeutic interventions.",Optical Coherence Elastography of the Cornea,10256083,R01EY022362,"['3-Dimensional', 'Achievement', 'Agreement', 'Air Pressure', 'Animals', 'Anisotropy', 'Anterior', 'Ants', 'Artificial Intelligence', 'Beds', 'Biological', 'Biomechanics', 'Cataract Extraction', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Connective Tissue', 'Cornea', 'Corneal Diseases', 'Custom', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Diagnostic tests', 'Discipline', 'Disease', 'Elasticity', 'Eye', 'Glaucoma', 'Goals', 'Heterogeneity', 'Human', 'Iatrogenesis', 'Image', 'Individual', 'Intervention', 'Keratoconus', 'Knowledge', 'Laser In Situ Keratomileusis', 'Link', 'Location', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myopia', 'Nature', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathologic', 'Patients', 'Physiologic Intraocular Pressure', 'Physiological', 'Property', 'Protocols documentation', 'Reaction', 'Reporting', 'Research', 'Routine Diagnostic Tests', 'Shapes', 'Signal Transduction', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Tissue Transplantation', 'Tissues', 'Training', 'Tunic', 'Validation', 'Variant', 'Work', 'base', 'biomechanical model', 'clinical diagnostics', 'clinical imaging', 'clinical translation', 'clinically significant', 'convolutional neural network', 'corneal epithelial wound healing', 'crosslink', 'deep learning', 'denoising', 'design', 'elastography', 'improved', 'improved outcome', 'in vivo', 'insight', 'mechanical properties', 'models and simulation', 'new technology', 'novel', 'novel strategies', 'personalized medicine', 'physical property', 'pressure', 'response', 'success', 'viscoelasticity', 'visual tracking']",NEI,UNIVERSITY OF HOUSTON,R01,2021,397700
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,10316448,R00EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R00,2021,247154
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality Project Summary Climate change is the greatest public health challenge of the 21st century. While numerous pathways of the health impact of climate change have been proposed, the “climate penalty” effect, i.e., a warming temperature worsens ambient air quality and consequently influences human health, remains poorly understood, resulting in an underestimated public health burden associated with global warming. Our previous epidemiological studies have reported that higher summer mean temperatures and higher PM2.5 concentrations are each associated with increased all-cause mortality in the Medicare population (aged ≥65) in the Southeastern US (SEUS)1, 2. Satellite and ground-based observations suggest a strong dependence of air pollution on interannual variabilities of summer mean temperature in SEUS3. These findings suggest that the indirect health effect of temperature via the climate penalty on air quality can be potentially important in the SEUS region, in addition to the direct adverse effects that we observed. However, clear epidemiological evidence of the air pollution serving as a mediator for the health effects of temperature, and accurate estimate of this effect is still missing in current literature. Herein, drawing on our preliminary results, we hypothesize that rising temperature can indirectly affect all-cause mortality via worsening both PM2.5 and ozone levels in the SEUS. We propose a study that will leverage the Medicare cohort from 2000-2016 (124 million person-years), the largest longitudinal cohort available for the SEUS and the high-resolution temperature, PM2.5, and O3 data, to investigate all-cause mortality in response to the “climate penalty” effect using a mediation statistical analysis. Specifically, in this project we will (1) update the present- day temperature and ozone predictions at 1-km2 grids across the SEUS through 2016 by incorporating ensemble averaging of machine learning models; (2) quantify the health effect of “climate penalty” on all-cause mortality using a mediation analysis, and explore whether mitigating anthropogenic air pollution emissions might serve as a pathway of climate change adaptation; (3) perform a risk assessment on the excess deaths related to the climate penalty on air pollution for the mid- (2050) and late-21st century (2100), using climate model output, chemical transport modeling, along with the top-down estimate of “climate penalty” from Aim 2. The proposed research will improve understanding of the interplays between climate, air pollution, and human health based on real-world big data, and provide epidemiological evidence of an important pathway that climate change adversely affects human health, with immediate relevance to climate and environmental policymaking. Project Narrative This project aims to estimate the health effect of “climate penalty”, i.e., the rising temperature indirectly affects human health via worsening ambient air quality (primarily PM2.5 and ozone levels) using a mediation analysis based on satellite-retrieved exposures and Medicare all-cause mortality. We will test the hypotheses that 1) the indirect health effect of a warming climate by worsening air quality can be a major public health burden of future climate change, and 2) improving air quality by reducing anthropogenic emission can mitigate the health effect of climate penalty. We will also forecast the excess deaths in 2050 and 2100 related to the climate penalty on air pollution using climate model ensembles simulated for different emission scenarios.",Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality,10218738,R21ES032606,"['Address', 'Adverse effects', 'Affect', 'Air', 'Air Pollution', 'American', 'Big Data', 'Cessation of life', 'Chemicals', 'Chronic', 'Climate', 'Coupled', 'Data', 'Data Set', 'Databases', 'Dependence', 'Environmental Policy', 'Epidemiology', 'Frequencies', 'Future', 'Global Warming', 'Goals', 'Health', 'Health Insurance', 'Hospitalization', 'Human', 'Individual', 'Knowledge', 'Lead', 'Link', 'Literature', 'Longitudinal cohort', 'Machine Learning', 'Measures', 'Mediation', 'Mediator of activation protein', 'Medicare', 'Modeling', 'Outcome', 'Output', 'Ozone', 'Pathway interactions', 'Personal Satisfaction', 'Persons', 'Planet Earth', 'Policies', 'Policy Making', 'Pollution', 'Population', 'Population Study', 'Positioning Attribute', 'Public Health', 'Quality Control', 'Reaction', 'Reporting', 'Research', 'Resolution', 'Risk Assessment', 'Statistical Data Interpretation', 'Statistical Methods', 'Suggestion', 'Surface', 'Temperature', 'Testing', 'Update', 'Weather', 'air pollution control', 'anthropogenesis', 'atmospheric chemistry', 'base', 'climate change', 'climate impact', 'cohort', 'epidemiology study', 'experience', 'fine particles', 'human old age (65+)', 'improved', 'mortality', 'neural network', 'oxidation', 'pollutant', 'prevent', 'prospective', 'random forest', 'resilience', 'response', 'tropospheric ozone', 'ventilation', 'volatile organic compound', 'warm temperature']",NIEHS,EMORY UNIVERSITY,R21,2021,260895
"Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning ABSTRACT Alcoholic liver disease (ALD) is a serious global health problem. It encompasses a spectrum of pathological conditions, ranging from simple hepatic steatosis, steatohepatitis, fibrosis, alcoholic hepatitis, to liver cirrhosis. Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. As a result, management of ALD is frequently empiric. In recent years, some progress has been made using metabolomics to identify potential biomarkers of ALD in animal models and human cohorts. However, global metabolomic profiling of ALD in humans has proceeded slowly and as of today, no studies have been performed that relate metabolomic profiles with pathological changes occurring during the development of ALD. Our working hypothesis predicts that biomarkers specific to ALD may be more effectively identified by applying integrative machine learning to the analysis of data from two state-of-the-art analytical approaches, i.e., metabolomics and imaging mass spectrometry (IMS). As such, we propose to use plasma metabolomics (Specific Aim 1), and histological analysis and liver tissue IMS (Specific Aim 2) in three mouse models of ALD (alcohol-induced steatosis, hepatitis or mild fibrosis) to gain unique insights into the feasibility of using these approaches to identify pathogenic markers of ALD. Ethanol-induced damage to the liver results in alterations in cellular function that can be documented as changes in the metabolome of biological fluids (plasma) and hepatic cells. Metabolomics, the analysis of low molecular metabolites (e.g., lipids and small molecules) in a sample, can be used to directly investigate changes in biochemical pathways induced by alcohol in the liver, such as occurs during ALD. Tissue IMS maps molecules in a tissue section, thereby allowing the quantitation of lipids, proteins and metabolites within a tissue in unprecedented detail. When interfaced with histological analysis of a paired adjacent tissue section, the cellular source of the mapped molecules may be identified. We strongly believe that the integration of metabolomics, IMS and histology (Specific Aim 3) using integrative machine learning will greatly enhance our understanding of the biochemical basis of ALD pathophysiology, and in so doing, allow the development of diagnostic tools that can be used to detect biomarkers in other forms of ALD, thereby improving early diagnosis and treatment of ALD. The management and interpretation of large metabolomics and proteomic data generated as part of the project (10-100GB of raw IMS data per single tissue section) require advanced data-analytics solutions. We will capitalize on our recently published bespoke machine learning solution (“BASIS”) for interrogation of large “-omics” data to identify metabolic/signaling pathways and their downstream metabolites disrupted in ALD. The novelty of this proposal relies on the use of cutting-edge approaches that will allow identification of novel biomarkers and their cellular sources in predictable animal models of ALD. Such information will form a basis for more effective diagnosis and prediction of the progression of ALD. Successful completion of the proposed studies will form a foundation upon which studies in human biological fluids will be conducted in the future. In addition, it is anticipated that our studies will also lay the foundation for examination of the molecular mechanisms associated with other forms of alcohol-induced tissue injury. Such knowledge will facilitate the development of more effective treatments of alcohol abuse. NARRATIVE Excessive alcohol consumption induces alcoholic liver disease (ALD). Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. Because the early stages of ALD can potentially be reversed by sobriety, regular screening of the general population and early diagnosis are essential. The overarching goal of this application is to establish metabolomic analyses and tissue imaging mass spectrometry coupled with integrative machine learning to identify novel pathways in and biomarkers for ALD that will be applied in humans.","Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning",10140254,R21AA028432,"['Alcohol-Induced Disorders', 'Alcoholic Hepatitis', 'Alcoholic Liver Diseases', 'Alcoholic liver damage', 'Alcohols', 'Animal Model', 'Biochemical', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Cell physiology', 'Cells', 'Chronic', 'Complex', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Early treatment', 'Ethanol', 'Fatty Liver', 'Fibrosis', 'Foundations', 'Functional disorder', 'Future', 'General Population', 'Goals', 'Heavy Drinking', 'Hepatitis', 'Hepatocyte', 'Histologic', 'Histology', 'Human', 'Hybrids', 'Image', 'Individual', 'Inflammation', 'Investigation', 'Knowledge', 'Label', 'Link', 'Lipids', 'Liquid substance', 'Liver', 'Liver Cirrhosis', 'Liver diseases', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Metabolic', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Monoclonal Antibody R24', 'National Institute on Alcohol Abuse and Alcoholism', 'Pathogenicity', 'Pathologic', 'Pathway interactions', 'Pattern', 'Phase', 'Plasma', 'Process', 'Proteomics', 'Publishing', 'Recovery', 'Resources', 'Risk', 'Sampling', 'Signal Pathway', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Steatohepatitis', 'Structure', 'System', 'Tissue imaging', 'Tissues', 'alcohol abuse therapy', 'alcohol research', 'biobank', 'biomarker identification', 'candidate marker', 'cohort', 'diagnostic biomarker', 'effective therapy', 'global health', 'human subject', 'improved', 'insight', 'intrahepatic', 'liver biopsy', 'liver imaging', 'metabolome', 'metabolomics', 'molecular imaging', 'mouse model', 'novel', 'novel diagnostics', 'novel marker', 'potential biomarker', 'predictive marker', 'protein metabolite', 'screening', 'small molecule', 'sobriety', 'specific biomarkers', 'tissue injury', 'tool']",NIAAA,YALE UNIVERSITY,R21,2021,202259
"Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning ABSTRACT Alcoholic liver disease (ALD) is a serious global health problem. It encompasses a spectrum of pathological conditions, ranging from simple hepatic steatosis, steatohepatitis, fibrosis, alcoholic hepatitis, to liver cirrhosis. Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. As a result, management of ALD is frequently empiric. In recent years, some progress has been made using metabolomics to identify potential biomarkers of ALD in animal models and human cohorts. However, global metabolomic profiling of ALD in humans has proceeded slowly and as of today, no studies have been performed that relate metabolomic profiles with pathological changes occurring during the development of ALD. Our working hypothesis predicts that biomarkers specific to ALD may be more effectively identified by applying integrative machine learning to the analysis of data from two state-of-the-art analytical approaches, i.e., metabolomics and imaging mass spectrometry (IMS). As such, we propose to use plasma metabolomics (Specific Aim 1), and histological analysis and liver tissue IMS (Specific Aim 2) in three mouse models of ALD (alcohol-induced steatosis, hepatitis or mild fibrosis) to gain unique insights into the feasibility of using these approaches to identify pathogenic markers of ALD. Ethanol-induced damage to the liver results in alterations in cellular function that can be documented as changes in the metabolome of biological fluids (plasma) and hepatic cells. Metabolomics, the analysis of low molecular metabolites (e.g., lipids and small molecules) in a sample, can be used to directly investigate changes in biochemical pathways induced by alcohol in the liver, such as occurs during ALD. Tissue IMS maps molecules in a tissue section, thereby allowing the quantitation of lipids, proteins and metabolites within a tissue in unprecedented detail. When interfaced with histological analysis of a paired adjacent tissue section, the cellular source of the mapped molecules may be identified. We strongly believe that the integration of metabolomics, IMS and histology (Specific Aim 3) using integrative machine learning will greatly enhance our understanding of the biochemical basis of ALD pathophysiology, and in so doing, allow the development of diagnostic tools that can be used to detect biomarkers in other forms of ALD, thereby improving early diagnosis and treatment of ALD. The management and interpretation of large metabolomics and proteomic data generated as part of the project (10-100GB of raw IMS data per single tissue section) require advanced data-analytics solutions. We will capitalize on our recently published bespoke machine learning solution (“BASIS”) for interrogation of large “-omics” data to identify metabolic/signaling pathways and their downstream metabolites disrupted in ALD. The novelty of this proposal relies on the use of cutting-edge approaches that will allow identification of novel biomarkers and their cellular sources in predictable animal models of ALD. Such information will form a basis for more effective diagnosis and prediction of the progression of ALD. Successful completion of the proposed studies will form a foundation upon which studies in human biological fluids will be conducted in the future. In addition, it is anticipated that our studies will also lay the foundation for examination of the molecular mechanisms associated with other forms of alcohol-induced tissue injury. Such knowledge will facilitate the development of more effective treatments of alcohol abuse. NARRATIVE Excessive alcohol consumption induces alcoholic liver disease (ALD). Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. Because the early stages of ALD can potentially be reversed by sobriety, regular screening of the general population and early diagnosis are essential. The overarching goal of this application is to establish metabolomic analyses and tissue imaging mass spectrometry coupled with integrative machine learning to identify novel pathways in and biomarkers for ALD that will be applied in humans.","Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning",10382633,R21AA028432,"['Alcohol-Induced Disorders', 'Alcoholic Hepatitis', 'Alcoholic Liver Diseases', 'Alcoholic liver damage', 'Alcohols', 'Animal Model', 'Biochemical', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Cell physiology', 'Cells', 'Chronic', 'Complex', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Early treatment', 'Ethanol', 'Fatty Liver', 'Fibrosis', 'Foundations', 'Functional disorder', 'Future', 'General Population', 'Goals', 'Heavy Drinking', 'Hepatitis', 'Hepatocyte', 'Histologic', 'Histology', 'Human', 'Hybrids', 'Image', 'Individual', 'Inflammation', 'Investigation', 'Knowledge', 'Label', 'Link', 'Lipids', 'Liquid substance', 'Liver', 'Liver Cirrhosis', 'Liver diseases', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Metabolic', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Monoclonal Antibody R24', 'National Institute on Alcohol Abuse and Alcoholism', 'Pathogenicity', 'Pathologic', 'Pathway interactions', 'Pattern', 'Phase', 'Plasma', 'Process', 'Proteomics', 'Publishing', 'Recovery', 'Resources', 'Risk', 'Sampling', 'Signal Pathway', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Steatohepatitis', 'Structure', 'System', 'Tissue imaging', 'Tissues', 'alcohol abuse therapy', 'alcohol research', 'biobank', 'biomarker identification', 'candidate marker', 'cohort', 'diagnostic biomarker', 'effective therapy', 'global health', 'human subject', 'improved', 'insight', 'intrahepatic', 'liver biopsy', 'liver imaging', 'metabolome', 'metabolomics', 'molecular imaging', 'mouse model', 'novel', 'novel diagnostics', 'novel marker', 'potential biomarker', 'predictive marker', 'protein metabolite', 'screening', 'small molecule', 'sobriety', 'specific biomarkers', 'tissue injury', 'tool']",NIAAA,YALE UNIVERSITY,R21,2021,148243
"Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics PROJECT SUMMARY When an outbreak of an established or emerging infectious disease occurs we ask a standard set of questions that are critical to a lifesaving public health response: Where will future incidence occur? How many cases will there be? And where can we most effectively intervene? The proposed research is motivated by real world instances where answering these questions was critical to making practical public health decisions, and current methods came up short: from deciding if and where to build additional Ebola Treatment Units in the 2014-15 West African Ebola epidemic, to identifying priority districts where oral cholera vaccine should be used in the 2016-17 cholera outbreak in Yemen, to picking locations where sufficient cases might occur to selecting and prioritizing interventions to slow the spread of COVID-19 worldwide. Forecasts informing such decisions are typically generated either using an epidemic model that relies on knowledge of the disease transmission mechanism and epidemic theory or using a statistical model to project the expected number of cases based on the relationship between covariates and observed counts. However, both approaches are subject to limitations, particularly early in an epidemic when few cases are observed. This project is based on the overarching scientific premise that inferences that combine the strengths of mechanistic epidemic models and statistical covariate models will substantially outperform either approach alone in forecasting and making decisions to confront emerging infectious disease threats. Specifically, this project aims to (1) Develop a framework to forecast incidence in ongoing outbreaks that merges mechanistic and machine learning approaches; (2) Validate the framework using retrospective data and apply the framework to inform decision making in emerging epidemics; (3) Integrate this inferential forecasting framework into causal decision theory to optimize critical actions in the public health response to emerging epidemics; and (4) Develop accessible and extensible tools for forecasting and decision analysis in infectious disease epidemics. We will validate these approaches using rigorous simulation studies and by applying the proposed approaches to retrospective data from important recent epidemics (e.g., Ebola, Cholera and COVID-19, as mentioned above). We will prospectively apply our approach to inform the response to emerging disease threats that occur during the project period, including the ongoing COVID-19 pandemic. To ensure that the tools developed are useful, efficient, and user friendly, we will work with international humanitarian organizations responding to epidemics. Successful completion of these aims will provide a flexible and validated framework for forecasting and decision making during ongoing epidemics, while allowing for innovation in mechanistic and statistical approaches. In doing so it will provide tools to optimize responses and reduce morbidity and mortality during public health crises. PROJECT NARRATIVE The purpose of the proposed project is to improve inference, forecasting and decision making in response to emerging infectious diseases by developing a framework to integrate mechanistic and statistical approaches to epidemic modeling and causal inference. Approaches developed will be validated using simulations and retrospective data and applied prospectively to reduce morbidity and mortality in emerging public health crises. Further, they will be incorporated into publically available tools for use in epidemic response.",Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics,10142638,R01GM140564,"['African', 'Algorithms', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Cholera', 'Cholera Vaccine', 'Communicable Diseases', 'Community Health', 'Cost utility', 'Data', 'Data Set', 'Decision Analysis', 'Decision Making', 'Decision Theory', 'Disease', 'Disease Outbreaks', 'Ebola', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Evaluation', 'Fogs', 'Future', 'Geographic Locations', 'Incidence', 'International', 'Intervention', 'Knowledge', 'Liberia', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Online Systems', 'Oral', 'Policies', 'Public Health', 'Research', 'Research Personnel', 'Series', 'Shapes', 'Statistical Algorithm', 'Statistical Methods', 'Statistical Models', 'System', 'Time', 'Translating', 'Update', 'War', 'Work', 'Yemen', 'base', 'case-based', 'curve fitting', 'dashboard', 'disease transmission', 'experience', 'flexibility', 'improved', 'innovation', 'mortality', 'multidimensional data', 'programs', 'prospective', 'response', 'simulation', 'sound', 'surveillance data', 'theories', 'tool', 'transmission process', 'user-friendly']",NIGMS,JOHNS HOPKINS UNIVERSITY,R01,2021,429701
"Data-Driven Phenotyping of Severe Traumatic Brain Injury Project Summary This predoctoral fellowship will provide the applicant (Hayley Falk), a doctoral candidate in the Department of Computational Medicine & Bioinformatics at the University of Michigan, with the skills necessary to become an independent research investigator with expertise in novel applications of machine learning for TBI. The limited accuracy of current models for early prediction of GCS 3-8 TBI (commonly referred to as severe TBI) outcomes (prognostic models) is a major barrier to improving the clinical care of patients with GCS 3-8 TBI. Less than 20% of patients with GCS 3-8 TBI experience a good neurologic recovery and currently there are no therapeutic agents that improve long-term outcomes. In GCS 3-8 TBI clinical trials of promising therapeutic agents, a favorable outcome is typically defined as a better outcome than would be expected, taking into account the predicted prognosis for each individual patient. Therefore, accurate estimation of predicted prognosis is critical to assessing the efficacy of novel therapeutic agents. The leading prognostic models for GCS 3-8 TBI, IMPACT (International Mission for Prognosis and Analysis of Clinical Trials in TBI) and CRASH (Corticosteroid Randomization After Significant Head Injury), have undergone extensive external validation, however, the discriminative accuracy is highly cohort dependent with AUCs as low as 0.60 in some patient groups. The two major limitations of the IMPACT and CRASH models include one-time measurements of clinical predictor variables and regression-based methods, which are not designed to handle complex, multidimensional datasets. Our objective is to derive a dynamic prognostic model which provides updated outcome predictions as new data becomes available. We will then develop a clustering algorithm to identify physiologically distinct subtypes (clusters) of GCS 3-8 TBI derived from continuous, high frequency data streams. Our proposed goals will be achieved by the following specific aims: 1) we will derive a dynamic prognostic model using a RNN (recurrent neural network)-based framework and data collected during the first two weeks post-injury from BOOST-2 (Brain Oxygen Optimization in Severe Traumatic Brain Injury: Phase 2) which provides updated 6-month outcome predictions every 24 hours; and 2) using time series hierarchical clustering and continuous measures of physiologic parameters collected from subjects enrolled in BOOST-2 during the first two weeks post-injury, we will identify distinct subtypes of GCS 3-8 TBI and examine the association between subtype and 6-month outcome. In Aim 1, we hypothesize that our dynamic prognostic model derived from time-varying data will have a higher discriminative accuracy (AUC) than a static prognostic model (similar to IMPACT and CRASH) derived using single timepoint data collected on the day of injury. In Aim 2, we hypothesize that subtypes of GCS 3-8 TBI characterized by continuous physiologic parameters such as increasing ICP (intracranial pressure), decreasing CPP (cerebral perfusion pressure), and decreasing PbtO2 (brain tissue oxygenation) will be associated with poor 6-month outcomes. Project Narrative The proposed project aims to address the limitations of current prognostic models for GCS 3-8 TBI using state- of-the-art machine learning techniques including RNNs (recurrent neural networks) and time series hierarchical clustering. Using time-varying data collected during the first two weeks post-injury from GCS 3-8 TBI subjects enrolled in BOOST-2 (Brain Oxygen Optimization in Severe Traumatic Brain Injury: Phase 2), we will use a RNN-based framework to derive a dynamic prognostic model which improves upon the accuracy of existing static TBI prognostic models and a time series hierarchical clustering algorithm to identify distinct subtypes (clusters) of GCS 3-8 TBI derived from continuous physiologic parameters and examine the association between subtype and 6-month outcome. We will validate and refine the models developed using BOOST-2 data and data from a cohort of subjects enrolled in BOOST-3.",Data-Driven Phenotyping of Severe Traumatic Brain Injury,10230403,F31NS118944,"['Address', 'Adrenal Cortex Hormones', 'Algorithms', 'Area', 'Bioinformatics', 'Brain', 'Cerebral perfusion pressure', 'Clinical', 'Clinical Trials', 'Coma', 'Complex', 'Craniocerebral Trauma', 'Data', 'Early identification', 'Enrollment', 'Fellowship', 'Frequencies', 'Funding', 'Glasgow Outcome Scale', 'Goals', 'Hour', 'Injury', 'International', 'Intracranial Hypertension', 'Intracranial Pressure', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Medicine', 'Mentors', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Morbidity - disease rate', 'Network-based', 'Outcome', 'Oxygen', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Physiological', 'Probability', 'ROC Curve', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Risk', 'Series', 'Techniques', 'Therapeutic Agents', 'Time', 'Traumatic Brain Injury', 'Universities', 'Update', 'Validation', 'Work', 'base', 'brain tissue', 'clinical care', 'clinical predictors', 'clinical trial analysis', 'cohort', 'data streams', 'experience', 'improved', 'improved outcome', 'individual patient', 'innovation', 'long short term memory', 'mortality', 'multidimensional data', 'neurological recovery', 'novel', 'novel therapeutics', 'outcome forecast', 'outcome prediction', 'pre-doctoral', 'predictive modeling', 'recurrent neural network', 'skills', 'temporal measurement', 'time use', 'tissue oxygenation']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2021,37988
"A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals PROJECT SUMMARY The aim of this proposal is to deliver an innovative and easy-to-use experimental platform for measuring and quantifying naturalistic behaviors of mammalian animal models used for biomedical research, including rodents and monkeys, across a range of spatial and temporal scales. This will require developing a method for tracking movements freely behaving animals with far higher spatiotemporal resolution and more kinematic detail than currently possible. To overcome the limitations of current technologies, a new solution is proposed that synergistically combines two methods - marker based motion capture and a video- based machine learning approach. First, using marker-based motion capture, the gold standard for 3D tracking in humans, the position of experimental subjects' head, trunk, and limbs will be tracked in 3D with submillimeter precision. An innovative marker design, placement strategy, and post-processing pipeline will ensure an unprecedentedly detailed description of rodent behavior over a large range of timescales. To make the system more efficient, robust, affordable and better suited for high-throughput longitudinal studies, the unprecedentedly rich and large 3D datasets generated by the motion capture experiments will be leveraged to train a deep neural network to predict pose and appendage positions from a set of 1-6 normal video cameras. To best capitalize on the large training datasets, the latest advances in convolutional neural networks for image analysis will be incorporated. Together, these advances will promote generalization of the high-resolution 3D tracking system to a variety of animals and environments, thus establishing a cheap, flexible, and easy-to use kinematic tracking method that can easily be scaled up and adopted by other labs. The large ground-truth datasets will allow the system to be benchmarked and compared against state-of-the art technologies in quantitative and rigorous ways. Preliminary studies have been very positive and suggest large improvements over current methods both when it comes to the range of behaviors that can be tracked and the precision with which they can be measured. Importantly, all new technology will be readily shared with the scientific community, thereby leveraging from this single grant the potential for numerous investigators to dramatically improve the efficiency of their research programs requiring rigorous quantitative descriptions of animal behavior. Narrative We will develop and disseminate innovative new technology for measuring precise 3D kinematics in freely moving animals over long time-periods. Our proposed experimental platform will illuminate how natural behaviors are organized and help us understand how they are controlled by the nervous system, and how this control goes awry in disease. The technological leap made possible by this grant will catalyze a host of studies on the neural mechanisms underlying motor control, learning, and mental disorders, and thus help in the discovery of new diagnostic and therapeutic approaches for afflicted patients.",A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals,10120068,R01GM136972,"['3-Dimensional', 'Address', 'Adopted', 'Anatomy', 'Animal Behavior', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Benchmarking', 'Biological Models', 'Biomedical Research', 'Brain', 'Callithrix', 'Cephalometry', 'Communities', 'Complex', 'Data', 'Data Set', 'Deer Mouse', 'Disease', 'Ensure', 'Environment', 'Gold', 'Grant', 'Hand', 'Head', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Learning Disorders', 'Lighting', 'Limb structure', 'Logic', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Movement', 'Mus', 'Nervous System Physiology', 'Nervous System control', 'Neurologic Deficit', 'Output', 'Patients', 'Performance', 'Positioning Attribute', 'Posture', 'Process', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'appendage', 'base', 'computer science', 'convolutional neural network', 'cost', 'deep neural network', 'design', 'expectation', 'experimental study', 'flexibility', 'improved', 'innovation', 'kinematics', 'motor control', 'neural network', 'neuromechanism', 'new technology', 'novel diagnostics', 'novel therapeutic intervention', 'programs', 'relating to nervous system', 'scale up', 'skeletal', 'spatiotemporal']",NIGMS,HARVARD UNIVERSITY,R01,2021,411071
"Application of advanced methodology to osteoarthritis phenotyping Osteoarthritis (OA) is highly prevalent, contributes to substantial morbidity in the population, and lacks effective interventions to prevent onset and progression. Importantly, and like many other chronic conditions, OA is not a single disease but rather a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying pathophysiological mechanisms. It is becoming increasingly clear that consideration of specific OA phenotypes in clinical studies and trials is critically needed to move the field forward. The overall goal of this line of work is to identify and understand potential phenotypes of knee osteoarthritis (KOA) to better inform future research efforts and treatments; this exploratory R21 project using OA Initiative (OAI) data will investigate novel methodology to support phenotyping in KOA. Successful treatments for OA will need to be targeted to, and tested in, specifically chosen OA phenotypes. Our hypothesis is that an understanding of KOA phenotypes, a key step toward Precision Medicine in OA, will lead to more successful clinical studies in the long-term. To approach this important clinical problem, we propose a project in which we will apply innovative machine learning methods and validation strategies to data from the large, publicly available OAI cohort. We will leverage this large dataset, along with local expertise in statistics, biostatistics and machine learning methodology, to tackle the problem of phenotyping this heterogeneous disease. In Aim 1, we will utilize a data-driven, unsupervised learning approach, to cluster features that best define and discriminate among phenotypes of KOA in the OAI dataset, using biclustering and a novel significance test (SigClust) developed by co-I Marron. For Aim 2, we will test specific hypotheses of relevance to OA outcomes, such as differences between those with and without OA, or those who do or do not develop new or worsening disease, using another set of machine learning methods (Direction-projection-permutation [DiProPerm] hypothesis testing, and Distance-Weighted Discrimination [DWD]), also developed by co-I Marron, in the full cohort and in any identified clusters from Aim 1. In order to address these aims, this proposal involves interdisciplinary collaborations among experts in statistics, biostatistics, computer science, rheumatology, and epidemiology. This work will significantly impact the field by fulfilling a critical need to accurately define OA phenotypes, discover the key features associated with these phenotypes, link phenotype subgroups to underlying mechanisms and use this information to inform and focus future clinical studies. In the long term, we expect that this strategy will lead to more personalized and successful management of the millions of people affected by OA. Project narrative Osteoarthritis is an enormous and increasing public health problem, and like many other chronic conditions it is not a single disease but a heterogeneous condition consisting of multiple subgroups, or phenotypes, with differing underlying mechanisms. The lack of appreciation of this heterogeneity has contributed to the failure of all attempts to date to develop disease-modifying osteoarthritis drugs; future trials will need to target specific OA phenotypes. There is a critical need to define and understand phenotypes in OA and link these to outcomes, leading to more personalized and successful management of this common and debilitating disease.",Application of advanced methodology to osteoarthritis phenotyping,10083187,R21AR074685,"['Address', 'Affect', 'Age-Years', 'Arthritis', 'Biomechanics', 'Biometry', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Discrimination', 'Disease', 'Epidemiology', 'Etiology', 'Failure', 'Fibrinogen', 'Future', 'General Population', 'Goals', 'Heterogeneity', 'Individual', 'Inflammation', 'Injury', 'Intervention', 'Joints', 'Knee Injuries', 'Knee Osteoarthritis', 'Link', 'Machine Learning', 'Meniscus structure of joint', 'Methodology', 'Morbidity - disease rate', 'Non obese', 'Obesity', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Progressive Disease', 'Public Health', 'Randomized', 'Research Methodology', 'Resources', 'Rheumatology', 'Risk Factors', 'Structure', 'Subgroup', 'Symptoms', 'Syndrome', 'Synovial Membrane', 'Techniques', 'Testing', 'Time', 'Tissues', 'Validation', 'Visit', 'Work', 'base', 'bone', 'cohort', 'common treatment', 'computer science', 'demographics', 'design', 'disability', 'drug development', 'effective intervention', 'experience', 'improved', 'injured', 'innovation', 'interdisciplinary collaboration', 'joint destruction', 'large datasets', 'loss of function', 'machine learning method', 'novel', 'precision medicine', 'prevent', 'statistics', 'unsupervised learning']",NIAMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2021,160567
"Bioinformatics for post-traumatic stress Project Summary/Abstract Maladaptive complications following trauma, including post-traumatic stress (PTS), are highly prevalent in both veterans and civilians, and have been difficult to accurately diagnose, manage and treat. Debate regarding diagnostic criteria and the need to represent the full spectrum of inter-connected features contributing to psychopathology has spawned the development of the Research Domain Criteria (RDoC) by the National Institute of Mental Health (NIMH). RDoC is a developing framework to help guide the discovery and validation of new dimensions of mental health disorders and their relationships to underlying biological mechanisms. NIMH now has a rich federated database that currently houses raw data from RDoC-sponsored clinical research, and clinical trial data from the National Database of Clinical Trials (NDCT) with information that may help to unlock the complex and overlapping relationships between symptoms of PTS and the underlying biomarkers to fuel improvements on diagnostic and therapeutic frameworks for trauma recovery. The proposed project will apply bioinformatics and machine learning analytical tools to these large, heterogeneous datasets to identify and validate new research dimensions of trauma-related psychopathology and treatment response trajectories and their predictors. Aim 1 will develop an in silico trauma patient population by integrating data from diverse sources, including cross-sectional and observational longitudinal clinical studies housed within available data repositories for trauma and other related mental health research. Data will include medical history, demographics, diagnostic tests, clinical outcomes, psychological assessments, genomics, imaging, and other relevant study and meta-data. Aim 2 will identify multiple dimensions of PTS diagnostic criteria, using a combination of unsupervised dimension-reduction statistical methods, internal and external cross-validation, and supervised hypothesis testing of predictive models to understand the heterogeneous subtypes of PTS. Aim 3 will deploy unsupervised machine learning methods, such as topological data analysis and hierarchical clustering, to identify unique clusters of patients based on symptomatology to develop clustering methods for precision mapping of PTS patients based on disease severity. Aim 4 will use supervised machine learning techniques for targeted predictive analytics focused on identifying treatment responders from the NDCT, and identification of latent variables that predict treatment response. The results of the proposed research project will greatly enrich the field of computational psychiatry research to identify conserved dimensions associated with the complex relationships of psychopathology and precision treatment planning following exposure to traumatic events. Project Narrative A recent restructuring of diagnostic and research criteria for psychiatric disorders has been implemented to promote greater understanding of the biological mechanisms involved in the development of complex mental health disorders. The proposed project aims to apply bioinformatics and machine learning analytics to large datasets from trauma-exposed patients to identify and validate dimensions of post-traumatic stress (PTS), relevant biological predictors, and precision treatment response trajectories.",Bioinformatics for post-traumatic stress,10205954,R01MH116156,"['Bioinformatics', 'Biological', 'Biological Markers', 'Categories', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Database', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Dimensions', 'Disease', 'Exposure to', 'Genomics', 'Growth', 'Image', 'Laboratories', 'Linear Models', 'Linear Regressions', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Medical History', 'Mental Health', 'Mental disorders', 'Metadata', 'Methods', 'Modeling', 'National Institute of Mental Health', 'Nervous System Trauma', 'Neurocognitive', 'Observational Study', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Principal Component Analysis', 'Psychiatry', 'Psychopathology', 'Recovery', 'Reproducibility', 'Research', 'Research Domain Criteria', 'Research Project Grants', 'Severity of illness', 'Source', 'Statistical Methods', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Therapeutic', 'Trauma', 'Trauma Research', 'Trauma patient', 'Trauma recovery', 'Traumatic Brain Injury', 'Validation', 'Veterans', 'Work', 'accurate diagnosis', 'analytical tool', 'base', 'biobehavior', 'combat veteran', 'computational platform', 'data archive', 'data mining', 'data repository', 'data sharing', 'demographics', 'diverse data', 'feature selection', 'federated computing', 'guided inquiry', 'hands-on learning', 'heterogenous data', 'in silico', 'indexing', 'innovation', 'insight', 'interest', 'large datasets', 'machine learning method', 'multidimensional data', 'multimodality', 'patient population', 'patient subsets', 'post-traumatic stress', 'post-traumatic symptoms', 'precision medicine', 'predictive modeling', 'predictive test', 'psychologic', 'research and development', 'research study', 'response', 'statistics', 'stress related disorder', 'supervised learning', 'symptomatology', 'tool', 'trauma exposure', 'traumatic event', 'treatment planning', 'treatment responders', 'treatment response', 'unsupervised learning', 'vector']",NIMH,UNIVERSITY OF MINNESOTA,R01,2021,501996
"Modeling the influence of translation-elongation kinetics on protein structure and function Project Summary mRNA degradation is an essential process in post-translational gene regulation, and influences protein expression levels in cells. In S. cerevisea the lifetime of mRNA ranges from 43 sec to 39 min, with a median half-life of 3.6 min. The molecular factors governing these differential degradation rates has long been an area of active research. Recently though, clear evidence has emerged that the codon optimality correlates with half- lives. At a mechanistic level, the emerging perspective is that some transcripts are translated quickly, and some slowly, and that transcripts in which ribosomes end up forming queues, much like a traffic jam of cars on a highway, are recognized by ubiquitin ligases such as Hel2 that trigger the RQC pathway to promote mRNA degradation. There are two major gaps in this field. The first is the capability to predict mRNA half-lives accurately from mRNA sequence features. The second is understanding at the molecular level how the distribution of codon translation speeds along a transcript’s coding sequence promote ribosome queues and hence degradation. In this proposal, a graduate student will combine the PI’s labs expertise in modeling the kinetics of translation and ribosome traffic with interpretable machine learning techniques to address these two gaps. In achieving this, the field will be advanced by having both predictive and explanatory models for how translation speed and codon usage differentially impacts the degradation rates of different mRNAs. Specifically, our first aim is to build an interpretable machine learning model to identify robust and predictive features governing mRNA degradation. Our second aim is to explain at the molecular level why these features influence degradation rates. We will do this in two ways. First, we will use the essential and predictive features resulting from the interpretable machine learning model to identify potential underlying mechanisms contributing to degradation. Second, we will simulate the movement of ribosomes on each transcript based on reported initiation and elongation rates to detect ribosome queues and provide an explanation for differential degradation rates. Finally, our third aim is to test the predictions coming from the models. For example, do the models from Aim 1 accurately predict mRNA half-lives when synonymous mutations are introduced? There is sufficient published data on transcriptome-wide mRNA half-lives on S. cerevisiae to train and test the machine learning models in Aim 1. Further, we have arranged for a machine learning expert to co-advise the graduate student on the second aim. This co-advisor is already a collaborator of the PI on other machine learning projects. Finally, a collaborator who has measured mRNA half-lives will further advise the student on the third aim. In summary, this training supplement will address cutting edge questions in the molecular biology and biophysics of mRNA lifetimes and provide the student the opportunity to get advanced training and expertise in machine learning, molecular modeling, and experimental techniques. Project Narrative Messenger RNA (mRNA) half-lives are influenced by the rate of protein synthesis and the ribosome traffic jams that can form on transcripts when slow-translating codons are encountered by ribosomes. The complex distribution of codon usage across transcripts, and the interplay of initiation and elongation rates that can create ribosome queues make it difficult to predict an mRNA's half-life based on its sequence. Here, we will apply machine learning to accurately predict mRNA half-lives from sequence, and combine it with biophysical modeling to understand the molecular events regulating mRNA degradation.",Modeling the influence of translation-elongation kinetics on protein structure and function,10307359,R35GM124818,"['Address', 'Area', 'Biophysics', 'Cells', 'Code', 'Codon Nucleotides', 'Complex', 'Coupling', 'Data', 'Event', 'Gene Expression Regulation', 'Half-Life', 'Kinetics', 'Lead', 'Machine Learning', 'Measures', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Biology', 'Movement', 'Mutation', 'Pathway interactions', 'Process', 'Property', 'Protein Biosynthesis', 'Proteins', 'Publishing', 'Reporter', 'Reporting', 'Research', 'Ribosomes', 'Saccharomyces cerevisiae', 'Speed', 'Students', 'Techniques', 'Testing', 'Training', 'Transcript', 'Translating', 'Translations', 'base', 'biophysical model', 'graduate student', 'insight', 'kinetic model', 'mRNA Transcript Degradation', 'models and simulation', 'molecular modeling', 'protein expression', 'protein structure function', 'ribosome profiling', 'simulation', 'transcriptome', 'ubiquitin ligase']",NIGMS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R35,2021,31246
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243
"Deep learning and topological approaches to identify kidney tissue features associated with adverse outcomes after nephrectomy ABSTRACT Pathologic assessment of kidney biopsy tissue remains the best predictor of adverse outcomes in patients with kidney diseases. These features are largely independent of disease etiology and are not well reflected in non- invasive tests (e.g. serum creatinine and albuminuria). Quantitative assessment of these parameters is time consuming and maybe flawed by heterogeneity of pathologic features within kidney tissue. We propose to evaluate and optimize computational image analysis approaches to support pathologic analysis of large pieces of cancer-free kidney tissue from patients who underwent nephrectomy which we have collected (n > 220). Computer-assisted analysis of glomerular phenotypes in these samples show that morphometric features in glomeruli without obvious pathology precede established pathologic changes. We hypothesize that evaluation of cancer-free kidney tissue will inform about subclinical damage in the remaining kidney which is associated with relevant pathologic and clinical parameters. We propose to assess glomeruli, arteries and tubuli, and determine the spatial inter-relationship of the assessed features within the kidney tissue. The examination of significantly larger pieces of kidney tissue than those obtained by needle biopsy allows to include 20 times more glomeruli (nephrectomy samples: avrg. 256 glomeruli/sample; needle biopsy: avrg. 13/sample) with the vast majority considered “normal appearing” as per standard pathologic criteria. In addition, these samples include a significant larger number of blood vessels (nephrectomy samples: avrg. 18 arteries/sample; needle biopsy: avrg. 1/sample) allowing a more robust evaluation of the vasculature. We propose to apply and optimize our detection and segmentation approach to detect glomeruli, arteries and tubular segments to train convolutional neural networks and use topological image analysis to automate the identification of visual and sub-visual features. In addition, we will assess the spatial relationship between individual features (glomeruli, arteries and tubular segments and features of the same category, i.e. globally sclerosed glomeruli, arteries with hyalinosis, atrophied tubuli) within the section. To determine reproducibility of our approach, we will assess a second tissue section from a separate part of the same samples. Specifically, we propose an algorithmic detection and characterization of kidney features using deep learning, a topological image analysis for discovery of novel sub-visual features in kidney tissue images and to determine spatial relatedness of these features. If successful, we will validate our analytical approach in future independent studies. For this purpose, we are already prospectively collecting kidney tissue and longitudinal clinical data from consented patients undergoing nephrectomies, allowing association of specific features with clinical relevant outcomes. LAY NARRATIVE Patients who have one kidney removed because of cancer or other reasons, are at risk of experiencing kidney failure after the surgery due to damage to the remaining kidney, but it is difficult to know why the kidney fails and how to prevent or treat it. Evaluation of kidney tissue is the best way to determine how strong or weak the kidney is at time of surgery and how to best manage kidney-related complications afterwards. We propose a detailed analysis of pieces of tissue not affected by the tumor from the removed kidney using advanced computer-assisted analysis methods (“convolutional neural networks” and “topological image analysis”) to more accurately evaluate the status of the kidney, predict what will happen to the kidney function in the future and thereby guide therapy.",Deep learning and topological approaches to identify kidney tissue features associated with adverse outcomes after nephrectomy,10229784,R21DK126329,"['Acute', 'Albuminuria', 'Algorithms', 'Arteries', 'Atrophic', 'Blood Vessels', 'Categories', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Collection', 'Computer Assisted', 'Consent', 'Consumption', 'Contralateral', 'Creatinine', 'Data', 'Data Analyses', 'Detection', 'Diabetes Mellitus', 'Diabetic Nephropathy', 'Disease', 'Distant', 'Elderly', 'Etiology', 'Evaluation', 'Excision', 'Fibrosis', 'Functional disorder', 'Future', 'Glomerulonephritis', 'Heterogeneity', 'Human', 'Hypertension', 'Image', 'Image Analysis', 'Individual', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Malignant Neoplasms', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modernization', 'Needle biopsy procedure', 'Needles', 'Nephrectomy', 'Nephrotic Syndrome', 'Neural Network Simulation', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Phenotype', 'Population', 'Renal function', 'Reproducibility', 'Research', 'Risk', 'Risk Factors', 'Sampling', 'Scanning', 'Serum', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Tubular formation', 'Visual', 'adverse outcome', 'base', 'clinically relevant', 'cohort', 'convolutional neural network', 'cost effective', 'deep learning', 'experience', 'glomerulosclerosis', 'histological stains', 'improved', 'insight', 'interstitial', 'kidney biopsy', 'kidney imaging', 'morphometry', 'novel', 'outcome prediction', 'prevent', 'prospective', 'renal damage', 'serial imaging', 'spatial relationship', 'tumor', 'user-friendly']",NIDDK,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2021,234000
"Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease PROJECT SUMMARY/ABSTRACT Chronic obstructive pulmonary disease (COPD) is the leading cause of respiratory mortality in the United States. COPD is a highly heterogeneous disease and some COPD therapies are only applied to specific clinically defined subtypes. With the advent of multiple high-throughput biological assays and machine learning approaches, data-driven subtypes are increasingly being recognized. We hypothesize that such subtypes exist in COPD and that they can be identified using an integrative, multi-'omic approach. To accomplish this goal, we first propose to complement existing RNA and whole genome sequencing data in the well-phenotyped COPDGene study with peripheral blood microRNA sequencing. We will study the relationship of microRNA to genetic variation and gene expression in COPD. Next, we will apply a patient-based network similarity method to these three data types to identify COPD molecular subtypes. Finally, we will associate these subtypes with important clinical phenotypes and outcomes, and validate these subtypes in an independent subset of subjects. Our analysis targets a key clinical problem in COPD management, and will allow the mentee to become an independent investigator, applying bioinformatic and machine learning methods to genomic data in respiratory diseases. PROJECT NARRATIVE Chronic obstructive pulmonary disease (COPD) is a leading cause of death in the United States. Patients with COPD may have very similar lung function but differ in many other characteristics. We propose to use multiple types of biologic data to identify different COPD subtypes, which may be important for disease prognosis and treatment.",Multi-omic Subtyping of Chronic Obstructive Pulmonary Disease,10205150,K08HL136928,"['Affect', 'Bioinformatics', 'Biological', 'Biological Assay', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complement', 'Complex', 'Data', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Expert Opinion', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Diseases', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Goals', 'Impairment', 'Individual', 'Lung', 'Lung diseases', 'Lung volume reduction surgery', 'Machine Learning', 'Measures', 'Methods', 'MicroRNAs', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Muscular Atrophy', 'Network-based', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Principal Investigator', 'Pulmonary Emphysema', 'RNA', 'Research Personnel', 'SNP array', 'Severities', 'Spirometry', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'United States', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'disorder subtype', 'exome', 'genome sequencing', 'genome wide association study', 'genomic data', 'machine learning method', 'miRNA expression profiling', 'molecular subtypes', 'mortality', 'multiple omics', 'next generation sequencing', 'novel', 'outcome forecast', 'patient subsets', 'peripheral blood', 'personalized approach', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'risk variant', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,172800
"Focal nerve fiber layer reflectance analysis for glaucoma evaluation PROJECT SUMMARY Glaucoma is a leading cause of blindness, and effective glaucoma management requires early detection. Nerve fiber layer (NFL) thickness measurement by optical coherence tomography (OCT) is useful for confirming the diagnosis of glaucoma, but its diagnostic sensitivity is not sufficient to be used alone for population-based screening.  NFL reflectivity is reduced in glaucoma subjects, presumably due to loss of axons and axonal microtubule content. But its diagnostic value is diminished by its dependence on the incident angle of the OCT beam, which is highly variable in routine clinical imaging. We hypothesize that the diagnostic accuracy can be boosted by reducing incidence angle effects with azimuthal filtering of NFL reflectance profile, and by analysis of focal rather than average reflectance changes. The preliminary result, bases on 100 normal and glaucoma eyes, showed that the diagnostic sensitivity was significantly improved from 71% for average NFL thickness to 97% for focal NFL reflectance loss in PG eyes, at a 99% specificity cutoff. We propose to validate this result in the large Advanced Imaging for Glaucoma (AIG) study dataset that comprises 249 perimetric glaucoma (PG), 252 pre-perimetric glaucoma (PPG), and 145 normal participants. The AIG study has an average follow-up of more than 4 years, which also allows assessment of the accuracy in predicting glaucoma progression. 1. Reproduce the high diagnostic accuracy of focal NFL reflectance loss analysis using the large AIG  dataset. If we could again demonstrate high diagnostic accuracy in the AIG dataset, especially in the PPG  and early PG subgroups, this could bring OCT glaucoma evaluation into the realm of population screening.  The primary performance metric will be the diagnostic sensitivity at a fixed 99% specificity cut point. 2. Use focal NFL reflectance loss to predict visual field (VF) conversion and progression. In the AIG  study, focal thinning of the macular ganglion cell complex (GCC) and peripapillary nerve fiber layer (NFL)  were found to be the best predictors of VF conversion (development of glaucomatous VF abnormality in an  eye with normal baseline VF) and progression (significant worsening of VF). We hypothesize that focal  NFL reflectance loss would have even better predictive accuracy. Predictive accuracy will be assessed  using the area under the receiver operating curve (AROC) and logistic regression (odds ratio). 3. Combine OCT reflectance and structural maps using machine learning to improve glaucoma  diagnostic accuracy. A combination of disc, peripapillary, and macular thickness parameters had  previously been shown to be synergistic, producing higher AROC than any single parameter. We  hypothesize that the addition of the novel NFL reflectance loss map to the set of input parameters will  further enhance the diagnostic accuracy of a machine learning algorithm. PROJECT NARRATIVE Nerve fiber layer (NFL) thickness using OCT is widely used in clinic for glaucoma diagnosis, but the diagnostic sensitivity is limited. Combination of NFL reflectivity and other structural OCT information promises to improve the diagnostic accuracy to a level where population-based screening would be feasible.",Focal nerve fiber layer reflectance analysis for glaucoma evaluation,10108277,R21EY032146,"['Algorithms', 'Area', 'Axon', 'Blindness', 'Clinic', 'Clinical Management', 'Complex', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Diagnostic Specificity', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Glaucoma', 'Image', 'Incidence', 'Logistic Regressions', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Nerve Fibers', 'Odds Ratio', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Performance', 'Population', 'Retina', 'Sampling', 'Scanning', 'Specificity', 'Structure', 'Subgroup', 'System', 'Thick', 'Thinness', 'Visual Fields', 'base', 'clinical imaging', 'cost', 'diagnostic accuracy', 'disorder risk', 'follow-up', 'ganglion cell', 'improved', 'machine learning algorithm', 'macula', 'novel', 'population based', 'screening']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,192500
"CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy Acute intoxication with organophosphorus (OP) pesticides is a significant public health concern and long-term neurological effects are not well understood. A major obstacle to progress towards reproducible, rigorous preclinical research in the long-term effects of OP- induced status epilepticus is that current experimental approaches often require prohibitively time and labor-intensive 24/7 video-EEG monitoring and inherently subjective scoring of seizures by human observers (like the widely used Racine scale). While algorithms for automated seizure detection in EEG are improving, the critically important behavioral manifestations of acquired epilepsy and assessment of its cognitive comorbidities remain poorly quantified. Our parent grant focuses on developing an objective, high-throughput technique to characterize epileptic phenotypes using a new method called motion sequencing (MoSeq) and apply it to automated anti-epileptic drugs (AED) screening. The central idea of MoSeq rests on the discovery that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales that are arranged according to specific rules (“grammar”) that can be detected without observer bias by artificial intelligence (AI)-assisted 3D video analysis. In this administrative supplement project, we propose to employ and refine MoSeq to address key challenges in research into the development of new medical countermeasures (MCM) against nerve agents and OP pesticides. This includes testing if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale by determine epilepsy-specific behavioral modules and associated transition probabilities in mice after acute OP exposure. In addition, given that neuroinflammation is likely to play a key role in OP-induced persistent neuronal circuit disturbance, we will test if microglial depletion can rescue the OP-induced chronic changes in behavioral syllables and transition probabilities. Together, the aims in this administrative supplement will both benefit from and contribute to our parent grant’s goal to develop a reliable, sharable tool for the research community to study seizures and cognitive comorbidities of epilepsy. There is an urgent need for medical countermeasures (MCMs) against nerve agents and organophosphorus (OP) pesticides. The project will leverage from our recent technical breakthroughs in artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to test if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale. If successful, this innovative approach is expected to have a significant and sustained impact on preclinical research by enabling objective, automated, inexpensive, reproducible assessment of epileptic phenotypes in experimental animals after acute OP intoxication to aid the testing of anti-seizure drugs and other novel therapies.",CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy,10227611,R01NS114020,"['3-Dimensional', 'Acute', 'Address', 'Administrative Supplement', 'Animal Behavior', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Cannabidiol', 'Chronic', 'Cognitive', 'Communities', 'Complex', 'Data', 'Detection', 'Development', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Exposure to', 'Goals', 'Human', 'Intoxication', 'Isoflurophate', 'Long-Term Effects', 'Longitudinal Studies', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Neurologic Effect', 'Observer Variation', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Probability', 'Public Health', 'Reproducibility', 'Research', 'Rest', 'Seizures', 'Status Epilepticus', 'Stereotyping', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-dimensional analysis', 'Time', 'acquired epilepsy', 'automated algorithm', 'comorbidity', 'improved', 'innovation', 'medical countermeasure', 'nerve agent', 'neuroinflammation', 'neuronal circuitry', 'novel therapeutics', 'parent grant', 'pre-clinical research', 'screening', 'tool', 'valproate']",NINDS,STANFORD UNIVERSITY,R01,2021,123798
"Bioinformatics Strategies for Genome-Wide Association Studies One promise of precision medicine for Alzheimer’s disease is to edit a patient’s DNA and/or administer therapeutics targeting etiologic molecules that prevent or reverse the disease process using a tailored design. All of this happens at the level of the individual and requires precision knowledge of that patient’s biology. In stark contrast, much of the knowledge we possess about genomic risk factors comes from statistical measures of association in subjects ascertained with and without Alzheimer’s. The conceptual and practical disconnect between the populations we study and the individuals we want to treat is a major source of confusion about how to move forward in an era driven by genome technology. The primary goal of this proposal is to develop novel informatics methodology and software to facilitate precision medicine for Alzheimer’s by connecting population and individual genomic phenomena. We propose here a Virtual Genomic Medicine (VGMed) workbench where clinicians can carry out thought experiments about the treatment of individual Alzheimer’s patients using models of disease risk derived from population-level studies. This will be accomplished by first developing a novel Genomics-guided Automated Machine Learning (GAML) algorithm for deriving risk models from real data that is accessible to Alzheimer’s clinicians (AIM 1). We will then develop a novel simulation approach that is able to generate artificial Alzheimer’s data that preserves the distribution of genetic effects observed in the real data while maintaining other characteristics such as genotype frequencies (AIM 2). This will generate open data allowing anyone to perform virtual interventions on Alzheimer’s patients derived from a population-level risk distribution. The workbench will allow editing of individual genotypes and simulate the administration of drugs by editing machine learning parameters in the simulation model (AIM 3). The change in risk and Alzheimer’s disease status for the specific patient will be tracked in real time. Finally, we provide a feature in the workbench that will allow the Alzheimer’s clinician to generate specific hypotheses about individual genetic variants that can then be validated using integrated Alzheimer’s knowledge sources that include databases such as PubMed and ClinVar thus giving the user immediate feedback (AIM 4). All methods and software will be provided as open-source to the Alzheimer’s disease research community (AIM 5). Most genetic studies of Alzheimer’s disease result in statistical summaries of risk derived from human populations. These statistical summaries are not that helpful for determining the health of an individual. This proposal will create new computer algorithms and software help Alzheimer’s clinicians and researchers connect population-level statistics with individual level genetic effects to advance our understanding of how to treat Alzheimer’s patients based on their own unique genetic makeup.",Bioinformatics Strategies for Genome-Wide Association Studies,10284977,R01LM010098,"['Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Bioinformatics', 'Biology', 'Characteristics', 'ClinVar', 'Communities', 'Computational algorithm', 'Computer software', 'Confusion', 'DNA', 'Data', 'Databases', 'Disease', 'Disease model', 'Etiology', 'Feedback', 'Frequencies', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Process', 'PubMed', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Source', 'Technology', 'Time', 'base', 'data preservation', 'design', 'disorder risk', 'experimental study', 'genetic makeup', 'genetic variant', 'genome wide association study', 'machine learning algorithm', 'models and simulation', 'novel', 'open data', 'open source', 'precision medicine', 'prevent', 'simulation', 'statistics', 'therapeutic target', 'virtual', 'virtual intervention']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2021,391879
"Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity PROJECT SUMMARY/ABSTRACT  Experimental animal and clinical testing to evaluate hepatotoxicity demands extensive resources and long turnaround times. Utilization of computational models to directly predict the toxicity of new compounds is a promising strategy to reduce the cost of drug development and to screen the multitude of industrial chemicals and environmental contaminants currently lacking safety assessments. However, the current computational models for complex toxicity endpoints, such as hepatotoxicity, are not reliable for screening new compounds and face numerous challenges. Our recent studies have shown that traditional Quantitative Structure-Activity Relationship modeling is applicable for relatively simple properties or toxicity endpoints with a clear mechanism, but fails to address complex bioactivities such as hepatotoxicity. The primary objective of this proposal is to develop novel mechanism-driven Virtual Adverse Outcome Pathway (vAOP) models for the fast and accurate assessment of hepatotoxicity in a high-throughput manner The resulting vAOP models will be experimentally validated using a complement of in vitro and ex vivo testing. We have generated a preliminary vAOP model based on the antioxidant response element (ARE) pathway that has undergone initial validation and refinement using in vitro testing. To this end, our project will generate novel predictive models for hepatotoxicity by applying 1) a virtual cellular stress pathway model to mechanism profiling and assessment of new compounds; 2) computational predictions to fill in the missing data for specific targets within the pathway; 3) in vitro experimental validation with three complementary bioassays; and 4) ex vivo experimental validation with pooled primary human hepatocytes capable of biochemical transformation. The scientific approach of this study is to develop a universal modeling workflow that can take advantage of all available short-term testing information, obtained from both computational predictions using novel machine learning approaches and in vitro experiments, for target compounds of interest. We will validate and use our modeling workflow to directly evaluate the hepatotoxicity of new compounds and prioritize candidates for validation in pooled primary human hepatocytes. The resulting workflow will be disseminated via a web portal for public users around the world with internet access. Importantly, this study will pave the way for the next generation of chemical toxicity assessment by reconstructing the modeling process through a combination of big data, computational modeling, and low cost in vitro experiments. To the best of our knowledge, the implementation of this project will lead to the first publicly available mechanisms-driven modeling and web- based prediction framework for complex chemical toxicity based on publicly-accessible big data. These deliverables will have a significant public health impact by not only prioritizing compounds for safety testing or new chemical development, but also revealing toxicity mechanisms. PROJECT NARRATIVE Hepatotoxicity is a leading safety concern in the development of new chemicals. We will create virtual “Adverse Outcome Pathway” models that will directly evaluate the hepatotoxicity potentials of chemicals using massive public toxicity data. The primary deliverable of this project will be a publically-accessible, web-based search engine to evaluate new chemicals for risk of hepatotoxicity.",Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity,10166848,R01ES031080,"['Address', 'Animal Model', 'Animal Testing', 'Antioxidants', 'Big Data', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Cellular Stress', 'Chemical Injury', 'Chemical Structure', 'Chemicals', 'Clinical', 'Complement', 'Complex', 'Computer Models', 'Computer software', 'Computers', 'Cryopreservation', 'Custom', 'Data', 'Data Pooling', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Drug Costs', 'Ensure', 'Environment', 'Environmental Pollution', 'Evaluation', 'Face', 'Generations', 'Hepatocyte', 'Hepatotoxicity', 'Human', 'In Vitro', 'Industrialization', 'Injury', 'Internet', 'Libraries', 'Liver', 'Luciferases', 'Machine Learning', 'Marketing', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nutraceutical', 'Online Systems', 'Pathway interactions', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Population', 'Process', 'Property', 'Proteomics', 'PubChem', 'Public Health', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Personnel', 'Resources', 'Response Elements', 'Risk', 'Safety', 'Signal Transduction', 'Source', 'Statutes and Laws', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxicology', 'Translating', 'Validation', 'Vertebrates', 'adverse outcome', 'base', 'candidate validation', 'cell injury', 'combat', 'computational toxicology', 'computer framework', 'computerized tools', 'cost', 'data mining', 'deep neural network', 'design', 'developmental toxicity', 'drug development', 'endoplasmic reticulum stress', 'experimental study', 'hepatocellular injury', 'improved', 'in vitro Assay', 'in vitro testing', 'in vivo', 'interest', 'knowledge base', 'large datasets', 'liver injury', 'next generation', 'novel', 'pre-clinical', 'predictive modeling', 'reproductive toxicity', 'research clinical testing', 'safety assessment', 'safety testing', 'screening', 'search engine', 'tool', 'toxicant', 'transcriptomics', 'virtual', 'web portal']",NIEHS,RUTGERS THE STATE UNIV OF NJ CAMDEN,R01,2021,457521
"An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics Immune-repertoire sequence, which consists of an individual's millions of unique antibody and T-cell receptor (TCR) genes, encodes a dynamic and highly personalized record of an individual's state of health. Our long- term goal is to develop the computational models and tools necessary to read this record, to one day be able diagnose diverse infections, autoimmune diseases, cancers, and other conditions directly from repertoire se- quence. The key problem is how to find patterns of specific diseases in repertoire sequence, when repertoires are so complex. Our hypothesis is that a combination of bottom-up (sequence-level) and top-down (systems- level) modeling can reveal these patterns, by encoding repertoires as simple but highly informative models that can be used to build highly sensitive and specific disease classifiers. In preliminary studies, we introduced two new modeling approaches for this purpose: (i) statistical biophysics (bottom-up) and (ii) functional diversity (top-down), and showed their ability to elucidate patterns related to vaccination status (97% accuracy), viral infection, and aging. Building on these studies, we will test our hypothesis through two specific aims: (1) We will develop models and classifiers based on the bottom-up approach, statistical biophysics; and (2) we will de- velop the top-down approach, functional diversity, to improve these classifiers. To achieve these aims, we will use our extensive collection of public immune-repertoire datasets, beginning with 391 antibody and TCR da- tasets we have characterized previously. Our team has deep and complementary expertise in developing computational tools for finding patterns in immune repertoires (Dr. Arnaout) and in the mathematics that under- lie these tools (Dr. Altschul), with additional advice available as needed regarding machine learning (Dr. AlQuraishi). This proposal is highly innovative for how our two new approaches address previous issues in the field. (i) Statistical biophysics uses a powerful machine-learning method called maximum-entropy modeling (MaxEnt), improving on past work by tailoring MaxEnt to learn patterns encoded in the biophysical properties (e.g. size and charge) of the amino acids that make up antibodies/TCRs; these properties ultimately determine what targets antibodies/TCRs can bind, and therefore which sequences are present in different diseases. (ii) Functional diversity fills a key gap in how immunological diversity has been measured thus far, by factoring in whether different antibodies/TCRs are likely to bind the same target. This proposal is highly significant for (i) developing an efficient, accurate, generative, and interpretable machine-learning method for finding diagnostic patterns in repertoire sequence; (ii) applying a robust mathematical framework to the measurement of immuno- logical diversity; (iii) impacting clinical diagnostics; and (iv) adding a valuable new tool for integrative/big-data medicine. The expected outcome of this proposal is an integrated pair of robust and well validated new tools/models for classifying specific disease exposures directly from repertoire sequence. This proposal in- cludes plans to make these tools widely available, to maximize their positive impact across medicine. The proposed research is relevant to public health because B cells/antibodies and T cells play vital roles across such a vast range of health conditions, from infection, to autoimmunity, to cancer, that the ability to de- code what they are doing would be an important step forward for diagnosing these conditions. The proposed research is relevant to the NIH's mission of fostering fundamental creative discoveries, innovative research strategies, and their applications as a basis for ultimately protecting and improving health, specifically relating to the diagnosis of human diseases.",An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics,10165490,R01AI148747,"['Address', 'Affect', 'Aging', 'Amino Acid Motifs', 'Amino Acids', 'Antibodies', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Base Sequence', 'Big Data', 'Binding', 'Biophysics', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Code', 'Collection', 'Complex', 'Computer Models', 'Data Set', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Entropy', 'Fostering', 'Gene Frequency', 'Genes', 'Goals', 'Health', 'Human', 'Immune', 'Immunology', 'Individual', 'Infection', 'Influenza vaccination', 'Intuition', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Physics', 'Play', 'Population Heterogeneity', 'Privatization', 'Property', 'Public Health', 'Reading', 'Reporting', 'Research', 'Role', 'Sample Size', 'Sampling', 'Sampling Errors', 'Signs and Symptoms', 'Speed', 'Statistical Study', 'System', 'T-Cell Receptor', 'T-Cell Receptor Genes', 'T-Lymphocyte', 'Testing', 'United States National Institutes of Health', 'Vaccination', 'Virus Diseases', 'Work', 'base', 'biophysical properties', 'clinical diagnostics', 'computerized tools', 'diagnostic accuracy', 'human disease', 'immunological diversity', 'improved', 'information model', 'innovation', 'machine learning method', 'multidisciplinary', 'multilevel analysis', 'novel', 'novel strategies', 'tool']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,528873
"Biopsychosocial Phenotypes and Potential Mechanisms in CHARTER Central nervous system (CNS) complications are common among people with HIV (PWH), even those who are taking antiretroviral therapy (ART). The spectrum of CNS complications is broad, ranging from mild cognitive deficits that do not affect daily functioning to life-threatening encephalitis. Cognitive and mood disorders are among the most common CNS diseases that affect PWH and share a common risk factor, inflammation. Inflammation persists in effectively treated PWH for multiple reasons, including production of HIV RNA and proteins and gut dysbiosis and microbial translocation. CHARTER is a multisite, U.S.-based, neuroHIV cohort study that is funded by NIH and that has investigated CNS disorders in PWH for nearly two decades, during which it has completed more than 6,000 assessments generating more than 10 million data points. CHARTER has made important contributions to understanding the frequency, risk factors, and pathogenesis of these disorders. In recent years, new questions have arisen about the heterogeneity, biological basis, clinical impact, and management of CNS disorders. This debate has highlighted the need to create new classifications of CNS disorders in PWH that are more biology-based. We propose to use methods such as machine learning and an agnostic approach to categorize CHARTER’s high-dimensional neurobehavioral, neuromedical, psychiatric, substance use, and imaging data. Such analyses would yield not just cognitive phenotypes but biopsychosocial (BPS) phenotypes that could identify new mechanisms that lead to clinically useful diagnostic tests, new therapies, and better management of CNS disorders in PWH.  Our overarching goal is to leverage prior investment in CHARTER by using its data and stored specimens to a) better understand cognitive and BPS phenotypes in PWH and b) relate them to biological mechanisms. To accomplish this, we will use unsupervised and supervised machine learning methods to analyze data from CHARTER’s comprehensive assessments with the goal of identifying new cognitive and BPS phenotypes (Aim 1). We will then compare these new phenotypes to high-dimensional data from CHARTER’s completed genomewide association study as well as new data we will generate on inflammation (45-plex bead-based array) and highly novel assays of the microbiome and the metabolome in blood and CSF (Aim 2). Our analyses will include a specific focus how sex affects the observed relationships. To determine if this novel approach relates more strongly to biology than prior methods, we will also compare the performance of the new phenotypes to those defined by the 2007 HAND criteria. This highly innovative application is supported by strong preliminary data, responds well to Office of AIDS Research priorities, and will address key gaps in the field, including the need to better understand the pathogenesis of comorbid disease. Cognitive and mood disorders occur more commonly in people with HIV than in the general population but the field still does not fully understand why and has no effective therapies for most of those who are affected. This project will take a new approach to understanding how cognition, mood, substance use, and medical characteristics cluster together and will identify new biological mechanisms associated with these conditions. The successful project could lead to new diagnostic tests and therapies for these disorders, which would have substantial public health relevance.",Biopsychosocial Phenotypes and Potential Mechanisms in CHARTER,10161628,R01MH125720,"['AIDS dementia', 'Acquired Immunodeficiency Syndrome', 'Address', 'Affect', 'Alcohol or Other Drugs use', 'Biological', 'Biological Assay', 'Biological Markers', 'Biology', 'Blood', 'Brain imaging', 'Central Nervous System Diseases', 'Cerebrospinal Fluid', 'Characteristics', 'Classification', 'Clinical', 'Cognition', 'Cognition Disorders', 'Cognitive', 'Cognitive deficits', 'Cohort Studies', 'Data', 'Data Store', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Encephalitis', 'Frequencies', 'Funding', 'General Population', 'Genetic', 'Goals', 'Gut associated lymphoid tissue', 'HIV', 'HIV antiretroviral', 'HIV-associated neurocognitive disorder', 'Heterogeneity', 'Image', 'Individual', 'Inflammation', 'Injury', 'Intervention', 'Investments', 'Lead', 'Life', 'Machine Learning', 'Mediating', 'Medical', 'Methods', 'Mood Disorders', 'Moods', 'Neuraxis', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Participant', 'Pathogenesis', 'Pathology', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Production', 'Proteins', 'RNA', 'Research', 'Research Priority', 'Risk', 'Risk Factors', 'Specimen', 'Standardization', 'Structure', 'United States National Institutes of Health', 'Work', 'antiretroviral therapy', 'base', 'biopsychosocial', 'comorbidity', 'daily functioning', 'disease classification', 'effective therapy', 'genome wide association study', 'gut dysbiosis', 'high dimensionality', 'innovation', 'machine learning method', 'magnetic resonance spectroscopic imaging', 'metabolome', 'microbial', 'microbiome', 'microbiome analysis', 'multidimensional data', 'neuroAIDS', 'neurobehavioral', 'neurocognitive disorder', 'novel', 'novel diagnostics', 'novel strategies', 'novel therapeutics', 'public health relevance', 'research study', 'sex', 'supervised learning', 'unsupervised learning']",NIMH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,708875
"Identification of Distinct Multimodal Biotypes of PTSD Using Data Driven Approach: A Multisite Big Data Study Posttraumatic stress disorder (PTSD) is a highly prevalent and debilitating disorder. Despite efforts to characterize the pathophysiology of PTSD and its heterogenity, no objective biomarker have been established to aid in diagnosis, and prediction of treatment response. This K01 presents a program for research and training that will support the applicant on a path towards becoming an independent investigator, focused on utilizing a data-driven computational approach and machine learning techniques to identify multimodal neural biomarkers of PTSD (supervised) and multimodal biotypes of PTSD (unsupervised) and explore whether such biotypes could be used to predict response to prolonged exposure (PE), the first line treatment for PTSD. The training plan builds on the candidate’s prior training and experience and capitalizes on a mentorship team and a research environment to foster development of the candidate’s expertise in 1) the neural and behavioral basis of PTSD and anxiety disorders; 2) multimodal data fusion analysis and latent dimension interpretation with data-driven computational approaches and data reproducibility; and 3) patient-oriented translational research in anxiety disorders. This research project will apply both supervised and unsupervised machine learning techniques on multimodal MRI data from the largest existing PTSD dataset (N~3000 from the ENIGMA-PTSD working group). Biotypes identified from this large dataset will then be extended to clinical treatment data. The results of the proposed research will be vital to aid in finding neural biomarkers of PTSD and better predict different treatment outcomes through different biotype targets and will lead to a future R01 grant examining brain-symptoms association across anxiety and trauma-related disorders, and to use the newly identified PTSD biotypes to inform different treatment outcomes in a following R61/33. Together, the research and training experiences and expertise developed through this K01 award will support the applicant’s transition to research independence and ensure the applicant becomes a leading authority in the application of data-driven computational approaches in psychiatry research, and provide the basis for future NIMH grants to explore biotypes from multimodal brain imaging using data-driven computational approaches across anxiety-related disorders. PTSD can occur after a direct or indirect traumatic experience and is a highly prevalent and debilitating disorder. This research project use a big data and data-driven approaches to study the heterogenity of PTSD. In the long term, this line of research will aid in finding neural biomarkers of PTSD and better predict different treatment outcomes through different biotype targets, which will advance the development of effective diagnostics and treatments for PTSD.",Identification of Distinct Multimodal Biotypes of PTSD Using Data Driven Approach: A Multisite Big Data Study,10127376,K01MH122774,"['Address', 'Advanced Development', 'Anxiety', 'Anxiety Disorders', 'Behavioral', 'Big Data', 'Biological', 'Biological Markers', 'Brain', 'Brain imaging', 'Categories', 'Classification', 'Clinical', 'Clinical Treatment', 'Clinical Trials', 'Cluster Analysis', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Ensure', 'Environment', 'Fostering', 'Fright', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Heterogeneity', 'Individual', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measures', 'Mental Depression', 'Mentored Research Scientist Development Award', 'Mentorship', 'Methods', 'Modeling', 'Multimodal Imaging', 'National Institute of Mental Health', 'Neurobiology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Post-Traumatic Stress Disorders', 'Prediction of Response to Therapy', 'Prevalence', 'Psychiatry', 'Psychotherapy', 'Psychotic Disorders', 'Public Health', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Research Training', 'Rest', 'Sample Size', 'Selection for Treatments', 'Subgroup', 'Supervision', 'Symptoms', 'Techniques', 'Training', 'Translational Research', 'Trauma', 'Treatment outcome', 'Work', 'advanced analytics', 'anxiety-related disorders', 'associated symptom', 'authority', 'base', 'clinical heterogeneity', 'clinical phenotype', 'comorbidity', 'data fusion', 'design', 'experience', 'gray matter', 'individualized medicine', 'large datasets', 'memory process', 'multimodal data', 'multimodality', 'neurobiological mechanism', 'neuroimaging', 'patient oriented', 'predicting response', 'programs', 'relating to nervous system', 'reward processing', 'skills', 'supervised learning', 'therapy development', 'trauma exposure', 'treatment comparison', 'treatment research', 'treatment response', 'treatment strategy', 'unsupervised learning', 'working group']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K01,2021,176916
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,10085244,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,356625
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,10372268,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2021,267499
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10178133,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2021,422740
"Accounting for Hidden Bias in Vaccine Studies: A Negative Control Framework Project Summary / Abstract The proposed research aims to develop novel causal inference methods to resolve unmeasured confounding bias known to plague vaccine effectiveness and safety studies by leveraging so-called negative control variables widely available in vaccine studies. A negative control outcome is a variable known not to be causally affected by the treatment of interest, while a negative control exposure is a variable known not to causally affect the outcome of interest. Both share a common confounding mechanism as the exposure-outcome pair of primary interest. Examples of negative controls abound in vaccine studies. Such known-null effects form the basis of falsiﬁca- tion strategy to detect unmeasured confounding, however little is known about when and how negative controls can be used to resolve unmeasured confounding bias. We plan to develop principled negative control methods for identiﬁcation and semiparametric estimation of causal effects in the presence of unmeasured confounding, incorporating modern highly adaptive machine learning methods. We also plan to develop negative control meth- ods to detect and quantify causal effects in complex longitudinal and survival settings critical to vaccine studies using routinely collected healthcare data. Finally we plan to apply the proposed methods to evaluate vaccine effectiveness using data collected from a pioneering test-negative design platform and to monitor vaccine safety using electronic health record data. Successful completion of the proposed research will equip investigators with paradigm-shifting methods to unlock the full potential of contemporary healthcare data, encourage investigators to routinely check for evidence of confounding bias, and ultimately improve the validity of scientiﬁc research. Project Narrative The proposed research will develop statistical methods to detect and resolve unmeasured confounding bias by leveraging prior knowledge about known-null effects widely available but often underappreciated in healthcare data — thereby facilitating valid and reproducible research in vaccine effectiveness and safety studies.",Accounting for Hidden Bias in Vaccine Studies: A Negative Control Framework,10093358,R01GM139926,"['Accounting', 'Affect', 'Area', 'Benefits and Risks', 'Complex', 'Data', 'Data Set', 'Dimensions', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Failure', 'Gene Expression Profiling', 'Health Policy', 'Healthcare', 'Knowledge', 'Machine Learning', 'Methods', 'Modernization', 'Monitor', 'Nature', 'Observational Study', 'Outcome', 'Plague', 'Plague Vaccine', 'Property', 'Public Health', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Residual state', 'Risk', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Tissue-Specific Gene Expression', 'Use Effectiveness', 'Vaccination', 'Vaccines', 'adverse event risk', 'design', 'effectiveness evaluation', 'effectiveness study', 'flexibility', 'high dimensionality', 'improved', 'innovation', 'interest', 'machine learning method', 'novel', 'pathogen', 'public health priorities', 'safety study', 'semiparametric', 'theories', 'tool', 'user friendly software', 'vaccine effectiveness', 'vaccine evaluation', 'vaccine safety', 'vaccine trial']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,401613
"Development of A High Throughput Image-Guided IMRT System for Preclinical Research Project Summary/Abstract Preclinical radiobiology experiments on small animals are crucial to test the safety and efficacy before human clinical trials. However, limited by currently available technologies, preclinical animal studies substantially differ from state-of-the-art human treatments in dose conformity. Consequently, the animal studies poorly mimic the radiobiological, radioimmunological, and toxicity environment of human therapies. The disparity adversely affects our ability to meaningfully test hypotheses that are intended for human translation. With decades of advancement, human radiotherapy has achieved high targeting accuracy and dose conformality based on technological breakthroughs, including intensity-modulated radiotherapy (IMRT), which is unavailable for mouse experiments. A practical device and algorithm to modulate the x-ray intensity for the scale of small animals is the first step to bridge the gap. With the support of an NIH R21 grant, we engineered a novel small animal IMRT dose modulator termed sparse orthogonal collimator (SOC). Equally important as the hardware, we created the enabling mathematical tools to deliver SOC IMRT plans with higher achievable resolution than a theoretically miniaturized MLC-based IMRT. We commissioned and tested prototypical SOCs to deliver highly modulated doses in silico and on phantoms. Nonetheless, there are still large gaps between an intensity modulation device and a small animal IMRT system suitable for broad adoption and impact. The required time, resources, and training to create sophisticated SOC-IMRT plans are incompatible with preclinical settings. Furthermore, without automation, the existing image-guided small animal IMRT treatment is prohibitively slow for treating live animals under anesthesia. Lastly, the current manual method to switch between imaging and therapy modes results in intractable uncertainties in dose delivery. We propose to fill these gaps using automation, robotics, and system optimization. We propose the following specific aims. Specific Aim 1 (SA1). Automated organ segmentation for mice using deep learning neural networks. Specific Aim 2 (SA2). Development of a fully functional, automated, and efficient IMRT system. Specific Aim 3 (SA3). Development and validation of a robotic Multi Mouse Automated Treatment Environment (Multi-MATE) for automated imaging and treatment. Besides dosimetry, we will quantify the time performance, which is critical to small animal IMRT system. As a result, in addition to improving the hardware accuracy and reliability, the proposed project will provide a fully automated planning and delivery system, thus removing the last barriers towards the broad adoption of small animal IMRT. The success of the proposed project will help existing research to achieve the full potential for human translation and enable future hypotheses testing where accurate complex dose distribution is critical. Project Narrative A major impediment in translating animal radiation studies to human patients is the disparity in radiation techniques. Existing methods cannot create human like conformal radiation dose on mice with necessary accuracy and efficiency. To better mimic human treatment without prohibitively complicated and slow procedures, we propose to develop a high throughput image guided small animal conformal irradiation platform.",Development of A High Throughput Image-Guided IMRT System for Preclinical Research,10317441,R01CA259008,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Anesthesia procedures', 'Animals', 'Automation', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collimator', 'Complex', 'Computer software', 'Conformal Radiotherapy', 'Development', 'Devices', 'Dose', 'Engineering', 'Environment', 'Future', 'Grant', 'Human', 'Image', 'Individual', 'Intensity-Modulated Radiotherapy', 'Intervention', 'Knowledge', 'Manuals', 'Mathematics', 'Methods', 'Mus', 'Organ', 'Patients', 'Performance', 'Procedures', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Radiobiology', 'Research', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Roentgen Rays', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Toxic effect', 'Training', 'Translating', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'base', 'biological research', 'deep learning', 'deep neural network', 'design', 'dosimetry', 'experimental study', 'image guided', 'improved', 'in silico', 'innovation', 'irradiation', 'miniaturize', 'novel', 'pre-clinical', 'pre-clinical research', 'process optimization', 'robotic system', 'safety testing', 'success', 'tool', 'treatment planning', 'trend', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,441662
"CSHL Network Biology Conference PROJECT SUMMARY This proposal seeks support for the conference on Network Biology, to take place March/April 2021 to 2025, at the Cold Spring Harbor Laboratory (CSHL). This meeting, held in biannual rotation on the CSHL campus in New York, brings together senior and junior scientists from both experimental and computational laboratories with common interests in network biology. The meeting will emphasize new discoveries and provide an open forum for the presentation of the latest research and results on molecular networks and their relevance to normal and abnormal cellular physiology. It will be essential for advancing knowledge in all aspects of the network modeling process, from data generation in experimental cell biology to data analysis and computer simulation and from the development and validation of network models describing these data to biological inferences made from the models. The conference will include platform sessions on interaction networks, signaling and network dynamics, regulatory networks, computational tools, artificial intelligence and big data, multi-scale networks, networks and disease, networks in differentiation, microbiome networks, network evolution, synthetic networks, network engineering and networks beyond biology though the exact program for the meeting will be assembled after the abstract submission deadline in February 2021 and adapted to ongoing developments in the field in subsequent years. This conference will include significant components designed to facilitate the active participation of younger scientists such as selection of platform speakers on the basis of the scientific merit of their submitted abstracts as well as poster presentations, round tables, lightning talks and poster prizes. Distinguished speakers will also be invited to give platform talks and interact with more junior scientists. The intimate environment at CSHL fosters social interactions and active participation by all. The majority of participants to the previous CSHL Network Biology meeting expressed that they were “very satisfied”. Speakers' panels have consisted of at least 50% women; the gender balance will be maintained in future meetings. In the 2019 iteration of the meeting, a panel discussion was established to address the challenges of Women in Network Science. We will continue to address big community challenges though panel discussions in this meeting. In 2021, we will discuss Applicability and Translatability of Network Biology with panelists including network biologists whose work is deeply influential throughout the ongoing covid-19 pandemic. PROJECT NARRATIVE Biological systems are functionally and structurally formed by complex networks of interacting molecular components, many of which are encoded in the genome. Elucidating the structure and function of these networks and understanding how their dysregulation causes disease are critical steps toward improving human health. This application seeks support for the conference on Network Biology to be held every two years in March/April 2021-25 at the Cold Spring Harbor Laboratory, to bring together experimental and computational biologists and discuss emerging trends and latest results in the field.",CSHL Network Biology Conference,10137390,R13HG011550,"['Address', 'Animals', 'Artificial Intelligence', 'Attention', 'Awareness', 'Big Data', 'Biochemistry', 'Biological', 'Biological Process', 'Biology', 'COVID-19 pandemic', 'Cell physiology', 'Cellular biology', 'Chalk', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Discipline', 'Disease', 'Engineering', 'Ensure', 'Environment', 'Equilibrium', 'Event', 'Evolution', 'Faculty', 'Fostering', 'Future', 'Gender', 'Gene Proteins', 'Generations', 'Genetic', 'Genome', 'Geography', 'Health', 'Human', 'Industrialization', 'Influentials', 'International', 'Intervention', 'Knowledge', 'Laboratories', 'Length of Stay', 'Lightning', 'Methodology', 'Microbe', 'Modeling', 'Molecular', 'Nationalities', 'New York', 'Normal Cell', 'Organism', 'Participant', 'Plants', 'Postdoctoral Fellow', 'Prize', 'Process', 'Property', 'Published Comment', 'RNA', 'Reagent', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Rotation', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Structure', 'Technology', 'Validation', 'Woman', 'Work', 'base', 'biological systems', 'career', 'computer science', 'computerized tools', 'data exchange', 'data reuse', 'design', 'graduate student', 'host-microbe interactions', 'improved', 'innovation', 'interdisciplinary collaboration', 'interest', 'meetings', 'microbiome', 'multidisciplinary', 'network models', 'posters', 'precision medicine', 'programs', 'senior faculty', 'social', 'symposium', 'trend', 'unpublished works']",NHGRI,COLD SPRING HARBOR LABORATORY,R13,2021,3000
"Biomedical Raman Imaging Workshop Summary The purpose of the planned conference is to facilitate development of Raman-spectroscopy based clinical appli- cations.  Raman scattering provides label-free contrast for imaging that derives from intrinsic molecular vibrations. Because it is label-free and reports in an unbiased way on all molecular species in a sample, it provides a holistic “view” of the chemical environment in clinical samples, and thus holds signiﬁcant value as a diagnostic and treatment monitoring tool.  While the phenomenon of Raman scattering has been known since 1920, and its clinical potential has been recognized for many decades, roadblocks including weak signal levels and complexity of its readout has precluded it from clinical use. These roadblocks are now being removed through innovations in instrument development and machine learning. Narrative Raman spectroscopy provides diagnostically important chemical proﬁles of clinical samples, withouth the need of labeling. Throgh this it holds tremendous potential to improve many diagnostic and monitoring aspects of healthcare. The purpose of this workshop is to facilitate efﬁcient development of these techniques in a way that will be clinically acceptable.",Biomedical Raman Imaging Workshop,10318774,R13EB032251,"['Adopted', 'Adoption', 'Antibiotic susceptibility', 'Area', 'Biological', 'Biology', 'Brain', 'Caring', 'Chemicals', 'Clinical', 'Complex', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Diagnostic', 'Educational workshop', 'Environment', 'Excision', 'Fingerprint', 'Fruit', 'Generations', 'Healthcare', 'Histology', 'Image', 'Image Analysis', 'Imaging technology', 'In Situ', 'Label', 'Light', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Molecular', 'Monitor', 'Nature', 'Paper', 'Pathogen detection', 'Photons', 'Physicians', 'Publishing', 'Raman Spectrum Analysis', 'Reporting', 'Role', 'Sampling', 'Scheme', 'Signal Transduction', 'Time', 'Tissues', 'Translating', 'Voice', 'base', 'clinical application', 'clinical practice', 'contrast imaging', 'imaging approach', 'imaging modality', 'improved', 'in vivo', 'innovation', 'liquid biopsy', 'screening', 'symposium', 'technique development', 'technology development', 'tool', 'tumor', 'vibration']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R13,2021,9996
"Public Insurance Design and Health at Older Ages PROJECT ABSTRACT Health insurance has been at the forefront of US public policy debate throughout the last decade. For elderly Americans, who benefit from nearly universal coverage under Medicare, decisions about the scope of their insurance coverage have been a central policy concern since Medicare’s inception in 1965. Medicare’s coverage is extensive, but by statute the program only covers medical services that are “reasonable and necessary,” which can be a controversial definition. Some decisions about what Medicare should cover have engendered intense debate, underscoring the importance of the program’s coverage decisions for millions of patients and doctors. The debate around the scope of Medicare coverage is likely to intensify in the coming decades as options for medical treatment, and testing, expand rapidly, the population ages, and public insurance systems grapple with how to address inequality in access to medical innovations. Yet, despite the importance of decisions about the scope of insurance coverage in and outside of Medicare, we know little about how the scope of coverage (as opposed to patient cost-sharing), affects treatment choices, clinical practice, and health outcomes for the elderly. The research outlined in this proposal aims to start filling this gap. The project investigates how the presence or lack of insurance coverage for specific procedural or pharmacologic therapies affects treatment decisions and health outcomes for the elderly with Alzheimer’s Disease and related Dementias (ADRD). This is a population that may be particularly vulnerable to changes and limits in insurance coverage, as the patients may have limited decision-making capacity and may be disproportionately exposed to treatments that are deemed experimental and lacking effectiveness to clear the “reasonable and necessary” threshold. Aim 1 of the project is to estimate the average effect of coverage decisions across prescription drugs and outpatient procedures on treatment decisions and health outcomes of elderly Medicare enrollees with ADRD. Aim 2 is to predict and characterize the subgroups of ADRD patients that are most likely to be affected by decisions that restrict the scope of insurance coverage using machine learning methods. The proposed empirical method is to use quasi- experimental variation that arises from natural experiments of abrupt changes in insurance coverage within different parts of the Medicare program. The analysis takes advantage of variation in the scope of formularies across Medicare Part D plans, as well as the variation in local coverage decisions for physician services and outpatient procedures under Medicare Part B. These sources of variation coupled with methods for quasi- experimental estimation of treatment effects and machine learning methods for heterogeneity analyses, allow estimating the response of treatment decisions and health of the elderly with ADRD across different drugs, procedures, and subgroups of ADRD patients. PROJECT NARRATIVE For elderly Americans, who benefit from nearly universal coverage under Medicare, decisions about the scope of their insurance coverage have been a central policy concern since Medicare’s inception in 1965 - Medicare’s coverage is extensive, but nevertheless incomplete as by statute the program only covers medical services that are “reasonable and necessary,” which can be hard to define. The debate around the scope of Medicare coverage is likely to intensify in the coming decades as options for medical treatment, and testing, expand rapidly, the population ages, and public insurance systems grapple with how to address inequality in access to medical innovations. In this project I investigate how changes in coverage for prescription drugs, physician office visits, and outpatient procedures affect the treatment received by elderly patients with Alzheimer’s Disease and related dementias (ADRD), who often face coverage limitations due to experimental nature of many ADRD treatments, and yet may be most vulnerable to unintended consequences of any coverage restrictions.",Public Insurance Design and Health at Older Ages,10137860,K01AG059843,"['Address', 'Admission activity', 'Affect', 'Age', 'Alzheimer&apos', 's disease related dementia', 'American', 'Amyloid', 'Anxiety', 'Barbiturates', 'Benzodiazepines', 'Caring', 'Characteristics', 'Clinical Medicine', 'Cost Sharing', 'Coupled', 'Data', 'Diagnostic', 'Diagnostic Procedure', 'Drug Prescriptions', 'Drug Targeting', 'Economics', 'Effectiveness', 'Elderly', 'Ethnic Origin', 'Exposure to', 'Face', 'Family Physicians', 'Formularies', 'Fracture', 'Frequencies', 'Future', 'Geography', 'Geriatrics', 'Gerontology', 'Goals', 'Health', 'Health Benefit', 'Health Insurance', 'Heart', 'Heterogeneity', 'Hospitalization', 'Individual', 'Inequality', 'Insurance', 'Insurance Coverage', 'Investigation', 'Knowledge', 'Learning Skill', 'Length of Stay', 'Light', 'Machine Learning', 'Measures', 'Medical', 'Medicare', 'Medicare Part B', 'Mental Depression', 'Mentors', 'Methods', 'Movement', 'Natural experiment', 'Nature', 'Office Visits', 'Outcome', 'Outcome Measure', 'Outpatients', 'Pain', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Physicians', 'Policies', 'Policy Maker', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Public Policy', 'Quasi-experiment', 'Race', 'Recording of previous events', 'Research', 'Services', 'Skilled Nursing Facilities', 'Source', 'Subgroup', 'System', 'Testing', 'Therapeutic procedure', 'Time', 'Training', 'Universal Coverage', 'Variant', 'aging population', 'alternative treatment', 'bariatric surgery', 'base', 'clinical practice', 'comorbidity', 'decision-making capacity', 'design', 'experience', 'high dimensionality', 'innovation', 'insurance claims', 'machine learning method', 'mortality', 'older patient', 'patient population', 'patient subsets', 'precision medicine', 'predictive modeling', 'programs', 'public health insurance', 'response', 'socioeconomics', 'theories', 'tool', 'treatment choice', 'treatment effect', 'treatment response']",NIA,STANFORD UNIVERSITY,K01,2021,126700
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods. 1 This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings –  2 funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating  3 Biology into In Silico Methodologies: Modern Approaches for incorporating biological  4 reasoning and understanding into computational methods. As a “Contemporary Concepts  5 in Toxicology” meeting, this workshop has the full backing, including being financially  6 underwritten, by the Society of Toxicology.  7 Computational modeling is an important tool for assessing the safety and use of  8 chemicals across many industries, including chemical, pharmaceutical, and consumer products.  9 Moreover, in silico methodologies offer academia and regulatory a fast and cheap method of 10 prioritizing its efforts to maintain compliance and safety in the market and environment. 11 This conference is designed to promote the development of actionable insights and 12 methodologies for increasing the biological relevance of in silico solutions. Specifically, this 13 conference will focus on solving the “black box effect”. There are many ways to validate a 14 model’s accuracy and domain – however if the model cannot explain what is happening 15 biologically, its use is severely diminished. This workshop will bring together regulatory, 16 academia, industry, and service providers to discuss current solutions and efforts, as well as 17 ongoing and future research. One goal of this conference will be to develop a roadmap for the 18 incorporation of AOPs (and similar biological reasonings) for computational tools. 19 This workshop has great appeal for multiple stakeholders within toxicology, namely 20 industry, academia, regulators, as well as service providers. The use of machine-learning to 21 replace laboratory toxicological tests is paramount to the future of the industry (3Rs). The use 22 of in silico models are explicitly referenced by NICEATM’s U.S. Strategic Roadmap, as well as 23 TSCA. Moreover, many industries and regulatory entities are taking significant steps away from 24 animal testing. Most recently, the US EPA stated that it will eliminate animal testing by 2035. 25 This workshop will bring together different stakeholders to discuss the current state of 26 AOPs and in silico methodologies, and to work towards a unified approach for their 27 incorporation. The final outcome of the workshop will be a white-paper that not only reviews the 28 current landscape but discusses concretes steps, as outlined in the breakout session, needed 29 for the regulatory acceptance of machine learning technologies – specifically a roadmap for the 30 inclusion of AOPs into computational tools and explanations. This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings – funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating Biology into In Silico Methodologies: Modern Approaches for incorporating biological reasoning and understanding into computational methods. This workshop will bring together different stakeholders to discuss the current state of AOPs and in silico methodologies, and to work towards a unified approach for their incorporation. The final outcome of the workshop will be a white- paper that not only reviews the current landscape but discusses concretes steps, as outlined in the breakout session, needed for the regulatory acceptance of machine learning technologies – specifically a roadmap for the inclusion of AOPs into computational tools and explanations.",Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods.,10144727,R13ES032662,"['Academia', 'Address', 'Adoption', 'Animal Testing', 'Animals', 'Back', 'Biological', 'Biology', 'Budgets', 'Chemicals', 'Chemistry', 'Communities', 'Computer Models', 'Computing Methodologies', 'Decision Making', 'Development', 'Educational workshop', 'Environment', 'Event', 'Funding', 'Future', 'Goals', 'In Vitro', 'Individual', 'Industry', 'Laboratories', 'Laws', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'National Institute of Environmental Health Sciences', 'Nonprofit Organizations', 'Outcome', 'Paper', 'Pathway interactions', 'Pharmacologic Substance', 'Policies', 'Process', 'Publishing', 'Safety', 'Societies', 'System', 'Technology', 'Testing', 'Toxicology', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'cheminformatics', 'computer framework', 'computerized tools', 'consumer product', 'cost', 'design', 'improved', 'in silico', 'in vivo', 'insight', 'meetings', 'predictive modeling', 'research and development', 'service providers', 'symposium', 'tool', 'web site']",NIEHS,"TOXTRACK, LLC",R13,2021,4000
"Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease PROJECT SUMMARY Hemoglobin (Hb) disorders are among the world's most common monogenic diseases. Nearly 7% of the world’s population carry Hb gene variants. Sickle cell disease (SCD) arises when Hb mutations are inherited homozygously (HbSS) or paired with another β-globin gene mutation. Globally, an estimated 400,000 babies are born annually with SCD, and 70%-75% are in sub-Saharan Africa (SSA). It is estimated that 50-90% in SSA die by their 5th birthday, 70% of these deaths are preventable. Effective management of SCD involves early diagnosis, and genetic counselling, and, importantly, nationwide newborn screening (NBS). NBS programs utilizing centralized laboratories have dramatically reduced SCD mortality in high-resource countries. NBS requires sensitive detection of relatively low levels of Hb variants in the presence of high fetal Hb (HbF). Normal HbA and sickle HbS should be accurately identified in the presence of high levels (up to 90%) of HbF. The current gold standard for Hb variant testing is high-performance liquid chromatography (HPLC), which requires expensive equipment and reagents, highly trained personnel, and modern laboratories. In low- resource regions, very few centralized laboratories can perform costly Hb testing. Testing is not available to the large percentage of infants born outside of a major hospital or city. There is an unmet need for affordable, portable, easy-to-use, accurate, point-of-care (POC) tests to facilitate decentralized Hb testing to enable nationwide NBS programs. In 2019, the World Health Organization (WHO) listed Hb electrophoresis as an essential in vitro diagnostic in low- and middle-income countries. We have developed a POC microchip electrophoresis Hb variant testing system, MicroChip Electrophoresis (MCE), under the product name “Gazelle Hb Variant” by Hemex Health, Inc. MCE reports Hb phenotype, Hb quantification (%Hb), and an interpretive statement showing genotype (such as SCD, Sickle Cell Trait, or Normal). MCE has been extensively validated for hemoglobinopathies, including SCD, hemoglobin E disease, and thalassemia. Newborns and infants below 6 weeks of age have very low concentrations of Hb variants other than Hb F which is high, therefore an improvement to lower the limit of detection (LoD) is needed to support NBS programs worldwide. By decreasing the LoD from the current 10% to 2%, newborns and infants can be screened with this affordable system. The innovation in this SBIR Phase I is the integration of multi-spectral imaging and machine learning based data analysis capability to MCE to develop MCE+ to accurately screen newborns for common Hb variants. We propose the following aims: Aim 1: Integrate multi-spectral imaging and machine learning algorithm into the MCE platform to enable identification and quantification of hemoglobin variants in newborns. Aim 2: Perform clinical testing of the MCE+ multi-spectral newborn screening system. Significance of this project is that MCE+ is the only affordable POC system for quantitative and objective hemoglobin variant testing that allows screening at birth. PROJECT NARRATIVE Up to 50 to 90% of children born with sickle cell disease (SCD) in economically disadvantaged countries (over 400,000 per year) die before the age of five, although the WHO estimates that 70% could be saved through simple, cost-effective treatments. Early diagnosis starting at birth is critical for implementing effective disease management, but newborn screening is a challenge for low resource environments where a decentralized, point-of-care solution is needed. This project enables our affordable, point-of-care platform based on microchip electrophoresis technology to accurately perform newborn screening.",Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease,10255480,R43HL156685,"['Africa', 'Africa South of the Sahara', 'Age', 'Bedside Testings', 'Birth', 'Blood', 'Care Technology Points', 'Caring', 'Child', 'Cities', 'Clinical', 'Clinical Research', 'Country', 'Data Analyses', 'Decentralization', 'Detection', 'Development', 'Disease', 'Disease Management', 'Drops', 'Early Diagnosis', 'Economically Deprived Population', 'Electrophoresis', 'Ensure', 'Environment', 'Equipment', 'Fetal Hemoglobin', 'Gender', 'Gene Mutation', 'Genetic Counseling', 'Genotype', 'Ghana', 'Gold', 'Health', 'Health Status', 'Hemoglobin', 'Hemoglobin E Disease', 'Hemoglobin concentration result', 'Hemoglobinopathies', 'High Pressure Liquid Chromatography', 'Hospitals', 'Human Resources', 'India', 'Infant', 'Inherited', 'Laboratories', 'Machine Learning', 'Mendelian disorder', 'Microchip Electrophoresis', 'Modernization', 'Mutation', 'Names', 'Neonatal Screening', 'Newborn Infant', 'Phase', 'Phenotype', 'Point-of-Care Systems', 'Population', 'Race', 'Reagent', 'Reference Standards', 'Reporting', 'Resources', 'Sickle Cell Anemia', 'Sickle Cell Trait', 'Small Business Innovation Research Grant', 'Southeastern Asia', 'Specificity', 'System', 'Teaching Hospitals', 'Technology', 'Testing', 'Thalassemia', 'Training', 'Validation', 'Variant', 'Work', 'World Health Organization', 'base', 'beta Globin', 'commercialization', 'cost', 'cost effective treatment', 'detection limit', 'diagnostic accuracy', 'genetic variant', 'improved', 'in-vitro diagnostics', 'innovation', 'innovative technologies', 'low and middle-income countries', 'machine learning algorithm', 'miniaturize', 'mortality', 'novel', 'point of care', 'portability', 'preventable death', 'research clinical testing', 'screening', 'screening program', 'sickling', 'spectrograph', 'trait']",NHLBI,"HEMEX HEALTH, INC.",R43,2021,256580
"An Agent-Based Modeling Platform for Environmental Biotechnology Hazardous pollutants in the environment continue to threaten public health and environmental  safety. Human exposure to major contaminant classes, such as polyfluorinated compounds  (PFCs), hazardous organic compounds (HOCs), and heavy metals, has been linked to a variety of  diseases and is subject to stringent State and Federal environmental regulations.  Bioremediation is a low-cost and environmentally friendly approach with many successful  use-cases; however, conventional bioremediation technologies can suffer from unreliability, low  degradation rates, and incomplete degradation. As stakeholders to Superfund sites and other sites  with water or soil pollution urgently demand more efficient, less costly and more reliable  remediation technologies, it is critical to look to advancements in computational  modeling to develop next-generation, precision-engineered bioremediation technologies. The proposed project builds on successful outcomes from Phase I in which a new computational  platform was designed and validated to accurately predict the bioremediation kinetics of  a multi-organism microcosm degrading a combination of HOCs in groundwater. The basis of  this platform is an approach called agent-based modeling (ABM), where the functions of  individual components (e.g. microorganisms) within complex ecosystems are used to predict and  optimize system-level properties (e.g. bioremediation kinetics). In this Phase II project, the novel computational platform developed in Phase I is  further improved with a machine learning component that leverages bioinformatics  databases to develop rationally tailored microbiomes for degrading complex pollutant  mixtures. Iterative experimental validation of model outputs is conducted using an innovative  materials science platform that maintains the relative concentration of different species in the  microbiome constant within the multi-zone treatment barrier (in-situ) or multi-zone bioreactor  (ex-situ). The project includes focused development of a prototype for one bioremediation use-case,  which is directly compared to a conventional (non-precision) bioremediation system treating   actual contaminated groundwater. This will be performed in order to assess and quantify  the expected technical and economic benefits of harnessing the project's novel computational  platform in biotechnology development. The broad, long-term impact of the proposed project will be to transform the development and  implementation of bioremediation by integrating advancements in computational modeling, machine  learning, bioinformatics, and materials science. By leveraging novel tools across disciplines, the  project will accelerate the development of more precise, reliable and inexpensive technologies for  environmental remediation. The successful outcome of the proposed project will also provide new  collaborative opportunities for industry and academia to more rapidly address the remediation of  high-priority pollutants in the environment, and ultimately help mitigate the effects of hazardous  pollutants on communities impacted by the presence of environmental contamination. PROJECT NARRATIVE Contaminated soils and waters continue to threaten public health and safety. This project builds on the development of a novel computational platform for predicting the complex, dynamic interactions between microbial ecosystems and hazardous contaminants-of-concern in the environment, and to utilize this information to develop improved engineered remediation biotechnologies.",An Agent-Based Modeling Platform for Environmental Biotechnology,10158243,R44ES026541,"['Academia', 'Address', 'Biodegradation', 'Bioinformatics', 'Bioreactors', 'Bioremediations', 'Biotechnology', 'Chemicals', 'Classification', 'Colorado', 'Communities', 'Complex', 'Computer Models', 'Data', 'Databases', 'Development', 'Discipline', 'Disease', 'Economics', 'Ecosystem', 'Engineering', 'Environment', 'Environmental Monitoring', 'Environmental Pollution', 'Enzymes', 'Exposure to', 'Ginkgo biloba', 'Goals', 'Growth', 'Heavy Metals', 'In Situ', 'Indiana', 'Individual', 'Industry', 'Kinetics', 'Laboratories', 'Learning Module', 'Letters', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Molecular', 'Municipalities', 'Organism', 'Outcome', 'Output', 'Phase', 'Polymers', 'Process', 'Property', 'Public Health', 'Regulation', 'Research', 'Safety', 'Side', 'Site', 'Soil', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Water', 'Water Pollution', 'base', 'computational platform', 'cost', 'design', 'economic evaluation', 'enzyme pathway', 'exposed human population', 'ground water', 'improved', 'innovation', 'laboratory experiment', 'materials science', 'microbial', 'microbiome', 'microorganism', 'next generation', 'novel', 'pollutant', 'prototype', 'remediation', 'research and development', 'soil pollution', 'success', 'superfund site', 'tool']",NIEHS,"MICROVI BIOTECH, INC.",R44,2021,630992
"Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility Traumatic brain injury (TBI) is a leading cause of neurological disorders and affects over 2.5 million people each year, yet no treatment has successfully translated from bench to clinic. TBI is a broad term and encompasses an extremely heterogeneous set of injuries differing by cause, severity, biomechanics, and the varied, complex secondary injury responses that collectively result in chronic disabilities. Current preclinical research circumvents the issue of TBI heterogeneity by relying on specific preclinical animal models that mimic subpopulations of patients and particular secondary injury mechanisms with each study focusing on limited, individual pathways. This proposal instead aims to tackle TBI heterogeneity by approaching TBI as a “big data” problem and aggregating and analyzing the multidimensional data collectively. A framework for data harmonization and curation will be developed, and datasets from a consortium of preclinical labs employing a variety of preclinical TBI models will be collected and curated into an open data commons (ODC-TBI). Utilizing machine learning and multidimensional analytics, the proposed research will directly leverage TBI heterogeneity in the merged dataset to identify persistent features of TBI to empower translational research. By creating a preclinical TBI ODC and applying machine learning to integrate the heterogeneity of preclinical TBI models, the project will reveal multidimensional features of TBI across heterogeneous injuries and characterize how diverse secondary injury mechanisms interact and ultimately affect injury outcome. Throughout the project's timeline, new datasets will continue to be harmonized into the ODC-TBI according to the established framework. The ODC-TBI will be the first open multicenter, multi-model repository of preclinical TBI data and will enable the application of data science to the field of TBI. Furthermore, the ODC-TBI and the methods implemented throughout the project will be openly shared to improve reproducibility of TBI research. Together with the multidimensional analysis that will provide quantitative and qualitative understanding of TBI heterogeneity, the project aims to ultimately accelerate data- driven discovery and precision medicine for TBI. Reflecting the complexities of clinical traumatic brain injury (TBI), preclinical TBI research is confounded by the extreme heterogeneity prevalent across possible injury models and resulting biological responses. The proposed research will aggregate and curate an extensive open data commons (ODC) of preclinical TBI research with multiple TBI models and utilize machine learning to tackle TBI heterogeneity directly. The project will create an ODC for preclinical TBI research to improve data sharing and scientific reproducibility, and will empower translational TBI research by identifying multidimensional features of TBI that best predict functional outcome.",Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility,10212363,F32NS117728,"['Address', 'Affect', 'Animal Model', 'Big Data', 'Biological', 'Biological Markers', 'Biomechanics', 'Brain region', 'Chronic', 'Clinic', 'Clinical', 'Closed head injuries', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Element', 'Data Science', 'Data Set', 'Development', 'Foundations', 'Goals', 'Heterogeneity', 'Incidence', 'Individual', 'Inflammation', 'Informatics', 'Injury', 'Institutes', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Multivariate Analysis', 'National Institute of Neurological Disorders and Stroke', 'Outcome', 'Pathway interactions', 'Pattern', 'Pharmacologic Substance', 'Population', 'Positioning Attribute', 'Pre-Clinical Model', 'Principal Component Analysis', 'Publishing', 'Reproducibility', 'Research', 'Severities', 'Standardization', 'Synaptic plasticity', 'Therapeutic', 'TimeLine', 'Translating', 'Translational Research', 'Translations', 'Traumatic Brain Injury', 'behavioral outcome', 'bench to bedside', 'biomarker discovery', 'controlled cortical impact', 'data curation', 'data framework', 'data harmonization', 'data sharing', 'disability', 'experimental study', 'functional outcomes', 'genetic manipulation', 'improved', 'insight', 'multidimensional data', 'multiple datasets', 'nerve injury', 'nervous system disorder', 'neuroinflammation', 'open data', 'patient subsets', 'pre-clinical', 'pre-clinical research', 'precision medicine', 'repository', 'response', 'response to injury']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2021,71224
"Data-driven subtyping in major depressive disorder Abstract  Major depressive disorder contributes substantially to morbidity, mortality, and health care cost. Standard treatments are ineffective for up to a third of patients, so new treatment options are needed along with strategies to make more effective use of existing treatments. However, progress in expanding therapeutic options has been hindered by heterogeneity in clinical presentation and course of depression.  In other disorders such as inflammatory bowel disease, cancer, and dementia, identifying disease subtypes has led to therapeutic discoveries. In major depressive disorder, efforts to identify subtypes based on clinical observation have yielded limited success, primarily because of the lack of availability of adequate cohorts for replication, and because those features most apparent to clinicians may not be the most relevant for differentiating subgroups. Efforts to leverage large electronic health record data sets for subtyping address some of these challenges, but standard approaches may not yield human-interpretable features nor those with value in prediction.  The investigators have developed methods for engineering features that balance utility in prediction with interpretability. Preliminary work by the investigators during a year of R56 support yielding 4 publications demonstrates that this approach indeed yields coherent topics without sacrificing predictive validity; electronic health records contain meaningful data that facilitates identification of interpretable patient subgroups. The present study draws on very large cohorts of individuals with major depression, defined by a validated algorithm, in electronic health records from two health systems. It will first apply methods developed by the investigators to identify MDD subtypes. These subtypes will then be examined in terms of predictive validity as well as interpretability by clinicians.  The study builds on a productive collaboration between a team experienced in mood disorder phenotyping and clinical investigation, analysis of large-scale longitudinal electronic health records, and development and application of innovative methods in machine learning that yield interpretable models rather than black boxes. Data-driven disease subtyping will facilitate clinically useful risk stratification as well as biological study of mood disorders. Narrative  The wide variation in symptoms of major depressive disorder complicates efforts to develop new treatments and make effective use of existing treatments. Applying machine learning methods to electronic health records will enable the identification of interpretable disease subgroups, enabling development of more targeted treatment strategies.",Data-driven subtyping in major depressive disorder,10211310,R01MH123804,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cessation of life', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Disease remission', 'Electronic Health Record', 'Endocrine System Diseases', 'Engineering', 'Equilibrium', 'Evidence based treatment', 'Functional disorder', 'Health Care Costs', 'Health system', 'Heart Diseases', 'Heterogeneity', 'Hospitals', 'Human', 'Individual', 'Inflammatory Bowel Diseases', 'Machine Learning', 'Major Depressive Disorder', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medical', 'Medicine', 'Mental Depression', 'Methods', 'Modeling', 'Mood Disorders', 'Morbidity - disease rate', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Prevalence', 'Public Health', 'Publications', 'Quality of life', 'Research Personnel', 'Selection for Treatments', 'Series', 'Subgroup', 'Suicide', 'Supervision', 'Symptoms', 'System', 'Therapeutic', 'Variant', 'Work', 'base', 'biomarker identification', 'clinical investigation', 'clinical subtypes', 'cohort', 'depressive symptoms', 'disorder subtype', 'experience', 'ineffective therapies', 'innovation', 'machine learning method', 'mortality', 'mortality risk', 'novel therapeutics', 'patient subsets', 'phenomenological models', 'precision medicine', 'risk stratification', 'standard care', 'success', 'targeted treatment', 'therapy resistant', 'treatment response', 'treatment strategy']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,832192
"Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA) Neonatal hypoxic-ischemic encephalopathy (HIE) is a neurologic syndrome that results from reduced flow of oxygenated blood to the fetal or newborn brain. HIE occurs in 1-3 per 1,000 term births and may cause death or neurologic disabilities such as cerebral palsy. Electronic fetal monitoring (EFM) was developed in the 1970's to assess the adequacy of fetal oxygenation as a strategy to prevent HIE, and is now standard of care. Yet clinical trials report that EFM usage has not reduced the rate of CP, perinatal death or HIE, but is associated with a dramatic increase in cesarean deliveries. The currently used 3 Category fetal heart rate (FHR) classification system, based on simple rules designed to be easy to apply at the bedside, has some utility in predicting HIE. However, Category II FHR patterns that make up the vast majority of tracings are poorly predictive of HIE and confer “indeterminate” risk. Category III patterns are also of limited use in predicting HIE due to low sensitivity. There is an urgent need to develop better objective methods to assess EFM that would identify more fetuses at risk of HIE in time for corrective actions. Uterine tachysystole, or excessive frequency of uterine contractions, has been implicated as a preventable cause of HIE; yet studies report conflicting results. EFM research has been limited by an inability to access and manually analyze the large datasets needed to study HIE. We now have the ability to analyze digital EFM signals using automated methods to measure standard FHR patterns as well as to discover novel aspects of the tracing that may not be readily detectable by a clinician at the bedside. We hypothesize that modern signal processing and machine learning techniques can create highly predictive models of HIE by analyzing established and novel features of EFM tracings, in combination with demographic and pertinent clinical information from the mother and fetus. We propose a population-based retrospective cohort study of 350,000 infants born at ≥ 36 weeks gestation at Kaiser Permanente Northern California in 2010-19. Our specific aims are: 1) To create the MAESTRA Cohort dataset that links EFM recordings to HIE and neonatal acidosis among 350,000 infants born at ≥ 36 weeks gestation in 2010-19 at Kaiser Permanente Northern CA; 2) Using modern signal processing and machine learning techniques, to extract established and novel FHR and uterine contractility features from the EFM recordings, and to determine which of these features are most predictive of HIE and acidosis when combined with maternal and fetal clinical data; and 3) To perform external validation by applying the final predictive models to a historical dataset. We anticipate that machine learning techniques incorporating novel FHR and uterine contractility patterns over time, as well as pre- and perinatal clinical characteristics, will improve the predictive value of the EFM data that are already being collected as part of routine care. Our results will inform future clinical trials. Such an unprecedented large-scale multidisciplinary study will lead to improvements in our ability to use EFM data to prevent neonatal brain injury while minimizing unnecessary cesarean sections. MAESTRA Project Narrative Hypoxic-ischemic encephalopathy (HIE) occurs when a baby gets reduced oxygen and blood flow to the brain, and can lead to death or long-term disabilities such as cerebral palsy. During labor and delivery, doctors are able to continuously record the heart rate of the fetus. This study will determine how best to use the heart rate information so that we can reduce the number of infants who develop this severe brain condition.",Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA),10145055,R01HD099216,"['Acidosis', 'Address', 'Apgar Score', 'Asphyxia', 'Blood', 'Blood flow', 'Brain', 'California', 'Categories', 'Cause of Death', 'Cerebral Palsy', 'Cesarean section', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Computerized Medical Record', 'Conflict (Psychology)', 'Data', 'Data Set', 'Discipline of obstetrics', 'Educational workshop', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Frequencies', 'Future', 'Heart Rate', 'Infant', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Metabolic Brain Diseases', 'Metabolic acidosis', 'Methods', 'Modeling', 'Modernization', 'Mothers', 'National Institute of Child Health and Human Development', 'Neonatal', 'Neonatal Brain Injury', 'Neurologic', 'Newborn Infant', 'Observational Study', 'Outcome', 'Oxygen', 'Pattern', 'Perinatal', 'Perinatal anoxic ischemic brain injury', 'Perinatal mortality demographics', 'Population', 'Positioning Attribute', 'Predictive Value', 'Pregnancy', 'Preventive Intervention', 'Records', 'Reporting', 'Research', 'Retrospective cohort study', 'Risk', 'Seizures', 'Sensitivity and Specificity', 'Signal Transduction', 'Syndrome', 'System', 'Techniques', 'Term Birth', 'Testing', 'Time', 'Uterine Contraction', 'Uterus', 'Validation', 'base', 'cohort', 'computerized', 'design', 'digital', 'disability', 'effectiveness evaluation', 'falls', 'fetal', 'fetus at risk', 'high risk', 'improved', 'large datasets', 'multidisciplinary', 'neonatal hypoxic-ischemic brain injury', 'novel', 'population based', 'predictive modeling', 'prevent', 'routine care', 'signal processing', 'standard measure', 'standard of care', 'uterine contractility']",NICHD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,566881
"COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS COPD SUBTYPING AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS ABSTRACT One of the main obstacles in developing efficient personalized therapeutic and disease management strategies is that most common diseases are typically defined based on symptoms and clinical measurements, although they are believed to be syndromes, consisting of multiple subtypes with variable etiology. Identifying disease subtypes has thus become very important, but so far it has been met with limited success for most diseases. In asthma, a notable exception, it was the clinical characterization that led to successful subtyping; and this is now incorporated in treatment guidelines. Unsupervised machine learning approaches of single data modalities (e.g., omics, radiographic images) have not produced actionable subtypes due to instability across cohorts. Developing data integrative approaches for multi-scale data, which are becoming available for a number of diseases, is expected to lead to robust subtyping and provide mechanistic insights of disease onset and progression. This proposal focuses on developing new computational methods, based on probabilistic graphical models (PGMs), to address this unmet need; and apply them to investigate three problems of clinical importance in chronic obstructive pulmonary disease (COPD), which is the fourth leading cause of mortality in USA. Our underlying hypothesis is that PGMs can integrate and analyze under the same probabilistic framework heterogeneous biomedical data (omics, chest CT scan, clinical) and identify disease subtypes and their main determinants. The objectives of our proposal is to build a comprehensive computational framework for disease subclassification, identify stable COPD subtypes at the baseline and longitudinally, and build interpretable models of the disease The deliverables of this project are: (1) new integrative computational approaches for clinical subtyping from multi-scale data; (2) new predictors of COPD progression and severity; (3) new discoveries of longitudinally stable COPD subtypes; (4) new predictors of future development of COPD; (5) new omics datasets that will be invaluable to future research in the area (baseline and longitudinal). To ensure the success of the project we follow a team science approach. This multi-PI proposal builds on the ongoing efforts of our group in the area of graphical models and their applications in biomedicine; and the ongoing collaboration of the three PIs that have complementary strengths: Prof. Benos (systems medicine and machine learning), Dr. Hersh (COPD genetics and genomics) and Dr. Sciurba (clinical aspects of COPD). It is powered by the access of the investigators to three major COPD cohorts (COPDGene®, SCCOR, ECLIPSE) that contain multiple parallel deep phenotyping and omics data from thousands of patients and controls. Although in this project we focus on COPD, our methods are generally applicable to any disease, therefore our project will have a positive impact beyond the above deliverables. We believe that due to their robust nature and interpretability, PGMs will soon become the norm for multi-scale biomedical data integration and modeling, when genetic and genomic data collection will become routine prognostic and diagnostic tools in clinical practice. PROJECT NARRATIVE Understanding the etiology of complex diseases and categorizing patients from samples taken from easily accessible tissues (like blood) are two very important aspects that will lead to development of new precision medicine strategies. In this proposal, we plan to develop new computational methods and tools that will allow researchers to identify subphenotypes in any disease. We will apply these methods on three cohorts with thousands of patients with chronic obstructive pulmonary disease (COPD) and our results are expected to help us understand the complexities of this disease and build predictors of future development.",COPD SUBTYPES AND EARLY PREDICTION USING INTEGRATIVE PROBABILISTIC GRAPHICAL MODELS,10206417,R01HL157879,"['Address', 'Algorithms', 'Area', 'Asthma', 'Biology', 'Blood', 'Cause of Death', 'Characteristics', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Disease Management', 'Disease Progression', 'Disease model', 'Enrollment', 'Ensure', 'Etiology', 'Functional Imaging', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Profiling', 'Genes', 'Genetic', 'Genetic Diseases', 'Genomics', 'Graph', 'Health Care Costs', 'Image', 'Incidence', 'Individual', 'Lead', 'Link', 'Machine Learning', 'Measurement', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Target', 'Multiomic Data', 'Nature', 'Onset of illness', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Pulmonary function tests', 'Pulmonology', 'Research', 'Research Personnel', 'Sampling', 'Science', 'Severities', 'Severity of illness', 'Stable Disease', 'Symptoms', 'Syndrome', 'System', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Visit', 'X-Ray Computed Tomography', 'airway obstruction', 'analytical method', 'base', 'cellular targeting', 'chest computed tomography', 'clinical practice', 'clinical subtypes', 'clinically relevant', 'cohort', 'computer framework', 'computerized tools', 'data integration', 'data modeling', 'disability', 'disease phenotype', 'disorder subtype', 'follow-up', 'genetic variant', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'insight', 'learning algorithm', 'mortality', 'mortality risk', 'multimodal data', 'multimodality', 'multiscale data', 'peripheral blood', 'personalized predictions', 'personalized therapeutic', 'precision medicine', 'predictive modeling', 'prognostic', 'prognostic value', 'pulmonary function', 'success', 'tool', 'treatment guidelines', 'unsupervised learning', 'vector']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,739755
"Longitudinal neuroimaging and neurocognitive assessment of risk and protective factors across the schizophrenia spectrum PROJECT SUMMARY Schizotypal personality disorder (SPD) is similar to schizophrenia (SZ), but with fewer and attenuated abnormalities, thus representing an important yet understudied intermediate SZ-spectrum phenotype. Examination of abnormalities in SPD will provide information regarding etiology, genetics, treatment and risk factors associated with psychosis. Although individuals with SPD demonstrate marked temporal lobe abnormalities that resemble SZ, we hypothesize that relative “sparing” or “functional enhancement” in the frontal lobes (e.g., dorsolateral prefrontal cortex), may protect these individuals from frank psychosis and the severe social and cognitive deficits typically observed in SZ. Studying SPD is powerful as antipsychotic medication and hospitalization confounds observed in SZ are not present. Moreover, there is no study examining neurobiological changes in the SZ-spectrum that incorporates individuals with SPD using a longitudinal design as proposed here. This novel approach will help disentangle potential risk and protective factors for psychosis in the SZ spectrum. This is the first longitudinal study to utilize multimodal MR imaging and Research Domain Criteria (RDoC) approaches in SZ-spectrum disorders to identify aberrant neural circuitry along a continuum from healthy controls (HCs) to SPD to SZ and examine changes in these measures in relationship to impairments in symptom severity, neurocognition and functional outcome. We propose studying three groups (80 in each) of demographically matched and rigorously diagnosed individuals (age 18- 40): HCs (no Axis I or personality disorder), unmedicated individuals with SPD (and no Axis I disorder), and early-onset (first 2 years of illness) SZ patients at baseline, 9-, and 18-month follow-up. Measures assessing frontal and temporal lobe integrity include multimodal MR imaging (structural MRI, DTI, resting-state fMRI, and task-based fMRI with a nonverbal event related working-memory task; baseline and 18-months) and neuropsychological assessment (all three timepoints). We will utilize dynamic causal modeling to test competing neurobiological models involving abnormal frontotemporal connectivity in the SZ-spectrum and machine learning approaches to integrate multimodal neuroimaging, neurocognitive, and clinical assessment data. We focus on three specific aims: (1) Investigate the longitudinal course of frontal-temporal lobe/circuitry abnormalities in the SZ-spectrum using multimodal MR imaging; (2) Investigate the longitudinal course of neurocognition, clinical, and functional outcome in the SZ spectrum; (3) Determine which factor or combination of factors differentiate groups in the SZ-spectrum to identify those that are associated with risk for and protection from SZ using machine learning. PROJECT NARRATIVE Schizotypal personality disorder (SPD) is similar to schizophrenia (SZ), but with fewer and attenuated abnormalities, representing an important yet understudied intermediate SZ-spectrum phenotype that provides important information regarding etiology, genetics, treatment and risk factors associated with psychosis. This study utilizes a Research Domain Criteria (RDoC) approach coupled with longitudinal multimodal MR imaging and neurocognitive assessment in SZ-spectrum disorders to identify aberrant neural circuitry and cognition along a continuum from healthy controls to SPD (in the SZ spectrum but not fully psychotic) to SZ (psychosis). Changes in frontal-temporal regions/circuitry and neurocognitive measures over time will be examined together using novel approaches (e.g., machine learning) to predict diagnostic group, symptom severity, and functional outcome for the identification of key factors associated with risk and resilience in the SZ spectrum.",Longitudinal neuroimaging and neurocognitive assessment of risk and protective factors across the schizophrenia spectrum,10123002,R01MH121411,"['Age', 'Antipsychotic Agents', 'Attenuated', 'Brain', 'Brain region', 'Brodmann&apos', 's area', 'Clinical', 'Clinical assessments', 'Cognition', 'Cognitive deficits', 'Coupled', 'Data', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Etiology', 'Event', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Hospitalization', 'Impairment', 'Individual', 'Investigation', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Modeling', 'Neurobiology', 'Neurocognition', 'Neurocognitive', 'Neuropsychology', 'Onset of illness', 'Outcome', 'Pathogenesis', 'Patients', 'Pattern', 'Performance', 'Personality Disorders', 'Pharmaceutical Preparations', 'Phenotype', 'Prefrontal Cortex', 'Psychotic Disorders', 'Research Domain Criteria', 'Rest', 'Risk', 'Risk Assessment', 'Risk Factors', 'Scanning', 'Schizophrenia', 'Schizotypal Personality Disorder', 'Severities', 'Short-Term Memory', 'Structure', 'Symptoms', 'Temporal Lobe', 'Testing', 'Time', 'Treatment Factor', 'Ursidae Family', 'base', 'causal model', 'early onset', 'follow-up', 'frontal lobe', 'functional outcomes', 'improved', 'longitudinal course', 'longitudinal design', 'multimodality', 'neural circuit', 'neuroimaging', 'novel strategies', 'predictive modeling', 'protective factors', 'resilience', 'social deficits', 'white matter']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,796941
"A Geometric and Morphoelastic Study of Aortic Dissection Evolution Project Summary/Abstract: The natural evolution of aortic dissection is notoriously unpredictable under current methods of evaluation and management. There is an urgent need to more completely elucidate the biomechanical stability of type B aortic dissections and identify signatures in the imaging data allowing for optimal patient classification based on aortic fragility. The long-term goal is the development and validation of image-based analysis algorithms to classify aortic stability and allow a personalized risk stratification for a given patient’s aortic geometry providing the basis for optimizing clinical management. The overall objective of this proposal is to utilize modern approaches in differential geometry, continuum mechanics, and computer vision to discover and characterize high-risk geometric structures hidden within computed tomography angiography (CTA) data of fragile aortas. The central hypothesis of this application is the existence of a fundamental link between aortic shape and aortic stability as it relates to the risk of aortic dissection and fragility. The rationale for this work is development of an easily translatable geometry and mechanics-based algorithm to predict dissection stability and intervention timing by discovering a richer and more nuanced mapping of aortic shapes hidden in existing patient imaging data. The central hypothesis will be tested by pursuing three specific aims: 1) develop a modern geometric classification for aortic shapes, 2) develop a computational model that provides the mechanism underpinning the shape evolution of aortic dissections, and 3) develop a modern successor to the traditional ‘maximum diameter’ measure of aortic dissections that integrates geometric, finite element, and physiologic factors. Utilizing a large pre-identified CTA data set of normal and dissected aortas at various stages of disease and intervention, aim 1 will use tools from computer vision to reduce aortic shape to distributions of shape index and curvedness. Aim 2 will utilize advanced morphoelastic finite element growth models to discover the biomechanical mechanism underpinning aortic shape changes in aortic dissections and validate these models on patient specific geometries over clinically relevant time periods. These novel shape and mechanical stability classifiers will be used in both linear and non-linear dimensionality reduction methods to define aortic shape sub-spaces for different clinical scenarios in aim 3. This proposal is innovative as it challenges the status quo of evaluation and treatment by deploying novel measures and techniques that analyze clinically relevant aortic geometry and the evolution of aortic shape. Every patient is taken to the operating room under the full intent of having a positive clinical outcome. The research outlined is significant because it is expected to provide surgeons and patients a more discriminative framework with which to make better informed management decisions concerning type B aortic dissections and ultimately optimize outcomes. Project Narrative: The proposed research is relevant to public health because it seeks to inform upon the potential benefits of surgical versus medical intervention for type B aortic dissection through the development of modern geometric and mechanistically based selection criteria. Upon completion there will be a richer and more nuanced understanding of aortic stability as defined from computed tomography angiography imaging, which will allow for more optimal patient selection. Thus, the proposed research is relevant to the part of the NIH’s mission to enhance cardiovascular health and improve mortality.",A Geometric and Morphoelastic Study of Aortic Dissection Evolution,10280305,R01HL159205,"['Algorithmic Analysis', 'Algorithms', 'Angiography', 'Aorta', 'Behavior', 'Biomechanics', 'Caliber', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Pathways', 'Computer Models', 'Computer Vision Systems', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Dissection', 'Elasticity', 'Elements', 'Equilibrium', 'Evaluation', 'Evolution', 'Failure', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Injury', 'Intervention', 'Link', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathway interactions', 'Patient Selection', 'Patient imaging', 'Patients', 'Pattern', 'Physiological', 'Principal Component Analysis', 'Probability', 'Process', 'Public Health', 'Research', 'Risk', 'Role', 'Scanning', 'Selection Criteria', 'Shapes', 'Stress', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Walking', 'Work', 'X-Ray Computed Tomography', 'base', 'biomechanical model', 'blood pressure variability', 'cardiovascular health', 'clinically relevant', 'density', 'differential geometry', 'geometric structure', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'mortality', 'novel', 'patient population', 'preservation', 'risk stratification', 'simulation', 'surgical risk', 'tool']",NHLBI,UNIVERSITY OF CHICAGO,R01,2021,459189
"Evaluation of molecular mechanisms of treatment response in late-life depression DESCRIPTION: Over the past decades, antidepressants and psychotherapy have been the first-line treatments for LLD. Despite being safe and well-tolerated, a large number of patients do not achieve full and persistent remission after initial treatment. About 50% of patients with LLD do not respond after two antidepressant trials, meeting the consensus definition of treatment resistance (TR-LLD). The persistence of chronic and elevated depressive symptoms in older adults has significant clinical and public health implications. This has been correlated to poor general health, reduced quality of life, and a higher risk of mortality when compared to those with sustained remission after treatment. Despite the relevance to public health of TR-LLD, there is little information about the biological mechanisms and no robust clinical prediction model to evaluate at the outset of antidepressant therapy who will or will not respond to treatment. Leveraging an NIMH funded clinical trial, the Incomplete Response in Late-Life Depression: Getting to Remission” (IRL-GREY), across 3 sites, in this study, we propose to evaluate the biological mechanisms related to treatment response in late-life depression and to develop a machine learning based algorithm for prediction of treatment response in these subjects. We will carry out a comprehensive, multiplexed proteomic analysis on 542 samples from patients who completed phase 1 and phase 2 of the clinical trial. We hypothesise that ageing-related biological pathways (i.e. inflammatory response control, proteostasis control, cell damage response, endothelial function) will be associated with poorer treatment response in LLD. Moreover, we hypothesize that a machine learning derived biomarker panel will have sensitivity and specificity greater than 80% to predict treatment response in LLD. Finally, we will evaluate the biological mechanisms related to different depressive symptoms trajectories after treatment. This work will set the stage for a biologically-driven model of treatment response that will be useful to guide, at the outset of antidepressant treatment, those who will benefit more from a specific treatment. If successful, our work can accelerate therapeutic efforts and innovation targeting depression and reduce suffering for large numbers of elderly and their families. Using advanced molecular approaches, we will determine the biological mechanisms related to treatment response in late-life depression. Our proposed study will also develop a predictive tool combining neurocognitive, neuroimaging, and protein data to identify who with late-life depression is more likely to have no benefit from antidepressant treatment at the outset of therapy. The goal of the study is to clarify the mechanisms of treatment response in late-life depression, and whether we can effectively identify those who will benefit from antidepressant therapy at the outset of treatment.",Evaluation of molecular mechanisms of treatment response in late-life depression,10129431,R01MH118311,"['Address', 'Aftercare', 'Aging', 'Antidepressive Agents', 'Bioinformatics', 'Biological', 'Biological Aging', 'Biological Markers', 'Biological Process', 'Blood specimen', 'Brain', 'Cell Cycle', 'Chronic', 'Clinical', 'Clinical Trials', 'Consensus', 'Data', 'Disease remission', 'Double-Blind Method', 'Elderly', 'Endothelium', 'Evaluation', 'Family', 'Funding', 'Geroscience', 'Goals', 'Growth Factor', 'Health', 'Immune', 'Impaired cognition', 'Inflammatory', 'Inflammatory Response', 'Knowledge', 'Machine Learning', 'Mental Depression', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Neurocognitive', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Phase', 'Phase II Clinical Trials', 'Placebos', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Proteins', 'Proteomics', 'Psychotherapy', 'Public Health', 'Quality of life', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Site', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Work', 'angiogenesis', 'aripiprazole', 'base', 'biomarker panel', 'cell injury', 'cohort', 'depressive symptoms', 'design', 'endothelial dysfunction', 'geriatric depression', 'high risk', 'innovation', 'meetings', 'mortality risk', 'neuroimaging', 'new therapeutic target', 'novel', 'novel marker', 'novel strategies', 'open label', 'prediction algorithm', 'predictive modeling', 'predictive tools', 'proteostasis', 'recruit', 'response', 'therapy resistant', 'treatment response', 'treatment-resistant depression', 'venlafaxine']",NIMH,CENTRE FOR ADDICTION AND MENTAL HEALTH,R01,2021,490569
"Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises Project summary: Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems. This leads to at least 16 million cases of acute gastroenteritis directly linked to pollution at community water systems, with tens of millions more directly impacted by chemical and organic pollutants. Impacts are further exacerbated in locations dealing with water scarcity, in under-served populations, and within other vulnerable populations already suffering from health disparities. Many of these water problems are the direct result of managerial negligence, inconsistent monitoring, and a lack of the ability to anticipate where problems may arise next. While the reasons for drinking water problems are complex, if we could anticipate where health-based drinking water problems were to occur in the future, it could have an immediate and positive impact on tens of millions of Americans annually. Interestingly, extensive data about water quality and the performance of municipal water systems already exists in large, disparate databases. These databases are largely ignored and, when used, are typically used only anecdotally and retroactively. Preliminary evidence suggests that these existing databases, which contain histories of administrative violations and sub-threshold water-quality results, can be mined to accurately predict future drinking water crises. The Superior Statistical Research R&D team is an internationally recognized group of water experts with cross-cutting expertise in statistics/data analysis/modelling/computing, water-quality monitoring of biological and chemical contaminants, and the ability to clearly and compellingly translate water-quality and health information to actionable steps for individuals, organizations and communities. In this Phase I project, we will show that it is possible to predict water-related, health-based problem areas utilizing already collected, historical data on water quality and municipal water system performance. We will begin by harmonizing the disparate water quality and municipal water system performance in two different states (Michigan and Iowa). We will then utilize machine-learning techniques to predict health-based violation histories and will evaluate our methods by comparing predicted violations to actual health-based violations in the previous 5 years. Finally, we will identify at least 10 municipalities determined by our algorithm to be at the highest risk for future health- based water problems and will do systematic sampling to confirm our model-based predictions. We will then demonstrate how making these predictions can be leveraged to profitability by exploring how our model-based predictions can be presented to customers in an economical, usable form. Proof of our concept and profitability models in two states (Phase I) will set us up for widespread (multi-state) database harmonization and improvement of the proposed machine-learning/modelling effort in Phase II. With multi-state harmonized datasets, identification of key data gaps in particular states/areas, and proven financial models, our technology will ultimately lead to dramatic reductions in the number of health-based drinking water problems annually. Project Narrative Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems, but predicting where and when these health-based drinking water problems will occur remains a large and complex obstacle. Current approaches focus on a reactive approach to health-based water-quality violations in community water systems, rather than a proactive one that seeks to anticipate where problems will occur in the future. The overall goal of this project is to leverage large and disparate historical datasets of water quality to accurately predict locations of future health-based water-quality violations, validate the predictions, and commercialize our proprietary predictions as a practical and cost-saving approach to anticipating and heading off future health-based water problems.",Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises,10253600,R43ES033134,"['Acute', 'Address', 'Algorithms', 'American', 'Area', 'Biological Monitoring', 'Chemicals', 'Cities', 'Coal', 'Communities', 'Community Surveys', 'Complex', 'Cost Savings', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ensure', 'Exposure to', 'Filtration', 'Focus Groups', 'Future', 'Gastroenteritis', 'Goals', 'Government', 'Health', 'Human', 'Individual', 'International', 'Iowa', 'Lead', 'Lead levels', 'Link', 'Location', 'Machine Learning', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Municipalities', 'Negligence', 'Pathway interactions', 'Performance', 'Persons', 'Phase', 'Pollution', 'Price', 'Provider', 'Public Health', 'ROC Curve', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Sampling', 'Serinus', 'Site', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Trust', 'Underserved Population', 'Vulnerable Populations', 'Water', 'advocacy organizations', 'base', 'commercialization', 'data harmonization', 'data integration', 'drinking water', 'economic impact', 'health disparity', 'high risk', 'improved', 'inner city', 'innovation', 'large scale data', 'member', 'pollutant', 'predictive modeling', 'research and development', 'rural area', 'statistics', 'water quality', 'water sampling', 'water testing', 'willingness to pay']",NIEHS,"SUPERIOR STATISTICAL RESEARCH, LLC",R43,2021,256579
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,10087504,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomarker performance', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'multidimensional data', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'secondary analysis', 'skills', 'social', 'substance use treatment', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2021,158923
"Understanding the role of the Complement Proteome in progressive Diabetic Kidney Disease PROJECT SUMMARY / ABSTRACT There is a critical need to identify novel mechanisms of diabetic kidney disease (DKD) that will provide targets for new interventions. Chronic inflammation is one plausible mechanism. Using untargeted high-throughput aptamer proteomics, our recently published study has shed new light on specific, key inflammatory drivers of DKD. This was a large prospective three-cohort study that identified a novel and extremely robust circulating signature (KRIS) associated with risk of ESRD in diabetes. Our pilot study points to the data-driven connection between circulating KRIS and urinary profiles of the Complement pathway. Our hypothesis is that the Complement involvement in the kidney is a downstream effect of the systemic inflammatory processes mediating an increased DKD risk. The overarching goal of this proposal is to provide a high-resolution view of the involvement of the Complement proteome in progressive diabetic kidney disease. Aim 1 will comprehensively evaluate the etiological role of the urinary Complement proteome in progressive DKD leading to ESRD. This evaluation will leverage a prospective two-cohort population of Joslin Kidney Study (JKS) participants with an overt DKD at baseline followed for 10 years (primary outcome – incident ESRD). Measurements will utilize an aptamer proteomic technology (SOMAscan). Aim 2 will extend generalizability of the urinary Complement proteome to earlier DKD stages. The proposed study will be conducted in participants of the Preventing Early Renal Loss (PERL) clinical trial with predominantly normal renal function at baseline followed for 3 years (primary outcome - renal slope). Aim 3 proposes to gain direct insight into the intra-renal Complement proteome by targeted and untargeted protein studies in diabetic kidney tissue (Susztaklab Biobank). This project focuses on a significant public health problem, leverages the progressiveness of the disease, employs an innovative proteomic technology and stems from strong preliminary data. Advances in this project will pinpoint missing key components of DKD etiology, thereby accelerating drug development strategies for patients with diabetes. PROJECT NARRATIVE Diabetes accounts for approximately 45% of prevalent ESRD cases in the United States, therefore new interventions to prevent or decelerate development of kidney failure are critical in order to improve the health of patients with diabetes who comprise a large sector of the US population. This study will advance our knowledge regarding the etiology of diabetic kidney complications evaluating specific components of systemic (KRIS) and local, kidney inflammation (Complement). These advances offer long-term potential for the development of new therapies that will ultimately improve clinical outcomes of patients with diabetes.",Understanding the role of the Complement Proteome in progressive Diabetic Kidney Disease,10153779,R01DK123459,"['Address', 'Biological Markers', 'CCL2 gene', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Trials', 'Cohort Studies', 'Complement', 'Complex', 'Data', 'Data Reporting', 'Development', 'Diabetes Mellitus', 'Diabetic Nephropathy', 'Disease Progression', 'End stage renal failure', 'Ethnic Origin', 'Etiology', 'Evaluation', 'Goals', 'Health', 'Histology', 'Immunoglobulin G', 'Inflammation', 'Inflammatory', 'Injury to Kidney', 'Intervention', 'Kidney', 'Kidney Failure', 'Knowledge', 'Light', 'Machine Learning', 'Measurement', 'Mediating', 'Mediation', 'Medicine', 'Nature', 'Nested Case-Control Study', 'Participant', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Phenotype', 'Pilot Projects', 'Population', 'Process', 'Progressive Disease', 'Proteins', 'Proteome', 'Proteomics', 'Public Health', 'Publishing', 'Renal function', 'Resolution', 'Risk', 'Role', 'Severity of illness', 'Signaling Protein', 'Source', 'Technology', 'Tissue Banks', 'Tissues', 'Tubular formation', 'Tumor Necrosis Factor Receptor', 'United States', 'aptamer', 'biobank', 'cohort', 'complement pathway', 'complement system', 'diabetic', 'disorder risk', 'drug development', 'follow-up', 'improved', 'indexing', 'innovation', 'insight', 'member', 'nephrogenesis', 'non-diabetic', 'novel', 'novel therapeutics', 'prevent', 'primary outcome', 'prospective', 'random forest', 'stem', 'study population', 'systemic inflammatory response', 'tool', 'transcriptomics', 'urinary']",NIDDK,JOSLIN DIABETES CENTER,R01,2021,478789
"APPLYING ERROR-CORRECTED SEQUENCING TO DETECT MINIMAL RESIDUAL IN THE AAML 1031 STUDY Abstract  Acute myeloid leukemia (AML) accounts for half of all pediatric leukemia deaths and is the leading cause of leukemia-related death in adulthood. One reason for worse outcomes is the inability to properly assess for minimal residual disease (MRD) following therapy. Unlike ALL, AML presents with multiple subclonal populations without a singular clonal surface marker, and surface markers can change during therapy. The current gold standard for AML MRD is multi-parameter flow cytometry (MPFC), which is predictive of outcomes to frequencies of 0.001, yet 30% of MPFC-MRD-negative patients still relapse. Alternatively, every AML case harbors leukemia-specific mutations that could be markers of disease, except that next-generation sequencing has high error rate of ~1%. In this proposal, we will implement a novel, validated error-corrected sequencing (ECS) strategy, developed by the Druley lab in collaboration with Illumina, to improve MRD assessment of AML subclonal heterogeneity in 990 pediatric de novo AML cases from the Children's Oncology Group AAML1031 study. We hypothesize that using a highly sensitive sequencing method will improve identification of residual AML, provide important insights on subclonal heterogeneity in pediatric AML, improve understanding of the role of germline variability and gene function on relapses or refractory disease and facilitate personalized medicine. To interrogate this hypothesis, we propose the following aims: 1. Define subclonal heterogeneity at diagnosis and end of Induction 1 (EOI1) in 990 pediatric de novo  AML patients (n=1890). By using the largest prospective study of pediatric AML that has ever been  performed, we will perform ECS on 94 genes that are the most frequently mutated genes in pediatric and  adult AML at diagnosis and EOI1 to identify patterns of mutation associated with relapsed disease, FAB  subtypes or other cytogenetic features. 2. Correlate ECS-MRD with existing EOI1 MPFC-MRD for all participants in the COG AAML1031 study.  A major question is whether the “different from normal” cell population identified as residual disease by  MPFC is actually the same population(s) identified by ECS. We will define residual disease by ECS and  compare results to MPFC status (positive/negative), actual MPFC percentages (<0.001) and the clinical  outcomes (relapse risk, disease-free survival and overall survival) of study participants. 3. Integrate germline variation and all subclonal mutations into mechanistic groups that are frequently  mutated in pediatric AML and correlate with outcomes using unbiased machine learning  algorithms. Preliminary data tells us that every patient will have multiple subclones at diagnosis and EOI1  as well as germline variants in AML-associated genes, which may be important for outcome. In this aim, we  will take these mutations into account as well as MPFC, clinical features and cytogenetics for probabilistic  risk assessment using unsupervised machine learning algorithms for improved outcome prognostication. Narrative We have developed Error-Corrected Sequencing (ECS) that enables the highly accurate detection of leukemia- specific mutations in heterogeneous DNA samples to a limit of 0.0001. We will perform ECS with a panel of 94 frequently mutated genes in adult and pediatric AML in matched diagnostic and end of Induction 1 bone marrow samples from 990 pediatric de novo AML patients enrolled on the Children's Oncology Group AAML1031 protocol, which is the largest pediatric AML trial ever performed in North America. With these data, we can truly understand subclonal heterogeneity in pediatric AML, significantly improve minimal residual disease testing in pediatric AML, and integrate these data into an unbiased multivariate probability platform taking into account individual sequencing, flow cytometry, cytogenetic and clinical features to provide truly personalized cancer care.",APPLYING ERROR-CORRECTED SEQUENCING TO DETECT MINIMAL RESIDUAL IN THE AAML 1031 STUDY,10063814,R01CA211711,"['Acute Myelocytic Leukemia', 'Adult', 'Adult Acute Myeloblastic Leukemia', 'Alleles', 'BAY 54-9085', 'Biological Markers', 'Bone Marrow', 'Bortezomib', 'Categories', 'Cessation of life', 'Childhood', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Cytogenetics', 'DNA', 'DNA Sequence Alteration', 'DNA sequencing', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Marker', 'Disease-Free Survival', 'Enrollment', 'Epigenetic Process', 'Exons', 'FLT3 gene', 'Family', 'Flow Cytometry', 'Frequencies', 'Future', 'Genes', 'Genetic', 'Goals', 'Gold', 'Hematology', 'Immunophenotyping', 'Individual', 'Investigation', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Mutate', 'Mutation', 'Normal Cell', 'North America', 'Oncogenes', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Pediatric Oncology Group', 'Phase', 'Point Mutation', 'Population', 'Probability', 'Prospective Studies', 'Protein Tyrosine Kinase', 'Protein phosphatase', 'Protocols documentation', 'Reagent', 'Recurrent disease', 'Refractory Disease', 'Relapse', 'Residual Neoplasm', 'Residual Tumors', 'Residual state', 'Resolution', 'Risk', 'Risk Assessment', 'Role', 'Sampling', 'Site', 'Spliceosomes', 'Surface', 'Testing', 'Time', 'Treatment Efficacy', 'Tumor Suppressor Proteins', 'United States National Institutes of Health', 'Variant', 'analytical method', 'base', 'chemotherapy', 'cohesion', 'design', 'detection limit', 'digital', 'falls', 'functional group', 'gene function', 'improved', 'improved outcome', 'insight', 'leukemia', 'leukemia treatment', 'machine learning algorithm', 'next generation', 'next generation sequencing', 'novel', 'nucleocytoplasmic transport', 'outcome prediction', 'pediatric patients', 'personalized cancer care', 'personalized medicine', 'prognostic', 'prospective', 'randomized trial', 'relapse risk', 'response', 'risk stratification', 'specific biomarkers', 'subclonal heterogeneity', 'transcription factor', 'unsupervised learning']",NCI,WASHINGTON UNIVERSITY,R01,2021,352587
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Experimentally guided modeling and simulation for cholera dynamics Project Summary/Abstract Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), remains a global pandemic at present. Quantitative research is urgently needed to clarify the impacts of the current vaccination campaign on the pandemic evolution and economic growth, and to guide future policy development. The overall objective of this proposal is to establish a new computational modeling framework for an investigation of the COVID-19 vaccination campaign in the US, and to incorporate real data to assess the impacts of COVID-19 vaccination on public health and the economy. To achieve this objective, the team will pursue three specific aims: (1) Modeling the transmission and spread of COVID-19 under the impact of vaccination; (2) Modeling the economic impact of COVID-19 vaccination; (3) Conducting a case study for the Chattanooga region in the state of Tennessee. The proposed research is significant because it will incorporate detailed characteristics and potential limitations of the current vaccination campaign (such as the vaccine efficacy, phased allocation schemes, public resistance to vaccination, and vaccine breakthrough due to new variants of SARS- CoV-2) into a sophisticated modeling framework, which will enable us to make more accurate forecasts on the progression and long-term evolution of the pandemic. As such, the project is expected to advance the current understanding of COVID-19 transmission and to quantify the interaction between epidemic spreading, economic growth, and disease prevention and intervention under the impact of COVID-19 vaccination, all of which are important for the control and management of the pandemic. The approach is innovative in the development of a computational framework that integrates novel mechanistic and machine learning models and that connects the epidemic and economic aspects of COVID-19. The innovation of this project is also reflected by the integration of sophisticated computational modeling, rigorous mathematical analysis, intensive numerical simulation, and detailed data validation. The project represents an interdisciplinary collaboration among an applied and computational mathematician with long-term interest in infectious disease modeling (Wang), an epidemiologist with extensive working experiences at CDC and a current member of the regional COVID-19 task force (Heath), a business and management professor with a background in public heath (Mullen), and a statistician with expertise in machine learning and biomedical data analytics (Ma). The success of this project will not only build a solid knowledge base for the complex transmission dynamics of SARS-CoV-2 and the health and economic impacts of COVID-19 vaccination, but also provide important guidelines for the government agencies and public health administrations in pandemic management and policy development. Project Narrative The proposed project is relevant to public health because a deep understanding of the COVID-19 vaccination campaign and its health and economic impacts will help to inform the pandemic management and improve the current practice in disease prevention and intervention. The mathematical and machine learning models developed in this project will improve such understanding and make new knowledge discovery. This research effort aligns with part of NIH's mission to reduce public health burdens of infectious diseases.",Experimentally guided modeling and simulation for cholera dynamics,10376956,R15GM131315,"['2019-nCoV', 'Address', 'Advisory Committees', 'Attention', 'Businesses', 'COVID-19', 'COVID-19 vaccination', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Cholera', 'Clinical Research', 'Collaborations', 'Communicable Diseases', 'Complement', 'Complex', 'Computer Models', 'Computer Simulation', 'Country', 'County', 'Coupled', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Differential Equation', 'Economic Factors', 'Economic Models', 'Economics', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evolution', 'Foundations', 'Future', 'Goals', 'Government Agencies', 'Growth', 'Guidelines', 'Health', 'Investigation', 'Joints', 'Knowledge Discovery', 'Machine Learning', 'Mathematics', 'Mission', 'Modeling', 'Persons', 'Phase', 'Policy Developments', 'Preventive Intervention', 'Public Health', 'Public Health Administration', 'Research', 'Resistance', 'Route', 'SARS-CoV-2 transmission', 'SARS-CoV-2 variant', 'Scheme', 'Schools', 'Science', 'Solid', 'Techniques', 'Tennessee', 'Theoretical Studies', 'Unemployment', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'computer framework', 'disorder prevention', 'dynamic system', 'economic impact', 'economic indicator', 'experience', 'experimental study', 'health economics', 'improved', 'infectious disease model', 'innovation', 'interdisciplinary collaboration', 'interest', 'knowledge base', 'mathematical analysis', 'mathematical learning', 'mathematical model', 'member', 'models and simulation', 'novel', 'pandemic disease', 'professor', 'programs', 'simulation', 'success', 'transmission process', 'vaccine efficacy']",NIGMS,UNIVERSITY OF TENNESSEE CHATTANOOGA,R15,2021,122580
"Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support,10393815,R01GM109718,"['Communicable Diseases', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Economic Burden', 'Economics', 'Epidemic', 'Geography', 'Growth', 'Health', 'Health Personnel', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Methodology', 'Methods', 'Modeling', 'Policy Maker', 'Population', 'Privatization', 'Public Health', 'Resource Allocation', 'Resources', 'Risk', 'Science', 'Source', 'System', 'Techniques', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Work', 'base', 'data mining', 'health care delivery', 'improved', 'novel', 'provider networks', 'statistics', 'undergraduate student']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,11253
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",10139101,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'diverse data', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multidimensional data', 'multimodality', 'multiple omics', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2021,341300
