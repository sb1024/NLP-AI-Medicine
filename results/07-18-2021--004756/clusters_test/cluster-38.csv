text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Evaluating National Sepsis Policy Using the Electronic Health Record Project Summary/Abstract Sepsis is a critical illness syndrome characterized by infection leading to life-threatening organ failure. Affecting over 200,000 individuals in the United States each year, sepsis accounts for nearly half of all hospital deaths and over $20 billion in yearly US hospital costs. Despite the development and dissemination of evidence-based guidelines, most patients with sepsis do not consistently receive recommended care, resulting in preventable morbidity and mortality. Consequently, there is increasing interest in implementing health policies designed to incentivize quality improvement at the hospital level. The largest and most prominent of these policies to date is the new Centers for Medicare and Medicaid Services (CMS) quality reporting initiative, known as SEP-1. SEP-1 requires hospitals to report their compliance with a variety of evidence-based care processes, including timely antibiotic administration, timely volume resuscitation, and routine monitoring of the clinical response to therapy. SEP-1 is unique among quality measures in the CMS Inpatient Quality Reporting Program, both because it is the only measure based on a critical illness syndrome and because it is of unparalleled complexity, requiring the coordinated efforts of multiple health care providers across the acute care spectrum. As a consequence, it is essential to understand how SEP-1 has affected patient care and clinical outcomes. To address this need, we propose to comprehensively evaluate the impact of the SEP-1 measure using the electronic health record (EHR) of a large multihospital health system. An EHR-based approach will allow us to understand the impact of the policy in exceptional detail, yielding actionable data not only for policy makers seeking to refine SEP-1 but also for health systems seeking to respond to SEP-1 in a way that maximizes the potential benefits. First, we will analyze the impact of the program on sepsis recognition and documentation using natural language processing of clinical notes. Second, we will analyze the impact of the program on sepsis care processes using structured data elements such as vital signs, laboratory values, and medication administration. Third, we will evaluate the impact of the program on patient mortality, length of stay, and requirement for organ support. In all aims we will examine both overall effects and hospital-specific effects, providing an understanding of how hospitals and health systems implement quality improvement in the context of a novel reporting mandate. Together, these aims will yield important new insights into how clinicians and hospitals implement new quality reporting programs. At the same time, through a program of structured mentorship, career development, and stakeholder involvement, this project will provide the principal investigator with new skills in the use of the EHR to evaluate health care quality and the impact of system-level health policies, uniquely positioning him to lead future efforts to develop, implement, evaluate, and disseminate EHR-based performance interventions for critically ill patients. NARRATIVE Sepsis is a life-threatening response to infection and accounts for significant morbidity, mortality, and hospital costs in the United States. In this proposal, we will use data from the electronic health record of a large health system to evaluate the effects of a novel sepsis quality reporting program on sepsis recognition, treatment, and outcomes. Our findings will yield important early information on the quality reporting program’s impact, helping to guide policy makers as they seek to refine the program and yielding novel insights into strategies to improve sepsis quality in US hospitals.",Evaluating National Sepsis Policy Using the Electronic Health Record,10173872,K08HS025455,[' '],AHRQ,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K08,2021,146648
"COVID-19 disease course analysis using multi-site large-scale EHR data Project Summary/Abstract  Since its ﬁrst case reported in December 2019, the coronavirus disease-2019 (COVID-19) has caused a pan- demic in 188 countries/regions, and has precipitated an unprecedented health, economic and social crisis. In order to cope with the volatile dynamic and severity of the pandemic, it is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other variables inﬂuence them. Knowledge of the disease's transmission, symptomatology, clinical course, treatment and outcomes is rapidly evolving based on many sources. An important source for advancing this knowledge is data from electronic health records (EHR) and health information exchanges (HIE) because they can pro- vide a real-time, unvarnished view of the disease. Using large-scale, well-integrated and rich EHR data enables comprehensive proﬁling and quantiﬁcation of the COVID-19 disease course that can directly inform clinical prac- tice. The long-term goal of our research is to develop Artiﬁcial Intelligence (AI) tools to facilitate access to and analysis of clinical data. The goal of this application is to develop effective algorithms and tools to mine clinical data to categorize disease courses of COVID-19, and determine the effect of clinical and other variables asso- ciated with them. We will develop our algorithms using data from a large and comprehensive health information exchange, the Indiana Network for Patient Care (INPC), which has about 40,000 COVID-19 patients and fairly complete EHR data about them. We will evaluate the algorithms against other data sets, including EHR data from the OSU Wexner Medical Center and the National COVID Cohort Collaborative (N3C). The speciﬁc aims of this project are to (1) develop COVID-19 disease course groupings, (2) relate comorbidities and other clinical variables to the COVID-19 disease course, and (3) validate the developed algorithms on N3C data. This pro- posal is signiﬁcant because the methods developed in this project have the potential to signiﬁcantly increase our capability for computational analysis of large and rich patient data during the pandemic and beyond; the knowl- edge derived from our comprehensive proﬁling of COVID-19 courses over large, inclusive patient populations supported by rich EHR data can positively impact clinical practice; and the tools developed in this project will be released to the public as a free COVID-19 research re- source. It is innovative because our methods integrate novel methods such as patient clustering using clinical variables and disease progression trajectories, and pa- tient trajectory comparison, with established univariate and predictive analysis; our primary approach will lever- age the oldest and one of the country's largest HIEs to derive detailed and comprehensive knowledge about a large patient population; and the strong preliminary data generated by this project can help improve COVID-19 patient phenotyping, disease characterization and diagnosis. Project Narrative  The coronavirus disease-2019 (COVID-19) has caused a pandemic in 188 countries/regions, and has pre- cipitated an unprecedented health, economic and social crisis. It is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other vari- ables inﬂuence them. This project will use large-scale, comprehensive EHR data from the Indiana Network for Patient Care (INPC), the Ohio State University Wexner Medical Center (OSUWMC) and National COVID Cohort Collaborative (N3C) to develop effective algorithms and tools to accomplish this goal.",COVID-19 disease course analysis using multi-site large-scale EHR data,10196001,R21LM013678,"['Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'COVID-19', 'COVID-19 pandemic', 'COVID-19 patient', 'Cardiovascular Diseases', 'Caring', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Chills', 'Clinical', 'Clinical Course of Disease', 'Clinical Data', 'Cluster Analysis', 'Communicable Diseases', 'Computer Analysis', 'Coronavirus', 'Coughing', 'Country', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Diabetes Mellitus', 'Diagnosis', 'Disadvantaged', 'Disease', 'Disease Management', 'Disease Progression', 'Dyspnea', 'Electronic Health Record', 'Fever', 'Functional disorder', 'Geographic Locations', 'Goals', 'Grouping', 'Guidelines', 'Headache', 'Health', 'Hypoxia', 'Image', 'Indiana', 'Interdisciplinary Study', 'Kidney Diseases', 'Knowledge', 'Lung', 'Medical center', 'Methods', 'Modeling', 'Myalgia', 'Ohio', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Physicians', 'Play', 'Pneumonia', 'Postdoctoral Fellow', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Respiratory Failure', 'Role', 'SARS-CoV-2 infection', 'Salvelinus', 'Severities', 'Severity of illness', 'Shock', 'Shortness of Breath', 'Signs and Symptoms', 'Site', 'Smell Perception', 'Source', 'Symptoms', 'System', 'Taste Perception', 'Time', 'Treatment outcome', 'Universities', 'Work', 'base', 'clinical effect', 'clinical practice', 'cohort', 'comorbidity', 'coronavirus disease', 'disease transmission', 'electronic data', 'health economics', 'improved', 'innovation', 'novel', 'pandemic disease', 'patient population', 'respiratory', 'response', 'social', 'symptomatology', 'tool']",NLM,OHIO STATE UNIVERSITY,R21,2021,229308
"Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics PROJECT SUMMARY The widespread adoption of EHRs has enabled the collection of massive amounts of digital ophthalmic data which have great potential for secondary use in research, quality improvement, and clinical decision support. While the amount of digital ophthalmic data recorded in the EHR is substantial and could be analyzed using the latest techniques for big data, questions about the quality of the data are a barrier to its reuse. Now that the American Academy of Ophthalmology has aggregated digital ophthalmic data from the EHR into the IRIS Registry, data quality is even more imperative for reaching the potential of the registry. To date, there has not be a comprehensive evaluation of the data quality of digital ophthalmic data, nor have there been any solutions for improving its quality. These are important gaps that will limit the utility of EHR data as a tool for knowledge discovery in ophthalmology. The goal of this grant is to assess the quality of digital ophthalmic exam data in order to improve its ability to be reused for research. Our hypothesis is that studying the variability of data quality in large datasets will provide insights into improving its quality. The first aim employs an established framework for data quality analysis to assess the intrinsic quality of a single institution’s EHR data as well as its fitness for use--the ability to be applied to a particular research scenario. In this proposal, we are evaluating the data’s ability to identify patient cohorts for clinical trials and to accurately calculate outcome based clinical quality measures. The variability in data’s quality and fitness among providers, subspecialties, diagnoses, and visit types will be analyzed. The second aim validates the analysis of the first aim by repeating it for all of the ophthalmic data in the IRIS Registry. For this analysis, the differences in quality and fitness between institutions and EHR vendors will also be assessed, along with the barriers to data quality and reuse. For both aims, ophthalmology experts will review the results to make recommendations for improving data quality and utility for digital ophthalmic data. In the future, these recommendations will provide a direction for correcting these quality issues and for ultimately advancing knowledge discovery in ophthalmic care. PROJECT NARRATIVE Electronic health records (EHRs) have not yet reached their potential for transforming healthcare, particularly for reusing clinical data for research. The American Academy of Ophthalmology has aggregated ophthalmic data from the EHR into the IRIS Registry, and data quality is even more imperative to achieve to reach the potential of this registry. Using methodological data quality analysis, we will analyze the quality of a single institution’s ophthalmic data and again for multiple institutions’ ophthalmic data in the IRIS Registry, documenting barriers for data quality and reuse that will lead to improving knowledge discovery from this data.",Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics,10149327,R21LM013937,"['Academy', 'Adoption', 'Age related macular degeneration', 'American', 'Big Data', 'Big Data Methods', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Collection', 'Complex', 'Data', 'Data Discovery', 'Data Store', 'Diabetic Retinopathy', 'Diagnosis', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Exfoliation Syndrome', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Hand', 'Health Sciences', 'Healthcare', 'Human', 'Image', 'Individual', 'Informatics', 'Institutes', 'Institution', 'Intelligence', 'Iris', 'Knowledge Discovery', 'Manuals', 'Measurement', 'Measures', 'Medical Informatics', 'Medicine', 'Methodology', 'Methods', 'Ophthalmology', 'Oregon', 'Outcome', 'Patients', 'Process', 'Provider', 'Recommendation', 'Registries', 'Research', 'Research Personnel', 'Retinopathy of Prematurity', 'Secondary to', 'Source', 'Structure', 'System', 'Techniques', 'Terminology', 'Treatment outcome', 'Universities', 'Vendor', 'Vision', 'Visit', 'base', 'clinical decision support', 'clinical encounter', 'cohort', 'data framework', 'data harmonization', 'data quality', 'data registry', 'data reuse', 'data submission', 'deep learning', 'digital', 'electronic data', 'experience', 'fitness', 'improved', 'insight', 'large datasets', 'large scale data', 'research study', 'tool', 'treatment comparison']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,186725
"PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally. However, a vital step for EHR-based research is valid, accurate, and reliable phenotyping (i.e., correctly identifying individuals with a particular trait of interest). Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. However, each requires an extensive investment of time and resources to develop due to the heterogeneity, complexity, inaccuracy, and frequent fragmentation of EHRs. The lack of general, automatic, and portable approaches to enable accurate high- throughput phenotyping is a critical barrier that hampers our ability to leverage valuable clinical data in EHRs for better healthcare. We propose a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that we have developed from public resources and will further refine and implement across various EHRs. We recognize that mass information about phenotypes is often described in significant detail and continuedly accumulated within publicly available resources (e.g., MedlinePlus and Wikipedia). We hypothesize this information can be retrieved, filtered, organized, measured, and formalized into standard EHR phenotype profiles. Indeed, we have used such an ensemble approach to integrate four generalizable online medication resources (e.g., SIDER and RxNorm) to create MEDI--a resource linking 2,136 medications and 13,304 indications. In preliminary studies, we extended this strategy to phenotyping and created a prototype PheMAP. For each phenotype, we identified relevant clinical concepts and weighted each based on its importance to the phenotype. We then mapped all associated concepts to commonly-used clinical terminologies. Our preliminary studies showed an average consistency of 98.6%±0.8% between our early-stage PheMAP and three validated eMERGE algorithms (Type 2 Diabetes, dementia, and hypothyroidism). We seek support to refine and optimize PheMAP and develop tools to allow researchers to implement PheMAP efficiently in different EHRs. This will allow researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention. Since PheMAP is created using independent resources that are more generalizable than a local clinical dataset, the implementation will generate more consistent outcomes in different EHRs for large-scale analyses.The work we propose is a necessary step toward being able to conduct high-throughput genome-wide and phenome-wide association analyses (GWASs and PheWASs). We will use data from multiple biobanks to accomplish these tasks. Specifically, we will achieve the following goals in this grant: 1.refine PheMAP and conduct large-scale validation, 2. implement PheMAP and perform representative GWASs and PheWASs, 3. Use PheMAP to conduct GWASs for unstudied or understudied diseases and phenotypes, and 4. Share PheMAP to facilitate research using EHRs. Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally while a vital step for EHR-based research is valid, accurate, and reliable phenotyping. Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. We propose to refine, validate, and share a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that allows researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention.","PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping",10095131,R01GM139891,"['Algorithms', 'Benchmarking', 'Biological', 'Catalogs', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Dementia', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Environment', 'Evaluation', 'Genes', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Heritability', 'Heterogeneity', 'Human', 'Hypothyroidism', 'Individual', 'Institution', 'Intervention', 'Investments', 'Knowledge', 'Left', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical center', 'MedlinePlus', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Sensorineural Hearing Loss', 'Signal Transduction', 'Site', 'Statistical Models', 'Terminology', 'Time', 'Validation', 'Work', 'base', 'biobank', 'biomedical ontology', 'clinically relevant', 'cost', 'data modeling', 'disease phenotype', 'experience', 'genome wide association study', 'genome-wide', 'implementation tool', 'interest', 'novel', 'off-label drug', 'off-label use', 'phenome', 'phenotyping algorithm', 'portability', 'prototype', 'tool', 'trait']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,432500
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10136739,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2021,496453
"Extended Methods and Software Development for Health NLP Project Summary Our program vision is to unravel the information buried in health-related narratives by advancing text-processing methods in a unified way across all the genres of health texts and distributing them through an advanced NLP software platform under solid governance and sustainability. The crosscutting theme is the investigation of methods for health NLP made possible by big data, fused with health knowledge. The underlying theme of this renewal is the development of methods towards generalizable, efficient and knowledge-rich models in the context of modern machine learning techniques, particularly models implementing attention mechanisms and using large unlabeled datasets. There is growing penetration of deep learning approaches in the field of health natural language processing. Our proposal aims to address critical methodological gaps and understudied areas in the current unprecedented fast-paced environment. Therefore, our renewal lays out novel and much needed explorations of health NLP research which we will advance through our specific aims. Our datasets will continue to span the spectrum of health-related data – Electronic Medical Records clinical narrative, patient-authored on- line community posts, and health-related social media. The evaluation of the methods we will develop will be performed on the key clinical tasks of concept extraction, relation extraction, and phenotyping with comparisons to other traditional or deep learning algorithms as baselines. We will demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine. Finally, we will disseminate our work through community activities to advance the state of the art in health natural language processing. Project Narrative There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,10209178,R01GM114355,"['Address', 'Adult', 'Algorithms', 'Apache', 'Area', 'Attention', 'Big Data', 'Childhood', 'Clinical', 'Communities', 'Community Health', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Set', 'Detection', 'Development', 'Environment', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Health', 'Healthcare', 'Information Retrieval', 'Institution', 'Investigation', 'Joints', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Ontology', 'Patients', 'Penetration', 'Personal Satisfaction', 'Phenotype', 'Physicians', 'Public Health', 'Publications', 'Research', 'Risk', 'Solid', 'Source', 'Supervision', 'System', 'Techniques', 'Text', 'Time', 'Training', 'Training and Infrastructure', 'Uncertainty', 'Unified Medical Language System', 'Vision', 'Work', 'commercialization', 'data streams', 'deep learning', 'deep learning algorithm', 'design', 'electronic data', 'health data', 'health knowledge', 'insight', 'learning strategy', 'medical specialties', 'method development', 'multitask', 'neural network', 'novel', 'online community', 'open source', 'point of care', 'precision medicine', 'programs', 'social media', 'software development', 'structured data', 'tool', 'translational medicine']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2021,463346
"Personalized Predictions for Glaucoma Progression Using Artificial Intelligence for Electronic Health Records Project Summary/Abstract: Glaucoma is the leading cause of irreversible blindness, affecting over 60 million people worldwide. Glaucoma patients vary widely in their presentation, with some retaining long-term disease stability, and others progressing quickly to vision loss. If glaucoma patients at highest risk of progression could be identified early, clinicians could better personalize their treatment approaches. Many clinical factors that affect glaucoma progression, such as intraocular pressure, treatment history, and medication adherence, are documented within the free-text notes of the electronic health records (EHR) and are not in large-scale administrative claims databases. Recent advances in artificial intelligence (AI) and natural language processing (NLP) have enabled the integration of the rich and complex EHR data into highly accurate predictive algorithms for health outcomes in medicine and surgery. We hypothesize that we can extend these AI and NLP techniques to build predictive algorithms for glaucoma progression that outperform traditional models reliant on only administrative features. The goal of this project is to build and evaluate predictive algorithms for glaucoma progression using large-scale EHR data, while developing Dr Wang's expertise in AI and NLP, advancing her career as an independent clinician scientist. Aim 1 focuses on using the structured clinical data within the EHR, which are numeric or coded and readily machine-readable, to build baseline machine learning models predicting glaucoma progression requiring surgery. Aim 2 focuses on using and augmenting clinical named entity recognition tools to integrate information from EHR free text into AI models predicting glaucoma progression to surgery. Aim 3 focuses on understanding, explaining, and evaluating the performance of AI algorithms in a real-world prospective setting, by evaluating their performance on key subpopulations, their reliance on key features, and investigating potential areas of bias in a new cohort of glaucoma patients. This proposal is innovative in developing AI-based predictive algorithms for glaucoma progression using numeric and textual clinical data uniquely available in the EHR. The tools and methods Dr Wang will build and evaluate will substantially impact the ophthalmology field by enabling evidence-based tailoring of treatment approaches to patients' unique clinical characteristics, a step towards precision medicine. Furthermore, the careful evaluation of AI predictive algorithms on a new cohort of patients will provide insights into their performance on key subpopulations and reliance on key features, which is critical to advancing our understanding of possible limitations of deploying AI in the clinical workflow. Dr. Wang's career and research will advance under the primary mentorship of Dr. Tina Hernandez-Boussard, a national leader in informatics and expert in using NLP on EHR to improve patient care. Her outstanding Advisory Committee, including clinician-investigators Drs. Pershing, Stein, Chang, and Goldberg, will ensure Dr. Wang's success in becoming an independent clinician-investigator integrating ophthalmology and informatics. Project Narrative/Public Health Statement: This project is relevant to public health in focusing on developing and evaluating predictive algorithms for glaucoma progression, which are necessary to tailor treatment approaches to individual glaucoma patients' needs and achieve optimal treatment outcomes to prevent blindness. The powerful artificial intelligence techniques we will develop and use for large-scale data from electronic health records can be extended to include a wide variety of data sources and shared with the research and clinical community to answer ophthalmic questions in many domains. In supporting personalized medicine for glaucoma patients to improve ophthalmic outcomes, the proposed research is relevant to the NEI's mission to protect and prolong vision.",Personalized Predictions for Glaucoma Progression Using Artificial Intelligence for Electronic Health Records,10191911,K23EY032635,"['Adherence', 'Advisory Committees', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Blindness', 'Calibration', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Complex', 'Computers', 'Data', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Future', 'Glaucoma', 'Goals', 'Health', 'Image', 'Individual', 'Informatics', 'Intervention', 'Machine Learning', 'Measurement', 'Medicine', 'Mentorship', 'Methods', 'Mission', 'Modeling', 'Names', 'Natural Language Processing', 'Operative Surgical Procedures', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Physiologic Intraocular Pressure', 'Process', 'Public Health', 'Readability', 'Recording of previous events', 'Registries', 'Research', 'Research Personnel', 'Scientist', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Translating', 'Treatment outcome', 'Variant', 'Vertebral column', 'Veterans Health Administration', 'Vision', 'Work', 'base', 'biomedical informatics', 'career', 'clinical data warehouse', 'clinically relevant', 'cohort', 'data sharing', 'demographics', 'evidence base', 'high risk', 'improved', 'individualized medicine', 'innovation', 'insight', 'intelligent algorithm', 'large scale data', 'medication compliance', 'optimal treatments', 'personalized medicine', 'personalized predictions', 'precision medicine', 'prediction algorithm', 'predictive modeling', 'prevent', 'prospective', 'structured data', 'success', 'support tools', 'tool']",NEI,STANFORD UNIVERSITY,K23,2021,254159
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,10144364,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,805312
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000
"Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease PROJECT SUMMARY Kidney stones are highly prevalent and recurrent. Our current understanding of kidney stone disease risk factors and disease associations has relied primarily on data from chart review, nonspecific administrative datasets, and secondary analyses of observation studies. Current study designs suffer from small sample sizes, heterogenous patient groups, and lack of standardized accuracy data and outcome definitions. The widespread adoption of electronic health records (EHRs) provides novel research opportunities for kidney stone disease. EHRs contain a robust clinical repository of data collected over time from clinical care. However, there are currently limited tools to identify and characterize kidney stone patients in the EHR. The objective of this study is to establish feasibility of utilizing EHR data to investigate kidney stone disease. To structure EHR data in an efficient and cost-effective manner, natural language processing and deep learning methods can be designed for identifying and phenotyping kidney stone patients and clinical outcomes. Our de-identified EHR is linked to a DNA biobank that can enable investigation of genetic associations with disease. This project has two specific aims. In Aim 1, we will perform genetic association studies in our EHR and linked DNA biobank. We will replicate previously described associations with genetic variants and kidney stone disease. We will then perform a genome-wide association study to discover novel associations. In Aim 2, our goal is to develop and validate a computable framework to extract clinical outcomes of kidney stone disease from the EHR. Clinically meaningful outcomes include symptomatic stone passage and radiographic stone characterization. We will develop and test natural language processing and deep learning algorithms to extract keywords and context-based information in clinical notes and reports. We will train and test these algorithms using manual annotation as the gold standard. This aim will enable rigorous phenotyping of each kidney stone patient using structured and unstructured EHR data. Successful completion of this project will lay the groundwork towards advancing genomic medicine and precision health to support clinical decision-making in kidney stone patients. PROJECT NARRATIVE Our overall goal is to establish the feasibility of kidney stone research using electronic health record data. Genetic association studies will be performed to replicate known and discover new variants with kidney stone disease. A computerized framework will be developed and validated to extract kidney stone patient outcomes.",Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease,10103906,R21DK127075,"['Address', 'Adoption', 'Algorithms', 'Area', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Collaborations', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Diabetes Mellitus', 'Diagnostic radiologic examination', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Emergency department visit', 'Event', 'Future', 'Genetic Variation', 'Genetic study', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hypertension', 'Investigation', 'Kidney Calculi', 'Link', 'Manuals', 'Methods', 'Mind', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phenotype', 'Precision Health', 'Radiology Specialty', 'Recurrence', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Sample Size', 'Sampling', 'Scanning', 'Standardization', 'Structure', 'Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Variant', 'Vision', 'Work', 'artificial neural network', 'base', 'biobank', 'case control', 'clinical care', 'clinical data repository', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'disorder risk', 'electronic structure', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic tools', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'novel', 'phenotypic data', 'secondary analysis', 'support tools', 'text searching', 'tool', 'treatment response', 'unstructured data', 'web site']",NIDDK,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2021,259500
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step – designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Children’s Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,10085674,R01LM012973,"['Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Information Retrieval', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'large scale data', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'phenotyping algorithm', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,366696
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,10126722,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'provider behavior', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2021,46036
"An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment Abstract The overall goal of this proposal is to combine expertise and approaches from biomedical engineering and critical care medicine to design a universal system to acquire, record and transmit physiological signals from bedside monitored patients. Patient monitors generate over a million datapoints of information per hour, however, only a tiny fraction of those data are transmitted or recorded. In order to improve data exchange in healthcare, the Fast Healthcare Interoperability Resources (FHIR) standard was published in 2014. However, it has yet to make a significant impact on Medical Device Integration (MDI), which is the process of automating the flow of clinical data from bedside medical devices, such as patient monitors, to external systems such as Electronic Medical Records (EMR). Also, MDI is a complex task because data from these devices are high-frequency and high- volume and because most devices use proprietary protocols and outdated interfaces such as serial cables. Hospitals and researchers have therefore been left with few options except to use expensive and vendor-specific MDI solutions to access these data or to use manual data entry into the patient EMR, which leads to data entry errors, late entry of data, and lost time for clinical care. Manual data entry only captures a tiny fraction of the available data, and with increased research interest in Artificial Intelligence (AI) and Machine Learning, there is a growing need for a standardized way to access the vast amounts of data from bedside devices. This project will develop a vendor-neutral software-based Medical Device Data System (MDDS) that acquires and records data from bedside devices across a hospital network and makes live data available to 3rd party systems using a FHIR application programming interface (API). The proposed proof-of-concept will consist of three elements: [i] a transmitter which encrypts and transmits patient signals across the network, [ii] an aggregator which receives, translates and records the signals to a central location, and [iii] a FHIR Server with API for allowing external systems to access live data as FHIR resources. This proposal seeks to create a novel design that will overcome a critical barrier in healthcare, medicine and research. The proposed MDDS will be valuable to hospitals, clinicians, researchers and app developers because it makes data accessible which were previously only available to clinicians at the bedside in real-time. Narrative MediCollector’s proposed vendor-neutral medical device data system (MDDS) will be a valuable research tool to access, acquire and record high-frequency bedside patient monitor data for facilitating clinical research in hospitals. In addition, it will make live patient monitor data accessible to external systems through an HL7 FHIR application programming interface (API), thereby improving interoperability in hospitals and opening the doors to the integration of live data into external systems, such as smartphone apps and artificial intelligence algorithms, which can improve clinical workflow and healthcare in general.",An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment,10353084,R43EB030890,"['Artificial Intelligence', 'Biomedical Engineering', 'Clinical', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'Computerized Medical Record', 'Critical Care', 'Data', 'Devices', 'Elements', 'Equipment', 'Fast Healthcare Interoperability Resources', 'Frequencies', 'Goals', 'Healthcare', 'Hospitals', 'Hour', 'Information Systems', 'Left', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Medicine', 'Patient Monitoring', 'Patients', 'Physiological', 'Process', 'Protocols documentation', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Standardization', 'System', 'Time', 'Translating', 'Vendor', 'application programming interface', 'base', 'clinical care', 'data access', 'data exchange', 'design', 'encryption', 'improved', 'intelligent algorithm', 'interest', 'interoperability', 'novel', 'point of care', 'smartphone Application', 'tool']",NIBIB,"MEDICOLLECTOR, LLC",R43,2021,40963
"Big Data Methods for Comprehensive Similarity based Risk Prediction Project Summary Electronic health records (EHR) provide rich source of data about representative populations and are yet to be fully utilized to enhance clinical decision-making. Conventional approaches in clinical decision-making start with the identification of relevant biomarkers based on subject-matter knowledge, followed by detailed but limited analysis using these biomarkers exclusively. As the current scientific literature indicates, many human disorders share a complex etiological basis and exhibit correlated disease progression. Therefore, it is desirable to use comprehensive patient data for patient similarity. This proposal focuses on deriving a comprehensive and integrated score of patient similarity from complete patient characteristics currently available, including but not limited to 1) demographic similarity; 2) genetic similarity; 3) clinical phenotype similarity; 4) treatment similarity; and 5) exposome similarity (here exposome defined as all available attributes of the living environment an individual is exposed to), when some of the aspects may overlap and interact. We will optimize information fusion and task-dependent feature selection for assessing patient similarity for clinical risk prediction. Since currently there does not exist a pipeline that is able to extract executable complete patient determinant data, to achieve the research goal described above, we propose first deliver an open- source data preparation pipeline that is based on a widely used clinical data standard, the OMOP (Observational Medical Outcomes Partnership) Common Data Model (CMD) version 5.2. Moreover, to mitigate common missingness and sparsity challenges in clinical data, we describe the first attempt to represent patients' sparse clinical information with missingness, including diagnosis information, medication data, treatment intervention, with a fixed-length feature vector (i.e. the Patient2Vec). This project has four specific aims. Aim 1 is to develop a clinical data processing pipeline for harmonizing patient information from multiple sources into a standards-based uniformed data representation and to evaluate its efficiency, interoperability, and accuracy. Aim 2 is to leverage a powerful machine learning technique, Document2Vec, from the natural language processing literature, to create an open-source Patient2Vec framework for the derivation of informative numerical representations of patients. Aim 3 is to develop a unified machine learning clinical- outcome-prediction framework for Optimized Patient Similarity Fusion (OptPSF) that integrates traditional medical covariates with the derived numerical patient representations from Patient2Vec (Aim 2) for improved clinical risk prediction. Aim 4 is to evaluate our similarity framework for predicting 1) the risk of end-stage kidney disease (ESKD) in general EHR patient population and 2) the risk of death among patients with chronic kidney disease (CKD). The project focus on developing a novel data science pipeline which includes a clinical data processing pipeline to format comprehensive patient health determinants from a variety of sources of clinical, genomic, socioenvironmental data, and a clinical-outcome-prediction framework that optimally fuses relevant patient health determinants to define patient similarity for improved clinical risk predictions.",Big Data Methods for Comprehensive Similarity based Risk Prediction,10087958,R01LM013061,"['Address', 'Automation', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biological Process', 'Biometry', 'Case Study', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Data', 'Data Reporting', 'Data Science', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronic Health Record', 'End stage renal failure', 'Environment', 'Etiology', 'Exhibits', 'Exposure to', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Professional', 'Healthcare', 'Heterogeneity', 'Human', 'Individual', 'Informatics', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Length', 'Life', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preparation', 'Reporting', 'Reproducibility', 'Research', 'Risk', 'Social Environment', 'Source', 'Surveys', 'Techniques', 'base', 'biomedical informatics', 'clinical decision support', 'clinical decision-making', 'clinical phenotype', 'clinical risk', 'data analysis pipeline', 'data modeling', 'data standards', 'design', 'disease diagnosis', 'feature selection', 'health data', 'improved', 'interoperability', 'mortality risk', 'novel', 'open data', 'open source', 'outcome prediction', 'patient health information', 'patient population', 'precision medicine', 'predict clinical outcome', 'risk prediction', 'socioeconomics', 'support tools', 'vector']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,455669
"Identification of Trauma-related Features in EHR Data for Patients with Psychosis and Mood Disorders Project Summary Psychotic and mood disorders represent a major driver of disability as well as health care cost. There is considerable clinical heterogeneity among patients. Developing clinically implementable machine learning (ML) tools to enable accurate patient stratification is critically important in order to augment effective personalized treatment plans. Among the factors contributing to heterogeneity, childhood trauma is an under-recognized source. The prevalence of childhood trauma is significant in adults with psychiatric disorders. Robust evidence shows that: i) individuals exposed to childhood abuse are 2-3 times more likely to develop a psychiatric disorder later in life, particularly psychosis; ii) childhood traumas impact critical windows of brain development and can trigger the onset of psychosis; and iii) among patients with psychotic and mood disorders, childhood trauma influences psychopathology, leading to more severe symptoms, poorer long-term outcomes (longer and higher rate of relapses or rehospitalization), associated with substance abuse, and are often treatment resistant and function poorly in society. Although evidence clearly indicates that childhood trauma contributes to psychiatric risk and poor treatment outcomes, large-scale computational approaches to stratify subpopulations, extract trauma features (e.g., frequency, type), and examine the links or the impact of trauma features on psychopathology and treatment outcome have yet to be developed. We propose to create gold standard annotations from Electronic health records (EHRs) and to leverage natural language processing (NLP) and ML methods to develop a standardized re-useable data model for automatically extracting trauma-related features, complex concepts, and symptom dimensions from EHRs. We will train and evaluate a semi-supervised NLP model, which is built as a joint sequence model that can both identify named entities as well as extract the relations between them. We will apply multiple strategies to validate the robustness of our model. Our proposed NLP model is essentially a “computational version of a chart review” tool, designed to mimic human chart review but performed automatically with the ability to scale. We will use this model to stratify psychosis subgroups (with or without childhood trauma history) and to correlate among the extracted features with important clinical outcome variables. Importantly, the annotation guidelines, corpus, and the data model developed by us will be valuable resources to researchers in the field. The study builds on existing collaborations between a team experienced in psychiatric phenotyping and application of EHRs, and a team active in developing and applying emerging methods in ML to natural language data. The model architecture developed in this application will lay the groundwork for a future clinical trial application. Project Narrative There is considerable clinical heterogeneity among patients with psychotic and mood disorders. This project will use electronic health record databases and machine learning approaches to automatically stratify subpopulations, to examine the impact of childhood trauma on psychopathology, and to establish a gold standard annotation guideline and a standardized re-useable data model for use by the psychiatric community. Development of a “computational version of chart review” tool will be cost-effective and allow for future large- scale clinical investigations.",Identification of Trauma-related Features in EHR Data for Patients with Psychosis and Mood Disorders,10296954,R21MH125076,"['Achievement', 'Adult', 'Architecture', 'Brain', 'Child Abuse', 'Child Sexual Abuse', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Element', 'Databases', 'Development', 'Diagnostic', 'Dimensions', 'Electronic Health Record', 'Event', 'Exposure to', 'Female', 'Frequencies', 'Future', 'Gold', 'Guidelines', 'Health Care Costs', 'Heterogeneity', 'Hospitals', 'Human', 'Individual', 'Institution', 'Joints', 'Knowledge', 'Label', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Massachusetts', 'Mediation', 'Mental disorders', 'Methods', 'Modeling', 'Mood Disorders', 'Names', 'Natural Language Processing', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Prevalence', 'Psychopathology', 'Psychotic Disorders', 'Psychotic Mood Disorders', 'Recording of previous events', 'Relapse', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Resistance', 'Resources', 'Risk', 'Societies', 'Source', 'Standardization', 'Subgroup', 'Substance abuse problem', 'Suicide', 'Supervision', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Trauma', 'Treatment outcome', 'Validation', 'base', 'clinical heterogeneity', 'clinical investigation', 'clinically significant', 'computing resources', 'cost effective', 'data modeling', 'data registry', 'data reuse', 'data standards', 'design', 'disability', 'emotional abuse', 'experience', 'hospital readmission', 'insight', 'machine learning method', 'male', 'natural language', 'new therapeutic target', 'patient health information', 'patient stratification', 'pediatric trauma', 'personalized medicine', 'physical abuse', 'repository', 'severe psychiatric disorder', 'structured data', 'therapy resistant', 'tool', 'treatment planning', 'unstructured data']",NIMH,MCLEAN HOSPITAL,R21,2021,220614
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,10139100,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2021,20000
"Evaluating and Improving Utilization of Evidence-Based Medical Therapy in Patients with Heart Failure using Automated Tools in the Electronic Health Record PROJECT SUMMARY Heart failure (HF) affects over 6 million US adults, with high rates of hospitalization and nearly 50% mortality at 5 years from diagnosis. Nearly half of these patients have systolic HF with multiple evidence-based therapeutic options proven to reduce the risk of hospitalization and mortality in this subgroup of patients. Evaluating the appropriate utilization of these therapies is currently limited to post-hoc assessments of manually abstracted patient records at a limited number of hospitals participating in quality improvement registries. These manual abstraction strategies do not offer opportunities to improve care in real-time, and even at hospitals engaged in quality improvement efforts, only 1 in 5 of eligible patients with HF receive all first-line evidence based medical treatments. In this patient-oriented mentored career development award proposal, Dr. Rohan Khera proposes to leverage the ubiquitous digitization of medical records in the electronic health record (EHR) to address the adequate utilization of evidence based medical therapy in HF. He proposes to use a large, publicly accessible, deidentified EHR database to develop and validate an algorithm that uses deep learning based natural language processing (NLP) within unstructured clinical documentation for hospitalized HF patients to identify those with systolic HF (Aim #1). He will engage clinicians to design consensus-based algorithms to identify contraindications to HF treatments, developed as algorithms within the EHR (Aim #2). Finally, he will construct a prototypic clinical decision support (CDS) tool identifying HF treatment eligibility in real-time using the algorithms and evaluate potential implementation strategies using qualitative evaluation of feedback from clinicians and patients (Aim #3). While proposed as a strategy to evaluate quality of care of individual patients, the proposed research will also model a fully automated electronic clinical quality measure for HF. The algorithms will be made open source to allow institutions to validate and apply them to their individual care setting. The proposal is supported by strong mentorship from experts in quality measure design, informatics, advanced NLP, CDS design, and qualitative research methodology. The facilities at Yale Center of Outcomes Research and Evaluation, which designs and evaluates national quality measures, and has access to computational resources required to accomplish the research goals as well as to the Yale EHR to validate the models are major strengths of the application. The proposed period of mentored research will support Dr. Khera’s training in medical informatics, advanced analytic tools such as NLP, and qualitative research methodology. The experience and skillset acquired during this period will support Dr. Khera’s transition to independence where he plans to lead multi-institutional collaboratives to evaluate the use of automated tools in the measurement and improvement of the quality of medical care in HF. The career development plan that accompanies the proposal is designed to support Dr. Khera’s long-term career goal to be a national leader in the design and implementation of informatics- based approaches of delivering high quality, patient-centered, cardiovascular care. PROJECT NARRATIVE The scope of quality improvement programs that focus on improving the utilization of first-line evidence-based medical therapies in patients with heart failure is limited by mechanisms to identify those who are eligible for specific treatments. The current proposal aims to design automated tools to identify patients eligible for heart failure therapies using various data components already captured in the electronic health record in hospitalized patients. The proposal will then pilot test strategies of improving treatment utilization with electronic alerts delivered to clinicians based on these tools.",Evaluating and Improving Utilization of Evidence-Based Medical Therapy in Patients with Heart Failure using Automated Tools in the Electronic Health Record,10214973,K23HL153775,"['Acute Renal Failure with Renal Papillary Necrosis', 'Address', 'Adrenergic beta-Antagonists', 'Adult', 'Affect', 'Algorithm Design', 'Algorithms', 'Anaphylaxis', 'Angiotensin Receptor', 'Angiotensin-Converting Enzyme Inhibitors', 'Angiotensins', 'Automated Clinical Decision Support', 'Automation', 'Bradycardia', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Clinical', 'Code', 'Consensus', 'Coughing', 'Critical Care', 'Data', 'Databases', 'Decision Making', 'Development Plans', 'Diagnosis', 'Documentation', 'Echocardiography', 'Electronic Health Record', 'Eligibility Determination', 'Ensure', 'Environment', 'Evaluation', 'Evidence based treatment', 'Feedback', 'Focus Groups', 'Functional disorder', 'Goals', 'Gold', 'Healthcare', 'Heart failure', 'Hospitalization', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intensive Care', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Left', 'Low Cardiac Output', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical History', 'Medical Informatics', 'Medical Records', 'Mentors', 'Mentorship', 'Methodology', 'Mineralocorticoid Receptor', 'Modeling', 'Natural Language Processing', 'Neprilysin', 'Outcomes Research', 'Outpatients', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Peptidyl-Dipeptidase A', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Process', 'Provider', 'Qualitative Evaluations', 'Qualitative Research', 'Quality of Care', 'Recommendation', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Risk', 'Source', 'Structure', 'Surveys', 'Systolic heart failure', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Failure', 'Validation', 'Ventricular', 'advanced analytics', 'analytical tool', 'automated algorithm', 'base', 'care delivery', 'career', 'career development', 'clinical care', 'clinical decision support', 'computing resources', 'deep learning', 'design', 'evidence base', 'experience', 'follow-up', 'health data', 'hospitalization rates', 'hyperkalemia', 'implementation strategy', 'improved', 'improved outcome', 'individual patient', 'inhibitor/antagonist', 'mortality', 'open source', 'patient oriented', 'patient subsets', 'point of care', 'programs', 'prospective', 'recruit', 'structured data', 'support tools', 'time use', 'tool']",NHLBI,YALE UNIVERSITY,K23,2021,193510
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,10091381,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,376860
"Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques Despite their adverse impact on patient quality of life and healthcare utilization and costs, symptom clusters (SCs) in common adult chronic conditions such as cancer, heart failure (HF), type 2 diabetes mellitus (T2DM), and chronic obstructive pulmonary disease (COPD) are understudied and poorly understood. The lack of access to real world, longitudinal patient symptom data sets and inability to adequately model the complexity of SCs has greatly limited research. Based on our previous work, we propose that these gaps can be addressed in an innovative way using electronic health records (EHRs) and data science techniques. Our overall objective is to develop, apply and refine, and implement an optimized data processing and analysis pipeline for the characterization of SCs in common adult chronic conditions for use with EHR data. We hypothesize that a core set of SCs is shared among all common adult chronic conditions and that distinct SCs characterize specific conditions and/or treatments. The long term training goal of this project is to assist Dr. Koleck in becoming an independent investigator conducting a program of research dedicated to mitigating symptom burden in patients with chronic conditions through use of informatics and omics (e.g., genomics and proteomics), the focus of her pre-doctoral work. Using exceptional resources available from Columbia University, the K99 phase of this project will focus on the development of a rigorous pipeline; essential competencies in SC analysis and interpretation; and the data science techniques of clinical data mining, natural language processing, machine learning, and data visualization. In the R00 phase, Dr. Koleck will independently implement the pipeline in another medical center to determine the reproducibility of identified SCs and begin to explore clinical predictors (e.g., socio-demographics, laboratory results, and medications) of SCs. The specific aims are to 1) develop a data-driven pipeline for the characterization of SCs from EHRs using a cohort of adult patients diagnosed with cancer, as SCs have been most systematically characterized in this condition; 2) apply the pipeline to three other common adult chronic conditions that share biological and behavioral risk factors with cancer, i.e., HF, T2DM, and COPD, and evaluate SCs in these conditions; and 3) determine if SCs differ for cancer, HF, T2DM, and COPD when implementing the pipeline within another medical center and explore clinically relevant, EHR- documented predictors of identified SCs. To accomplish research aims and training goals, an interdisciplinary team of scientists with expertise in symptom science, biomedical informatics, data science, pertinent clinical domains, and career development mentorship has been assembled. This research is significant because a pipeline that accommodates the format in which symptom data is already being documented in EHRs has the potential to greatly accelerate the acquisition of SC knowledge and expedite clinical translation of symptom mitigation strategies. Given the array of new competencies to be developed, this K99/R00 award is necessary for achieving the candidate’s career goal of advancing chronic condition symptom science. The proposed research is relevant to public health because adult patients diagnosed with chronic conditions are frequently burdened by two or more co-occurring, related symptoms. Development of an optimized process to study multiple symptoms collected in patient electronic health records has the potential to lead to new knowledge and improved symptom management. The proposed research addresses the NINR theme of “symptom science” and a key area in the NINR Strategic Plan, “taking advantage of innovations in data science in order to develop interventions to promote health and wellness that are leading-edge, effective, and translatable to clinical practice.”",Advancing Chronic Condition Symptom Cluster Science Through Use of Electronic Health Records and Data Science Techniques,10171921,R00NR017651,"['18 year old', 'Academic Medical Centers', 'Address', 'Adult', 'Advance Directives', 'American', 'Anxiety', 'Area', 'Award', 'Behavioral', 'Biological', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Cluster Analysis', 'Code', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Store', 'Depressed mood', 'Detection', 'Development', 'Diagnosis', 'Dyspnea', 'Electronic Health Record', 'Equipment and supply inventories', 'Ethnic Origin', 'Fatigue', 'Funding', 'Future', 'Genetic', 'Genomics', 'Goals', 'Health Care Costs', 'Health Promotion', 'Healthcare Systems', 'Heart failure', 'Impaired cognition', 'Informatics', 'Intervention', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Life', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mastectomy', 'Medical Genetics', 'Medical center', 'Mentorship', 'Modeling', 'Natural Language Processing', 'Nausea', 'Nausea and Vomiting', 'Neurobehavioral Manifestations', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncology', 'Pain', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Postoperative Nausea and Vomiting', 'Procedures', 'Proteomics', 'Pruritus', 'Public Health', 'Quality of life', 'Race', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Science', 'Scientist', 'Signs and Symptoms', 'Sleep disturbances', 'Strategic Planning', 'Structure', 'Symptoms', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Woman', 'Work', 'Xerostomia', 'base', 'biomarker discovery', 'biomedical informatics', 'career', 'career development', 'clinical data warehouse', 'clinical practice', 'clinical predictors', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'data analysis pipeline', 'data mining', 'data visualization', 'data warehouse', 'electronic data', 'experience', 'health care service utilization', 'health data', 'innovation', 'knowledge translation', 'malignant breast neoplasm', 'patient oriented', 'pre-doctoral', 'process optimization', 'programs', 'sociodemographics', 'statistics', 'symptom cluster', 'symptom management', 'symptom science', 'symptomatic improvement', 'unsupervised learning']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2021,241411
"Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data Project Summary/Abstract The routine operation of the US Healthcare system produces an abundance of electronically-stored data that captures the care of patients as it is provided in settings outside of controlled research environments. The potential for utilizing these data to inform future treatment choices and improve patient care and outcomes of all patients in the very system that generates the data is widely acknowledged. Given these key properties of the routine-care data and the abundance of electronic healthcare databases covering millions of patients, it is critical to strengthen the rigor of analyses of such data. Our group has previously developed an analytic approach to reduce bias when analyzing routine-care databases, which has proven effective in more than 50 empirical research studies across a range of topics and data sources. However, this approach currently cannot incorporate free-text information that is recorded in electronic health records, such as clinical notes and reports. This limitation has left a large amount of rich patient information underutilized for clinical research. We thus aim to adapt and refine a set of established computerized natural language processing algorithms that can identify and extract useful information from the clinical notes and reports in electronic health records and incorporate them into our validated analytical approach for balancing background risks of different comparison groups, a key step to ensure fair evaluation when comparing different therapeutic options. To test this newly integrated and augmented approach, we will implement and adapt it in simulation studies where we can evaluate and improve the performance of these new analytic methods in a controlled but realistic fashion. In addition, we will assess the performance of our new approach in 8 practical studies comparing medical or surgical treatments that are highly relevant to patients. To ensure highest level of data completeness and quality, we have linked multiple healthcare utilization (claims) databases, spanning from 2007 to 2016, with 3 electronic health records systems, including one each in Massachusetts, North Carolina, and Texas. This data will allow testing of our newly integrated approach in a variety of care delivery systems and data environments, which will be very informative for the application of our products in the real-world settings. Narrative The project will yield a highly flexible and effective analytical method for reducing confounding bias in studies that utilize routine-care data to compare effects of medical or surgical treatments. This method will enable researchers to leverage a large amount of patient information recorded in the clinical notes and reports that are contained within electronic health records to adjust for differences in background risks of different comparison groups. Our proposal can improve the quality of evidence based on electronic healthcare data generated in the routine-care settings to better inform patient care and optimal prescribing.",Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data,10168610,R01LM013204,"['Address', 'Algorithms', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Comparative Effectiveness Research', 'Complex', 'Confounding Factors (Epidemiology)', 'Consumption', 'Data', 'Data Set', 'Data Sources', 'Data Store', 'Databases', 'Disease', 'Electronic Health Record', 'Elements', 'Empirical Research', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Future', 'Gold', 'Healthcare', 'Healthcare Systems', 'Influentials', 'Knowledge', 'Knowledge acquisition', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Massachusetts', 'Medical', 'Medicare/Medicaid', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'North Carolina', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Probability', 'Property', 'Proxy', 'Randomized Controlled Trials', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Risk Factors', 'Semantics', 'Severities', 'Specific qualifier value', 'Stratification', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Texas', 'Text', 'Therapeutic', 'Time', 'Training', 'Treatment outcome', 'Validation', 'Weight', 'Work', 'analytical method', 'base', 'care delivery', 'care outcomes', 'comparative effectiveness study', 'comparison group', 'computerized', 'cost', 'disorder risk', 'evidence base', 'flexibility', 'health care service utilization', 'high dimensionality', 'improved', 'innovation', 'machine learning method', 'novel strategies', 'operation', 'outcome forecast', 'preservation', 'randomized trial', 'research study', 'routine care', 'safety study', 'simulation', 'sound', 'tool', 'treatment choice', 'unstructured data']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,469927
"Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports Abstract Unexpected findings, or incidentalomas, are increasing dramatically with the growth in the use of imaging technology within healthcare organizations. Incidentalomas may indicate significant health problems, such as malignancy in the medium or long term. However, they also may lead to overinvestigation, unnecessary radiation exposure, overtreatment, substantial downstream expenditures, and patient anxiety. Several systematic reviews have explored the prevalence and outcomes of incidentalomas. These studies used inconsistent and often inappropriate synthesis methods, commonly only focusing on one imaging scan or organ in a very limited number of patients. As a result, there is need for large-scale study of incidentalomas that can inform their follow up and guide efforts to optimize health outcomes. To address this need, we propose to build natural language processing (NLP) approaches to identify cancer-related incidentalomas reported in radiology reports (Aim 1) and to create the first large-scale incidentaloma database covering over half-a-million patients (Aim 2). Our research dataset will contain radiology reports, clinical notes containing imaging orders, as well as structured data such as demographic information (e.g., age) and diagnoses codes of patients who received radiologic imaging tests in University of Washington Medical Center (UWMC), Harborview Medical Center (HMC), Seattle Cancer Care Alliance (SCCA), and Northwest Hospital and Medical Center (NWMC) between 2007-2019. Our patient population will be linked to Hutchinson Institute for Cancer Outcomes Research (HICOR) data repository for detailed cancer outcomes and claims data. The created database will be used for clinical and economic analysis of incidentalomas (Aim 3). We will (1) evaluate the concordance between radiologists' documentation of incidentaloma follow-up and established clinical guidelines for thyroid, lung, adrenal, kidney, liver, and pancreas incidentalomas, (2) determine risk of subsequent cancer diagnosis and median survival for each category of incidentaloma, and (3) determine the incremental cost associated with follow-up imaging in patients with incidentalomas. All models and their implementations produced during the execution of this project will be shared with the community as open source. Additionally, the de-identified incidentaloma database will be made available to the research community under a data use agreement. By identifying risk factors for cancer diagnosis and death for common incidental findings, we will be able to provide critical information for future clinical practice guideline development and appropriate use criteria. We assembled a highly interdisciplinary team of experts in NLP, medical informatics, radiology, oncology, health outcomes, and health economics to ensure the successful completion of the proposed project. Project Narrative Incidentalomas may indicate significant health problems, such as malignancy to the patient in the short or medium term, but also may lead to overtreatment, which comes with substantial downstream expenditures as well as patient anxiety. In this project, we will build natural language processing approaches to extract cancer related incidentalomas reported in radiology reports (Aim 1) and create the first large scale incidentaloma database for half-a-million patients who received radiologic imaging tests in University of Washington Medical Center, Harborview Medical Center, Seattle Cancer Care Alliance, and Northwest Hospital and Medical Center between 2007 and 2019 (Aim 2). This database will be used for clinical and economic analysis of incidentalomas (Aim 3).",Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports,10116614,R01CA248422,"['Abdomen', 'Active Learning', 'Address', 'Adherence', 'Adrenal Glands', 'Age', 'Agreement', 'Angiography', 'Anxiety', 'Caregivers', 'Categories', 'Cessation of life', 'Chest', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Code', 'Communication', 'Communities', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Economics', 'Ensure', 'Epidemic', 'Expenditure', 'Funding', 'Future', 'Gold', 'Growth', 'Guidelines', 'Health', 'Healthcare', 'Hospitals', 'Image', 'Imaging technology', 'Incidental Findings', 'Institutes', 'Interdisciplinary Study', 'Investigation', 'Kidney', 'Lead', 'Link', 'Liver', 'Lung', 'Lung nodule', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical Informatics', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Oncology', 'Organ', 'Outcome', 'Outcomes Research', 'Pancreas', 'Pancreatic Cyst', 'Patient Noncompliance', 'Patient risk', 'Patients', 'Performance', 'Prevalence', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Project Grants', 'Risk', 'Risk Factors', 'Running', 'Scanning', 'Semantics', 'Services', 'Technology', 'Testing', 'Text', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Universities', 'Washington', 'base', 'cancer care', 'cancer diagnosis', 'cancer risk', 'clinical database', 'cohort', 'comorbidity', 'cost', 'data repository', 'economic evaluation', 'economic impact', 'follow-up', 'health care delivery', 'health care service organization', 'health economics', 'improved', 'machine learning method', 'mortality', 'novel', 'open source', 'overtreatment', 'patient population', 'radiological imaging', 'radiologist', 'repository', 'structured data', 'surveillance imaging', 'systematic review', 'tumor']",NCI,UNIVERSITY OF WASHINGTON,R01,2021,674025
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, “Discovering and applying knowledge in clinical databases,” is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR data—its breadth and flexible nature—imposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,10321056,R01LM006910,"['Active Learning', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Drug Side Effects', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'data reuse', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,37243
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, “Discovering and applying knowledge in clinical databases,” is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR data—its breadth and flexible nature—imposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,10116464,R01LM006910,"['Active Learning', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Drug Side Effects', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'data reuse', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,568584
"eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants Project Abstract eMERGE IV (E4) proposes to investigate the implementation of 15 “genomic risk assessment” (GRA) scores in a network-wide set of diverse participants. These GRAs will include polygenic risk score (PRS) information, as well as risk information, such as personal and family health history, environmental and social health determinants, and physical and lab measures. The GRA will aggregate these factors into a single score to identify those who would benefit from screening and other interventions. Substantial challenges must be addressed before genomic medicine is a part of standard medical care. We will collaborate to refine multi-ancestry GRAs and support the inclusion of non-genetic risk factors extracted from the electronic health record with innovative natural language processing approaches and apply them in a cohort enriched for Asian ancestry, and sexual and gender minorities. The specific aims of our proposal are designed to use an implementation science approach to advance the integration of genomic data into clinical practice, including evaluation of patient perspectives and economic outcomes, and broadening the impact of eMERGE through collaborations. The University of Washington Medicine dedication to preventative health in a learning health system and broad expertise across genomics, statistical, ethical, informatic, implementation, outcomes and economic disciplines will support this multi-site clinical trial. Specific Aims: Aim 1: Refine GRA scores and outcomes measures for five high impact conditions, considering stakeholder input, for implementation in the electronic health record. The conditions are: colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma. Aim 2: Integrate 15 GRA scores and electronic clinical decision support for management into clinical care and the EHR and capture clinical outcomes. Aim 3: Evaluate the implementation, effectiveness, and economic utility of GRA result return. Project Narrative As part of the eMERGE IV (E4) Network clinical trial, we propose to develop 5, and investigate the implementation of 15, “genomic risk assessment” (GRA) scores in a large set of diverse participants. These GRAs will include genetic and non-genetic information. We specifically propose study of implementation and outcomes of GRA scores for colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma in the electronic health record.",eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants,10207713,U01HG008657,"['3-Dimensional', 'Address', 'Adopted', 'Adult', 'Alaska Native', 'Asians', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials Network', 'Collaborations', 'Colorectal Cancer', 'Coronary Arteriosclerosis', 'Data', 'Dedications', 'Development', 'Discipline', 'Disease', 'Economics', 'Education', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environmental Risk Factor', 'Ethics', 'Ethnic group', 'Evaluation', 'Family', 'Family health status', 'Genetic', 'Genetic Risk', 'Genomic medicine', 'Genomics', 'Genotype', 'Glaucoma', 'Health', 'Health system', 'Healthcare', 'Informatics', 'Intervention', 'Leadership', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medicine', 'Methods', 'Mission', 'Morbidity - disease rate', 'Multi-Institutional Clinical Trial', 'Native Americans', 'Natural Language Processing', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Pacific Island Americans', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Population', 'Population Heterogeneity', 'Primary Health Care', 'Process', 'Provider', 'Publishing', 'Recording of previous events', 'Risk', 'Risk Assessment', 'Risk Factors', 'Risk Management', 'Sexual and Gender Minorities', 'Site', 'Underrepresented Populations', 'Universities', 'Variant', 'Washington', 'base', 'clinical care', 'clinical decision support', 'clinical practice', 'cohort', 'data curation', 'design', 'economic outcome', 'economic value', 'ethical legal social implication', 'genetic risk assessment', 'genome wide association study', 'genome-wide', 'genomic data', 'high risk', 'implementation evaluation', 'implementation outcomes', 'implementation science', 'improved', 'innovation', 'malignant breast neoplasm', 'medical specialties', 'mortality', 'non-genetic', 'novel', 'online resource', 'outreach', 'polygenic risk score', 'prevent', 'racial and ethnic', 'risk prediction', 'screening', 'social health determinants', 'support tools', 'tool']",NHGRI,UNIVERSITY OF WASHINGTON,U01,2021,1682350
"Development and validation of an electronic health record prediction tool for first-episode psychosis Psychosis is a major public health challenge, with approximately 100,000 adolescents and young adults in the US experiencing a first episode of psychosis (FEP) every year. Early intervention following FEP is critical for achieving improved outcomes, yet treatment of FEP is often delayed between 1 and 3 years in the US due to delays in detection and referral. The World Health Organization has advocated shortening the duration of untreated psychosis (DUP) to three months or less. The goal of this study is to develop and validate a universal EHR-based screening tool for early detection of FEP across large clinical populations in diverse healthcare settings. In order to maximize the impact and generalizability of the tool across a wide range of healthcare settings, we will rely only on coded medical information collected in the course of care and thus widely available in EHRs. The tool will be developed and validated with data from three diverse health systems that cover over 8 million patients spanning a wide range of demographic, socioeconomic and ethnic backgrounds: Partners Healthcare System, Boston Children's Hospital, and Boston Medical Center. The study will be conducted by a closely collaborating interdisciplinary team of clinical specialists, psychosis researchers, and risk modeling experts based at these health systems and Harvard Medical School, with extensive experience in treating psychosis patients, and developing strategies for detecting FEP and EHR-based risk screening tools for early detection of various clinical conditions. Our preliminary studies show that EHR-based risk models can be used to sensitively and specifically detect FEP cases, on average 2 years before the first psychosis diagnosis appears in their EHR. Our specific aims include: 1. Define a robust cross-site case definition for FEP that relies only on information commonly available in EHRs and validate it through expert chart review; 2. Train and validate a predictive model for early detection of FEP based on large samples of patient data from the three sites; 3. Develop and validate FEP early detection models for key subpopulations, including patients receiving care at mental health clinics, adolescent medicine outpatient programs, and substance abuse treatment programs; and 4. Engage clinical stakeholders in the process of developing a prototype clinician-facing EHR-based risk screening tool for FEP, and release it as an open source SMART App, enabling further validation and clinical integration across a wide range of healthcare settings. Completion of these aims would provide a novel, clinically deployable, and potentially transformative tool for improving the trajectory of those affected with psychosis and reducing the burden and costs of untreated illness. Psychosis is a major public health challenge, with difficulties and delays in detecting its onset that can lead to worse clinical outcomes. The proposed research will develop a clinician-facing electronic-health-record-based automated screening tool for early detection of the first episode of psychosis, with implications for reducing the duration of untreated psychosis as recommended by the NIMH and World Health Organization. The tool will be validated across three large and diverse health systems and released as an open source application (SMART App), increasing its potential for rapid implementation in health systems and clinical care.",Development and validation of an electronic health record prediction tool for first-episode psychosis,10057390,R01MH116042,"['Accident and Emergency department', 'Adolescent Medicine', 'Adolescent and Young Adult', 'Advocate', 'Affect', 'Boston', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Code', 'Communities', 'Data', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'General Population', 'Goals', 'Health system', 'Healthcare Systems', 'Inpatients', 'Intervention', 'Laboratories', 'Lead', 'Manuals', 'Measures', 'Medical', 'Medical center', 'Mental Health', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Primary Health Care', 'Procedures', 'Process', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Risk', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Suicide', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'World Health Organization', 'base', 'clinical care', 'cost', 'data resource', 'design', 'experience', 'first episode psychosis', 'health care settings', 'improved', 'improved outcome', 'individual patient', 'interest', 'medical schools', 'medical specialties', 'novel', 'open source', 'outpatient programs', 'predictive modeling', 'prototype', 'random forest', 'socioeconomics', 'substance abuse treatment', 'support vector machine', 'tool', 'treatment program']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,748815
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,10164857,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,399965
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,10103780,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction', 'risk prediction model', 'structured data', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2021,574852
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format with tremendous potential but an equally large concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potential for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary use of clinical data and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for higher accuracy and much faster de- identification than manual approaches. Clinacuity, Inc. proposes to advance a text de-identification system from a prototype to an accurate, adaptable, and robust system, integrated into the research infrastructure at our implementation and testing site (Medical University of South Carolina, Charleston, SC), and ready for commercialization efforts. To accomplish this undertaking, we will focus on the following specific aims and related objectives, while continuing to prepare the commercialization of the integrated system, with detailed market analysis, commercial roadmap development, and modern media communication: 1) Enhance the text de-identification system performance, scalability, and quality to produce an enterprise-grade solution ready for deployment; 2) Enable use of structured data for enhanced text de-identification (when structured PII is available) and for complete patient records de-identification (i.e., records combining structured and unstructured data). This aim also includes implementing “one-way” pseudo-identifier cryptographic hashing to enable securely linking already de-identified patient records; 3) Integrate the text de-identification system with a research data capture and management system. This includes implementation of the de-identification system as a secure web service, with standards-based access and integration. This de-identification system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will ease research data sharing (as expected for larger NIH-funded research projects) and help healthcare organizations protect patient data confidentiality. Significant time-savings will also be offered, with a process at least 200-1000 times faster than manual de-identification. The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potential, but also equally growing concern for patient confidentiality breaches. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data and protect patient data confidentiality. This project will advance a text de-identification system from a prototype to an accurate, adaptable and robust system allowing for complete patient records de-identification, integrated in the research infrastructure at our implementation and testing site and ready for commercialization efforts. It will improve access to richer, more detailed, and more accurate clinical data for clinical researchers, ease research data sharing and help healthcare organizations protect patient data confidentiality. !",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,10098325,R42GM116479,"['Adoption', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communications Media', 'Confidentiality of Patient Information', 'Data', 'Deimplementation', 'Development', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Funding', 'Growth', 'Health Insurance Portability and Accountability Act', 'Improve Access', 'Link', 'Manuals', 'Medical', 'Modernization', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Performance', 'Personally Identifiable Information', 'Phase', 'Privacy', 'Process', 'Records', 'Reference Standards', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Risk', 'Savings', 'Secure', 'Site', 'South Carolina', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'Universities', 'Visualization', 'base', 'commercial application', 'commercialization', 'cost', 'cryptography', 'data reuse', 'data sharing', 'health care quality', 'health care service organization', 'health care settings', 'health management', 'improved', 'large scale data', 'participant enrollment', 'prototype', 'software development', 'standard measure', 'structured data', 'systems research', 'unstructured data', 'web services']",NIGMS,"CLINACUITY,INC.",R42,2021,725232
"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",Advancing Quality and Outcomes Measurement in Rheumatology,10070083,K24AR074534,"['Address', 'Algorithms', 'American', 'Area', 'Award', 'Back', 'Benchmarking', 'California', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Collection', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Dictionary', 'Disease', 'Electronic Health Record', 'Environment', 'Feeds', 'Foundations', 'Funding', 'Goals', 'Gout', 'Grant', 'Growth', 'Health', 'Healthcare', 'Healthcare Systems', 'High Prevalence', 'Individual', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Leadership', 'Learning', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Monitor', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Preventive care', 'Process', 'Public Health', 'Quality of Care', 'Registries', 'Research', 'Research Personnel', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Safety', 'San Francisco', 'Scientist', 'Specific qualifier value', 'Testing', 'Text', 'Time', 'Training', 'United States', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vision', 'Work', 'base', 'career', 'career development', 'college', 'comorbidity', 'dashboard', 'data mining', 'data modeling', 'data registry', 'data repository', 'data standards', 'design', 'digital', 'evidence base', 'health care quality', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'learning progression', 'novel', 'patient oriented', 'patient oriented research', 'patient registry', 'patient safety', 'programs', 'prototype', 'research study', 'rheumatologist', 'structured data', 'success', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2021,189666
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,10224079,R33AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'data infrastructure', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R33,2021,792718
