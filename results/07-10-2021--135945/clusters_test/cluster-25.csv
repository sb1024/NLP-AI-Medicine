text,title,id,project_number,terms,administration,organization,mechanism,year,cost,funding
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000,511154
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,10054168,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'detection sensitivity', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,120631,551214295
"Develop an Artificial Intelligence-powered Smartphone App AICaries for Caries Detection in Children Project Summary Early childhood caries (ECC) is the most common chronic childhood disease, with nearly 1.8 billion new cases per year globally. ECC afflicts approximately 55% of low-income and minority US preschool children, resulting in harmful short- and long-term effects on health and quality of life. The current biomedical approach to control the ECC pandemic has had limited success. It primarily focuses on restorative procedures rather than population-wide preventive strategies. Clinical evidence shows that caries is reversible if detected and addressed in its early stages. However, many low-income US children often have poor access to pediatric dental services. In this underserved group, dental caries is often diagnosed at a late stage when extensive restorative treatment is needed. We believe that with more than 85% of lower-income Americans owning a smartphone, mHealth tools hold great promise to achieve patient-driven early detection and risk control of ECC. Our long-term goal is to develop strategies that use mHealth tools to achieve early detection and prevention of ECC at a broad population base. Our previous innovative work has led to a novel prototype of an artificial intelligence (AI) -powered smartphone app, AICaries, to be used by children's parents/caregivers. This AICaries app prototype offers a) AI-powered caries detection using photos of children's teeth taken by the parents' smartphones, b) interactive caries risk assessment, and c) personalized education on reducing children's ECC risk. The preliminary AI- powered caries detection module demonstrated a satisfactory sensitivity and specificity for front teeth caries detection, using 6,895 annotated tooth images from 1,277 photos. We have recently built an archive of > 100,000 high-quality intra-oral photos that is ready to be used for finalizing the development of a reliable automatic detection algorithm. The immediate objectives of the study are - AIM 1: complete the development of AICaries smartphone app, maximize its caries detection performance, and achieve a caries detection sensitivity and specificity that are comparable to trained dental practitioners; AIM 2: employ a community-based participatory research strategy to conduct moderated testing and refinement of the app usability, and non-moderated field testing of the app feasibility/acceptability. Our multidisciplinary team is well-positioned for proposal success with needed expertise in computer science, AI imaging recognition, oral health care, mHealth, disparity research, patient education and community engagement. The AICaries app could facilitate early detection of ECC for many underserved US children, who often have poor access to pediatric dental services. Using AICaries, parents can use their regular smartphones to take photo of their children’s teeth and detect ECC aided by AICaries, so that they can actively seek treatment for their children at an early and reversible stage of ECC. Using AICaries, parents can also obtain essential knowledge on reducing their children's caries risk. Data from this R21 will support a R01 clinical trial that evaluates the real-world impact of using this innovative smartphone app on early detection and prevention of ECC among low-income children. Narrative Although largely preventable, early childhood caries (ECC) remains the most common chronic childhood disease, disproportionately afflicts vulnerable parts of the population and has a substantial adverse impact on children, families, and healthcare systems. Our multidisciplinary team is proposing to use an Artificial Intelligence-powered mHealth tool coupled with a community engagement strategy to revolutionize the detection and monitoring of ECC at the patient level, which may pave the way for improving oral heath among low-income children.",Develop an Artificial Intelligence-powered Smartphone App AICaries for Caries Detection in Children,10105768,R21DE030251,"['Address', 'Advisory Committees', 'Algorithms', 'American', 'Archives', 'Artificial Intelligence', 'Caregivers', 'Caries prevention', 'Cellular Phone', 'Child', 'Childhood', 'Chronic', 'Chronic Disease', 'Clinical', 'Clinical Trials', 'Communities', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dental', 'Dental Care', 'Dental Clinics', 'Dental Hygiene', 'Dental caries', 'Dentists', 'Detection', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Diet', 'Disease', 'Early Diagnosis', 'Education', 'Family', 'Family Caregiver', 'Feedback', 'Future', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Image', 'Individual', 'Knowledge', 'Life Style', 'Long-Term Effects', 'Low income', 'Methods', 'Minority', 'Modification', 'Monitor', 'Oral', 'Oral health', 'Parents', 'Patient Education', 'Patients', 'Performance', 'Population', 'Positioning Attribute', 'Preschool Child', 'Prevention', 'Prevention strategy', 'Preventive', 'Procedures', 'Process', 'Quality of life', 'Reporting', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'System', 'Technology', 'Testing', 'Tooth structure', 'Training', 'Underserved Population', 'Work', 'acceptability and feasibility', 'community based participatory research', 'computer science', 'computerized', 'detection sensitivity', 'dieting', 'early childhood', 'education resources', 'empowered', 'field study', 'health literacy', 'improved', 'indexing', 'innovation', 'lower income families', 'mHealth', 'microbial', 'multidisciplinary', 'novel', 'pandemic disease', 'performance tests', 'population based', 'prototype', 'recruit', 'restorative treatment', 'satisfaction', 'skills', 'smartphone Application', 'success', 'tool', 'usability']",NIDCR,UNIVERSITY OF ROCHESTER,R21,2021,189800,179705973
"Robot-Assisted 3D ICE Catheter for Cardiac Ablation ABSTRACT  Although the cardiac ablation procedure for atrial fibrillation has a wide adoption rate, it also has a high recurrence of arrhythmia primarily due to the creation of suboptimal lesions. The procedure is also associated with complications including cardiac perforation, tamponade, atrio-esophageal fistulas and thrombus. Repeated and prolonged X-ray exposure for the clinician can also lead to enhanced risk of cancer. A fluoroless approach using intracardiac echocardiography (ICE) is becoming a more widely adopted imaging option due to the absence of ionizing radiation and the possibility of real-time monitoring of the created lesions. However, the ICE- guided approach suffers from significant shortcomings, which include poor dexterity of the ICE catheter, difficulty in simultaneously manipulating the ICE and ablation catheters, unintuitive image orientation and noisy image quality. There is therefore an unmet need to overcome these shortcomings of the ICE-guided approach to enable better lesion creation and reduced complications associated with the cardiac ablation procedure. The long-term goal of this research is to develop robotic technologies, control and machine learning algorithms to enable ICE- guided cardiac ablation procedures. The objective is to develop a novel robotic manipulator, a steerable ICE catheter, and machine learning and control algorithms to manipulate the ICE catheter and monitor the created lesions in real-time. The rationale that underlies the proposed research is that the robot-assisted steerable ICE catheter with the catheter tracking algorithms will enable simultaneous manipulation of the ICE and ablation catheters. Further, the machine learning algorithms to monitor therapy will reduce the risk of complications, while ensuring the creation of necrotic lesions, thereby reducing the recurrence of AF. In this proposal, we plan to pursue the following specific aims: 1) Design, develop, and model a steerable 3D ICE catheter with enhanced dexterity. 2) Design and develop a robotic manipulator and associated control algorithms to allow for precise manipulation of the ICE catheter. 3) Develop machine-learning and vision-based algorithms integrated with a navigation system for tracking the ablation catheter, and monitoring therapy. 4) Validate the robotic ICE system in heart phantom and porcine models. The proposed research is significant since it will allow for better therapeutic outcomes by reducing recurrence rates and complications associated with cardiac ablation, and avoiding exposure of the patient and clinical care team to X-ray radiation. The proposed research is innovative in that it builds on state-of-the-art robotics technology, machine learning and vision algorithms to enable fluoroless ICE- guided cardiac ablation procedures. PROJECT NARRATIVE  The proposed study addresses an important and under-investigated area of treating atrial fibrillation using a completely fluoroless approach with ICE imaging. The proposed research is significant since it will allow for better therapeutic outcomes by reducing recurrence rates and complications associated with cardiac ablation, and avoiding exposure of the patient and clinical care team to X-ray radiation.",Robot-Assisted 3D ICE Catheter for Cardiac Ablation,10187566,R01EB028278,"['3-Dimensional', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Canada', 'Cardiac', 'Cardiac ablation', 'Catheters', 'Computer Vision Systems', 'Computer software', 'Coupling', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Ensure', 'Esophageal Fistula', 'Family suidae', 'Fluoroscopy', 'Goals', 'Grant', 'Heart', 'Heart Atrium', 'Hospitals', 'Image', 'Intuition', 'Ionizing radiation', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Medical', 'Microbubbles', 'Modeling', 'Monitor', 'Myocardium', 'Navigation System', 'Necrotic Lesion', 'Ontario', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Perforation', 'Performance', 'Positioning Attribute', 'Procedures', 'Pulmonary veins', 'Radial', 'Recurrence', 'Research', 'Research Personnel', 'Risk', 'Robot', 'Robotics', 'Roentgen Rays', 'Surgical Instruments', 'System', 'Technology', 'Thrombus', 'Time', 'Ultrasonography', 'United States', 'Universities', 'Vision', 'Woman', 'Work', 'base', 'cancer risk', 'clinical care', 'convolutional neural network', 'deep learning algorithm', 'design', 'dexterity', 'image guided', 'innovation', 'instrument', 'kinematics', 'light weight', 'machine learning algorithm', 'machine vision', 'novel', 'radio frequency', 'real time monitoring', 'robot assistance', 'therapy outcome', 'time use']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,379119,327644200
"Integrate Dynamic System Model and Machine Learning for Calibration-Free Noninvasive ICP Project Summary  No clinical device exists for noninvasive intracranial pressure (nICP) assessment. Past attempts have focused on identifying ICP-related signals that are noninvasively measureable, but have done little to address the calibration problem. Without calibration, only ICP trending can be inferred at the best. However, noninvasive calibration is not trivial. A universal calibration will fail because individual patients require different calibration to obtain accurate results. On the other hand, the use of plain regression for individualized calibration is infeasible because ICP cannot be obtained noninvasively for a de novo patient to begin with.  Invasive ICP monitoring remains a standard of care and this can be leveraged to continuously grow a database of ICP, noninvasive signals, and different calibration equations, e.g., each built from a pair of invasive ICP and noninvasive signal in the database. Then nICP becomes feasible by selecting from a rich set of calibration equations the optimal choice for a de novo patient. In this project, we will pursue three aims that will lead to the development of an accurate noninvasive ICP system based on Transcranial Doppler. These aims are: 1) To implement and validate core algorithms needed for achieving accurate nICP; 2) To test if estimated nICP is sensitive to variations in ultrasound probe placement; 3) To test the generalizability of the proposed nICP approach.  Large epidemiologic surveys reveal that ICP is monitored in only about 58% of US patients when ICP monitoring is indicated. It is a smaller percentage (37%) in European patients and even fewer in developing countries. The proposed nICP approach does not have the high risks associated with invasive ICP, requires no onsite neurosurgical expertise, and can be economically deployed and readily practiced. Therefore, its potential impact is enormous. Project Narrative  No clinically accepted device exists for noninvasive intracranial pressure (ICP) assessment. This proposed project aims to complete the development and validation of a novel noninvasive ICP assessment approach. Large epidemiologic surveys reveal that ICP is monitored in only about 58% of US patients when ICP monitoring is indicated. It is a smaller percentage (37%) in European patients and even fewer in developing countries. The proposed nICP approach does not have the high risks associated with invasive ICP, requires no onsite neurosurgical expertise, and can be economically deployed and readily practiced. Therefore, its potential impact is enormous.",Integrate Dynamic System Model and Machine Learning for Calibration-Free Noninvasive ICP,10228768,R01NS106905,"['Address', 'Adherence', 'Adoption', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Biological Models', 'Blood Flow Velocity', 'Blood Pressure', 'Body mass index', 'Calibration', 'Cerebrovascular Circulation', 'Clinical', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Developing Countries', 'Development', 'Devices', 'Electrocardiogram', 'Ensure', 'Epidemiology', 'Equation', 'Europe', 'European', 'Fibrinogen', 'Gender', 'Intracranial Hypertension', 'Intracranial Pressure', 'Lead', 'Learning', 'Libraries', 'Machine Learning', 'Measurement', 'Measures', 'Modeling', 'Monitor', 'Morphology', 'Movement', 'Nature', 'Patients', 'Physiologic pulse', 'Research', 'Residual state', 'Secure', 'Signal Transduction', 'Stress Tests', 'Surveys', 'System', 'Temporal bone structure', 'Testing', 'Training', 'Transcranial Doppler Ultrasonography', 'Ultrasonography', 'Validation', 'Variant', 'base', 'dynamic system', 'high risk', 'indexing', 'individual patient', 'kernel methods', 'learning algorithm', 'middle cerebral artery', 'novel', 'standard of care', 'trend']",NINDS,DUKE UNIVERSITY,R01,2021,544156,607172798
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124,27165390
"Neurobehavioral mechanisms of parent-child extinction learning in adolescent PTSD Project Summary The goal of this proposal is to elucidate neurobehavioral mechanisms of parent-child extinction learning in early adolescent PTSD. Notably, deficits in directly learned fear extinction are implicated in adult PTSD. However, youth with PTSD live within the family system, which could impact their ability to extinguish trauma memories. Indeed, abnormal parent-child transmission of fear following trauma is a potent risk factor for youth PTSD. Furthermore, trauma-focused cognitive behavioral therapy (TF-CBT), the gold-standard treatment for pediatric PTSD, uses exposure therapy of the child's trauma narrative for both youth and their caregiver. Here, TF-CBT aims to promote extinction of trauma-related fear both directly in the child and vicariously through parent modeling. However, no reported studies have examined the cumulative impact of direct and vicarious fear extinction in pediatric PTSD. Finally, the diagnosis of PTSD in youth continues to rely on DSM syndromal criteria, creating a great need to establish objective, biologically based diagnoses. This innovative research program will (1) identify physiological impairments in direct/vicarious fear extinction and their unique contributions to adolescent PTSD, (2) identify the neural substrates of fear acquisition and direct/vicarious extinction learning in adolescent PTSD, and (3) use machine learning on biomarkers of fear acquisition and direct/vicarious extinction to classify trauma exposure and PTSD diagnosis in adolescents. This interdisciplinary research team will recruit 40 non-traumatized typically developing (TD) youth, 40 trauma- exposed comparison (TEC) youth without mental illness, and 80 medication-free youth with PTSD, ages 10-14, along with their primary caregiving parent. Youth and parents will undergo fear acquisition followed by a novel fear extinction paradigm. Here, youth will undergo two extinction training conditions: 1) direct extinction and 2) vicarious extinction by observing their parent complete extinction training. Parent/child skin conductance and corrugator EMG will be measured during all fear protocol phases. Additionally, youth will complete all fear phases during fMRI to probe neural substrates of fear acquisition, and direct and vicarious extinction. Following physiological and fMRI analyses, a deep evolutionary machine learning approach will be applied to youth neurophysiological fear indices to classify trauma and PTSD status. Primary analyses will 1) examine physiological markers of direct and vicarious extinction in youth and their relative contribution to PTSD, 2) examine neural abnormalities during direct and vicarious extinction in adolescent PTSD, and 3) determine whether adding vicarious extinction markers enhances machine learning classification of youth trauma and PTSD status. This ambitious program of parent-child extinction learning promises to yield the first comprehensive set of neurophysiological markers of pediatric PTSD that will allow for objective, rational targeting of treatment in the parent-child dyad to improve outcomes for afflicted youth. Project Narrative This project seeks to conduct the first comprehensive, biological study of how parent-child fear and safety learning contribute to adolescent PTSD. This project will establish biomarkers of parent-child safety learning in adolescent PTSD, and test whether machine learning can use these markers to diagnose PTSD in youth. This research would represent a significant advance beyond subjective assessments currently used in clinical settings, paving the way towards biologically-based diagnosis and treatment of youth PTSD within the family context.",Neurobehavioral mechanisms of parent-child extinction learning in adolescent PTSD,10067383,R01MH117141,"['Address', 'Adolescent', 'Adult', 'Age', 'Algorithms', 'Amygdaloid structure', 'Behavioral', 'Biological', 'Biological Markers', 'Biological Testing', 'Caregivers', 'Child', 'Childhood', 'Classification', 'Clinical', 'Cognitive Therapy', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Emotional', 'Emotions', 'Exhibits', 'Extinction (Psychology)', 'Face Processing', 'Family', 'Female', 'Foundations', 'Fright', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Future', 'Galvanic Skin Response', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Impairment', 'Incidence', 'Interdisciplinary Study', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Memory', 'Mental disorders', 'Methods', 'Modeling', 'Parents', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Population', 'Post-Traumatic Stress Disorders', 'Prefrontal Cortex', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Risk Factors', 'Safety', 'Scheme', 'Severities', 'Sex Differences', 'Stimulus', 'Structural defect', 'Syndrome', 'System', 'Testing', 'Training', 'Trauma', 'Work', 'Youth', 'aged', 'base', 'caregiving', 'early adolescence', 'girls', 'imaging platform', 'improved', 'improved outcome', 'indexing', 'innovation', 'learning extinction', 'male', 'neural circuit', 'neurobehavioral', 'neuroimaging', 'neurophysiology', 'novel', 'predicting response', 'programs', 'recruit', 'relating to nervous system', 'response', 'standard care', 'transmission process', 'trauma exposure']",NIMH,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,765655,338121506
"Clinical performance of hemodynamics-based non-invasive device for skin cancer testing Skin cancer is the most common form of cancer in the US, accounting for just under half of all diagnosed cancers (5+ million diagnoses), 27,000+ deaths each year and the annual treatment costs of over $8.1 billion. The early diagnosis of skin cancer has significant impact on patient outcomes and health care costs but remains highly subjective and requires highly specialized training while existing diagnostic devices offer low positive predictive value which results in both, missed skin cancers as well as a large number of unnecessary biopsies. When a patient presents with a suspicious skin lesion, uncertainty in the initial assessment by a dermatologist may lead to biopsies that suggest that no subsequent treatment is necessary (false positive - FP) while at the same time lesions that are not biopsied may warrant treatment (false negative - FN) potentially giving rise to claims of malpractice. FPs subject patients to unnecessary procedures and the health care system to unnecessary costs. FNs result in delayed treatment, compromising patient outcomes and increasing health care costs. This diagnostic problem is exacerbated when a patient first presents to a primary care practice due to lesser diagnostic performance. Here, some patients may be referred unnecessarily to dermatologists while other cases go undetected. The Veriskin’s TruScore device is a proprietary, non-invasive, low-cost, easy-to-use, hand-held unit that supports the diagnosis of skin cancer. It rapidly and objectively determines whether a suspicious skin lesion is cancerous, reducing the number of FNs and also reducing the need for unnecessary biopsies. The device provides a score of 0% to 100% indicating the probability of malignancy. The TruScore works by detecting and analyzing force-induced hemodynamic abnormalities due to pathological angiogenesis which is a well established early hallmark of cancer. Pilot clinical studies indicate >99% sensitivity and >94% specificity in differentiating of skin cancer from a variety of benign conditions. The device is useful at all levels of care, but the greatest benefits to patients may result when the device is used in primary care practice. The specific goal of this project is to test the device in a larger scale clinical study. The long-term goal of the project is to achieve widespread clinical adoption of this simple-to-use and low-cost non- invasive skin cancer diagnostic method and device that will (1) facilitate sensitive, specific and non-subjective assessment of suspect skin regions by general practice clinicians and nurse practitioners, (2) enable precise targeting of patients for biopsies and/or escalation of care and (3) provide overall reduction in skin cancer treatment costs. Project Narrative The lack of accurate, objective skin cancer assessment tool for frontline caregivers leads to preventable loss of lives and costs the US healthcare system over $8B each year.  VeriSkin device enables a low cost, non-invasive, easy-to-use skin cancer diagnostic method that will (1) facilitate accurate and non-subjective assessment of suspect skin lesions by general practice clinicians, nurse practitioners and physician assistants, (2) enable precise targeting of patients for biopsies and/or escalation of care resulting in reduction in both the number of missed skin cancers and the number of unneeded referrals to dermatologists and unnecessary biopsies, and (3) provide overall reduction in skin cancer treatment costs.  The requested funds will be used to demonstrate the safety and the effectiveness of the device in a larger clinical study needed to enable regulatory approval of the device.",Clinical performance of hemodynamics-based non-invasive device for skin cancer testing,10127607,R44CA250768,"['Accounting', 'Adoption', 'Affect', 'Algorithmic Analysis', 'Assessment tool', 'Basal Cell', 'Behavior', 'Benign', 'Biopsy', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cancer Detection', 'Cancer Diagnostics', 'Cancerous', 'Caregivers', 'Caring', 'Certification', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Coupled', 'Cutaneous', 'Data Analyses', 'Decision Making', 'Dermatologist', 'Detection', 'Device Approval', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Early Diagnosis', 'Effectiveness', 'Family Practice', 'Frequencies', 'Funding', 'General Practices', 'General Practitioners', 'Goals', 'Hand functions', 'Health Care Costs', 'Health Personnel', 'Healthcare Systems', 'Image', 'Institutional Review Boards', 'Intercellular Fluid', 'Internal Medicine', 'Investments', 'Lead', 'Lesion', 'Light', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malpractice', 'Measurement', 'Measures', 'Methods', 'Mind', 'Morphology', 'Neoplasms', 'Nevus', 'Non-Invasive Cancer Detection', 'Nurse Practitioners', 'Optics', 'Painless', 'Pathologic', 'Pathologic Neovascularization', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physician Assistants', 'Physicians', 'Pigments', 'Predictive Value', 'Primary Health Care', 'Privatization', 'Probability', 'Procedures', 'Process', 'Provider', 'Research', 'Risk', 'Safety', 'Savings', 'Screening for Skin Cancer', 'Sensitivity and Specificity', 'Skin', 'Skin Cancer', 'Specialist', 'Specificity', 'Squamous cell carcinoma', 'Structure', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Cost', 'Tumor Tissue', 'Uncertainty', 'Unnecessary Procedures', 'Vascular resistance', 'Work', 'absorption', 'accurate diagnosis', 'base', 'cancer diagnosis', 'clinical practice', 'commercialization', 'cost', 'design', 'hemodynamics', 'improved', 'machine learning algorithm', 'mechanical pressure', 'melanoma', 'novel', 'peace', 'pressure', 'response', 'safety testing', 'screening', 'skills', 'skin lesion', 'tumor', 'vascular abnormality']",NCI,"VERISKIN, INC.",R44,2021,833460,1164975
"Malarial retinopathy screening system for improved diagnosis of cerebral malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. In 2018, malaria affected more than 213 million people in Africa alone and claimed 381,000 lives, more than 65% of whom were African children less than 5 years old. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM, incorrect treatment, and resulting mortality or neurological disability. The specificity of the current standard of care for clinical diagnosis of CM (physical symptoms, coma, and malaria parasite test such as rapid diagnostic testing) is reported around 61%. Therefore, there is a significant market need for a highly specific, low-cost, and easy-to-use test to improve CM diagnosis and save lives. Since Malarial retinopathy (MR) is greater than 95% specific to the presence of CM, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. Screening for MR in addition to the current standard of care improves the specificity of CM diagnosis from 61% to 100%. VisionQuest Biomedical has developed ASPIRE, the first fully automated MR detection software integrated with a low-cost and portable retinal camera, a system that can be operated by minimally trained personnel such as medical technician or nurse without the need of an ophthalmic specialist. We have assembled a multidisciplinary team of regulatory consultants, commercialization experts, business development specialists, and clinicians; to clinically deploy and launch ASPIRE in our target market in Africa. This team will validate and prepare ASPIRE for regulatory clearance as well as finalize the marketing and commercial rollout strategy. In Phase II-B, the research team at VisionQuest Biomedical deployed a fully-functional clinical version of ASPIRE and tested it in nine malaria clinics in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In CRP, ASPIRE will be validated for technical and clinical performance and will be brought to commercial readiness with regulatory clearance. We will accomplish this through four specific aims. In the first aim, the software system for MR detection will be validated to bring it under design controls. In the second aim, we will deploy ASPIRE at 25 clinics in Africa to demonstrate safety and efficacy as well as to promote market traction. The third aim will focus on preparing ASPIRE for regulatory submission. In the fourth aim, we will complete African healthcare market research for a startup market of 5 countries (Malawi, Zambia, Kenya, Uganda, Rwanda) and finalize marketing and rollout strategy. Within one year after CRP, our goal will be to deploy ASPIRE in more than 200 malaria clinics across 5 countries in Africa. Narrative Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection, which claims hundreds of thousands of lives of African children every year. The detection of retinal biomarkers of CM, called malarial retinopathy, can improve the diagnostic accuracy of CM. This project proposes the development, clinical deployment, and commercialization of a fully automated malarial retinopathy detection system consisting of a low-cost retinal camera and automatic malarial retinopathy detection software.",Malarial retinopathy screening system for improved diagnosis of cerebral malaria,10253474,SB1AI162452,"['5 year old', 'Affect', 'Africa', 'African', 'Artificial Intelligence', 'Biological Markers', 'Businesses', 'Cerebral Malaria', 'Cessation of life', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Coma', 'Computer software', 'Consult', 'Country', 'Detection', 'Development', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Expert Systems', 'Feedback', 'Goals', 'Government', 'Grant', 'Health', 'Healthcare Market', 'Human Resources', 'Incidence', 'Institution', 'Institutional Review Boards', 'Internet', 'Kenya', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Market Research', 'Marketing', 'Medical', 'Medical Device', 'Medicine', 'Neurologic', 'Nurses', 'Parasites', 'Pathology', 'Performance', 'Pharmacy facility', 'Phase', 'Policies', 'Rapid diagnostics', 'Readiness', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Rwanda', 'Safety', 'Series', 'Software Validation', 'Specialist', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Traction', 'Training', 'Uganda', 'Validation', 'Work', 'Zambia', 'clinical Diagnosis', 'clinical research site', 'commercialization', 'cost', 'design', 'detection platform', 'diagnostic accuracy', 'disability', 'improved', 'malaria infection', 'mortality', 'multidisciplinary', 'physical symptom', 'portability', 'programs', 'research clinical testing', 'research study', 'screening', 'smartphone Application', 'software systems', 'standard of care', 'success', 'usability', 'verification and validation', 'web site']",NIAID,VISIONQUEST BIOMEDICAL INC,SB1,2021,999158,1989109
"Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors ABSTRACT Aura is a digital health platform that uses Epilog™, a miniature, wireless, wearable EEG sensor worn on the scalp below hairline that can record clinical and subclinical seizures. After an initial diagnosis of epilepsy, an epileptologist will use known information about patients’ seizures to guide the best scalp location to place the Epilog EEG sensor (A). EEG data is continuously transferred (B) to the Aura app on a person’s smartphone (C) using secure BluetoothTM where it communicates over WiFi (D) to the Aura cloud platform (E). Epilog EEG is analyzed for seizures and a daily digital seizure diary is shared with epileptologists (F) and pushed back to the Aura app (G). Epilog is recharged daily, and reusable for a year. Epilog is designed to be discreet, allowing for continuous use in all facets of daily life. Data are a 10 s snippet of the beginning of a focal seizure with motor impairment and intact awareness (ILAE 1A1) recorded from Epitel’s single-channel Epilog sensor placed on the left forehead. The patient was admitted for video-EEG monitoring as standard-of-care. This seizure was verified independently by three epileptologists. In Phase I, automated, machine learning-based seizure detection algorithms will be designed to first work in the Aura cloud to detect seizures in Epilog EEG, including seizures a person may not consciously know they are having (>50% of all seizures), such as while sleeping. Aura will run these algorithms developed exclusively for Epilog’s single-channel of EEG to provide a daily digital seizure diary. In Phase II, the Aura system will enter clinical validation trials for FDA clearance as an EEG-based automated home seizure detection and alerting system. Early in Phase II Aura will be commercialized as a medical device-enabled-service business model. Out-of-pocket costs for a person living with epilepsy is an average of $380/year. Armed with long-term, reproducible EEG, epileptologists will now have a more precise, quantitative record of seizure counts, enabling them to adapt patient treatment more rapidly and successfully to improve quality of life. Aura will give people living with epilepsy their lives back. Aura provides certainty where you are and when you need it. Throughout Phase II, physiological, psychological, behavioral, and environmental factors will be combined in the Aura app to collect 27,000 days of multi-modal data from 300 patients to create an unprecedented dataset of features known to precipitate seizures. These data will be used in Phase III to create a robust, wearable seizure forecasting system using artificial intelligence that combines multi-modal seizure precipitating factors, creating an hourly seizure probability. Aura will profoundly disrupt how epilepsy is managed and improve the quality of life of people living with epilepsy. This grant proposal aims to create a digital health platform that includes a wearable medical device worn on the scalp below the hairline. The system detects and counts seizures, and alerts to seizures in real time. The goal is to empower people with epilepsy to take control of their seizure monitoring and help improve the treatment of epilepsy.",Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors,10200346,U44NS121562,"['Adoption', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Auras', 'Awareness', 'Back', 'Behavioral', 'Bluetooth', 'Businesses', 'Cellular Phone', 'Clinical', 'Community Hospitals', 'Consumption', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Emergency Medicine', 'Environment', 'Environmental Risk Factor', 'Epilepsy', 'Event', 'Family', 'Financial Hardship', 'Focal Seizure', 'Forehead', 'Freedom', 'Goals', 'Gold', 'Home environment', 'Hospitals', 'Hour', 'Left', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Paper', 'Patient Self-Report', 'Patients', 'Periodicity', 'Persons', 'Phase', 'Physiological', 'Precipitating Factors', 'Predisposition', 'Probability', 'Process', 'Quality of life', 'Reproducibility', 'Running', 'Scalp structure', 'Screening procedure', 'Secure', 'Seizures', 'Services', 'Sleep', 'Subclinical Seizures', 'System', 'Time', 'Validation', 'Wireless Technology', 'Work', 'base', 'cloud platform', 'cost', 'design', 'diaries', 'digital', 'digital health', 'effective therapy', 'encryption', 'improved', 'machine learning algorithm', 'motor impairment', 'multimodal data', 'multimodality', 'optimal treatments', 'programs', 'psychologic', 'remote monitoring', 'sensor', 'social', 'standard of care']",NINDS,"EPITEL, INC.",U44,2021,999853,0
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10074515,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'detection platform', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2021,1000000,1989109
